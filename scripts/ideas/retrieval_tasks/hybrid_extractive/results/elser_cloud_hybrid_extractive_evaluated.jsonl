{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00580-3166-5282","score":17.053404,"text":"\nIt is accessed with an HTTP API and can therefore be accessed by any device on the internet that speaks HTTP: application code, web browser, IoT device, or mobile phone. IBM Cloudant is a highly available managed service able to continue to operate with multiple hardware failures.\n\nThat's the end of this part. The next part is called The Document.\n\n\n\n\n\n\n\n The Document video \n\nLearn about IBM Cloudant databases and documents work.\n\n\n\n* The Document video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 2 - The IBM Cloudant Document.\n\nIn the previous section, we saw that IBM Cloudant is a JSON document store. Let's find out what that means in practice and how that compares to other types of database.\n\nMost databases store their data in collections that are called tables, where each unit of data is a row, each with identical, fixed columns. The schema of each table is predefined: a list of columns with their name, date type, value constraints, and relations to other tables carefully defined. Each new record forms a row in a table.\n\nIBM Cloudant is different!\n\nAn IBM Cloudant service includes collections that are called databases (instead of tables) each of which contain any number of documents.\n\nThe example of this slide shows the same data that is expressed in a traditional tabular database and how the same data would be stored in IBM Cloudant as JSON documents.\n\nSo if you come from a relational database background: tables are \"databases\" in IBM Cloudant, and rows are \"documents\".\n\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00550-7-2005","score":16.833296,"text":"\nGrouping related documents together in IBM Cloudant \n\nTraditionally, e-commerce systems are built with relational databases. These databases typically use a number of tables joined to record sales, customer details, purchased products, and delivery tracking information.\n\nRelational databases offer high consistency, which means that application developers can build their applications to a database's strengths. This practice includes joins between collections, enumerations to record the state of an object, and database transactions to guarantee atomic operations.\n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae favors availability over consistency. It's a high-availability, fault-tolerant, distributed database that is eventually consistent. A distributed database means the customer's shopping service is always available and scalable enough to cope with many users who make purchases at the same time. With that in mind, your application can leverage IBM Cloudant's strengths and not treat it like a relational database.\n\nThis discussion outlines some of the factors that are involved in building an e-commerce system that takes advantage of IBM Cloudant's strengths. IBM Cloudant uses concepts that are applicable to many other domains, such as:\n\n\n\n* Using multiple documents to represent the state of a purchase, rather than frequently updating a single document.\n* Storing copies of related objects in order instead of joining to another collection.\n* Creating views to collate documents by order_id to reflect the current state of a purchase.\n\n\n\nFor example, you might create a purchase document that includes details such as the items ordered, customer information, cost, and delivery information.\n\nSee the following example document that describes a purchase:\n\n{\n\"_id\": \"023f7a21dbe8a4177a2816e4ad1ea27e\",\n\"type\": \"purchase\",\n\"order_id\": \"320afa89017426b994162ab004ce3383\",\n\"basket\": [\n{\n\"product_id\": \"A56\",\n\"title\": \"Adele - 25\",\n\"category\": \"Audio CD\",\n\"price\": 8.33,\n\"tax\": 0.2,\n\"quantity\": 2\n},\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudant"},{"document_id":"ibmcld_09715-2612-4022","score":16.200602,"text":"\n[IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) IBM Cloudant is a document-oriented database as a service (DBaaS). It stores data as documents in JSON format. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-monitor-ibm-cloud-pm) \n [IBM Cloud Databases for PostgreSQL](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-getting-started) IBM Cloud Databases for PostgreSQL is a managed PostgreSQL service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-monitoring) \n [IBM Cloud Databases for Redis](https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-getting-started) IBM Cloud Databases for Redis is a managed service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-monitoring) \n [IBM Cloud Databases for etcd](https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-getting-started) IBM Cloud Databases for etcd is a managed etcd service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-monitoring)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-cloud_services"},{"document_id":"ibmcld_00612-7-2163","score":16.15645,"text":"\nMigration overview \n\nThe [IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae](https:\/\/www.ibm.com\/cloud\/cloudant) database-as-a-service offering is a JSON document store that runs on multi-tenant clusters. The service is available with a choice of geographical locations with predictable costs, scalability, and a service-level agreement (SLA).\n\nYou can migrate to an IBM Cloudant Lite or Standard plan instance on IBM Cloud from one of the following plans:\n\n\n\nTable 1. IBM Cloudant migration paths\n\n Plan Description \n\n IBM Cloudant Enterprise Dedicated, single-tenant clusters \n Apache CouchDB The self-hosted, open source database on which IBM Cloudant is based. \n\n\n\n\n\n Benefits of the IBM Cloudant Lite and Standard plans \n\nWith the Standard plan, you can reserve throughput capacity for your database service, that is, to specify how much throughput your application's database is going to need to handle demand. The Standard plan also charges for the amount of storage you use. Capacity is measured with the following metrics:\n\n\n\nTable 2. Capacity metrics\n\n Metric Description \n\n Reads per second The rate when simple document fetches are performed, for example, retrieving a document by its _id, or querying against a partitioned database that uses a partition key. \n Writes per second The rate when data is written to the database. API calls dealing with document creation, update, or deletion count as \"writes\". \n Global Queries per second The rate when the database is queried by global indices, typically by accessing the _find endpoint, secondary MapReduce, or search indices. \n Storage The amount of disk space occupied by your JSON data, attachments, and secondary indices. \n\n\n\nAs an example, the Lite plan offers 20 reads per second, 10 writes per second, 5 global queries per second, and 1 GB of storage for free. This plan is ideal when you're evaluating the product and during product development. When your application goes into QA or production, switch to the Standard plan to scale the instance. The Standard plan's smallest capacity has 100 reads per second, 50 writes per second, 5 global queries per second, and 20 GB of storage for USD$76.65 per month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-ibm-cloudant-on-ibm-cloud"},{"document_id":"ibmcld_00550-2700-4404","score":16.092848,"text":"\n* The basket duplicates some of the product data in this record, enough to record the state of the items purchased at the point of sale.\n* The document doesn't contain fields that mark the status of the order. More documents would be added later to record payments and delivery.\n* The database automatically generates a document _id when it inserts the document into the database.\n* A unique identifier (order_id) is supplied with each purchase record to reference the order later.\n\n\n\nWhen the customer places an order, typically at the point when they enter the check out phase on the website, a purchase order record is created similar to the previous example.\n\n\n\n Generating your own unique identifiers (UUIDs) \n\nIn a relational database, sequential \"auto incrementing\" numbers are often used. While in distributed databases, data is spread around a cluster of servers, and longer UUIDs are used to ensure that documents are stored with their unique ID.\n\nTo create a unique identifier for use in your application, such as an order_id, call the [GET _uuids endpoint](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetuuids) on the IBM Cloudant API. The database generates an identifier for you. The same endpoint can be used to generate multiple IDs by adding a count parameter, for example, \/_uuids?count=10.\n\n\n\n\n\n Recording payments \n\nWhen the customer successfully pays for their items, more records are added to the database to record the order.\n\n\n\n Example of a payment record \n\n{\n\"_id\": \"bf70c30ea5d8c3cd088fef98ad678e9e\",\n\"type\": \"payment\",\n\"account_id\": \"985522332\",\n\"order_id\": \"320afa89017426b994162ab004ce3383\",\n\"value\": 6.46,\n\"method\": \"credit card\",\n\"payment_reference\": \"AB9977G244FF2F667\"\n}\n...\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudant"},{"document_id":"ibmcld_00580-25421-27357","score":15.793286,"text":"\nType acurl $URL\/_all_dbs to see an array of databases.\n\n\n\nA quick note here on formatting JSON on the command line. We can send the output of our acurl command to another tool, which formats the data nicely on the terminal. The following tools are available for your use:\n\n\n\n* Jq available from the URL on the page, which is more than just a JSON formatter - it allows JSON to be parsed, queried, and manipulated too.\n* python -m json.tool is a simple JSON formatter, if Python is installed on your computer.\n\n\n\nSo acurl $URL\/_all_dbs | jq means pipe the output of acurl into jq and what you see is a nicely formatted, colored output.\n\nThe IBM Cloudant API paths are hierarchical with the first level that gives you information about the service, and then each database sits at a level beneath it.\n\nSo acurl $URL\/books gives us information about the books database that we created earlier.\n\nYou see information about how many documents it has, how many deleted documents, and how much disk space it's occupying.\n\nDon't forget to pipe the output to jq or Python to get a prettier output.\n\nIf we want to see the documents contained in the database, we can use the _all_docs endpoint.\n\nSo acurl $URL\/books\/_all_docs means get all the documents from the books database from the IBM Cloudant service at the supplied URL.\n\nThis command's results return a list of _id and _rev values for each document. If you want the document bodies too, then add ?include_docs=true to your API call.\n\nIf we want to fetch a single document back from the database, then documents sit one level beneath the database in the hierarchy of the URL.\n\nSo acurl $URL\/books\/id means \"get document ID from the database books from the IBM Cloudant service at the supplied URL\".\n\nNotice the hierarchy: service, database, and document.\n\nSo far we only used the GET HTTP method, which is the default one for curl and the one used when you enter a URL into your web browser.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00580-6386-8382","score":15.620933,"text":"\nIt has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.\n\nDevelopers like this flexibility because they can design their data in their code, turn it into JSON, and write it to the database.\n\nIt's still important to think about the shape of your data, especially in terms of how you are going to query and index it, as we see later.\n\nData design is still required, but strictly speaking that database doesn't need to know about your schema.\n\nLet's say we want to create a database of US presidents. We can simply devise our \"model\" of the data in our app, turn it into JSON, and write it to the database. In this case, we are using a common CouchDB convention: the \"type\" field indicates the data type of the document.\n\nIf at a future date we decide we want to add more data to our \"schema\", we can simply write a new object to the database with no complaints from IBM Cloudant. We could decide to add the \"address\" object only to the following documents:\n\n\n\n* Documents that are created from now on.\n* Only documents that we have addresses for.\n\n\n\nIn other words, documents of the same type can have fields present or missing.\n\nYour database's schema can evolve over time to match your application's needs. You don't (necessarily) need to tell the database about the schema change - write new documents in the new format.\n\nWe can even store multiple document \"types\" in the same database. In this case, people, books, and places reside in the same database. We know which is which because of the \"type\" field (this field is a convention and not something that means anything to IBM Cloudant).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_07502-7384-9254","score":15.561755,"text":"\n[IBM Cloud Databases](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-about) provide automatic daily backups that are stored in the same account and geography. Backups are typically stored in [cross-regional storage](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups&interface=uibackup-locations) and should therefore be immune to a single region outage. This facility is reliable and convenient, but does not currently support backup storage in a specified alternate region or account. However, backups can be [restored to another region or account](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups&interface=ui), so recovery to a passive deployment (cold standby) is supported.\n\nIt is also possible to use database-specific clients (for example pg_dump for PostgreSQL) to backup IBM Cloud Databases to arbitrary storage by using customer automation. If used, these backups should be stored in Cloud Object Storage in an alterative region and in the backup account as described in [Backup accounts](https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture?topic=enterprise-account-architecture-bcdraccounts).\n\n\n\n\n\n Virtual servers \n\nBoth [volume snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backups-vpc-best-practices&interface=ui) and [Veeam](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-veeam) are available to backup virtual servers. Veeam is preferred for extensive feature set and its ability to backup application workloads. However, Veeam does require deploying an agent to backup workloads not hosted on VMWare. The Veeam server that is used for backups should be located in a alterative region and in the backup account as described in [Backup accounts](https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture?topic=enterprise-account-architecture-bcdraccounts).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture?topic=enterprise-account-architecture-bcdr"},{"document_id":"ibmcld_00576-6036-7924","score":15.545756,"text":"\nFor more information, see [IBM Cloud Databases for PostgreSQL](https:\/\/www.ibm.com\/cloud\/databases-for-postgresql).\n* Data warehouse for ad hoc querying. For more information, see [IBM\u00ae Db2\u00ae Warehouse on Cloud](https:\/\/www.ibm.com\/products\/db2-warehouse).\n* A queue. For more information, see [IBM MQ](https:\/\/www.ibm.com\/uk-en\/products\/mq).\n\n\n\nFor more information, see the [Best and worst practice](https:\/\/blog.cloudant.com\/2019\/11\/21\/Best-and-Worst-Practices.html) blog.\n\n\n\n\n\n Organizing documents and databases \n\nIBM Cloudant data is organized in a hierarchy of databases and documents. A document is a JSON object with a unique identifier: its _id. A database is a collection of documents with a primary index that allows documents to be retrieved by _id. It also has optional secondary indexes that allow documents to be queried by other attributes in the object.\n\nWhen developers start a project, they sometimes struggle with the following questions:\n\n\n\n* How much data can I put into a single object?\n* Must I store different document types in the same collection or one database per document type?\n\n\n\nIt is important for a document to include all the data about an object that is modeled by your application, for example, a user, an order, or a product. This practice ensures you fetch the entire object from the database in one API call. IBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00580-4796-6846","score":15.545049,"text":"\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.\n\n\n\n* The first example shows a person object, storing strings, booleans, and an array of tags.\n* The second example shows brief attribute names to save on storage and represents a web event such as click a website.\n* The last example shows how the document may itself contain subjects.\n\n\n\nA note on dates. JSON has no native Date type, so dates are usually stored in 30-October-2018 or similar formats. We return to dates later.\n\nNow, for your first practical exercise, visit www.ibm.com\/cloud. Register an account with the IBM Cloud, if you don't have one already.\n\nOnce registered, you can click services, search for the Cloudant database, and provision a new service.\n\nThe IBM Cloudant Lite service provides a free plan to allow users to try IBM Cloudant in a limited capacity while in development. Its bigger brother, the Standard Plan, is a paid-for service where you specify the number of reads, writes, and queries per second for your application and that capacity is reserved for you. You pay for the capacity you provision and your data storage usage.\n\nThe Lite plan operates in a similar way. It has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00623-7-1781","score":17.144503,"text":"\nWorking with IBM Cloudant Query \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query is a declarative JSON querying syntax for IBM Cloudant databases. You can use a json or text type of index with IBM Cloudant.\n\nIn the following cases, you can specify how the index is created by making it of type json:\n\n\n\n* You know exactly what data you want to look for.\n* You want to keep storage and processing requirements to a minimum.\n\n\n\nBut for maximum flexibility when you search for data, you typically create an index of type text. Indexes of type text have a simple mechanism for automatically indexing all the fields in the documents.\n\nWhile more flexible, text indexes might take longer to create and require more storage resources than json indexes.\n\n\n\n Creating an index \n\nYou can create an index with one of the following types:\n\n\n\n* \"type\": \"json\"\n* \"type\": \"text\"\n\n\n\n\n\n Creating a type=json index \n\nTo create a JSON index in the database $DATABASE, make a POST request to \/$DATABASE\/_index with a JSON object that describes the index in the request body. The type field of the JSON object must be set to json. A JSON index can be partitioned or global; this option is set by using the partitioned field.\n\nSee the following example that uses HTTP to request an index of type JSON:\n\nPOST \/$DATABASE\/_index HTTP\/1.1\nContent-Type: application\/json\n\nSee the following example of a JSON object that creates a partitioned index that is called foo-partitioned-index for the field called foo:\n\n{\n\"index\": {\n\"fields\": [\"foo\"]\n},\n\"name\" : \"foo-partitioned-index\",\n\"type\" : \"json\",\n\"partitioned\": true\n}\n\nSee the following example of a JSON object that creates a global index that is called bar-global-index for the field called bar:\n\n{\n\"index\": {\n\"fields\": [\"bar\"]\n},\n\"name\" : \"bar-global-index\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-query"},{"document_id":"ibmcld_00580-4796-6846","score":16.421957,"text":"\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.\n\n\n\n* The first example shows a person object, storing strings, booleans, and an array of tags.\n* The second example shows brief attribute names to save on storage and represents a web event such as click a website.\n* The last example shows how the document may itself contain subjects.\n\n\n\nA note on dates. JSON has no native Date type, so dates are usually stored in 30-October-2018 or similar formats. We return to dates later.\n\nNow, for your first practical exercise, visit www.ibm.com\/cloud. Register an account with the IBM Cloud, if you don't have one already.\n\nOnce registered, you can click services, search for the Cloudant database, and provision a new service.\n\nThe IBM Cloudant Lite service provides a free plan to allow users to try IBM Cloudant in a limited capacity while in development. Its bigger brother, the Standard Plan, is a paid-for service where you specify the number of reads, writes, and queries per second for your application and that capacity is reserved for you. You pay for the capacity you provision and your data storage usage.\n\nThe Lite plan operates in a similar way. It has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_07046-13262-15106","score":15.930176,"text":"\n* The field with the longest string value and highest number of distinct values is chosen.\n* If more than one field meets the previous condition, one of the fields is chosen at random.\n\n\n\n* If you want to apply an enrichment to a nested field, you must create a Content Mining project, and then apply the enrichment to the field. If you want to use a project type other than Content Mining, you can reuse the collection that you created with the Content Mining project type elsewhere. For more information, see [Applying enrichments](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-database-cp4dconnector-database-cp4d-enrich-db).\n\n\n\nYou can specify the normalizations and conversions objects in the [Update a collection](https:\/\/cloud.ibm.com\/apidocs\/discovery-dataupdatecollection) method of the API to move or merge JSON fields.\n\n\n\n\n\n\n\n How passages are derived \n\nDiscovery uses sophisticated algorithms to determine the best passages of text from all of the documents that are returned by a query. Passages are returned per document by default. They are displayed as a section within each document query result and are ordered by passage relevance.\n\nDiscovery uses sentence boundary detection to pick a passage that includes a full sentence. It searches for passages that have an approximate length of 200 characters, then looks at chunks of content that are twice that length to find passages that contain full sentences. Sentence boundary detection works for all supported languages and uses language-specific logic.\n\nFor all project types except Conversational Search, you can change how the passages are displayed in the search results from the Customize display > Search results page. For example, you can configure the number of passages that are shown per document and the maximum character size per passage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-index-overview"},{"document_id":"ibmcld_00580-6386-8382","score":15.901202,"text":"\nIt has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.\n\nDevelopers like this flexibility because they can design their data in their code, turn it into JSON, and write it to the database.\n\nIt's still important to think about the shape of your data, especially in terms of how you are going to query and index it, as we see later.\n\nData design is still required, but strictly speaking that database doesn't need to know about your schema.\n\nLet's say we want to create a database of US presidents. We can simply devise our \"model\" of the data in our app, turn it into JSON, and write it to the database. In this case, we are using a common CouchDB convention: the \"type\" field indicates the data type of the document.\n\nIf at a future date we decide we want to add more data to our \"schema\", we can simply write a new object to the database with no complaints from IBM Cloudant. We could decide to add the \"address\" object only to the following documents:\n\n\n\n* Documents that are created from now on.\n* Only documents that we have addresses for.\n\n\n\nIn other words, documents of the same type can have fields present or missing.\n\nYour database's schema can evolve over time to match your application's needs. You don't (necessarily) need to tell the database about the schema change - write new documents in the new format.\n\nWe can even store multiple document \"types\" in the same database. In this case, people, books, and places reside in the same database. We know which is which because of the \"type\" field (this field is a convention and not something that means anything to IBM Cloudant).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00580-9670-11721","score":15.81772,"text":"\nThat's the end of this part. The next part is called The Document ID.\n\n\n\n\n\n\n\n The _id video \n\nLearn how _ids work in IBM Cloudant, how they are different from relational databases, and how you can define your own _id.\n\n\n\n* The _id video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 3 - The Document _id.\n\nIn the previous section, we saw how data is stored in IBM Cloudant documents with flexibility on how your application stores JSON objects in IBM Cloudant databases. However, a few hard and fast rules exist.\n\nOne rule is that every document must contain a unique identifier that is called _id, which is a string. Two documents in the same database can have the same _id field. In other databases, you specify which column is the unique identifier, but in IBM Cloudant, it's always _id and can't be changed.\n\nAlso, unlike relational databases, IBM Cloudant does not have \"auto-incrementing IDs\" that is, an ID field that starts at 1 and increments for each document added.\n\nIBM Cloudant's _id field is one of the following strings:\n\n\n\n* A 32-character string generated by IBM Cloudant. The ID is a meaningless sequence of numbers and letters that are guaranteed to be unique.\n* A string that is defined by you (if you know something unique about your data).\n\n\n\nThe following examples show how to supply your own document _id:\n\nUsing it to store something that you know is unique that is, the email address of a user. Your registration mechanism can enforce a one-user-per-email address policy. Some users choose to encode the document type in the _id, for example, user:56, book:55. The last example shows with a 32-digit string (generated in your app) that is designed to sort in approximate date and time order. This method makes it easy to retrieve the latest documents from the database, without a secondary index.\n\nIBM Cloudant takes your document _ids and stores them in an index (like the contents page of book).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_13493-1220-3010","score":15.755082,"text":"\n* If the format of the input objects is CSV and a delimiter other than the default , (comma) is used, you must specify the delimiter by using the FIELDS TERMINATED BY option of the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause. All single Unicode characters are allowed as delimiters.\n* By default, it is assumed that CSV input objects have a header line that specifies the names of the input columns. If the objects don't have a header line, you must specify NOHEADER in the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause.\n* By default, it is assumed that JSON input objects consist of a single JSON record per line. If individual records span multiple lines, you must specify MULTILINE in the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause.\n* If required, you can use JOIN constructs to join data from several input URIs, even if those URIs point to different instances of Cloud Object Storage.\n* Use the INTO clause of a [query](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencechapterSQLQueryStatement) to specify the output [URI](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-runningunique), that is, the location to which the result is to be written and the wanted result format.\n\n\n\n2. The Target location field displays where the result is stored. An initial bucket in one of your Object Storage instances is automatically created for you when you open the UI. It is then chosen as your default location, if your query does not specify an INTO clause. To ensure the automatic setup of an initial bucket, do the following steps in advance:\n\n\n\n* You must create an Object Storage instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-running"},{"document_id":"ibmcld_00526-7-1750","score":15.561984,"text":"\nOverview \n\nDocuments are [JSON objects](https:\/\/en.wikipedia.org\/wiki\/JSONData_types.2C_syntax_and_example). Documents are also containers for your data, and are the basis of the IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae database.\n\nIf you're using an [IBM Cloudant service on IBM Cloud\u00ae](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicibm-cloud-public), documents are limited to a maximum size of 1 MB. Exceeding this limit causes a [413 error](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes).\n\nIBM Cloudant uses an [eventually consistent](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cap-theoremcap-theorem) model for data. If you use the eventually consistent model, it's possible, under some conditions, to retrieve older document content. For example, older content is retrieved when your application writes or updates a document that is followed immediately by a read of the same document.\n\nIn other words, your application would see the document content as it was before the write or update occurred. For more information about this model, see the topic on [Consistency](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cap-theoremcap-theorem).\n\n\n\n Document fields \n\nAll documents must have two fields:\n\n\n\n* A unique _id field. The _id field is detailed in the next section.\n* A _rev field. The _rev field is a revision identifier, and is [essential to the IBM Cloudant replication protocol](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-document-versioning-and-mvccdocument-versioning-and-mvcc).\n\n\n\nIn addition to these two mandatory fields, documents can generally contain any other content that can be described by using JSON, subject to some caveats detailed in the following sections.\n\n\n\n Document IDs","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-documents"},{"document_id":"ibmcld_00518-7-1546","score":15.497486,"text":"\nDesign document management \n\nThe scalable JSON data store for IBM Cloudant has several querying mechanisms, all of which generate indices that are created and maintained separately from the core data.\n\nArticle contributed by Glynn Bird, Developer Advocate at IBM Cloudant, [glynn@cloudant.com](mailto:glynn@cloudant.com).\n\nIndexing isn't performed immediately when a document is saved. Instead, indexing is scheduled to happen later, providing a faster, non-blocking write throughput.\n\n\n\n* MapReduce views are indexes into the data set with key value pairs that are stored in a BTree for efficient retrieval by key or range of keys.\n* Search Indexes are constructed by using Apache Lucene to allow free-text search, faceting, and complex ad hoc queries.\n\n\n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae's [search indexes](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-search) and [MapReduce views](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-views-mapreduce) are configured by adding design documents to a database. Design documents are JSON documents that include the instructions about how the view or index is to be built. Let's take a simple example. Assume that you have a simple collection of data documents, similar to the following example.\n\nSee an example of a simple data document:\n\n{\n\"_id\": \"23966717-5A6F-E581-AF79-BB55D6BBB613\",\n\"_rev\": \"1-96daf2e7c7c0c277d0a63c49b57919bc\",\n\"doc_name\": \"Markdown Reference\",\n\"body\": \"Lorem Ipsum\",\n\"ts\": 1422358827\n}\n\nEach data document includes a name, a body, and a timestamp.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-design-document-management"},{"document_id":"ibmcld_00580-3166-5282","score":15.467147,"text":"\nIt is accessed with an HTTP API and can therefore be accessed by any device on the internet that speaks HTTP: application code, web browser, IoT device, or mobile phone. IBM Cloudant is a highly available managed service able to continue to operate with multiple hardware failures.\n\nThat's the end of this part. The next part is called The Document.\n\n\n\n\n\n\n\n The Document video \n\nLearn about IBM Cloudant databases and documents work.\n\n\n\n* The Document video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 2 - The IBM Cloudant Document.\n\nIn the previous section, we saw that IBM Cloudant is a JSON document store. Let's find out what that means in practice and how that compares to other types of database.\n\nMost databases store their data in collections that are called tables, where each unit of data is a row, each with identical, fixed columns. The schema of each table is predefined: a list of columns with their name, date type, value constraints, and relations to other tables carefully defined. Each new record forms a row in a table.\n\nIBM Cloudant is different!\n\nAn IBM Cloudant service includes collections that are called databases (instead of tables) each of which contain any number of documents.\n\nThe example of this slide shows the same data that is expressed in a traditional tabular database and how the same data would be stored in IBM Cloudant as JSON documents.\n\nSo if you come from a relational database background: tables are \"databases\" in IBM Cloudant, and rows are \"documents\".\n\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00576-7385-9302","score":15.446811,"text":"\nIBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether. Otherwise, separate databases, for example, users, orders, products, might be better so that secondary indexes are specific to each object type.\n\nIf you're storing arrays of objects within a document, consider whether the array items must really be their own document. For example, a product and each product review must be stored in separate documents, but a user and each of that user's orders must have their own document.\n\nIf you have an ever-growing data set, then you probably don't want to store data in a single, ever-growing database. Data is best stored in time-boxed databases that allow older data to be archived and deleted cleanly. Deleting an IBM Cloudant document leaves a tombstone document behind, so don't rely on deleting documents to recover disk space. Instead, you must rely on deleting whole databases.\n\nJSON doesn't offer a native way to store dates or timestamps. Choose your [date format](https:\/\/blog.cloudant.com\/2018\/05\/24\/Date-formats.html) carefully if you intend to query it later.\n\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2043823976}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13064-7-2233","score":16.156929,"text":"\nWhat is IBM Cloud Object Storage? \n\nIBM Cloud\u00ae Object Storage is a highly available, durable, and secure platform for storing unstructured data. Unstructured data (sometimes called binary or \"blob\" data) refers to data that is not highly structured in the manner of a database. Object storage is the most efficient way to store PDFs, media files, database backups, disk images, or even large structured datasets.\n\nThe files that are uploaded into IBM Cloud Object Storage are called objects. Objects can be anywhere from very small (a few bytes) [to very large] (up to 10TB). They are organized into buckets that serve as containers for objects, and which can be configured independently from one another in terms of locations, resiliency, billing rates, security, and object lifecycle. Objects themselves have their own metadata in the form of user-defined tags, legal holds, or archive status. Within a bucket, the hierarchy of objects is effectively \"flat\", although it is possible to add prefixes to object names to provide some organization and to provide flexibility in listing and other operations.\n\nIBM Cloud Object Storage is strongly consistent for all data operations, and eventually consistent for bucket configuration operations. This means that when an object is uploaded, the server responds with a 200 OK after the object is successfully written, and the object is immediately available for listing and reading. All data stored in IBM Cloud Object Storage is encrypted, erasure-coded, and dispersed across three locations (with the distance between locations ranging from within a single data center, across a Multi-Zone Region or MZR, or even across multiple MZRs). This geographic range of dispersal contributes to a bucket's resiliency.\n\nAll requests and responses are made over HTTPS and all requests support the use of hash-based integrity checks using a Content-MD5 header. If the provided MD5 hash does not match the checksum computed by the storage service, the object is discarded and an error is returned. All GET and HEAD requests made to objects return an Etag value with the MD5 hash of the object to ensure integrity on the client side.\n\nDevelopers use APIs to interact with their object storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage"},{"document_id":"ibmcld_10885-21825-23148","score":14.924734,"text":"\nDatabases are deployed on a virtual server. Backup is enabled and replication is set up between regions. The alternative would be to use a database-as-service, a topic discussed later in the tutorial.\n5. IBM Cloud File Storage for Classic to store the application images and files, File Storage for Classic offers the capability to take a snapshot at a given time and date, this snapshot then can be reused within another region, something that you would do manually.\n\n\n\nThe tutorial [Use Virtual Servers to build highly available and scalable web app](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-highly-available-and-scalable-web-applicationhighly-available-and-scalable-web-application) implements this architecture.\n\n\n\n\n\n Back up and restore procedures \n\nRefer to the following backup and restore procedures:\n\n\n\n* [Managing backups for Databases for Elasticsearch](https:\/\/cloud.ibm.com\/docs\/services\/databases-for-elasticsearch?topic=cloud-databases-dashboard-backups)\n* [Managing backups for Databases for PostgreSQL](https:\/\/cloud.ibm.com\/docs\/services\/databases-for-postgresql?topic=cloud-databases-dashboard-backups)\n* [Backups and restoration for Databases for Redis](https:\/\/cloud.ibm.com\/docs\/services\/databases-for-redis?topic=cloud-databases-dashboard-backupsbackups-and-restoration)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-bcdr-app-recovery"},{"document_id":"ibmcld_06968-15099-17180","score":14.797274,"text":"\n[checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/icons\/checkmark-icon.svg) \n\n\n\n\n\n* PDF files that are secured with a password or certificate are not supported. Vector objects, including SVG images and vectorized text, are not supported. Only images of the supported image file types that occur in the PDF are rendered.\n* Only single-page image files are supported.\n* Files within compressed archive files (ZIP, GZIP, TAR) are extracted. Discovery ingests the supported file types within the archive; it ignores all other file types. The file names must be encoded in UTF-8. Files with names that include Japanese characters, for example, must be renamed before they are added to the ZIP file.\n* Discovery supports MacOS ZIP files only if they are generated by using a command such as: zip -r my-folder.zip my-folder -x \".DS_Store\". ZIP files that are created by right-clicking a folder and clicking Compress are not supported.\n* PDF files that you upload as part of an archive file are not displayed in the advanced view for a query result that you open from the Improve and customize page. If you want the file to be viewable from the advanced view, reimport the PDF file separately from the archive file.\n\n\n\nWhen you add files to a Document Retrieval for Contracts project type, any file types that support SDU and OCR are processed with a pretrained Smart Document Understanding model and Optical Character Recognition automatically.\n\n\n\n\n\n Document limits \n\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"},{"document_id":"ibmcld_00556-7-1696","score":14.525955,"text":"\nHow to use attachments \n\nAnother way to store data is to use attachments. Attachments are Binary Large OBject ([BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object)) files that are included within documents.\n\nIt's a good idea to keep attachments small in size and number because attachments can impact performance.\n\nThe BLOB is stored in the _attachments component of the document. The BLOB holds data that includes the following information:\n\n\n\n* The attachment name\n* The type of the attachment\n* The actual content\n\n\n\nExamples of BLOBs would be images and multimedia.\n\nIf you include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the overall JSON, the attachment content is represented by using BASE64 form.\n\nThe content type corresponds to a [MIME type](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types). For example, if you want to attach a .jpg image file to a document, you specify the attachment MIME type as image\/jpeg.\n\nAttachments aren't permitted on documents in [_replicator](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostreplicate) or [_users](https:\/\/cloud.ibm.com\/apidocs\/cloudantputsecurity) databases.\n\n\n\n Create or update \n\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/$DOCUMENT_ID\/$ATTACHMENT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_00510-7123-9213","score":14.413999,"text":"\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1. IBM Cloudant is expensive as a block store.\n2. IBM Cloudant\u2019s internal implementation is not efficient in handling large amounts of binary data.\n\n\n\nSo, slow and expensive.\n\nIBM Cloudant is acceptable for small assets and occasional use. As a rule, if you need to store binary data alongside IBM Cloudant documents, it\u2019s better to use a separate solution more suited for this purpose. You need store only the attachment metadata in the IBM Cloudant document. Yes, that means you need to write some extra code to upload the attachment to a suitable block store of your choice. Verify that it succeeded before you store the token or URL to the attachment in the IBM Cloudant document.\n\nYour databases are smaller, cheaper, faster, and easier to replicate. For more information, see the following websites:\n\n\n\n* IBM Cloudant docs on [attachments](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments)\n* Detaching IBM Cloudant attachments to [Object Storage](https:\/\/medium.com\/codait\/detaching-cloudant-attachments-to-object-storage-with-serverless-functions-99b8c3c77925)\n\n\n\n\n\n\n\n Fewer databases are better than many \n\nIf you can, limit the number of databases per IBM Cloudant account to 500 or fewer. While this particular number is not magic (IBM Cloudant can safely handle more), several use cases exist that are adversely affected by large numbers of databases in an account.\n\nThe replicator scheduler has a limited number of simultaneous replication jobs that it is prepared to run. As the number of databases grows, the replication latency is likely to increase if you try to replicate everything contained in an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_05166-15912-16684","score":14.352157,"text":"\nThis allows for lower latency when accessing storage from compute resources co-located within the same data center, or for data requiring a specific geographic location. More information can be found in the [Select Regions and Endpoints](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) documentation.\n\n\n\n\n\n 8 August 2017 \n\nIntroducing IBM Cloud Object Storage\n: Object Storage is a highly available, durable, and secure platform for storing unstructured data. Unstructured data (sometimes called binary or \"blob\" data) refers to data that is not highly structured in the manner of a database. Object storage is the most efficient way to store PDFs, media files, database backups, disk images, or even large structured datasets.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-updates"},{"document_id":"ibmcld_00580-3166-5282","score":14.335743,"text":"\nIt is accessed with an HTTP API and can therefore be accessed by any device on the internet that speaks HTTP: application code, web browser, IoT device, or mobile phone. IBM Cloudant is a highly available managed service able to continue to operate with multiple hardware failures.\n\nThat's the end of this part. The next part is called The Document.\n\n\n\n\n\n\n\n The Document video \n\nLearn about IBM Cloudant databases and documents work.\n\n\n\n* The Document video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 2 - The IBM Cloudant Document.\n\nIn the previous section, we saw that IBM Cloudant is a JSON document store. Let's find out what that means in practice and how that compares to other types of database.\n\nMost databases store their data in collections that are called tables, where each unit of data is a row, each with identical, fixed columns. The schema of each table is predefined: a list of columns with their name, date type, value constraints, and relations to other tables carefully defined. Each new record forms a row in a table.\n\nIBM Cloudant is different!\n\nAn IBM Cloudant service includes collections that are called databases (instead of tables) each of which contain any number of documents.\n\nThe example of this slide shows the same data that is expressed in a traditional tabular database and how the same data would be stored in IBM Cloudant as JSON documents.\n\nSo if you come from a relational database background: tables are \"databases\" in IBM Cloudant, and rows are \"documents\".\n\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_07152-5566-7596","score":14.323987,"text":"\nYou can view the number of documents stored and the total amount of storage used by either using the [Environments](https:\/\/cloud.ibm.com\/apidocs\/discoveryget-environment-info) or [Collections](https:\/\/cloud.ibm.com\/apidocs\/discoveryget-collection-details) API, or by using the tooling. If your documents are, on average, larger than 100KB on disk, you will hit the storage limit of a plan before the maximum document limit. If you perform [document segmentation](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configservicedoc-segmentation) on your documents, each segment counts as a separate document.\n\n** The [IBM Watson\u2122 Natural Language Understanding enrichments](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceadding-enrichments) are: Entity Extraction, Sentiment Analysis, Category Classification, Concept Tagging, Keyword Extraction, Relation Extraction, Emotion Analysis, Element Classification, and Semantic Role Extraction. Only the first 50,000 characters of each document are enriched.\n\n*** Element Classification is an enrichment that parses through governing documents to convert, identify, and classify elements of importance. It uses Natural Language Processing to extract the following elements from PDF documents: party (who it refers to), nature (type of element), and category (specific class).\n\nTo take advantage of the new string environment sizing values (LT, XS, S, MS, M, ML, L, XL, XXL, XXXL), use the version date of 2018-08-01 or later in your API request when you create an environment. Before version 2018-08-01, the value was an integer.\n\n\n\n\n\n Premium \n\nPremium plans offer developers and organizations a single tenant instance of one or more Watson services for better isolation and security. These plans offer compute-level isolation on the existing shared platform, as well as end-to-end encrypted data while in transit and at rest.\n\nFor more information, or to purchase a Premium plan, contact [Sales](https:\/\/ibm.biz\/contact-wdc-premium).\n\n\n\n\n\n Additional information","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-discovery-pricing-plans"},{"document_id":"ibmcld_09715-2612-4022","score":14.152977,"text":"\n[IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) IBM Cloudant is a document-oriented database as a service (DBaaS). It stores data as documents in JSON format. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-monitor-ibm-cloud-pm) \n [IBM Cloud Databases for PostgreSQL](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-getting-started) IBM Cloud Databases for PostgreSQL is a managed PostgreSQL service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-monitoring) \n [IBM Cloud Databases for Redis](https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-getting-started) IBM Cloud Databases for Redis is a managed service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-monitoring) \n [IBM Cloud Databases for etcd](https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-getting-started) IBM Cloud Databases for etcd is a managed etcd service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-monitoring)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-cloud_services"},{"document_id":"ibmcld_06427-3-1675","score":13.886535,"text":"\nIBM Cloud\u00ae Databases for etcd docs \n\netcd is a distributed, reliable key-value store for the most critical data of a distributed system.\n\n Developer tools \n\n[API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/cloud-databases-api\/cloud-databases-api-v5introduction)[CLI reference](https:\/\/cloud.ibm.com\/docs\/databases-cli-plugin)[Terraform reference](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/database)\n\n Recommended content \n\n[Getting Started A brief tutorial to introduce using an IBM Cloud\u00ae Databases for etcd deployment.](https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-getting-started)[Setting the Root Password The Databases for etcd service is provisioned with a root user. You must set the root password before you use it to connect.](https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-root-password)[Creating Users and Getting Connection Strings To connect to IBM Cloud\u00ae Databases for etcd, you need some users and connection strings. Connection Strings for your deployment are displayed on the Dashboard Overview, in the Endpoints panel. These strings can be used with any set of credentials that you generate.](https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-connection-strings&interface=ui)\n\n Learn more \n\n[IBM Developer<br><br>Visit IBM Developer for technical articles, code patterns, tutorials, and more.<br><br>![112-Developer-tools.svg](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/112-Developer-tools.svg)](https:\/\/developer.ibm.com\/depmodels\/cloud\/)[Architecture Center<br><br>Discover the architecture references available for this product.<br><br>!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06968-16615-18789","score":18.684605,"text":"\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row\n* Each object that is defined in an array in a JSON file results in a separate document\n\n\n\n\n\nNumber of documents per service instance\n\n Plan Documents per service instance \n\n Cloud Pak for Data Unlimited \n Premium Unlimited \n Enterprise Unlimited \n Plus (includes Trial) 500,000 \n\n\n\nThe maximum allowed number can vary slightly depending on the size of the documents. Use these values as a general guideline.\n\n\n\n\n\n File size limits \n\n\n\n Crawled documents \n\nThe maximum size of each file that you can crawl by using a connector differs by deployment type.\n\nIBM Cloud\n\nManaged deployments on IBM Cloud\n\n\n\n* Premium plans only:\n\n\n\n* Box: 50 MB\n* IBM Cloud Object Store: 50 MB\n* Salesforce Files objects: 50 MB\n* All other data sources: 10 MB\n\n\n\n* All other plans: 10 MB\n\n\n\nIBM Cloud Pak for Data\n\nInstalled deployments on IBM Cloud Pak for Data\n\n\n\n* All data sources: 32 MB\n\n\n\n\n\n\n\n Uploaded documents \n\nThe size of each file that you can upload depends on your Discovery plan type. See the *Maximum document size table for details.\n\n\n\nMaximum document size\n\n Plan File size per document \n\n Cloud Pak for Data 50 MB \n Premium 50 MB \n Enterprise 10 MB \n Plus (includes Trial) 10 MB \n\n\n\n\n\n\n\n\n\n Field limits \n\nWhen a document is added to a collection, content from the document is evaluated and added to the appropriate fields in an internal index.\n\nFor structured data, such as uploaded CSV or JSON files, or data from crawled databases, each column or object is stored as a root-level field. For example, if you add a CSV file to collection, each column in the CSV file is stored as a separate field in the index.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"},{"document_id":"ibmcld_00500-14708-16372","score":18.4393,"text":"\nWe limit documents to a maximum size of 64 MB.\n\n\n\n\n\n No JavaScript reducers when options.partitioned is true \n\nDesign documents with options.partitioned set to true can't contain JavaScript reduce functions, only built-ins Erlang reducers such as _stats.\n\n\n\n\n\n\n\n Storing the view definition \n\nEach view is a JavaScript function. Views are stored in design documents. So, to store a view, IBM Cloudant simply stores the function definition within a design document. A design document can be [created or updated](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-design-documentscreating-or-updating-a-design-document) just like any other document.\n\nTo store a view definition, PUT the view definition content into a _design document.\n\nIn the following example, the getVerifiedEmails view is defined as a map function, and is available within the views field of the design document.\n\nUse the PUT method to add a view into a design document:\n\nPUT $SERVICE_URL\/$DATABASE\/_design\/$DDOC HTTP\/1.1\nContent-Type: application\/json\n\nThe following sample adds a new getVerifiedEmails named view function to the allusers design document with view definition:\n\n{\n\"views\": {\n\"getVerifiedEmails\": {\n\"map\": \"function(user) { if(user.email_verified === true){ emit(doc.email, {name: user.name, email_verified: user.email_verified, joined: user.joined}) }} \"\n}\n}\n}\n\nSee the request examples:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X PUT \"$SERVICE_URL\/users\/_design\/allusers\" --data '{\n\"views\": {\n\"getVerifiedEmails\": {\n\"map\": \"function(user) { if(user.email_verified === true){ emit(doc.email, {name: user.name, email_verified: user.email_verified, joined: user.joined}) }}\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-creating-views-mapreduce"},{"document_id":"ibmcld_00558-23465-25360","score":18.42063,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-23555-25450","score":18.42063,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_06968-18330-20453","score":18.350164,"text":"\nPlus (includes Trial) 10 MB \n\n\n\n\n\n\n\n\n\n Field limits \n\nWhen a document is added to a collection, content from the document is evaluated and added to the appropriate fields in an internal index.\n\nFor structured data, such as uploaded CSV or JSON files, or data from crawled databases, each column or object is stored as a root-level field. For example, if you add a CSV file to collection, each column in the CSV file is stored as a separate field in the index.\n\nA maximum of 1,000 fields can be added to the index.\n\nYou cannot assign the data type, such as Date or String, of a field. The data type is detected automatically and assigned to the field during document ingestion. The assignment is based on the data type that is detected from the first document that is indexed. Ingestion errors can occur in subsequent documents if a different data type is detected for the value in the same field. Therefore, if your documents have a mix of data types in a single field, first ingest the document that has a value with the most flexible data type, such as String, in the field.\n\nWhen you crawl a website or upload an HTML file, the HTML content is added to the collection and indexed in an html field.\n\nThe following table shows the maximum size limit for fields per document.\n\n\n\nMaximum field sizes\n\n Field type Maximum allowed size per document \n\n html field 5 MB \n Sum of all other fields 1 MB \n\n\n\nIf the maximum size of the fields in the document exceeds the allowed limits, they are treated as follows:\n\n\n\n* For a document with an oversized html field, all of the fields in the document are indexed except the html field.\n\nFor IBM Cloud Pak for Data version 4.0 and earlier, the entire document is not indexed.\n* For a document with oversized non-HTML fields, the document is not indexed.\n\n\n\nIf you are uploading a Microsoft Excel file and a message is displayed that indicates that the non-HTML field size limit is exceeded, consider converting the XLS file into a CSV file. When you upload a comma-separated value (CSV) file, each row is indexed as a separate document. As a result, no field size limits are exceeded.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-collections"},{"document_id":"ibmcld_00576-8941-10714","score":18.048666,"text":"\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https:\/\/blog.cloudant.com\/2019\/05\/10\/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https:\/\/blog.cloudant.com\/2019\/04\/08\/Time-series-data-storage.html)\n* [Partitioned databases - data design](https:\/\/blog.cloudant.com\/2019\/03\/05\/Partition-Databases-Data-Design.html)\n\n\n\n\n\n\n\n Making the most of the primary index \n\nIBM Cloudant has a primary index on the document's _id attribute. This index allows documents to be retrieved by _id (GET \/db\/id) or a range of _ids (GET \/db\/_all_docs?startkey=\"a\"&endkey=\"z\"). By storing data in the primary key and ensuring that each _id is unique, the primary index can be used to fetch documents and ranges of documents without secondary indexing. See the following list of ideas:\n\n\n\n* If you have something unique in your object that would be useful to query against, use it as your _id field, for example, bob.smith@gmail.com, isbn9780241265543, or oakland,ca.\n* If your objects contain a hierarchy, model that in your _id: usa:ca:oakland or books:fiction:9780241265543. The hierarchy goes from largest to smallest, so you can use the primary index to find all the cities in usa or all the cities in usa:ca, without secondary indexing.\n* If you're storing time-series data, encoding time at the start of your _id sorts the primary index by time, for example, 001j40Ox1b2c1B2ubbtm4CsuLB4L35wQ.\n* Partitioned databases group documents that share a partition key together. A partition key must have many values and must not include hot spots to avoid directing a large proportion of your application's traffic to a few partitions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_01234-7-2066","score":17.908754,"text":"\nGetting started with File Storage for Classic \n\nIBM Cloud\u00ae File Storage for Classic is persistent, fast, and flexible network-attached, NFS-based File Storage for Classic. In this network-attached storage (NAS) environment, you have total control over your file shares function and performance. File Storage for Classic shares can be connected to up to 64 authorized devices over routed TCP\/IP connections for resiliency.\n\nFor more information about using File Storage for Classic with the IBM Cloud\u00ae Kubernetes Service, see [Storing data on classic IBM Cloud File Storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-file_storage).\n\n\n\n Before you begin \n\nFile Storage for Classic volumes can be provisioned from 20 GB to 12 TB with two options:\n\n\n\n* Provision Endurance tiers that feature pre-defined performance levels and other features like snapshots and replication.\n* Build a high-powered Performance environment with allocated input\/output operations per second (IOPS).\n\n\n\nFor more information about the File Storage for Classic offering, see [What is IBM Cloud File Storage](https:\/\/www.ibm.com\/products\/file-storage).\n\n\n\n\n\n Step 1: Provisioning considerations \n\n\n\n Block size \n\nThe IOPS value for both Endurance and Performance is based on a 16-KB block size with a 50\/50 read and write, 50\/50 random and sequential workload. A 16-KB block is the equivalent of one write to the volume.\n\nThe block size that is used by your application directly impacts the storage performance. If the block size that is used by your application is smaller than 16 KB, the IOPS limit is realized before the throughput limit. Conversely, if the block size that is used by your application is larger than 16 KB, the throughput limit is realized before to the IOPS limit.\n\n\n\nTable 1 shows examples of how block size and IOPS affect the throughput. Average IO size x IOPS = Throughput in MB\/s.\n\n Block Size (KB) IOPS Throughput (MB\/s) \n\n 4 1,000 4 \n 8 1,000 8 \n 16 1,000 16 \n 32 500 16 \n 64 250 16 \n 128 128 16 \n 512 32 16 \n 1024 16 16 \n\n\n\n\n\n\n\n Authorized hosts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-getting-started"},{"document_id":"ibmcld_00581-0-1268","score":17.841951,"text":"\n\n\n\n\n\n\n  Limits \n\nLimits that pertain to the usage of IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases are shown in the following tables.\n\n\n\n  Databases \n\n\n\nTable 1. Limits for databases\n\n Description     Limit                                                                             \n\n Database size   Consult the IBM Cloudant team if your database is likely to exceed 5 TB in size.  \n Partition size  10 GB                                                                             \n\n\n\n\n\n\n\n  Indexes \n\n\n\nTable 2. Limits for indexes\n\n Description                  Limit     \n\n Number of global indexes     Unlimited \n Number of partition indexes  10        \n\n\n\n\n\n\n\n  Request payload \n\n\n\nTable 3. Limits for request payload\n\n Description         Limit \n\n Total request size  10 MB \n Document size       1 MB  \n Attachment size     10 MB \n\n\n\n\n\n\n\n  Request timeouts \n\n\n\nTable 4. Limits for request timeouts\n\n Description     Limit      \n\n Default         60 seconds \n _partition\/*    5 seconds  \n\n\n\n\n\n\n\n  Query \n\n\n\nTable 5. Limits for query results\n\n Description                    Limit     \n\n Default                        Unlimited \n _partition\/* default           2000      \n _search                        200       \n _find by using text index      200       \n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-limits"},{"document_id":"ibmcld_16727-1272819-1274596","score":17.79394,"text":"\nAny volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760 \n 80 GB 20,971,520 \n 100 GB 26,214,400 \n 500 GB 131,072,000 \n 1 TB 268,435,456 \n 4 TB 1,073,741,824 \n 8 TB 2,040,109,451 \n 12 TB 2,040,109,451 \n\n\n\n* I ordered a File Storage for Classic volume in the wrong data center. Is it possible to move or migrate it to another data center?\n\nYou need to order new File Storage for Classic in the right data center, and then cancel the File Storage for Classic device that you ordered in the incorrect location. When the volume is canceled, the request is followed by a 24-hour reclaim wait period. You can still see the volume in the console during those 24 hours. Billing for the volume stops immediately. When the reclaim period expires, the data is destroyed and the volume is removed from the console, too.\n* Measuring IOPS\n\nIOPS is measured based on a load profile of 16-KB blocks with random 50 percent reads and 50 percent writes. Workloads that differ from this profile might experience poor performance. To improve performance, you can try adjusting the host settings or [enabling Jumbo frames](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-jumboframes).\n* What happens when I use a smaller block size for measuring performance?\n\nMaximum IOPS can be obtained even if you use smaller block sizes. However, the throughput is less in this case. For example, a volume with 6000 IOPS has the following throughput at various block sizes:\n\n\n\n* 16 KB * 6000 IOPS == 93.75 MB\/sec","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1270170-1271947","score":17.79394,"text":"\nAny volume of 7.8 TB or larger reaches the maximum limit at 2,040,109,451 inodes.\n\n\n\nTable comparison\nTable 1 shows the maximum number of inodes that are allowed based on the volume size. Volume sizes are in the left column. The numbers of inodes (files and directories) are on the right.\n\n Volume Size Inodes \n\n 20 GB 5,242,880 \n 40 GB 10,485,760 \n 80 GB 20,971,520 \n 100 GB 26,214,400 \n 500 GB 131,072,000 \n 1 TB 268,435,456 \n 4 TB 1,073,741,824 \n 8 TB 2,040,109,451 \n 12 TB 2,040,109,451 \n\n\n\n* I ordered a File Storage for Classic volume in the wrong data center. Is it possible to move or migrate it to another data center?\n\nYou need to order new File Storage for Classic in the right data center, and then cancel the File Storage for Classic device that you ordered in the incorrect location. When the volume is canceled, the request is followed by a 24-hour reclaim wait period. You can still see the volume in the console during those 24 hours. Billing for the volume stops immediately. When the reclaim period expires, the data is destroyed and the volume is removed from the console, too.\n* Measuring IOPS\n\nIOPS is measured based on a load profile of 16-KB blocks with random 50 percent reads and 50 percent writes. Workloads that differ from this profile might experience poor performance. To improve performance, you can try adjusting the host settings or [enabling Jumbo frames](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-jumboframes).\n* What happens when I use a smaller block size for measuring performance?\n\nMaximum IOPS can be obtained even if you use smaller block sizes. However, the throughput is less in this case. For example, a volume with 6000 IOPS has the following throughput at various block sizes:\n\n\n\n* 16 KB * 6000 IOPS == 93.75 MB\/sec","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00556-7-1696","score":19.577057,"text":"\nHow to use attachments \n\nAnother way to store data is to use attachments. Attachments are Binary Large OBject ([BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object)) files that are included within documents.\n\nIt's a good idea to keep attachments small in size and number because attachments can impact performance.\n\nThe BLOB is stored in the _attachments component of the document. The BLOB holds data that includes the following information:\n\n\n\n* The attachment name\n* The type of the attachment\n* The actual content\n\n\n\nExamples of BLOBs would be images and multimedia.\n\nIf you include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the overall JSON, the attachment content is represented by using BASE64 form.\n\nThe content type corresponds to a [MIME type](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types). For example, if you want to attach a .jpg image file to a document, you specify the attachment MIME type as image\/jpeg.\n\nAttachments aren't permitted on documents in [_replicator](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostreplicate) or [_users](https:\/\/cloud.ibm.com\/apidocs\/cloudantputsecurity) databases.\n\n\n\n Create or update \n\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/$DOCUMENT_ID\/$ATTACHMENT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_00510-7123-9213","score":18.225857,"text":"\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1. IBM Cloudant is expensive as a block store.\n2. IBM Cloudant\u2019s internal implementation is not efficient in handling large amounts of binary data.\n\n\n\nSo, slow and expensive.\n\nIBM Cloudant is acceptable for small assets and occasional use. As a rule, if you need to store binary data alongside IBM Cloudant documents, it\u2019s better to use a separate solution more suited for this purpose. You need store only the attachment metadata in the IBM Cloudant document. Yes, that means you need to write some extra code to upload the attachment to a suitable block store of your choice. Verify that it succeeded before you store the token or URL to the attachment in the IBM Cloudant document.\n\nYour databases are smaller, cheaper, faster, and easier to replicate. For more information, see the following websites:\n\n\n\n* IBM Cloudant docs on [attachments](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments)\n* Detaching IBM Cloudant attachments to [Object Storage](https:\/\/medium.com\/codait\/detaching-cloudant-attachments-to-object-storage-with-serverless-functions-99b8c3c77925)\n\n\n\n\n\n\n\n Fewer databases are better than many \n\nIf you can, limit the number of databases per IBM Cloudant account to 500 or fewer. While this particular number is not magic (IBM Cloudant can safely handle more), several use cases exist that are adversely affected by large numbers of databases in an account.\n\nThe replicator scheduler has a limited number of simultaneous replication jobs that it is prepared to run. As the number of databases grows, the replication latency is likely to increase if you try to replicate everything contained in an account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-data-modeling"},{"document_id":"ibmcld_00556-10831-12062","score":16.16072,"text":"\nThe content must be provided by using [BASE64](https:\/\/en.wikipedia.org\/wiki\/Base64) representation, as shown in the example.\n\nA full list of media types is available in the [media types](https:\/\/en.wikipedia.org\/wiki\/Internet_media_typeList_of_common_media_types) article.\n\nSee the following example JSON document that includes an inline attachment of a jpeg image:\n\n{\n\"_id\":\"document_with_attachment\",\n\"_attachments\":\n{\n\"name_of_attachment\": {\n\"content_type\":\"image\/jpeg\",\n\"data\": \"iVBORw0KGgoAA... ...AASUVORK5CYII=\"\n}\n}\n}\n\n\n\n\n\n Performance considerations \n\nWhile document attachments are useful, they do have implications for application performance. In particular, having too many attachments can have an adverse performance impact during replication.\n\nFor example, if your application requires storage for multiple images as attachments or includes large images, you must use an alternative [BLOB](https:\/\/en.wikipedia.org\/wiki\/Binary_large_object) storage mechanism to store the images. You might then use IBM Cloudant to keep the image metadata, such as URLs to the BLOB store.\n\nYou might find it helpful to do performance testing for your specific application to determine which approach works best for your circumstances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_00523-10191-11663","score":16.032179,"text":"\n* Attachments aren't backed up by the tools.\n* Backups aren't precisely accurate \"point-in-time\" snapshots. The reason is that the documents in the database are retrieved in batches, but other applications might be updating documents at the same time. Therefore, the data in the database can change between the times when the first and last batches are read.\n* Index definitions held design documents are backed up, but when data is restored the indexes must be rebuilt. This rebuilding might take a considerable amount of time, depending on how much data is restored.\n\n\n\n\n\n\n\n Next steps with your data protection strategies \n\nYou can develop applications that build on basic IBM Cloudant functions and supported tools to enable more complex data protection strategies. Example scenarios are shown in the following list:\n\n\n\n* Restoring single documents from previous states.\n* Storing multiple previous document states to allow for restores from older backups.\n* Migrating older data to cheaper storage, for more cost-effective retention.\n\n\n\nThe backup tools consist of an open source node.js command-line application and library. It's available on [NPM](https:\/\/www.npmjs.com\/package\/@cloudant\/couchbackup).\n\nFor ideas and examples that show how to integrate the tools into your data protection strategy, see the [IBM Cloudant backup and recovery guide](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup"},{"document_id":"ibmcld_00564-2769-4709","score":15.269905,"text":"\n* _security settings aren't backed up by the tools.\n* Attachments aren't backed up by the tools.\n* Backups aren't precise \"point-in-time\" snapshots. The reason is that the documents in the database are retrieved in batches, but other applications might be updating documents at the same time. Therefore, data in the database can change between the times when the first and last batches are read.\n* Index definitions that are held in design documents are backed up, but the content of indexes isn't backed up. This limitation means that when data is restored, the indexes must be rebuilt. The rebuilding might take a considerable amount of time, depending on how much data is restored.\n\n\n\n\n\n\n\n Using the tools \n\nThe [NPM page](https:\/\/www.npmjs.com\/package\/@cloudant\/couchbackup) details the basics of using the command-line tools for backup and restore of data. The following examples show how to put those details into practice by describing the use of the tools for specific tasks.\n\nThe CouchBackup package provides two ways of using its core functions.\n\n\n\n* The command-line tools can be embedded into standard UNIX\u2122 command pipelines. For many scenarios, a combination of cron and simple shell scripting of the couchbackup application is sufficient.\n* A library usable from Node.js. The library allows more complicated backup processes to be created and deployed, such as determining dynamically which databases must be backed up.\n\n\n\nUse either the command-line backup tool, or the library with application code, to enable backup from IBM Cloudant databases as part of more complicated situations. A useful scenario is scheduling backups by using cron, and automatically uploading data to [Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage\/solutions?mhq=object%20storage%20public&mhsrc=ibmsearch_a) for long-term retention.\n\n\n\n\n\n Command line scripting examples \n\nYou frequently need to meet the following two requirements:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recovery"},{"document_id":"ibmcld_00576-2983-5018","score":15.090342,"text":"\nFiles that include media, such as images, videos, and audio, are called BLOBs (Binary Large Objects). BLOBs can be stored as attachments associated with documents.\n\nMore information about JSON can be found in the [JSON Guide](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-json-works).\n\n\n\n\n\n Distributed systems \n\nBy using IBM Cloudant's API, you can interact with a collaboration of numerous machines, called a cluster. The machines in a cluster must be in the same datacenter, but can be within different \"pods\" in that datacenter. Using different pods helps improve the High Availability characteristics of IBM Cloudant.\n\nAn advantage of clustering is that when you need more computing capacity, you add more machines. This method is often more cost-effective and fault-tolerant than scaling up or enhancing an existing single machine.\n\nFor more information about IBM Cloudant and distributed system concepts, see the [CAP Theorem](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cap-theorem) guide.\n\n\n\n\n\n Replication \n\n[Replication](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-replication-api) is a procedure followed by IBM Cloudant, [CouchDB](https:\/\/couchdb.apache.org\/), [PouchDB](https:\/\/pouchdb.com\/), and other distributed databases. Replication synchronizes the state of two databases so that their contents are identical.\n\nYou can replicate continuously. Continuous replication means that a target database updates every time the source database changes. Continuous replication can be used for backups of data, aggregating data across many databases, or for sharing data.\n\nHowever, continuous replication means testing continuously for any source database changes. This testing requires continuous internal calls, which might impact performance or the cost of using the database.\n\nContinuous replication can result in many internal calls. These calls might affect costs for multi-tenant users of IBM Cloudant systems. Continuous replication is disabled by default.\n\n\n\n\n\n Using the proper tool for the job","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basics"},{"document_id":"ibmcld_00580-3166-5282","score":15.081277,"text":"\nIt is accessed with an HTTP API and can therefore be accessed by any device on the internet that speaks HTTP: application code, web browser, IoT device, or mobile phone. IBM Cloudant is a highly available managed service able to continue to operate with multiple hardware failures.\n\nThat's the end of this part. The next part is called The Document.\n\n\n\n\n\n\n\n The Document video \n\nLearn about IBM Cloudant databases and documents work.\n\n\n\n* The Document video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 2 - The IBM Cloudant Document.\n\nIn the previous section, we saw that IBM Cloudant is a JSON document store. Let's find out what that means in practice and how that compares to other types of database.\n\nMost databases store their data in collections that are called tables, where each unit of data is a row, each with identical, fixed columns. The schema of each table is predefined: a list of columns with their name, date type, value constraints, and relations to other tables carefully defined. Each new record forms a row in a table.\n\nIBM Cloudant is different!\n\nAn IBM Cloudant service includes collections that are called databases (instead of tables) each of which contain any number of documents.\n\nThe example of this slide shows the same data that is expressed in a traditional tabular database and how the same data would be stored in IBM Cloudant as JSON documents.\n\nSo if you come from a relational database background: tables are \"databases\" in IBM Cloudant, and rows are \"documents\".\n\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00556-7864-9221","score":14.949295,"text":"\nTo delete an attachment, make a DELETE request with the document's most recent _rev to https:\/\/$ACCOUNT.cloudant.com\/$DATABASE\/$DOCUMENT_ID\/$ATTACHMENT. If you don't supply the most recent _rev, the response is a [409 error](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes).\n\nSee the following example of deleting an attachment by using HTTP:\n\nDELETE \/$DATABASE\/$DOCUMENT_ID\/$ATTACHMENT?rev=$REV HTTP\/1.1\n\nSee the following example of deleting an attachment:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -H \"Authorization: Bearer $API_BEARER_TOKEN\" -X DELETE \"$SERVICE_URL\/products\/small-appliances:100001\/product_details.txt?rev=4-1a0d1cd6f40472509e9aac646183736a\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.DeleteAttachmentOptions;\nimport com.ibm.cloud.cloudant.v1.model.DocumentResult;\n\nCloudant service = Cloudant.newInstance();\n\nDeleteAttachmentOptions attachmentOptions =\nnew DeleteAttachmentOptions.Builder()\n.db(\"products\")\n.docId(\"small-appliances:100001\")\n.attachmentName(\"product_details.txt\")\n.rev(\"4-1a0d1cd6f40472509e9aac646183736a\")\n.build();\n\nDocumentResult response =\nservice.deleteAttachment(attachmentOptions).execute()\n.getResult();\n\nSystem.out.println(response);\n\nfrom ibmcloudant.cloudant_v1 import CloudantV1\n\nservice = CloudantV1.new_instance()\n\nresponse = service.delete_attachment(","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-how-to-use-attachments"},{"document_id":"ibmcld_00558-23465-25360","score":14.937359,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-23555-25450","score":14.937359,"text":"\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https:\/\/cloud.ibm.com\/apidocs\/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https:\/\/www.ibm.com\/cloud\/data-centers\/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09715-2612-4022","score":13.407288,"text":"\n[IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) IBM Cloudant is a document-oriented database as a service (DBaaS). It stores data as documents in JSON format. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-monitor-ibm-cloud-pm) \n [IBM Cloud Databases for PostgreSQL](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-getting-started) IBM Cloud Databases for PostgreSQL is a managed PostgreSQL service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-monitoring) \n [IBM Cloud Databases for Redis](https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-getting-started) IBM Cloud Databases for Redis is a managed service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-monitoring) \n [IBM Cloud Databases for etcd](https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-getting-started) IBM Cloud Databases for etcd is a managed etcd service that is hosted in the IBM Cloud and integrated with other IBM Cloud services. [Platform metrics](https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-monitoring)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-cloud_services"},{"document_id":"ibmcld_00578-7-1549","score":13.273895,"text":"\ncloudant.com \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae is a hosted and fully managed database-as-a-service (DBaaS). It was built to scale globally, run non-stop, and handle a wide variety of data types like [JSON](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basicsjson-overview-basics) and [full-text](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-querycreating-an-index).\n\nIBM Cloudant Shared Plan is being retired on 31 March 2018. Starting 24 July 2017, no new Shared Plan accounts can be created from the [IBM Cloudant product page](https:\/\/www.ibm.com\/cloud\/cloudant).\n\nIBM Cloudant is an operational data store optimized to handle concurrent reads and writes, and enable high availability and data durability.\n\nIt provides an [HTTP API](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basicshttp-api-basics) for working with your [JSON](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant-basicsjson-overview-basics) data, and 24-hour operational support and maintenance. IBM Cloudant is based on [Apache CouchDB](https:\/\/couchdb.apache.org\/), and is delivered as various multi-tenant, dedicated, and installed services.\n\nAll currency values in this document are in US dollars ($).\n\nIBM Cloudant is offered as either a [Shared Plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant.comshared-plan) or an [Enterprise (Dedicated) Plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant.comenterprise-plan), and as an [IBM Cloud\u00ae service](https:\/\/www.ibm.com\/cloud\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloudant.com"},{"document_id":"ibmcld_00547-7-1654","score":12.814754,"text":"\nGetting started with IBM Cloudant \n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Getting started tutorial demonstrates how to use the IBM Cloud\u00ae dashboard to create an IBM Cloudant service instance and obtain service credentials to connect to it. Finally, it guides you through the creation of a simple, locally hosted web application that uses your IBM Cloudant database.\n\n\n\n Objectives \n\n\n\n* Create a service instance.\n* Create an IBM Cloudant service credential.\n\n\n\n\n\n\n\n Step 1: Creating a service instance \n\n\n\n1. Log in to your IBM Cloud account, and click Create resource.\n\nZoom\n\n![IBM Cloud Dashboard, which includes Build tile, Monitor your resources tile, Create and deploy an application tile, API Connect tile, Integrate Watson with anything tile, and Watson starter kits tile.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/\/tutorials\/images\/img0001.png)\n\nFigure 1. IBM Cloud Dashboard\n\nThe IBM Cloud Dashboard can be found at: [https:\/\/cloud.ibm.com\/](https:\/\/cloud.ibm.com\/). After you authenticate with your username and password, you're presented with the IBM Cloud Dashboard.\n2. Type Cloudant in the Search bar and click to open it.\n3. Select an offering and an environment.\n4. Type an instance name.\n\nZoom\n\n![Create the IBM Cloudant service name and credentials.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/522c6f62358b063f921283400a601c3f9bc66f08\/Cloudant\/tutorials\/images\/img0005b.png)\n\nFigure 2. IBM Cloudant service name and credentials\n\n(In this example, the instance name is Cloudant-o7.) Verify that the resource group and authentication methods are correct. Add a tag if you like.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant"},{"document_id":"ibmcld_00580-7-1957","score":12.73347,"text":"\nLearning Center \n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Learning Center offers a video series to help you learn to use IBM Cloudant. The videos start with the basics of using IBM Cloudant. Then the videos walk you through document structure, the API, indexing and querying, and include an Under the Hood topic that highlights the architecture that powers the service.\n\nYou can use the [playlist](https:\/\/www.youtube.com\/embed\/playlist?list=PLzpeuWUENMK3F93hGaS4ezGmlX4Bipt4S) to go through the courses, or navigate directly to the topic of your choosing.\n\n\n\n Introduction to IBM Cloudant video \n\nLearn about the IBM Cloudant 17-part video series that provides an overview of the IBM Cloudant database-as-a-service.\n\n\n\n* Introduction to IBM Cloudant video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 1 - What is IBM Cloudant?\n\nIBM Cloudant is a database, run as a service in the IBM Cloud\u00ae. Its job is to store your application's data securely and make it possible for you to retrieve it quickly and efficiently. IBM Cloudant's key features are shown in the following list:\n\nDatabase\n: Stores and retrieves data. More specifically, it is a JSON document store. JSON comes from JavaScript and represents simple objects in a universal file format.\n\nDocument\n: The unit of storage in IBM Cloudant. Documents are added, updated, and deleted in their entirety.\n\nHTTP API\n: Any IBM Cloudant operation can be achieved by using HTTPS. HTTP is the protocol that powers the World Wide Web and IBM Cloudant is a database that is built for the web. Most databases are hidden in a private network, inaccessible but to a handful of machines. The IBM Cloudant service sits (mainly) on the public internet where it can be accessed by anyone with an internet connection (and permission to do so).\n\nIBM Cloudant wasn't written entirely by IBM.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00612-7-2163","score":12.701883,"text":"\nMigration overview \n\nThe [IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae](https:\/\/www.ibm.com\/cloud\/cloudant) database-as-a-service offering is a JSON document store that runs on multi-tenant clusters. The service is available with a choice of geographical locations with predictable costs, scalability, and a service-level agreement (SLA).\n\nYou can migrate to an IBM Cloudant Lite or Standard plan instance on IBM Cloud from one of the following plans:\n\n\n\nTable 1. IBM Cloudant migration paths\n\n Plan Description \n\n IBM Cloudant Enterprise Dedicated, single-tenant clusters \n Apache CouchDB The self-hosted, open source database on which IBM Cloudant is based. \n\n\n\n\n\n Benefits of the IBM Cloudant Lite and Standard plans \n\nWith the Standard plan, you can reserve throughput capacity for your database service, that is, to specify how much throughput your application's database is going to need to handle demand. The Standard plan also charges for the amount of storage you use. Capacity is measured with the following metrics:\n\n\n\nTable 2. Capacity metrics\n\n Metric Description \n\n Reads per second The rate when simple document fetches are performed, for example, retrieving a document by its _id, or querying against a partitioned database that uses a partition key. \n Writes per second The rate when data is written to the database. API calls dealing with document creation, update, or deletion count as \"writes\". \n Global Queries per second The rate when the database is queried by global indices, typically by accessing the _find endpoint, secondary MapReduce, or search indices. \n Storage The amount of disk space occupied by your JSON data, attachments, and secondary indices. \n\n\n\nAs an example, the Lite plan offers 20 reads per second, 10 writes per second, 5 global queries per second, and 1 GB of storage for free. This plan is ideal when you're evaluating the product and during product development. When your application goes into QA or production, switch to the Standard plan to scale the instance. The Standard plan's smallest capacity has 100 reads per second, 50 writes per second, 5 global queries per second, and 20 GB of storage for USD$76.65 per month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-migrating-to-ibm-cloudant-on-ibm-cloud"},{"document_id":"ibmcld_10165-5520-7943","score":12.620328,"text":"\nIBM Cloudant is a modern NoSQL database that is useful for many data-driven use cases: from key-value to complex document-oriented data storage and query. To manage the growing set of regulatory and management report rules, the mortgage company uses IBM Cloudant to store documents that are associated with raw regulatory data the come into the firm. Compute processes on Red Hat OpenShift on IBM Cloud are triggered to compile, process, and publish the data in various reporting formats. Intermediate results common across reports are stored as IBM Cloudant documents so template-driven processes can be used to produce the necessary reports.\n\n\n\n\n\n Results \n\n\n\n* Complex financial simulations are completed in 25% of the time than was previously possible with the existing on-premises systems.\n* Time to deployment improved from the previous 6 - 9 months to 1 - 3 weeks on average. This improvement occurs because Red Hat OpenShift on IBM Cloud allows for a disciplined, controlled process for ramping up app containers and replacing them with newer versions. Reporting bugs can be fixed quickly, addressing issues, such as accuracy.\n* Regulatory reporting costs were reduced with a consistent, scalable set of storage and compute services that Red Hat OpenShift on IBM Cloud and IBM Cloudant bring.\n* Over time, the original apps that were initially moved to the cloud were restructured into cooperative microservices that run on Red Hat OpenShift on IBM Cloud. This action further sped up development and time to deploy and allowed more innovation due to the relative ease of experimentation. They also released innovative apps with newer versions of microservices to take advantage of market and business conditions (that is, so called situational apps and microservices).\n\n\n\n\n\n\n\n\n\n Payment tech company streamlines developer productivity, deploying AI-enabled tools to their partners 4 times faster \n\nA Development Exec has Developers that use on-premises application tools that slow down prototyping while they wait for hardware procurement.\n\nRed Hat OpenShift on IBM Cloud provides spin-up of compute by using open-source standard technology. After the company moved to Red Hat OpenShift on IBM Cloud, Developers have access to DevOps friendly tools, such as portable and easily shared containers.\n\nThen, Developers can experiment easily, pushing changes to Development and Test systems quickly with open toolchains.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_finance"},{"document_id":"ibmcld_00646-7-1813","score":12.618365,"text":"\nCreating a web-based To-Do list \n\nCreate a simple web-based to-do list to get familiar with the basic IBM Cloud features.\n\n\n\n Objectives \n\n\n\n1. From this tutorial, you learn how to create a basic website that interfaces with your IBM Cloud database to read and write data.\n\nThe project is a simple to-do list, where you can see a list of notes. You can add and delete notes. Each of your notes has a tag, and you can filter your notes by tag.\n2. To create this to-do list, your application needs to be able to read and write to the database. To read to-dos in \"newest first\" order and to filter by tag, your database needs to have some secondary indexes. Now, we can create all of that.\n\n\n\nYou can complete the tutorial in less than an hour. It doesn't cost you anything over your current IBM Cloudant bill (so it's free if you are on the IBM Cloudant Lite plan).\n\nThe website that you create is served from your local machine, so no other services are required apart from IBM Cloud.\n\nAfter you complete it, you have a basic understanding of how applications can interface with IBM Cloudant through an IBM Cloudant SDK (in this case, NodeJS).\n\n\n\n\n\n Before you begin \n\nYou need the following implements to complete this tutorial:\n\n\n\n1. An IBM Cloudant service instance and some service credentials. You can create the instance and credentials in the IBM Cloudant Dashboard by following the [Getting started with IBM Cloudant](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) tutorial. Be sure to make a note of the APIKey and URL when you create your service credentials.\n2. Ensure you have access to a Mac or Linux\u2122 terminal.\n3. Download [Git](https:\/\/git-scm.com\/downloads).\n4. Download [Node.js and npm](https:\/\/docs.npmjs.com\/downloading-and-installing-node-js-and-npm).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-web-based-todo-list"},{"document_id":"ibmcld_12904-7-1919","score":12.55109,"text":"\nPlans and provisioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Standard is IBM Cloudant's most feature-rich offering, receiving updates and new features first. Pricing is based on provisioned throughput capacity that is allocated and data storage that is used, making it suitable for any required load.\n\nThe free [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) includes a fixed amount of throughput capacity and data for development and evaluation purposes. The paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan) offers configurable provisioned throughput capacity and data storage pricing that scales as your application requirements change. An optional [Dedicated Hardware plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicdedicated-hardware-plan) is also available for an extra monthly fee to run one or more of your Standard plan instances on a dedicated hardware environment. The dedicated hardware environment is for your sole use. If a Dedicated Hardware plan instance is provisioned within a US location, you can optionally select a [HIPAA](https:\/\/en.wikipedia.org\/wiki\/Health_Insurance_Portability_and_Accountability_Act) -compliant configuration.\n\n\n\n Plans \n\nYou can select which plan to use when you [provision your IBM Cloudant service instance](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioning-a-cloudant-nosql-db-instance-on-ibm-cloud). The available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00522-7-1725","score":12.531082,"text":"\nDigging deeper into IBM Cloudant Dashboard \n\nThe IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Dashboard gives new and experienced IBM Cloudant users the opportunity to add, edit, and delete documents. The IBM Cloudant users can refine the indexing and querying options that best suit their application's use-cases.\n\n\n\n Objectives \n\nSet up some basic indexes using the Dashboard to see how each of IBM Cloudant's querying mechanisms works.\n\n\n\n\n\n Before you begin \n\nYou need to create a service instance in IBM Cloudant before you start this tutorial. You can follow the instructions in the [Getting started](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-getting-started-with-cloudant) tutorial to create one.\n\n\n\n\n\n Step 1. The data set \n\n\n\n1. Create a database called books.\n2. Create some sample data that represents a book in a library as shown in the following example:\n\n{\n\"_id\": \"BXP9G5ZQY9Q4EA13\",\n\"author\": \"Dickens\",\n\"title\": \"David Copperfield\",\n\"year\": 1840,\n\"pages\": 723,\n\"publisher\": \"Penguin\",\n\"url\": \"https:\/\/www.somurl.com\/dc\"\n}\n3. Continue to add some documents that match the pattern in the previous step by using the IBM Cloudant Dashboard.\n\nThe documents store simple key\/value pairs that hold metadata about each book: its author and its publisher. In this example, we address the following three use-cases:\n\n\n\n1. A query facility that allows a user to find a book by a known publisher and year.\n2. A general-purpose search engine that allows a user to find books by a combination of one or more of the following descriptors: author, title, year, and publisher.\n3. A report that details the number of books that are published by year.\n\n\n\n\n\n\n\n\n\n Step 2. Querying books by publisher and year - IBM Cloudant Query","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-dig-deeper-dashboard"},{"document_id":"ibmcld_10853-2344-4364","score":12.491083,"text":"\n<br><br> * Node.js 10<br> * Node.js 12<br> * Python 3<br> * PHP 7<br><br><br> [Code](https:\/\/github.com\/ibm-functions\/template-reminder-slack) \n\n\n\n\n\n\n\n Deploying the IBM Cloudant Events template \n\nThe IBM Cloudant template creates a sequence of actions and a trigger that invokes that sequence. The trigger is fired when a change is made in the connected IBM Cloudant example database.\n\nWhen you deploy this template, you create the following entities:\n\n\n\n* An action called process-change.\n* A sequence that uses the process change action as well as a preinstalled action for IBM Cloudant called read that reads entries from the IBM Cloudant database.\n* A user-named trigger that is fired whenever an entry is added to the connected database. This trigger calls the sequence.\n\n\n\nBefore you begin\n\nYou must have an instance of [IBM Cloudant](https:\/\/cloud.ibm.com\/catalog\/services\/cloudant) set up before you deploy this quick start template. When you create your IBM Cloudant instance, you must select Use both legacy credentials and IAM as your available authentication methods. This template does not work with an IBM Cloudant instance that uses IAM only.\n\n\n\n1. After your IBM Cloudant instance is provisioned, select the instance from the Resource list and then select Launch Cloudant Dashboard.\n2. From the IBM Cloudant Dashboard, click Create Database.\n3. Create a non-partitioned database called cats.\n4. From the IBM Cloudant instance, select Service credentials. If you do not have service credentials set up, click New Credentials to create them. These values are required for deploying this template.\n\n\n\nNow that your instance of IBM Cloudant is provisioned and a sample database of cats set up, you are ready to deploy the IBM Cloudant Events template.\n\n\n\n Deploying the IBM Cloudant Events template from the console \n\nDeploy the IBM Cloudant Events template from the console.\n\nBefore you begin\n\nSelect a namespace to contain your Cloud Functions entities from the [console](https:\/\/cloud.ibm.com\/functions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-templates"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.5,"ndcg_cut_5":0.5,"ndcg_cut_10":0.5}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00558-1499-3456","score":14.172555,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_01150-5900-8142","score":13.945309,"text":"\nAllow a few minutes for the cached limit of 1 partition for the Lite plan to clear so that you can take advantage of the 100 partition limit for the Standard plan.\n\nHowever, this option does not currently work in the IBM Cloud console for any other combination of plans. For example, if you try a different plan combination, you'll see an error message like the the following:\n\nCould not find VCAP::CloudController::ServicePlan with guid: ibm.eventstreams.standard\n\n\n\n\n\n\n\n What are the differences between the Event Streams Standard and Event Streams Enterprise plans? \n\nTo find out more information about the different Event Streams plans, see [Choosing your plan](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose).\n\n\n\n\n\n How do I handle disaster recovery? \n\nCurrently, it is the responsibility of the user to manage their own Event Streams disaster recovery. Event Streams data can be replicated between an Event Streams instance in one location (region) and another instance in a different location. However, the user is responsible for provisioning a remote Event Streams instance and managing the replication.\n\nWe suggest a tool like Kafka MirrorMaker to replicate data between clusters. For information about how to run MirrorMaker, see [Event Streams kafka-mirrormaker repository](https:\/\/github.com\/ibm-messaging\/event-streams-samples\/tree\/master\/kafka-mirrormaker).\n\nThe user is also responsible for the backup of message payload data. Although this data is replicated across multiple Kafka brokers within a cluster, which protects against the majority of failures, this replication does not cover a location-wide failure.\n\nTopic names are backed up by Event Streams, although it is recommended good practice for users to back up topic names and the configuration data for those topics.\n\nIf you have configured your Event Streams instance in a Multi-Zone Region, a regional disaster is very unlikely. However, we recommend that users do plan for such circumstances. If a user's instance is no longer available because of a disaster (and a remote DR instance is not already set up), the user should consider configuring a new instance in a new region and restoring their topics and data from backup if available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-faqs"},{"document_id":"ibmcld_12904-1535-3460","score":13.926782,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_13336-1484-3613","score":13.84467,"text":"\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:\n\n\n\n* Users who recognize 1 to 999,999 minutes of audio in a given month pay $0.02 (USD) per minute of audio for that month.\n* Users who recognize at least 1,000,000 minutes of audio in a given month pay $0.01 (USD) per minute of audio for that month.\n\n\n\nThe Plus plan is intended for small businesses. It is also a good choice for large enterprises that want to develop and test larger applications before considering moving to a Premium plan. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text).\n\n\n\n\n\n Can I continue to use the Speech to Text Standard plan? \n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https:\/\/cloud.ibm.com\/catalog\/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n\n\n\n\n\n What pricing plan do I need to use the service's customization interface? \n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n\n\n\n\n\n How do I upgrade from the Lite plan to the Plus plan?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-faq-pricing"},{"document_id":"ibmcld_12904-7-1919","score":13.77038,"text":"\nPlans and provisioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Standard is IBM Cloudant's most feature-rich offering, receiving updates and new features first. Pricing is based on provisioned throughput capacity that is allocated and data storage that is used, making it suitable for any required load.\n\nThe free [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) includes a fixed amount of throughput capacity and data for development and evaluation purposes. The paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan) offers configurable provisioned throughput capacity and data storage pricing that scales as your application requirements change. An optional [Dedicated Hardware plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicdedicated-hardware-plan) is also available for an extra monthly fee to run one or more of your Standard plan instances on a dedicated hardware environment. The dedicated hardware environment is for your sole use. If a Dedicated Hardware plan instance is provisioned within a US location, you can optionally select a [HIPAA](https:\/\/en.wikipedia.org\/wiki\/Health_Insurance_Portability_and_Accountability_Act) -compliant configuration.\n\n\n\n Plans \n\nYou can select which plan to use when you [provision your IBM Cloudant service instance](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioning-a-cloudant-nosql-db-instance-on-ibm-cloud). The available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_02660-1509-3609","score":13.764671,"text":"\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-create-an-instance"},{"document_id":"ibmcld_00558-20425-22479","score":13.7136965,"text":"\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-20515-22569","score":13.7136965,"text":"\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_00558-7-1874","score":13.443055,"text":"\nPlans and provisioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Standard is IBM Cloudant's most feature-rich offering, receiving updates and new features first. Pricing is based on provisioned throughput capacity that is allocated and data storage that is used, making it suitable for any required load.\n\nThe free [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) includes a fixed amount of throughput capacity and data for development and evaluation purposes. The paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan) offers configurable provisioned throughput capacity and data storage pricing that scales as your application requirements change. An optional [Dedicated Hardware plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicdedicated-hardware-plan) is also available for an extra monthly fee to run one or more of your Standard plan instances on a dedicated hardware environment. The dedicated hardware environment is for your sole use. If a Dedicated Hardware plan instance is provisioned within a US location, you can optionally select a [HIPAA](https:\/\/en.wikipedia.org\/wiki\/Health_Insurance_Portability_and_Accountability_Act) -compliant configuration.\n\n\n\n Plans \n\nYou can select which plan to use when you [provision your IBM Cloudant service instance](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicprovisioning-a-cloudant-nosql-db-instance-on-ibm-cloud). The available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_05012-7-2083","score":13.41334,"text":"\nFAQ - One Rate plans \n\nFrequently asked questions can produce helpful answers and insight into best practices for working with IBM Cloud\u00ae Object Storage.\n\n\n\n What is the difference between a Standard and One Rate plan? \n\n\n\n* Standard plan is our most popular public Cloud pricing plan, that meets the requirements of majority of the enterprise workloads. The Standard plan is best suited for workloads that have large amount of storage and relatively small Outbound bandwidth (Outbound bandwidth < 20% of Storage capacity). The plan offers flexible choices for storage class based on data access patterns (lower the cost, the less frequently data is accessed). The Standard plan bills for every stored capacity ($\/GB\/month), Outbound bandwidth ($\/GB), class A ($\/1,000), class B ($\/10,000) and retrieval ($\/GB) metrics, where applicable.\n* One Rate plan is suited for active workloads with large amounts of Outbound bandwidth (or varying Outbound bandwidth) as a percent of their Storage capacity (Outbound bandwidth > 20% of Storage capacity). Typical workloads belong to large enterprises and ISVs which may have sub-accounts with multiple divisions\/departments or end-users. The plan offers a predictable TCO with an all-inclusive flat monthly charge ($\/GB\/month) that includes capacity, and built-in allowances for Outbound bandwidth and Operational requests. The built-in allowances for Outbound bandwidth and Operational requests (Class A, Class B) depend on the monthly stored capacity. There is no data retrieval charge.\n\n\n\n\n\n\n\n How are the allowance thresholds (for Outbound bandwidth, class A and class B) calculated for the One-Rate plan? \n\nFor each of the One-Rate plan pricing regions(North America, Europe, South America,and Asia Pacific), the total aggregated Storage capacity across all instances (within a region) is used to determine the allowance thresholds.\n\n\n\n* Outbound bandwidth: No charge if Outbound bandwidth \u2264 100% of Storage capacity in GB, then list prices apply ($0.05\/GBfor North America and Europe, $0.08\/GB for South America and Asia Pacific).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-faq-onerate"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6508205186,"ndcg_cut_10":0.6508205186}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07103-29564-31587","score":14.5895605,"text":"\nPreviously, the list included fields that were not valid choices.\n\n\n\n\n\n 14 October 2021 \n\nNew Discovery home page\n: A new home page is displayed when you start Discovery and gives you quick access to a product overview video, and tours. You can collapse the home page welcome banner to see more projects.\n\nNew plan usage section\n: Stay informed about plan usage and check your usage against the limits for your plan type from the Plan limits and usage page. From the product page header, click the user icon ![User icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/discovery-data\/images\/user--avatar.svg). The Usage section shows a short summary. Click View all to see usage information for all of the plan limit categories.\n\nChange to spelling settings in Search\n: The spelling correction setting changed from being enabled automatically in new projects to being disabled by default. If you want to alert users when they misspell a term in their query, turn on Spelling suggestions. For more information, see [Customizing the search bar](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-search-bar).\n\nImproved Guided tours availability\n: The Guided tours button is now available from the product page header, which make them accessible from anywhere. Previously, it was available from the My Projects page only.\n\n\n\n\n\n 1 October 2021 \n\nChange to Lite and Advanced plans in all locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_07103-31052-33321","score":14.448836,"text":"\nYou cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, and Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 24 September 2021 \n\nNew scoring for NLU enrichments\n: Relevance and confidence scores are displayed for NLU enrichments that are returned by search. For example, when you open the JSON view of the document preview from a query result, you can see confidence scores for Entities mentions and relevance scores for Keyword mentions.\n\n\n\n\n\n 9 September 2021 \n\nNew location for Plus plan\n: The Plus plan is now available from the Sydney location. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product. For more information, see [Getting the most from Discovery](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-choose).\n\nChange to Lite and Advanced plans in most locations\n: Lite and Advanced plans are discontinued. You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Sydney, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\n\n\n\n\n 26 August 2021 \n\nNew locations for the Plus plan\n: The Plus plan is now available from the London and Washington DC locations, in addition to Dallas, Frankfurt, and Tokyo.\n\nChange to Lite and Advanced plans in some locations\n: You cannot create new service instances that use the Lite or Advanced plan types in the Dallas, Frankfurt, London, Tokyo, or Washington DC locations. Any existing Lite and Advanced plans continue to function properly and continue to be supported. You can upgrade from a Lite plan to an Advanced plan.\n\nNew answer finding feature\n: Answer finding is now generally available for managed deployments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"},{"document_id":"ibmcld_16727-1079289-1081125","score":14.100531,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":14.100531,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01316-2609-4002","score":13.587571,"text":"\nWatson IoT Platform Standard The Standard service plan includes the free data-transfer limit that is offered in the Lite plan and then usage-based billing beyond the free quote for data exchanged, data analyzed, and edge data analyzed. \n Watson IoT Platform Advanced Security The Advanced Security service plan includes the free data-transfer limit that is offered in the Lite plan and then usage-based billing beyond the free quote for data exchanged, data analyzed, and edge data analyzed. This plan also provides advanced Risk and Security Management features. \n\n\n\n\n\n\n\n\n\n Upgrading service plans \n\nIf you are an existing customer and want to take advantage of the full [Watson IoT Platform feature set ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.ibm.com\/support\/knowledgecenter\/SSQP8H\/iot\/overview\/overview.html), you can purchase one of the Connection and Analytics Service plans and then migrate your existing environment.\n\nTo migrate plans, contact your IBM\u00ae representative or raise a support ticket.\n\nTo migrate from Watson IoT Platform Lite plan, or to migrate to other plans with only the essential configuration settings included, see the instructions in [Migrating Watson IoT Platform Lite to Watson IoT Platform Non-production or Production](https:\/\/cloud.ibm.com\/docs\/services\/IoT?topic=IoT-org_migrationorg_migration).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/IoT?topic=IoT-plans_overview"},{"document_id":"ibmcld_07128-7-1957","score":13.390604,"text":"\nAbout Discovery v1 \n\nIBM Watson\u2122 Discovery v1 is deprecated. As of 1 October 2021, you cannot create new v1 instances. Lite or Advanced plan service instances are Discovery v1 instances, as are service instances that you created with a Premium plan before 16 July 2020. Existing v1 service instances are supported until 11 July 2023. Any v1 instances that still exist on that date will be deleted. Migrate your solutions to use Discovery v2 before 11 July 2023. For more information, see the [Discovery v2 documentation](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-choose).\n\nDiscovery makes it possible to rapidly build cognitive, cloud-based exploration applications that unlock actionable insights hidden in unstructured data \u2014 including your own proprietary data, as well as public and third-party data.\n\n![Discovery architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ded4adc3ea0bd2a81b113c579f2b1183926da211\/discovery\/images\/about-discovery1.png)\n\nWith Discovery, it only takes a few steps to prepare your unstructured data, create a query that pinpoints the information you need, and then integrate those insights into your new application or existing solution.\n\nHow does Discovery do it? By using data analysis combined with cognitive intuition to take your unstructured data and enrich it so you can discover the information you need.\n\nIBM Watson\u2122 Discovery brings together a functionally rich set of integrated, automated Watson APIs to:\n\n\n\n* Crawl, convert, enrich and normalize data.\n* Securely explore your proprietary content as well as free and licensed public content.\n* Apply additional enrichments such as concepts, relations, and sentiment through Natural Language Understanding (NLU).\n* Simplify development while still providing direct access to APIs.\n\n\n\nTo try out Discovery, see the [IBM Watson\u2122 Discovery Query Demo](https:\/\/www.ibm.com\/demos\/live\/watson-discovery\/self-service\/home).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-about"},{"document_id":"ibmcld_02775-7-2245","score":13.292493,"text":"\nHow does App ID calculate pricing? \n\nWhen you work with App ID, you are charged based on the number of authentication events, the number of authorized users, and the number of advanced security events.\n\nFor the most up-to-date pricing information, you can create a cost estimate by clicking Add to estimate in the App ID section of the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/services\/app-id).\n\n\n\n Pricing plans \n\nThe service offers two pricing plans.\n\nLite\n: Each month, your first 1000 authentication events and 1000 authorized users per service instance are free, except for any advanced security events. You incur an extra charge for any advanced security events. In this plan, you can issue access and anonymous tokens when a user or an app initiates a sign-in request.\n\nGraduated tier\n: In the graduated tier plan, you are charged each month after you reach the limits of the lite plan. The cost is based on the summary of three parts: the number of authentication events, the number of authorized users, and the number of advanced security events.\n\nFor example, if these quantities are in the 1 - 10,000 tier, the charge for each authentication event, authorized user, and advanced security event is assessed by multiplying each quantity by the unit price that is set for that tier. Then, the total price is calculated by combining the charges for authentication events, authorized users, and advanced security events.\n\n\n\n\n\n What are authorized users? \n\nAn authorized user is a unique user that signs in with your service whether directly or indirectly, including anonymous users. You are charged for one authorized user each time a new user signs in to your application, including anonymous users. For example, if a user signs in with Facebook and later signs in by using Google, they are considered two separate authorized users. The total number of your authorized users includes future users that you preregistered to your app because you already know who they are going to be. You are charged for each future user at the time of registration. For example, you work at a company and recently hired a team lead. When you preregister them to your application, they become an authorized user and count toward your total.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-pricing"},{"document_id":"ibmcld_00558-20425-22479","score":13.277834,"text":"\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_12904-20515-22569","score":13.277834,"text":"\nThe data storage that is measured for billable purposes for an IBM Cloudant instance is inclusive of both JSON data, indexes, and attachments.\n\n\n\n Data storage included \n\nThis value is the storage capacity that is included in the plan. The Lite plan has a hard limit of 1 GB allowed. The paid Standard plan includes 20 GB for free and any additional data that is stored is metered for billing.\n\n\n\n\n\n Data overage \n\nAll Lite and Standard plans are monitored for disk space used. When you use more data than the plan allocates, you can expect the conditions that are described in the following sections to apply:\n\n\n\n Lite plan \n\n\n\n* Disk usage is capped on the Lite plan at 1 GB.\n* After you reach the cap, you receive a warning on the IBM Cloudant Dashboard and can't write new data. If you try to write new data, a 402: payment required response occurs.\n* To write new data, you must either upgrade to the Standard plan or delete data, and wait until the next check runs for your account to be reactivated.\n\n\n\n\n\n\n\n Standard plan \n\n\n\n* If the account uses more than the 20 GB of storage that is included in the Standard plan, the excess is considered \"disk overage\". Overage causes the account to be billed at the indicated price for each extra GB used beyond the plan allocation.\n* The cost for the amount of disk overage is calculated on an hourly basis.\n\n\n\nFor example, assume your Standard plan increases disk usage to 107 GB for half a day (12 hours). This change means that your instance caused overflow of 87 GB more than the 20 GB plan allocation, for 12 hours. As the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_07103-13283-15511","score":13.184898,"text":"\nYou cannot create new service instances that use the Lite plan type in any location, including London. Use the new Plus plan and its associated 30-day free trial to explore new features and a simpler way to build that is available with the latest version of the product.\n\n\n\n\n\n 22 September 2022 \n\nPlus plan supports more entity extractors\n: The maximum number of entity extractors that you can create with a Plus plan increased from 3 to 6.\n\nYou cannot apply a Smart Document Understanding model to Microsoft Excel files\n: The quality of structural analysis that can be produced for Excel files is not sufficient. Starting on 22 September 2022, you cannot apply an SDU model to Excel files. This change does not impact Excel files in collections where an SDU model was applied before 22 September 2022.\n\n\n\n\n\n 16 September 2022 \n\nIn-context document preview is now available for PDF files that are crawled\n: When you click to view a passage from a search result that is extracted from a PDF document, a document preview page is displayed that shows the returned passage in the context of the original PDF page. The in-context view is available for PDF files to which a Smart Document Understanding model is applied.\n\n\n\n\n\n 15 August 2022 \n\nSDKs were updated to reflect the latest API changes.\n: The following [Discovery v2 API](https:\/\/cloud.ibm.com\/apidocs\/discovery-data) changes are now reflected in the SDKs:\n\n\n\n* Use the new document classifier API to get, add, update, or delete a document classifier.\n* A new document status API is available. You can use it to get a list of the documents in a collection and to get details about a single document.\n* You can now get, add, and remove a stop words or expansion list for a collection.\n* A smart_document_understanding field is returned with the Get collection method. This new field specifies whether an SDU model is enabled for the collection and indicates the model type.\n* A similar parameter is available from the Query method. Use it to find documents that are similar to documents of interest to you.\n* The suggested_refinements parameter of the Query method is deprecated. The suggested_refinements parameter was used to identify dynamic facets from Premium plan data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"d5b1e735a040853ed361a3dfde1b8ef0<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00644-29795-31578","score":16.525612,"text":"\nMulti-document fetching \n\nThe following section covers a POST request to many documents from a database.\n\nFor a client application, this technique is more efficient than using multiple [GET](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsquerying-a-view) API requests.\n\nHowever, include_docs=true might require extra processing time when compared to accessing the view on its own.\n\nThe reason is that by using include_docs=true in a view query, all of the result documents must be retrieved to construct the response for the client application. In effect, a whole series of document GET requests are run, each of which competes for resources with other application requests.\n\nOne way to mitigate this effect is by retrieving results directly from the view index file. Omit include_docs=true to retrieve results directly from the view index file. Instead, in the map function in a design document, emit the fields that are required as the value for the view index.\n\nFor example, in your map function, you might use the following design specification:\n\nfunction(user) {\nif(user.email_verified === true) {\nemit(user.email, {name: user.name, email_verified: user.email_verified, joined: user.joined});\n}\n}\n\nSee the example request that uses HTTP to obtain the full content of documents that match the listed keys within a partition:\n\nPOST $SERVICE_URL\/$DATABASE\/_partition\/$PARTITION_KEY\/_design\/$DDOC\/_view\/$VIEW_NAME HTTP\/1.1\nContent-Type: application\/json\n\n{\n\"include_docs\": true,\n\"keys\" : [\n\"1000043\",\n\"1000044\"\n]\n}\n\nSee the example request to obtain the full content of documents that match the listed keys within the products partition:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X POST \"$SERVICE_URL\/products\/_partition\/small-appliances\/_design\/appliances\/_view","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_00620-14227-15704","score":16.332138,"text":"\nThe previous Go example requires the following import block: import (\n\"encoding\/json\"\n\"fmt\"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n\"github.com\/IBM\/go-sdk-core\/core\"\nAll Go examples require the service object to be initialized. For more information, see the API documentation's Authentication section]] ! ! ! ! for examples.This option works, but you end up fetching n+1 documents when only n are required.<-- <\/section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --><-- <section \"id=\"section-option-2-the-u0000-trick\" \"> --> Option 2 - The \\u0000 trick If you're determined to fetch only n documents each time, then you need to calculate a value of startkey, which means the next ID after the last _id in the result set. For example, if the last document in the first page of results is \"example\", what must the startkey of the next call to _all_docs be? It can't be \"example\", otherwise you get the same document ID again. It turns out that you can append u0000 to the end of a key string to indicate the \"next key\" (u0000 is a Unicode null character, which can be placed in a URL as-is or with the percent code %00). ).See the following example of a first request:<-- <ul> --> * Curl * Java * Node * Python * Go<-- <\/ul> --> curl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL\/orders\/_all_docs?limit=5\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.DocsResultRow;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks"},{"document_id":"ibmcld_13481-7434-8879","score":15.653404,"text":"\nThe SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine-spark-integration-1.4.51.jar)\n* [spark-dataengine-python](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine_spark-1.4.51-py3-none-any.whl)\n\n\n\nAn example of how to use the Python helper can be found in the [Watson Studio Notebooks section](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastoreusage_watson_notebooks).\n\nUse the following example to get started with IBM\u00ae Analytics Engine (IAE) or Spark runtimes in Watson Studio when using Scala. Submit the following application using a notebook or the spark-submit command:\n\npackage com.ibm.cloud.dataengine\nimport org.apache.spark.sql.SparkSession\nimport org.apache.spark.sql.SparkSession.{Builder => SessionBuilder}\nimport SparkSessionBuilderAddOn._\nobject SparkSessionBuilderHMSConfigTest {\ndef main(args: Array[String]) = {\nval spark = SparkSession\n.builder()\n.appName(\"Spark DataEngine integration\")\n.enableDataengine(args(0), args(1), \"public\")\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\")\n.config(\"fs.stocator.scheme.list\", \"cos\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_12341-1239-2954","score":15.538467,"text":"\nThe releases of these SDKs should be published on [NPM](https:\/\/www.npmjs.com\/). Your NPM package should be [scoped](https:\/\/docs.npmjs.com\/creating-and-publishing-scoped-public-packagescreating-a-scoped-public-package) with [@ibm-cloud](https:\/\/www.npmjs.com\/search?q=%40ibm-cloud), so that NPM users can find similar packages across NPM.\n\nYour SDK should follow the [semantic versioning best practices](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributiondistribution-semver).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [Airbnb conventions](https:\/\/github.com\/airbnb\/javascript), with two spaces for indentation.\n\nYou should use the standard [development tools](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools) for JavaScript to check style and code coverage.\n\n\n\n\n\n Streaming support \n\nIf your API takes fileType parameters, you should accept Node.js streams as an input type.\n\n\n\n\n\n Dependencies \n\nUse a well-defined, well-documented request library that includes browser support, like [axios](https:\/\/github.com\/axios\/axios), [superagent](https:\/\/github.com\/visionmedia\/superagent), or [node-fetch](https:\/\/github.com\/node-fetch\/node-fetch).\n\n\n\n\n\n Objects for arguments \n\nThe methods in your SDK should take a JSON object as an argument. This object will contain the options for the requests, instead of using positional parameters in the function definition.\n\n\n\n\n\n Async architecture","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-node"},{"document_id":"ibmcld_12343-7-1769","score":15.127755,"text":"\nPython \n\nGiven its ease of use and adoption for data science applications, [Python](https:\/\/www.python.org\/) support is imperative to increase adoption of your IBM Cloud service. Supporting Python applications using [Flask](https:\/\/github.com\/pallets\/flask), [Django](https:\/\/www.djangoproject.com\/), [Jupyter](https:\/\/jupyter.org\/), and functional programming paradigms introduces special considerations that need to be observed by your SDK.\n\n\n\n Environment support \n\n\n\n* Your Python SDK should be written to support all [Python >=3.5](https:\/\/www.python.org\/downloads\/) releases.\n* Ensure your SDK is compatible with data science usecases, such as [Jupyter Notebooks](https:\/\/jupyter.org\/).\n\n\n\n\n\n\n\n Publishing \n\nAll Python SDKs should be publicly available on an [IBM GitHub organization](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributionopen-source). The releases of these SDKs should be published on [PyPI](https:\/\/pypi.org\/).\n\nYour SDK should follow the [semantic versioning best practices](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distributionsemantic-versioning).\n\n\n\n\n\n Community support \n\nAllow your users to find answers to their questions. Users should be able to report problems on GitHub by raising issues on your SDK repository. Having a public Slack channel is a great way to engage with users who have questions specific to their use cases.\n\n\n\n\n\n Style guidelines \n\nYou should follow the [PEP8 style guide for Python](https:\/\/www.python.org\/dev\/peps\/pep-0008\/), with a few modifications, like four spaces instead of tabs for indentation.\n\nYou should use the standard [development tools](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-developer-tools) for Python to check style and code coverage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-python"},{"document_id":"ibmcld_12341-2467-4426","score":15.022989,"text":"\nUse a well-defined, well-documented request library that includes browser support, like [axios](https:\/\/github.com\/axios\/axios), [superagent](https:\/\/github.com\/visionmedia\/superagent), or [node-fetch](https:\/\/github.com\/node-fetch\/node-fetch).\n\n\n\n\n\n Objects for arguments \n\nThe methods in your SDK should take a JSON object as an argument. This object will contain the options for the requests, instead of using positional parameters in the function definition.\n\n\n\n\n\n Async architecture \n\nAll network calls from your SDK should be asynchronous. All asynchronous calls should be handled using Promises, not callbacks.\n\n\n\n\n\n Standard features \n\n\n\n\n\n Authentication \n\nYou are not required to use a particular library to provide the authentication for your service.\n\nYour SDK must support all of the authentication methods for your service.\n\n\n\n\n\n Configuration \n\nIn the interests of making your SDK easy to consume and cloud native, you should provide the ability to read in environment variables. Abstracting the application logic from the environment logic allows your users to focus on using your service capabilities their applications.\n\nIf you build this capability into your SDK, you must document this mechanism clearly with examples.\n\n\n\n\n\n Using node-sdk-core \n\n[IBM node-sdk-core](https:\/\/github.com\/IBM\/node-sdk-core) provides configuration and authentication support. You can use the existing functionality provided by this dependency in your SDK.\n\n\n\n\n\n Documentation \n\nYour SDK is not useful if your audience cannot understand how to consume it in order to do the basic operations for your service. Your SDK needs to contain the following resources to help your users:\n\n\n\n* README.md\n* NPM metadata\n* [Contributor guidelines](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentationsdk-contributor-docs)\n* Code Samples\n* [Service documentation](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentation)\n\n\n\n\n\n\n\n Samples","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-node"},{"document_id":"ibmcld_05137-892-2529","score":14.9545965,"text":"\nSpecific instructions for downloading and installing the SDK is available in [Using Python](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-python)[Using Node.js](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-node)[Using Java](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-java)[Using Go](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-using-go).\n\n\n\n\n\n Code Example \n\nThe code examples below provide introductory examples of running the basic operations with Object Storage. For simplicity, the code example can be run multiple times as it uses Universally Unique Identifiers (UUIDs) for bucket\/item names to prevent potential conflicts.\n\nIn your code, you must remove the angled brackets or any other excess characters that are provided here as illustration.\n\nTo complete the code example, you need to replace the following values:\n\n\n\n Value Description Example \n\n <endpoint> Regional endpoint for your COS instance s3.us-south.cloud-object-storage.appdomain.cloud \n <api-key> IAM API Key with at least Writer permissions xxxd12V2QHXbjaM99G9tWyYDgF_0gYdlQ8aWALIQxXx4 \n <resource-instance-id> Unique ID for the Service Instance crn:v1:bluemix:public:cloud-object-storage:global:a\/xx999cd94a0dda86fd8eff3191349999:9999b05b-x999-4917-xxxx-9d5b326a1111:: \n <storage-class> Storage class for a new bucket us-south-standard \n\n\n\nFor more information about endpoints, see [Endpoints and storage locations](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-endpointsendpoints).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-sdk-gs"},{"document_id":"ibmcld_00099-7-1786","score":14.920586,"text":"\nUsing the Python SDK \n\nThe IBM Analytics Engine SDK can be installed by installing the library iaesdk from the Python Package Index.\n\nType the following command into a command line:\n\npip install --upgrade \"iaesdk>=1.1.1\"\n\nSource code can be found at [GitHub](https:\/\/github.com\/IBM\/ibm-iae-python-sdk). The iaesdk library provides complete access to the IBM Analytics Engine API.\n\nYou need to provide the service endpoints and the API key when you create a IBM Analytics Engine service resource or a low-level client.\n\nThe service instance ID is also referred to as a instance GUID. You can retrieve the service instance ID when you create service credentials or through the CLI. See [Retrieving service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverless).\n\nTo use the iaesdk library, you need the following values:\n\n\n\n* IAM_API_KEY: The API key generated when creating the service credentials. You can retrieve by viewing the service credentials on the [IBM Cloud dashboard](https:\/\/cloud.ibm.com\/resources).\n* instance_guid: The value in resource_instance_id generated when the service credentials are created. You can retrieve by viewing the service credentials on the [IBM Cloud dashboard](https:\/\/cloud.ibm.com\/resources).\n* IAE_ENDPOINT_URL: The service endpoint URL including the https:\/\/ protocol. See [Service endpoints](https:\/\/cloud.ibm.com\/apidocs\/ibm-analytics-engineservice-endpoints).\n\n\n\n\n\n Code samples using iaesdk \n\nGetting started with the Python SDK after you have installed it, involves sourcing credentials to the IBM Analytics Engine service, invoking the service and then issuing different cluster commands as shown in the following sample code snippets. The code examples are written for Python 3.7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-using-python-sdk-serverless"},{"document_id":"ibmcld_12343-2679-4417","score":14.858478,"text":"\nIn the interests of making your SDK easy to consume and cloud native, you should provide the ability to read in environment variables. Abstracting the application logic from the environment logic allows your users to focus on using your service capabilities their applications.\n\nIf you build this capability into your SDK, you must document this mechanism clearly with examples.\n\n\n\n\n\n Using python-sdk-core \n\n[IBM python-sdk-core](https:\/\/github.com\/IBM\/python-sdk-core) provides configuration and authentication support. You can use the existing functionality provided by this dependency in your SDK.\n\n\n\n\n\n Documentation \n\nYour SDK is not useful if your audience cannot understand how to consume it in order to do the basic operations for your service. Your SDK needs to contain the following resources to help your users:\n\n\n\n* README.md\n* [Contributor guidelines](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentationsdk-contributor-docs)\n* Code Samples\n* [Service documentation](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentation)\n\n\n\n\n\n\n\n Samples \n\nFor your Python SDK, you will want some simple code samples and explanations of what each does. Linking out to the API reference documentation for more advanced use is strongly encouraged.\n\nAt minimum, the samples should be included in the README.md file. They should communicate how to install the library, and complete the basic operations provided by your API.\n\nThe samples should include simple installation and initialization instructions for the popular frameworks and data science tools. Additional examples should be available in an \/examples directory for more advanced operations which can be copied and pasted in to user applications.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-python"},{"document_id":"ibmcld_00580-25421-27357","score":14.850592,"text":"\nType acurl $URL\/_all_dbs to see an array of databases.\n\n\n\nA quick note here on formatting JSON on the command line. We can send the output of our acurl command to another tool, which formats the data nicely on the terminal. The following tools are available for your use:\n\n\n\n* Jq available from the URL on the page, which is more than just a JSON formatter - it allows JSON to be parsed, queried, and manipulated too.\n* python -m json.tool is a simple JSON formatter, if Python is installed on your computer.\n\n\n\nSo acurl $URL\/_all_dbs | jq means pipe the output of acurl into jq and what you see is a nicely formatted, colored output.\n\nThe IBM Cloudant API paths are hierarchical with the first level that gives you information about the service, and then each database sits at a level beneath it.\n\nSo acurl $URL\/books gives us information about the books database that we created earlier.\n\nYou see information about how many documents it has, how many deleted documents, and how much disk space it's occupying.\n\nDon't forget to pipe the output to jq or Python to get a prettier output.\n\nIf we want to see the documents contained in the database, we can use the _all_docs endpoint.\n\nSo acurl $URL\/books\/_all_docs means get all the documents from the books database from the IBM Cloudant service at the supplied URL.\n\nThis command's results return a list of _id and _rev values for each document. If you want the document bodies too, then add ?include_docs=true to your API call.\n\nIf we want to fetch a single document back from the database, then documents sit one level beneath the database in the hierarchy of the URL.\n\nSo acurl $URL\/books\/id means \"get document ID from the database books from the IBM Cloudant service at the supplied URL\".\n\nNotice the hierarchy: service, database, and document.\n\nSo far we only used the GET HTTP method, which is the default one for curl and the one used when you enter a URL into your web browser.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16384-7-2422","score":13.479381,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16365-8408-10508","score":13.297304,"text":"\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16368-7-2072","score":12.591245,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_03418-1763-3833","score":12.45247,"text":"\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Global audience support \n\nThe underlying skills understand customer messages that are written in any of the languages that are supported by the service. For more information, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support). The responses from your assistant are defined by you in the underlying skill and can be written in any language you want.\n\nEven if your skill includes responses in a language other than English, some of the phrases that are displayed in the web chat widget are added by the web chat itself and do not come from the underlying skill. These hardcoded phrases are specified in English unless you choose to apply a different language.\n\nThere are language files that contain translations of each English-language phrase that is used by the web chat. You can instruct the web chat to use one of these other languages files by using the instance.updateLanguagePack() method.\n\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1. To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basics"},{"document_id":"ibmcld_03109-10370-12635","score":12.348773,"text":"\nWhen the web chat widget is being interacted with by a user, we track the features that are being used, and events such as how many times the widget is opened and how many users start conversations. This information does not include Assistant training data or the content of any chat interactions. The information being sent to Amplitude is not Content as defined in the Cloud Service Agreement (CSA); it is Account Usage Information as described in Section 9.d of the CSA and is handled accordingly as described in the [IBM Privacy Statement](https:\/\/www.ibm.com\/privacy). The purpose of this information gathering is limited to establishing statistics about use and effectiveness of the web chat and making general improvements.\n\n\n\n\n\n Private network endpoints \n\nYou can set up a private network for Watson Assistant instances that are part of a Plus or Enterprise service plan. Using a private network prevents data from being transferred over the public internet, and ensures greater data isolation.\n\n![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) This feature is available only to users of paid plans.\n\nPrivate network endpoints support routing services over the IBM Cloud private network instead of the public network. A private network endpoint provides a unique IP address that is accessible to you without a VPN connection.\n\nFor implementation details, see [Public and private network endpoints](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-public-private-endpoints).\n\n\n\n Important private network endpoint notes \n\n\n\n* The integrations that are provided with the product require endpoints that are available on the public internet. Therefore, any built-in integrations you add to your assistant will have public endpoints. If you only want to connect to a client application or messaging channel over the private network, then you must build your own custom client application or channel integration.\n* Before you can use a search integration or search skill, you must create a Discovery instance with a private network endpoint. The list of Discovery instances that are displayed for you to connect to includes only instances with private network endpoints.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-securing"},{"document_id":"ibmcld_16295-7-1721","score":12.274339,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16280-4696-6712","score":12.172553,"text":"\nYou can configure how and where the web chat widget appears, and you can use theming to align it with your branding and website design. If a customer needs help from a person, the web chat integration can transfer the conversation to an agent.\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone): The phone integration enables your assistant to converse with customers on the phone by using the IBM Watson Text to Speech and Speech to Text services. If your customer asks to speak to a person, the phone integration can transfer the call to an agent.\n\n\n\n\n\n\n\n Updating and managing channels \n\nEach channel has specific settings that you can adjust to adapt the end experience for your user. You can edit these settings by selecting the channel in an environment, or in Integrations.\n\nIf you make an update to a channel in the draft environment, the same channel in live environment is not affected in the live environment. Similarly, if you make an update to a channel in the live environment, the same channel in draft environment is not affected. If you select a channel from the Integrations page, you are asked to select which environment you are editing.\n\nFor more information about editing your web chat integration, see [Basic web chat configuration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview).\n\n\n\n\n\n Deleting channels \n\nTo delete a channel, go to the Integrations page and use the overflow menu on the integration:\n\n![GIF of how to delete a channel](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/delete-channel.gif)\n\nIf you deployed your assistant to a channel, then deleting the channel does not remove the assistant from the channel. For example, if you deploy web chat, you paste the JavaScript snippet into the HTML header of your website. Deleting your channel disconnects your content from the customer experience that is shown on your website.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-assistant"},{"document_id":"ibmcld_02855-7-2041","score":11.89051,"text":"\nIntegrating the web chat with your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, click the Web chat tile.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n4. Click Create to create a web chat instance.\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Public assistant name. Name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 18 characters in length.\n* Primary color. Sets the color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: Sets the color of the user input message bubble.\n* Accent color. Sets the color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option\n* Typing indicator that is shown to repesent a pause response","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_03080-7-1901","score":11.810551,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03421-1518-3290","score":11.680739,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.6173196815}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02855-7-2041","score":14.427685,"text":"\nIntegrating the web chat with your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, click the Web chat tile.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n4. Click Create to create a web chat instance.\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Public assistant name. Name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 18 characters in length.\n* Primary color. Sets the color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: Sets the color of the user input message bubble.\n* Accent color. Sets the color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option\n* Typing indicator that is shown to repesent a pause response","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16295-7-1721","score":14.3175955,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16368-7-2072","score":14.210228,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_03421-1518-3290","score":14.114895,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_16389-0-2061","score":13.930729,"text":"\n\n\n\n\n\n\n  Configuring style and appearance \n\nOn the Style tab, you can configure the overall appearance of the web chat widget. You can make the following changes:\n\n\n\n*  Set the assistant name. Click Assistant's name as known by customers to specify the name that is displayed in the header of the chat window. The name can be up to 64 characters in length.\n*  Change the colors used in the web chat widget. You can set the following colors:\n\n\n\n*  Primary color: The color of the web chat header.\n*  Secondary color: The color of the customer input message bubble.\n*  Accent color: The color of interactive elements such as the following:\n\n\n\n*  Web chat buttons such as the suggestions button and the \"send message\" button\n*  The border around the input text field (when in focus)\n*  The markers that appear beside the assistant\u2019s messages\n*  The borders that appear around buttons and drop-down lists when customers select from options\n*  The home screen background\n\n\n\n\n\nEach color is specified as an HTML hexadecimal color code, such as FF33FC for pink and 329A1D for green. To change a color, type the HTML color code you want to use, or click the dot next to the field and choose the color from the interactive color picker.\n*  Enable or disable the Built with IBM Watson watermark that is displayed in the web chat widget. To disable the watermark, click to toggle the IBM Watermark switch to the off position. (The watermark cannot be disabled on the Lite plan.)\n*  Provide an avatar image to represent your assistant or organization in the web chat header. Click Add an avatar image to add an image, or Change avatar image to change an image you have previously added.\n\nSpecify the URL for a publicly accessible hosted image, such as a company or brand logo or an assistant avatar. The image file must be between 64 x 64 and 100 x 100 pixels in size.\n\n\n\nStyle changes you make are immediately reflected by the web chat preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-style"},{"document_id":"ibmcld_16365-8408-10508","score":13.745564,"text":"\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03080-1529-3357","score":13.744394,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16384-7-2422","score":13.332693,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_03080-7-1901","score":13.324187,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16280-4696-6712","score":12.88476,"text":"\nYou can configure how and where the web chat widget appears, and you can use theming to align it with your branding and website design. If a customer needs help from a person, the web chat integration can transfer the conversation to an agent.\n* [Phone integration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone): The phone integration enables your assistant to converse with customers on the phone by using the IBM Watson Text to Speech and Speech to Text services. If your customer asks to speak to a person, the phone integration can transfer the call to an agent.\n\n\n\n\n\n\n\n Updating and managing channels \n\nEach channel has specific settings that you can adjust to adapt the end experience for your user. You can edit these settings by selecting the channel in an environment, or in Integrations.\n\nIf you make an update to a channel in the draft environment, the same channel in live environment is not affected in the live environment. Similarly, if you make an update to a channel in the live environment, the same channel in draft environment is not affected. If you select a channel from the Integrations page, you are asked to select which environment you are editing.\n\nFor more information about editing your web chat integration, see [Basic web chat configuration](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview).\n\n\n\n\n\n Deleting channels \n\nTo delete a channel, go to the Integrations page and use the overflow menu on the integration:\n\n![GIF of how to delete a channel](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/delete-channel.gif)\n\nIf you deployed your assistant to a channel, then deleting the channel does not remove the assistant from the channel. For example, if you deploy web chat, you paste the JavaScript snippet into the HTML header of your website. Deleting your channel disconnects your content from the customer experience that is shown on your website.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-assistant"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16368-7-2072","score":18.484684,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16384-7-2422","score":15.757648,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16384-1889-3334","score":15.189713,"text":"\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_02855-6718-8435","score":14.814624,"text":"\nSubmit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nYou can apply more advanced customizations to the style of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration). For example, the text that is displayed in the chat window uses the fonts: IBMPlexSans, Arial, Helvetica, sans-serif. If you want to use a different font, you can specify it by using the instance.updateCSSVariables() method.\n\n\n\n\n\n Adding a home screen ![Beta](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/beta.png) \n\nCustomers often don't know how to interact with your assistant at first. They aren't sure how to format a question or what types of things they can ask. Don't make them guess. Show them by adding a home screen to the web chat window.\n\n![An example of the home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/home-screen.png)\n\n\n\n1. From the Home screen tab, turn the home screen feature On.\n2. Add a greeting that is engaging and invites the user to interact with your assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_02855-13982-15842","score":14.417318,"text":"\nFor more information about rich response types, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n Extending the web chat \n\nA developer can extend the capabilities of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html).\n\nIf you choose to use the provided methods, you implement them by editing the code snippet that was generated earlier. You then embed the updated code snippet into your web page.\n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-set-context%7D)\n* [Adding user identity information (if you don't enable security)](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid)\n\n\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {\nevent.data.context.skills['main skill'].user_defined.ismember = true;\n}\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_02855-5574-7284","score":14.129587,"text":"\nFor more information, see the [Using a custom launcher tutorial](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Changing the size or position of the chat window that is displayed when users click the launcher button. For more information, see the [Render to a custom element tutorial](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n\n\n\n14. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/web-chat-window.png)\n\nThe traffic to and from the web chat is sent between the instance that is hosted by your deployed cluster environment and the web page where you embed the web chat.\n15. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere that you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n16. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16295-7-1721","score":13.944913,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_02855-7-2041","score":13.774148,"text":"\nIntegrating the web chat with your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, click the Web chat tile.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n4. Click Create to create a web chat instance.\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Public assistant name. Name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 18 characters in length.\n* Primary color. Sets the color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: Sets the color of the user input message bubble.\n* Accent color. Sets the color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option\n* Typing indicator that is shown to repesent a pause response","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_03166-8640-10452","score":13.633328,"text":"\nFor more information, see [Applying advanced customizations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config).\n4. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/web-chat-window.png)\n5. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere where you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n6. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf the Connect to agent button is displayed and you don't have human agent support configured, you can hide it by changing the Suggestions configuration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nA developer can use APIs to apply more advanced customizations to the style of the web chat. For more information, see [Applying advanced customizations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config).\n\n\n\n\n\n Launcher appearance and behavior","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16365-8408-10508","score":13.263913,"text":"\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.7122630665,"ndcg_cut_10":0.7122630665}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16368-7-2072","score":13.725685,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16384-7-2422","score":13.659326,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_16387-7-1890","score":13.648151,"text":"\nEnabling web chat security \n\nTo enable web chat security, you must make changes to your web application server code and the web chat embed script, as well as the web chat integration settings.\n\n\n\n Before you begin \n\nBefore you enable security, you must create an RS256 public\/private key pair. You can use a tool such as OpenSSL or PuTTYgen.\n\nFor example, to create the key pair at a command prompt using OpenSSL, you would use the command openssl genrsa -out key.pem 2048.\n\nSave the generated key pair in a secure location.\n\nMake sure these keys are accessible only by your server code. Never pass them to a client browser through your website.\n\n\n\n\n\n Generating a JWT \n\nTo use web chat security, you must configure the web chat on your website to send a JSON Web Token (JWT) with each message to the assistant. The JWT is used to verify the origin of messages sent from your website, and optionally to carry additional encrypted data. Your website will need to be able to generate a new JWT at the beginning of each session, and also whenever an existing JWT expires.\n\nDo not hardcode a JWT in your website code or share JWTs between users.\n\nOn your server, implement a function that generates and returns a JSON Web Token (JWT) that is signed with your private key. You will use this token to verify the origin of messages sent from your website, and optionally to carry additional encrypted data.\n\nMost programming languages offer JWT libraries that you can use to generate a token. To validate signed JWTs, the web chat integration uses the [jsonwebtoken](https:\/\/www.npmjs.com\/package\/jsonwebtoken) library with the RS256 algorithm.\n\nThe JWT payload must specify the following claims:\n\n\n\n* sub: A unique user ID that identifies the customer who is interacting with the web chat. This can be either a generated unique identifier (for anonymous users) or an authenticated user ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable"},{"document_id":"ibmcld_03180-5630-7213","score":13.511803,"text":"\nEnabling visitor authentication also enables support for cross-domain traffic and cross-browser identification. For more information, see the [Zendesk documentation](https:\/\/support.zendesk.com\/hc\/en-us\/articles\/360022185314-Enabling-authenticated-visitors-in-the-Chat-widget).\n\nBefore you can secure the Zendesk connection, complete the following required tasks:\n\n\n\n1. Secure the web chat. For more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n\/\/ Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n\/\n* Returns a signed JWT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-zendesk"},{"document_id":"ibmcld_02855-3103-4802","score":13.326627,"text":"\nFor more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-alternate).\n8. Optional: To secure the web chat, click the Security tab. For more information, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security).\n9. Click the Embed tab.\n\nA code snippet is displayed that defines the chat window implementation. You will add this code snippet to your web page. The code snippet contains an HTML script element. The script calls JavaScript code that is hosted in your deployed cluster environment. The code creates an instance of a widget that communicates with the assistant. The generated code includes a region and unique integration ID. Do not change these parameter values.\n10. Copy the script HTML element.\n11. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.\n12. Open the HTML source for a web page on your website where you want the chat window to be displayed. Paste the code snippet into the page.\n\nPaste the code as close to the closing <\/body> tag as possible to ensure that your page renders faster.\n\nThe following HTML snippet is the source for a test page that you can copy and save as a file with a .html extension for testing purposes. You would replace the script element block here with the script elements you copied from the web chat integration setup page.\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n13. Refresh the web page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16298-6367-7794","score":13.187397,"text":"\nFor more information see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n\/\/ Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n\/\n* Returns a signed JWT. Optionally, adds an encrypted user_payload in stringified JSON.\n\/\nfunction mockLogin(userID, userPayload) {\nconst payload = {\nsub: userID, \/\/ Required\niss: 'www.ibm.com', \/\/ Required\nacr: 'loa1' \/\/ Required","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-zendesk"},{"document_id":"ibmcld_16385-7-2272","score":13.061507,"text":"\nOverview: Securing the web chat \n\nIf you enable security, you can configure the web chat to authenticate users, protect private data, and restrict access to your assistant.\n\nAll messages that are sent between the web chat and the assistant are encrypted using Transport Layer Security (TLS), which protects sensitive data as it travels through the network. However, there are still potential security exposures that you might need to protect against. By enabling the web chat security feature and updating your website code appropriately, you can add the following protections:\n\n\n\n* You can prevent unauthorized websites from sending messages to your assistant, even if they copy your web chat embed script. (The unique identifiers in the embed script, such as the integration ID and service instance ID, are visible to anyone who has access to your website.)\n* You can securely authenticate customers in order to control access to features of your assistant that require authorization.\n* You can encrypt sensistive data so that customers cannot see it, while still allowing your assistant to access it.\n\n\n\nWeb chat security uses JSON Web Tokens (JWTs), which are data objects that are sent with each message from your website to the Watson Assistant service. Because a JWT is digitally signed using a private encryption key that only you have, it ensures that each message originates with your website. The JWT payload can also be used to securely authenticate users and carry encrypted private data.\n\nFor detailed information about JSON Web Tokens, see the [JWT specification](https:\/\/tools.ietf.org\/html\/rfc7519)).\n\nEnabling web chat security involves making the following customizations:\n\n\n\n* Implementing web application server code that generates a JWT signed with your private encryption key\n* Customizing the web chat configuration to provide the generated JWT\n* Enabling security in the web chat security settings\n\nAfter you enable web chat security, any message received by the web chat integration that is not accompanied by a properly signed JWT will be rejected.\n\n\n\nFor detailed information about how to complete these steps, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security"},{"document_id":"ibmcld_16365-11574-13329","score":12.645003,"text":"\nAnyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website. For more information, see [Web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n Updating site security policies \n\nIf your website uses a Content Security Policy (CSP), you must update it to grant permission to the web chat.\n\nThe following table lists the values to add to your CSP.\n\n\n\nCSP properties\n\n Property Additional values \n\n default-src 'self' *.watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline' \n connect-src *.watson.appdomain.cloud \n\n\n\nThe following example shows a complete CSP metadata tag:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline';connect-src .watson.appdomain.cloud\" \/>\n\n\n\n Allowing elements \n\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_03422-4-2013","score":12.612344,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Securing the web chat \n\nUnderstand what you need to do to secure your web chat integration.\n\nConfigure the web chat to authenticate users and send private data from your embedded web chat.\n\nAll messages that are sent from the web chat are encrypted. When you enable security, your assistant takes an additional step to verify that messages originate from the web chat that is embedded in your website only.\n\nThe web chat uses an RSA signature with SHA-256 (RS256) to encrypt communication. RS256 signatures use a sophisticated type of RSA encryption. An RSA key pair includes a private and a public key. The RSA private key is used to generate digital signatures, and the RSA public key is used to verify digital signatures. The complexity of the RSA algorithm that is used to scramble the message makes it nearly impossible to unscramble the message without the key.\n\nThe following diagram illustrates the requests that are sent back and forth to authenticate a request.\n\n![Shows the order in which requests are sent among your website, web chat, and the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/web-chat-security.png)\n\nYou can implement the following security measures:\n\n\n\n* Ensure that messages sent from the web chat to your assistant come from your customers only\n* Send private data from the web chat to your assistant\n\n\n\n\n\n Before you begin \n\nThe process you use to add the web chat to your website is simple. Its simplicity also means it can be misused. That's why it's important to verify that the messages sent to your assistant are coming from authorized users only.\n\nBefore you enable security, complete the following steps:\n\n\n\n1. Create a RS256 private\/public key pair.\n\nYou can use a tool such as the OpenSSL command line or PuTTYgen.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security"},{"document_id":"ibmcld_16388-7-1918","score":12.554253,"text":"\nEncrypting sensitive data \n\nBy using the public key that is provided by IBM, you can add another level of encryption to hide sensitive data you send from the web chat.\n\nTo use this method for encrypting data, you must first enable the web chat security feature. For more information, see [Enabling web chat security](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-enable).\n\nUse this method to send sensitive information in messages that come from your website, such as information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from actions. Information passed to your assistant in this way is stored in a private context variable. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for a standard customer. You do not want non-VIPs to know that they are categorized as such, but you must pass this information to your action so it can change the flow of the conversation. To do this, you can pass the customer MVP status as an encrypted variable. This private context variable is available for use by the action, but not by anything else.\n\n![development icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/development-icon.png)Tutorial: For a tutorial that shows an example of using web chat security to authenticate users and protect sensitive data, see [Tutorial: Authenticating a user in the middle of a session](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-security).\n\nTo encrypt sensitive data:\n\n\n\n1. On the Security tab of the web chat integration settings, click the Generate key button.\n2. Copy the public key that displays in the IBM-provided public key field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-security-encrypt"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2043823976}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16368-7-2072","score":14.316253,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_02855-3103-4802","score":13.804265,"text":"\nFor more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-alternate).\n8. Optional: To secure the web chat, click the Security tab. For more information, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security).\n9. Click the Embed tab.\n\nA code snippet is displayed that defines the chat window implementation. You will add this code snippet to your web page. The code snippet contains an HTML script element. The script calls JavaScript code that is hosted in your deployed cluster environment. The code creates an instance of a widget that communicates with the assistant. The generated code includes a region and unique integration ID. Do not change these parameter values.\n10. Copy the script HTML element.\n11. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.\n12. Open the HTML source for a web page on your website where you want the chat window to be displayed. Paste the code snippet into the page.\n\nPaste the code as close to the closing <\/body> tag as possible to ensure that your page renders faster.\n\nThe following HTML snippet is the source for a test page that you can copy and save as a file with a .html extension for testing purposes. You would replace the script element block here with the script elements you copied from the web chat integration setup page.\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n13. Refresh the web page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_03080-1529-3357","score":13.519653,"text":"\nFor a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_03166-4588-6408","score":13.462825,"text":"\nIf you don't want to use a home screen, go to the Home screen tab and toggle the switch to Off.\n8. Optional: To configure support for transferring conversations to a service desk agent, click the Live agent tab. For more information, see [Adding service desk support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa).\n9. Optional: The web chat gives your customers a way to reset the conversation if they get stuck by showing them a list of suggestions. Suggestions are enabled automatically. You can control how often suggestions are displayed and what they include. Click the Suggestions tab. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n10. Optional: To secure the web chat, click the Security tab. For more information, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security).\n11. Click the Embed tab.\n\nA code snippet is displayed that defines the chat window implementation. You will add this code snippet to your web page. The code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site. The code creates an instance of a widget that communicates with the assistant. The generated code includes a region and unique integration ID. Do not change these parameter values.\n12. Copy the script HTML element. You add this script to your website in the next section, [Deploy your assistant in production](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-snippet).\n13. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_03080-7-1901","score":13.258831,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"},{"document_id":"ibmcld_16384-7-2422","score":13.174778,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_03421-1518-3290","score":13.089016,"text":"\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"},{"document_id":"ibmcld_03166-1557-3458","score":13.003448,"text":"\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) For environments where private endpoints are in use, keep in mind that the web chat integration sends traffic over the internet. For more information, see [Private network endpoints](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-securitysecurity-private-endpoints).\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Assistant's name as known by customers: The name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 64 characters in length.\n* Primary color: The color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: The color of the user input message bubble.\n* Accent color: The color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16326-3092-4450","score":12.868267,"text":"\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed. Any login, splash, cookie, or warning screens might be captured in the image.\n\nTo enter a URL:\n\n\n\n1. On the Preview page, click Change background.\n2. Click Enter URL, then click Continue.\n3. Enter the path of your website URL, for example, https:\/\/www.example.com or example.com.\n4. Click Continue.\n\n\n\n\n\n\n\n Uploading an image \n\nYou can upload an image of your organization's website. Images are stored for 24 hours. Maximum file size is 1 MB. Supported file types are JPEG and PNG.\n\nTo upload an image:\n\n\n\n1. On the Preview page, click Change background.\n2. Click Upload an image, then click Continue.\n3. Drag a file or click to upload, then click Change background.\n\n\n\nImages are stored for 24 hours. A warning message might appear on the Preview page about the time limit expiration. To clear this message:\n\n\n\n1. On the Preview page, click Change background.\n2. Click Clear background setting, then click Continue.\n3. Click Remove background to finish.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-preview-share"},{"document_id":"ibmcld_03421-4-1877","score":12.830975,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-config"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.3379680345}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03166-1557-3458","score":11.68469,"text":"\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) For environments where private endpoints are in use, keep in mind that the web chat integration sends traffic over the internet. For more information, see [Private network endpoints](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-securitysecurity-private-endpoints).\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Assistant's name as known by customers: The name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 64 characters in length.\n* Primary color: The color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: The color of the user input message bubble.\n* Accent color: The color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16295-7-1721","score":11.600632,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_03166-4588-6408","score":11.390274,"text":"\nIf you don't want to use a home screen, go to the Home screen tab and toggle the switch to Off.\n8. Optional: To configure support for transferring conversations to a service desk agent, click the Live agent tab. For more information, see [Adding service desk support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa).\n9. Optional: The web chat gives your customers a way to reset the conversation if they get stuck by showing them a list of suggestions. Suggestions are enabled automatically. You can control how often suggestions are displayed and what they include. Click the Suggestions tab. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n10. Optional: To secure the web chat, click the Security tab. For more information, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security).\n11. Click the Embed tab.\n\nA code snippet is displayed that defines the chat window implementation. You will add this code snippet to your web page. The code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site. The code creates an instance of a widget that communicates with the assistant. The generated code includes a region and unique integration ID. Do not change these parameter values.\n12. Copy the script HTML element. You add this script to your website in the next section, [Deploy your assistant in production](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-snippet).\n13. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16389-0-2061","score":11.359561,"text":"\n\n\n\n\n\n\n  Configuring style and appearance \n\nOn the Style tab, you can configure the overall appearance of the web chat widget. You can make the following changes:\n\n\n\n*  Set the assistant name. Click Assistant's name as known by customers to specify the name that is displayed in the header of the chat window. The name can be up to 64 characters in length.\n*  Change the colors used in the web chat widget. You can set the following colors:\n\n\n\n*  Primary color: The color of the web chat header.\n*  Secondary color: The color of the customer input message bubble.\n*  Accent color: The color of interactive elements such as the following:\n\n\n\n*  Web chat buttons such as the suggestions button and the \"send message\" button\n*  The border around the input text field (when in focus)\n*  The markers that appear beside the assistant\u2019s messages\n*  The borders that appear around buttons and drop-down lists when customers select from options\n*  The home screen background\n\n\n\n\n\nEach color is specified as an HTML hexadecimal color code, such as FF33FC for pink and 329A1D for green. To change a color, type the HTML color code you want to use, or click the dot next to the field and choose the color from the interactive color picker.\n*  Enable or disable the Built with IBM Watson watermark that is displayed in the web chat widget. To disable the watermark, click to toggle the IBM Watermark switch to the off position. (The watermark cannot be disabled on the Lite plan.)\n*  Provide an avatar image to represent your assistant or organization in the web chat header. Click Add an avatar image to add an image, or Change avatar image to change an image you have previously added.\n\nSpecify the URL for a publicly accessible hosted image, such as a company or brand logo or an assistant avatar. The image file must be between 64 x 64 and 100 x 100 pixels in size.\n\n\n\nStyle changes you make are immediately reflected by the web chat preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-style"},{"document_id":"ibmcld_16365-8408-10508","score":11.222802,"text":"\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16365-12876-14604","score":11.128123,"text":"\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https:\/\/web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https:\/\/integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16365-7-1700","score":11.040654,"text":"\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_02855-6718-8435","score":11.011177,"text":"\nSubmit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nYou can apply more advanced customizations to the style of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration). For example, the text that is displayed in the chat window uses the fonts: IBMPlexSans, Arial, Helvetica, sans-serif. If you want to use a different font, you can specify it by using the instance.updateCSSVariables() method.\n\n\n\n\n\n Adding a home screen ![Beta](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/beta.png) \n\nCustomers often don't know how to interact with your assistant at first. They aren't sure how to format a question or what types of things they can ask. Don't make them guess. Show them by adding a home screen to the web chat window.\n\n![An example of the home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/home-screen.png)\n\n\n\n1. From the Home screen tab, turn the home screen feature On.\n2. Add a greeting that is engaging and invites the user to interact with your assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_16334-28517-30318","score":10.923016,"text":"\nFor more information, see [Create a web chat instance to add to your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-task).\n* Fixes to rendering of list items: The rendering of HTML list items in the web chat widget has been updated.\n\n\n\n\n\n\n\n 4.1.0 \n\nRelease date: 8 April 2021\n\n\n\n* Home screen now generally available: Ease your customers into the conversation by adding a home screen to your web chat window. The home screen greets your customers and shows conversation starter messages that customers can click to easily start chatting with the assistant. For more information about the home screen feature, see [Configuring the home screen](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-home-screen).\n* Home screen enabled by default: The home screen feature is now enabled by default for all new web chat deployments.\n* Home screen context support: You can now access context variables from the home screen. Note that initial context must be set using a conversation_start node. For more information, see [Starting the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-startdialog-start-welcome).\n\n\n\n\n\n\n\n 4.0.0 \n\nRelease date: 16 March 2021\n\n\n\n* Session history now generally available: Session history allows your web chats to maintain conversation history and context when users refresh a page or change to a different page on the same website. It is enabled by default. For more information about this feature, see [Session history](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-session-history).\n\nSession history persists within only one browser tab, not across multiple tabs. The dialog provides an option for links to open in a new tab or the same tab.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_16334-27263-29119","score":10.876877,"text":"\nFor more information about the suggestions feature, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate). For more information about the home screen, see [Configuring the home screen](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-home-screen).\n* onError callback: The new onError callback option in the web chat configuration enables you to specify a callback function that is called if errors occur in the web chat. This makes it possible for you to handle any errors or outages that occur with the web chat. For more information, see [Listening for errors](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationonerror-detail).\n* Session ID available in widget state: The state information returned by the getState() instance method now includes the session ID for the current conversation. For more information, see [instance.getState()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsgetState).\n* IBM watermark: The web chat can now display a Built with IBM Watson watermark to users. This watermark is always enabled for any new web chat integrations on Lite plans. For more information, see [Create a web chat instance to add to your website](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-task).\n* Fixes to rendering of list items: The rendering of HTML list items in the web chat widget has been updated.\n\n\n\n\n\n\n\n 4.1.0 \n\nRelease date: 8 April 2021\n\n\n\n* Home screen now generally available: Ease your customers into the conversation by adding a home screen to your web chat window. The home screen greets your customers and shows conversation starter messages that customers can click to easily start chatting with the assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02774-5358-7120","score":13.441859,"text":"\nA user's predefined attributes are empty until their first authentication. Although they're empty, the user is still fully authenticated. You can use their profile ID just as you would someone who has already signed in. For instance, you can modify, search, or delete the profile.\n\n\n\n Before you begin \n\nBefore you get started, you must have the following information:\n\n\n\n* Which identity provider that the user will sign in with.\n* The email of the user that you want to add or their [unique identifier](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregisterpreregister-idp-provide).\n* The [custom attribute](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-profiles) information that you want to assign.\n\n\n\n\n\n\n\n With the GUI \n\nYou can add a future user and their custom attributes by using the GUI.\n\nThe ability to add future users is disabled for the user name and password configuration of Cloud Directory.\n\n\n\n1. Go to the User Profiles tab of the App ID dashboard.\n2. Click Future users. If you already have future users, you see a table with a list of the user's that you already added. To add another user, click Build a profile. If you don't have any users yet, click Get Started. A screen opens.\n3. Enter your user's email.\n4. Select the identity provider that they sign in with from the Identity Provider drop down.\n5. Add custom attributes by entering the information in a JSON object as shown in the following example.\n\n{\n\"food\": \"Pizza\",\n\"preference\": \"Vegetarian\",\n\"points\": \"37\"\n}\n6. Click Save. The table displays and the user is assigned an identifier.\n\n\n\n\n\n\n\n With the API \n\nYou can add a future user and their custom attributes by using the API.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Find your IAM token by running the following command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregister"},{"document_id":"ibmcld_02766-3003-4951","score":12.286671,"text":"\nAn identity provider creates and manages information about an entity such as a user, a functional ID, or an application. The provider verifies the identity of the entity by using credentials, such as a password. Then, the IdP sends the identity information back to App ID, which authorizes the user and then grants access to your app.\n\n\n\n1. Navigate to your service dashboard.\n2. In the Identity Providers section of the navigation, select the Manage page.\n3. On the Identity Providers tab, set the providers that you want to use, to On.\n4. Optional: Decide whether to turn off Anonymous users, or leave the default, which is On. When set to On, user attributes are associated with the user from the moment they begin interacting with your app. For more information about the path to becoming an identified user, see [Progressive authentication](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymousprogressive).\n\n\n\nApp ID provides default credentials to help with your initial setup of Facebook and Google+. You are limited to 20 uses of the credentials per instance, per day. Because they are IBM credentials, they are meant to be used only for development. Before you publish your app, update the configuration to your own credentials.\n\n\n\n\n\n Adding redirect URIs \n\nYour application redirects users to App ID for authentication. After authentication completes, App ID redirects users back to your application. In order for App ID to be able to redirect users back to your app, you need to register the redirect URI. During the sign-in flow, App ID validates the URIs before it allows clients to participate in the authorization workflow, which helps to prevent phishing attacks and grant code leakage. By registering your URI, you're telling App ID that the URI is trusted and it's OK to redirect your users.\n\n\n\n1. Click Authentication Settings to see your URI and token configuration options.\n2. In the Add web redirect URI field, type the URI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-managing-idp"},{"document_id":"ibmcld_02797-2605-4221","score":12.252145,"text":"\nThis action allows users to update their attributes after they answer your initial questionnaire.\n\n\n\nExcellent! Your dashboard is configured and you're ready to start setting attributes.\n\n\n\n\n\n Step 2: Creating user attributes \n\nWhen your users interact with your questionnaire, you can map their answers to specific attributes, then add those attributes to their file.\n\nYour application is responsible for mapping the answers to the specific attributes that you want to add to the profile.\n\n\n\n1. Update the profile with the attribute.\n\ncurl --request PUT https:\/\/<region>.appid.cloud.ibm.com\/management\/v4\/<tenantID>\/users\/<userID>\/profile --header 'Authorization: Bearer <IAMToken>' --header 'Content-Type: application\/json' -d '{\n\"profile\": {\n\"attributes\": {\n\u201cfood-preference\u201d: \u201cvegetarian, glutten-free\u201d\n}\n}\n}'\n2. View the profile to verify that it was updated correctly.\n\ncurl --request GET https:\/\/<region>.appid.cloud.ibm.com\/management\/v4\/<tenantID>\/users\/<userID>\/profile --header 'Authorization: Bearer <IAMToken>' --header 'Content-Type: application\/json'\n\nSuccessful response output:\n\n{\n\"id\": \"5ce78e09-1356-4ef8-a45d-808b633101db\",\n\"identities\": [],\n\"attributes\": {\n\"food-preference\": \"vegetarian, gluten-free\"\n}\n}\n\n\n\nGreat work!\n\n\n\n\n\n Step 3: Injecting attributes into tokens \n\nBecoming more popular, you decide to implement a \"deal-of-the-day\". You want the first thing that the user sees when they sign in to your application to be a coupon for something that matches their dietary preferences. You can achieve this goal by injecting the attributes that are stored in their profiles into their tokens.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-tutorial-attributes"},{"document_id":"ibmcld_11474-5244-7072","score":12.074649,"text":"\nOpen the App ID instance page from the [resource list](https:\/\/cloud.ibm.com\/resources) Services and software section.\n2. Go to Manage Authentication \u2192 Cloud Directory \u2192 Users, and click Create User. Enter the user details.\n\n\n\n\n\n\n\n Step 6: Create or modify users' project assignments \n\nIf the IDP administrator will assign users to projects, you can define project values in the user's attributes.\n\n\n\n1. Open the App ID instance page from the [resource list](https:\/\/cloud.ibm.com\/resources) Services and software section.\n2. Go to Manage Authentication \u2192 Cloud Directory \u2192 Users, and click a user to open it.\n3. Scroll down to Custom Attributes, and click Edit.\n4. Enter a key value pair that can will checked by the dynamic rules of the access groups, then click Save. You can add several values in the same string (for example, {\"project\":\"ml finance\"}); the contains qualifier of the dynamic rule detects a match of a substring. For our example, add:\n\n{\"project\":\"ml\"}\n\nThe value project corresponds to the convention defined in the planning section. ml is the project that the user belongs to.\n\nThis check is done on every login, so changes in the ID provider user attributes will be effective when a user next logs in.\n\n\n\n\n\n\n\n User flow \n\n\n\n1. A user is sent the ID provider URL for the IBM Cloud account.\n\nThe administrator can always go to [Manage \u2192 Access (IAM) \u2192 Identity providers](https:\/\/cloud.ibm.com\/iam\/identity-providers) to look up the ID provider URL.\n2. To work with Qiskit Runtime serive instances, users must create an API key by going to ([Manage \u2192 Access (IAM) \u2192 API keys](https:\/\/cloud.ibm.com\/iam\/apikeys)).\n3. For further information, users can review [Getting started, Step 2](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-get-startedinstall-packages).\n\n\n\n\n\n\n\n Example scenario","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-appid-org"},{"document_id":"ibmcld_02777-2701-4678","score":11.851127,"text":"\n: If you need to see an in-depth view of the user profile information that is returned by an identity provider, you can call the [\/userinfo endpoint](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Authorization_Server_V4\/userInfo). It's recommended to use this endpoint only if the information cannot be mapped to the token as it requires extra network calls.\n\n\/api\/v1\/attributes\n: If your application requires reading and updating custom profile attributes for a currently logged in user, then you can use the \/attributes endpoint. For example, the user wants to update a food preference.\n\n\/management\/v4\/<tenantID>\/users\n: If you're building administrative interfaces or processes that might apply to multiple users, you can use the App ID management API. Specifically, you can use the \/users endpoint.\n\nThe easiest ways to work with user information are by using the GUI or an SDK. With those options, all the API calls are done behind the scenes for you.\n\n\n\n\n\n\n\n Accessing attributes at run time \n\nAfter successful user authentication, your app receives access and identity tokens from App ID. The service automatically injects a subset of attributes into your access and identity tokens. If the information isn't in the token, you can use any of the following endpoints to find the information.\n\n\n\n Accessing the \/userinfo endpoint \n\nTo see the information about your users that is provided by your configured identity providers, you can access your predefined attributes.\n\n\n\n1. Be sure that you have a valid access token with an openid scope. You can verify that your token is valid by using the \/introspect endpoint.\n2. Make a request to the [\/userinfo endpoint](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Authorization_Server_V4\/userInfo). If new tokens are not explicitly passed to the SDK, App ID uses the last received tokens to retrieve and validate the response. Passing an identity token is optional, but passed is used to validate the response.\n\n\n\n* Curl","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-profiles"},{"document_id":"ibmcld_06337-5470-7638","score":11.788887,"text":"\nIf you want to add them there, you can create a new credential with the existing user information.\n\nEnter the username and password in the JSON field Add Inline Configuration Parameters, or specify a file where the JSON information is stored. For example, putting {\"existing_credentials\":{\"username\":\"Robert\",\"password\":\"supersecure\"}} in the field generates Service Credentials with the username \"Robert\" and password \"supersecure\" filled into connection strings.\n\nGenerating credentials from an existing user does not check for or create that user.\n\n\n\n\n\n\n\n Connection String Breakdown \n\n\n\n The HTTPS Section \n\nThe \"https\" section contains information that is suited to applications that make connections to Elasticsearch.\n\n\n\nTable 1. https\/URI connection information\n\n Field Name Index Description \n\n Type Type of connection - for Elasticsearch, it is \"uri\" \n Scheme Scheme for a URI - for Elasticsearch, it is \"https\" \n Path Path for a URI \n Authentication Username The username that you use to connect. \n Authentication Password A password for the user - might be shown as $PASSWORD \n Authentication Method How authentication takes place; \"direct\" authentication is handled by the driver. \n Hosts 0... A hostname and port to connect to \n Composed 0... A URI combining Scheme, Authentication, Host, and Path \n Certificate Name The allocated name for the self-signed certificate for database deployment \n Certificate Base64 A base64 encoded version of the certificate. \n\n\n\n\n\n* 0... indicates that may be one or more of these entries in an array.\n\n\n\n\n\n\n\n The CLI Section \n\nThe \"CLI\" section contains information that is suited for connecting with cURL.\n\n\n\nTable 2. curl connection information\n\n Field Name Index Description \n\n Bin The recommended binary to create a connection; in this case it is curl. \n Composed A formatted command to establish a connection to your deployment. The command combines the Bin executable, Environment variable settings, and uses Arguments as command-line parameters. \n Environment A list of key\/values you set as environment variables. \n Arguments 0... The information that is passed as arguments to the command shown in the Bin field.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-connection-strings"},{"document_id":"ibmcld_16382-7-1870","score":11.670335,"text":"\nManaging user identity information \n\nWatson Assistant charges based on the number of unique monthly active users (MAU).\n\nIf you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user. And you are charged only once when the same anonymous user interacts with your assistant multiple times in a single month.\n\nIf you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration. Choose a non-human-identifiable ID. For example, do not use a person's email address as the user ID.\n\nIn addition, the ability to delete any data created by someone who requests to be forgotten requires that a customer_id be associated with the user input. When a user_id is defined, the product can reuse it to pass a customer_id parameter. (For more information about deleting user data, see [Labeling and deleting data](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-securingsecuring-gdpr-wa).)\n\nBecause the user_id value that you submit is included in the customer_id value that is added to the X-Watson-Metadata header in each message request, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nTo support these user-based capabilities, add the [updateUserID() method](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdateuserid) in the code snippet before you paste it into your web page.\n\nIf you enable security, you set the user ID in the JSON Web Token instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid"},{"document_id":"ibmcld_03422-1615-3407","score":11.571288,"text":"\nThe process you use to add the web chat to your website is simple. Its simplicity also means it can be misused. That's why it's important to verify that the messages sent to your assistant are coming from authorized users only.\n\nBefore you enable security, complete the following steps:\n\n\n\n1. Create a RS256 private\/public key pair.\n\nYou can use a tool such as the OpenSSL command line or PuTTYgen.\n\n\n\n* For example, to create the key pair: openssl genrsa -out key.pem 2048\n\n\n\n2. Use your private key to sign a JSON Web Token (JWT). You will pass the token with the messages that are sent from your website as proof of their origin.\n\nThe JWT payload must specify values for the following claims:\n\n\n\n* iss: Represents the issuer of the JWT. This value is a case-sensitive string.\n* sub: Represents the principal that is the subject of the JWT. This value must either be scoped to be locally unique in the context of the issuer or be globally unique. The value you specify for sub is used as the user_id.\n\nThe user ID that is specified in the sub claim is also sent in the customer_id section of the X-Watson-Metadata HTTP header. The customer_id can be used to make requests to delete user data. Because the ID is sent in a header field, the syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2) (all visible ASCII characters). For more information about deleting user data, see [Labeling and deleting data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-information-securityinformation-security-gdpr-wa).\n* exp: Represents the expiration time on or after which the JWT cannot be accepted for processing. Many libraries set this value for you automatically. Set a short-lived exp claim with whatever library you use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security"},{"document_id":"ibmcld_02734-1732-3794","score":11.539955,"text":"\nYou can attach the attributes of only one anonymous profile to the user's identity that is stored in App ID. For example, say that a user browses your application anonymously in two separate browser tabs. The user adds a t-shirt to the shopping cart on the first tab and a pair of shorts to the cart on the second tab. App ID creates two separate anonymous profiles to track the interactions of the user with your application on each tab.\n\nIf the user chooses to sign in from the first tab, then they have access only to the t-shirt they added to their cart before they signed in. In this case, App ID attaches only the attributes of the anonymous profile on the first tab to the user's identity. The service does not merge the anonymous profile that is created on the second tab to the user's identity stored in App ID. But the user can still access the shorts anonymously on the second tab because they are still accessible with the anonymous profile that was created on the second tab. While you develop your app, you can configure how to attach anonymous attributes to identified user profiles.\n\n\n\n What does the progressive authentication flow look like? \n\nIn the following image, you can see the direction of communication that defines the progressive authentication flow between the user, your application, App ID, and the identity provider.\n\nZoom\n\n![The path to becoming an identified user when they start as anonymous](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/27ecaa7a29890634603881a8e64789974a29916b\/appid\/images\/auth-anon-user.svg)\n\nFigure 1. Progressive authentication flow of anonymous user\n\n\n\n1. The user interacts with areas of your app that do not require authentication.\n2. Your application notifies App ID that the user wants to interact with your app as an anonymous user.\n3. App ID creates an ad hoc user profile and calls the OAuth login that issues anonymous tokens for the anonymous user.\n4. Using the anonymous tokens from App ID, you can create, read, update, and delete the attributes that are stored in the anonymous user profile.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymous"},{"document_id":"ibmcld_02774-6807-8305","score":11.481538,"text":"\n\"preference\": \"Vegetarian\",\n\"points\": \"37\"\n}\n6. Click Save. The table displays and the user is assigned an identifier.\n\n\n\n\n\n\n\n With the API \n\nYou can add a future user and their custom attributes by using the API.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Find your IAM token by running the following command.\n\nibmcloud iam oauth-tokens\n3. Make a POST request to the \/users endpoint that contains a description of the user and the attributes that you want to set as a JSON object.\n\nHeader:\n\nPOST <managementUrl>\/management\/v4\/<tenantID>\/users\nHost: <managementServerURL>\nAuthorization: 'Bearer <IAMToken>'\nContent-Type: application\/json\n\nBody:\n\n{\n\"idp\": \"<identityProvider>\",\n\"idp-identity\": \"<userUniqueIdentifier>\",\n\"profile\": {\n\"attributes\": {\n\"mealPreference\":\"vegeterian\"\n}\n}\n}\n\n\n\nTable 2. The components of the POST request\n\n Components Description \n\n idp The identity provider that the user authenticates with. Options include: saml, cloud_directory, facebook, google, appid_custom, ibmid. \n idp-identity The unique identifier provided by the identity provider. \n profile The user's profile that contains the custom attribute JSON mapping. \n\n\n\nExample request:\n\n$ curl --request POST --url 'https:\/\/<managementURI>\/users --header 'Authorization: Bearer <IAMToken>' --header 'Content-Type: application\/json' --data '{\"idp\": \"saml\", \"idp-identity\": \"user@ibm.com\", \"profile\": { \"attributes\": { \"role\": \"admin\",\n\"frequent_flyer_points\": 1000 }}}'\n4. Verify that registration was successful.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregister"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"fdee20f7fd677e420742b09989623d68<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16365-7-1700","score":14.519619,"text":"\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16389-0-2061","score":14.435158,"text":"\n\n\n\n\n\n\n  Configuring style and appearance \n\nOn the Style tab, you can configure the overall appearance of the web chat widget. You can make the following changes:\n\n\n\n*  Set the assistant name. Click Assistant's name as known by customers to specify the name that is displayed in the header of the chat window. The name can be up to 64 characters in length.\n*  Change the colors used in the web chat widget. You can set the following colors:\n\n\n\n*  Primary color: The color of the web chat header.\n*  Secondary color: The color of the customer input message bubble.\n*  Accent color: The color of interactive elements such as the following:\n\n\n\n*  Web chat buttons such as the suggestions button and the \"send message\" button\n*  The border around the input text field (when in focus)\n*  The markers that appear beside the assistant\u2019s messages\n*  The borders that appear around buttons and drop-down lists when customers select from options\n*  The home screen background\n\n\n\n\n\nEach color is specified as an HTML hexadecimal color code, such as FF33FC for pink and 329A1D for green. To change a color, type the HTML color code you want to use, or click the dot next to the field and choose the color from the interactive color picker.\n*  Enable or disable the Built with IBM Watson watermark that is displayed in the web chat widget. To disable the watermark, click to toggle the IBM Watermark switch to the off position. (The watermark cannot be disabled on the Lite plan.)\n*  Provide an avatar image to represent your assistant or organization in the web chat header. Click Add an avatar image to add an image, or Change avatar image to change an image you have previously added.\n\nSpecify the URL for a publicly accessible hosted image, such as a company or brand logo or an assistant avatar. The image file must be between 64 x 64 and 100 x 100 pixels in size.\n\n\n\nStyle changes you make are immediately reflected by the web chat preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-style"},{"document_id":"ibmcld_03166-1557-3458","score":14.04023,"text":"\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) For environments where private endpoints are in use, keep in mind that the web chat integration sends traffic over the internet. For more information, see [Private network endpoints](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-securitysecurity-private-endpoints).\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Assistant's name as known by customers: The name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 64 characters in length.\n* Primary color: The color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: The color of the user input message bubble.\n* Accent color: The color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16295-7-1721","score":13.632021,"text":"\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat"},{"document_id":"ibmcld_16368-7-2072","score":13.598713,"text":"\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop"},{"document_id":"ibmcld_16365-8408-10508","score":13.56542,"text":"\nThe code snippet that creates the web chat widget includes a configuration object, which you can modify to change the appearance and behavior of the web chat. The configuration object also specifies details that enable the web chat to connect to your assistant. If you are comfortable writing JavaScript code, you can customize the web chat by modifying the code snippet and using the web chat API.\n\nThe web chat uses the Watson Assistant v2 stateful API to communicate with the assistant. By default, the session ends and the conversation ends after 5 minutes of inactivity. This means that if a user stops interacting with the assistant, after 5 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values. You can change the inactivity timeout setting in the assistant settings (if allowed by your plan).\n\n\n\n Browser support \n\nThe web chat supports a variety of devices and platforms. As a general rule, if the last two versions of a browser account for more than 1% of all desktop or mobile traffic, the web chat supports that browser.\n\nThe following list specifies the minimum required browser software for the web chat (including the two most recent versions, except as noted):\n\n\n\n* Google Chrome\n* Apple Safari\n* Mobile Safari\n* Chrome for Android\n* Microsoft Edge (Chromium and non-Chromium)\n* Mozilla Firefox\n* Firefox ESR (most recent ESR only)\n* Opera\n* Samsung Mobile Browser\n* UC Browser for Android\n* Mobile Firefox\n\n\n\nFor optimal results when rendering the web chat on mobile devices, the <head> element of your web page must include the following metadata element:\n\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" \/>\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https:\/\/www.w3.org\/WAI\/standards-guidelines\/wcag\/new-in-21\/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"},{"document_id":"ibmcld_16384-7-2422","score":13.531105,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_03166-4588-6408","score":13.515208,"text":"\nIf you don't want to use a home screen, go to the Home screen tab and toggle the switch to Off.\n8. Optional: To configure support for transferring conversations to a service desk agent, click the Live agent tab. For more information, see [Adding service desk support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa).\n9. Optional: The web chat gives your customers a way to reset the conversation if they get stuck by showing them a list of suggestions. Suggestions are enabled automatically. You can control how often suggestions are displayed and what they include. Click the Suggestions tab. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n10. Optional: To secure the web chat, click the Security tab. For more information, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-security).\n11. Click the Embed tab.\n\nA code snippet is displayed that defines the chat window implementation. You will add this code snippet to your web page. The code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site. The code creates an instance of a widget that communicates with the assistant. The generated code includes a region and unique integration ID. Do not change these parameter values.\n12. Copy the script HTML element. You add this script to your website in the next section, [Deploy your assistant in production](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-snippet).\n13. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_02855-3103-4802","score":13.449513,"text":"\nFor more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-alternate).\n8. Optional: To secure the web chat, click the Security tab. For more information, see [Securing the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-security).\n9. Click the Embed tab.\n\nA code snippet is displayed that defines the chat window implementation. You will add this code snippet to your web page. The code snippet contains an HTML script element. The script calls JavaScript code that is hosted in your deployed cluster environment. The code creates an instance of a widget that communicates with the assistant. The generated code includes a region and unique integration ID. Do not change these parameter values.\n10. Copy the script HTML element.\n11. If you made any customizations, click Save and exit. Otherwise, click Close.\n\nThe web chat instance is created as soon as you click the Create button, and does not need to be saved.\n12. Open the HTML source for a web page on your website where you want the chat window to be displayed. Paste the code snippet into the page.\n\nPaste the code as close to the closing <\/body> tag as possible to ensure that your page renders faster.\n\nThe following HTML snippet is the source for a test page that you can copy and save as a file with a .html extension for testing purposes. You would replace the script element block here with the script elements you copied from the web chat integration setup page.\n\n<html>\n<head><\/head>\n<body>\n<title>My Test Page<\/title>\n<p>The body of my page.<\/p>\n\n<\/body>\n<\/html>\n13. Refresh the web page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_03080-7-1901","score":13.3795805,"text":"\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-config"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.636439181}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06160-11142-12906","score":16.28757,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-11475-13230","score":15.9922285,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10534-545406-546780","score":15.601525,"text":"\n* [If all worker nodes in a single zone, subnet, or VLAN are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-zone)\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-bm_machine_idbm_machine_id)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_05713-581893-583377","score":15.439815,"text":"\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10596-5350-7330","score":14.759005,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-5357-7356","score":14.738635,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\nIf some, but not all, of your worker nodes frequently enter a Critical or NotReady state, consider enabling [worker autorecovery](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorautorecovery) to automate these recovery steps.\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-9883-11854","score":14.628644,"text":"\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-10037-11653","score":14.585932,"text":"\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_06125-1305-2237","score":13.974974,"text":"\nRun the px_logcollect.sh script. You can collect logs from all your worker nodes, or you can specify the --workers option and pass the private IP addresses of the worker nodes from where you want to collect logs. If you specify the --workers option, the log files are saved in the \/tmp\/pxlogs\/<worker_node_IP> directory with the private IP address of each worker node as the folder name. To get the private IP addresses of your worker nodes, run the kubectl get nodes command.\n\n\n\n* Collect the logs from all worker nodes in your cluster.\n\nsudo .\/px_logcollect.sh\n* Collect the logs from only certain worker nodes in your cluster.\n\nsudo .\/px_logcollect.sh --workers <worker-IP> <worker-IP> <worker-IP>\n\n\n\n4. Review the log files locally. If you can't resolve your issue by reviewing the logs, [open a support ticket](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help) and provide the log information that you collected.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_support"},{"document_id":"ibmcld_10566-1230-2155","score":13.97289,"text":"\nRun the px_logcollect.sh script. You can collect logs from all your worker nodes, or you can specify the --workers option and pass the private IP addresses of the worker nodes from where you want to collect logs. If you specify the --workers option, the log files are saved in the \/tmp\/pxlogs\/<worker_node_IP> directory with the private IP address of each worker node as the folder name. To get the private IP addresses of your worker nodes, run the oc get nodes command.\n\n\n\n* Collect the logs from all worker nodes in your cluster.\n\nsudo .\/px_logcollect.sh\n* Collect the logs from only certain worker nodes in your cluster.\n\nsudo .\/px_logcollect.sh --workers <worker-IP> <worker-IP> <worker-IP>\n\n\n\n4. Review the log files locally. If you can't resolve your issue by reviewing the logs, [open a support ticket](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-get-help) and provide the log information that you collected.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage_portworx_support"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10394-7-1848","score":18.990969,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_06209-8154-10055","score":17.34784,"text":"\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the classic worker node to the same patch by using the ibmcloud ks worker update command.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_05528-69628-70310","score":17.150063,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.17.7_1530\n\n Component Previous Current Description \n\n HAProxy 2.0.15-afe432 1.8.25-384f42 See the [HAProxy change log](https:\/\/www.haproxy.org\/download\/1.8\/src\/CHANGELOG). Fixes a connection leak that happens when HAProxy is under high load. \n Kubernetes v1.17.7 v1.17.9 See the [Kubernetes change logs](https:\/\/github.com\/kubernetes\/kubernetes\/blob\/master\/CHANGELOG\/CHANGELOG-1.17.mdv1179). The update resolves CVE-2020-8557 (see the [IBM security bulletin](https:\/\/www.ibm.com\/support\/pages\/node\/6249941)).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-117_changelog"},{"document_id":"ibmcld_05527-34829-35515","score":17.149132,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.16.11_1537\n\n Component Previous Current Description \n\n HAProxy 2.0.15-afe432 1.8.25-384f42 See the [HAProxy change log](https:\/\/www.haproxy.org\/download\/1.8\/src\/CHANGELOG). Fixes a connection leak that happens when HAProxy is under high load. \n Kubernetes v1.16.11 v1.16.13 See the [Kubernetes change logs](https:\/\/github.com\/kubernetes\/kubernetes\/blob\/master\/CHANGELOG\/CHANGELOG-1.16.mdv11613). The update resolves CVE-2020-8557 (see the [IBM security bulletin](https:\/\/www.ibm.com\/support\/pages\/node\/6249941)).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-116_changelog"},{"document_id":"ibmcld_10642-6354-8294","score":17.113075,"text":"\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_05527-49848-50451","score":17.06512,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.16.8_1528\n\n Component Previous Current Description \n\n containerd v1.3.3 v1.3.4 See the [containerd release notes](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.3.4). \n HA proxy 1.8.25-30b675 1.8.25-adb65d The update addresses [CVE-2020-1967](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-1967). \n Kubernetes v1.16.8 v1.16.9 See the [Kubernetes release notes](https:\/\/github.com\/kubernetes\/kubernetes\/releases\/tag\/v1.16.9).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-116_changelog"},{"document_id":"ibmcld_05528-84256-84859","score":17.062223,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.17.4_1521\n\n Component Previous Current Description \n\n containerd v1.3.3 v1.3.4 See the [containerd release notes](https:\/\/github.com\/containerd\/containerd\/releases\/tag\/v1.3.4). \n HA proxy 1.8.25-30b675 1.8.25-adb65d The update addresses [CVE-2020-1967](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-1967). \n Kubernetes v1.17.4 v1.17.5 See the [Kubernetes release notes](https:\/\/github.com\/kubernetes\/kubernetes\/releases\/tag\/v1.17.5).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-117_changelog"},{"document_id":"ibmcld_05528-97241-98398","score":17.029598,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.17.3_1516\n\n Component Previous Current Description \n\n GPU worker node provisioning N\/A N\/A Fixed bug where new GPU worker nodes could not automatically join clusters that run Kubernetes version 1.16 or 1.17. \n Ubuntu 18.04 packages 4.15.0-76-generic 4.15.0-88-generic Updated worker node images with package updates for [CVE-2019-5108](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-5108), [CVE-2019-20096](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-20096), [CVE-2019-18885](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-18885), [CVE-2019-19082](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-19082), [CVE-2019-19078](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-19078), [CVE-2019-19332](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-19332), [CVE-2016-9840](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2016-9840), [CVE-2016-9841](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2016-9841), [CVE-2016-9842](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2016-9842), and [CVE-2016-9843](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2016-9843).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-117_changelog"},{"document_id":"ibmcld_05527-62350-63507","score":17.02594,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.16.7_1524\n\n Component Previous Current Description \n\n GPU worker node provisioning N\/A N\/A Fixed bug where new GPU worker nodes could not automatically join clusters that run Kubernetes version 1.16 or 1.17. \n Ubuntu 18.04 packages 4.15.0-76-generic 4.15.0-88-generic Updated worker node images with package updates for [CVE-2019-5108](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-5108), [CVE-2019-20096](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-20096), [CVE-2019-18885](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-18885), [CVE-2019-19082](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-19082), [CVE-2019-19078](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-19078), [CVE-2019-19332](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-19332), [CVE-2016-9840](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2016-9840), [CVE-2016-9841](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2016-9841), [CVE-2016-9842](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2016-9842), and [CVE-2016-9843](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2016-9843).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-116_changelog"},{"document_id":"ibmcld_05528-58483-59817","score":17.024527,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.17.11_1538\n\n Component Previous Current Description \n\n HAProxy 1.8.25-384f42 1.8.26-561f1a See the [HAProxy change log](https:\/\/www.haproxy.org\/download\/1.8\/src\/CHANGELOG). \n Ubuntu 18.04 packages 4.15.0-112-generic 4.15.0-117-generic Updated worker node image with kernel and package updates for [CVE-2020-14344](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-14344), [CVE-2020-14363](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-14363), and [CVE-2020-14386](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-14386). \n Ubuntu 16.04 packages 4.4.0-187-generic 4.4.0-189-generic Updated worker node image with kernel and package updates for [CVE-2020-14344](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-14344) and [CVE-2020-14363](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-14363). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.17.11_1538, released 31 August 2020 \n\nThe following table shows the changes that are in the worker node fix pack 1.17.11_1538. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.17.11_1537\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-117_changelog"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6508205186,"ndcg_cut_10":0.6508205186}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10394-1469-2994","score":11.272622,"text":"\nIf you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.\n\n\n\n\n\n\n\n Step 2: Determine which worker nodes you want to update \n\nMajor\n\nMinor\n\n\n\n1. List your worker nodes by using the oc get nodes command and determining which worker nodes you want to update.\n\noc get nodes\n\nExample output\n\nNAME STATUS ROLES AGE VERSION\n10.241.0.4 Ready master,worker 106s v1.21.6+4b61f94\n10.241.128.4 Ready master,worker 22d v1.21.6+bb8d50a\n10.241.64.4 Ready master,worker 22d v1.21.6+bb8d50a\n\n\n\n\n\n\n\n Step 3: Scale down OpenShift Data Foundation \n\nMajor\n\nMinor\n\n\n\n1. For each worker node that you found in the previous step, find the rook-ceph-mon and rook-ceph-osd deployments.\n\noc get pods -n openshift-storage -o wide | grep -i <node_name>\n2. Scale down the deployments that you found in the previous step.\n\noc scale deployment rook-ceph-mon-c --replicas=0 -n openshift-storage\noc scale deployment rook-ceph-osd-2 --replicas=0 -n openshift-storage\noc scale deployment --selector=app=rook-ceph-crashcollector,node_name=NODE-NAME --replicas=0 -n openshift-storage\n\n\n\n\n\n\n\n Step 4: Cordon and drain the worker node \n\nMajor\n\nMinor\n\n\n\n1. Cordon the node. Cordoning the node prevents any pods from being scheduled on this node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_10394-7-1848","score":11.060595,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_10395-7-1827","score":11.028046,"text":"\nUpdating VPC worker nodes that use OpenShift Data Foundation \n\nVirtual Private Cloud\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc"},{"document_id":"ibmcld_10395-1448-2944","score":10.525567,"text":"\nIf you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.\n\n\n\n\n\n\n\n Step 2: Determine which storage nodes you want to update \n\nMajor\n\nMinor\n\n\n\n1. List your worker nodes by using oc get nodes and determine which storage nodes you want to update.\n\noc get nodes\n\nExample output\n\nNAME STATUS ROLES AGE VERSION\n10.241.0.4 Ready master,worker 106s v1.21.6+4b61f94\n10.241.128.4 Ready master,worker 22d v1.21.6+bb8d50a\n10.241.64.4 Ready master,worker 22d v1.21.6+bb8d50a\n\n\n\n\n\n\n\n Step 3: Scale down OpenShift Data Foundation \n\nMajor\n\nMinor\n\n\n\n1. For each worker node that you found in the previous step, find the rook-ceph-mon and rook-ceph-osd deployments.\n\noc get pods -n openshift-storage -o wide | grep -i <node_name>\n2. Scale down the deployments that you found in the previous step.\n\noc scale deployment rook-ceph-mon-c --replicas=0 -n openshift-storage\ndeployment.apps\/rook-ceph-mon-c scaled\noc scale deployment rook-ceph-osd-2 --replicas=0 -n openshift-storage\ndeployment.apps\/rook-ceph-osd-2 scaled\noc scale deployment --selector=app=rook-ceph-crashcollector,node_name=NODE-NAME --replicas=0 -n openshift-storage\n\n\n\n\n\n\n\n Step 4: Cordon and drain the worker node \n\nMajor\n\nMinor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-vpc"},{"document_id":"ibmcld_11770-14487-16386","score":10.276323,"text":"\n[Assign the newly attached hosts to your Satellite resource](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-assigning-hostshost-assign-manual). These hosts automatically receive the update when you assign them.\n4. After the new hosts are successfully assigned to your Satellite resource, [remove and delete the old hosts that you previously noted](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-remove).\n\n\n\n\n\n\n\n Updating worker node hosts in the Red Hat OpenShift on IBM Cloud console \n\nYou can update worker node hosts by using the Red Hat OpenShift on IBM Cloud console.\n\n\n\n1. Log in to the IBM Cloud console and click OpenShift > Clusters.\n2. Click the cluster where the hosts that you want to update are assigned and navigate to the Worker nodes page.\n3. Select each host that you want to update. After you select the hosts, an Update option appears.\n4. Click Update. In the dialog box that appears, click Update again. A message appears that the update started successfully.\n5. Wait while the hosts update. The update process for each host is complete when the Status of the host returns to Normal and the new version is listed in the Version column.\n\n\n\n\n\n\n\n Determining if the worker node version update is a major, minor, or patch update \n\nThe process to update a worker node is the same for all types of updates. However, you can find information on whether the update is a major, minor, or patch update.\n\nTo determine the type of update that is available, compare your current worker node versions to the latest worker node fix pack version in the [Red Hat OpenShift version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions). Major updates are indicated by the first digit in the version label (4.x.x), minor updates are indicated by the second digit (x.7.x) and patch updates are indicated by the trailing digits (x.x.23_1528_openshift).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers"},{"document_id":"ibmcld_11770-15918-16546","score":10.207992,"text":"\nTo determine the type of update that is available, compare your current worker node versions to the latest worker node fix pack version in the [Red Hat OpenShift version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions). Major updates are indicated by the first digit in the version label (4.x.x), minor updates are indicated by the second digit (x.7.x) and patch updates are indicated by the trailing digits (x.x.23_1528_openshift). For more information on version updates, see [Version information and update actions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers"},{"document_id":"ibmcld_06209-24291-25925","score":10.140726,"text":"\n* If you want to apply a patch update, review the [Kubernetes clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) version change log.\n* Make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\n\n\n\n\n Updating VPC worker nodes in the CLI \n\nComplete the following steps to update your worker nodes by using the CLI.\n\n\n\n1. Complete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatevpc_worker_prereqs).\n2. Optional: Add capacity to your cluster by [resizing the worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workersresize_pool). The pods on the worker node can be rescheduled and continue running on the added worker nodes during the update.\n3. List the worker nodes in your cluster and note the ID and Primary IP of the worker node that you want to update.\n\nibmcloud ks worker ls --cluster CLUSTER\n4. Replace the worker node to update either the patch version or the major.minor version that matches the master version.\n\n\n\n* To update the worker node to the same major.minor version as the master, such as from 1.25 to 1.26, include the --update option.\n\nibmcloud ks worker replace --cluster CLUSTER --worker WORKER-NODE-ID --update\n* To update the worker node to the latest patch version at the same major.minor version, such as from 1.25.8_1530 to 1.25.9_1533, don't include the --update option.\n\nibmcloud ks worker replace --cluster CLUSTER --worker WORKER-NODE-ID\n\n\n\n5. Repeat these steps for each worker node that you must update.\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10642-7855-9754","score":10.059883,"text":"\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.\n\nIn addition, you can create a Kubernetes config map that specifies the maximum number of worker nodes that can be unavailable at a time, such as during an update. Worker nodes are identified by the worker node labels. You can use IBM-provided labels or custom labels that you added to the worker node.\n\nThe Kubernetes config map rules are used for updating worker nodes only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-19911-21816","score":9.872855,"text":"\nAs security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage_portworx_updateportworx_vpc_up).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud ks worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the VPC worker node to the same patch by using the ibmcloud ks worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10642-20176-22071","score":9.814168,"text":"\nFor more information about the latest updates, review the [change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud oc worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the VPC worker node to the same patch by using the ibmcloud oc worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload, such as by [resizing your worker pools](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersresize_pool).\n\nWhat happens to my worker node during an update?\n: Your VPC worker node is replaced by removing the old worker node and provisioning a new worker node that runs at the updated patch or major.minor version. The replacement worker node is created in the same zone, same worker pool, and with the same flavor as the deleted worker node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.329582748}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09767-11562-13372","score":9.236534,"text":"\n* TAG_DATA are comma-separated tags that are formatted as TAG_NAME:TAG_VALUE. You can associate one or more tags to your monitoring agent. For example: role:serviceX,location:us-south. Later on, you can use these tags to identify metrics from the environment where the agent is running.\n* Set sysdig_capture_enabled to false to disable the capture feature. By default is set to true. For more information, see [Working with captures](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-capturescaptures).\n\n\n\n6. Verify that the monitoring agent is created successfully and its status. Run the following command:\n\nkubectl get pods -n ibm-observe\n\nThe deployment is successful when you see one or more sysdig-agent pods. The number of sysdig-agent pods equals the number of worker nodes in your cluster. All pods must be in a Running state.\n\n\n\n\n\n\n\n Step 3: Launch the monitoring UI \n\nTo launch the monitoring UI through the IBM Cloud console, complete the following steps.\n\n\n\n1. [Log in to your IBM Cloud account](https:\/\/cloud.ibm.com\/login).\n\nAfter you log in with your user ID and password, the IBM Cloud Dashboard opens.\n2. From the menu ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/icon_hamburger.svg), select Observability.\n3. Select Monitoring. The list of instances that are available on IBM Cloud is displayed.\n4. Find your instance and click Open dashboard. The web UI opens.\n\n\n\nIt may take some time before you see the cluster entry while the information is initally collected and processed by the monitoring agent.\n\nYou only can monitor one instance per browser. You could have multiple tabs for the same instance.\n\n\n\n\n\n Step 4: Monitor your cluster \n\nIn the Advisor tab, you can monitor and troubleshoot the health, risk, and capacity of hosts and Kubernetes clusters.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-kubernetes_cluster"},{"document_id":"ibmcld_09410-3448-5457","score":8.779176,"text":"\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.\n* [hash] represents the digest (manifest) of the container image. It is a unique SHA-256 hash.\n\n\n\nThe following table outlines the tagging convention adopted and the agent update behavior:\n\n\n\nTable 1. logging agent tags explained\n\n Tag Logging agent auto-update enabled More info \n\n X YES The logging agent auto-updates when a new minor version releases. <br>The logging agent does not update to a new major version, as these updates may require configuration changes. \n X.Y YES The logging agent auto-updates when a new patch version is released. \n X.Y.Z YES The logging agent auto-updates when a new vulnerability fix is released. The agent code does not change, but the included libraries have vulnerability fixes. \n X.Y.Z-<date>.[hash] NO The logging agent never updates. If you use this tag, make sure you are watching for new agent releases that have vulnerability fixes. \n\n\n\nDepending on the tag that you use, you must consider upgrading the logging agent image in your DevOps maintenance plan, to resolve vulnerabilities and apply agent enhancements and agent bug fixes. For example:\n\n\n\n* In a development environment, you can use a tag X and let auto-updates happen as new minor versions are released.\n* In a staging environment, you might consider using a tag X.Y so auto-updates happen when a new patch is released.\n* In a production environment, you can use the tag X.Y.Z so that auto-updates happen when a new vulnerability fix is released.\n* For highly regulated environments, you should use the tag X.Y.Z-<date>.[hash]. Notice that you will have to check periodically for vulnerability fixes, patches, and minor version releases to keep the agent free of issues.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_12826-4200-6048","score":8.742184,"text":"\n[Edit icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ff5860bfede49db3197c4bbba7f7123769bdc068\/icons\/edit-tagging.svg).\n2. Preview how the information in the readme file is displayed to users when they install the Operator.\n3. If you need to make changes, edit the information in the source code and import the updated code file to your private catalog.\n4. Click Save.\n5. Click Next.\n\n\n\n\n\n\n\n Step 6: Validate the software version \n\n\n\n1. From the Validate product tab, select the target cluster and project, and click Next.\n2. Configure your Schematics workspace by entering the name of your workspace, selecting a resource group, selecting a Schematics region, and optionally adding tags. Then, click Next.\n\nYou can accept the default options that are displayed for your workspace name and resource group.\n3. Click Validate.\n\n\n\n\n\n\n\n Step 7: Manage compliance \n\nControls are safeguards that are used to meet security and compliance requirements. Only controls that are supported by Security and Compliance Center, formatted correctly, and validated by Code Risk Analysis and Security and Compliance Center scans appear in the catalog. For more information, see [Formatting controls in your readme file](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-sell-format-controls).\n\n\n\n Manage compliance controls \n\nYou can review the controls that were added from your readme file and add additional controls.\n\n\n\n1. Click Add controls.\n2. Choose a profile.\n3. Select the controls that you want to add to your version.\n4. Click Add.\n\n\n\n\n\n\n\n Run Code Risk Analyzer scan \n\nScan your source code with Code Risk Analyzer to identify any security vulnerabilities that you need to assess.\n\n\n\n1. Click Run scan.\n2. Wait for the scan to finish.\n\n\n\n\n\n\n\n Add Security and Compliance Center scan \n\nAdd the scans that you previously ran in Security and Compliance Center.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-operator-onboard"},{"document_id":"ibmcld_09275-13854-15898","score":8.681531,"text":"\nTags are case-sensitive, and the maximum length of a tag is 128 characters.\n\n\n\n* The characters that are permitted to name tags are A-Z, 0-9, spaces, underscore, hyphen, period, and colon.\n* Colons turn the tag into a string where you can isolate two logical parts, like a key:value pair. You can't use a colon in a tag without creating this pairing.\n* A comma separates tags and can't be used within the tag name itself.\n\n\n\nIf you add PII information in the name, you might be disclosing sensitive data to others in the same account.\n\nWhen you define your tags, do not add sensitive information in the tag name.\n\nTags are visible to all members of an account.\n\nTo control tag visibility, circulate tagging guidelines, and let users know that tags are visible account-wide.\n\n\n\n\n\n\n\n Define the log ingestion strategy \n\nFor non-IBM Cloud enabled services, you must decide the method to collect and forward logs from a log source that you want to monitor to a logging instance.\n\nIn IBM Log Analysis, you can collect and forward data to a logging instance by using any of the following methods:\n\n\n\n* logging agent: Logging agent that automatically collects and forwards logs to 1 logging instance in your account.\n* Syslog: Logging daemon that collects information across multiple devices and system-services, and forwards logs to 1 logging instance in your account.\n* REST API: API that you can use to send log data and custom metadata to 1 logging instance in your account.\n* Code libraries: Libraries that you can use to code ingestion of logs from your apps and services to 1 logging instance. logging offer libraries for Node.JS, Python, Rails, Ruby, Go, iOS, Java, and PHP.\n\n\n\nFor any method that you adopt, you have the flexibility to choose the logging instance where you want to send data per log source. Decide how many instances you might need to collect data from all your log sources based on who can see the data and the type of data that is collected. Avoid sending data to a logging instance that has the platform logs flag enabled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoption"},{"document_id":"ibmcld_09692-2563-4331","score":8.403978,"text":"\n* Check public endpoints are enabled if you plan to install image-analyzer, host-analyzer, and benchmark runner. For example, to deploy these components in a cluster in your Virtual Private Cloud (VPC), check that a public gateway is attached to the subnet configured for the cluster.\n\n\n\n\n\n Deploying an agent by using a script \n\nIn order to use this script, you must have a minimum of Viewer and Manager IAM permissions assigned for the Kubernetes cluster.\n\nTo deploy the agent, run the following command:\n\ncurl -sL https:\/\/ibm.biz\/install-sysdig-k8s-agent | bash -s -- -a ACCESS_KEY -c COLLECTOR_ENDPOINT -t TAG_DATA -ac 'sysdig_capture_enabled: false' --nodeanalyzer --analysismanager https:\/\/<COLLECTOR ENDPOINT>\/internal\/scanning\/scanning-analysis-collector --collector_port 6443 --api_endpoint <API-ENDPOINT> [-as] [-af]\n\nWhere\n\n\n\n* ACCESS_KEY is the ingestion key for the instance.\n* COLLECTOR_ENDPOINT is the public or private ingestion URL for the region where the instance is available. To get an endpoint, see [Collector endpoints](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-endpointsendpoints_ingestion).\n* TAG_DATA are comma-separated tags that are formatted as TAG_NAME:TAG_VALUE. You can associate one or more tags to your agent. For example: role:serviceX,location:us-south.\n* Set sysdig_capture_enabled to false to disable the capture feature. By default is set to true. For more information, see [Working with captures](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-capturescaptures).\n* Add --imageanalyzer --analysismanager https:\/\/<COLLECTOR ENDPOINT>\/internal\/scanning\/scanning-analysis-collector to install the image analyzer component. Configure this component when you have images that are hosted in the Container Registry.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-agent_Kube"},{"document_id":"ibmcld_09697-1196-2863","score":8.276588,"text":"\ncurl -sL https:\/\/ibm.biz\/install-sysdig-k8s-agent | bash -s -- -a ACCESS_KEY -c COLLECTOR_ENDPOINT -t TAG_DATA -ac 'sysdig_capture_enabled: false' --nodeanalyzer --analysismanager https:\/\/<COLLECTOR ENDPOINT>\/internal\/scanning\/scanning-analysis-collector --collector_port 6443 --API_ENDPOINT <API-ENDPOINT> --openshift [-as] [-af]\n\nWhere\n\n\n\n* ACCESS_KEY is the ingestion key for the instance.\n* COLLECTOR_ENDPOINT is the public or private ingestion URL for the region where the instance is available. To get an endpoint, see [Collector endpoints](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-endpointsendpoints_ingestion).\n* TAG_DATA are comma-separated tags that are formatted as TAG_NAME:TAG_VALUE. You can associate one or more tags to your agent. For example: role:serviceX,location:us-south.\n* Set sysdig_capture_enabled to false to disable the capture feature. By default is set to true. For more information, see [Working with captures](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-capturescaptures).\n* Add --imageanalyzer --analysismanager https:\/\/<COLLECTOR ENDPOINT>\/internal\/scanning\/scanning-analysis-collector, if you have images that are hosted in the Container Registry, to install the image analyzer component.\n* Add --nodeanalyzer --analysismanager https:\/\/<COLLECTOR ENDPOINT>\/internal\/scanning\/scanning-analysis-collector --API_ENDPOINT <API-ENDPOINT>to install image-analyzer, host-analyzer, and benchmark runner. The API_ENDPOINT is needed by the benchmark runner. The COLLECTOR_ENDPOINT is needed by the image analyzer.\n* Add the option that defines the type of agent that you want to deploy:\n\n\n\n* -as to deploy a slim agent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-agent_openshift"},{"document_id":"ibmcld_05558-27581-29239","score":8.212099,"text":"\nIf your cluster does not have any existing tags, you don't have an Edit tags pencil icon. Instead, use the [resource list](https:\/\/cloud.ibm.com\/docs\/account?topic=account-tag) or CLI.\n4. Enter the tag that you want to add to your cluster. To assign a key-value pair, use a colon such as costctr:1234.\n\n\n\n\n\n\n\n Adding tags to clusters with the CLI \n\n\n\n1. Log in to the [IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/cli\/reference\/ibmcloud?topic=cli-ibmcloud_cliibmcloud_login).\n\nibmcloud login [--sso]\n2. [Tag your cluster](https:\/\/cloud.ibm.com\/docs\/cli\/reference\/ibmcloud?topic=cli-ibmcloud_commands_resourceibmcloud_resource_tag_attach). Replace the --resource-name with the name of your cluster. To list available clusters, run ibmcloud ks cluster ls. If you want to check your existing tags so as not to duplicate any, run ibmcloud resource tags.\n\nibmcloud resource tag-attach --resource-name <cluster_name> --tag-names <tag1,tag2>\n\nIf you have more than one resource of the same name in your IBM Cloud account, the error message lists the resource CRNs and details, and instructs you to try again with the --resource-idoption.\n\n\n\n\n\n\n\n\n\n Adding labels to existing worker pools \n\nYou can assign a worker pool a label when you [create the worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workersadd_pool), or later by following these steps. After a worker pool is labeled, all existing and subsequent worker nodes get this label. You might use labels to deploy specific workloads only to worker nodes in the worker pool, such as [edge nodes for load balancer network traffic](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-edge).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workers"},{"document_id":"ibmcld_03970-6841-9069","score":8.197732,"text":"\nIf you import a bulk data transfer of nodes and do not also import identities, you will have to perform the separate step of associating identities with the nodes. There are a few ways to procure an identity that can operate a node. For more information about, see [Gathering certificates or credentials](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-import-nodesibp-console-import-start-here). Regardless of the process used to acquire the identity, after the bulk import has been completed you will need to click on each imported node. For peers and ordering nodes, a box on the left of the screen will say Identity not associated with (peer or ordering node), depending on the node in question. After clicking on this box, you will be able to associate the relevant identity by selecting it from your Wallet. Note that this process is distinctly different than the process for importing individual nodes, where you will be asked to associate an identity as part of the import process.\n\nYou will also need to associate an admin identity for the CA. This process is similar to the peer and ordering node process except that after you click on the imported CA you will see a separate screen asking you to associate an identity rather than a box on the left.\n\nFor cases where bulk data transfers are impractical or inadvisable, you can follow the steps below to export and import components and identities one at a time.\n\n\n\n\n\n Gathering certificates or credentials \n\nBecause identities contain private keys, be careful when exporting them to ensure they are handled securely. If a private key is compromised, it can be used to perform malicious actions.\n\nEach IBM Blockchain Platform component is deployed with the signing certificate of an administrator inside. When actions requiring the permission level of an admin are performed against the component, the signing certificate of the entity attempting the action is checked against the signing certificate inside the node. If they don't match, the action is denied. In this way, these certificates, which are also known as \"keys\", allow the administrator to operate their components.\n\nIf you intend to operate an imported node, you have two options:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-import-nodes"},{"document_id":"ibmcld_13218-12376-13510","score":8.142268,"text":"\nFor more information, see [Configure VLAN Tagging on a Distributed Port Group or Distributed Port](https:\/\/docs.vmware.com\/en\/VMware-vSphere\/7.0\/com.vmware.vsphere.networking.doc\/GUID-D5960C77-0D19-4669-A00C-B05D58A422F8.html)\n\n\n\n\n\n\n\n Step 6: Add edge transport nodes and create an edge cluster \n\nEdge nodes are grouped in one or several clusters, representing a pool of capacity.\n\nFollow the recommended order of procedures to install edge transport nodes and form an edge cluster for your logical routers.\n\n\n\n1. Install NSX Edges. When configuring the host TEP IPs, configure each host individually by using the [previously provisioned TEP IPs](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-nsx-t-hostsvpc-bm-vmware-nsx-t-vlannics) of the related IBM Cloud Bare Metal Servers for Virtual Private Cloud VLAN interface for TEP. For more information, see [Install an NSX Edge on ESXi Using the vSphere GUI](https:\/\/docs.vmware.com\/en\/VMware-NSX-T-Data-Center\/3.1\/installation\/GUID-AECC66D0-C968-4EF2-9CAD-7772B0245BF6.htmlGUID-AECC66D0-C968-4EF2-9CAD-7772B0245BF6).\n2. Create an NSX Edge cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-nsx-t-deploy"},{"document_id":"ibmcld_09461-6391-8076","score":8.066874,"text":"\n(Optional) Configure the logging agent to tag your hosts. Run the following command:\n\nsudo logging-agent -t TAG1,TAG2\n\nTags must be separated by commas and without any spaces between the comma and tag name.\n7. Update the logging agent with your changes. Run the following command:\n\nsudo update-rc.d logging-agent defaults\n8. Start the logging agent. Run the following command:\n\nsudo \/etc\/init.d\/logging-agent start\n\n\n\n\n\n Troubleshooting \n\nYou can use the \/var\/log\/logdna-agent.log log to determine if there are any issues with your logdna-agent installation.\n\n\n\n\n\n\n\n Step 4: Launch the logging Web UI \n\nTo launch the IBM Log Analysis dashboard from the IBM Cloud UI, complete the following steps:\n\n\n\n1. Log in to your IBM Cloud account.\n\nClick [IBM Cloud dashboard](https:\/\/cloud.ibm.com\/login) to launch the IBM Cloud dashboard.\n\nAfter you log in with your user ID and password, the IBM Cloud Dashboard opens.\n2. In the navigation menu, select Observability.\n3. Click Logging.\n\nThe list of IBM Log Analysis instances that are available on IBM Cloud is displayed.\n4. Select one instance. Then, click Open dashboard.\n\nThe logging Web UI opens and displays your cluster logs.\n\n\n\n\n\n\n\n Step 5: View your logs \n\nFrom the logging Web UI, you can view your logs as they pass through the system. You view logs by using log tailing.\n\nWith the Free service plan, you can only tail your latest logs.\n\nFor more information, see [Viewing logs](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-view_logsview_logs).\n\n\n\n\n\n Next steps \n\nThe following additional features are available:\n\n\n\n* [Filtering logs](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-view_logsview_logs_step5)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-ubuntu"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.414429925,"ndcg_cut_10":0.414429925}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06160-11142-12906","score":13.948272,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-11475-13230","score":13.598027,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_06160-12611-14167","score":12.672607,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\nkubectl describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) . Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.\n\nkubectl get mutatingwebhookconfigurations\n\nkubectl get validatingwebhookconfigurations\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_05713-581893-583377","score":12.620241,"text":"\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10534-545406-546780","score":12.506453,"text":"\n* [If all worker nodes in a single zone, subnet, or VLAN are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-zone)\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-bm_machine_idbm_machine_id)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_06160-10037-11653","score":12.264136,"text":"\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-12943-14509","score":12.233718,"text":"\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\noc describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) and the [Openshift Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug-tool). Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10596-9883-11854","score":12.18011,"text":"\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_14506-1553-3503","score":12.03445,"text":"\nThe primary node is responsible for queries and log ingestion. The primary node web UI is the single pane of glass for that VMware Aria Operations for Logs Cluster. All queries against data are directed against the primary, which in turn distributes the workload to the workers.\n* Worker Node - three nodes minimum are required to form a cluster with the ability to add more workers for scale-out. A worker node ingests logs and stores logs locally.\n* Integrated Load Balancer - provides high availability by using proprietary load-balancing configuration (no external load balancer required).\n* VMware Aria Operations for Logs Forwarder - deployed to receive logs from the NSX overlay components. Additionally, it can be used by a client if they want to send logs from compute VMs. The VMware Aria Operations for Logs Forwarder is a single VMware Aria Operations for Logs primary node that is used as a remote syslog aggregator to forward alerts to the VMware Aria Operations for Logs cluster. As the VXLAN-backed addresses are outside of the BYOIP address space, NAT rules must be implemented on the NSX ESG.\n\n\n\nThe following sizes are available and the appropriate one is selected:\n\n\n\n* Small \u2013 2,000 events per second\n* Medium \u2013 5,000 events per second\n* Large \u2013 15,000 events per second\n\n\n\nZoom\n\n![VMware Aria Operations for Logs components diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/opsmgmt-vrlicomponents.svg)\n\nFigure 2. VMware Aria Operations for Logs components\n\nVMware Aria Operations for Logs collects logs to provide monitoring information about the environment from a central location.\n\nVMware Aria Operations for Logs collects log events from the following virtual infrastructure and cloud management components (logging clients):\n\n\n\n* vCenter\n* ESXi hosts\n* NSX Manager\n* NSX Controllers\n* NSX Edge services gateways\n* NSX distributed logical router instances","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-opsmgmt-vrli"},{"document_id":"ibmcld_13144-34858-36660","score":11.91797,"text":"\n* stdout and stderr are automatically collected and forwarded from all containers. Log data includes application logs and worker logs.\n* By default, the Log Analysis agent pod that runs on a worker collects logs from all namespaces on that node.\n\n\n\nAfter the agent is configured logs from this cluster will be visible in the Log Analysis web UI covered in the next section. If after a period of time you cannot see logs, check the agent logs.\n\nTo check the logs that are generated by a Log Analysis agent, run the following command:\n\noc logs logdna-agent-<ID> -n ibm-observe\n\nWhere ID is the ID for a Log Analysis agent pod.\n\nFor example,\n\noc logs logdna-agent-mdgdz -n ibm-observe\n\n\n\n\n\n Launch the Log Analysis webUI \n\nLaunch the web UI within the context of a Log Analysis instance, from the IBM Cloud UI.\n\n\n\n1. Navigate to [Red Hat OpenShift on IBM Cloud clusters](https:\/\/cloud.ibm.com\/kubernetes\/clusters?platformType=openshift)\n2. Click on your cluster and verify the Overview tab on the left is selected\n3. Next to Logging, click the Launch button.\n\n\n\nThe Log Analysis UI should open in a new tab.\n\n\n\n\n\n Create a custom view \n\nIn Log Analysis, you can configure custom views to monitor a subset of data. You can also attach an alert to a view to be notified of the presence or absence of log lines.\n\nIn the Log Analysis web UI notice the log entries are displayed with a predefined format. You can modify in the User Preferences section how the information in each log line is displayed. You can also filter logs and modify search settings, then bookmark the result as a view. You can attach and detach one or more alerts to a view. You can define a custom format for how your lines are shown in the view. You can expand a log line and see the data parsed.\n\n\n\n\n\n Simulate Load on the Application","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-openshift-microservices"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10394-7-1848","score":16.854633,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_06160-10037-11653","score":16.484016,"text":"\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-9883-11854","score":16.108688,"text":"\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10534-545406-546780","score":16.021505,"text":"\n* [If all worker nodes in a single zone, subnet, or VLAN are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-zone)\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-bm_machine_idbm_machine_id)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-sitemap"},{"document_id":"ibmcld_06160-11142-12906","score":15.6791115,"text":"\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-11475-13230","score":15.596386,"text":"\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_worker_nodes), [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_05713-581893-583377","score":15.539609,"text":"\n* [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_sitemap"},{"document_id":"ibmcld_10596-5350-7330","score":15.40306,"text":"\nIf the previous steps do not solve the issue, [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_05819-4109-5731","score":15.150434,"text":"\nIn the Summary pane, review your order summary and then click Create.\n\n\n\nThe worker node can take a few minutes to provision, but you can see the progress in the Worker nodes tab. When the status reaches Ready, you can start working with your cluster by [deploying your first app](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-starteddeploy-app)!\n\n\n\n\n\n Creating classic clusters in the IBM Cloud Kubernetes Service CLI \n\nReview the sample commands for creating classic clusters in the CLI. For more detailed steps and information about creating clusters, see [Creating classic clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classic&interface=cli). For information about planning your cluster set up, see [Preparing to create clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusters&interface=cli).\n\nCreate a classic cluster on a shared virtual machine.\n\nibmcloud ks cluster create classic --name my_cluster --zone dal10 --flavor b3c.4x16 --hardware shared --workers 3 --public-vlan <public_VLAN_ID> --private-vlan <private_VLAN_ID>\n\nCreate a classic cluster with bare metal architecture.\n\nibmcloud ks cluster create classic --name my_cluster --zone dal10 --flavor mb2c.4x32 --hardware dedicated --workers 3 --public-vlan <public_VLAN_ID> --private-vlan <private_VLAN_ID>\n\nCreate a classic cluster that uses private VLANs and the private cloud service endpoint only.\n\nibmcloud ks cluster create classic --name my_cluster --zone dal10 --flavor b3c.4x16 --hardware shared --workers 3 --private-vlan <private_VLAN_ID> --private-only --private-service-endpoint","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-started"},{"document_id":"ibmcld_10197-2810-3810","score":15.148972,"text":"\nIf the details include an error message, review the list of [common error messages for worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-common_worker_nodes_issues) to learn how to resolve the problem.\n\nibmcloud oc worker get --cluster <cluster_name_or_id> --worker <worker_node_id>\n\n\n\n\n\n Step 4: Review the infrastructure provider for the worker node \n\nReview the infrastructure environment to check for other reasons that might cause the worker node issues.\n\n\n\n1. Check with your networking team to make sure that no recent maintenance, such as firewall or subnet updates, might impact the worker node connections.\n2. Review [IBM Cloud](https:\/\/cloud.ibm.com\/status\/) for Red Hat OpenShift on IBM Cloud and the underlying infrastructure provider, such as Virtual Servers for classic, VPC related components, or Satellite.\n3. If you have access to the underlying infrastructure, such as classic Virtual Servers, review the details of the corresponding machines for the worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_worker_nodes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06160-10037-11653","score":14.883419,"text":"\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) and include the worker node information you gathered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-critical-notready"},{"document_id":"ibmcld_10596-9883-11854","score":14.367282,"text":"\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ts-critical-notready"},{"document_id":"ibmcld_10444-3882-5785","score":14.20132,"text":"\nAfter you create a worker pool, you might notice that the worker node flavor has .encrypted in the name, such as b3c.4x16.encrypted.\n\n\n\n\n\n How do I manage my worker nodes? \n\nWorker nodes in classic clusters are provisioned into your IBM Cloud account. You can manage your worker nodes by using Red Hat OpenShift on IBM Cloud, but you can also use the [classic infrastructure dashboard](https:\/\/cloud.ibm.com\/classic\/) in the IBM Cloud console to work with your worker node directly.\n\nUnlike classic clusters, the worker nodes of your VPC cluster are not listed in the [VPC infrastructure dashboard](https:\/\/cloud.ibm.com\/vpc\/overview). Instead, you manage your worker nodes with Red Hat OpenShift on IBM Cloud only. However, your worker nodes might be connected to other VPC infrastructure resources, such as VPC subnets or VPC Block Storage. These resources are in the VPC infrastructure dashboard and can be managed separately from there.\n\n\n\n\n\n What limitations do I need to be aware of? \n\nKubernetes limits the maximum number of worker nodes that you can have in a cluster. Review [worker node and pod quotas](https:\/\/kubernetes.io\/docs\/setup\/best-practices\/cluster-large\/) for more information.\n\n[Reserved capacity and reserved instances](https:\/\/cloud.ibm.com\/docs\/virtual-servers?topic=virtual-servers-provisioning-reserved-capacity-and-instances) are not supported.\n\nRed Hat OpenShift on IBM Cloud also sets compute resource reserves that limit available compute resources on each worker node. For more information, see [worker node resource reserves](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesresource_limit_node).\n\nWant to be sure that you always have enough worker nodes to cover your workload? Try out [the cluster autoscaler](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-scaling-classic-vpc).\n\n\n\n\n\n Why do my worker nodes have the master role?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodes"},{"document_id":"ibmcld_10510-17837-19983","score":13.955024,"text":"\nWorker nodes carry the deployments and services that make up your app. When you host workloads in the public cloud, you want to ensure that your app is protected from being accessed, changed, or monitored by an unauthorized user or software.\n\n\n\n Who owns the worker node and am I responsible to secure it? \n\nThe ownership of a worker node depends on the type of cluster that you create and the infrastructure provider that you choose.\n\n\n\n* Classic clusters: Worker nodes are provisioned in to your IBM Cloud account. The worker nodes are dedicated to you and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n* VPC clusters: Worker nodes are provisioned in to an IBM Cloud account that is owned by IBM to enable monitoring of malicious activities and apply security updates. You can't access your worker nodes by using the VPC dashboard. However, you can manage your worker nodes by using the IBM Cloud Kubernetes Service console, CLI, or API. The virtual machines that make up your worker nodes are dedicated to you and you are responsible to request timely updates so that your worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n\n\n\nFor more information, see [Your responsibilities by using Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iks).\n\nUse the ibmcloud oc worker update[command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_update) regularly (such as monthly) to deploy updates and security patches to the operating system and to update the Red Hat OpenShift version that your worker nodes run. When updates are available, you are notified when you view information about the master and worker nodes in the IBM Cloud console or CLI, such as with the ibmcloud oc clusters ls or ibmcloud oc workers ls --cluster <cluster_name> commands. Worker node updates are provided by IBM as a full worker node image that includes the latest security patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_06079-10297-12436","score":13.896362,"text":"\nWorker node With IBM Cloud Kubernetes Service, the virtual machines that your cluster manages are instances that are called worker nodes. These worker nodes virtual machines and all the worker node components are dedicated to you only and are not shared with other IBM customers. However, the underlying hardware is shared with other IBM customers. For more information, see [Virtual machines](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesvm). You manage the worker nodes through the automation tools that are provided by IBM Cloud Kubernetes Service, such as the API, CLI, or console. Unlike classic clusters, you don't see VPC compute worker nodes in your infrastructure portal or separate infrastructure bill, but instead manage all maintenance and billing activity for the worker nodes from IBM Cloud Kubernetes Service. Worker nodes include the same [components](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-archworker-components) as described in the Classic architecture. Community Kubernetes worker nodes run on Ubuntu 18.04 x86_64, 16.04 x86_64 (deprecated). \n Cluster networking Your worker nodes are created in a VPC subnet in the zone that you specify. By default, the public and private cloud service endpoints for your cluster are enabled. Communication between the master and worker nodes is over the private network. Authenticated external users can communicate with the master over the public network, such as to run kubectl commands. You can optionally set up your cluster to communicate with on-prem services by setting up a VPC VPN on the private network. \n App networking You can create a Kubernetes LoadBalancer service for your apps in the cluster, which automatically provisions a VPC load balancer in your VPC outside the cluster. The load balancer is multizonal and routes requests for your app through the private NodePorts that are automatically opened on your worker nodes. For more information, see [Exposing apps with VPC load balancers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-lbaas). Calico is used as the cluster networking policy fabric.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch"},{"document_id":"ibmcld_10444-5383-7233","score":13.777792,"text":"\nFor more information, see [worker node resource reserves](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesresource_limit_node).\n\nWant to be sure that you always have enough worker nodes to cover your workload? Try out [the cluster autoscaler](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-scaling-classic-vpc).\n\n\n\n\n\n Why do my worker nodes have the master role? \n\nWhen you run oc get nodes or oc describe node <worker_node>, you might see that the worker nodes have master,worker roles. In OpenShift Container Platform clusters, operators use the master role as a nodeSelector so that OCP can deploy default components that are controlled by operators, such as the internal registry, in your cluster. No master node processes, such as the API server or Kubernetes scheduler, run on your worker nodes. For more information about master and worker node components, see [Red Hat OpenShift architecture](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architectureservice-architecture-4).\n\n\n\n\n\n How can I check the operating system that my worker nodes run? \n\nWhen you create a worker pool, you choose the flavor, which describes the operating system along with the compute resources of the worker nodes. Supported operating systems are RHEL 7.\n\nYou can also log in to your cluster to check the operating system of the worker nodes.\n\n\n\n1. [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n2. List your worker nodes.\n\noc get nodes\n3. Describe your worker node and check for the operating system label that IBM applies, or the OS Image and Operating System fields in the System Info section.\n\noc describe node <node>\n\nExample output\n\nNAME: 10.xxx.xx.xxx\nRoles: <none>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodes"},{"document_id":"ibmcld_10394-7-1848","score":13.742456,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_10642-26723-28394","score":13.698629,"text":"\nConsider storing your data on persistent storage outside of the worker node.\n* Make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms).\n\n\n\nTo update flavors:\n\n\n\n1. List available worker nodes and note their private IP address.\n\n1. List available worker pools in your cluster.\n {: pre}\nibmcloud oc worker-pool ls --cluster CLUSTER\n\n2. List the worker nodes in the worker pool. Note the ID and Private IP.\n {: pre}\nibmcloud oc worker ls --cluster CLUSTER --worker-pool WORKER-POOL\n\n3. Get the details for a worker node. In the output, note the zone and either the private and public VLAN ID for classic clusters or the subnet ID for VPC clusters.\n {: pre}\nibmcloud oc worker get --cluster CLUSTER --worker WORKER-ID\n\n2. List available flavors in the zone.\n\nibmcloud oc flavors --zone <zone>\n3. Create a worker node with the new machine type.\n\n\n\n1. Create a worker pool with the number of worker nodes that you want to replace.\n\n\n\n* Classic clusters:\n\nibmcloud oc worker-pool create classic --name WORKER-POOL --cluster CLUSTER --flavor FLAVOR --size-per-zone NUMBER-OF-WORKERS-PER-ZONE\n* VPC Generation 2 clusters:\n\nibmcloud oc worker-pool create vpc-gen2 --name NAME --cluster CLUSTER --flavor FLAVOR --size-per-zone NUMBER-OF-WORKERS-PER-ZONE --label LABEL\n\n\n\n2. Verify that the worker pool is created.\n\nibmcloud oc worker-pool ls --cluster CLUSTER\n3. Add the zone to your worker pool that you retrieved earlier. When you add a zone, the worker nodes that are defined in your worker pool are provisioned in the zone and considered for future workload scheduling.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06063-22816-25005","score":13.615517,"text":"\n: If you create a standard classic cluster, you can choose to provision your worker nodes on bare metal physical servers (instead of virtual server instances). With bare metal machines, you have additional control over the compute host, such as the memory or CPU. This setup eliminates the virtual machine hypervisor that allocates physical resources to virtual machines that run on the host. Instead, all a bare metal machine's resources are dedicated exclusively to the worker, so you don't need to worry about \"noisy neighbors\" sharing resources or slowing down performance. Bare metal servers are dedicated to you, with all its resources available for cluster usage.\n\nEncrypted disks\n: By default, every worker node is provisioned with two local SSD, AES 256-bit encrypted data partitions. The first partition contains the kernel image that is used to boot the worker node and is not encrypted. The second partition holds the container file system and is unlocked by using LUKS encryption keys. Each worker node in a cluster has its own unique LUKS encryption key, managed by IBM Cloud Kubernetes Service. When you create a cluster or add a worker node to an existing cluster, the keys are pulled securely and then discarded after the encrypted disk is unlocked. Encryption can impact disk I\/O performance. For workloads that require high-performance disk I\/O, test a cluster with encryption both enabled and disabled to help you decide whether to turn off encryption.\n\nExpert AppArmor policies\n: Every worker node is set up with security and access policies that are enforced by [AppArmor](https:\/\/wiki.ubuntu.com\/AppArmor) profiles that are loaded into the worker node during bootstrapping. AppArmor profiles can't be changed by the user or owner of the machine.\n\nSSH disabled\n: By default, SSH access is disabled on the worker node to protect your cluster from malicious attacks. When SSH access is disabled, access to the cluster is forced via the Kubernetes API server. The Kubernetes API server requires every request to be checked against the policies that are set in the authentication, authorization, and admission control module before the request is executed in the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_06010-6040-7693","score":13.608574,"text":"\nTo update the version of the operating system that a worker node uses, such as from Ubuntu 16 to 18, you can [replace the flavor of the worker pool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemachine_type).\n\nYou can also log in to your cluster to check the operating system of the worker nodes.\n\n\n\n1. [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n2. List your worker nodes.\n\nkubectl get nodes\n3. Describe your worker node and check for the operating system label that IBM applies, or the OS Image and Operating System fields in the System Info section.\n\nkubectl describe node <node>\n\nExample output\n\nNAME: 10.xxx.xx.xxx\nRoles: <none>\nLabels: arch=amd64\n...\nibm-cloud.kubernetes.io\/os=UBUNTU_18_64\n...\nkubernetes.io\/arch=amd64\nkubernetes.io\/hostname=10.189.33.198\nkubernetes.io\/os=linux\n...\nSystem Info:\nOS Image: Ubuntu 18.04.5 LTS\nOperating System: linux\nArchitecture: amd64\n...\n\n\n\n\n\n\n\n\n\n Virtual machines \n\nWith VMs, you get greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price. You can use VMs for most general-purpose use cases such as testing and development environments, staging, and prod environments, microservices, and business apps. However, there is a tradeoff in performance. If you need high-performance computing for data- or RAM-intensive workloads, consider creating classic clusters with [bare metal](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesbm) worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.4,"recall_10":0.6,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2772734274,"ndcg_cut_10":0.3903268291}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10068-154779-156261","score":24.173151,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.38_1542_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift 4.3.38 4.3.40 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.3\/release_notes\/ocp-4-3-release-notes.htmlocp-4-3-40). \n RHEL 7 Packages 3.10.0-1160.2.1.el7 3.10.0-1160.2.2.el7 Updated worker node images with kernel and package updates for [CVE-2020-12351](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-12351) and [CVE-2020-12352](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-12352). \n\n\n\n\n\n\n\n Change log for master fix pack 4.3.38_1544_openshift, released 26 October 2020 \n\nThe following table shows the changes that are in the master fix pack patch update 4.3.38_1544_openshift. Master patch updates are applied automatically.\n\n\n\nChanges since version 4.3.35_1539_openshift\n\n Component Previous Current Description \n\n Cluster health image v1.1.11 v1.1.12 Fixed check for unsupported add-ons. Updated to use Go version 1.15.2. \n Gateway-enabled cluster controller 1082 1105 Updated to use Go version 1.15.2. \n IBM Cloud Block Storage for Classic driver and plug-in 1.17.1 1.17.2 Updated to use Go version 1.13.15. \n IBM Cloud Controller Manager v1.17.12-1 v1.17.13-1 Updated to support the Kubernetes 1.17.13 release. \n IBM Cloud RBAC Operator 4b47693 31c794a Updated to use Go version 1.15.2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-changelog_archive"},{"document_id":"ibmcld_10405-70642-72221","score":23.49571,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.9.33_1539_openshift\n\n Component Previous Current Description \n\n RHEL 7 Packages N\/A N\/A Worker node package updates for [CVE-2022-24903](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2022-24903). \n Red Hat OpenShift on IBM Cloud. 4.9.33 4.9.36 For more information, see the [change log](https:\/\/docs.openshift.com\/container-platform\/4.9\/release_notes\/ocp-4-9-release-notes.htmlocp-4-9-36). \n\n\n\n\n\n\n\n Change log for master fix pack 4.9.33_1540_openshift, released 3 June 2022 \n\nThe following table shows the changes that are in the master fix pack 4.9.33_1540_openshift. Master patch updates are applied automatically.\n\n\n\nChanges since version 4.9.28_1536_openshift\n\n Component Previous Current Description \n\n Cluster health image v1.3.6 v1.3.7 Updated Go to version 1.17.10 and also updated the dependencies. Update registry base image version to 104 \n IBM Calico extension 954 980 Updated to use Go version 1.17.10. Updated minimal universal base image (UBI) to version 8.5. \n IBM Cloud Block Storage driver and plug-in v2.2.2 v2.2.4 Updated universal base image (UBI) to version 8.6-751 to resolve CVEs. \n IBM Cloud Controller Manager v1.22.8-7 v1.22.10-1 Updated to support the Kubernetes 1.22.10 release. \n IBM Cloud File Storage for Classic plug-in and monitor 408 410 Updated universal base image (UBI) to version 8.6-751 to resolve CVEs. \n IBM Cloud RBAC Operator 8c8c82b 8c96932 Updated Go to version 1.18.1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_49"},{"document_id":"ibmcld_10399-36221-37434","score":23.461704,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.11.13_1533_openshift\n\n Component Previous Current Description \n\n RHEL 8 Packages N\/A N\/A Worker node package updates for [CVE-2022-42898](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2022-42898). \n Red Hat OpenShift on IBM Cloud. 4.11.13 4.11.17 For more information, see the [change log](https:\/\/docs.openshift.com\/container-platform\/4.11\/release_notes\/ocp-4-11-release-notes.htmlocp-4-11-17). \n HAProxy c619f4 508bf6 [CVE-2016-3709](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2016-3709), [CVE-2022-42898](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2022-42898), [CVE-2022-1304](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2022-1304). \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.11.13_1533_openshift, released 21 November 2022 \n\nThe following table shows the changes that are in the worker node fix pack 4.11.13_1533_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.11.12_1530_openshift\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_411"},{"document_id":"ibmcld_10068-115418-116493","score":23.459267,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.4.23_1520_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift 4.4.23 4.4.26 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.3\/release_notes\/ocp-4-3-release-notes.htmlocp-4-4-26). \n RHEL 7 Packages 3.10.0-1127.19.1.el7 3.10.0-1160.2.1.el7 Updated worker node image with kernel and package updates for: [CVE-2019-12450](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-12450), [CVE-2019-14822](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-14822), [CVE-2020-12243](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-12243), [CVE-2019-14866](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-14866), [CVE-2017-12652](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2017-12652), [CVE-2017-18551](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2017-18551), [CVE-2018-20836](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2018-20836), [CVE-2019-9454](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2019-9454), [CVE","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-changelog_archive"},{"document_id":"ibmcld_10068-170960-171999","score":23.450787,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.29_1533_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift 4.3.29 4.3.31 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.3\/release_notes\/ocp-4-3-release-notes.htmlocp-4-3-31). The update resolves CVE-2020-8558 (see the [IBM security bulletin](https:\/\/www.ibm.com\/support\/pages\/node\/6319989)). \n RHEL 7 packages N\/A N\/A Updated worker node images with package updates. \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.3.29_1533_openshift, released 3 August 2020 \n\nThe following table shows the changes that are in the worker node fix pack update 4.3.29_1533_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.29_1532_openshift\n\n Component Previous Current Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-changelog_archive"},{"document_id":"ibmcld_10397-24840-26190","score":23.401918,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 3.11.524_1609_openshift\n\n Component Previous Current Description \n\n RHEL 7 Packages N\/A N\/A Updated worker node image packages for [CVE-2021-42574](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-42574). \n Red Hat OpenShift 3.11.524 3.11.542 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/3.11\/release_notes\/ocp_3_11_release_notes.htmlocp-3-11-542) \n\n\n\n\n\n\n\n Change log for master fix pack 3.11.524_1608_openshift, released 29 October 2021 \n\nThe following table shows the changes that are in the master fix pack patch update 3.11.524_1608_openshift. Master patch updates are applied automatically.\n\n\n\nChanges since version 3.11.521_1604_openshift\n\n Component Previous Current Description \n\n Cluster health image v1.1.25 v1.1.26 Updated universal base image (UBI) to the latest 8.4 version to resolve CVEs: [CVE-2021-36222](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-36222), [CVE-2021-37750](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-37750), [CVE-2021-22922](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-22922), [CVE-2021-22923](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-22923), and [CVE-2021-22924](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-22924).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_311"},{"document_id":"ibmcld_10642-10731-12253","score":23.397472,"text":"\n* Make any changes that are marked with Update after master in the [Red Hat OpenShift version preparation guide](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* If you want to apply a patch update, review the [Red Hat OpenShift version change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions).\n* Consider [adding more worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workers) so that your cluster has enough capacity to rescheduling your workloads during the update.\n* Make sure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-userschecking-perms).\n\n\n\n\n\n\n\n Updating classic worker nodes in the CLI with a configmap \n\nSet up a ConfigMap to perform a rolling update of your classic worker nodes.\n\n\n\n1. Complete the [prerequisite steps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker-up-prereqs).\n2. List available worker nodes and note their private IP address.\n\nibmcloud oc worker ls --cluster CLUSTER\n3. View the labels of a worker node. You can find the worker node labels in the Labels section of your CLI output. Every label consists of a NodeSelectorKey and a NodeSelectorValue.\n\noc describe node PRIVATE-WORKER-IP\n\nExample output\n\nNAME: 10.184.58.3\nRoles: <none>\nLabels: arch=amd64\nbeta.kubernetes.io\/arch=amd64\nbeta.kubernetes.io\/os=linux\nfailure-domain.beta.kubernetes.io\/region=us-south\nfailure-domain.beta.kubernetes.io\/zone=dal12","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_10068-175175-175909","score":23.375685,"text":"\nRed Hat OpenShift 4.3.27 4.3.29 See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.3\/release_notes\/ocp-4-3-release-notes.htmlocp-4-3-29). \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.3.27_1528_openshift, released 6 July 2020 \n\nThe following table shows the changes that are in the worker node fix pack update 4.3.27_1528_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.25_1527_openshift\n\n Component Previous Current Description \n\n Master Proxy 1.8.25-30b675 2.0.15-afe432 See the [HAProxy change logs](https:\/\/www.haproxy.org\/download\/2.0\/src\/CHANGELOG).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-changelog_archive"},{"document_id":"ibmcld_10400-7104-8022","score":23.335873,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.12.15_1542_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift on IBM Cloud. 4.12.15 4.12.16 see [change logs](https:\/\/docs.openshift.com\/container-platform\/4.12\/release_notes\/ocp-4-12-release-notes.htmlocp-4-12-16). \n RHEL 8 Packages 4.18.0-425.19.2.el8_7 4.18.0-477.10.1.el8_8 Worker node kernel & package updates for [CVE-2020-10735](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-10735), [CVE-2021-26341](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-26341), [CVE-2021-28861](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-28861), [CVE-2021-33655](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-33655), [CVE-2021-33656](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-33656), [CVE-2022-1462](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2022-1462), [CVE","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_412"},{"document_id":"ibmcld_10399-7236-8154","score":23.305883,"text":"\nWorker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.11.39_1554_openshift\n\n Component Previous Current Description \n\n Red Hat OpenShift on IBM Cloud. 4.11.39 4.11.40 see [change logs](https:\/\/docs.openshift.com\/container-platform\/4.11\/release_notes\/ocp-4-11-release-notes.htmlocp-4-11-40). \n RHEL 8 Packages 4.18.0-425.19.2.el8_7 4.18.0-477.10.1.el8_8 Worker node kernel & package updates for [CVE-2020-10735](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2020-10735), [CVE-2021-26341](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-26341), [CVE-2021-28861](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-28861), [CVE-2021-33655](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-33655), [CVE-2021-33656](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2021-33656), [CVE-2022-1462](https:\/\/nvd.nist.gov\/vuln\/detail\/CVE-2022-1462), [CVE","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_411"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"be461bfeda2d4826cdb663dcaa7d1ced<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10510-32019-33983","score":18.074148,"text":"\nPrivate services and worker node options\n\n Security feature Description \n\n Limit the number of exposed apps By default, your apps and services that run within the cluster are not reachable over the public internet. You can choose if you want to expose your apps to the public, or if you want your apps and services be reachable on the private network only. When you keep your apps and services private, you can leverage the built-in security features to assure secured communication between worker nodes and pods. To expose services and apps to the public internet, you can use Red Hat OpenShift routes, or leverage the [NLB and Ingress ALB support](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_network_planningopenshift_routers) to securely make your services publicly available. Ensure that only necessary services are exposed, and revisit the list of exposed apps regularly to ensure that they are still valid. \n Limit public internet connectivity with edge nodes Every worker node is configured to accept app pods and associated load balancer or ingress pods. You can label worker nodes as [edge nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-edgeedge) to force load balancer pods to be deployed to these worker nodes only. In addition, you can [taint your worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-edgeedge_workloads) so that app pods can't schedule onto the edge nodes. With edge nodes, you can isolate the networking workload on fewer worker nodes in your cluster and keep other worker nodes in the cluster private. \n\n\n\n\n\n\n\n What if I want to connect my cluster to an on-prem data center? \n\nTo connect your worker nodes and apps to an on-prem data center, you can configure a [VPN IPSec endpoint with a strongSwan service, a Virtual Router Appliance, or with a Fortigate Security Appliance](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpnvpn).\n\n\n\n\n\n Network segmentation and privacy for VPC clusters","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_10568-21131-23284","score":17.26973,"text":"\nInstead of making more clusters, you can add worker pools for different flavors of computing resources available for the app and service components that you want to use. When you develop the app, the resources it uses are in the same zone, or otherwise closely connected in a multizone, so that you can make assumptions about latency, bandwidth, or correlated failures. However, it becomes even more important for you to organize your cluster by using namespaces, resource quotas, and labels.\n\n\n\n\n\n How can I set up my resources within the cluster? \n\n\n\n Consider your worker node capacity \n\nTo get the most out of your worker node's performance, consider the following: - Keep up your core strength: Each machine has a certain number of cores. Depending on your app's workload, set a limit for the number of pods per core, such as 10. - Avoid node overload: Similarly, just because a node can contain more than 100 pods doesn't mean that you want it to. Depending on your app's workload, set a limit for the number of pods per node, such as 40. - Don't tap out your cluster bandwidth**: Keep in mind that network bandwidth on scaling virtual machines is around 1000 Mbps. If you need hundreds of worker nodes in a cluster, split it up into multiple clusters with fewer nodes, or order bare metal nodes. - Sorting out your services: Plan out how many services that you need for your workload before you deploy. Networking and port forwarding rules are put into Iptables. If you anticipate a larger number of services, such as more than 5,000 services, split up the cluster into multiple clusters.\n\n\n\n\n\n Provision different types of machines for a mix of computing resources \n\nEveryone likes choices, right? With Red Hat OpenShift on IBM Cloud, you have [a mix of flavors](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes) that you can deploy: from bare metal for intensive workloads to virtual machines for rapid scaling. Use labels or namespaces to organize deployments to your machines. When you create a deployment, limit it so that your app's pod deploys only on machines with the best mix of resources.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategy"},{"document_id":"ibmcld_10371-4805-6599","score":17.21066,"text":"\nallow-node-port-dnat Allows incoming network load balancer (NLB), Ingress application load balancer (ALB), and NodePort service traffic to the pods that those services are exposing. Note: You don't need to specify the exposed ports because Kubernetes uses destination network address translation (DNAT) to forward the service requests to the correct pods. That forwarding takes place before the host endpoint policies are applied in Iptables. \n allow-sys-mgmt Allows incoming connections for specific IBM Cloud infrastructure systems that are used to manage the worker nodes. \n allow-vrrp Allows VRRP packets, which monitor and move virtual IP addresses between worker nodes. \n\n\n\n\n\n\n\n Installing and configuring the Calico CLI \n\nTo view, manage, and add Calico policies, install and configure the Calico CLI.\n\n\n\n1. Set the context for your cluster to run Calico commands.\n\n\n\n* Red Hat OpenShift version 4.6 and later:\n\n\n\n1. Download the kubeconfig configuration file for your cluster.\n\nibmcloud oc cluster config --cluster <cluster_name_or_ID>\n2. Set the DATASTORE_TYPE environment variable to kubernetes.\n\nexport DATASTORE_TYPE=kubernetes\n\n\n\n\n\n2. If corporate network policies use proxies or firewalls to prevent access from your local system to public endpoints, [allow TCP access for Calico commands](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-firewallfirewall).\n3. Follow the steps to install the calicoctl command line tool.\n\n\n\n* Linux and OS X\n\n\n\n1. [Download the version of the Calico CLI that matches your operating system](https:\/\/github.com\/projectcalico\/calico\/releases). For OS X, you might need to manually allow the downloaded file to be opened and run by navigating to System Preferences > Security & Privacy > General.\n2. Move the file to the \/usr\/local\/bin directory.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-network_policies"},{"document_id":"ibmcld_10116-7-2157","score":17.091682,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith Red Hat OpenShift on IBM Cloud clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_10378-7-2015","score":16.982613,"text":"\nTesting access to apps with NodePorts \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\nMake your containerized app available to internet access by using the public IP address of any worker node in a Red Hat OpenShift cluster and exposing a NodePort. Use this option for testing in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae and for short-term public access.\n\n\n\n About NodePorts \n\nExpose a public port on your worker node and use the public IP address of the worker node to access your service in the cluster publicly from the internet.\n\nWhen you expose your app by creating a Kubernetes service of type NodePort, a NodePort in the range of 30000 - 32767 and an internal cluster IP address is assigned to the service. The NodePort service serves as the external entry point for incoming requests for your app. The assigned NodePort is publicly exposed in the kubeproxy settings of each worker node in the cluster. Every worker node starts listening on the assigned NodePort for incoming requests for the service. To access the service from the internet, you can use the public IP address of any worker node that was assigned during cluster creation and the NodePort in the format <IP_address>:<nodeport>. If you want to access the service on the private network, use the private IP address of any worker node instead of the public IP address.\n\nThe following diagram shows how communication is directed from the internet to an app when a NodePort service is configured.\n\nZoom\n\n![Expose an app in IBM Cloud Kubernetes Service by using NodePort](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/openshift\/images\/nodeport.svg)\n\nFigure 1. Expose an app by using NodePort\n\n\n\n1. A request is sent to your app by using the public IP address of your worker node and the NodePort on the worker node.\n2. The request is automatically forwarded to the NodePort service's internal cluster IP address and port. The internal cluster IP address is accessible inside the cluster only.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-nodeport"},{"document_id":"ibmcld_10527-21976-24090","score":16.973528,"text":"\n: [Master components](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architectureservice-architecture-4-master), including the API server and etcd, have three replicas and are spread across zones for even higher availability. Masters include the same components as described in the Classic cluster architecture for version 4 clusters. The master and all the master components are dedicated only to you, and are not shared with other IBM customers.\n\nWorker node\n: With Red Hat OpenShift on IBM Cloud, the virtual machines that your cluster manages are instances that are called worker nodes. These worker nodes virtual machines and all the worker node components are dedicated to you only and are not shared with other IBM customers. However, the underlying hardware is shared with other IBM customers. For more information, see [Virtual machines](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm). You manage the worker nodes through the automation tools that are provided by Red Hat OpenShift on IBM Cloud, such as the API, CLI, or console. Unlike classic clusters, you don't see VPC compute worker nodes in your infrastructure portal or separate infrastructure bill, but instead manage all maintenance and billing activity for the worker nodes from Red Hat OpenShift on IBM Cloud.\n: Worker nodes include the same [components](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architectureservice-architecture-4-workers) as described in the Classic cluster architecture for version 4 clusters. Red Hat OpenShift on IBM Cloud worker nodes run on the Red Hat Enterprise Linux 7 operating system.\n: When you run oc get nodes, you might notice that the ROLES of your worker nodes are marked as both master,worker. These nodes are worker nodes in IBM Cloud, and don't include the master components that are managed by IBM. Instead, these nodes are marked as master because they run OpenShift Container Platform components that are required to set up and manage default resources within the cluster, such as the OperatorHub and internal registry.\n\nCluster networking","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architecture"},{"document_id":"ibmcld_07986-11524-13676","score":16.968388,"text":"\nVirtual Servers for VPC is an infrastructure-as-a-service (IaaS) offering that gives you access to all of the benefits of VPC, including network isolation, security, and flexibility.\n\nWith Virtual Servers for VPC, you can quickly provision instances with high network performance. When you provision an instance, you select a profile that matches the amount of memory and compute power that you need for the application that you plan to run on the instance. Instances are available on the x86 architecture.\n\n\n\n\n\n Dedicated hosts for VPC (optional) \n\nWith [Dedicated hosts for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-dedicated-hosts-instances), you can carve out a single-tenant compute node, free from users outside of your organization. Within that dedicated space, you can create virtual server instances according to your needs. Additionally, you can create dedicated host groups that contain dedicated hosts for a specific purpose. Because a dedicated host is a single-tenant space, only users within your account that have the required permissions can create instances on the host.\n\nDedicated hosts are highly recommended when you use virtual servers, particularly for any parts of your application that process regulated data and keep it in memory.\n\n\n\n\n\n IBM Cloud Auto Scale for VPC (optional) \n\n[Auto Scale for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-group) is highly recommended if you are using virtual servers. With Auto Scale for VPC, you can improve performance and costs by dynamically creating virtual server instances to meet the demands of your environment. You set scaling policies that define your desired average utilization for metrics like CPU, memory, and network usage. The policies that you define determine when virtual server instances are added or removed from your instance group.\n\n\n\n\n\n\n\n Containers \n\n\n\n Red Hat OpenShift on IBM Cloud \n\nIn addition to Virtual Servers for VPC, you can use [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview) if you want to run containers. {{site.data.content.openshift-service-description}}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-about"},{"document_id":"ibmcld_10154-7-1896","score":16.92166,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_14493-7-1757","score":16.894726,"text":"\nRed Hat OpenShift Bastion node setup \n\nTo enable the deployment, a virtual machine (VM) is provisioned to run the Red Hat\u00ae OpenShift\u00ae installation steps and host an HTTP Server. This VM is known as the bastion node. The bastion node is connected to the Red Hat OpenShift logical switch and the ESG firewall and NAT rules are configured to allow SSH access from the jump-server or remote device.\n\nThe bastion node runs Red Hat\u00ae Enterprise Linux\u00ae, and it is used to host the scripts, files, and tools to provision the bootstrap, control-plane, and compute nodes. After the deployment, it is recommended to keep the bastion node as an administrative node for the cluster.\n\nThe bastion node setup consists of the following steps:\n\n\n\n1. Provision a Red Hat VM.\n2. Register the Red Hat VM.\n3. Install NGINX (HTTP Server).\n4. Generate an SSH private key and add it to the agent.\n\n\n\n\n\n Provisioning a Red Hat VM \n\nProvision a Red Hat VM based on the following specifications. Use the vCenter Server user interface or by using the PowerCLI script that is documented later in this document to provision the VM. Record you NAT address, which is configured in the NSX ESG.\n\n\n\nTable 1. Red Hat VM - provision\n\n VM IP address Gateway Disk (GB) Memory (GB) vCPU NAT address \n\n bastion 192.168.133.8 192.168.133.1 50 2 1 10.208.59.197 \n\n\n\nUse the following table to record your deployment details:\n\n\n\nTable 2. Red Hat VM deployment\n\n Parameter Example Your deployment \n\n vCenter Server IP address \n vCenter Server user \n vCenter Server password \n Logical Switch OpenShift-LS \n vCenter Server instance data store vsanDatastore \n VM name bastion \n ISO file name rhel-8.x-x86_64-dvd.iso \n IP address 192.168.133.8 \n Netmask 255.255.255.0 \n Default gateway 192.168.133.1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-bastion-intro"},{"document_id":"ibmcld_10444-16010-17976","score":16.839085,"text":"\nAfter you create GPU bare metal worker nodes in your Red Hat OpenShift version 4 cluster, [install the Node Feature Discovery and NVIDIA GPU operators for your cluster version](https:\/\/docs.nvidia.com\/datacenter\/cloud-native\/gpu-operator\/getting-started.html).\n\nChoose a flavor, or machine type, with the correct storage configuration to support your workload. Some flavors have a mix of the following disks and storage configurations. For example, some flavors might have a SATA primary disk with a raw SSD secondary disk.\n\n\n\n* SATA: A magnetic spinning disk storage device that is often used for the primary disk of the worker node that stores the OS file system.\n* SSD: A solid-state drive storage device for high-performance data.\n* SAN: For select virtual machines, the storage device is mounted via software area network (SAN).\n* Raw: The storage device is unformatted and the full capacity is available for use.\n* RAID: A storage device with data distributed for redundancy and performance that varies depending on the RAID level. As such, the disk capacity that is available for use varies.\n\n\n\n\n\nAvailable bare metal flavors in Red Hat OpenShift on IBM Cloud.\n\n Name and use case Cores \/ Memory Primary \/ Auxiliary disk Network speed \n\n RAM-intensive bare metal, mb4c.20x64: Maximize the RAM available to your worker nodes. This bare metal includes 2nd Generation Intel\u00ae Xeon\u00ae Scalable Processors with Intel\u00ae C620 Series chip sets for better performance for workloads such as machine learning, AI, and IoT. 20 \/ 64 GB 2 TB HDD \/ 960 GB SSD 10000 Mbps \n RAM-intensive bare metal, mb4c.20x192: Maximize the RAM available to your worker nodes. This bare metal includes 2nd Generation Intel\u00ae Xeon\u00ae Scalable Processors with Intel\u00ae C620 Series chip sets for better performance for workloads such as machine learning, AI, and IoT. 20 \/ 192 GB 2 TB HDD \/ 960 GB SSD 10000 Mbps \n RAM-intensive bare metal, mb4c.20x384: Maximize the RAM available to your worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13498-7-2240","score":10.398936,"text":"\nSQL reference \n\n\n\n Introduction \n\nWith IBM Cloud\u00ae Data Engine, you can analyze and transform open data with SQL. It supports the various types of SELECT statements from the ANSI SQL standard.\n\nThe SELECT statement (or query statement) is used to read object data from IBM Cloud\u00ae Object Storage (COS), process the data, and store it back on Cloud Object Storage eventually.\n\nYou can use Data Engine as a data transformation service, as it always writes the results of a query to a specified location in either Object Storage or Db2 tables. Data Engine provides extended SQL syntax inside a special INTO clause to control how the result data is stored physically. This extended SQL syntax includes control over data location, format, layout, and partitioning.\n\nA query statement can be submitted through Data Engine's web UI or programmatically, either by using the service's REST API, or by using the Python or Node.JS SDK. You can also use IBM Watson\u00ae Studio and the Python SDK to use Data Engine interactively with Jupyter Notebooks. In addition, you can submit SQL queries that use IBM Cloud\u00ae Functions.\n\nIn addition to the ad hoc usage of data in IBM Cloud\u00ae Object Storage, you can also register and manage your data in a catalog as tables, consisting of columns and partitions.\n\nSeveral benefits to cataloging your data exist:\n\n\n\n* It simplifies SQL SELECT statements because the SQL author does not need not know and specify exactly where and how the data is stored.\n* The SQL execution can skip the inference of schema and partitioning because this information is available in the metastore. Thus, cataloging improves your query performance, especially for text-based data formats, such as CSV and JSON, where the schema inference requires a full scan of the data before the actual query execution.\n\n\n\n\n\n\n\n Select \n\nSee the following examples for an outline of the general syntax of an SQL query statement that uses the query clause and the namedQuery clause.\n\n\n\n query \n\n\n\n\n\n namedQuery \n\n\n\n\n\n intoClause \n\nThe query statement supports common table expressions. A common table expression permits defining a result table with a table name that can be specified as a table name in any FROM clause of the fullselect that follows.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13493-7-1679","score":10.299463,"text":"\nRunning a query \n\nWatch the following video to learn more about Data Engine and how you can get started to run a basic query.\n\nIn SQL, the term query is just another way of saying SELECT statement. To run a query:\n\n\n\n1. In the SQL editor field of the Data Engine UI, enter a SELECT statement.\n\n\n\n* After the FROM keyword, specify one or more [unique resource identifiers](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-runningunique) (URIs). Each URI can be thought of as a table. It specifies one or more input objects; each input object can be thought of as a table partition. You must have at least 'Reader' access to the buckets that contain the input objects.\n* If the format of the input objects is CSV, and no special options are required, it is not necessary to specify a STORED AS clause. However, if the format is JSON, ORC, Parquet, or AVRO, after the FROM clause, specify STORED AS JSON, STORED AS ORC, STORED AS PARQUET, or STORED AS AVRO.\n* If text formats, such as JSON and CSV, are compressed with either gzip or bzip2 and have the extensions .gz and .bz, they automatically get recognized as compressed files. However, do not use these kinds of compressed files due to performance reasons.\n* If the format of the input objects is CSV and a delimiter other than the default , (comma) is used, you must specify the delimiter by using the FIELDS TERMINATED BY option of the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause. All single Unicode characters are allowed as delimiters.\n* By default, it is assumed that CSV input objects have a header line that specifies the names of the input columns.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-running"},{"document_id":"ibmcld_16662-0-1981","score":10.222396,"text":"\n\n\n\n\n\n\n  Running SQL queries \n\nSQL is a standardized language for defining and manipulating data in a relational database. You can use the Query workspace interface in IBM\u00ae watsonx.data to run SQL queries and scripts against your data.\n\nThe Query workspace has the following components:\n\n\n\n*  Data objects: To view the engines, catalogs, schemas, tables, and columns.\n*  Engine: To select an engine and view the associated catalogs.\n*  Saved queries: To view the saved queries.\n*  Worksheet: To write SQL queries.\n\n\n\nThe Query workspace page provides basic options to undo, redo, cut, copy, paste, save, clear, and delete.\n\nFormat selection option is enabled only when an SQL statement in a query worksheet is selected. The Format worksheet option formats all the content in the worksheet. Comment selection is used to explain sections of SQL statements.\n\nThe Delete option is enabled only after an SQL query is saved.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select SQL. The Query workspace page opens.\n3.  Select an engine from the Engine drop-down.\n4.  Select the catalog, schema, table, or column in which you want to run the query.\n5.  Click the overflow menu and select the required query.\n\n\n\n*  For a catalog and schema, you can run the Generate Path query.\n*  For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n*  For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\n6.  Click the Save icon to save the query. A Save query confirmation dialog appears.\n7.  Click Save.\n8.  Click the Run button to run the query.\n9.  Select Result set or Details tab to view the results.\n10. Click Saved queries to view the saved queries.\n11. Click [Explain](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-run_sql"},{"document_id":"ibmcld_05152-4777-6005","score":10.123588,"text":"\n[SQL Query Window](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/63322f2f3a72050206eb05ba7f590fdcb741105c\/cloud-object-storage\/images\/select-with-sql.jpg)\n\nFigure 7. Access with SQL query window\n\nThe entry representing the job of the SELECT statement run previously is shown in Figure 8. There are two tabs, \"Results\" and \"Details,\" at the top of the list that allow you to switch between seeing the results and more detailed information.\n\nZoom\n\n![SQL Query Results](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/63322f2f3a72050206eb05ba7f590fdcb741105c\/cloud-object-storage\/images\/results-from-sql.jpg)\n\nFigure 8. Access with SQL query jobs\n\nThe entry representing the details of running the SELECT statement run previously is shown in Figure 9.\n\nZoom\n\n![SQL Query Details](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/63322f2f3a72050206eb05ba7f590fdcb741105c\/cloud-object-storage\/images\/details-from-sql.jpg)\n\nFigure 9. Access with SQL query jobs\n\n\n\n\n\n Next Steps \n\nFor more information on using Data Engine see the [Data Engine documentation](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overview) and [Analyzing Data with IBM Cloud SQL Query](https:\/\/www.ibm.com\/cloud\/blog\/analyzing-data-with-ibm-cloud-sql-query).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-sql-query"},{"document_id":"ibmcld_09989-0-1547","score":10.022213,"text":"\n\n\n\n\n\n\n  Query editor \n\nWith the query editor, you can run SQL queries on a specific host and database. You can also save any of the queries that you create.\n\n\n\n  Creating queries \n\n\n\n1.  Go to Query editor.\n2.  From Data objects, select the database and schema in which you want to run the query.\nIf you do not pick a schema, the default database schema is selected.\n3.  Type the SQL query that you want to run.\nIf your query is a select statement, a Set Limit option shows up to allow you to specify how many rows of data you would like to retrieve. The default is No limit.\n\nIn the Worksheet settings you can specify your Default maximum number of rows limit in result. If you decide, however, to add a limit clause in a select statement that is greater than your Default maximum number of rows limit in result, for example: select * from table1 limit 10;, the Results field shows the smaller value of these two parameters.\n\nIn the Worksheet settings you can also specify the Statement separator you want to use. A semicolon (\";\") is the default Statement separator and you must change it to an ampersand (\"&\") when your queries contain semicolons (\";\") to avoid errors.\n4.  When you input the information, you can do one of the following:\n\n\n\n*  Click Run to run the query.\nThe results of the query are displayed in the panel.\n*  Click the floppy disk icon that is in the SQLworksheet toolbar to save the query as a template.\nThe saved query is added to Saved queries and Queries > Recent Queries.\n*  Click Clear to clear the query.\n\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-query-editor"},{"document_id":"ibmcld_05152-1176-2997","score":9.188085,"text":"\nFigure 3 shows the panel that opens when the card is selected. This panel give you control over the location and costs regarding your new instance of IBM Cloud Data Engine. Select the region appropriate for your buckets and the plan suitable for your projects. If you want more information you can use the documentation to [get started](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overview).\n\nZoom\n\n![Create SQL Instance](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/63322f2f3a72050206eb05ba7f590fdcb741105c\/cloud-object-storage\/images\/create-sql-instance-cos.jpg)\n\nFigure 3. Fill out form fields to configure your instance\n\n\n\n Querying Object Storage with SQL Query \n\nYou can use SQL Query to create SELECT statements only; actions such as CREATE, DELETE, INSERT, and UPDATE are not possible.\n\nInput data for your queries are read from ORC, CSV, JSON, or Parquet files located in one or more IBM Cloud Object Storage instances. Each query result is written by default to a CSV file in a Cloud Object Storage instance where you created the integration. But you can freely override and customise the format and Object Storage location as part of the SQL statement that you run.\n\nYou can use a custom INTO clause of a SELECT statement to control where and how result data from a SELECT statement is written to IBM Cloud Object Storage.\n\nGetting started using SQL Query SELECT statements from inside your instance is as easy as creating an integration. Objects of queryable data formats, as well as folders with multiple objects of a consistent queryable format (when shown in the \"folders\" view) are labeled as shown in Figure 4.\n\nZoom\n\n![Object with SQL label](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/63322f2f3a72050206eb05ba7f590fdcb741105c\/cloud-object-storage\/images\/accessible-using-sql.jpg)\n\nFigure 4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-sql-query"},{"document_id":"ibmcld_13471-1147-2628","score":9.181343,"text":"\nThe following SELECT statement combines the observations that have identical time-stamps into a single observation whose value is the original values that are separated by an underscore (_) character:\n\nSELECT TS_COMBINE_DUPLICATE_TIMETICKS(ts1a, TS_COMBINER_CONCATENATE(\"_\"))\nFROM cos:\/\/us\/sql\/timeseries.parquet STORED AS PARQUET\nINTO <your target location> STORED AS PARQUET\n\nFollowing, see the result of the example query:\n\n[(1,\"a\"), (3, \"b\"), (5, \"c_d_e\"), (7, \"f\"), (9, \"g\")]\n\nConsider the following input DoubleTimeSeries, which is stored in a table column with the name ts1b:\n\n[(1,7.0), (3, 8.5), (5, 9.1), (5, 9.3), (5, 9.8), (7, 10.7), (9, 12.2)]\n\nThe following SELECT statement combines the observations that have identical time-stamps into a single observation whose value is the average of the original values.\n\nSELECT TS_COMBINE_DUPLICATE_TIMETICKS(ts1b, TS_COMBINER_AVERAGE())\nFROM cos:\/\/us\/sql\/timeseries.parquet STORED AS PARQUET\nINTO <your target location> STORED AS PARQUET\n\nFollowing, see the result of the example query:\n\n[(1,7.0), (3, 8.5), (5, 9.8), (7, 10.7), (9, 12.2)]\n\n\n\n\n\n Segmentation \n\nSegmentation functions create, as output, a segmented version of a time series. Consider the following input DoubleTimeSeries, which is stored in a table column with the name ts2:\n\n[(1, 1.0), (3, 2.0), (5, 3.0), (7, 4.0), (9, 5.0)]\n\nThe following SELECT statement uses column ts2 and a window size of 2 and a step size of 1 to generate a new DoubleSegmentTimeSeries:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-examples_common"},{"document_id":"ibmcld_13498-48160-49912","score":9.175609,"text":"\nSELECT statements can retrieve and join column values from two or more tables into a single row. The retrieval is based on a specified condition, typically of matching column values.\n\nThe main characteristic of a join is, typically, matching column values in rows of each table that participates in the join. The result of a join associates rows from one table with rows from another table. Depending on the type of join operation, some rows might be formed that contain column values in one table that do not match column values in another table.\n\nA joined table specifies an intermediate result table that is the result of either an INNER join, an OUTER join, a CROSS join, or an ANTI join. The table is derived by applying one of the join operators to its operands.\n\n\n\n\n\n joinType \n\n\n\n Inner join \n\nAn INNER join combines each row of the left table with each row of the right table, keeping only the rows in which the join condition is true.\n\n-- inner join query\nSELECT\nleft_table.col1 AS l_col1,\nleft_table.col2 AS l_col2,\nright_table.col1 AS r_col1,\nright_table.col2 AS r_col2\nFROM\nVALUES (0, 10), (1, 11), (2, 12), (3,13), (4, 14), (5, 14) AS left_table\nINNER JOIN\nVALUES (0, 10), (2, 12), (4, 14), (6, 16) AS right_table\nON left_table.col1 = right_table.col1\n\nThe result of the example query is shown in the following table.\n\n\n\nTable 18. Query result for example.\n\n L_COL1 L_COL2 R_COL1 R_COL2 \n\n 0 10 0 10 \n 2 12 2 12 \n 4 14 4 14 \n\n\n\n\n\n\n\n Outer join \n\nAn OUTER join includes the rows that are produced by the inner join, plus the missing rows, depending on the type of outer join.\n\nA LEFT OUTER or LEFT join includes the rows from the left table that were missing from the inner join.\n\n-- left outer join query\nSELECT\nleft_table.col1 AS l_col1,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13482-13691-15267","score":8.898194,"text":"\n* Data skipping sometimes does not work if type casting is used in the WHERE clause. For example, given a MinMax index on a column with a short data type, the following query does not benefit from data skipping:\n\nselect * from table where shortType > 1\n\nApache Spark evaluates the query as (cast(shortType3 as int) > 1) because the constant 1 is of type integer.\n\nIn some cases, Apache Spark automatically casts the literal to the right type. For example, the previous query works for all other numerical types, except for the byte type, as it requires casting, as well. To benefit from data skipping in such cases, ensure that the literal has the same type as the column type, as in the following example:\n\nselect * from table where shortType > cast(1 as short)\n* Concurrent CREATE\/REFRESH operations are not supported.\n* Indexing nested geospatial field is not supported.\n* With the Lite plan, data skipping features, such as CREATE METAINDEX, are not allowed.\n\n\n\n\n\n\n\n References \n\n\n\n* [Data skipping for Data Engine](https:\/\/www.ibm.com\/cloud\/blog\/data-skipping-for-ibm-cloud-sql-query).\n* [Data skipping demo at Think 2019](https:\/\/www.ibm.com\/cloud\/blog\/ibm-cloud-sql-query-at-think-2019) for the [Danaos use case](https:\/\/www.danaos.com\/home\/default.aspx) of [BigDataStack](https:\/\/bigdatastack.eu\/?utm_source=IBM-Ta-Shma).\n* [How to lay out Big Data in IBM Cloud Object Storage for Spark SQL](https:\/\/www.ibm.com\/cloud\/blog\/big-data-layout).\n* [Querying Geospatial Data by using Data Engine](https:\/\/www.ibm.com\/cloud\/blog\/querying-geospatial-data-using-ibm-sql-query).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-index_management"},{"document_id":"ibmcld_09994-7-1823","score":8.8169,"text":"\nTime travel query syntax and timestamps \n\n\n\n Query syntax \n\nA SELECT query with one or more temporal clauses is a time travel query. Time travel queries might appear as sub-SELECTs in the INSERT, UPDATE, DELETE, MERGE, or CREATE TABLE AS SELECT (CTAS) statements.\n\nAlso, time travel queries might appear in a view definition (CREATE VIEW, with or without OR REPLACE) or a stored procedure definition (CREATE PROCEDURE, with or without OR REPLACE). In either case, timestamp expressions in the syntax (for example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019) are not evaluated at view or procedure definition time, but at the time a user or application queries the view or calls the procedure.\n\nAny base table reference (the table name, with or without database and schema name, and with or without an alias) in a SELECT or sub-SELECT might have an optional temporal clause, which consists of the keywords FOR SYSTEM_TIME followed by one of the following values:\n\n\n\n* AS OF <TIMESTAMP EXPRESSION>\n* BEFORE <TIMESTAMP EXPRESSION>\n* BETWEEN <TIMESTAMP EXPRESSION 1> AND <TIMESTAMP EXPRESSION 2>\n* FROM <TIMESTAMP EXPRESSION 1> TO <TIMESTAMP EXPRESSION 2>\n\n\n\nEach TIMESTAMP EXPRESSION must be one of the following:\n\n\n\n* A literal timestamp value. For example, \u20182022-10-31 20:00:00\u2019.\n* A query parameter or host variable whose value is a timestamp.\n* A built-in function that returns or implicitly converts to a timestamp. For example, CURRENT_DATE, CURRENT_TIMESTAMP or (equivalently) NOW(), or CURRENT_TIMESTAMP(subsecond-digits) or (equivalently) NOW(subsecond-digits).\n* An expression that evaluates to a single timestamp for all rows in the table. For example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019. The expression cannot refer to table columns or to a non-deterministic function (for example, RANDOM()) or be a sub-SELECT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-runningqueries_tt"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.62405052,"ndcg_cut_10":0.62405052}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13493-7-1679","score":11.6246395,"text":"\nRunning a query \n\nWatch the following video to learn more about Data Engine and how you can get started to run a basic query.\n\nIn SQL, the term query is just another way of saying SELECT statement. To run a query:\n\n\n\n1. In the SQL editor field of the Data Engine UI, enter a SELECT statement.\n\n\n\n* After the FROM keyword, specify one or more [unique resource identifiers](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-runningunique) (URIs). Each URI can be thought of as a table. It specifies one or more input objects; each input object can be thought of as a table partition. You must have at least 'Reader' access to the buckets that contain the input objects.\n* If the format of the input objects is CSV, and no special options are required, it is not necessary to specify a STORED AS clause. However, if the format is JSON, ORC, Parquet, or AVRO, after the FROM clause, specify STORED AS JSON, STORED AS ORC, STORED AS PARQUET, or STORED AS AVRO.\n* If text formats, such as JSON and CSV, are compressed with either gzip or bzip2 and have the extensions .gz and .bz, they automatically get recognized as compressed files. However, do not use these kinds of compressed files due to performance reasons.\n* If the format of the input objects is CSV and a delimiter other than the default , (comma) is used, you must specify the delimiter by using the FIELDS TERMINATED BY option of the [STORED AS](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexternalTableSpec) clause. All single Unicode characters are allowed as delimiters.\n* By default, it is assumed that CSV input objects have a header line that specifies the names of the input columns.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-running"},{"document_id":"ibmcld_16662-0-1981","score":11.07419,"text":"\n\n\n\n\n\n\n  Running SQL queries \n\nSQL is a standardized language for defining and manipulating data in a relational database. You can use the Query workspace interface in IBM\u00ae watsonx.data to run SQL queries and scripts against your data.\n\nThe Query workspace has the following components:\n\n\n\n*  Data objects: To view the engines, catalogs, schemas, tables, and columns.\n*  Engine: To select an engine and view the associated catalogs.\n*  Saved queries: To view the saved queries.\n*  Worksheet: To write SQL queries.\n\n\n\nThe Query workspace page provides basic options to undo, redo, cut, copy, paste, save, clear, and delete.\n\nFormat selection option is enabled only when an SQL statement in a query worksheet is selected. The Format worksheet option formats all the content in the worksheet. Comment selection is used to explain sections of SQL statements.\n\nThe Delete option is enabled only after an SQL query is saved.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select SQL. The Query workspace page opens.\n3.  Select an engine from the Engine drop-down.\n4.  Select the catalog, schema, table, or column in which you want to run the query.\n5.  Click the overflow menu and select the required query.\n\n\n\n*  For a catalog and schema, you can run the Generate Path query.\n*  For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n*  For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\n6.  Click the Save icon to save the query. A Save query confirmation dialog appears.\n7.  Click Save.\n8.  Click the Run button to run the query.\n9.  Select Result set or Details tab to view the results.\n10. Click Saved queries to view the saved queries.\n11. Click [Explain](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-run_sql"},{"document_id":"ibmcld_09994-7-1823","score":10.166142,"text":"\nTime travel query syntax and timestamps \n\n\n\n Query syntax \n\nA SELECT query with one or more temporal clauses is a time travel query. Time travel queries might appear as sub-SELECTs in the INSERT, UPDATE, DELETE, MERGE, or CREATE TABLE AS SELECT (CTAS) statements.\n\nAlso, time travel queries might appear in a view definition (CREATE VIEW, with or without OR REPLACE) or a stored procedure definition (CREATE PROCEDURE, with or without OR REPLACE). In either case, timestamp expressions in the syntax (for example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019) are not evaluated at view or procedure definition time, but at the time a user or application queries the view or calls the procedure.\n\nAny base table reference (the table name, with or without database and schema name, and with or without an alias) in a SELECT or sub-SELECT might have an optional temporal clause, which consists of the keywords FOR SYSTEM_TIME followed by one of the following values:\n\n\n\n* AS OF <TIMESTAMP EXPRESSION>\n* BEFORE <TIMESTAMP EXPRESSION>\n* BETWEEN <TIMESTAMP EXPRESSION 1> AND <TIMESTAMP EXPRESSION 2>\n* FROM <TIMESTAMP EXPRESSION 1> TO <TIMESTAMP EXPRESSION 2>\n\n\n\nEach TIMESTAMP EXPRESSION must be one of the following:\n\n\n\n* A literal timestamp value. For example, \u20182022-10-31 20:00:00\u2019.\n* A query parameter or host variable whose value is a timestamp.\n* A built-in function that returns or implicitly converts to a timestamp. For example, CURRENT_DATE, CURRENT_TIMESTAMP or (equivalently) NOW(), or CURRENT_TIMESTAMP(subsecond-digits) or (equivalently) NOW(subsecond-digits).\n* An expression that evaluates to a single timestamp for all rows in the table. For example, CURRENT_TIMESTAMP - INTERVAL \u20181 day\u2019. The expression cannot refer to table columns or to a non-deterministic function (for example, RANDOM()) or be a sub-SELECT.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-runningqueries_tt"},{"document_id":"ibmcld_09989-0-1547","score":10.099691,"text":"\n\n\n\n\n\n\n  Query editor \n\nWith the query editor, you can run SQL queries on a specific host and database. You can also save any of the queries that you create.\n\n\n\n  Creating queries \n\n\n\n1.  Go to Query editor.\n2.  From Data objects, select the database and schema in which you want to run the query.\nIf you do not pick a schema, the default database schema is selected.\n3.  Type the SQL query that you want to run.\nIf your query is a select statement, a Set Limit option shows up to allow you to specify how many rows of data you would like to retrieve. The default is No limit.\n\nIn the Worksheet settings you can specify your Default maximum number of rows limit in result. If you decide, however, to add a limit clause in a select statement that is greater than your Default maximum number of rows limit in result, for example: select * from table1 limit 10;, the Results field shows the smaller value of these two parameters.\n\nIn the Worksheet settings you can also specify the Statement separator you want to use. A semicolon (\";\") is the default Statement separator and you must change it to an ampersand (\"&\") when your queries contain semicolons (\";\") to avoid errors.\n4.  When you input the information, you can do one of the following:\n\n\n\n*  Click Run to run the query.\nThe results of the query are displayed in the panel.\n*  Click the floppy disk icon that is in the SQLworksheet toolbar to save the query as a template.\nThe saved query is added to Saved queries and Queries > Recent Queries.\n*  Click Clear to clear the query.\n\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-query-editor"},{"document_id":"ibmcld_13498-7-2240","score":9.83967,"text":"\nSQL reference \n\n\n\n Introduction \n\nWith IBM Cloud\u00ae Data Engine, you can analyze and transform open data with SQL. It supports the various types of SELECT statements from the ANSI SQL standard.\n\nThe SELECT statement (or query statement) is used to read object data from IBM Cloud\u00ae Object Storage (COS), process the data, and store it back on Cloud Object Storage eventually.\n\nYou can use Data Engine as a data transformation service, as it always writes the results of a query to a specified location in either Object Storage or Db2 tables. Data Engine provides extended SQL syntax inside a special INTO clause to control how the result data is stored physically. This extended SQL syntax includes control over data location, format, layout, and partitioning.\n\nA query statement can be submitted through Data Engine's web UI or programmatically, either by using the service's REST API, or by using the Python or Node.JS SDK. You can also use IBM Watson\u00ae Studio and the Python SDK to use Data Engine interactively with Jupyter Notebooks. In addition, you can submit SQL queries that use IBM Cloud\u00ae Functions.\n\nIn addition to the ad hoc usage of data in IBM Cloud\u00ae Object Storage, you can also register and manage your data in a catalog as tables, consisting of columns and partitions.\n\nSeveral benefits to cataloging your data exist:\n\n\n\n* It simplifies SQL SELECT statements because the SQL author does not need not know and specify exactly where and how the data is stored.\n* The SQL execution can skip the inference of schema and partitioning because this information is available in the metastore. Thus, cataloging improves your query performance, especially for text-based data formats, such as CSV and JSON, where the schema inference requires a full scan of the data before the actual query execution.\n\n\n\n\n\n\n\n Select \n\nSee the following examples for an outline of the general syntax of an SQL query statement that uses the query clause and the namedQuery clause.\n\n\n\n query \n\n\n\n\n\n namedQuery \n\n\n\n\n\n intoClause \n\nThe query statement supports common table expressions. A common table expression permits defining a result table with a table name that can be specified as a table name in any FROM clause of the fullselect that follows.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13498-1605-3435","score":9.675787,"text":"\nThus, cataloging improves your query performance, especially for text-based data formats, such as CSV and JSON, where the schema inference requires a full scan of the data before the actual query execution.\n\n\n\n\n\n\n\n Select \n\nSee the following examples for an outline of the general syntax of an SQL query statement that uses the query clause and the namedQuery clause.\n\n\n\n query \n\n\n\n\n\n namedQuery \n\n\n\n\n\n intoClause \n\nThe query statement supports common table expressions. A common table expression permits defining a result table with a table name that can be specified as a table name in any FROM clause of the fullselect that follows.\n\nCommon table expressions are defined by using the reserved keyword WITH followed by one or more named queries. Each common table expression that is specified can also be referenced by name in the FROM clause of subsequent common table expressions.\n\nCreating a common table expression avoids the overhead of creating and dropping an intermediate result object on Cloud Object Storage that is needed only for a certain query.\n\nMoreover, a common table expression is beneficial when the same result table must be shared in a fullselect.\n\n\n\n\n\n Examples \n\nThe common table expression examples use values clauses to define tables inline. For more information about the values clause, see [valuesClause](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencevaluesClause).\n\n-- find the department with the highest total pay\nWITH dtotal AS (\nSELECT\ncol1 AS deptno,\nSUM(col3+col4) AS totalpay\nFROM VALUES -- deptno, empid, salary, bonus\n(1, 1, 1000, 0), (1, 2, 2000, 500), (1, 3, 3000, 0),\n(2, 4, 5000, 200), (2, 5, 6000, 0), (2, 6, 4000, 0),\n(3, 7, 2000, 500), (3, 8, 2000, 500), (3, 9, 8000, 0)\nGROUP BY col1\n)\nSELECT deptno\nFROM dtotal\nWHERE totalpay = (SELECT MAX(totalpay) FROM dtotal)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13482-13691-15267","score":9.037532,"text":"\n* Data skipping sometimes does not work if type casting is used in the WHERE clause. For example, given a MinMax index on a column with a short data type, the following query does not benefit from data skipping:\n\nselect * from table where shortType > 1\n\nApache Spark evaluates the query as (cast(shortType3 as int) > 1) because the constant 1 is of type integer.\n\nIn some cases, Apache Spark automatically casts the literal to the right type. For example, the previous query works for all other numerical types, except for the byte type, as it requires casting, as well. To benefit from data skipping in such cases, ensure that the literal has the same type as the column type, as in the following example:\n\nselect * from table where shortType > cast(1 as short)\n* Concurrent CREATE\/REFRESH operations are not supported.\n* Indexing nested geospatial field is not supported.\n* With the Lite plan, data skipping features, such as CREATE METAINDEX, are not allowed.\n\n\n\n\n\n\n\n References \n\n\n\n* [Data skipping for Data Engine](https:\/\/www.ibm.com\/cloud\/blog\/data-skipping-for-ibm-cloud-sql-query).\n* [Data skipping demo at Think 2019](https:\/\/www.ibm.com\/cloud\/blog\/ibm-cloud-sql-query-at-think-2019) for the [Danaos use case](https:\/\/www.danaos.com\/home\/default.aspx) of [BigDataStack](https:\/\/bigdatastack.eu\/?utm_source=IBM-Ta-Shma).\n* [How to lay out Big Data in IBM Cloud Object Storage for Spark SQL](https:\/\/www.ibm.com\/cloud\/blog\/big-data-layout).\n* [Querying Geospatial Data by using Data Engine](https:\/\/www.ibm.com\/cloud\/blog\/querying-geospatial-data-using-ibm-sql-query).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-index_management"},{"document_id":"ibmcld_13498-48160-49912","score":8.852564,"text":"\nSELECT statements can retrieve and join column values from two or more tables into a single row. The retrieval is based on a specified condition, typically of matching column values.\n\nThe main characteristic of a join is, typically, matching column values in rows of each table that participates in the join. The result of a join associates rows from one table with rows from another table. Depending on the type of join operation, some rows might be formed that contain column values in one table that do not match column values in another table.\n\nA joined table specifies an intermediate result table that is the result of either an INNER join, an OUTER join, a CROSS join, or an ANTI join. The table is derived by applying one of the join operators to its operands.\n\n\n\n\n\n joinType \n\n\n\n Inner join \n\nAn INNER join combines each row of the left table with each row of the right table, keeping only the rows in which the join condition is true.\n\n-- inner join query\nSELECT\nleft_table.col1 AS l_col1,\nleft_table.col2 AS l_col2,\nright_table.col1 AS r_col1,\nright_table.col2 AS r_col2\nFROM\nVALUES (0, 10), (1, 11), (2, 12), (3,13), (4, 14), (5, 14) AS left_table\nINNER JOIN\nVALUES (0, 10), (2, 12), (4, 14), (6, 16) AS right_table\nON left_table.col1 = right_table.col1\n\nThe result of the example query is shown in the following table.\n\n\n\nTable 18. Query result for example.\n\n L_COL1 L_COL2 R_COL1 R_COL2 \n\n 0 10 0 10 \n 2 12 2 12 \n 4 14 4 14 \n\n\n\n\n\n\n\n Outer join \n\nAn OUTER join includes the rows that are produced by the inner join, plus the missing rows, depending on the type of outer join.\n\nA LEFT OUTER or LEFT join includes the rows from the left table that were missing from the inner join.\n\n-- left outer join query\nSELECT\nleft_table.col1 AS l_col1,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13498-80483-81768","score":8.702673,"text":"\n(1 , 2),\n(2, 2),\n(null, 2),\n(1, null),\n(2, null),\n(null, null)\n) WHERE a IS DISTINCT FROM b\n\nThe result of the example query is shown in the following table.\n\n\n\nTable 36. Query result for example: select all rows with distinct values in column A and B.\n\n A B \n\n 1 2 \n null 2 \n 1 null \n 2 null \n\n\n\n-- all rows that have no distinct values in column A and B\nSELECT * FROM (\nSELECT\ncol1 AS a,\ncol2 AS b\nFROM VALUES\n(1, 2),\n(2, 2),\n(null, 2),\n(1, null),\n(2, null),\n(null, null)\n) WHERE a IS NOT DISTINCT FROM b\n\nThe result of the example query is shown in the following table.\n\n\n\nTable 37. Query result for example: all rows that have no distinct values in column A and B.\n\n A B \n\n 2 2 \n null null \n\n\n\n\n\n\n\n BETWEEN ... AND ... examples \n\n-- all employees with a salary between 4000 and 8000\nSELECT\nemp.col1 AS emp_id,\nemp.col2 AS salary\nFROM VALUES\n(0, 1000),\n(2, 2000),\n(3, 3000),\n(4, 4000),\n(5, 5000),\n(6, 6000),\n(7, null),\n(8, 8000),\n(9,9000) AS emp\nWHERE emp.col2 BETWEEN 4000 AND 8000\n\nThe result of the example query is shown in the following table.\n\n\n\nTable 38. Query result for example: all employees with a salary in the range 4000 - 8000.\n\n EMP_ID SALARY \n\n 4 4000 \n 5 5000 \n 6 6000 \n 8 8000 \n\n\n\n-- all employees with a salary not between 4000 and 8000\nSELECT\nemp.col1 AS emp_id,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_13498-19610-21215","score":8.66156,"text":"\nThe result of the example query is shown in the following table.\n\n\n\nTable 4. Query result for the example set\n\n COL1 \n\n 1 \n 2 \n 3 \n 1 \n 2 \n 3 \n\n\n\n-- intersecting set eliminating duplicate rows\nSELECT * FROM VALUES 1, 2 ,3 INTERSECT VALUES 2, 2, 3, 3, 3\n\n-- intersecting set eliminating duplicate rows\nSELECT * FROM VALUES 1, 2 ,3 INTERSECT DISTINCT VALUES 2, 2, 3, 3, 3\n\nThe result of the example queries is shown in the following table.\n\n\n\nTable 5. Query result for the example intersecting\n\n COL1 \n\n 3 \n 2 \n\n\n\n-- Difference quantity eliminating duplicate rows\nSELECT * FROM VALUES 1, 2 ,3 EXCEPT VALUES 2, 2, 3, 3, 3\n\n-- difference quantity eliminating duplicate rows\nSELECT * FROM VALUES 1, 2 ,3 EXCEPT DISTINCT VALUES 2, 2, 3, 3, 3\n\n-- difference quantity eliminating duplicate rows\nSELECT * FROM VALUES 1, 2 ,3 MINUS VALUES 2, 2, 3, 3, 3\n\n-- difference quantity eliminating duplicate rows\nSELECT * FROM VALUES 1, 2 ,3 MINUS DISTINCT VALUES 2, 2, 3, 3, 3\n\nThe result of the example queries is shown in the following table.\n\n\n\nTable 6. Query result for the example difference\n\n COL1 \n\n 1 \n\n\n\n\n\n\n\n More topics - fullselect \n\nFor more information about the clauses that are used in a fullselect, see the following topics:\n\n\n\n* [expression](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceexpression)\n* [fullselect](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencefullselect)\n* [namedWindows](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencenamedWindows)\n* [simpleselect](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencesimpleselect)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07115-7009-9068","score":10.284418,"text":"\n* The rating that you apply to the result that indicates whether the result is relevant or not relevant\n\n\n\nTo apply relevancy training to a project, complete the following steps:\n\n\n\n1. Go to the Improve and customize page. On the Improvement tools panel, select Improve relevance, then Relevancy training.\n2. Enter a natural language query in the Enter a question to train field.\n\nDo not include a question mark in your query. Use the same wording as your users. For example, IBM Watson in healthcare. Write queries that include some of the terms that are mentioned in the target answer. Term overlap improves the initial results when the natural language query is evaluated.\n3. Click Add+.\n4. Click Rate results.\n5. After the results are displayed, assess each result, and then select Relevant or Not relevant, whichever option applies given the quality of the result.\n\nWhen you select Relevant, you apply a score of 10 to the result. Not relevant applies a score of 0. You can use a different scoring scale if you use the API to rate results, but you can't mix scoring scales within the same project.\n\nIf the result shows the message, \u201cNo content preview available for this document\u201d, it means that the document that was returned does not contain a text field or that its text field is empty. If none of the documents in your collection have a text field, use the API to train the project instead of training it from the product user interface.\n6. When you are finished, click Back to queries.\n7. Continue adding queries and rating them.\n\nAs you rate results, your progress is shown. Check your progress to see when enough rating information is available to meet the training threshold needs. Your progress is broken into the following tasks:\n\n\n\n* Add more queries\n* Rate more results\n* Add more variety to your ratings\n\n\n\nYou must evaluate at least 50 unique queries, maybe more, depending on the complexity of your data. You cannot add more than 10,000 training queries.\n8. You can continue adding queries and rating results after you reach the threshold.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-train"},{"document_id":"ibmcld_07108-2897-3942","score":10.238584,"text":"\nYou can use the [expansions.json](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/discovery\/expansions.json) file as a starting point when you build a query expansion list.\n2. From the navigation pane, open the Improve and customize page.\n3. Expand Improve relevance from the Improvement tools pane.\n4. Click Synonyms, and then click Upload synonyms for the collection.\n\nDo not upload a synonyms file while documents are being added to your collection. The ingestion processing that occurs when documents are added can cause the index to be unavailable.\n\nOnly one synonyms list can be uploaded per collection. If a second expansion list is uploaded, the second list replaces the first.\n5. Run a test query to verify that the query expansion is working as expected.\n\nQuery expansions are applied at query time, not during indexing, so you can add synonyms without reprocessing your collection.\n\n\n\nTo disable query expansion, delete the synonyms file. However, do not delete a synonyms file while new documents are being processed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-search-settings"},{"document_id":"ibmcld_07175-1564-2340","score":9.723827,"text":"\nFor more about training requirements and options, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n Query overview \n\nThe Query overview section displays:\n\n\n\n* The total number of queries made by users\n* The percentage of queries with one or more results clicked\n* The percentage of queries with no results clicked\n* The percentage of queries with no results returned\n* A graph that displays these results over time, so that you can track how adding more data and relevancy training are improving performance\n\n\n\nThese results are gathered using the Events and Feedback API. See the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discoverycreate-event) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboard"},{"document_id":"ibmcld_13075-1823-3835","score":9.4886,"text":"\nFor more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.\n\nSee [Training data requirements](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-apireqs) for the minimum requirements for training, as well as the training limits.\n\nSee [Usage monitoring](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-usage) for details on tracking usage and using this data to help you understand and improve your applications.\n\n\n\n Adding queries and rating the relevancy of results \n\nTraining consists of three parts: a natural language query, the results of the query, and the ratings you apply to those results.\n\n\n\n1. There are two ways to access the training page in the Discovery tooling:\n\n\n\n* For an individual collection, on the Build queries screen, click Train Watson to improve results on the upper right. You don't need to enter a query on the Build queries screen to start training.\n* From the Performance dashboard. Click on the View data metrics icon on the left to open the dashboard. You are prompted to choose a collection to train.\n\n\n\n2. On the Train Watson screen, click Add a natural language query, for example: \"IBM Watson in healthcare\", and add it. Make sure your queries are written the way your users would ask them. Also, it is recommended that training queries be written with some term overlap between the query and the desired answer. This overlap improves initial results, when the natural language query is run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"},{"document_id":"ibmcld_13075-7-2200","score":9.450472,"text":"\nImproving result relevance with the tooling \n\nThe relevance of natural language query results can be improved in IBM Watson\u2122 Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. See [Improving the relevance of your query results with the API](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api) if you would prefer to use the APIs.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nTo train Watson, you must provide the following:\n\n\n\n* Example queries that are representative of the queries your users enter\n* Ratings that indicate which results for each query are relevant and not relevant\n\n\n\nAfter Watson has enough training input, the information that you provide about which results are good and bad for each query is used to learn about your collection. Watson does not just memorize, but it also learns from the specific information about individual queries and applies the patterns it detects to all new queries. It does so, using machine-learning Watson techniques that find signals in your content and questions. After training, Discovery then reorders the query results to display the most relevant results at the top. As you add more and more training data, Discovery becomes more accurate in the ordering of query results.\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nAll private collections return a confidence score in the query results in most cases. For more information, see [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"},{"document_id":"ibmcld_07045-7-2118","score":9.38307,"text":"\nImproving your query results \n\nLearn about actions you can take to improve the quality of your query results.\n\nYou can use the tools that are built in to Discovery to make improvements.\n\n\n\n Results include more than exact matches \n\nUnlike some other search applications, adding quotation marks to a phrase that you submit does not return only exact matches. Queries that are submitted from the product user interface are natural language queries. When quoted text is submitted in a natural language query, the phrase is used to boost result scores. However, results are not limited to documents that contain the entire phrase.\n\nIf you want more control over how queries are handled, you must use the query API. For more information about the phrase operator of the query API, see [Query operators](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-operatorsphrase).\n\n\n\n\n\n A short query returns irrelevant results \n\nIt might be that your query contains too many stop words and not enough distinct terms to trigger a meaningful search. When you submit a query, the query text is analyzed and optimized before it is submitted to the project. One of the changes that occurs is the removal of any stop words from the text. A stop word is a word that is considered to be not useful in distinguishing the semantic meaning of the content. Examples of stop words include terms such as and, the, and about. Discovery defines a list of stop words that it ignores automatically both when the data is indexed and when it is searched. When you submit a query that contains mostly or only stop words, such as About us, it is equivalent to submitting an empty query.\n\nAlthough us is not included in the stop words list, it is lemmatized to we, which is listed as a stop word.\n\nYou can edit the stop words that are used by your collection. However, you can only augment the stop words list; you cannot remove stop words. And the stop words that you define are used only at query time. They do not affect the stop word list that is used by Discovery when data is added to a collection and the index is created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-improvements"},{"document_id":"ibmcld_13075-5007-7084","score":9.306359,"text":"\nTo return to the main Build queries screen at any time, click Build queries on the upper left. To return to the Manage data screen, click the name of the collection on the upper right.\n\nIf you would like to delete all of the training data in your collection at one time, you must do so via the API. See [Delete all training data for a collection](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-all-training-data) for more information. For more information about training via the API, see [Improving the relevance of your query results with the API](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api).\n\n\n\n\n\n Testing and iterating on the relevancy of results \n\nAfter you complete rating results and Watson applies the training, test to see if your query results improved. To do so, run test queries that are related, but not identical to, your training queries. Check to see if the results of your test queries improved.\n\nIf you would like to further improve results after testing, you could:\n\n\n\n* Add more documents to your collection.\n* Add more training queries.\n* Rate more results, making sure to use both the Relevant and Not relevant ratings.\n\n\n\nFor additional training guidance, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).\n\n\n\n\n\n Confidence scores \n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language.\n\nThe confidence score is returned for both trained and untrained private collections (with the exception of filter-only queries of untrained collections). In addition, Discovery returns a document_retrieval_strategy field that indicates the source of the confidence score:\n\n\n\n* untrained\n* relevancy_training, or\n* continuous_relevancy_training\n\n\n\nThe document_retrieval_strategy can be used along with the confidence score to determine how the results provided should be used. In cases where load is high, the document_retrieval_strategy returned might be untrained, even if the collection is trained.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-improving-result-relevance-with-the-tooling"},{"document_id":"ibmcld_07175-7-2035","score":9.26877,"text":"\nViewing metrics and improving query results with the Performance dashboard \n\nThe Performance dashboard in the Discovery tooling can be used to view query metrics, as well as improve query results, including query relevance.\n\nYou can access the Performance dashboard by clicking the View data metrics icon. The dashboard is not available in Premium or Dedicated environments.\n\nThere are two options to improve natural language query results:\n\n\n\n* [Fix queries with no results by adding more data](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboardaddmore)\n* [Bring relevant results to the top by training your data](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboardtraindata)\n\n\n\nYou can view the data metrics in the [query overview](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboardoverview).\n\n\n\n Fix queries with no results by adding more data \n\nIn this section of the dashboard, you can review queries that returned zero results and add more data so that the query returns results in the future. Click the View all and add data button to get started.\n\n\n\n\n\n Bring relevant results to the top by training your data \n\nIn this section, you can train your collections to improve the relevance of natural language query results. Click the View all and perform relevancy training button to get started. Then see [Adding queries and rating the relevancy of results](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingresults) for instructions.\n\nFor more about training requirements and options, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n Query overview \n\nThe Query overview section displays:\n\n\n\n* The total number of queries made by users\n* The percentage of queries with one or more results clicked\n* The percentage of queries with no results clicked\n* The percentage of queries with no results returned","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-performance-dashboard"},{"document_id":"ibmcld_00460-34449-36370","score":9.157074,"text":"\nQuery (_find endpoint) improved\n: IBM Cloudant Query now uses a new method to select an index. Learn more about [IBM Cloudant Query index selection](https:\/\/www.ibm.com\/support\/pages\/improving-cloudant-query-index-selection).\n\nIndex validation\n: The logic for determining whether a specific index is valid for a query that changed, addressing a bug that might lead to incorrect results.\n\nText indexes\n: Queries that use text indexes no longer fail when $exists: false is used.\n\nPartial indexes\n: Partial indexes are now supported for both JSON and text indexes. For more information, see [Creating a partial index](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostindex) to learn about the partial_filter_selector parameter.\n\nExecution statistics\n: Execution statistics about a query can now be generated. These statistics are enabled by using the execution_stats=true parameter. For more information, see [querying an index by using selector syntax](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) to learn more about execution_stats=true parameter.\n\nPagination\n: [Pagination](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-pagination-and-bookmarks) is supported by using the bookmark field. Bookmarks are enabled for all index types.\n\nuse_index field invalid\n: _find now falls back to any valid index if the value specified in the use_index field is invalid for the current query. When find falls back, the warning field is populated in the query response.\n\n\n\n\n\n 9 October 2017 \n\nError handling\n: If you rely on 500 replies for your application, you might have issues. To fix the problem, update your application to rely on 400 responses.\n: If you don't take care of reduce overflow errors as part of a row in the response body, issues occur. To fix this problem, change the application to handle the errors from view requests.\n\n\n\n\n\n\n\n August 2017 \n\n\n\n 17 August 2017 \n\nThe following changes were made in build 6365:\n\nNew!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-classic-release-notes"},{"document_id":"ibmcld_07163-7-1995","score":9.038211,"text":"\nImproving result relevance with the API \n\nYou can train Discovery to improve the relevance of query results for your particular organization or subject area. When you provide a Discovery instance with training data, the service uses machine-learning Watson techniques to find signals in your content and questions. The service then reorders query results to display the most relevant results at the top. As you add more training data, the service instance becomes more accurate and sophisticated in the ordering of results it returns.\n\nRelevancy training is optional; if the results of your queries meet your needs, no further training is necessary. For information about use cases for relevancy training, see [Improve your natural language query results from Watson Discovery](https:\/\/developer.ibm.com\/blogs\/improving-your-natural-language-query-results-from-watson-discovery\/).\n\nFor comprehensive information about the training APIs, see the [API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery).\n\nIf you would prefer to use the Discovery tooling to train Discovery, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\nRelevance training currently applies only to natural language queries in private collections. It is not intended for use with structured Discovery Query Language queries. For more about the Discovery Query Language, see [Query concepts](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts).\n\nTrained collections return a confidence score in the result of a natural language query. See [Confidence scores](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsstopwords) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-api"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.2,"recall_10":0.4,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1312050775,"ndcg_cut_10":0.2520163802}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02421-2997-4969","score":12.203781,"text":"\nIf you try to define a view and you do not define any of the following body parameters, query, hosts, apps, levels, tags, you can get the following error:\n\n{\"details\":[{\"message\":\"\"value\" must contain at least one of query, hosts, apps, levels, tags]\",\"key\":\"value\"}],\"error\":\"\"value\" must contain at least one of [query, hosts, apps, levels, tags]\",\"code\":\"BadRequest\",\"status\":\"error\"}\n\n\n\n\n\n Getting views \n\nWhen you retrieve all the views and alerts for the instance using the GET method, consider the following information:\n\n\n\n* The GET method will return all configured views and associated alerts for the instance.\n* The data returned can be imported into a different instance to create the same views and alerts in that instance.\n\nIf presets are defined, importing the data received from the GET method will fail. {: note\n\n\n\n\n\n\n\n Modifying views \n\nWhen you modify a view, consider the following information:\n\n\n\n* You must specify the name and the view ID of the view.\n* If you are viewing a view in the UI, the view is not refreshed automatically after you run an API request to modify the view. To refresh the view in the UI, you must navigate to the Everything view and back to the view.\n\n\n\nAn API request to modify a view replaces the existing view definition and associated alerts with your request body data. Any properties that are not specified in your PUT request will be removed.\n\nIf the viewid that you are trying to modify does not exist, a response similar to the following will be returned:\n\n{\"error\":\"Nothing to configure\",\"code\":\"BadRequest\",\"status\":\"error\"}\n\n\n\n\n\n Deleting views \n\nWhen you delete a view, consider the following information:\n\n\n\n* You must specify the ID of the view that you plan to delete.\n* You delete the view and all the alerts that are configured for the view.\n\n\n\n\n\n\n\n\n\n API methods \n\nThe following table outlines the actions that you can run to manage views and alerts programmatically:\n\n\n\nTable 1. Configuration API endpoints","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-config-api"},{"document_id":"ibmcld_13818-11430-13253","score":11.889659,"text":"\nQuery parameters Details \n\n version <br>Required <br>string Requests the version of the API as of a date in the format YYYY-MM-DD. Any date up to the current date can be provided. Specify the current date to request the latest version. <br>Possible values: Value must match regular expression ^[0-9]{4}-[0-9]{2}-[0-9]{2}$ \n\n\n\n\n\nTable 3. Request body attributes for adding prefix filters\n\n Request body Details \n\n action <br>Required <br>string Whether to permit or deny prefix filter. <br>Possible values: [permit,deny] <br>Example: permit \n prefix <br>Required <br>string IP prefix and subnet mask <br>Example: 192.168.100.0\/24 \n before <br>string Identifier of prefix filter to handle the ordering and follow semantics:<br><br><br><br> * When a filter reference another filter in it's before field, then the filter making the reference is applied before the referenced filter. For example: if filter A references filter B in its before field, A is applied before B.<br> * When a new filter is added that has the same before as an existing filter, then the older filter has its before field updated to point to the new filter. Starting with the above example: if filter C is added and it references B in its before field, then A's before field should be modified to point to C, so the order of application would be A, C and finally B.<br> * A filter that has an empty before reference is applied last (though the date order mentioned still applies). So continuing the preceding examples, if filter B has an empty before field, then it is applied last, but if filter D is created with an empty before field, then B's before field is modified to point to D, so B is applied before D. <br> Example: 1a15dcab-7e40-45e1-b7c5-bc690eaa9782<br><br><br> \n ge <br>integer IP prefix greater than or equal to this number is processed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/transit-gateway?topic=transit-gateway-adding-prefix-filters"},{"document_id":"ibmcld_00512-5160-7348","score":11.295605,"text":"\nSee also a brief overview of the underlying querying mechanism that you use to select the query mechanism that is best for each query your application needs to make.\n\n\n\n Global querying \n\nYou can make global queries to the following index types:\n\n\n\n* IBM Cloudant Query\n* Views\n* Search\n\n\n\nWhen you make a global query, the database must perform a scatter-gather operation across all data in the database. This action means making requests of many individual database servers. The API coordination node receives the responses from all these servers and combines them to form a single response to the client. This response might involve buffering data and delaying the response to the client if, for example, data requires sorting.\n\n\n\n\n\n Partition querying \n\nYou can make partition queries to the following index types:\n\n\n\n* IBM Cloudant Query\n* Views\n* Search\n\n\n\nWhen you make a partition query, the database can query just the data within a single partition. A partition's data resides in just one shard (with three replicas). The API coordination node can make a request directly to servers that host that data rather than needing to combine responses from many servers. The API coordination node is also free from buffering the response since it has no combination step to carry out. As a result, the data arrives at the client more quickly.\n\nAs the size of a database increases, the number of shards must also increase. The increase in shards directly increases the number of queries that the API coordination node needs to make to servers that host data when you use global queries. However, when you use partition queries, the number of shards has no effect on the number of servers the API coordination node needs to contact. As this number stays small, increasing data size has no effect on query latency, unlike global queries.\n\n\n\n\n\n\n\n Partitioned databases tutorials \n\nYou can see two examples of using partitioned databases:\n\n\n\n1. Read about [partitioned databases and Node.js](https:\/\/blog.cloudant.com\/2019\/05\/24\/Partitioned-Databases-with-Cloudant-Libraries.html) in this blog article that includes how to create a partitioned database, search, views, and a global index.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_07068-19814-21296","score":10.811775,"text":"\nGet details about a query [GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/training_data\/{query_id}](https:\/\/cloud.ibm.com\/apidocs\/discoverygettrainingdata) [GET \/v2\/projects\/{project_id}\/training_data \/queries\/{query_id}](https:\/\/cloud.ibm.com\/apidocs\/discovery-datagettrainingquery) \n Delete a training data query [DELETE \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/training_data\/{query_id}](https:\/\/cloud.ibm.com\/apidocs\/discoverydeletetrainingdata) [DELETE \/v2\/projects\/{project_id}\/training_data \/queries\/{query_id}](https:\/\/cloud.ibm.com\/apidocs\/discovery-datadeletetrainingquery) \n List examples for a training data query [GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/training_data\/{query_id}\/examples](https:\/\/cloud.ibm.com\/apidocs\/discoverylisttrainingexamples) [GET \/v2\/projects\/{project_id}\/training_data \/queries\/{query_id}](https:\/\/cloud.ibm.com\/apidocs\/discovery-datagettrainingquery) <br>The examples are in the list that is returned with the query. \n Add example to training data query [POST \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/training_data\/{query_id}\/examples](https:\/\/cloud.ibm.com\/apidocs\/discoverycreatetrainingexample) [POST \/v2\/projects\/{project_id}\/training_data \/queries\/{query_id}](https:\/\/cloud.ibm.com\/apidocs\/discovery-dataupdatetrainingquery) <br>Use the Create training query method in v2 and pass all examples when you create the query. Otherwise, use the update API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api"},{"document_id":"ibmcld_07121-1620-3479","score":10.5243635,"text":"\nSelect the html field from the field list.\n\nChoose the field that contains HTML representations of the tables.\n\n\n\nAfter the enrichment is applied, you can get valid results when you submit queries that require Discovery to find information that is stored in tables.\n\nA developer can query tables by using the API. For more information, see [Query parameters](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameterstable_retrieval).\n\nFor more information about how to apply the table understanding enrichment by using the API, see [Applying enrichments by using the API](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-manage-enrichmentsenrichments-api-task).\n\n\n\n Working with tabular data in Python \n\nUse [Text Extensions for Pandas](https:\/\/text-extensions-for-pandas.readthedocs.io\/en\/latest\/io.htmlmodule-text_extensions_for_pandas.io.watson.tables), an open-source library from IBM, to read the tables that were parsed from documents in Discovery into pandas DataFrame objects. A pandas DataFrame is an object that represents two-dimensional tabular data in a form that can be transformed and manipulated for downstream analysis in Python.\n\nFor example, you can extract content from tables in many annual report documents and reconstruct it into a single table that includes multiyear data points of interest. For more information, read the [Structured Information Extraction from Tables in PDF Documents with Pandas and IBM Watson](https:\/\/medium.com\/ibm-data-ai\/structured-information-extraction-from-tables-in-pdf-documents-with-pandas-and-ibm-watson-fac302fd25bd) blog post on Medium.com.\n\n\n\n\n\n\n\n Output schema \n\nThe output schema from the Table Understanding enrichment is as follows.\n\n{\n\"tables\": [\n{\n\"location\" : {\n\"begin\" : int,\n\"end\" : int\n},\n\"text\": string,\n\"section_title\": {\n\"text\": string,\n\"location\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-understanding_tables"},{"document_id":"ibmcld_13498-7-2240","score":10.511931,"text":"\nSQL reference \n\n\n\n Introduction \n\nWith IBM Cloud\u00ae Data Engine, you can analyze and transform open data with SQL. It supports the various types of SELECT statements from the ANSI SQL standard.\n\nThe SELECT statement (or query statement) is used to read object data from IBM Cloud\u00ae Object Storage (COS), process the data, and store it back on Cloud Object Storage eventually.\n\nYou can use Data Engine as a data transformation service, as it always writes the results of a query to a specified location in either Object Storage or Db2 tables. Data Engine provides extended SQL syntax inside a special INTO clause to control how the result data is stored physically. This extended SQL syntax includes control over data location, format, layout, and partitioning.\n\nA query statement can be submitted through Data Engine's web UI or programmatically, either by using the service's REST API, or by using the Python or Node.JS SDK. You can also use IBM Watson\u00ae Studio and the Python SDK to use Data Engine interactively with Jupyter Notebooks. In addition, you can submit SQL queries that use IBM Cloud\u00ae Functions.\n\nIn addition to the ad hoc usage of data in IBM Cloud\u00ae Object Storage, you can also register and manage your data in a catalog as tables, consisting of columns and partitions.\n\nSeveral benefits to cataloging your data exist:\n\n\n\n* It simplifies SQL SELECT statements because the SQL author does not need not know and specify exactly where and how the data is stored.\n* The SQL execution can skip the inference of schema and partitioning because this information is available in the metastore. Thus, cataloging improves your query performance, especially for text-based data formats, such as CSV and JSON, where the schema inference requires a full scan of the data before the actual query execution.\n\n\n\n\n\n\n\n Select \n\nSee the following examples for an outline of the general syntax of an SQL query statement that uses the query clause and the namedQuery clause.\n\n\n\n query \n\n\n\n\n\n namedQuery \n\n\n\n\n\n intoClause \n\nThe query statement supports common table expressions. A common table expression permits defining a result table with a table name that can be specified as a table name in any FROM clause of the fullselect that follows.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_07214-74576-76512","score":10.448684,"text":"\nNew support for 'sort' parameter in the query API : The query API (GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/query) now supports the sort parameter, which enables you to specify a comma-separated list of fields in the document to sort on. See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information.\n\nImproved handling by 'timeslice' parameter : The timeslice parameter for query aggregations now correctly handles dates in UNIX epoch format. See [Query reference](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-referenceaggregations) for information about aggregations and the timeslice parameter.\n\nUpdate to JavaSDK : The Discovery Java SDK has been updated. See the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/discovery?language=java) for details.\n\nFixed known issues with wildcard limitations in queries : Only one wildcard worked in any given query. For example, query-month:ctober worked, but query-month:ctobe generated a parsing error. This is resolved. : Wildcards did not work with queries that contained capital letters. For example, given the key\/field pair {\"borrower\": \"GOVERNMENT OF INDIA\"}, query-borrower:ndia returned results but query-borrower:NDIA did not. This is resolved. : Wildcards are not necessary within phrases in queries. For example, given the key\/field pair {\"borrower\": \"GOVERNMENT OF TIMOR\"}, query-borrower:\"GOVERNMENT OF TIMOR\" returns results, but query-borrower:\"GOVERNMENT OF TIOR\" does not. Using a wildcard is not applicable within phrases because all of the characters within the quotation marks (\") of a phrase are escaped.\n\n\n\n\n\n 24 March 2017 \n\nNew feature for My data insights : Added filtering to the \"My data insights\" screen in the Discovery tooling.\n\n\n\n\n\n 15 March 2017 \n\nKnown issues : All fields that are ingested from HTML, PDF, and Word documents are typed as string.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_16671-5931-7034","score":10.302476,"text":"\nFrom the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Select the catalog. In this scenario, consider the Apache Iceberg catalog, default schema, order_detail table, to run the query.\n4. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.\n* For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n* For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\nConsider the following sample query to view the details from iceberg-beta:\n\nExample:\n\n!\/bin\/bash\nSELECT * FROM \"iceberg-beta\".\"default\".\"order_detail\" LIMIT 10;\n5. Click the Run on button to run the query.\n6. Select Result set or Details tab to view the results. If required, you can save the query.\n7. Click Saved queries to view the saved queries.\n8. Click [Explain](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-tutorial_prov_custbckt"},{"document_id":"ibmcld_07214-72932-74977","score":10.253643,"text":"\nNew enhancements to query API : Enhancements are now available for the query API (GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/query). See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information.\n\nNew support for 'passages' parameter in the query API : The query API now supports the passages parameter. If the parameter is set to true, the query returns a set of the most relevant passages from the documents in your collection. The passages are generated by sophisticated Watson algorithms to determine the best passages of text from all of the documents returned by the query. This enables you to find information and context more precisely. See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information. : Specifying passages=true in your query can reduce performance as a result of increased processing to extract passages. With larger environments, the performance impact can be lessened. : The passages parameter is supported only on private collections. It is not supported in the Watson Discovery News collection. : The passages parameter currently returns a maximum of 10 results. The number of returned results cannot be changed. [Update](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameterspassages_count) : The passages parameter returns a maximum of three (3) passages from any given document in the collection. If a document contains more than three additional relevant passages, the parameter does not return them.\n\n\n\n\n\n 7 April 2017 \n\nNew support for 'sort' parameter in the query API : The query API (GET \/v1\/environments\/{environment_id}\/collections\/{collection_id}\/query) now supports the sort parameter, which enables you to specify a comma-separated list of fields in the document to sort on. See the [Query your collection](https:\/\/cloud.ibm.com\/apidocs\/discoveryquery-your-collection) method in the API reference for information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_06308-0-500","score":10.184515,"text":"\n\n\n\n\n\n\n  APIs and SDKs \n\nWatson Query provides REST APIs that you can use to interact with your instance.\n\nTo access data, view and create database objects, administer, and monitor your service, use the [Watson Query APIs](https:\/\/cloud.ibm.com\/apidocs\/data-virtualization-on-cloud).\n\nThe following Watson Query SDKs are supported by IBM:\n\n\n\n*  [Go SDK](https:\/\/github.com\/IBM\/data-virtualization-on-cloud-go-sdk\/)\n*  [Java SDK](https:\/\/github.com\/IBM\/data-virtualization-on-cloud-java-sdk\/)\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/data-virtualization?topic=data-virtualization-con_rest_api"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.25,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.195190025,"ndcg_cut_10":0.3080351663}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16551-0-1579","score":18.518463,"text":"\n\n\n\n\n\n\n  How can I address storage space limits? \n\nDepending on your subscription plan, you might reach the storage limit that is specified for your plan and be prevented from completing tasks.\n\n  What\u2019s happening \n\nYou might see a message about exceeding the allowed storage space when you attempt to perform one of these tasks:\n\n\n\n*  Upload documents or dictionaries\n*  Deploy a model or version a model\n*  Run a pre-annotator on documents\n\n\n\n  Why it\u2019s happening \n\nThe storage limit is met or exceeded if the action proceeds.\n\n  How to fix it \n\nThe largest consumers of storage space are machine learning and rule-based models. To free up space, you can take the following actions:\n\n\n\n*  Delete snapshot versions of any models that you do not expect to need to revert to.\n*  Delete any models that you do not need.\n*  If your models are too important to delete, consider upgrading your plan to one that provides a larger allotment of storage space.\n\n\n\nAfter you remove models or model versions, wait an hour before you retry the action that resulted in the error message. It can take up to an hour for the storage space that you freed up to be available for use.\n\nTo manage your monthly bill, if the Admin role is assigned to you and you have a Premium or Standard account, you can set a storage limit on the Service Details page in Knowledge Studio. To see the Service Details page and set the storage limit, from the top navigation bar in Knowledge Studio, click the Settings icon, click the View\/modify service details link, and then click the Set storage limit link.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_ts_storage"},{"document_id":"ibmcld_07214-62508-64603","score":17.776184,"text":"\nAs a result of this transition, existing users might meet or exceed the lite plan limit on documents (2000), storage (200Mb), or number of collections (2). If you exceed the limit of the Lite plan, you cannot add any additional content into the service, but you can still query collections. : View the current status of all these limits by using the Discovery tooling or API. To resume adding content to the Discovery instance, you must complete one of the following actions: : Remove collections or documents so that limits of the Lite plan are not exceeded. : You can delete documents either individually in the API, using the [delete-doc](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-a-document) method, or you can delete whole collections, using the tooling or API, by using the [delete-collection](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-a-collection) method. : Upgrade your plan to a level that meets your storage needs. : Customers with size 12 or 3 environments will be automatically migrated to the Advanced plan.\n\n\n\n\n\n 17 July 2017 \n\nUpdate to relevancy training, natural language query, and highlighting : Relevancy training announced on 23 June 2017 moved from beta to GA status. : Natural language query announced on 19 June 2017 movedd from beta to GA status. : Highlighting announced on 25 May 2017 moved from beta to GA status.\n\nUpdate to enrichment mechanism : IBM Watson\u2122 Discovery is changing its enrichment mechanism from AlchemyLanguage to Natural Language Understanding as of this release. : AlchemyLanguage is in the process of being deprecated, so it is recommended that you start using Natural Language Understanding as soon as possible. : If you integrate with Watson Knowledge Studio, you must still use the AlchemyLanguage enrichment configuration. For details, see [Integrating with IBM Watson\u2122 Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-integrating-with-wks).\n\nUpdate to version string : The version string for all API calls changed to 2017-07-19 from 2017-06-25. This version enables an NLU default config on collection creation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_01245-4-1307","score":17.31778,"text":"\n* CLI\n* API\n\n\n\n\n\n\n\n Managing storage limits \n\nBy default, you can provision a combined total of 700 Block Storage for Classic and File Storage for Classic volumes globally. By following this process, you can increase the number of volumes you can provision.\n\nFor more information about increasing your storage volume capacity beyond 12 TB, see [expanding File Storage for Classic capacity](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-expandCapacityincreasecapacityover12TB).\n\nIf you're unsure how many volumes you have, you can confirm the numbers by using multiple methods.\n\n\n\n Confirming your current limit and provisioning count from the CLI \n\n\n\n SLCLI \n\nYou can list the number of your volumes by using the [volume-limits](https:\/\/softlayer-python.readthedocs.io\/en\/latest\/cli\/file\/file-volume-limits) command in slcli (version 5.8.5 or higher).\n\n slcli file volume-limits\n\nThe output looks similar to the following example.\n\n[{'datacenterName': 'global', 'maximumAvailableCount': 700, 'provisioned Count':117}]\n:............:.......................:..................:\n: Datacenter : maximumAvailableCount : ProvisionedCount :\n:............:.......................:..................:\n: global : 700 : 117 :\n:............:.......................:..................:\n\n\n\n\n\n IBM Cloud CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits"},{"document_id":"ibmcld_00249-4-1321","score":17.08859,"text":"\n* CLI\n* API\n\n\n\n\n\n\n\n Managing storage limits \n\nBy default, you can provision a combined total of 700 Block Storage for Classic and File Storage for Classic volumes globally. By following this process, you can increase the number of volumes that you can provision.\n\nFor more information about increasing your storage volume capacity beyond 12 TB, see [expanding Block Storage for Classic capacity](https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-expandingcapacityincreasecapacityover12TB).\n\n\n\n Confirming your current limit and provisioning count from the CLI \n\nIf you're unsure how many volumes you have, you can confirm the numbers by using multiple methods.\n\n\n\n SLCLI \n\nYou can list the number of your volumes by using the [volume-limits](https:\/\/softlayer-python.readthedocs.io\/en\/latest\/cli\/block\/block-volume-limits) command in slcli (version 5.8.5 or higher).\n\n slcli block volume-limits\n\nThe output looks similar to the following example.\n\n[{'datacenterName': 'global', 'maximumAvailableCount': 700, 'provisioned Count':117}]\n:............:.......................:..................:\n: Datacenter : maximumAvailableCount : ProvisionedCount :\n:............:.......................:..................:\n: global : 700 : 117 :\n:............:.......................:..................:\n\n\n\n\n\n IBM Cloud CLI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/BlockStorage?topic=BlockStorage-managingstoragelimits"},{"document_id":"ibmcld_05149-4519-6367","score":16.605305,"text":"\nIf not, follow the [getting started tutorial](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage) to obtain the prerequisites and become familiar with the console.\n\n\n\n Set a list of authorized IP addresses using a legacy firewall \n\n\n\n1. Start by selecting Storage to view your resource list.\n2. Next, select the service instance with your bucket from within the Storage menu. This takes you to the Object Storage Console.\n3. Choose the bucket that you want to limit access to authorized IP addresses.\n4. Select Access policies from the navigation menu.\n5. Select the Authorized IPs tab.\n6. Click Add IP addresses, then choose Add.\n7. Specify a list of IP addresses in [CIDR notation](https:\/\/en.wikipedia.org\/wiki\/Classless_Inter-Domain_Routing), for example 192.168.0.0\/16, fe80:021b::0\/64. Addresses can follow either IPv4 or IPv6 standards.\n8. Click Add.\n9. The firewall will not be enforced until the address is saved in the console. Click Save all to enforce the firewall.\n10. Note that all objects in this bucket are only accessible from those IP addresses.\n\n\n\n\n\n\n\n Remove any IP address restrictions using a legacy firewall \n\n\n\n1. From the Authorized IPs tab, check the boxes next to any IP addresses or ranges to remove from the authorized list.\n2. Select Delete, and then confirm the dialog box by clicking Delete again.\n3. The updated list won't be enforced until the changes are saved in the console. Click Save all to enforce the new rules.\n4. Now all objects in this bucket are only accessible from these IP addresses!\n\n\n\nIf there are no authorized IP addresses listed this means that normal IAM policies will apply to the bucket, with no restrictions on the user's IP address, unless there are context-based restrictions in place.\n\n\n\n\n\n Set a legacy firewall through an API","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-setting-a-firewall"},{"document_id":"ibmcld_01169-0-1263","score":16.320696,"text":"\n\n\n\n\n\n\n  Using the administration Kafka Java client API \n\nIf you use a Kafka client version 0.11 or later, or Kafka Streams version 0.10.2.0 or later, you can use APIs to create and delete topics. We put some restrictions on the settings that are allowed when you create topics. See the following settings that you can modify.\n\ncleanup.policy\n:   Set to delete (default), compact or delete,compact.\n\nretention.ms\n:   The default retention period is 24 hours. The minimum is 1 hour and the maximum is 30 days. Specify this value as multiples of hours.\n\nIn the Enterprise plan, you can set retention to any value.\n\nretention.bytes\n:   The maximum size a partition (which consists of log segments) can grow to before we discard old log segments to free up space.\n\nEnterprise plan only. Set to any value larger than 10 MB.\n\nsegment.bytes\n:   The segment file size for the log.\n\nEnterprise plan only. Set to any value larger than 100 kB.\n\nsegment.index.bytes\n:   The size of the index that maps offsets to file positions.\n\nEnterprise plan only. Set to any value between 100 kB and 1 GB.\n\nsegment.ms\n:   The period after which Kafka forces the log to roll even if the segment file isn't full.\n\nEnterprise plan only. Set to any value between 5 minutes and 30 days.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-kafka_java_api"},{"document_id":"ibmcld_01245-2097-3849","score":15.819451,"text":"\nThe API call shows the combined number of Block Storage for Classic and File Storage for Classic.\n\n\n\n\n\n\n\n Requesting limit increase \n\nYou can request a limit increase by submitting a support case in the [portal](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/add). When the request is approved, you get a volume limit that is set for a specific data center.\n\nTo request a limit increase, open a support case and direct it to your sales representative.\n\nIn the ticket, provide the following information:\n\n\n\n* Ticket Subject: Request to Increase Data Center Volume Count Storage Limit\n* What is the use case for the additional volumes request?For example, your answer might be something similar to a new VMware\u00ae datastore, a new development and testing environment, an SQL database, or logging.\n* How many extra Block volumes are needed by type, size, IOPS, and location?For example, your answer might be \"25x Endurance 2 TB @ 4 IOPS in DAL09\" or \"25x Performance 4 TB @ 2 IOPS in WDC04\".\n* How many extra File volumes are needed by type, size, IOPS, and location?For example, your answer might be \"25x Performance 20 GB @ 10 IOPS in DAL09\" or \"50x Endurance 2 TB @ 0.25 IOPS in SJC03\".\n* Provide an estimate of when you expect or plan to provision all of the requested volume increase.For example, your answer might be \"90 days\".\n* Provide a 90-day forecast of expected average capacity usage of these volumes.For example, your answer might be \"expect 25 percent to be used in 30 days, 50 percent to be used in 60 days and 75 percent to be used in 90 days\".\n\n\n\nRespond to all questions and statements in your request. They are required for processing and approval.\n\nYou're going to be notified of the update to your limits through the case handling process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managinglimits"},{"document_id":"ibmcld_11910-18283-20023","score":15.739824,"text":"\nFrom the Satellite storage dashboard, select the storage configuration you want to delete.\n2. Select Actions > Delete\n3. Enter the name of your storage configuration.\n4. Select Delete.\n\n\n\n\n\n\n\n\n\n Parameter reference \n\n\n\n 21.04 parameter reference \n\n\n\nTable 1. 21.04 parameter reference\n\n Display name CLI option Type Description Required? Default value \n\n Management LIF managementLIF Config The IP address of the Management LIF. true N\/A \n Data LIF dataLIF Config The IP address of the Data LIF. true N\/A \n SVM svm Config The name of the SVM. true N\/A \n User Name username Secret The username to connect to the storage device. true N\/A \n User Password password Secret The password to connect to the storage device. true N\/A \n Export Policy exportPolicy Config The NAS option for the NFS export policy. true default \n Limit Volume Size limitVolumeSize Config Maximum requestable volume size (in Gibibytes) and qtree parent volume size true 50Gi \n Limit AggregateUsage limitAggregateUsage Config Fail provisioning if usage is above this percentage. true 80% \n NFS Mount Options nfsMountOptions Config The NFS mount options. true nfsvers=4 \n\n\n\n\n\n\n\n 22.04 parameter reference \n\n\n\nTable 2. 22.04 parameter reference\n\n Display name CLI option Type Description Required? Default value \n\n Management LIF managementLIF Config The IP address of the Management LIF. true N\/A \n Data LIF dataLIF Config The IP address of the Data LIF. true N\/A \n SVM svm Config The name of the SVM. true N\/A \n User Name username Secret The username to connect to the storage device. true N\/A \n User Password password Secret The password to connect to the storage device. true N\/A \n Export Policy exportPolicy Config The NAS option for the NFS export policy. true default","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-storage-netapp-ontap-nas"},{"document_id":"ibmcld_01241-14983-16623","score":15.739803,"text":"\nslcli file snapshot-delete --help\nUsage: slcli file snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI \n\nYou might need to take your storage volume back to a specific point in time because of user-error or data corruption.\n\n\n\n1. Unmount and detach your storage volume from the host.\n\nFor more information about mounting and unmounting storage, see [connecting your new storage](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-mountingLinux).\n2. Go to the [IBM Cloud\u00ae console](https:\/\/cloud.ibm.com\/login). From the menu, select Classic Infrastructure![Classic icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/04e9937a86546143babfc65ea21fdd4ea2d12d13\/icons\/classic.svg).\n3. Click Storage, File Storage for Classic.\n4. Scroll on the list, and click your volume to be restored. The Snapshots page displays the list of all saved snapshots along with their size and creation date.\n5. Click Actions![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/04e9937a86546143babfc65ea21fdd4ea2d12d13\/icons\/action-menu-icon.svg) next to the snapshot to be used and click Restore.\n\nCompleting the restore results in the loss of the data that was created or modified after the snapshot was taken. This data loss occurs because your storage volume returns to the same state that it was in of the time of the snapshot.\n6. Click Yes to start the restore.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-managingSnapshots"},{"document_id":"ibmcld_12904-22084-23929","score":15.727725,"text":"\nAs the result, you're billed an overage charge based on 87 GB x 12 hours = 1044 GB hours for that extra space.\n\nOverage is calculated by using the maximum number of GB more than the plan allocation during a particular hour within the billing cycle.\n\n\n\n\n\n\n\n Disk overage example \n\nAssume that you start a month of 30 days with a Standard plan service instance that uses 9 GB of storage. Next, your storage increases to 21.5 GB for 15 minutes during the hour beginning at 02:00 of day 3. The instance drops back to 9.5 GB for the next 10 minutes of hour 02:00, then increases to 108 GB for the next 25 minutes of hour 02:00. Finally, your instance finishes the hour and indeed the rest of the month by dropping down to 28 GB.\n\nThis pattern means the maximum number of GB more than the plan allocation was 88 GB during hour 2 of day 3. From hour 03:00 of day 3, and for the rest of the month, your instance was 8 GB more than the plan allocation.\n\nTherefore, from hour 02:00 of day 3, your bill includes an overage based on 88 GB x 1 hour = 88 GB hours.\n\nFrom hour 03:00 of day 3 to the end of day 3, your bill includes an overage based on 8 GB x 21 hours = 168 GB hours.\n\nFrom hour 00:00 of day 4 until the end of the month (of 30 days), your bill includes an overage. The overage is based on 8 GB x 24 hours x 27 days = 5184 GB hours.\n\nThe total overage bill for the month is based on a total of 88 + 168 + 5184 = 5440 GB hours.\n\n\n\n\n\n\n\n Request and document size limits \n\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https:\/\/cloud.ibm.com\/apidocs\/cloudantlist-of-http-codes) alerts you.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16728-6533-8457","score":13.733221,"text":"\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Build a database-driven Slackbot](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson)Build a database-driven Slackbot Solution tutorial\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\n![solution tutorial icon](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/solution-tutorial.svg) [Build, deploy, test and monitor a predictive machine learning model](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model)Build, deploy, test and monitor a predictive machine learning model Solution tutorial\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=solutions"},{"document_id":"ibmcld_16729-11586-13439","score":13.42294,"text":"\n* 15 minutes\n* 2023-01-31\n\n\n\n[Build a data lake using object storage](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\nBlockchain[Setting up multiregion High Availability (HA) deployments for the ordering service](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-hadr-mr-os)Setting up multiregion High Availability (HA) deployments for the ordering service\n\nIn this tutorial, you learn how to set up a Raft ordering service with five ordering nodes that span multiple regions for maximum high availability.\n\nIBM Blockchain Platform\n\n\n\n* 2023-02-17\n\n\n\n[Using certificates from an external Certificate Authority](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-tutorial-extca)Using certificates from an external Certificate Authority\n\nIn this tutorial, you learn how to use certificates that were generated by an external Certificate Authority (CA) with your IBM\u00ae Blockchain Platform network. After you gather the required certificates for a peer or ordering node, you build a Membership Service Provider (MSP) definition that is used by your blockchain components.\n\nIBM Blockchain Platform\n\n\n\n* 30 minutes\n* 2023-02-17","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_09984-0-1283","score":13.341751,"text":"\n\n\n\n\n\n\n  Overview \n\nData lakes are an essential tool for storing structured and unstructured data on the cloud. With IBM\u00ae Netezza\u00ae Performance Server for IBM Cloud Pak\u00ae for Data as a Service, you can use external tables to access parquet files that are stored outside of your database in data lakes (on AWS S3). Also, you can analyze this data by using the robust and massively parallel Netezza Performance Server execution engine.\n\nExternal data sources use connection strings to specify how you can access an external system. Each connection string describes where your data is placed and how to authenticate to your data source. Each external data source has a definition (schema), but the actual data exists external to the Netezza Performance Server database.\n\nYou cannot backup (nzbackup) and restore (nzrestore) external data source objects.\n\nUse cases for external data source include:\n\n\n\n*  [Running queries against parquet data that is stored in a data lake](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-querying_singularity).\n*  [Ingesting data into Netezza Performance Server](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-ingest_singularity).\n*  [Querying both local and remote data](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-merging_singularity).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-overview_singularity"},{"document_id":"ibmcld_13162-2830-4436","score":12.745635,"text":"\nCreate an instance of [Object Storage](https:\/\/cloud.ibm.com\/catalog\/services\/cloud-object-storage). If you already have Object Storage instance with a lite plan, use standard instead of lite.\n\nibmcloud resource service-instance-create data-lake-cos cloud-object-storage lite global\n4. Create an instance of [Data Engine](https:\/\/cloud.ibm.com\/catalog\/services\/sql-query). Replace us-south by your region, if needed. If you already have Data Engine instance with a lite plan, use standard instead of lite.\n\nibmcloud resource service-instance-create data-lake-sql sql-query lite us-south\n5. Create an instance of [Watson Studio](https:\/\/cloud.ibm.com\/catalog\/services\/watson-studio).\n\nibmcloud resource service-instance-create data-lake-studio data-science-experience free-v1 us-south\n6. Create an API key for service access. Copy the output to a secure, permanent location for later use.\n\nibmcloud iam api-key-create data-lake-cos-key --output json\n\n\n\n\n\n\n\n Step 2: Uploading data \n\nIn this section, you will upload data to an Object Storage bucket. You can do this using regular http upload or by utilising the built-in Cloud High-Speed Transfer Service. Cloud High-Speed Transfer Service protects data as it is uploaded to the bucket and [can greatly reduce transfer time](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/ibm-cloud-object-storage-simplifies-accelerates-data-to-the-cloud).\n\n\n\n1. Download the [City of Los Angeles \/ Traffic Collision Data from 2010](https:\/\/data.lacity.org\/api\/views\/d5tf-ez2w\/rows.csv?accessType=DOWNLOAD) CSV file. The file is 81MB and may take a few minutes to download.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_09976-7-1778","score":12.487989,"text":"\nMerging and querying data \n\nYou might keep only the most recent data locally in a database and use data lakes as your long term storage. With Netezza Performance Server, you can seamlessly query both local and remote data without having to load the remote data into a database first.\n\n\n\n Before you begin \n\nIn the examples, the publicly available [New York taxi trip record data](https:\/\/www1.nyc.gov\/site\/tlc\/about\/tlc-trip-record-data.page) for yellow taxis in January 2021 and 2022 is used. To follow this example, make sure that the data is in an accessible S3 bucket.\n\n\n\n\n\n 1. Create an external data source. \n\nExternal datasources allow an administrator to grant access to S3 without providing the keys directly to a user.\n\na) Set ENABLE_EXTERNAL_DATASOURCE.\n\nset ENABLE_EXTERNAL_DATASOURCE = 1;\n\nb) Create an external data source.\n\ncreate EXTERNAL DATASOURCE 'DATA SOURCE' on 'REMOTE SOURCE'\nusing (\nACCESSKEYID 'ACCESS KEY ID' SECRETACCESSKEY 'SECRET ACCESS KEY' BUCKET 'BUCKET' REGION 'REGION'\n);\n\nExample:\n\ncreate EXTERNAL DATASOURCE EXAMPLEDATALAKE\u00a0on AWSS3\u00a0\nusing (\nACCESSKEYID 'XXXX' SECRETACCESSKEY 'XXXX' BUCKET 'exampledatalakebucket' REGION 'US-EAST-1'\n);\n\nFor more information, see [CREATE EXTERNAL DATASOURCE command](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=tables-create-external-datasource-command).\n\n\n\n\n\n 2. Identify the data from Netezza Performance Server to merge and compare. \n\nIn this example, data that was loaded into Netezza Performance Server (YELLOW_TAXI_JANUARY_2022) is compared with data from a data like (YELLOW_TAXI_JANUARY_2021).\n\nTo follow this example, ensure that YELLOW_TAXI_JANUARY_2022 is in your Netezza Performance Server database.\n\na) Create an external table for the data that you want to load (YELLOW_TAXI_JANUARY_2022).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-merging_singularity"},{"document_id":"ibmcld_13162-12751-14416","score":12.34609,"text":"\nCongratulations, you have built a data lake using Object Storage. Below are additional suggestions to enhance your data lake.\n\n\n\n* Experiment with additional datasets using Data Engine\n* Stream data from multiple sources into your data lake by completing [Big data logs with streaming analytics and SQL](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-big-data-log-analyticsbig-data-log-analytics)\n* Build a web app with a dashboard for line of business users utilizing [IBM Cognos Dashboard Embedded](https:\/\/cloud.ibm.com\/docs\/cognos-dashboard-embedded?topic=cognos-dashboard-embedded-gettingstartedtutorial).\n\n\n\n\n\n\n\n Step 8: Remove resources \n\nRun the following commands to remove services, applications and keys you created and used.\n\nibmcloud resource service-instance-delete data-lake-sql\n\nibmcloud resource service-instance-delete data-lake-studio\n\nibmcloud iam api-key-delete data-lake-cos-key\n\nibmcloud resource service-instance-delete data-lake-cos\n\nIf the deletion of data-lake-cos is not successful delete it from the storage section of the [Resource List](https:\/\/cloud.ibm.com\/resources).\n\nDepending on the resource it might not be deleted immediately, but retained (by default for 7 days). You can reclaim the resource by deleting it permanently or restore it within the retention period. See this document on how to [use resource reclamation](https:\/\/cloud.ibm.com\/docs\/account?topic=account-resource-reclamation).\n\n\n\n\n\n Related content \n\n\n\n* [ibmcloudsql](https:\/\/github.com\/IBM-Cloud\/sql-query-clients\/tree\/master\/Python)\n* [Jupyter Notebooks](https:\/\/jupyter.org\/)\n* [Folium](https:\/\/python-visualization.github.io\/folium\/)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_13162-7-1878","score":12.004708,"text":"\nBuild a data lake using object storage \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n\n\n Objectives \n\n\n\n* Use Object Storage to store raw data files\n* Query data directly from Object Storage using Data Engine (previously SQL Query)\n* Refine and analyze data in IBM Watson\u00ae Studio\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution29\/Smart-Data-Lake-Architecture.png)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. Raw data is stored on Object Storage.\n2. Data is reduced, enhanced or refined with Data Engine.\n3. Data analysis occurs in Watson Studio.\n4. Non-technical users access data through application(s).\n5. Refined data is pulled from Object Storage.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI.\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools you can use the [Cloud Shell](https:\/\/cloud.ibm.com\/shell) from the IBM Cloud console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_13162-3985-5744","score":11.653663,"text":"\nCloud High-Speed Transfer Service protects data as it is uploaded to the bucket and [can greatly reduce transfer time](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/ibm-cloud-object-storage-simplifies-accelerates-data-to-the-cloud).\n\n\n\n1. Download the [City of Los Angeles \/ Traffic Collision Data from 2010](https:\/\/data.lacity.org\/api\/views\/d5tf-ez2w\/rows.csv?accessType=DOWNLOAD) CSV file. The file is 81MB and may take a few minutes to download.\n2. In your browser, access the data-lake-cos service instance from the [Resource List](https:\/\/cloud.ibm.com\/resources) under the Storage section.\n3. Create a new bucket to store data.\n\n\n\n* Click Create a bucket.\n* Select Custom bucket\/Customize your bucket.\n* Close to the top of the form, provide a bucket Name.\n* Select Regional in the Resiliency section.\n* Select a Location.\n* At the bottom of the form click Create bucket.\n\n\n\n4. Upload the CSV file to Object Storage.\n\n\n\n* From your bucket, click Upload.\n* Select Standard transfer to use regular http file transfer or select the Aspera high-speed transfer radio button, you may need to install the Aspera plugin to your machine.\n* Click Upload files.\n* Browse and select the previously downloaded CSV file and click Upload.\n\n\n\n\n\n\n\n\n\n Step 3: Working with data \n\nIn this section, you will convert the original, raw dataset into a targeted cohort based on time and age attributes. This is helpful to consumers of the data lake who have specific interests or would struggle with very large datasets.\n\nYou will use Data Engine to manipulate the data where it resides in Object Storage using familiar SQL statements. Data Engine has built-in support for CSV, JSON and Parquet - no additional computation services or extract-transform-load is necessary.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"},{"document_id":"ibmcld_00029-7-2023","score":11.5827055,"text":"\nUsing IBM Cloud Data Engine as external metastore \n\nIBM Cloud Data Engine is IBM Cloud's central service for data lakes. It provides stream ingestion, data preparation, ETL, and data query from IBM Cloud Object Storage and Kafka. It also manages tables and views in a catalog that is compatible with Hive metastore and other big data engines and services can connect to it. See [Overview of IBM Cloud Data Engine](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overview).\n\nEach instance of IBM Cloud Data Engine includes a database catalog that you can use to register and manage table definitions for your data on IBM Cloud Object Storage. Catalog syntax is compatible with Hive metastore syntax. You can use IBM Cloud Data Engine to externalize metadata outside the IBM Analytics Engine Spark cluster.\n\n\n\n Pre-requisites \n\nThe following are the pre-requisites:\n\n\n\n* Creating IBM Cloud Data Engine instance\n* Storing data in Cloud Object Storage\n* Creating schema\n\n\n\n\n\n Creating IBM Cloud Data Engine instance \n\n{: metastore-prerequisite_line1}\n\nCreate an IBM Cloud Data Engine instance by using the Standard plan.\u00a0See [Data Engine](http:\/\/cloud.ibm.com\/catalog\/services\/data-engine-previously-sql-query).\n\nAfter you have provisioned the Data Engine instance:\n1. Make a note of the CRN of the instance.\n1. Create an account-level API key or service ID level API key with access to the instance.\n1. This service ID should be granted access to both the Data Engine instance as well as the IBM Cloud Object Storage bucket.\n\nYou can then configure your IBM Analytics Engine instance to use the default metastore configuration either at instance level or at application level as needed.\n\nIBM Cloud Data Engine supports creating instances for different endpoints(location). Within an instance, different IBM Cloud Object Storage buckets are created to store data. The data buckets can be created for different end points(region). The endpoints for the data engine instance(thrift) and the data bucket are different.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_13162-6697-8604","score":11.57017,"text":"\nThe intermediate dataset is displayed below the query on the Results tab associated with the Job\n\n\n\n\n\n\n\n Step 4: Combine Jupyter Notebooks with Data Engine \n\nIn this section, you will use the Data Engine client within a Jupyter Notebook. This re-uses the data stored on Object Storage in a data analysis tool. The combination also creates datasets that are automatically stored in Object Storage that can then be accessed by applications and tools serving line of business users.\n\nFirst, create a new Jupyter Notebook and service connections in Watson Studio.\n\n\n\n1. Access the data-lake-studio Watson Studio service instance from the [Resource List](https:\/\/cloud.ibm.com\/resources) under the AI \/ Machine Learning section.\n\n\n\n* Click Launch in IBM Cloud Pak for Data.\n* Click Create a Project followed by Create an empty project.\n* Use Data lake project as Name.\n* Under Define storage select data-lake-cos.\n* Click Create.\n\n\n\n2. In the resulting project, add an access token to the project.\n\n\n\n* Click the Manage tab.\n* Click Access control on the left.\n* Click the Access tokens tab.\n* Click New access token.\n* Enter a name and select Editor for access role and click Create.\n\n\n\n3. Click the Assets tab and then click New asset and Connection.\n\n\n\n* From the list of services select IBM Cloud Data Engine.\n* In the dialog enter SQLQuery as Name.\n* As CRN copy in the Data Engine instance CRN. You can obtain it by clicking in the [Resource List](https:\/\/cloud.ibm.com\/resources) right to the service name. data-lake-sql. The pop-up has the CRN and a copy button.\n* Fill in cos:\/\/us-south\/<your-bucket-name> as Target. Replace us-south and <your-bucket-name> similar to how you did it earlier.\n* As Password under Credentials use the API key which you created earlier. The value is from the field apikey.\n* Finally, click Create.\n\n\n\n4. Now create the notebook. Click New asset and Jupyter notebook editor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-smart-data-lake"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.9197207891,"ndcg_cut_5":0.9197207891,"ndcg_cut_10":0.9197207891}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16638-0-764","score":14.010073,"text":"\n\n\n\n\n\n\n  Creating table from a file \n\nFiles can also be ingested or imported to IBM\u00ae watsonx.data through the overflow menu of schema in the Data explorer page to create tables.\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select Data manager.\n3.  Select the engine from the Engine drop-down. Catalogs that are associated with the selected engine are listed.\n4.  Select a schema under a catalog where you want to import a file to create table.\n5.  Click the overflow menu of the selected schema and select Create table from a file. The Create table from a file page opens.\n6.  Follow the steps in the [Creating tables](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-create_table) topic to complete importing the file.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-import_data"},{"document_id":"ibmcld_13480-1642-3813","score":13.998759,"text":"\nSo, if you are either familiar with the schema, or want to repetitively use the data for queries, create a table in the catalog. Such a table improves performance for repeated query executions.\n\nAnother advantage of creating a table in the catalog is that the table name serves as an alias and is decoupled from the data location. Hence, you can separate the tasks of data engineers and SQL authors. Data engineers deal with the data location and publish registered tables in the catalog by using descriptive table names. Hence, SQL authors are able to compose queries without having to know the exact location and format of data on Object Storage. If the data location changes, only the table in the catalog must be updated, but the table name remains unchanged. Updates of the physical data structure are simplified and the robustness of SQL statements and applications is increased.\n\n\n\n\n\n Usage \n\nYou manage the database catalog in Data Engine with Database Definition Language (DDL) statements that you submit just like any other SQL query statement. The catalog is stored independently of Object Storage: No data is written to Object Storage when you create or change table definitions, and no data is deleted from Object Storage when you drop a table definition. To call the catalog management statements, you need the Manager user role assigned.\n\nTo register a new table in the catalog, use the CREATE TABLE statement, as in the following example:\n\nCREATE TABLE employees\nUSING PARQUET\nLOCATION cos:\/\/us-geo\/sql\/employees.parquet\n\nThe statement automatically detects the schema of the data at the location that is indicated. See the [SQL reference](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencecreateTable) for options that can be set on the table.\n\nUse the DESCRIBE TABLE statement to verify the detected table schema:\n\nDESCRIBE TABLE employees\n\nIf the DESCRIBE TABLE output shows partition information, you must run an ALTER TABLE ... RECOVER PARTITIONS statement to attach the partitions. For more information, see the section on [partitioned tables](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalogpartitioned).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_13512-5424-5881","score":13.922009,"text":"\nThe <table name> part specifies the table that is created in your database. It has the format <schemaname>.<tablename>. If you omit the <schemaname> part, the table is created in the schema of database user that was created for the IBMid of the SQL user. The table name is case-preserving, so use uppercase to match database defaults.\n\nThe following URI is an example of a Db2 table URI:\n\ndb2:\/\/db2w-vqplkwx.us-south.db2w.cloud.ibm.com\/MYSCHEMA.QUERY_RESULT","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-writing-databases"},{"document_id":"ibmcld_09950-7-1844","score":13.781227,"text":"\nTables \n\nIn the table from the Tables tab, the value that is displayed in the row count column is an approximate. The exact row count is available after you run the GENERATE STATISTICS ON <table_name> command.\n\n\n\n Creating tables \n\n\n\n1. Go to Databases.\n2. Select the database in which you want to create a table.\n3. Select the schema in which you want to create a table.\n4. Ensure that you are in the DB Objects > Tables tab.\n5. Click Create table.\n6. Type a name for the table.\nIf the name contains special characters, enclose it in double quotation marks. The dot character (\".\") is not supported.\nYou can select a name that has up to 128 characters. The name must begin with a letter or an underscore and can't contain embedded spaces. The name must be unique.\n7. Optional: Specify the retention time interval (in days) for the table.\nYou can select between 1 day and up to 99 days, or zero to alter a temporal table to nontemporal.\n8. Add columns to the table:\n\n\n\n1. In the Columns section, under Name, type a name for the column. The name must start with a letter.\n2. Select your column type.\nThe data type restricts the type of data that can be stored in a column. For example, preventing entry of alphanumeric characters into a numeric field.\nData types also help sort data correctly and play a role in optimizing storage. For all these reasons, it is important to pick the appropriate data type.\n3. Specify whether Not null is true or false.\nA column that allows NULL values also allows rows to be inserted with no value in that column. A column that does not allow NULL values does not accept rows with no value.\n4. Specify the default value to be used if no value is specified when a row is inserted.\n5. In the Distribute on and Organize on sections, specify the distribution key for the table by selecting up to four columns.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-create-tables"},{"document_id":"ibmcld_00029-3016-4446","score":13.289762,"text":"\ndef generate_and_store_data(spark,sc):\n\u00a0\u00a0\u00a0 data =[(\"India\",\"New Delhi\"),(\"France\",\"Paris\"),(\"Lithuania\",\"Vilnius\"),(\"Sweden\",\"Stockholm\"),(\"Switzerland\",\"Bern\")]\n\u00a0\u00a0\u00a0 columns=[\"Country\",\"Capital\"]\n\u00a0\u00a0\u00a0 df=spark.createDataFrame(data,columns)\n\u00a0\u00a0\u00a0 df.write.mode(\"overwrite\").parquet(\"cos:\/\/mybucket.mycosservice\/countriescapitals.parquet\")\n\ndef main():\n\u00a0\u00a0\u00a0 spark,sc = init_spark()\n\u00a0\u00a0\u00a0 generate_and_store_data(spark,sc)\nif __name__ == '__main__':\n\u00a0\u00a0\u00a0 main()\n\nShow more\n\n\n\n\n\n Creating schema \n\nCreate the metastore table schema definition in the data engine. Note that you can't use standard Spark SQL syntax to create tables when using Data Engine as a metastore. There are two ways that you can use to create a table:\n\n- From the Data Engine user interface or by using, the standard Data Engine API (see [Data Engine service REST V3 API](https:\/\/cloud.ibm.com\/apidocs\/sql-query-v3introduction)) or Python SDK (see [ibmcloudsql](https:\/\/pypi.org\/project\/ibmcloudsql\/)).\n\nExample\n: Enter:\n\n {: codeblock}\nCREATE TABLE COUNTRIESCAPITALS (Country string,Capital string)\u00a0\nUSING PARQUET\u00a0\nLOCATION cos:\/\/ALIAS NAME\/mybucket\/countriescapitals.parquet\n\nParameter values:\nALIAS NAME: The data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewendpoints). Make sure that you select the standard aliases.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_07121-1620-3479","score":13.01667,"text":"\nSelect the html field from the field list.\n\nChoose the field that contains HTML representations of the tables.\n\n\n\nAfter the enrichment is applied, you can get valid results when you submit queries that require Discovery to find information that is stored in tables.\n\nA developer can query tables by using the API. For more information, see [Query parameters](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameterstable_retrieval).\n\nFor more information about how to apply the table understanding enrichment by using the API, see [Applying enrichments by using the API](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-manage-enrichmentsenrichments-api-task).\n\n\n\n Working with tabular data in Python \n\nUse [Text Extensions for Pandas](https:\/\/text-extensions-for-pandas.readthedocs.io\/en\/latest\/io.htmlmodule-text_extensions_for_pandas.io.watson.tables), an open-source library from IBM, to read the tables that were parsed from documents in Discovery into pandas DataFrame objects. A pandas DataFrame is an object that represents two-dimensional tabular data in a form that can be transformed and manipulated for downstream analysis in Python.\n\nFor example, you can extract content from tables in many annual report documents and reconstruct it into a single table that includes multiyear data points of interest. For more information, read the [Structured Information Extraction from Tables in PDF Documents with Pandas and IBM Watson](https:\/\/medium.com\/ibm-data-ai\/structured-information-extraction-from-tables-in-pdf-documents-with-pandas-and-ibm-watson-fac302fd25bd) blog post on Medium.com.\n\n\n\n\n\n\n\n Output schema \n\nThe output schema from the Table Understanding enrichment is as follows.\n\n{\n\"tables\": [\n{\n\"location\" : {\n\"begin\" : int,\n\"end\" : int\n},\n\"text\": string,\n\"section_title\": {\n\"text\": string,\n\"location\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-understanding_tables"},{"document_id":"ibmcld_13480-3420-5386","score":12.833667,"text":"\nUse the DESCRIBE TABLE statement to verify the detected table schema:\n\nDESCRIBE TABLE employees\n\nIf the DESCRIBE TABLE output shows partition information, you must run an ALTER TABLE ... RECOVER PARTITIONS statement to attach the partitions. For more information, see the section on [partitioned tables](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalogpartitioned).\n\nYou can then query the table by name instead of specifying the Object Storage URI directly in the SQL statement:\n\nSELECT * FROM employees LIMIT 10\n\nIf you want to use more specific data types than the data types inferred by automatic schema detection, you can also specify the table schema explicitly:\n\nCREATE TABLE employees (\nemployeeID int,\nlastName string,\nfirstName string,\ntitle string,\ntitleOfCourtesy string,\nbirthDate timestamp,\nhireDate timestamp,\naddress string,\ncity string,\nregion string,\npostalCode string,\ncountry string,\nhomePhone string,\nextension int,\nphoto string,\nnotes string,\nreportsTo string,\nphotoPath string\n)\nUSING PARQUET\nLOCATION cos:\/\/us-geo\/sql\/employees.parquet\nShow more\n\nIf accessing the table in a SELECT statement does not work as expected, it is possibly caused by improper specification of the table schema in the CREATE TABLE statement. The column names and their data types in your CREATE TABLE statement must match the result of the following query:\n\nSELECT * FROM describe (<data-location> stored as <storage-format>)\n\nColumn names are case-sensitive. Incorrect column name specification results in an empty column, that is, the column seems to contain no data. To solve such a problem, use the automatic schema detection, reorder the columns, or omit some columns.\n\nThe SHOW TABLES statement provides you with an overview of the existing tables in your instance. This statement allows an optional search filter to limit the number of results:\n\nSHOW TABLES LIKE 'cus'\n\nIt is not possible to use a different namespace than default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-getting_started_catalog"},{"document_id":"ibmcld_16640-1521-3641","score":12.384886,"text":"\nInitiating DROP SCHEMA statement against a non-empty schema may result in Db2 SQL Error SQLCODE=-478 and SQLSTATE=42893.\n\n\n\n\n\n Issue: CREATE VIEW statement that is partially supported by Db2 \n\nDb2 connector partially supports CREATE VIEW statement. The Presto supported SQL syntax does not include creating views with custom column names (different than the table column names).\n\n\n\n\n\n Issue: CREATE VIEW statement that is partially supported by Netezza \n\nNetezza connector partially supports CREATE VIEW statement. The Presto Supported SQL syntax does not include creating views with custom column names (different than the table column names).\n\n\n\n\n\n Issue: Data ingestion through CLI \n\nFollowing are the limitations when ingesting data through the CLI:\n\n\n\n* Schema evolution is not supported.\n* Partitioning is not supported.\n* Iceberg target table is the only supported output format.\n* Source CSV file containing TAB or space as delimiter is not supported.\n* pathStyleAccess property for object storage is not supported.\n* Source files must be of the same format type and only Parquet and csv file formats are supported.\n\n\n\n\n\n\n\n Issue: Data ingestion through web console \n\nFollowing are the limitations when ingesting data through the web console:\n\n\n\n* Iceberg target table is the only supported format.\n* Partitioning is not supported.\n* Source CSV file containing TAB or space as delimiter is not supported.\n* Configure options are disabled for GA.\n* Target table output format is Iceberg and the target data format is Parquet.\n* Target storage path is default and cannot be changed.\n\n\n\n\n\n\n\n Issue: Presto does not recognize the path as a directory \n\nWhen you create a new table with a Presto Hive connector that uses an S3 folder from an external location, Presto does not recognize the path as a directory and an error might occur.\n\nFor example, when creating a customer table in the target directory DBCERT\/tbint in a bucket that is called dqmdbcertpq by using the IBM Cloud UX and Aspera S3 console, the following error is encountered: External location must be a directory.\n\nCREATE TABLE \"hive-beta\".\"dbcert\".\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-known_issues"},{"document_id":"ibmcld_09958-9644-11401","score":12.234994,"text":"\nUnlike the CREATE TABLE command, which does not have any existing rows, existing visible rows in the table are treated as if they were inserted by this ALTER TABLE transaction. The existing visible rows receive virtual insert timestamps that are equal to the retention start time. With these timestamps, the rows are potentially visible to time travel queries.\n\n\n\n\n\n Altering temporal schemas to nontemporal with the command-line \n\nTo alter a temporal schema to nontemporal, set DATA_VERSION_RETENTION_TIME to 0.\n\nFor detailed syntax, the necessary privileges, and the CASCADE option, see [the ALTER SCHEMA command](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=npsscr-alter-schema-2).\n\nALTER SCHEMA <schema_name> DATA_VERSION_RETENTION_TIME 0 NOCASCADE;\n\nExample:\n\nALTER SCHEMA SCHEMA DATA_VERSION_RETENTION_TIME 0 NOCASCADE;\n\n\n\n\n\n Altering nontemporal schemas to temporal with the command-line \n\nTo alter a nontemporal schema to temporal, set DATA_VERSION_RETENTION_TIME to a nonzero value.\n\nFor detailed syntax, the necessary privileges, and the CASCADE option, see [the ALTER SCHEMA command](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=npsscr-alter-schema-2).\n\nALTER SCHEMA <schema_name> DATA_VERSION_RETENTION_TIME <number-of-days> NOCASCADE;\n\nExample:\n\nALTER SCHEMA DB1 DATA_VERSION_RETENTION_TIME 30 NOCASCADE;\n\n\n\n\n\n Altering temporal databases to nontemporal with the command-line \n\nTo alter a temporal database to nontemporal, set DATA_VERSION_RETENTION_TIME to 0.\n\nFor detailed syntax and the necessary privileges, see [the ALTER DATABASE command](https:\/\/www.ibm.com\/docs\/en\/netezza?topic=npsscr-alter-database-2).\n\nALTER DATABASE <db_name> DATA_VERSION_RETENTION_TIME 0 NOCASCADE;\n\nExample:\n\nALTER DATABASE DB1 DATA_VERSION_RETENTION_TIME 0 NOCASCADE;","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-enablingdisabling_tt"},{"document_id":"ibmcld_16613-0-1165","score":12.147709,"text":"\n\n\n\n\n\n\n  Creating table \n\nYou can generate, configure, and run DDL from the Data manager page by using the web console.\n\n\n\n1.  Log in to IBM\u00ae watsonx.data console.\n2.  From the navigation menu, select Data manager.\n3.  Select the engine from the Engine menu. Catalogs that are associated with the selected engine are listed.\n4.  Click Create and select Create table.\n5.  In the Create table form, drag a file to the box or click to upload.\n\n.CSV, .Parquet, .json, .txt are the supported data file formats. For .json file, you must enclose the content in [].\n6.  Click the data type and choose the required data types for each column. Click Next.\n7.  In the Target form, select the Engine, Catalog, and Schema in which the table is created.\n8.  Enter a name for the table in the Table name field and click Next.\n9.  Verify the details in the Summary page and scroll down to view the DDL preview.\n10. Click Create.\n11. Verify that the table creation status in the Result set is successful, indicated as true.\n12. Go to the Data manager page and select the schema under which you created the table and click the refresh icon. The newly created table is listed.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-create_table"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1356519734}}
{"task_id":"1c041ce47a81941c26899fdf08bde961<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_00644-25890-27361","score":15.719647,"text":"\n\"github.com\/IBM\/cloudant-go-sdk\/cloudantv1\"\n)\n\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration) for examples.\n\n\n\n\n\n Querying a view by using a list of keys \n\nYou can also run a query by providing a list of keys to use.\n\nRequesting information from a database in this way uses the specified $VIEW_NAME from the specified $DDOC design document. Like the keys parameter for the [GET](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsquerying-a-view) method, you can use the POST method to specify the keys to use to retrieve the view results. In all other aspects, the POST method is the same as the [GET](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-viewsquerying-a-view) API request. In particular, you can use any of its query parameters in either the query string or the JSON body.\n\nSee the example HTTP request that returns all users, where the key for the view matches either amelie.smith@aol.com or bob.smith@aol.com:\n\nPOST $SERVICE_URL\/$DATABASE\/_design\/$DDOC\/_view\/$VIEW_NAME HTTP\/1.1\nContent-Type: application\/json\n\n{\n\"keys\": [\n\"amelie.smith@aol.com\",\n\"bob.smith@aol.com\"\n]\n}\n\nSee the example of a global query that returns all users (where the key for the view matches is either amelie.smith@aol.com or bob.smith@aol.com):\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-using-views"},{"document_id":"ibmcld_16567-1410-2678","score":15.682706,"text":"\nStore them in a [credentials file](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration). As an alternative to ibmcloud login, you can set the environment variable DATA_VIRTUALIZATION_APIKEY to an IAM API key.\n\nIBM Cloud CLI requires Java&trade 1.8.0. You can download the CLI from IBM Cloud to use on your local system as a complement to the IBM Cloud console.\n\n\n\n\n\n Data sources \n\nConnect data sources to the watson query service.\n\n\n\n ibmcloud watson-query datasource-connections \n\nGets all data source connections that are connected to the service.\n\nibmcloud watson-query datasource-connections\n\n\n\n Examples \n\nGet data connections\n\nibmcloud watson-query datasource-connections\n\n\n\n\n\n Example output \n\n{\n\"datasource_connections\" : [ {\n\"agent_class\" : \"F\",\n\"dscount\" : \"0\",\n\"hostname\" : \"dv-0.dv.tns.svc.cluster.local\",\n\"is_docker\" : \"N\",\n\"node_name\" : \"AdminNode\",\n\"node_description\" : \"Not specified\",\n\"port\" : \"6414\",\n\"os_user\" : \"bigsql\",\n\"data_sources\" : {\n\"cid\" : \"MSSQL10000\",\n\"dbname\" : \"mssql2014db1\",\n\"connection_id\" : \"75e4d01b-7417-4abc-b267-8ffb393fb970\",\n\"srchostname\" : \"example.ibm.com\",\n\"srcport\" : \"1433\",\n\"srctype\" : \"MSSQLServer\",\n\"status\" : \"string\",\n\"usr\" : \"DV-user\",\n\"uri\" : \"example.ibm.com:1433\/\"\n} ]\n} ]\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin"},{"document_id":"ibmcld_16582-1410-2678","score":15.682706,"text":"\nStore them in a [credentials file](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration). As an alternative to ibmcloud login, you can set the environment variable DATA_VIRTUALIZATION_APIKEY to an IAM API key.\n\nIBM Cloud CLI requires Java&trade 1.8.0. You can download the CLI from IBM Cloud to use on your local system as a complement to the IBM Cloud console.\n\n\n\n\n\n Data sources \n\nConnect data sources to the watson query service.\n\n\n\n ibmcloud watson-query datasource-connections \n\nGets all data source connections that are connected to the service.\n\nibmcloud watson-query datasource-connections\n\n\n\n Examples \n\nGet data connections\n\nibmcloud watson-query datasource-connections\n\n\n\n\n\n Example output \n\n{\n\"datasource_connections\" : [ {\n\"agent_class\" : \"F\",\n\"dscount\" : \"0\",\n\"hostname\" : \"dv-0.dv.tns.svc.cluster.local\",\n\"is_docker\" : \"N\",\n\"node_name\" : \"AdminNode\",\n\"node_description\" : \"Not specified\",\n\"port\" : \"6414\",\n\"os_user\" : \"bigsql\",\n\"data_sources\" : {\n\"cid\" : \"MSSQL10000\",\n\"dbname\" : \"mssql2014db1\",\n\"connection_id\" : \"75e4d01b-7417-4abc-b267-8ffb393fb970\",\n\"srchostname\" : \"example.ibm.com\",\n\"srcport\" : \"1433\",\n\"srctype\" : \"MSSQLServer\",\n\"status\" : \"string\",\n\"usr\" : \"DV-user\",\n\"uri\" : \"example.ibm.com:1433\/\"\n} ]\n} ]\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-query-cli-plugin?topic=watson-query-cli-plugin-CLI-name"},{"document_id":"ibmcld_04326-1410-2678","score":15.682706,"text":"\nStore them in a [credentials file](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=goauthentication-with-external-configuration). As an alternative to ibmcloud login, you can set the environment variable DATA_VIRTUALIZATION_APIKEY to an IAM API key.\n\nIBM Cloud CLI requires Java&trade 1.8.0. You can download the CLI from IBM Cloud to use on your local system as a complement to the IBM Cloud console.\n\n\n\n\n\n Data sources \n\nConnect data sources to the watson query service.\n\n\n\n ibmcloud watson-query datasource-connections \n\nGets all data source connections that are connected to the service.\n\nibmcloud watson-query datasource-connections\n\n\n\n Examples \n\nGet data connections\n\nibmcloud watson-query datasource-connections\n\n\n\n\n\n Example output \n\n{\n\"datasource_connections\" : [ {\n\"agent_class\" : \"F\",\n\"dscount\" : \"0\",\n\"hostname\" : \"dv-0.dv.tns.svc.cluster.local\",\n\"is_docker\" : \"N\",\n\"node_name\" : \"AdminNode\",\n\"node_description\" : \"Not specified\",\n\"port\" : \"6414\",\n\"os_user\" : \"bigsql\",\n\"data_sources\" : {\n\"cid\" : \"MSSQL10000\",\n\"dbname\" : \"mssql2014db1\",\n\"connection_id\" : \"75e4d01b-7417-4abc-b267-8ffb393fb970\",\n\"srchostname\" : \"example.ibm.com\",\n\"srcport\" : \"1433\",\n\"srctype\" : \"MSSQLServer\",\n\"status\" : \"string\",\n\"usr\" : \"DV-user\",\n\"uri\" : \"example.ibm.com:1433\/\"\n} ]\n} ]\n}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-CLI-name"},{"document_id":"ibmcld_00469-13046-15136","score":15.435297,"text":"\nYou might find that you\u2019re mainly hitting the Query limit, but you have plenty of headroom in Lookups. It might be possible to reduce the reliance on Queries through some remodeling of the data or perhaps doing more work client-side.\n\nThe corollary here though is that you can\u2019t assume that any third-party library or framework optimizes for cost ahead of convenience. Client-side frameworks that support multiple persistence layers by using plug-ins are unlikely to be aware of this situation, or might be incapable of making such tradeoffs.\n\nChecking for third-party library or framework compatibility before you commit to a particular tool is a good idea.\n\nIt is also worth understanding that the rates aren\u2019t directly equivalent to HTTP API endpoint calls. You must expect that, for example, a bulk update counts according to its constituent document writes.\n\n\n\n* IBM Cloudant documentation on [plans and pricing](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicibm-cloud-public) on IBM public cloud\n\n\n\n\n\n\n\n Logging helps you see what\u2019s going on \n\nIBM Cloudant\u2019s logs indicating each API call made, what was requested and how long it took to respond can be automatically spooled to LogDNA for analysis and reporting for IBM Cloud-based services. This data is useful for keeping an eye on request volumes, performance, and whether your application is exceeding the provisioned capacity for your IBM Cloudant service.\n\nYou can set up the logging service at no cost to get started. Paid-for plans allow data to be parsed, retained, and archived to Object Storage. Slices and aggregations of your data can be built up into visual dashboards to give you an at-a-glance view of your IBM Cloudant traffic. For more information, see the following website:\n\n\n\n* [IBM Cloudant Logging with LogDNA blog](https:\/\/blog.cloudant.com\/2019\/09\/16\/Cloudant-Logging-with-LogDNA.html)\n\n\n\n\n\n\n\n Compress your HTTP traffic \n\nIBM Cloudant compresses its JSON responses to you if you supply an HTTP header in the request that indicates that your code can handle data in this format:\n\nRequest:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-in-practice"},{"document_id":"ibmcld_00580-64080-66194","score":15.406983,"text":"\nTo summarize, IBM Cloudant Search indexes are defined with a supplied JavaScript function. They are built on Apache Lucene and are primarily used for free-text search matching, but the query language is useful for building flexible queries on a fixed set of indexed fields. It also has some powerful counting aggregations suitable for drill-down user interfaces.\n\nIBM Cloudant Search also powers type=text IBM Cloudant Query indexes, so a subset of its capabilities is surfaced by using the _find API.\n\nThat's the end of this part. The next part is called Under the hood.\n\n\n\n\n\n\n\n Under the hood video \n\nLearn how the IBM Cloudant service is organized.\n\n\n\n* Under the hood video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 17 - Under the hood.\n\nLet's look at how an IBM Cloudant service is organized: This overview applies to the IBM Cloudant services that map to CouchDB 2 and 3. CouchDB 4 is built on different technology.\n\nIBM Cloudant is a distributed database with data that is stored around a cluster of storage nodes. Picture the IBM Cloudant service as ring of nodes, in this case twelve. Every node can deal with incoming API calls and every node has responsibility for storing some of the data: shards and associated secondary indexes of databases that exist in the cluster.\n\nWhen data is written to IBM Cloudant, one of the nodes in the ring handles the request: Its job is to instruct three copies of the data to be stored in three storage nodes. Data is stored in triplicate in IBM Cloudant, so each shard of a database is stored multiple times, often across a region's availability zones.\n\nWhen you make an API call to write data and get a response back, we write the data to at least two of the three storage nodes. Data is flushed to disk - it isn't cached in memory to be flushed data. We consider that technique too risky and prone to data loss.\n\nWhen you create a database, a number of database shards are created (16 by default) which are spread around the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00580-34804-36790","score":15.365251,"text":"\nYou can see from the first line that standard JavaScript objects can be used in your code and sent to IBM Cloudant with no conversion, as they turn into JSON natively in JavaScript.\n\nWriting a document is simply a matter of calling db.insert, which maps to a PUT\/POST API call or to _bulk_docs.\n\nTo summarize, the official libraries for IBM Cloudant are Java\u2122, Python, and Nodejs. They are thin wrappers around the IBM Cloudant HTTP API - so it's worth understanding the underlying API to understand all the parameters.\n\nThe libraries handle two things for you, which is useful:\n\nAuthentication\n: Exchanging your keys for tokens, whether it be legacy authentication or IAM.\n\nRetry logic\n: The libraries can be configured to retry API calls that exceeded your provisioned capacity. If configured this way, they pause and reattempt the API call multiple times with exponential back-off.\n\nRetrying such API calls is sensible if you have a temporary and unexpected elevation in traffic. If you are routinely exceeding your provisioned capacity, no amount of retrying gets the database work done - you need more capacity!\n\nThat's the end of this part. The next part is called Querying.\n\n\n\n\n\n\n\n Querying video \n\nLearn the different ways to query data in IBM Cloudant.\n\n\n\n* Querying video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.\n\nThis video is part 10 - Querying.\n\nSo far we performed CRUD (create, retrieve, update, and delete) operations from the command line, the dashboard, and from code. These operations use the document's _id:\n\n\n\n* Fetch document by _id.\n* Update document whose _id = 'x'.\n* Delete document whose _id = 'x'.\n* Get documents in the _id range 'a' to 'z'.\n\n\n\nThese operations are the building blocks of a database, but they get you only so far. What if you need to return a subset of documents that match on fields within the document? A person's birth date?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00512-5160-7348","score":15.363295,"text":"\nSee also a brief overview of the underlying querying mechanism that you use to select the query mechanism that is best for each query your application needs to make.\n\n\n\n Global querying \n\nYou can make global queries to the following index types:\n\n\n\n* IBM Cloudant Query\n* Views\n* Search\n\n\n\nWhen you make a global query, the database must perform a scatter-gather operation across all data in the database. This action means making requests of many individual database servers. The API coordination node receives the responses from all these servers and combines them to form a single response to the client. This response might involve buffering data and delaying the response to the client if, for example, data requires sorting.\n\n\n\n\n\n Partition querying \n\nYou can make partition queries to the following index types:\n\n\n\n* IBM Cloudant Query\n* Views\n* Search\n\n\n\nWhen you make a partition query, the database can query just the data within a single partition. A partition's data resides in just one shard (with three replicas). The API coordination node can make a request directly to servers that host that data rather than needing to combine responses from many servers. The API coordination node is also free from buffering the response since it has no combination step to carry out. As a result, the data arrives at the client more quickly.\n\nAs the size of a database increases, the number of shards must also increase. The increase in shards directly increases the number of queries that the API coordination node needs to make to servers that host data when you use global queries. However, when you use partition queries, the number of shards has no effect on the number of servers the API coordination node needs to contact. As this number stays small, increasing data size has no effect on query latency, unlike global queries.\n\n\n\n\n\n\n\n Partitioned databases tutorials \n\nYou can see two examples of using partitioned databases:\n\n\n\n1. Read about [partitioned databases and Node.js](https:\/\/blog.cloudant.com\/2019\/05\/24\/Partitioned-Databases-with-Cloudant-Libraries.html) in this blog article that includes how to create a partitioned database, search, views, and a global index.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-database-partitioning"},{"document_id":"ibmcld_00580-65668-67805","score":15.343609,"text":"\nData is stored in triplicate in IBM Cloudant, so each shard of a database is stored multiple times, often across a region's availability zones.\n\nWhen you make an API call to write data and get a response back, we write the data to at least two of the three storage nodes. Data is flushed to disk - it isn't cached in memory to be flushed data. We consider that technique too risky and prone to data loss.\n\nWhen you create a database, a number of database shards are created (16 by default) which are spread around the cluster. Three copies of each shard exist, which equals 48 shard copies.\n\nYou don't see any of this activity. The activity is handled for you transparently when you create a database.\n\nWhat happens if a node goes down or needs to be rebooted for maintenance? The rest of the cluster continues as normal. Most shards still have three copies of data but some have only two. API calls continue to work as normal, only two copies of the data are written.\n\nEven if two nodes go down, most shards still have three copies, some have two, and some have one. Writes continue to work, although the HTTP response code reflects that the quorum of two node confirmations wasn't reached.\n\nIt's the same story for reads. Service continues with a failed node. We can survive one failed node...\n\nOr more failed nodes. If a copy of each node exists, the API continues to function.\n\nWhen a node returns, it catches up any missed data from its peers and then returns into service, handling API calls and answering queries for data.\n\nThe nature of this configuration is that IBM Cloudant exhibits eventual consistency. Any node can handle a request. Data is distributed around nodes without the sort of locking that you might see in a relational database.\n\nIBM Cloudant favors availability over consistency: It would rather be up and answering API calls than be down because it can't provide consistency guarantees. (A relational database is often configured in the opposite way: It operates in a consistent manner or not at all.) The upshot of eventual consistency for a developer is that your app must not read its writes in a short time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-learning-center"},{"document_id":"ibmcld_00539-3574-5364","score":15.287009,"text":"\nThe [POST \/{db}\/_explain](https:\/\/cloud.ibm.com\/apidocs\/cloudant?code=javapostexplain) API endpoint when passed a JSON object that is usually sent to the [POST \/{db}\/_find](https:\/\/cloud.ibm.com\/apidocs\/cloudantpostfind) endpoint, explains how such a query is handled and which indexes, if any, might be used.\n\nIf the index object in the response indicates that \"all_docs\" is being used, a full database scan is required to service the query. We recommend that you use the _explain mechanism to check each IBM Cloudant query to ensure it is using an index before you deploy to production.\n\nFor example, a type=json index on firstname, surname and date is suitable for finding documents for:\n\n\n\n* A known firstname, lastname, and date.\n* A known firstname, lastname, and a range of date values (that use $lt, $lte, $gt, $gte operators).\n* A known firstname and lastname sorted by date.\n\n\n\nIt can also be used to assist queries on firstname, surname, date, and other attributes. In other words, it might be able to answer only part of the query but it can help reduce the number of documents that are scanned to find the answer.\n\n\n\n\n\n How can I ensure that my query is efficent? \n\nIdeally, an IBM Cloudant Query execution would need to scan only one document for each document returned. If a query has to scan a million documents for each one returned, it is clearly not optimal, and is in need of a secondary index to help.\n\nWhen you execute a query, passing execution_stats: true as an extra parameter forces IBM Cloudant to enumerate the number of documents it scanned in performing the query, for example:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\"date\"],\n\"limit\": 10,\n\"execution_stats\": true\n}\n\nThe returned data now includes an extra JSON object:\n\n{\n...","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-using-cloudant-query"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16258-2570-3569","score":10.501561,"text":"\n[Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps. A panel opens showing the full back and forth between your customer and the assistant, including step interactions. The panel also provides a summary of how many requests there were, how many were recognized, whether search was initiated, and the duration of the conversation.\n\n![Conversation detail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-side.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-1324-3123","score":9.9381075,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_06953-2615-5096","score":9.331074,"text":"\nWhen Emphasize the answer is used (\"find_answers\": true), Discovery rescores and reorders the documents to ensure that documents with the highest-quality answers are returned first.\n\n\n\n\n\n Choosing a project type \n\nIf the Conversational Search project type isn't providing the best answers and you want to understand why, switch to using a Document Retrieval project type.\n\nMost often, the Conversational Search project type is the right choice. You get great results from the start, and when you enable extra features like Emphasize the answer, the answers are clear and concise. However, for advanced use cases, or if you want to be able to troubleshoot issues, a Document Retrieval project type might be a better fit.\n\nTo help you choose the right Discovery project type, review the project type differences that are described in the following table.\n\n\n\nProject type details\n\n Function Conversational Search Document Retrieval \n\n Enrichment support Only the Part of Speech enrichment is applied. The Part of Speech and Entities enrichments are applied. The Entities enrichment is helpful for identifying important information and introduces more ways to filter query results. \n Testing queries from the Improve and customize page in Discovery You see only one of the responses that are returned from the chatbot. You cannot see all of the available responses and cannot analyze individual query results. You can filter query results by enrichment-based facets. You can review details about fields that are indexed in the source documents that are returned for a query. Access to more information makes it easier to troubleshoot unexpected results. \n Search triggers Returns answers from the text field automatically. If answers are stored in another field, you must change the configuration. You can apply a Smart Document Understanding (SDU) model or enrichments to your collections and retrieve useful information from fields other than text when search is triggered from the assistant. \n\n\n\nFor both project types, the best way to test is to trigger search from the Watson Assistant preview. When you configure search support for an assistant, you can fine-tune the experience in ways that aren't available in Discovery.\n\nAnd settings that are available from the Search results tool for a Document Retrieval project type are replaced by configuration settings that you specify in Watson Assistant. For example, the query response title and body are defined in Watson Assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-chat-choose-project"},{"document_id":"ibmcld_07046-13262-15106","score":8.639302,"text":"\n* The field with the longest string value and highest number of distinct values is chosen.\n* If more than one field meets the previous condition, one of the fields is chosen at random.\n\n\n\n* If you want to apply an enrichment to a nested field, you must create a Content Mining project, and then apply the enrichment to the field. If you want to use a project type other than Content Mining, you can reuse the collection that you created with the Content Mining project type elsewhere. For more information, see [Applying enrichments](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-connector-database-cp4dconnector-database-cp4d-enrich-db).\n\n\n\nYou can specify the normalizations and conversions objects in the [Update a collection](https:\/\/cloud.ibm.com\/apidocs\/discovery-dataupdatecollection) method of the API to move or merge JSON fields.\n\n\n\n\n\n\n\n How passages are derived \n\nDiscovery uses sophisticated algorithms to determine the best passages of text from all of the documents that are returned by a query. Passages are returned per document by default. They are displayed as a section within each document query result and are ordered by passage relevance.\n\nDiscovery uses sentence boundary detection to pick a passage that includes a full sentence. It searches for passages that have an approximate length of 200 characters, then looks at chunks of content that are twice that length to find passages that contain full sentences. Sentence boundary detection works for all supported languages and uses language-specific logic.\n\nFor all project types except Conversational Search, you can change how the passages are displayed in the search results from the Customize display > Search results page. For example, you can configure the number of passages that are shown per document and the maximum character size per passage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-index-overview"},{"document_id":"ibmcld_16258-7-1952","score":8.274196,"text":"\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16364-201078-203239","score":8.264884,"text":"\nSee [Fuzzy matching](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-fuzzy-matching) for details.\n\n\n\n\n\n 13 June 2017 \n\nUser conversations\n: The Improve panel now includes a User conversations page, which provides a list of user interactions with your chatbot that can be filtered by keyword, intent, entity, or number of days. You can open individual conversations to correct intents, or to add entity values or synonyms.\n\nRegex change\n: The regular expressions that are supported by SpEL functions like find, matches, extract, replaceFirst, replaceAll and split have changed. A group of regular expression constructs are no longer allowed, including look-ahead, look-behind, possessive repetition and backreference constructs. This change was necessary to avoid a security exposure in the original regular expression library.\n\n\n\n\n\n 12 June 2017 \n\nUpdates\n: This release includes the following updates:\n\n\n\n* The maximum number of workspaces that you can create with the Lite plan (formerly named the Free plan) changed from 3 to 5.\n* You can now assign any name to a dialog node; it does not need to be unique. And you can subsequently change the node name without impacting how the node is referenced internally. The name you specify is treated as an alias and the system uses its own internal identifier to reference the node.\n* You can no longer change the language of a workspace after you create it by editing the workspace details. If you need to change the language, you can export the workspace as a JSON file, update the language property, and then import the JSON file as a new workspace.\n\n\n\n\n\n\n\n 6 June 2017 \n\nLearn\n: A new Learn about IBM Watson\u00ae Assistant page is available that provides getting started information and links to service documentation and other useful resources. To open the page, click the icon in the page header.\n\nBulk export and delete\n: You can now simultaneously export a number of intents or entities to a CSV file, so you can then import and reuse them for another Watson Assistant application. You can also simultaneously select a number of entities or intents for deletion in bulk.\n\nUpdates to Korean","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16364-34499-36597","score":7.957586,"text":"\nFilter variables and saved responses by name\n: You can now find variables and saved responses more easily. On the Actions page, you can filter variables you created or saved responses you added. Click the search icon, then enter a search string. Your list of variable or saved responses filters to match what you enter.\n\n\n\n\n\n 1 September 2022 \n\nConditioning on days of the week\n: You can now condition a step on days of the week. This feature is available with the date response type and the Current date built-in variable.\n\nFor example, you might [define a customer response](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-collect-infochoose-type) in step 1 with the date response type. When the customer responds to that step, they choose a date. You can then condition a later step on whether the date that the customer chose is Wednesday.\n\nNew operators available for building conditions\n: Several new operators are available for building conditions in your actions. The free text response type now has the contains, does not contain, matches, and does not match operators available. For more information, see [Operators](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-conditionsoperators).\n\nExtensions support for arrays\n: Custom extensions now support passing arrays as parameters and accessing arrays in response variables. For more information, see [Calling a custom extension](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-call-extension).\n\n\n\n\n\n 26 August 2022 \n\nNew filter on the Analyze page\n: You can now filter customer conversation data by the Greet customer system action. From the Conversations tab of the Analyze page, open the Actions filter and select Greet customer. For more information, see [Filtering conversations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversationsanalytics-conversations-filtering).\n\nFilter actions by name\n: You can now find actions more easily. On the Actions page, you can filter actions by name. Click the search icon, then enter a search string.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16343-7-1927","score":7.933487,"text":"\nNeuralSeek extension setup \n\n[NeuralSeek](https:\/\/neuralseek.com) by [Cerebral Blue](https:\/\/cerebralblue.com\/) is a combined search and natural-language generation system that is designed to [make conversational AI feel more conversational](https:\/\/garrettrowe.medium.com\/making-conversational-ai-feel-more-conversational-8748009b3fda). It requires that you load all your content into [IBM Watson\u00ae Discovery](https:\/\/cloud.ibm.com\/catalog\/services\/watson-discovery). Then, when a user asks a question, it has Discovery search for multiple relevant documents and then it generates a natural-language answer that uses the contents of those documents. In some cases, the answer might be taken directly from a single document, and in others, the answer can include information from multiple sources that are combined into a single coherent statement. For each query, NeuralSeek returns a single answer and a confidence score. In most cases, it also returns a URL of a document that influenced the answer, which might be one of several documents.\n\nTo set up the extension for NeuralSeek search:\n\n\n\n Set up IBM Watson\u00ae Discovery \n\n\n\n1. You need an instance of [IBM Watson\u00ae Discovery](https:\/\/cloud.ibm.com\/catalog\/services\/watson-discovery). Because NeuralSeek can modify your data as needed to make it more effective, make sure it is not an instance with important data that you are using for other purposes.\n2. In Discovery, create a project and load the documents that you want to use.\n\n\n\n\n\n\n\n Get the NeuralSeek OpenAPI specification and API Key \n\n\n\n1. You also need an instance of [NeuralSeek on IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/neuralseek).\n2. In NeuralSeek, open the Configure page and enter your information in the Discovery instance details section.\n3. On the Integrate page, and click the OpenAPI file link to download the NeuralSeek.json OpenAPI specification file configured for your instance.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-search-extension-neuralseek"},{"document_id":"ibmcld_16364-36153-38148","score":7.7949967,"text":"\nFrom the Conversations tab of the Analyze page, open the Actions filter and select Greet customer. For more information, see [Filtering conversations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversationsanalytics-conversations-filtering).\n\nFilter actions by name\n: You can now find actions more easily. On the Actions page, you can filter actions by name. Click the search icon, then enter a search string. Your list of actions filters to match what you enter.\n\n\n\n\n\n 12 August 2022 \n\nActions templates\n: When creating actions, you can choose a template that relates to the problem you\u2019re trying to solve. Templates help tailor your actions to include items specific to your business need. The examples in each template can also help you to learn how actions work. Actions templates include features such as intents, entities, condition-based responses, synonyms, response validations, and agent fallback. For more information, see [Building actions from a template](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-templates).\n\nChannel name variable\n: The Channel name integration variable lets you add step conditions using these channels: web chat, phone, SMS, WhatsApp, Slack, or Facebook Messenger. For more information, see [Adding conditions to a step](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-step-conditions).\n\n\n\n\n\n 11 August 2022 \n\nAlgorithm version options available in more languages\n: Algorithm version options are now available in Arabic, Czech, and Dutch. This allows you to choose which Watson Assistant algorithm to apply to your future trainings. For more information, see [Algorithm version and training](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).\n\n\n\n\n\n 9 August 2022 \n\nNew API methods\n: The v2 API now supports new Environments and Releases methods:\n\n\n\n* Environments: Retrieve information about the environments associated with an assistant.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_06953-1532-3194","score":7.705744,"text":"\nAlternatively, you can add a generative language service named NeuralSeek between the Watson Discovery and Watson Assistant services. For more information, see [Use NeuralSeek to return polished answers from existing help content](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-tutorial-neuralseek).\n\n\n\n How the assistant calls Discovery \n\nWhen a user asks your assistant a question that triggers a search, the following API request is sent to Discovery if Emphasize the answer is enabled.\n\nThe Emphasize the answer feature is available from instances that are managed by IBM Cloud only.\n\n{\n\"aggregation\": \"\",\n\"sort\": \"\",\n\"count\": 10,\n\"return\": [],\n\"filter\": <custom_filter_specified_in_assistant>\n\"passages\": {\n\"enabled\": \"true\",\n\"fields\": [\n<search_config_body_field_specified_in_assistant>\n],\n\"characters\": 325,\n\"per_document\": true,\n\"max_per_document\": 3,\n\"find_answers\": true,\n\"max_answers_per_passage\": 1\n},\n\"highlight\": false,\n\"spelling_suggestions\": false,\n\"table_results\": {\n\"enabled\": false\n},\n\"suggested_refinements\": {\n\"enabled\": false\n}\n}\nShow more\n\nWhen Emphasize the answer is used (\"find_answers\": true), Discovery rescores and reorders the documents to ensure that documents with the highest-quality answers are returned first.\n\n\n\n\n\n Choosing a project type \n\nIf the Conversational Search project type isn't providing the best answers and you want to understand why, switch to using a Document Retrieval project type.\n\nMost often, the Conversational Search project type is the right choice. You get great results from the start, and when you enable extra features like Emphasize the answer, the answers are clear and concise.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-chat-choose-project"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16258-2570-3569","score":10.051843,"text":"\n[Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps. A panel opens showing the full back and forth between your customer and the assistant, including step interactions. The panel also provides a summary of how many requests there were, how many were recognized, whether search was initiated, and the duration of the conversation.\n\n![Conversation detail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-side.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_16258-1324-3123","score":9.852858,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_03107-5127-7134","score":9.744403,"text":"\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For Facebook integrations, the user_id property is set to the sender ID that Facebook provides in its payload.\n* For Slack integrations, the user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n* For web chat, you can set the value of the user_id property.\n\n\n\nBilling is managed per monthly active user per service instance. If a single user interacts with assistants that are hosted by different service instances that belong to the same plan, each interaction is treated as a separate use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_03042-2711-4616","score":9.631473,"text":"\n{: note}\n\n1. conversation_id (v1 only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\nShow more\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For web chat, you can set the value of the user_id property. For more information, see [Adding user identity information](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid).\n\n\n\n\n\n Handling anonymous users \n\nIf your custom application or assistant interacts with users who are anonymous, you can generate a randomized universally unique ID to represent each anonymous user. For more information about UUIDs, see [RFC 4122](https:\/\/tools.ietf.org\/html\/rfc4122.html).\n\n\n\n* For web chat, if you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user.\n\n\n\n\n\n\n\n\n\n Service API versioning","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-services-information"},{"document_id":"ibmcld_16259-1485-3642","score":8.533648,"text":"\nUnique user is anyone who interacts with your assistant. User ID identifies each user, using a unique label to track the level of service usage. A unique user can have multiple conversations, but a conversation never has more than one unique user.\n\nConversation is a set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back. Conversations can have multiple requests within a single conversation, but a single request doesn't span more than 1 conversation.\n\nRequest is a root-level utterance, such as an initial question or request, that signals the start of a specific flow. A user can initiate multiple requests. Requests are meant to represent the core concepts or topics your users are asking about. A request can have multiple steps within it, for example I want to order a pizza is a request. Delivery\/takeout, Small\/Medium\/Large, Cheese\/Pepperoni\/Mushrooms\/Peppers are all steps within the request of ordering a pizza.\n\n\n\n\n\n Completion and recognition \n\nThe completion and recognition charts provide information about the actions in your assistant.\n\n![Completion and recognition](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-completion-recognition-2.png)\n\n\n\n Completion \n\nCompletion is the measurement of how often users are able to successfully get through all steps of an action.\n\nYour assistant measures when someone reaches the final step of an action. The completion chart provides an overview of all the actions you have built and how many of these are being completed or not.\n\nCompletion is only applicable when a user question or request matched to an action, and the action starts.\n\nOne action can be triggered multiple times, so to better understand individual action performance, click Action completion to understand each action in more detail.\n\n\n\n\n\n Recognition \n\nRecognition is the measurement of how many requests are being recognized by the assistant and routed into starting an action.\n\nThe recognition chart provides you with a view into how many requests are matched to actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-overview"},{"document_id":"ibmcld_03109-5081-6683","score":8.471689,"text":"\nThe Intercom user_id property is the id of the author message object in the Conversation Model that is defined by Intercom.\n\n\n\n* To get the ID, open the channel from a web browser. Open the web developer tools to view the console. Look for author.\n\n\n\nThe full customer ID looks like this: customer_id=intercom_5c499e5535ddf5c7fa2d72b3.\n* For Slack, the customer_id is the user_id prepended with slack_. The Slack user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n\n\n\n* To get the team ID, open the channel from a web browser. Open the web developer tools to view the console. Look for [BOOT] Initial team ID.\n* You can copy the member ID from the user's Slack profile.\n* To get the IDs programmatically, use the Slack API. For more information, see [Overview](https:\/\/api.slack.com\/apis). The full customer ID looks like this: customer_id=slack_T09LVDR7YW4F8K9JNF.\n\n\n\n* For the web chat integration, the service takes the user_id that is passed in and adds it as the customer_id parameter value to the X-Watson-Metadata header with each request.\n\n\n\n\n\n Before you begin \n\nTo be able to delete message data associated with a specific user, you must first associate all messages with a unique customer ID for each user. To specify the customer ID for any messages sent using the \/message API, include the X-Watson-Metadata: customer_id property in your header. For example:\n\ncurl -X POST -u \"apikey:3Df... ...Y7Pc9\"\n--header\n'Content-Type: application\/json'\n'X-Watson-Metadata: customer_id=abc'\n--data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-securing"},{"document_id":"ibmcld_03107-3801-5605","score":7.919631,"text":"\nThe user_id property is specified at the root of the request body, as in this example:\n\n{\n\"input\": {\n\"message_type\": \"text\",\n\"text\": \"I want to cancel my order\"\n},\n\"user_id\": \"my_user_id\"\n}\n\nIn some older SDK versions, the user_id property is not supported as a top-level method parameter. As an alternative, you can specify user_id within the nested context.global.system object.\n\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2messagestateless)\n* [v2 stateful \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in \/message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-plan"},{"document_id":"ibmcld_16262-1662-3650","score":7.9133196,"text":"\nFor user-based plans, this ID is used for billing purposes. For more information, see [User-based plans explained](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-user-based).\n\nThere are two types of context:\n\n\n\n* Global context: context variables that are shared by all skills that are used by an assistant, including internal system variables that are used to manage conversation flow. The global context includes the user ID and other global values such as the time zone and language of the assistant.\n* Skill-specific context: context variables specific to a particular skill, including any user-defined variables needed by your application. Currently, only one skill (named main skill) is supported.\n\n\n\nUser-defined context variables that you specify in a dialog node are part of the user_defined object within the skill context when accessed by using the API. This structure differs from the context structure that appears in the JSON editor in the Watson Assistant user interface. For example, you might specify the following code in the JSON editor:\n\n\"context\": {\n\"my_context_var\": \"this is the value\"\n}\n\nIn the v2 API, you would access this user-defined variable as follows:\n\n\"context\": {\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"my_context_var\": \"this is the value\"\n}\n}\n}\n}\n\nFor more information about how to access context variables by using the API, see the [v2 API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2).\n\n\n\n Example \n\nThe following example shows a stateful \/message request that includes both global and skill-specific context variables; it also uses the options.return_context property to request that the context is returned with the response. This option is applicable only if you are using the stateful message method because the stateless message method always returns the context.\n\n\n\n* Java\n* Python\n* Node\n\n\n\nMessageInputOptions inputOptions = new MessageInputOptions.Builder()","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-api-client-get-context"},{"document_id":"ibmcld_03037-1358-3485","score":7.8106523,"text":"\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing. A skill is effectively a wrapper for a V1 workspace.\n\n\n\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each \/message API call.\n\n\n\n\n\n Enabling user metrics","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-resources"},{"document_id":"ibmcld_16252-3899-5971","score":7.7511687,"text":"\nFor more information about the user_id property, see the API reference documentation:\n\n\n\n* [v2 stateless \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2messagestateless)\n* [v2 stateful \/message](https:\/\/cloud.ibm.com\/apidocs\/assistant-v2\/assistant-v2message)\n\n\n\n\n\n\n\n If the user ID is not specified \n\nIf you are using a custom client application and do not set a user_id value, the service automatically sets it to one of the following values:\n\n\n\n* session_id (v2 API only): A property defined in the v2 API that identifies a single conversation between a user and the assistant. A session ID is provided in \/message API calls that are generated by the built-in integrations. The session ends when a user closes the chat window or after the inactivity time limit is reached.\n\nIf you use the stateless v2 message API, you must specify the session_id with each message in an ongoing conversation (in context.global.session_id).\n* conversation_id (v1 API only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\n\n\n\nFor example, if the same person chats with your assistant on three separate occasions over the same billing period, how you represent that user in the API call impacts how the interactions are billed. If you identify the user interaction with a user_id, it counts as one use. If you identify the user interaction with a session_id, then it counts as three uses (because there is a separate session that is created for each interaction).\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2043823976}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02797-1486-3139","score":10.395741,"text":"\nLet's get started!\n\nBe sure that you have the following prerequisites before you begin:\n\n\n\n* An instance of the App ID service\n* A set of service credentials\n\n\n\n\n\n\n\n Step 1: Configuring your App ID instance \n\nBefore you can start adding attributes for your users, you need to configure your instance of App ID.\n\n\n\n1. In the Identity Providers tab of the service dashboard, enable Cloud Directory. Although this tutorial focuses [Cloud Directory](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cloud-directory), you might also choose to use any of the other IdP's such as [SAML](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-enterprise), [Facebook](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-socialfacebook), [Google](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-socialgoogle), or a [custom provider](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-custom-identity).\n2. In the Cloud Directory > Email Verification tab, enable verification and set Allow users to sign-in to your app without first verifying their email address to Yes.\n3. Optionally, in the Profiles tab, set Change custom attributes from the app to Enabled. This action allows users to update their attributes after they answer your initial questionnaire.\n\n\n\nExcellent! Your dashboard is configured and you're ready to start setting attributes.\n\n\n\n\n\n Step 2: Creating user attributes \n\nWhen your users interact with your questionnaire, you can map their answers to specific attributes, then add those attributes to their file.\n\nYour application is responsible for mapping the answers to the specific attributes that you want to add to the profile.\n\n\n\n1. Update the profile with the attribute.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-tutorial-attributes"},{"document_id":"ibmcld_03042-2711-4616","score":10.103015,"text":"\n{: note}\n\n1. conversation_id (v1 only): A property defined in the v1 API that is stored in the context object of a \/message API call. This property can be used to identify multiple \/message API calls that are associated with a single conversational exchange with one user. However, the same ID is only used if you explicitly retain the ID and pass it back with each request that is made as part of the same conversation. Otherwise, a new ID is generated for each new \/message API call.\nShow more\n\nDesign any custom applications to capture a unique user_id or session_id and pass the information to Watson Assistant. Choose a non-human-identifiable ID that doesn't change throughout the customer lifecycle. For example, don't use a person's email address as the user ID. In fact, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https:\/\/tools.ietf.org\/html\/rfc7230section-3.2).\n\nThe built-in integrations derive the user ID in the following ways:\n\n\n\n* For web chat, you can set the value of the user_id property. For more information, see [Adding user identity information](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid).\n\n\n\n\n\n Handling anonymous users \n\nIf your custom application or assistant interacts with users who are anonymous, you can generate a randomized universally unique ID to represent each anonymous user. For more information about UUIDs, see [RFC 4122](https:\/\/tools.ietf.org\/html\/rfc4122.html).\n\n\n\n* For web chat, if you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user.\n\n\n\n\n\n\n\n\n\n Service API versioning","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-services-information"},{"document_id":"ibmcld_02774-5358-7120","score":10.070528,"text":"\nA user's predefined attributes are empty until their first authentication. Although they're empty, the user is still fully authenticated. You can use their profile ID just as you would someone who has already signed in. For instance, you can modify, search, or delete the profile.\n\n\n\n Before you begin \n\nBefore you get started, you must have the following information:\n\n\n\n* Which identity provider that the user will sign in with.\n* The email of the user that you want to add or their [unique identifier](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregisterpreregister-idp-provide).\n* The [custom attribute](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-profiles) information that you want to assign.\n\n\n\n\n\n\n\n With the GUI \n\nYou can add a future user and their custom attributes by using the GUI.\n\nThe ability to add future users is disabled for the user name and password configuration of Cloud Directory.\n\n\n\n1. Go to the User Profiles tab of the App ID dashboard.\n2. Click Future users. If you already have future users, you see a table with a list of the user's that you already added. To add another user, click Build a profile. If you don't have any users yet, click Get Started. A screen opens.\n3. Enter your user's email.\n4. Select the identity provider that they sign in with from the Identity Provider drop down.\n5. Add custom attributes by entering the information in a JSON object as shown in the following example.\n\n{\n\"food\": \"Pizza\",\n\"preference\": \"Vegetarian\",\n\"points\": \"37\"\n}\n6. Click Save. The table displays and the user is assigned an identifier.\n\n\n\n\n\n\n\n With the API \n\nYou can add a future user and their custom attributes by using the API.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Find your IAM token by running the following command.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-preregister"},{"document_id":"ibmcld_02104-7488-9365","score":10.039329,"text":"\nFor more information about trusted profiles, see [Creating trusted profiles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-trusted-profile).\n\n\n\nIf you have onboarding set to Static and the user selects a trusted profile when they log in the first time, the user is still added to the account.\n5. Then, select the following settings (Optional):\n\n\n\n* Enable for account login?: Enable your IdP references to be used for users to log in to your account. This option is set by default when you first create an IdP reference.\n* Set as the default?: Users can use the default IdP reference URL that you created when you enabled this feature to log in to your account. You can have only one default IdP reference. For all other IdP references that you create, users must use the realm IDs to log in.\n\n\n\n6. Click Create.\n\n\n\nYour IdP reference is now available on the Identity providers list and the realm ID is generated automatically as the value that represents your IAM IdP in IBM Cloud.\n\n\n\n\n\n Logging in with external identity provider credentials \n\nAfter your App ID instance is connected to your IdP, and your App ID instance is integrated with IAM, your users can start logging in to your account. If the IdP reference is set as the default, then you can share the Default IdP URL for your account.\n\nHowever, since you can have only one set as the default, but you can have up to five set up in your account, you might need to get the URL for another IdP reference:\n\n\n\n1. From the Identity provider pages, click the Actions icon ![List of actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/action-menu-icon.svg) for the row of the IdP reference you need a URL for.\n2. Select View IdP URL.\n3. Copy the IdP URL link to give to users to log in.\n\n\n\n\n\n\n\n Using App ID instances to build dynamic rules in access groups","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-idp-integration"},{"document_id":"ibmcld_11608-0-1212","score":9.821355,"text":"\n\n\n\n\n\n\n  Necessary account credentials for SAP and IBM Cloud \n\nUse the following steps to obtain account credentials for SAP and IBM Cloud.\n\n\n\n  SAP credentials and accounts for new users \n\n\n\n1.  To set up an SAP ID account, follow the instructions on the [SAP Support Portal Home](https:\/\/support.sap.com\/en\/my-support\/users.html).\n\n\n\n\n\n\n\n  IBM Cloud credentials and accounts for new users \n\n\n\n1.  Go to [Getting started with IBM Cloud](https:\/\/www.ibm.com\/cloud\/get-started) and click Create a free account.\n\nAn email is sent from IBM Cloud Support that contains your verification code, from which you can create your initial login ID and password.\n2.  Set up your [profile](https:\/\/cloud.ibm.com\/docs\/account?topic=account-usersettingsprofile-photo) to log in as a new user.\n\n\n\nFor more information, see [Signing up for IBM Cloud](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started).\n\n\n\n1.  After you receive your login credentials and have access to your IBM Cloud account, you can create other accounts and users. See [IAM Best practices for assigning access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account_setup) to learn more about assigning access to IBM Cloud.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-necessary-credentials"},{"document_id":"ibmcld_02746-7454-8167","score":9.787156,"text":"\n\"user_id\" : \"356e065e-49da-45f6-afa3-091a7b464f51\"\n}\n\n\n\n\n\n\n\n Policy: Ensure that the password does not include user name \n\nFor stronger passwords, you might want to prevent users from creating a password that contains their username or the first part of their email address.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. Toggle Advanced password policy to Enabled.\n3. Toggle Password should not contain user ID to Enabled.\n4. Click Save.\n\n\n\nThis constraint is not case-sensitive. Users are not able to alter the case of some or all the characters to use the personal information. To configure this option, toggle the switch to on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength"},{"document_id":"ibmcld_02797-7-1882","score":9.674108,"text":"\nCustomizing your user experience \n\nIn a world with everything at our finger tips, people expect their experiences to be tailored to them. Whether we're having an in-person conversation or shopping online, we want to see only the things that apply to us. By using this step-by-step guide, you can learn how to harness the power of user attributes and really capture your users attention with App ID.\n\n\n\n Scenario \n\nYou're a developer for an online retailer, with a specialization in food. You're tasked with creating a personalized experience for your app users. You decide to focus your efforts on creating targeted advertising based on things that you know about your users. So, when a user signs up for your app, you ask them a few questions with answers that they can choose from. For example, you might ask the following question:\n\nDo you have any dietary preferences?\n\n\n\n* I'm a vegetarian.\n* I'm a pescatarian.\n* I'm dairy-free.\n* I'm gluten-free.\n* I'm low carb.\n\n\n\nYou can then map their answers to [specific attributes](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-profiles) that you can use to target the advertising that they're shown.\n\nAlthough this tutorial is written for web apps that use Cloud Directory, attributes can be used in a much broader sense. Custom attributes can be anything that you want them to be! If you stay under 100k attributes and you format them as a plain JSON object, you can store all types of information.\n\n\n\n\n\n Before you begin \n\nReady? Let's get started!\n\nBe sure that you have the following prerequisites before you begin:\n\n\n\n* An instance of the App ID service\n* A set of service credentials\n\n\n\n\n\n\n\n Step 1: Configuring your App ID instance \n\nBefore you can start adding attributes for your users, you need to configure your instance of App ID.\n\n\n\n1. In the Identity Providers tab of the service dashboard, enable Cloud Directory.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-tutorial-attributes"},{"document_id":"ibmcld_02855-25179-26743","score":9.595882,"text":"\nfunction mockLogin() {\nconst payload = {\n\/\n* Even if this is an unauthenticated user, add a userID in the sub claim that can be used\n* for billing purposes.\n* This ID will help us keep track \"unique users\". For unauthenticated users, drop a\n* cookie in the browser so you can make sure the user is counted uniquely across visits.\n\/\nsub: 'some-user-id', \/\/ Required\niss: 'yourdomain.com' \/\/ Required\n};\n\/\/ The \"expiresIn\" option adds an \"exp\" claim to the payload.\nreturn jwt.sign(payload, process.env.YOUR_PRIVATE_RSA_KEY, { algorithm: 'RS256', expiresIn: '10000ms' });\n}\nShow more\n\n\n\nTo enable security, complete the following steps:\n\n\n\n1. From the web chat integration page in Watson Assistant, set the Secure your web chat switch to On.\n2. Add your public key to the Your public key field.\n\nThe public key that you add is used to verify that data which claims to come from your web chat instance is coming from your web chat instance.\n3. To prove that a message is coming from your website, each message that is submitted from your web chat implementation must include the JSON Web Token (JWT) that you created earlier.\n\nAdd the token to the web chat code snippet that you embed in your website page. Specify the token in the identityToken property.\n\nFor example:\n\n<script>\nwindow.watsonAssistantChatOptions = {\nintegrationID: 'YOUR_INTEGRATION_ID',\nregion: 'YOUR_REGION',\nserviceInstanceID: 'YOUR_SERVICE_INSTANCE',\nidentityToken: 'YOUR_JWT',\nonLoad: function(instance) {\ninstance.render();\n}\n};\nsetTimeout(function(){\nconst t=document.createElement('script');","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-web-chat"},{"document_id":"ibmcld_02734-3347-4762","score":9.592718,"text":"\nThe user interacts with areas of your app that do not require authentication.\n2. Your application notifies App ID that the user wants to interact with your app as an anonymous user.\n3. App ID creates an ad hoc user profile and calls the OAuth login that issues anonymous tokens for the anonymous user.\n4. Using the anonymous tokens from App ID, you can create, read, update, and delete the attributes that are stored in the anonymous user profile.\n5. The user might choose to sign in to access more features of your app.\n6. Your application notifies App ID that the user wants to interact with your app as an identified user.\n7. App ID returns the login widget to your app.\n8. The user selects their preferred identity provider and provides their credentials.\n9. Your application informs App ID that the user selected an identity provider.\n10. App ID authenticates the call with the identity provider.\n11. The identity provider confirms whether the login was successful.\n12. App ID uses the anonymous token to find the anonymous profile and attaches the user's identity to it.\n13. After App ID creates the new tokens, the service invalidates the user's anonymous token.\n14. App ID returns the new access and identity tokens. The new tokens contain the public information that is shared by the identity provider and the attributes of the user's formerly anonymous profile.\n15. The user is granted access to your app.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-anonymous"},{"document_id":"ibmcld_11474-5244-7072","score":9.57831,"text":"\nOpen the App ID instance page from the [resource list](https:\/\/cloud.ibm.com\/resources) Services and software section.\n2. Go to Manage Authentication \u2192 Cloud Directory \u2192 Users, and click Create User. Enter the user details.\n\n\n\n\n\n\n\n Step 6: Create or modify users' project assignments \n\nIf the IDP administrator will assign users to projects, you can define project values in the user's attributes.\n\n\n\n1. Open the App ID instance page from the [resource list](https:\/\/cloud.ibm.com\/resources) Services and software section.\n2. Go to Manage Authentication \u2192 Cloud Directory \u2192 Users, and click a user to open it.\n3. Scroll down to Custom Attributes, and click Edit.\n4. Enter a key value pair that can will checked by the dynamic rules of the access groups, then click Save. You can add several values in the same string (for example, {\"project\":\"ml finance\"}); the contains qualifier of the dynamic rule detects a match of a substring. For our example, add:\n\n{\"project\":\"ml\"}\n\nThe value project corresponds to the convention defined in the planning section. ml is the project that the user belongs to.\n\nThis check is done on every login, so changes in the ID provider user attributes will be effective when a user next logs in.\n\n\n\n\n\n\n\n User flow \n\n\n\n1. A user is sent the ID provider URL for the IBM Cloud account.\n\nThe administrator can always go to [Manage \u2192 Access (IAM) \u2192 Identity providers](https:\/\/cloud.ibm.com\/iam\/identity-providers) to look up the ID provider URL.\n2. To work with Qiskit Runtime serive instances, users must create an API key by going to ([Manage \u2192 Access (IAM) \u2192 API keys](https:\/\/cloud.ibm.com\/iam\/apikeys)).\n3. For further information, users can review [Getting started, Step 2](https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-get-startedinstall-packages).\n\n\n\n\n\n\n\n Example scenario","title":"","source":"https:\/\/cloud.ibm.com\/docs\/quantum-computing?topic=quantum-computing-appid-org"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1772392868}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02746-7-1681","score":11.720292,"text":"\nDefining password policies \n\nPassword policies, such as strength requirements, help you to enforce more secure applications. By defining advanced policies, you can define the rules that a user must conform to when they set their password or attempt to sign in to your app. For example, you can set the number of times that a user can try to sign in before they are locked out of their account.\n\n\n\n Policy: password strength \n\nA strong password makes it difficult, or even improbable for someone to guess the password in either a manual or automated way. To set requirements for the strength of a user's password, you can use the following steps.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. In the Define password strength box, click Edit. A screen opens.\n3. Enter a valid regex string in the Password strength box.\n\nExamples:\n\n\n\n* Must be at least 8 characters. (^.{8,}$)\n* Must have one number, one lowercase letter, and one capital letter. (^(?:(?=.d)(?=.[a-z])(?=.[A-Z]).)$)\n* Must have only English letters and numbers. (^[A-Za-z0-9]$)\n* Must have at least one unique character. (^(w)w?(?!1)w+$)\n\n\n\n4. Click Save.\n\n\n\nPassword strength can be set in the Cloud Directory settings page in the App ID dashboard, or by using [the management APIs](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Management%20API%20-%20Config\/mgmt.set_cloud_directory_password_regex).\n\n\n\n Setting a custom error message \n\nIf you set your own password regex policy and a user chooses a password that does not meet your requirements, the default message is The password doesn't meet the strength requirements.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength"},{"document_id":"ibmcld_02746-1213-3197","score":10.967993,"text":"\nPassword strength can be set in the Cloud Directory settings page in the App ID dashboard, or by using [the management APIs](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Management%20API%20-%20Config\/mgmt.set_cloud_directory_password_regex).\n\n\n\n Setting a custom error message \n\nIf you set your own password regex policy and a user chooses a password that does not meet your requirements, the default message is The password doesn't meet the strength requirements. You can also choose to set your own message by using the [\/management\/v4\/{tenantId}\/config\/cloud_directory\/password_regex endpoint](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Management%20API%20-%20Config\/mgmt.set_cloud_directory_password_regex).\n\n\n\n\n\n\n\n Advanced password policies \n\nYou can enhance the security of your application by enforcing password constraints.\n\nYou can create an advanced password policy that consists of any combination of the following five features:\n\n\n\n* Lockout after repeated wrong credentials\n* Avoid password reuse\n* Password expiration\n* Minimum period between password changes\n* Ensure that the password does not include user name\n\n\n\nWhen you enable this feature, extra billing for advanced security capabilities is activated. For more information, see [how does App ID calculate pricing](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-pricing).\n\n\n\n Policy: Avoid Password Reuse \n\nYou might want to prevent your users from choosing a recently used password when they attempt to create a new one. If they try to set their password to one that was recently used, an error is shown in the default Login Widget GUI and the user is prompted to enter another option. This setting allows for you to choose the number of passwords that a user must have before they're able to repeat a previously used password.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. Toggle Advanced password policy to Enabled.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength"},{"document_id":"ibmcld_02746-7454-8167","score":10.840393,"text":"\n\"user_id\" : \"356e065e-49da-45f6-afa3-091a7b464f51\"\n}\n\n\n\n\n\n\n\n Policy: Ensure that the password does not include user name \n\nFor stronger passwords, you might want to prevent users from creating a password that contains their username or the first part of their email address.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. Toggle Advanced password policy to Enabled.\n3. Toggle Password should not contain user ID to Enabled.\n4. Click Save.\n\n\n\nThis constraint is not case-sensitive. Users are not able to alter the case of some or all the characters to use the personal information. To configure this option, toggle the switch to on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength"},{"document_id":"ibmcld_07765-0-1628","score":10.1594095,"text":"\n\n\n\n\n\n\n  IA-5 (4) - Automated Support for Password Strength Determination \n\n\n\n  Control requirements \n\nIA-5 (4) - 0\n:   The organization employs automated tools to determine if password authenticators are sufficiently strong to satisfy [Assignment: organization-defined requirements].\n\n\n\n\n\n  IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n*  Check whether App ID advanced password policies are enabled\n*  IBMid employs automated tools to determine if password authenticators satisfy IBMid password requirements\n*  Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n*  Check whether App ID password strength regex is configured\n*  Check whether IBMid password policy policy contains spaces or any of the following characters: ;:(\"?)<>\n*  Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters\n*  Check whether IBMid password policy requires at least one uppercase letter\n*  Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nThis control enhancement focuses on the creation of strong passwords and the characteristics of such passwords (e.g., complexity) prior to use, the enforcement of which is carried out by organizational information systems in IA-5 (1).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5.4"},{"document_id":"ibmcld_02775-4830-5961","score":9.204025,"text":"\nFor a complete list of the options and setup information, see [Advanced password management](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strengthcd-advanced-password). \n\n\n\nThese features are available only to those instances that are on the graduated tier pricing plan and that were created after 15 March 2018.\n\n\n\n\n\n When am I charged? \n\nYour first 1000 authentication events and 1000 authorized users per service instance are free of charge. You are charged monthly for any additional authentication events and authorized users, as well as any advanced security features that are enabled for each service instance.\n\n\n\n\n\n How do I stop getting charged for App ID? \n\nIf you no longer want to be charged for authentication events and authorized users, you need to ensure that no user can authenticate by using App ID. You must remove the App ID configuration from your app code or confirm that your users are not able to use the configuration to log in to your app. To stop getting charged for advance security features, you must disable them on the Manage Authentication > Authentication Settings page of the service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-pricing"},{"document_id":"ibmcld_02746-2715-4757","score":9.080812,"text":"\nIf they try to set their password to one that was recently used, an error is shown in the default Login Widget GUI and the user is prompted to enter another option. This setting allows for you to choose the number of passwords that a user must have before they're able to repeat a previously used password.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. Toggle Advanced password policy to Enabled.\n3. Specify The number of times that a password can't be repeated. You can use any whole value in range 1 - 8.\n4. Toggle The number of times that a password can't be repeated to Enabled.\n5. Click Save.\n\n\n\nPrevious passwords are securely stored in the same way that a user's current password is stored.\n\n\n\n\n\n Policy: Lockout after repeated wrong credentials \n\nYou might want to protect your users' accounts by temporarily blocking the ability to sign in when a suspicious behavior is detected, such as multiple consecutive sign-in attempts with an incorrect password. This measure can help to prevent a malicious party from gaining access to a user's account by guessing their password.\n\nIf an account is locked, users are unable to sign in or complete any other self-service operations until the specified lockout period is complete. When the lockout period is over, the user is automatically unlocked.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. Toggle Advanced password policy to Enabled.\n3. Specify The number of times a user can try to sign in before getting locked out. You can use any whole value in range 1 - 10.\n4. Specify The time a user will be locked out after trying to sign in with wrong credentials. The time is specified in minutes. You can use any whole value in range 1 - 1440 (24 hours).\n5. Toggle The number of times a user can try to sign in before getting locked out row to Enabled.\n6. Click Save.\n\n\n\nYou can unlock a user before the lockout period is over.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength"},{"document_id":"ibmcld_07761-2352-4487","score":8.512913,"text":"\nIA-5 (c) <br><br> * Check whether App ID advanced password policies are enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID prevent username in password policy is enabled<br> * Check whether App ID password strength regex is configured<br> * Check whether OpenShift cluster has image pull secrets enabled<br> * IBM Cloud IAM ensures that authenticators, such as API keys, have sufficient strength for their intended use<br> * Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters<br> * Check whether App ID avoid password reuse policy is enabled<br> * IBMid ensures that passwords have sufficient strength for their intended use<br><br><br> \n IA-5 (f) <br><br> * Check whether App ID minimum period between password changes policy is set to greater than 0<br> * IBM Cloud IAM establishes minimum and maximum lifetime restrictions and reuse conditions for authenticators, such as API keys<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * Check whether App ID lockout policy after failed # of sign-in attempts is enabled<br> * IBMid establishes minimum and maximum lifetime restrictions and reuse conditions for authenticators<br> * Check whether App ID avoid password reuse policy is enabled<br><br><br> \n IA-5 (g) <br><br> * Check whether Secrets Manager user credentials are rotated at least every # days<br> * Check whether Secrets Manager arbitrary secrets are rotated at least every # days<br> * Check whether Hyper Protect Crypto Services encryption keys that are generated by the service are rotated automatically at least every # months<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nIndividual authenticators include, for example, passwords, tokens, biometrics, PKI certificates, and key cards. Initial authenticator content is the actual content (e.g., the initial password) as opposed to requirements about authenticator content (e.g., minimum password length).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5"},{"document_id":"ibmcld_02779-11079-12973","score":8.444832,"text":"\n: Require users to enter a second form of authentication during sign-in to increase the security of your app. With Cloud Directory, the first factor is the user's password that they would normally use. Then, the service sends the user a one-time code through SMS that the user must enter before they can gain access to your app. For more information, see [Multi-factor authentication](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-mfa).\n\n\n\n\n\n 11 December 2018 \n\nCloud Directory: Multi-factor authentication - Email\n: Require users to enter a second form of authentication during sign-in to increase the security of your app. With Cloud Directory, the first factor is the user's password that they would normally use. Then, the service sends the user a one-time code through the email that is registered that the user must enter before they can gain access to your app. For more information, see [Multi-factor authentication](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-mfa).\n\nCloud Directory: Password policies\n: Further enforce app security by specifying rules that users must adhere to when they create the password that they use to sign in. For example, you can set an advanced policy that dictates the number of times a password must change before a user can reuse a previous password. Or, you can prevent users from creating a password that contains their username or email address. For more information, see [Defining password policies](https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-strength).\n\n\n\n\n\n 17 March 2017 \n\nIntroducing App ID\n: IBM Cloud App ID allows you to easily add authentication to web and mobile apps. You no longer have to worry about setting up infrastructure for identity, ensuring geo-availability, and confirming compliance regulations. Instead, you can enhance your apps with advanced security capabilities like multifactor authentication and single sign-on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-release-notes"},{"document_id":"ibmcld_09120-36418-37514","score":8.440224,"text":"\n\"id\": \"8480e26f-3add-4fff-bca7-8cf908894b7c\",\n\"name\": \"credentials-key\",\n\"type\": \"application\/vnd.ibm.kms.key+json\",\n\"algorithmType\": \"AES\",\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-08-18T16:13:08Z\",\n\"lastUpdateDate\": \"2020-08-18T16:13:08Z\",\n\"extractable\": true,\n\"payload\": \"ewoJImhvc3QiOiAibG9jYWxob3N0IiwKCSJkYXRhYmFzZSI6ICJkZXYtYmFja3VwIiwKCSJ1c2VybmFtZSI6ICJteS11c2VybmFtZSIsCgkicGFzc3dvcmQiOiAibXktcGFzc3dvcmQiCn0=\",\n\"state\": 1,\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:key:8480e26f-3add-4fff-bca7-8cf908894b7c\",\n\"deleted\": false,\n\"dualAuthDelete\": {\n\"enabled\": false\n}\n}\n\n decode the payload to get the original string (credentials)\n$ echo $PAYLOAD | base64 -d\n\n{\n\"host\": \"localhost\",\n\"database\": \"dev-backup\",\n\"username\": \"my-username\",\n\"password\": \"my-password\"\n}\n\n\n\n\n\n Example 7 \n\nCreate a root key with an alias, then use that alias to identify the key to show the key details.\n\n create a root key with an alias\n$ ibmcloud kp key create root-key-with-alias -a example-alias --output json\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference"},{"document_id":"ibmcld_08987-35098-36194","score":8.440224,"text":"\n\"id\": \"8480e26f-3add-4fff-bca7-8cf908894b7c\",\n\"name\": \"credentials-key\",\n\"type\": \"application\/vnd.ibm.kms.key+json\",\n\"algorithmType\": \"AES\",\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-08-18T16:13:08Z\",\n\"lastUpdateDate\": \"2020-08-18T16:13:08Z\",\n\"extractable\": true,\n\"payload\": \"ewoJImhvc3QiOiAibG9jYWxob3N0IiwKCSJkYXRhYmFzZSI6ICJkZXYtYmFja3VwIiwKCSJ1c2VybmFtZSI6ICJteS11c2VybmFtZSIsCgkicGFzc3dvcmQiOiAibXktcGFzc3dvcmQiCn0=\",\n\"state\": 1,\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:key:8480e26f-3add-4fff-bca7-8cf908894b7c\",\n\"deleted\": false,\n\"dualAuthDelete\": {\n\"enabled\": false\n}\n}\n\n decode the payload to get the original string (credentials)\n$ echo $PAYLOAD | base64 -d\n\n{\n\"host\": \"localhost\",\n\"database\": \"dev-backup\",\n\"username\": \"my-username\",\n\"password\": \"my-password\"\n}\n\n\n\n\n\n Example 7 \n\nCreate a root key with an alias, then use that alias to identify the key to show the key details.\n\n create a root key with an alias\n$ ibmcloud kp key create root-key-with-alias -a example-alias --output json\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"1dcbbeb35d4d25ba1ffb787a9f2080e2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03363-6198-7991","score":12.208048,"text":"\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter. In each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.\n\nThe time shown for each conversation is localized to reflect the time zone of your browser. However, API log calls are always shown in UTC time. As a result, if you choose a single day view, for example, the time shown in the visualization might differ from the timestamp specified in the log for the same conversation.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-time2.png)\n* Intents and Entities filters - Use either of these drop-down filters to show data for a specific intent or entity in your skill.\n\nThe intent and entities filters are populated by the intents and entities in the skill, and not what is in the data source. If you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03354-4-1897","score":11.674161,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Improve your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nThe length of time for which messages are retained depends on your Watson Assistant service plan:\n\nService plan | Chat message retention\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs"},{"document_id":"ibmcld_16258-1324-3123","score":10.729814,"text":"\n[Time period](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-conversations"},{"document_id":"ibmcld_09774-3357-5415","score":10.625065,"text":"\nFor example, metric data for an instance that is provisioned in US South is hosted in the US South region.\n\n\n\n\n\n\n\n Data retention \n\nData is retained for each instance based on a roll-up policy.\n\nAs time progresses, the data is rolled up from a fine granularity to a coarser one by the end 2 months.\n\nThe roll-up policy describes the granularity of the data over time:\n\n\n\n* Data is retained at 10-second resolution for the first 4 hours.\n* Data is retained at 1-minute resolution for 2 days.\n* Data is retained at 10-minute resolution for 2 weeks.\n* Data is retained at 1-hour resolution for 2 months.\n* Data is retained at 1-day resolution for 15 months.\n\n\n\n\n\n\n\n Data availability \n\nData is available for a maximum of 15 months.\n\nUser metadata is always available.\n\nAfter you remove a monitoring agent from a host or container, historical data is not deleted.\n\n\n\n* Data is available for a maximum of 15 months.\n* Data is available for analysis through the web UI for the time period that the agent was installed and reporting.\n\n\n\nAfter you delete an instance of the IBM Cloud Monitoring service, data is not available for search and analysis.\n\n\n\n\n\n\n\n Deleting your data \n\n\n\n Deleting metric data \n\nMetric data is deleted automatically after 15 months.\n\n\n\n\n\n Deleting user metadata \n\nUser metadata, such as alerts, dashboards, teams, and users, is never deleted.\n\nYou must open a case through support to request the metadata to be deleted. For more information, see [Open a support ticket](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case).\n\n\n\n\n\n Deleting a subset of data \n\nDeletion of a subset of data is not supported.\n\nFor example, deletion of data that is collected from 1 monitoring agent in a Monitoring instance is not supported.\n\n\n\n\n\n Deleting captures \n\nWhen you delete a capture, the data file for that capture is automatically deleted.\n\n\n\n\n\n Deleting an IBM Cloud Monitoring instance \n\nWhen you delete an instance of IBM Cloud Monitoring from the IBM Cloud, you must open a case through support to request the data to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-mng-data"},{"document_id":"ibmcld_09994-5971-8165","score":10.450322,"text":"\nThe retention start timestamp is the larger of the following values:\n\n\n\n* The beginning of the retention time period (the current date\/time minus the retention interval).\n* The retention lower bound.\n\n\n\nA table\u2019s retention start timestamp comes into play in the following operations:\n\n\n\n* Time travel queries (SELECT and sub-SELECT)\n\nIf you attempt to run queries for historical rows that were deleted before the retention start timestamp, an error is returned.\n\nIf you want to query historical data as far back as possible, you can use the RETENTION_START_TIMESTAMP keyword in time travel queries. If you do this, you can avoid having to try to compute the right timestamp on your own. By extension, you eliminate the risk of running into an error if the value turns out to be too old (older than the retention start timestamp).\n* GROOM TABLE Historical rows that were deleted before the retention start timestamp are no longer needed for time travel queries and can be reclaimed.\n\n\n\n\n\n\n\n Row timestamps and validity \n\nThe insert timestamp of a current or historical row is the date\/time that the transaction inserting the row committed. It is not the time when a particular INSERT, UPDATE, or MERGE statement that inserted the row was run.\n\nIf the inserting transaction for a row committed before the retention start timestamp, the row is treated as having been inserted at the retention start timestamp. This generally applies only to existing rows at the time of altering a nontemporal table to a temporal table.\n\nAn inserted row whose transaction has not yet committed does not have an insert timestamp. Such a row will never be visible to a time travel query.\n\nIn a time travel query, you can select the insert timestamp by using the _SYS_START virtual column of a temporal table.\n\nThe delete timestamp of a historical row is the date\/time that the transaction deleting the row committed. It is not the time when a particular DELETE, UPDATE, MERGE, or TRUNCATE statement that deleted the row was run.\n\nIf a temporal table is truncated, the existing table rows are available to time travel queries and are treated as having been deleted as of the time the truncating transaction committed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-runningqueries_tt"},{"document_id":"ibmcld_09956-1678-3537","score":10.404825,"text":"\nTo view DATA_VERSION_RETENTION_TIME for a specific object, run one of these commands. The commands display DATA_VERSION_RETENTION_TIME only if it is a nonzero value.\n\nd <table_name>\n\nSHOW SCHEMA <schema_name>\n\nl+ <all databases, with detail>\n\nRetention time interval and retention lower bound for an object are available in the dataverretntime and dataverretnlowerbound columns of the following system views:\n\n\n\n* _v_table\n* _v_schema\n* _v_database\n\n\n\n\n\n\n\n\n\n Viewing the retention time interval with the web console \n\n\n\n Viewing the default retention time interval for the system with the web console \n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. Go to Databases. The retention time interval for the system is displayed in the Retention time interval section at the top of the page.\n\n\n\n\n\n\n\n Viewing the retention time interval for tables, schemas, and databases with the web console \n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-getstarted-console).\n2. View the retention time interval:\n\n\n\n* For a table:\n\n\n\n\n\n1. Go to Databases.\n2. Select the database and schema in which the table that you want to view the retention interval is located.\n3. Ensure that you are in the DB Objects > Tables tab.\n4. Identify the table for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.\n\n\n\n\n\n* For a schema:\n\n\n\n\n\n1. Go to Databases.\n2. Select the database in which the schema that you want to view the retention interval is located.\n3. Identify the schema for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-dataretentioninterval_tt"},{"document_id":"ibmcld_09956-3082-3744","score":10.382477,"text":"\nIdentify the table for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.\n\n\n\n\n\n* For a schema:\n\n\n\n\n\n1. Go to Databases.\n2. Select the database in which the schema that you want to view the retention interval is located.\n3. Identify the schema for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.\n\n\n\n\n\n* For a database:\n\n\n\n\n\n1. Go to Databases.\n2. Identify the database for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-dataretentioninterval_tt"},{"document_id":"ibmcld_05032-3142-5463","score":10.353184,"text":"\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-3142-5463","score":10.353184,"text":"\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_09956-7-2100","score":10.343438,"text":"\nManaging the default retention time interval for the system and viewing retention time intervals \n\nBefore you set retention time interval for all tables in a schema or database, consider the cost of storage for temporal tables, which could be significant. See [Managing time travel space usage](https:\/\/cloud.ibm.com\/docs\/docs\/netezza?topic=netezza-managing_tt).\n\n\n\n Setting the retention time interval for the system \n\nTo set the default DATA_VERSION_RETENTION_TIME to a specific value for the system, run the SET SYSTEM DEFAULT command.\n\nBefore you set DATA_VERSION_RETENTION_TIME for all tables in a schema or database, consider the cost of storage for temporal tables, which could be significant. See [Managing time travel space usage](https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-managing_tt).\n\nSET SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME TO <NUMBER OF DAYS>\n\nExample:\n\nSET SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME TO 30\n\nThe value of the property at the system level determines the default value inherited by a subsequent CREATE DATABASE statement that does not explicitly specify this property.\n\nTo set DATA_VERSION_RETENTION_TIME for a specific object, you can run the ALTER or CREATE command.\n\n\n\n\n\n Viewing the retention time interval with the command-line \n\n\n\n Viewing the default retention time interval for the system with the command-line \n\nTo view DATA_VERSION_RETENTION_TIME for the system, run the SHOW SYSTEM DEFAULT command.\n\nSHOW SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME\n\nIf you did not set the retention time previously, the default is 0.\n\n\n\n\n\n Viewing the retention time interval for tables, schemas, and databases with the command-line \n\nTo view DATA_VERSION_RETENTION_TIME for a specific object, run one of these commands. The commands display DATA_VERSION_RETENTION_TIME only if it is a nonzero value.\n\nd <table_name>\n\nSHOW SCHEMA <schema_name>\n\nl+ <all databases, with detail>\n\nRetention time interval and retention lower bound for an object are available in the dataverretntime and dataverretnlowerbound columns of the following system views:\n\n\n\n* _v_table","title":"","source":"https:\/\/cloud.ibm.com\/docs\/netezza?topic=netezza-dataretentioninterval_tt"}],"retriever_scores":{"recall_1":0.2,"recall_3":0.2,"recall_5":0.2,"recall_10":0.2,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.3391602053,"ndcg_cut_10":0.3391602053}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16481-3559-5682","score":9.628049,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16417-3559-5683","score":9.625923,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16464-13891-15856","score":9.079096,"text":"\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16410-8324-10312","score":8.288632,"text":"\nInter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set.\n\nYou cannot change the annotation set name after the set is created.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.\n* Open a task to add annotation sets to it. Ensure that the annotation sets that you add include documents that overlap with documents in the original annotation sets.\n\n\n\nFrom the Settings tab of the main navigation, you can specify the following information:\n\n\n\n* Specify preferences for using colors and keyboard shortcuts in the ground truth editor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_16417-5155-7505","score":7.827393,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-5154-7504","score":7.827393,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16417-1764-4158","score":7.6567516,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-1764-4158","score":7.6567516,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16563-12333-14196","score":7.5899353,"text":"\nThe IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16410-13218-15390","score":7.4744143,"text":"\nTo compare how different human annotators annotated the same documents, specify an evaluation threshold. If the annotations made by one human annotator differ from the annotations made by another human annotator to the point where the difference results in a low score, it means that the annotators do not agree. The disagreement needs to be investigated and resolved.\n\n\n\n\n\n Procedure \n\nTo set the inter-annotator agreement threshold:\n\n\n\n1. Log in as a Knowledge Studio administrator, and select your workspace.\n2. Select the Settings > IAA Settings tab.\n3. Specify a value between 0 and 1, such as .5 or .8, and then click Save.\n\n\n\n\n\n\n\n\n\n Connecting to annotation guidelines \n\nAfter you create annotation guidelines for your project, you can configure Knowledge Studio to connect to them. For help with choosing the correct annotation to apply, human annotators can review the guidelines while annotating documents. Administrators can also review the guidelines if they need assistance while resolving annotation conflicts in overlapping documents.\n\n\n\n Procedure \n\nTo connect the ground truth editor and adjudication tool to your annotation guidelines:\n\n\n\n1. Log in as a Knowledge Studio administrator, and select your workspace.\n2. select the Settings > Annotation Guidelines tab.\n3. Specify the URL to where your guidelines are hosted.\n4. Click Save. The system connects the ground truth editor and adjudication tool to your annotation guidelines. Depending on the access permissions granted to users when you created the guidelines, human annotators and workspace administrators might be able to update the guidelines after opening them, for example, to add clarifications and examples.\n\n\n\n\n\n\n\n Annotation guidelines \n\nThere is no prescribed format for how to document the guidelines, but it is important that the guidelines include detailed examples. Human annotators need to understand which entity type to apply to a mention given the context, and know which relation types are valid for a given pair of mentions. Examples drawn from your domain content are often the best way to convey the correct annotation choices to make.\n\nAnnotation guidelines are not static.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16410-8324-10312","score":14.58718,"text":"\nInter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set.\n\nYou cannot change the annotation set name after the set is created.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.\n* Open a task to add annotation sets to it. Ensure that the annotation sets that you add include documents that overlap with documents in the original annotation sets.\n\n\n\nFrom the Settings tab of the main navigation, you can specify the following information:\n\n\n\n* Specify preferences for using colors and keyboard shortcuts in the ground truth editor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_16468-8522-10510","score":13.971008,"text":"\nIf no annotation sets are available, click Create Annotation Sets.\n\n\n\n1. For the base set, select the document set or annotation set that you want to divide into annotation sets.\n2. For the overlap value, specify the percentage of documents that you want to include in each annotation set. Inter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set. You cannot change the annotation set name after the set is created.\n\nThe maximum size of the annotation set name is 256 characters.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_16464-13891-15856","score":12.651911,"text":"\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16563-12333-14196","score":12.182944,"text":"\nThe IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16464-12399-14287","score":12.008651,"text":"\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16417-5155-7505","score":11.863407,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-5154-7504","score":11.863407,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16410-6875-8784","score":11.856681,"text":"\nTo add an annotation set in one task to a different task, you must first delete the task where the annotation set is active.\n* If you delete a human annotator's user account, it affects their annotations too. Any annotations in documents that were assigned to that user but were not promoted to ground truth are deleted.\n* If the type system or ground truth editor settings change after you create a human annotation task, you must decide whether to propagate the changes to the task. Type system changes can affect annotations; human annotators might need to review and update their documents.\n* If the dictionaries change, the changes are not reflected in the current annotation task. To apply resource changes to ground truth, you must create a new annotation task.\n* You can have up to 256 annotation tasks per workspace.\n\n\n\n\n\n\n\n\n\n Procedure \n\nTo create an annotation task:\n\n\n\n1. Log in as a Knowledge Studio administrator, and select your workspace.\n2. Select the Machine Learning Model > Annotations page, then click the Annotation Tasks tab.\n3. Click Add Task.\n4. Specify a descriptive task name and select the date that the task must be completed.\n5. If no annotation sets are available, click Create Annotation Sets.\n\n\n\n1. For the base set, select the document set or annotation set that you want to divide into annotation sets.\n2. For the overlap value, specify the percentage of documents that you want to include in each annotation set. Inter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_16464-10867-12930","score":11.834373,"text":"\n[This screen capture shows two mentions connected by the relation type, \"founderOf\".](images\/wks_tut_annotaterelation.png \"This screen capture shows two mentions connected by the relation type, \"founderOf\".\")\n\n\n\n8. From the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\n> Note: In a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16481-3559-5682","score":11.77065,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16481-3559-5682","score":13.823969,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16417-3559-5683","score":13.812691,"text":"\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16410-8324-10312","score":13.738137,"text":"\nInter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set.\n\nYou cannot change the annotation set name after the set is created.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.\n* Open a task to add annotation sets to it. Ensure that the annotation sets that you add include documents that overlap with documents in the original annotation sets.\n\n\n\nFrom the Settings tab of the main navigation, you can specify the following information:\n\n\n\n* Specify preferences for using colors and keyboard shortcuts in the ground truth editor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_16468-8522-10510","score":13.176704,"text":"\nIf no annotation sets are available, click Create Annotation Sets.\n\n\n\n1. For the base set, select the document set or annotation set that you want to divide into annotation sets.\n2. For the overlap value, specify the percentage of documents that you want to include in each annotation set. Inter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set. You cannot change the annotation set name after the set is created.\n\nThe maximum size of the annotation set name is 256 characters.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"},{"document_id":"ibmcld_16425-14122-16407","score":12.676869,"text":"\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"},{"document_id":"ibmcld_16490-14092-16377","score":12.676869,"text":"\nAnother indicator of annotation inconsistency is if you have enough annotations, but the corpus density is low. Density can be impacted when a mention that is significant in the domain literature occurs often, but is annotated as different types across the document set.\n\nLow precision is often an indication that you need to improve annotation consistency. To do so, review the annotation guidelines, better train the human annotators, and ensure that human annotators are working in concert and not in isolation from one another.\n\nCheck the inter-annotator agreement score. This score, which measures the degree of agreement between different annotators' output on the same document, is a valuable number. Not only does this score tell you the quality of the ground truth documents that will be used to train the machine learning model, but it also indicates the upper bound of machine learning model performance. A model that is trained on these documents is unlikely to outperform the best agreement that humans can reach. For example, if performance persists at 75 and does not go higher, take a look at the inter-annotator agreement results. If the inter-annotator agreement score is 80, take actions to better train the human annotators and ensure that conflicts are correctly resolved (according to the annotation guidelines) during adjudication. If humans can't agree on how something should be labeled, then it's unlikely that a machine learning model will apply the correct labels.\n* Enhance human annotator guidelines\n\nClear and comprehensive annotator guidelines are a crucial part of a harmonious and successful annotation development effort. Human annotators have a tough job to do. There can be nuances in assigning entity and relation types that are hard to anticipate until you start to work with the domain documents. The guidelines can provide a sanity check to human annotators as they evaluate documents. The guidelines should be a living and changing document, especially at the beginning of the annotation process. They provide a key feedback loop because a human annotator can capture things she learned while annotating a few documents, then as she or someone else annotates a few more documents, new tips and gotchas can be added to the guideline, and so on.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"},{"document_id":"ibmcld_16417-5155-7505","score":12.639576,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"},{"document_id":"ibmcld_16481-5154-7504","score":12.639576,"text":"\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"},{"document_id":"ibmcld_16464-13891-15856","score":12.46633,"text":"\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N\/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16417-1764-4158","score":12.180941,"text":"\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16444-1600-3658","score":14.041452,"text":"\nHuman annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16464-4463-6317","score":13.997442,"text":"\nOn the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\n> Note: In a realistic scenario, you would create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16507-4382-6307","score":13.911867,"text":"\nConfiguring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson. If a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2. Click the Move up and Move down arrow** buttons to move pre-annotation methods earlier or later in the order.\n3. Click Save.\n4. Double check the Order column on the Pre-annotation page to make sure that it matches the order that you want.\n\n\n\n\n\n\n\n Run pre-annotators \n\n\n\n1. After your pre-annotation methods are prepared and you have configured the order of your pre-annotators, click Run Pre-annotators.\n2. Select the pre-annotators that you want to use, and then click Next.\n3. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n4. Select the document sets that you want to pre-annotate.\n5. Click Run.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with Natural Language Understanding \n\nYou can use the Natural Language Understanding service to pre-annotate documents that you add to your corpus.\n\n\n\n Before you begin \n\nDetermine whether the Natural Language Understanding pre-annotator is likely to add value for your use case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16507-1455-3632","score":13.76586,"text":"\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-7-2064","score":13.492475,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16507-9193-11335","score":13.294876,"text":"\nClick Run.\n\nIf you are doing a validation check of the pre-annotator, then open the annotated documents and review the annotations that were added. Make sure a sufficient number of accurate annotations were created. If the annotations are accurate, then you can run the annotator again on more and larger document sets. If the annotations are not accurate, then consider mapping different Natural Language Understanding entity types to your types. If the types do not naturally overlap, then the Natural Language Understanding pre-annotator is not the best pre-annotator for you to use.\n\nPre-annotation is applied to individual documents without regard for the various document sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\n\n\n\n\n Results \n\nGround truth that is produced by documents that were pre-annotated by the Natural Language Understanding service cannot be used directly outside of Knowledge Studio. You can download the ground truth (in non-readable form) to move it from one Knowledge Studio workspace to another. And you can continue to develop the ground truth and use it to build a machine learning model or rule-based model that can be deployed for use in services outside of Knowledge Studio.\n\nDocuments that were pre-annotated with Natural Language Understanding are obscured into a non-readable format when they are downloaded. But, all annotations in those documents are obscured, including annotations that were added to the documents by human annotators.\n\nRelated information:\n\n[Natural Language Understanding](https:\/\/www.ibm.com\/watson\/services\/natural-language-understanding\/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16444-3168-4952","score":13.243535,"text":"\nYou can run a pre-annotator on documents that were added to the ground truth as part of the current workspace. Annotations that were added to the documents, reviewed, accepted, and promoted to ground truth within the current workspace are not stripped out.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections.\n\n\n\n* [Dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannot)\n* [Machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannotsire)\n* [Rules-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannotrule)\n\n\n\n\n\n Configuring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson. If a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"},{"document_id":"ibmcld_16410-8324-10312","score":13.122562,"text":"\nInter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set.\n\nYou cannot change the annotation set name after the set is created.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.\n* Open a task to add annotation sets to it. Ensure that the annotation sets that you add include documents that overlap with documents in the original annotation sets.\n\n\n\nFrom the Settings tab of the main navigation, you can specify the following information:\n\n\n\n* Specify preferences for using colors and keyboard shortcuts in the ground truth editor.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"},{"document_id":"ibmcld_16563-4292-6145","score":13.068012,"text":"\nSelect the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introtut_lessml1).\n6. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\nIn a realistic scenario, you create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3. Specify the details for the task:\n\n\n\n* In the Task name field, enter Test.\n* In the Deadline field, select a date in the future.\n\n\n\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16507-12419-14261","score":13.060026,"text":"\nAdd entries for the dictionary or upload a file that contains dictionary terms.\n6. Go to the Machine Learning Model > Pre-annotation page.\n7. Click Run Pre-annotators.\n8. Select Dictionaries, and then click Next.\n9. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n10. Select the check box for each document set that you want to pre-annotate and click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets or annotation sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\nRelated information:\n\n\n\n* [Creating dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-dictionaries)\n* [Getting Started > Adding a dictionary](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutless4)\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with the machine learning model \n\nYou can use an existing machine learning model to pre-annotate documents that you add to your corpus.\n\n\n\n About this task \n\nAfter 10 to 30 documents are annotated, a machine learning model can be trained on the data. Don't use such a minimally trained model in production. However, you can use the model to pre-annotate documents to help speed up the human annotation of subsequent documents. For example, if you add documents to the corpus after you train a machine learning model, you can use the model to pre-annotate the new document sets. Never run a pre-annotator on the same documents that have been annotated by a person. Pre-annotators remove human annotation.\n\n\n\n\n\n Procedure","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.1815417925}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16507-1455-3632","score":12.156503,"text":"\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16464-4463-6317","score":12.093497,"text":"\nOn the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\n> Note: In a realistic scenario, you would create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"},{"document_id":"ibmcld_16465-16375-17201","score":12.076574,"text":"\n(images\/rule-anno2.png \"Shows the user clicking Edit for the \"DATE\" entity type in the \"Rule-based model type mapping\" tab.\")\n2. Choose the RuleDate class from the list and click Save.\n\n![Shows the user choosing the \"RuleDate\" class from the list.](images\/rule-anno3.png \"Shows the user choosing the \"RuleDate\" class from the list.\")\n\n\n\n3. To pre-annotate document sets or annotation sets with the rule-based model, select the Rule-based Model tab and click Run this model.\n\nAttention: Run the rule-based model as a pre-annotator only on documents that were not already annotated by humans.\n\n\n\n\n\n\n\n\n\n Tutorial summary \n\nWhile learning about Knowledge Studio, you created a rule-based model.\n\n\n\n Lessons learned \n\nBy completing this tutorial, you learned about the following concepts:\n\n\n\n* Classes\n* Regular expressions\n* Rules","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutrule_intro"},{"document_id":"ibmcld_16507-3099-4772","score":12.013881,"text":"\nIt can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators \n\nKnowledge Studio allows you to run multiple pre-annotators at once. First, you need to prepare the pre-annotation methods that you want to use. For more information, see the following sections:\n\n\n\n* [Natural Language Understanding](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotnlu)\n* [Dictionaries](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannot)\n* [Machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotsire)\n* [Rules-based model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_preannotrule)\n\n\n\n\n\n Configuring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16507-4382-6307","score":11.885502,"text":"\nConfiguring the order of pre-annotators \n\nWhen multiple pre-annotators are used, the first annotation made to a span of text is saved for the results, even if other pre-annotators attempt to annotate the same span of text later in the order. This doesn't apply to human annotations, which are preserved regardless of pre-annotation order.\n\nFor example, consider the example text IBM Watson. If a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2. Click the Move up and Move down arrow** buttons to move pre-annotation methods earlier or later in the order.\n3. Click Save.\n4. Double check the Order column on the Pre-annotation page to make sure that it matches the order that you want.\n\n\n\n\n\n\n\n Run pre-annotators \n\n\n\n1. After your pre-annotation methods are prepared and you have configured the order of your pre-annotators, click Run Pre-annotators.\n2. Select the pre-annotators that you want to use, and then click Next.\n3. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n4. Select the document sets that you want to pre-annotate.\n5. Click Run.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with Natural Language Understanding \n\nYou can use the Natural Language Understanding service to pre-annotate documents that you add to your corpus.\n\n\n\n Before you begin \n\nDetermine whether the Natural Language Understanding pre-annotator is likely to add value for your use case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16507-9193-11335","score":11.874642,"text":"\nClick Run.\n\nIf you are doing a validation check of the pre-annotator, then open the annotated documents and review the annotations that were added. Make sure a sufficient number of accurate annotations were created. If the annotations are accurate, then you can run the annotator again on more and larger document sets. If the annotations are not accurate, then consider mapping different Natural Language Understanding entity types to your types. If the types do not naturally overlap, then the Natural Language Understanding pre-annotator is not the best pre-annotator for you to use.\n\nPre-annotation is applied to individual documents without regard for the various document sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\n\n\n\n\n Results \n\nGround truth that is produced by documents that were pre-annotated by the Natural Language Understanding service cannot be used directly outside of Knowledge Studio. You can download the ground truth (in non-readable form) to move it from one Knowledge Studio workspace to another. And you can continue to develop the ground truth and use it to build a machine learning model or rule-based model that can be deployed for use in services outside of Knowledge Studio.\n\nDocuments that were pre-annotated with Natural Language Understanding are obscured into a non-readable format when they are downloaded. But, all annotations in those documents are obscured, including annotations that were added to the documents by human annotators.\n\nRelated information:\n\n[Natural Language Understanding](https:\/\/www.ibm.com\/watson\/services\/natural-language-understanding\/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16507-7-2044","score":11.862481,"text":"\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"},{"document_id":"ibmcld_16463-7-1870","score":11.814349,"text":"\nPre-annotating documents \n\nThis tutorial helps you understand how to pre-annotate documents, which bootstraps the annotation process of human annotation.\n\n\n\n Learning objectives \n\nAfter you complete this tutorial, you will know how to pre-annotate documents with a machine learning model.\n\nThis tutorial should take approximately 5 minutes to finish. If you explore other concepts related to this tutorial, it could take longer to complete.\n\n\n\n\n\n Before you begin \n\n\n\n* You're using a supported browser. For information, see [Browser requirements](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-system-requirements).\n* You successfully completed [Getting started with Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintro), which covers creating a workspace, creating a type system, and adding a dictionary.\n* You successfully completed [Creating a machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro).\n* You must have at least one user ID in either the Admin or Project Manager role. For information about user roles, see [User roles in Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles).\n\n\n\n\n\n\n\n Results \n\nAfter completing this tutorial, you will have a set of partially annotated documents. Then, you can assign the documents to human annotators to finish the annotation work.\n\n\n\n\n\n Lesson 1: Pre-annotating new documents with a machine learning model \n\nIn this lesson, you will learn how to use a machine learning model to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nAfter you train a machine learning model, you can use it to pre-annotate new documents that you add to the corpus.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutboot_intro"},{"document_id":"ibmcld_16552-7-1961","score":11.765619,"text":"\nPre-annotating documents \n\nThis tutorial helps you understand how to pre-annotate documents, which bootstraps the annotation process of human annotation.\n\n\n\n Learning objectives \n\nAfter you complete this tutorial, you will know how to pre-annotate documents with a machine learning model.\n\nThis tutorial should take approximately 5 minutes to finish. If you explore other concepts related to this tutorial, it could take longer to complete.\n\n\n\n\n\n Before you begin \n\n\n\n* You're using a supported browser. For more information, see [Browser requirements](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-system-requirements).\n* You successfully completed [Getting started with Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintro), which covers creating a workspace, creating a type system, and adding a dictionary.\n* You successfully completed [Creating a machine learning model](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro).\n* You must have at least one user ID in either the Admin or Project Manager role. For more information about user roles, see [User roles in Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-roles).\n\n\n\n\n\n\n\n Results \n\nAfter completing this tutorial, you will have a set of partially annotated documents. Then, you can assign the documents to human annotators to finish the annotation work.\n\n\n\n\n\n Lesson 1: Pre-annotating new documents with a machine learning model \n\nIn this lesson, you will learn how to use a machine learning model to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nAfter you train a machine learning model, you can use it to pre-annotate new documents that you add to the corpus.\n\nDo not run a pre-annotator on documents that have been annotated by humans, but not been added to the ground truth yet.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutboot_intro"},{"document_id":"ibmcld_16552-2856-4585","score":11.7348585,"text":"\nYou can use the [documents-ml.csv](https:\/\/watson-developer-cloud.github.io\/doc-tutorial-downloads\/knowledge-studio\/documents-ml.csv) file.\n\nFor more information about adding documents to a workspace, see [Adding documents for annotation](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotation).\n3. Create an annotation set that uses the documents-ml.csv file as the base set, and assign it to yourself, the administrator.\n\nAfter you complete the following steps to pre-annotate the new documents, you can view the annotation set to see how the machine learning model annotated the documents. Typically, you assign annotation sets to one or more human annotators. For more information about creating and assigning annotation sets, see [Adding documents for annotation](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotation).\n4. To pre-annotate the new documents:\n\n\n\n* On the Machine Learning Model > Pre-annotation page click Run Pre-annotators.\n* Select Machine Learning Model, then click Next.\n* Select the document set that you added to the corpus, documents-ml.csv, and click Run.\n\n\n\n5. After the pre-annotation is complete, create a human annotation task that includes the annotation set you created.\n\nFor more information about creating an annotation task, see [Annotation setup](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents).\n6. To view the annotations that were applied by the machine learning model to the new documents, open the annotation task.\n\nBecause the new documents were pre-annotated with the machine learning model, human annotation requires less time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutboot_intro"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1301266833}}
{"task_id":"ddbbbe7ea13560c5768639207e1ca604<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16490-3348-5630","score":8.10429,"text":"\n* Percentage of corpus density (by the number of words)\n\nA measurement of ground truth that shows the number of words that were annotated with a given entity type or relation type out of the total number of words, whether annotated or unannotated. This statistic is not available for coreferenced mentions. This value can help you to see how prevalent mentions of this type are compared to all of the other words in your domain documents.\n* Percentage of documents that contain the type\n\nA measurement of ground truth that shows how many documents contain a given entity type or relation type. This statistic is not available for coreferenced mentions. This value can help you to assess whether the documents in the set represent the domain sufficiently. If the percentage is low for key entity types, then you might want to add more documents with mentions of under-represented types.\n\n\n\n\n\n\n\n Procedure \n\nTo view performance statistics for how well the model was trained:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. For the mentions, relations, or coreferences, select the Detailed Statistics link.\n4. In the Summary view, specify whether you want to evaluate test data or training data, and then specify the type of annotations you want to see statistics for: entity types, relation types, or coreferenced mentions. As you scroll through the data, items that have low scores are flagged and highlighted to indicate that they require investigation and improvement. The triangle warning icon indicates that the F1 value is less than the fixed value, 0.5.\n\nFor example, the F1 score for some entity types might be high because the document was annotated through pre-annotation as well as by a human annotator. But the F1 score for other entity types might be low because differences in phrasing, and differences in how human annotators interpret the text or annotation guidelines, make it more difficult for the machine learning model to recognize the pattern and apply the correct annotation.\n5. In the Confusion Matrix view for test data, specify the type of annotations that you want to see statistics for: entity types or relation types. For each entity type or relation type:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"},{"document_id":"ibmcld_15788-7-1722","score":8.018328,"text":"\nLinux and Windows benchmark scores \n\nLinux\u00ae and Windows\u00ae benchmark scores are measured on high-performance virtual servers for IBM Cloud\u00ae Virtual Private Cloud (VPC) by using [CoreMark](https:\/\/www.eembc.org\/coremark\/faq.php). CoreMark is an industry standard benchmark that measures the performance of CPUs on physical machines and virtual servers that are offered by Infrastructure-as-a-Service (IaaS) providers like IBM Cloud VPC.\n\nWhile the current benchmark results are for Compute instance profiles, we expect the CoreMark scores to be similar for Balanced and Memory instance profiles with the same CPU count.\n\n\n\n Compute virtual server profiles \n\nCompute profiles offer a core to RAM ratio of 1 vCPU to 2 GiB of RAM ratio and are best for moderate to high web traffic workloads. Compute profiles are best for workloads with intensive CPU demands, such as high web traffic workloads, production batch processing, and front-end web servers.\n\nYou can provision virtual servers on Compute hosts with Broadwell, Skylake, or Cascade Lake processor types. The benchmark tests are run on all CPU types. The following tables show the benchmark scores for Linux and Windows virtual server Compute instance profiles.\n\nLinux\n\nWindows\n\n\n\nTable 1. Linux benchmark for Compute profile family\n\n Profile CPU CPU MHz vCPUs Score Standard Deviation (%) Sample Count \n\n cx2-2x4 Broadwell 2095.170 2 24690.74 3.76 2160 \n cx2-4x8 Broadwell 2095.148 4 49126.78 2.08 1560 \n cx2-8x16 Broadwell 2095.148 8 99210.04 1.47 1070 \n cx2-16x32 Broadwell 2095.148 16 197633.25 1.38 735 \n cx2-32x64 Broadwell 2095.148 32 389354.87 1.01 2600 \n cx2-48x96 Broadwell 2095.148 48 579164.89 1.81 3150 \n cx2-2x4 Skylake 2593.910 2 33762.35 3.05 1180","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profiles_benchmark"},{"document_id":"ibmcld_16425-3435-5660","score":7.8425813,"text":"\nA measurement of ground truth that shows the number of words that were annotated with a given entity type or relation type out of the total number of words, whether annotated or unannotated. This statistic is not available for coreferenced mentions. This value can help you to see how prevalent mentions of this type are compared to all of the other words in your domain documents.\n* Percentage of documents that contain the type\n\nA measurement of ground truth that shows how many documents contain a given entity type or relation type. This statistic is not available for coreferenced mentions. This value can help you to assess whether the documents in the set represent the domain sufficiently. If the percentage is low for key entity types, then you might want to add more documents with mentions of under-represented types.\n\n\n\n\n\n\n\n Procedure \n\nTo view performance statistics for how well the model was trained:\n\n\n\n1. Log in as a Knowledge Studio administrator or project manager, and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. For the mentions, relations, or coreferences, select the Detailed Statistics link.\n4. In the Summary view, specify whether you want to evaluate test data or training data, and then specify the type of annotations you want to see statistics for: entity types, relation types, or coreferenced mentions. As you scroll through the data, items that have low scores are flagged and highlighted to indicate that they require investigation and improvement. The triangle warning icon indicates that the F1 value is less than the fixed value, 0.5.\n\nFor example, the F1 score for some entity types might be high because the document was annotated through pre-annotation as well as by a human annotator. But the F1 score for other entity types might be low because differences in phrasing, and differences in how human annotators interpret the text or annotation guidelines, make it more difficult for the machine learning model to recognize the pattern and apply the correct annotation.\n5. In the Confusion Matrix view for test data, specify the type of annotations that you want to see statistics for: entity types or relation types. For each entity type or relation type:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"},{"document_id":"ibmcld_16425-7-2236","score":7.6785393,"text":"\nAnalyzing machine learning model performance \n\nReview the annotations that were added by the trained model to determine whether any adjustments must be made to the model to improve its ability to find valid entity mentions, relation mentions, and coreferences in the documents.\n\n\n\n About this task \n\nYou can analyze performance by viewing a summary of statistics for entity types, relation types, and coreferenced mentions. You can also analyze statistics that are presented in a confusion matrix. The confusion matrix helps you compare the annotations added by the machine learning model to the annotations in ground truth.\n\nThe model statistics provide the following metrics:\n\n\n\n* F1 score\n\nA measurement that considers both precision and recall to compute the score. The F1 score can be interpreted as a weighted average of the precision and recall values, where an F1 score reaches its best value at 1 and worst value at 0. See [Analyzing low F1 scores](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-mlevaluate-mllowf1).\n* Precision\n\nA measurement that specifies what fraction of the machine learning model's output was accurate when compared to the human annotator output. Precision is determined by the number of correctly labeled annotations divided by the total number of annotations added by the machine learning model. A precision score of 1.0 for entity type A means that every mention that was labeled as entity type A does indeed belong to that classification. A low precision score helps you identify places where the machine learning model created incorrect annotations. The score says nothing about how many other mentions that were labeled as entity type A by the human annotator were missed by the machine learning model; the recall score reflects that information. See [Analyzing low precision scores](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-mlevaluate-mllowp).\n* Recall\n\nA measurement that specifies how many mentions that should have been annotated by a given label were actually annotated with that label - the right mentions being those that human annotators identified in the same documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"},{"document_id":"ibmcld_16490-7-2216","score":7.482832,"text":"\nAnalyzing machine learning model performance \n\nReview the annotations that were added by the trained model to determine whether any adjustments must be made to the model to improve its ability to find valid entity mentions, relation mentions, and coreferences in the documents.\n\n\n\n About this task \n\nYou can analyze performance by viewing a summary of statistics for entity types, relation types, and coreferenced mentions. You can also analyze statistics that are presented in a confusion matrix. The confusion matrix helps you compare the annotations added by the machine learning model to the annotations in ground truth.\n\nThe model statistics provide the following metrics:\n\n\n\n* F1 score\n\nA measurement that considers both precision and recall to compute the score. The F1 score can be interpreted as a weighted average of the precision and recall values, where an F1 score reaches its best value at 1 and worst value at 0. See [Analyzing low F1 scores](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-mlevaluate-mllowf1).\n* Precision\n\nA measurement that specifies what fraction of the machine learning model's output was accurate when compared to the human annotator output. Precision is determined by the number of correctly labeled annotations divided by the total number of annotations added by the machine learning model. A precision score of 1.0 for entity type A means that every mention that was labeled as entity type A does indeed belong to that classification. A low precision score helps you identify places where the machine learning model created incorrect annotations. The score says nothing about how many other mentions that were labeled as entity type A by the human annotator were missed by the machine learning model; the recall score reflects that information. See [Analyzing low precision scores](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-mlevaluate-mllowp).\n* Recall\n\nA measurement that specifies how many mentions that should have been annotated by a given label were actually annotated with that label - the right mentions being those that human annotators identified in the same documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"},{"document_id":"ibmcld_16563-18465-20518","score":7.2630296,"text":"\nTo see the annotations that the trained machine learning model created on that same set of documents, click View Decoding Results.\n8. To view details about the precision, recall, and F1 scores for the machine learning model, click the Performance page.\n9. Click the Detailed Statistics links above each of the graphs. On these Statistics pages, you can view the scores for mentions, relations, and coreference chains by using the radio buttons.\n\nYou can analyze performance by viewing a summary of statistics for entity types, relation types, and coreference chains. You can also analyze statistics that are presented in a confusion matrix. To see the matrix, change Summary to Confusion Matrix. The confusion matrix helps you compare the annotations that were added by the machine learning model to the annotations in the ground truth.\n\nIn this tutorial, you annotated documents with only a single dictionary for organizations. Therefore, the scores you see are 0 or N\/A for most entity types except ORGANIZATION. The numbers are low, but that is expected because you did not do any human annotation or correction.\n\nFigure 2. Options on the Statistics page for a machine learning model\n\n![This screen capture shows the Statistics page.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks_tutanno9.png)\n10. Click Versions. On the Versions page, you can take a snapshot of the model and the resources that were used to create it (except for dictionaries and annotation tasks). For example, you might want to take a snapshot before you retrain the model. If the statistics are poorer the next time you train it, you can promote the older version and delete the version that returned poorer results.\n\n\n\n\n\n\n\n Results \n\nYou created a machine learning model, trained it, and evaluated how well it performed when annotating test data and blind data. By exploring the performance metrics, you can identify ways to improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n Tutorial summary","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_11310-11400-13261","score":7.168548,"text":"\nYou can use this option if you are concerned about a single-server outage that might affect all Power Systems Virtual Server instances. A placement group is automatically created. The instance name previously provided will be used as the group name and cannot be edited. <br>Numerical prefix : Select this option to add numbers before the name of the virtual server. If, for example, the first Power Systems Virtual Server name is Austin the next name for the virtual instance is 1Austin. <br>Numerical postfix : Select this option to add numbers after the name of the virtual server. If, for example, the first Power Systems Virtual Server name is Austin the next name for the virtual instance is Austin1. <br>VM pinning : Select this option to pin your virtual machine. You can choose either a soft or hard pinning policy. <br>[Learn more](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-power-iaas-faqspinning). <br>Note: When you create multiple instances of the virtual server, you must select On from the Shareable field for each data volume that you add. If you do not want the data volume to be shareable, you can add the data volume after you create the virtual server. For IBM i OS you cannot have shareable data volumes. \n Machine type Specify the machine type. The machine type that you select determines the number of cores and memory that is available. For more information about hardware specifications, see [S922](https:\/\/www.ibm.com\/downloads\/cas\/KQ4BOJ3N), and [E980 (Data centers other than Dallas and Washington)](http:\/\/www-01.ibm.com\/support\/docview.wss?uid=ssm1platformaix9080-M9S-vios-only). \n Cores There is a core-to-vCPU ratio of 1:1. For shared processors, fractional cores round up to the nearest whole number. For example, 1.25 cores equals 2 vCPUs. \n Memory Select the amount of memory for the Power Systems Virtual Server.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-creating-power-virtual-server"},{"document_id":"ibmcld_16425-1845-4030","score":7.1654935,"text":"\nSee [Analyzing low precision scores](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-mlevaluate-mllowp).\n* Recall\n\nA measurement that specifies how many mentions that should have been annotated by a given label were actually annotated with that label - the right mentions being those that human annotators identified in the same documents. Recall is determined by the number of correctly labeled annotations divided by the number of annotations that should have been created. A recall score of 1.0 means that every mention that should have been labeled as entity type A was labeled correctly. A low recall score helps you identify places where the machine learning model failed to create an annotation that it should have. The score says nothing about how many other mentions were also labeled as entity type A, but should not have been; the precision score reflects that information. See [Analyzing low recall scores](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-mlevaluate-mllowr).\n* Percentage of total annotations\n\nA measurement of ground truth that shows how many words were annotated with a given entity type or relation type out of the total number of words that were annotated as any entity type or relation type in the test document set. This statistic is not available for coreferenced mentions. This value can help you to see how prevalent mentions of one type are compared to the other types in your ground truth.\n* Percentage of corpus density (by the number of words)\n\nA measurement of ground truth that shows the number of words that were annotated with a given entity type or relation type out of the total number of words, whether annotated or unannotated. This statistic is not available for coreferenced mentions. This value can help you to see how prevalent mentions of this type are compared to all of the other words in your domain documents.\n* Percentage of documents that contain the type\n\nA measurement of ground truth that shows how many documents contain a given entity type or relation type. This statistic is not available for coreferenced mentions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"},{"document_id":"ibmcld_11310-12774-14467","score":7.164911,"text":"\nFor more information about hardware specifications, see [S922](https:\/\/www.ibm.com\/downloads\/cas\/KQ4BOJ3N), and [E980 (Data centers other than Dallas and Washington)](http:\/\/www-01.ibm.com\/support\/docview.wss?uid=ssm1platformaix9080-M9S-vios-only). \n Cores There is a core-to-vCPU ratio of 1:1. For shared processors, fractional cores round up to the nearest whole number. For example, 1.25 cores equals 2 vCPUs. \n Memory Select the amount of memory for the Power Systems Virtual Server. If you choose to use more than 64 GBs of memory per core, you are charged a higher price. For example, when you choose one core with 128 GBs of memory, you are charged the regular price for the first 64 GBs. After the first 64 GBs (64 - 128 GBs), you are charged a higher price. \n Boot image Select a version of the IBM-provided AIX or IBM i operating system stock image. You can also select Linux stock images for SAP HANA and SAP NetWeaver applications. For these SAP stock images it is mandatory to set an SSH key while creating the VM. You will be able to access the VM instance only via SSH after launch. However, it is recommended to set a password by using the passwd command during the first SSH access. By setting a password, you are able to access the instance in the UI console. You can also [deploy your own custom image](https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-deploy-custom-image) of AIX, IBM i, or Linux. IBM also provides a community supported CentOS image under Linux operating system. However, IBM does not provide any support for this image. For CentOS support, see the [CentOS forum](https:\/\/forums.centos.org\/) or [FAQ](https:\/\/forums.centos.org\/app.php\/help\/faq) page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-creating-power-virtual-server"},{"document_id":"ibmcld_06136-17977-19825","score":7.15045,"text":"\nPrometheus Prometheus is an open source monitoring, logging, and alerting tool that was designed for Kubernetes. Prometheus retrieves detailed information about the cluster, worker nodes, and deployment health based on Kubernetes logging information. CPU, memory, I\/O, and network activity is collected for each container that runs in a cluster. You can use the collected data in custom queries or alerts to monitor performance and workloads in your cluster. To use Prometheus, follow the [CoreOS instructions](https:\/\/github.com\/prometheus-operator\/kube-prometheus). Yes Yes \n Sematext View metrics and logs for your containerized applications by using [Sematext](https:\/\/sematext.com\/). For more information, see [Monitoring and logging for containers with Sematext](https:\/\/www.ibm.com\/cloud\/blog\/monitoring-logging-ibm-bluemix-container-service-sematext). Yes Yes \n Splunk Import and search your Kubernetes logging, object, and metrics data in Splunk by using Splunk Connect for Kubernetes. Splunk Connect for Kubernetes is a collection of Helm charts that deploy a Splunk-supported deployment of Fluentd to your Kubernetes cluster, a Splunk-built Fluentd HTTP Event Collector (HEC) plug-in to send logs and metadata, and a metrics deployment that captures your cluster metrics. For more information, see [Solving Business Problems with Splunk on IBM Cloud Kubernetes Service](https:\/\/www.ibm.com\/cloud\/blog\/solving-business-problems-with-splunk-on-ibm-cloud-kubernetes-service). Yes Yes \n Weave Scope [Weave Scope](https:\/\/www.weave.works\/oss\/scope\/) provides a visual diagram of your resources within a Kubernetes cluster, including services, pods, containers, processes, nodes, and more. Weave Scope provides interactive metrics for CPU and memory and also provides tools to tail and exec into a container. Yes Yes \n\n\n\n\n\n\n\n Security services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrations"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2772734274,"ndcg_cut_10":0.247386359}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09149-2959-3768","score":17.930632,"text":"\nFor more information about deleting keys, check out [About deleting and purging keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keys).\n\n\n\n\n\n How many key versions do you have? \n\nTo see how many versions you have of each key you have deployed:\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the Keys panel, click the \u22ef icon and select Key details. This opens a side panel that shows, among other things, the number of versions of this key you have.\n5. Repeat this process for every key in your instance. Note that because only root keys can be rotated, all of your standard keys only have one version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-pricing-plan"},{"document_id":"ibmcld_08446-4-1771","score":17.897745,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting managed keys \n\nYou can delete your managed keys in Unified Key Orchestrator with the IBM Cloud\u00ae console, or programmatically with the Unified Key Orchestrator API.\n\nWhen you delete a managed key, the key is to be detached from all target keystores, and all key materials and the metadata are destroyed permanently.\n\n\n\n Deleting managed keys with the IBM Cloud console \n\nTo delete a key in Active state, you need to first deactivate the key, and then destroy the key and remove it from the vault.\n\nTo delete a key in Pre-active or Deactivated state, you only need to destroy the key, and then remove it from the vault.\n\nFor more information about key states and transitions, see [Monitoring the lifecycle of encryption keys in Unified Key Orchestrator](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-uko-key-states).\n\nFollow these steps to complete the process:\n\n\n\n1. [Log in to the Hyper Protect Crypto Services instance](https:\/\/cloud.ibm.com\/login).\n2. Click Managed keys from the navigation to view all the available keys.\n3. If the managed key that you want to delete is in Active state, click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/action-menu-icon.svg) and choose Deactivated to deactivate the key first.\n\nWhen you change the Active key to Deactivated state, the key is detached from all the target keystores, and not accessible to all associated resources and their data. Make sure that you open the confirmation tile to check all the associated resources before you continue. However, you can still reactivate the key so that it is accessible to the resources again.\n4. To destroy a Pre-active or Deactivated key, click the Actions icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-managed-keys"},{"document_id":"ibmcld_09064-4-1760","score":17.553766,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys using a single authorization \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to delete an encryption key and its key material, if you are a manager for your Key Protect instance.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Deleting keys in the console \n\nBy default, Key Protect requires one authorization to delete a key. If you prefer to delete your encryption keys by using a graphical interface, you can use the IBM Cloud console.\n\n[After you create or import your existing keys into the service](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-root-keys), complete the following steps to delete a key:\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.\n6. From the options menu, click Delete key and confirm the key deletion in the next screen by ensuring the key has no associated resources. Note that you will not be able to delete the key if it is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy).\n\n\n\nAfter you delete a key, the key transitions to the Destroyed state. Any data encrypted by keys in this state is no longer accessible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys"},{"document_id":"ibmcld_09061-2799-4588","score":17.532267,"text":"\n[Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.\n6. From the options menu, click Schedule key deletion and review the key's associated resources.\n7. Click the Next button, enter the key name, and click Schedule deletion.\n8. Contact another user to complete the deletion of the key.\n\n\n\nThe other user must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n\n\n Purging a key that holds dual authorization in the console \n\nFour hours after the other user with a Manager access policy has authorized the key for deletion, it can be purged by one of the users as long as they hold [the KeyPurge attribute](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grant-access-keysgrant-access-keys-specific-functions).\n\nThis can be done by clicking the \u22ef icon to open a list of options for the key that you want to purge and then clicking Purge. If you cannot delete the key, make sure it has been at least four hours since the key was authorized for deleting by another user and that you hold the KeyPurge attribute.\n\n\n\n\n\n Authorize deletion for a key with the API \n\n[After you enable dual authorization for an instance or key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\/actions\/setKeyForDeletion\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08580-8441-10004","score":17.50389,"text":"\nThe created key is displayed as the first row in the Enterprise PKCS #11 keys table.\n\n\n\n\n\n Deleting EP11 keys \n\nFor default service access roles that support deleting EP11 keys, see [service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles). If you are to create custom roles, make sure to assign the following actions to the custom role:\n\n\n\n* hs-crypto.keystore.listkeystoresbyids\n* hs-crypto.keystore.listkeysbyids\n* hs-crypto.keystore.deletekey\n\n\n\nFor instructions on creating custom roles, see [Creating custom roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-custom-roles).\n\nIf you want to delete an EP11 key, complete the following steps:\n\nAfter you delete an EP11 key, you are not able to access the data associated with the key. This action cannot be undone.\n\n\n\n1. Select the EP11 keys tab in the side menu, and find the key that you want to delete in the list.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/action-menu-icon.svg) in the key row, and click Delete key.\n3. Verify the ID of the key to be deleted, and check the box to confirm the deletion.\n4. Click Delete keystore.\n\n\n\nIf you are performing cryptographic operations using the PKCS #11 API, to delete the key in your PKCS #11 application, reinitialize the PKCS #11 API by using the C_Finalize() and C_Initialize() functions.\n\n\n\n\n\n What's next \n\nYou can use EP11 keys for cryptographic operations with the PKCS #11 API. For more information, see","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-ep11-key-ui"},{"document_id":"ibmcld_09087-47101-48578","score":17.413036,"text":"\nWhen you restore a key, you move the key from the Destroyed (state value is 5) to the Active (state value is 1) key state, and you restore access to any data that was previously encrypted with the key.\n\nYou can restore a deleted key within 30 days of its deletion. This capability is available only for root keys that were created with a key material, also known as the \"payload.\"\n\nYou can only restore root keys that were created with a key material, using the kp key create command with the -k, --key-material option. You cannot restore a root key if the --key-material option was not specified.\n\nIf you want to restore a deleted root key then you must save the key material that was used to create the root key. You cannot restore a deleted key without provided the original key material.\n\n\n\n Example \n\nFollow these steps to create the only imported keys may be restored error.\n\n\n\n1. Create a root key without a key material (payload)\n2. Delete the key\n3. Sleep 30 seconds\n4. Create a key material\n5. Restore the key and provide a key material (payload)\n\n\n\n step 1 - create a root key without a key material (payload)\n$ KEY_ID=$(ibmcloud kp key create example-key -i $KP_INSTANCE_ID --output json | jq -r '.[\"id\"]')\n\n$ echo $KEY_ID\n\ne631925f-affb-457e-886d-57cb2a5f565b\n\n step 2 - delete the key\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID\n\nDeleting key: 'e631925f-affb-457e-886d-57cb2a5f565b', from instance: 'a192d603-0b8d-452f-aac3-f9e1f95e7411'...\nOK\nDeleted Key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_08988-31938-33189","score":17.376392,"text":"\n* KEY_ID_OR_ALIAS\n\nThe v4 UUID or alias of the key that you want to delete. To retrieve a list of your available keys, run the [kp keys](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-referencekp-keys) command.\n\n\n\n\n\n\n\n\n\n kp key create \n\n[Create a root key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-root-keys) in the Key Protect instance that you specify or [import your own key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-import-root-keys)\n\nRoot keys must be 16, 24, or 32 bytes long; corresponding to 128, 192, or 256 bits.\n\nibmcloud kp key create KEY_NAME\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n[-k, --key-material KEY_MATERIAL]\n[-n, --encrypted-nonce NONCE]\n[-o, --output OUTPUT]\n[-s, --standard-key]\n[-v, --iv IV]\n\n\n\n Examples \n\nThese are examples of kp key create.\n\n\n\n Example 1 \n\nCreate a root key.\n\n create a root key\n$ ibmcloud kp key create my-root-key\n\nCreating key: 'my-root-key', in instance: '390086ac-76fa-4094-8cf3-c0829bd69526'...\nOK\nKey ID Key Name\n24203f96-b134-440e-981a-a24f2d432256 my-root-key\n\n\n\n\n\n Example 2 \n\nCreate a root key and show the JSON output.\n\n create a root key\n$ ibmcloud kp key create my-root-key --output json\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"},{"document_id":"ibmcld_09099-5695-7625","score":17.36042,"text":"\nBecause a key ring cannot be deleted as long as it contains keys in any state (including the destroyed state keys are moved to after they are deleted but before they are automatically purged 90 days after deletion), if you want to delete a key ring, you might need to transfer keys to a different ring first.\n\nAfter transferring a key to a different key ring, it may take up to a maximum of ten minutes for the change to take effect.\n\n\n\n Transferring a key to a different key ring with the UI \n\nIf you do not see all of the options you expect to see, it might be because you do not have the permission to execute a particular action. Make sure your roles and permissions are sufficient to perform the action. For more information on roles, check out [Managing user access](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-access).\n\nYou must have the service \"Manager\" role of both the key being transferred and the target key ring to transfer a key.\n\nFrom the Keys panel:\n\n\n\n1. Find the key you want to transfer. Note that it can be helpful to specify the key ring where the key is currently located by selecting the ring in the Key ring ID drop down list. You can also click on Key rings in the left navigation, find the appropriate key ring, and click View associated keys inside the setting drop-down list. This will show you all of the keys associated with that key ring.\n2. Click on the \u22ef button, and select Edit key ring from the drop-down list.\n3. In the drop-down list, select the key ring you want to move the key to. Then click Save.\n\n\n\n\n\n\n\n Transferring a key to a different key ring with the API \n\nTransfer a key to a different key ring by making a PATCH call to the following endpoint.\n\nhttps:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-up-api).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys"},{"document_id":"ibmcld_09061-1334-3188","score":17.149076,"text":"\nWhen the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted. When you delete a key, it is \"soft deleted\", meaning that the key and its associated data will be restorable up to 30 days after deletion. You are able to still retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically [purged](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-key-purge), or hard deleted, and its associated data will be permanently removed from the Key Protect service.\n\n\n\n\n\n\n\n Authorize deletion for a key in the console \n\n[After you enable dual authorization for an instance or key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by using the Key Protect IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08580-9654-10235","score":17.133236,"text":"\nClick Delete keystore.\n\n\n\nIf you are performing cryptographic operations using the PKCS #11 API, to delete the key in your PKCS #11 application, reinitialize the PKCS #11 API by using the C_Finalize() and C_Initialize() functions.\n\n\n\n\n\n What's next \n\nYou can use EP11 keys for cryptographic operations with the PKCS #11 API. For more information, see\n\n[Performing cryptographic operations with the PKCS #11 API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-pkcs-api) and\n\n[PKCS #11 API reference](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-pkcs11-api-ref).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-ep11-key-ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1412669729}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09061-1334-3188","score":16.370007,"text":"\nWhen the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted. When you delete a key, it is \"soft deleted\", meaning that the key and its associated data will be restorable up to 30 days after deletion. You are able to still retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically [purged](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-key-purge), or hard deleted, and its associated data will be permanently removed from the Key Protect service.\n\n\n\n\n\n\n\n Authorize deletion for a key in the console \n\n[After you enable dual authorization for an instance or key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by using the Key Protect IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-3634-5079","score":15.748904,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_02770-3094-4748","score":15.48018,"text":"\nSelect App ID as your source service.\n5. Select Key Protect as your target service.\n6. Specify the scope of the access.\n7. Assign the Reader role.\n8. Click Authorize.\n\n\n\n4. Create an instance of the App ID service.\n\n\n\n1. Select your Key Protect instance.\n2. Select the root key that you previously authorized.\n3. Click Create.\n\n\n\n\n\nApp ID supports state changes to your key.\n\n\n\n Rotating your keys \n\nWhen you [rotate your KEK](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-rotation), App ID rewraps the DEKs associated with the rotated key, ensuring that your user data is always protected with your up-to-date encryption key.\n\n\n\n\n\n Deleting your keys \n\nWhen you [delete your KEK](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys), user data becomes inaccessible within 4 hours of deletion. Although user data is not destroyed when a key is deleted, App ID is no longer able to decrypt the user data, making it inaccessible.\n\n\n\n\n\n\n\n Enabling customer-managed keys for App ID by using Hyper Protect Crypto Services \n\nIf you choose to work with a key that you manage, you must ensure that valid IAM authorization is assigned to the App ID service.\n\n\n\n1. [Create an instance of Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-get-startedprovision-service).\n2. [Initialize your instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-initialize-hsm) by loading a master key from smart cards or from your workstation.\n3. [Generate or import your own root key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-create-root-keys) to your instance of Hyper Protect Crypto Services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mng-data"},{"document_id":"ibmcld_08435-4752-6201","score":15.327829,"text":"\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-2799-4588","score":15.169786,"text":"\n[Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.\n6. From the options menu, click Schedule key deletion and review the key's associated resources.\n7. Click the Next button, enter the key name, and click Schedule deletion.\n8. Contact another user to complete the deletion of the key.\n\n\n\nThe other user must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n\n\n Purging a key that holds dual authorization in the console \n\nFour hours after the other user with a Manager access policy has authorized the key for deletion, it can be purged by one of the users as long as they hold [the KeyPurge attribute](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grant-access-keysgrant-access-keys-specific-functions).\n\nThis can be done by clicking the \u22ef icon to open a list of options for the key that you want to purge and then clicking Purge. If you cannot delete the key, make sure it has been at least four hours since the key was authorized for deleting by another user and that you hold the KeyPurge attribute.\n\n\n\n\n\n Authorize deletion for a key with the API \n\n[After you enable dual authorization for an instance or key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\/actions\/setKeyForDeletion\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09055-23127-24436","score":15.140403,"text":"\nUser 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:policy:2427dbde-6cff-41eb-8b5a-ff26b038cafc\",\n\"lastUpdateDate\": \"2020-06-22T21:29:10Z\",\n\"updatedBy\": \"user id ...<redacted>...\",\n\"dualAuthDelete\": {\n\"enabled\": true\n}\n}\n]\n\n cancel a previously scheduled key delete\n$ ibmcloud kp key cancel-delete $KEY_ID\n\nCancelling key for deletion...","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_08435-1255-3053","score":14.832977,"text":"\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09055-69659-70937","score":14.696932,"text":"\nUser 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-twokp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_08776-2908-4519","score":14.539972,"text":"\nDual authorization enabled The status of a dual authorization policy on the key.<br><br><br><br> * True: Dual authorization is required to delete the key.<br> * False: No prior authorization is required to delete the key.<br><br><br> \n Set for deletion Indicates whether a delete authorization is issued for a key.<br><br><br><br> * True: An authorization to delete this key is issued by the first user. A second user with a Manager access policy can safely delete the key.<br> * False: The key is not set for deletion. No further action is needed.<br><br><br> \n Deletion expiration The date that an authorization for deletion expires for the key. If this date passes, the authorization is no longer valid. If False is the value for the Dual authorization enabled or Set for deletion column of the key, the Deletion expiration column is left empty. \n\n\n\nNot all key characteristics are displayed by default. To customize how the Keys table is to be presented, click the Settings icon![Settings icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/settings.svg) and check the columns to be displayed.\n\nNot seeing the full list of keys that are stored in your service instance? Verify with your administrator that you are assigned the correct role for the applicable service instance or individual key. For more information about roles, see [Roles and permissions](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessroles).\n\nYou can also search for a specific key by using the search bar, or filter keys based on your needs by clicking the Filter icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-keys"},{"document_id":"ibmcld_08987-28071-29358","score":14.507555,"text":"\nThe [kp key schedule-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-pluginkp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin"}],"retriever_scores":{"recall_1":0.2,"recall_3":0.4,"recall_5":0.4,"recall_10":0.6,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.55314647,"ndcg_cut_10":0.6661998718}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-4752-6201","score":16.555756,"text":"\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-3634-5079","score":15.382438,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-8253-9823","score":15.274486,"text":"\nDuring this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09055-23127-24436","score":14.344611,"text":"\nUser 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:policy:2427dbde-6cff-41eb-8b5a-ff26b038cafc\",\n\"lastUpdateDate\": \"2020-06-22T21:29:10Z\",\n\"updatedBy\": \"user id ...<redacted>...\",\n\"dualAuthDelete\": {\n\"enabled\": true\n}\n}\n]\n\n cancel a previously scheduled key delete\n$ ibmcloud kp key cancel-delete $KEY_ID\n\nCancelling key for deletion...","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_03418-8007-9822","score":14.215147,"text":"\nAnd you are charged only once when the same anonymous user interacts with your assistant multiple times in a single month.\n\n\n\n\n\n Apple devices \n\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs.\n\nTo avoid this problem, use a server-side first-party cookie in your web application. For example, when an anonymous user visits your website for the first time, you can generate a unique user ID and store it in a server-side cookie with any expiration date you choose. Then, your code can use the [updateUserID()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdateuserid) instance method to set the user ID. You can then use the same cookie to set the same user ID for this customer on any future visits until it expires.\n\n\n\n\n\n More information \n\nFor more information about billing, see [User-based plans explained](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-planadmin-managing-plan-user-based).\n\nFor more information about MAU limits per plan, see [Web chat integration limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-limits).\n\nFor more information about deleting a user's data, see [Labeling and deleting data](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-information-securityinformation-security-gdpr-wa).\n\n\n\n\n\n\n\n Human agent service integration \n\nYou can configure the web chat to transfer a customer to a human customer support agent if the customer asks for help from a person. The following service desk integrations are supported:\n\nBuilt-in service desk integrations:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basics"},{"document_id":"ibmcld_09061-7530-9143","score":14.200673,"text":"\nIf no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.\n\nhttps:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-up-api).\n2. Retrieve the ID of the key that you would like to delete.\n\nYou can retrieve the ID for a specified key by making a GET \/v2\/keys request, or by viewing your keys in the Key Protect dashboard.\n3. Run the following curl command to delete the key and its contents.\n\n$ curl -X DELETE \"https:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\" -H \"prefer: <return_preference>\"\n\nReplace the variables in the example request according to the following table.\n\n\n\n\n\nTable 2. Describes the variables that are needed to delete a key.\n\n Variable Description \n\n region Required. The region abbreviation, such as us-south or eu-gb, that represents the geographic area where your Key Protect instance resides. <br> <br>For more information, see [Regional service endpoints](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-regionsservice-endpoints). \n key_ID_or_alias Required. The unique identifier or alias for the key that you would like to delete. \n IAM_token Required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_08987-93468-94751","score":13.325761,"text":"\nIf a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-pluginkp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:policy:2427dbde-6cff-41eb-8b5a-ff26b038cafc\",\n\"lastUpdateDate\": \"2020-06-22T21:36:16Z\",\n\"updatedBy\": \"user id ...<redacted>...\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin"},{"document_id":"ibmcld_09061-1334-3188","score":12.988133,"text":"\nWhen the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted. When you delete a key, it is \"soft deleted\", meaning that the key and its associated data will be restorable up to 30 days after deletion. You are able to still retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically [purged](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-key-purge), or hard deleted, and its associated data will be permanently removed from the Key Protect service.\n\n\n\n\n\n\n\n Authorize deletion for a key in the console \n\n[After you enable dual authorization for an instance or key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by using the Key Protect IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_16382-2411-3972","score":12.4889345,"text":"\nt.src='https:\/\/web-chat.global.assistant.dev.watson.appdomain.cloud\/versions\/' +\n(window.watsonAssistantChatOptions.clientVersion || 'latest') +\n'\/WatsonAssistantChatEntry.js';\ndocument.head.appendChild(t);\n});\n<\/script>\nShow more\n\n\n\n Apple devices \n\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs.\n\nTo avoid this problem, use a server-side first-party cookie in your web application. For example, when an anonymous user visits your website for the first time, you can generate a unique user ID and store it in a server-side cookie with any expiration date you choose. Then, your code can use the [updateUserID()](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methodsupdateuserid) instance method to set the user ID. You can then use the same cookie to set the same user ID for this customer on any future visits until it expires.\n\n\n\n\n\n More information \n\nFor more information about billing, see [User-based plans explained](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-managing-plan).\n\nFor more information about MAU limits per plan, see [Pricing](https:\/\/www.ibm.com\/products\/watson-assistant\/pricing).\n\nFor more information about deleting a user's data, see [Labeling and deleting data](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-securing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid"},{"document_id":"ibmcld_16365-15662-16934","score":12.315084,"text":"\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs. For information about how to avoid this problem, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nFor information about how to customize the handling of user identity information for billing purposes, see [Managing user identity information](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nThe usage is measured differently depending on the plan type. For Lite plans, usage is measured by the number of \/message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU \n Plus Unlimited MAU \n Trial 5,000 MAU \n Lite 10,000 API (approximately 1,000 MAU)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-architecture"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.75,"recall_5":0.75,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":0.8318724637,"ndcg_cut_10":0.9550236581}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08211-2628-3483","score":19.33693,"text":"\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period. If a server is restored, the timeframe for which the server was within the resource reclamations is billed to your account.\n\nAfter the server is deleted, only metadata, which isn't considered to be personal data is kept for 6 months. Make sure you back up important data for future use because you can't recover data after the virtual server has been deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_08211-1158-3123","score":15.624686,"text":"\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_08217-3469-5347","score":13.734013,"text":"\nHow to fix it \n\nVirtual servers in paid plans aren't deleted. You can remove the server from the resource list by deleting it from the resource list.\n\n\n\n\n\n Can't create new virtual servers because of exhausted resources or plan limitations \n\nYou can't create new virtual servers because of exhausted resources or plan limitations, although you've less than the described limits.\n\n What\u2019s happening \n\nYou try to create a new server but fail. Instead a message is displayed, which informs you that the maximum number of servers is reached in the selected data center for this account, or that you've reached the maximum number of free plans for this account. When you look in the resource list, you see that you haven't reached the limit.\n\n Why it\u2019s happening \n\nThe resource list is not a complete list of your servers. If you \u201cdelete\u201d a server from the resource list, it's made inaccessible and marked for deletion, but it's still available for you within the [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) for a limited amount of time, as described in [Deleting a virtual server](https:\/\/cloud.ibm.com\/docs\/services\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs).\n\n How to fix it \n\nDepending on your requirements, you must either delete the resource from the resource reclamations, or select a different data center (maximum number of servers is reached), or select the appropriate paid plan that meets your requirements if you reach the maximum number of free plans. For more information, see [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations).\n\n\n\n\n\n VoiceOver on MacOS does not announce all information on the dashboard in Firefox \n\nVoiceOver on MacOS does not announce information presented on the dashboard in Firefox.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-troubleshooting"},{"document_id":"ibmcld_08217-1687-3909","score":13.140519,"text":"\nWhen you click the 'Inactive' server in Name field, an error message is displayed to indicate that provisioning has failed.\n\n What\u2019s happening \n\nYou try to create more than five virtual servers within a short period in one data center without any existing virtual server instances.\n\n Why it\u2019s happening \n\nThe number of virtual servers per data center is limited to five. Creating more than five virtual servers almost all at the same time in one data center leads to the status 'Inactive' (provisioning failed) for the sixth and all subsequent instances.\n\n How to fix it \n\nYou can either provision more than five virtual servers in different data centers. Or you can provision more than five instances by using different IBM Cloud accounts.\n\n\n\n\n\n Generating a new virtual server fails because of exhausted resources \n\nYou can only create a limited number of virtual server instances in each data center.\n\n What\u2019s happening \n\nWhen you provision a new virtual server, you get an error message because the resources (for example, memory) are exhausted.\n\n Why it\u2019s happening \n\nThe resources for the selected data center are exhausted.\n\n How to fix it \n\nRetry the action and select a different data center.\n\n\n\n\n\n Can't connect to free virtual server anymore \n\nI can't connect to a server (for example, via SSH), which is in the free plan although it's visible in the IBM Cloud resource list.\n\n What\u2019s happening \n\nYou can't connect to a server in the free plan anymore. The server is still visible in the resource list, but the dashboard shows an error message. The message indicates that the server has expired. When a server expires, the server and all data that is stored on the server are deleted.\n\n Why it\u2019s happening \n\nAll virtual servers in free plans are deleted after 30 days.\n\n How to fix it \n\nVirtual servers in paid plans aren't deleted. You can remove the server from the resource list by deleting it from the resource list.\n\n\n\n\n\n Can't create new virtual servers because of exhausted resources or plan limitations \n\nYou can't create new virtual servers because of exhausted resources or plan limitations, although you've less than the described limits.\n\n What\u2019s happening \n\nYou try to create a new server but fail.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-troubleshooting"},{"document_id":"ibmcld_09087-53684-55836","score":12.947011,"text":"\nThe access is permanently forbidden and tied to the application logic, such as insufficient rights to a resource.\n\n\n\n\n\n Context \n\nThis error message occurs when an instance policy prevents access to a resource. For example, if the request originated from a public IP address and the instance policy prohibits access from a public IP address, then you will receive this error message.\n\n\n\n\n\n\n\n 20 - Signature is invalid \n\n\n\n Message \n\nSignature is invalid\n\nReason code: INVALID_SIG_EXP_ERR\n\n\n\n\n\n HTTP status code \n\n422 - Unprocessable Entity\n\nThe HTTP 422 Unprocessable Entity response status code indicates that the server understands the content type of the request entity, and the syntax of the request entity is correct, but it was unable to process the contained instructions.\n\nThe client should not repeat this request without modification.\n\n\n\n\n\n Context \n\nAn error occurred when a key was rewrapped.\n\nIf you get this error please contact [IBM support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter)\n\n\n\n\n\n\n\n 21 - The action could not be performed on... \n\n\n\n Message \n\nThe action could not be performed on the key because the key is expired\n\nReason code: KEY_EXPIRED_ERR\n\n\n\n\n\n HTTP status code \n\n400 - Bad Request\n\nThe HTTP 400 Bad Request response status code indicates that the server cannot or will not process the request due to something that is perceived to be a client error (e.g., malformed request syntax, invalid request message framing, or deceptive request routing).\n\nThe client should not repeat this request without modification.\n\n\n\n\n\n Context \n\nThis error occurs when restoring a deleted key after the key has expired.\n\n\n\n Example \n\nA key restore request fails because the key is delete and the key has expired.\n\nThe following steps will create this error.\n\n\n\n1. Create a key material (payload) and an expiration date\n2. Create a root key using the key material and the expiration date\n3. Capture the key id\n4. Allow the expiration date to pass\n5. Delete the key\n6. Restore the key, which fails because you cannot restore a deleted key after the expiration date\n\n\n\n step 1 - create a key material (payload) and an expiration date","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_15998-1422-3109","score":12.697607,"text":"\nCommon problems \n\nHere are a few difficulties you might encounter.\n\n\n\n Not authorized (401 or 403 error) \n\nYour account might not be authorized for VPC. Make sure that you are using an account that has been onboarded.\n\n\n\n\n\n IAM token expired \n\nThe service is no longer returning any JSON, instead of just giving an HTTP \"401 Unauthorized\" to all requests. This error occurs after about an hour if your IAM token has expired. Refresh your IAM token by rerunning iam_token=$(ibmcloud iam oauth-tokens | awk '\/IAM\/{ print $4; }').\n\n\n\n\n\n Cannot create resources \n\nIf you cannot create a VPC or other resources, make sure that the owner of the account has granted you the correct [permissions](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resourcesmanaging-user-permissions-for-vpc-resources).\n\n\n\n\n\n No response from API \n\nIf the API is no longer returning any JSON, it is likely your IAM token has expired and needs to be refreshed. Log in to IBM Cloud again or refresh your token by running iam_token=$(ibmcloud iam oauth-tokens | awk '\/IAM\/{ print $4; }').\n\n\n\n\n\n\n\n Cannot delete resources \n\nCertain operations--creating and deleting virtual server instances, and creating and deleting subnets, for example--are completed asynchronously through the API. Because of this fact, it is recommended to poll the resources you're deleting, to check for deletion before proceeding.\n\nIt can take several minutes for resources to be deleted from the system, due to these asynchronous operations. To facilitate deletion, the best practice is to do things in this order:\n\n\n\n1. Delete your instances\n2. Delete your public gateways\n3. Delete your subnets\n4. Delete your VPCs","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-troubleshooting-vpc"},{"document_id":"ibmcld_02586-15452-17185","score":12.191729,"text":"\n* A request would update or create a resource with a binding to an existing resource which has irrecoverably failed or expired. This SHOULD result in a 400 Bad Request.\n* A request would use an existing resource (for example, to generate a new resource) which has irrecoverably failed or expired. This SHOULD result in a 400 Bad Request.\n\n\n\n\n\n\n\n\n\n Server errors: 5xx \n\n\n\nServer error status codes\n\n Code Meaning Description \n\n 500 [Internal Server Error](https:\/\/datatracker.ietf.org\/doc\/html\/rfc7231section-6.6.1) This code MUST be returned when a fatal error caused by an unexpected condition occurs on the server and was not caused by the client.<br><br>[11] \n 501 [Not Implemented](https:\/\/datatracker.ietf.org\/doc\/html\/rfc7231section-6.6.2) The code MUST be returned when the server does not recognize the request method. This code MUST only be used for methods not documented under [Methods](https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-methods). See also 405 under [client errors](https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-status-codesclient-errors-4xx). \n 503 [Service Unavailable](https:\/\/datatracker.ietf.org\/doc\/html\/rfc7231section-6.6.4) This code SHOULD be returned when the server is temporarily unavailable because it is overloaded or down for maintenance. The server MAY include a Retry-After header telling the client when it should try submitting the request again. \n 505 [HTTP Version Not Supported](https:\/\/datatracker.ietf.org\/doc\/html\/rfc7231section-6.6.6) This code SHOULD be returned when the server does not support the HTTP protocol version used in a request. The response SHOULD contain a document describing which protocols the server does support. \n\n\n\n\n\n 500 and 503 errors","title":"","source":"https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-status-codes"},{"document_id":"ibmcld_08211-7-1559","score":12.132643,"text":"\nDeleting a virtual server \n\nYou can use the Hyper Protect Virtual Servers UI or the CLI to delete virtual servers. Deleted servers that belong to paid plans can also be restored before the reclamation period expires.\n\n\n\n Deleting a virtual server in the UI \n\n\n\n1. Go to the [Resource list](https:\/\/cloud.ibm.com\/resources) (see [Retrieving virtual server information](https:\/\/cloud.ibm.com\/docs\/services\/hp-virtual-servers?topic=hp-virtual-servers-retrieve-info-vs)) to delete a virtual server.\n2. Select the instance from the Services list and apply the Delete from its action list.\n\n\n\nZoom\n\n![Deleting a virtual server instance](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/29e0ddc9fd7149f916889ba6a4d131cc3528c9bc\/hp-virtual-servers\/image\/hpvs_delete_instance.gif)\n\nFigure 1. Deleting a virtual server instance\n\n\n\n\n\n Deleting a virtual server from the CLI \n\nTo delete Hyper Protect Virtual Servers from the [CLI](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-plugin):\n\n\n\n1. Make sure you know the Cloud resource name (CRN) of the server you want to delete. To find the CRN, run:\n\nibmcloud hpvs instances\n2. To delete the server, run the following command:\n\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https:\/\/cloud.ibm.com\/docs\/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"},{"document_id":"ibmcld_08399-11378-13200","score":12.01595,"text":"\nYou can restore a resource within 7 days after you delete it.\nYou can run the 'ibmcloud resource reclamations' command to check the resources that you can restore.\nTo irrecoverable delete the instance run the 'ibmcloud resource reclamation-delete RECLAMATION_ID' command.\n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it stops and is marked for deletion. It is deleted after a reclamation period of seven days. During this seven-day reclamation period, you can restore the virtual server or manually trigger a deletion thru [resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations).\n\n\n\n\n\n\n\n hpvs registration-key-create \n\nThis command creates a Hyper Protect virtual server gpg registration key. The resulting output files are required as inputs for the hpvs registration-create command, where it is used to sign the registration definition file for the deployment that uses your own image (BYOI). You need to run this command only when you do not have the gpg registration key or you have not already created the key pair, and when you want to use your own image (BYOI).\n\nibmcloud hpvs registration-key-create ID [--gpg-passphrase-path FILE-PATH] [-v VERBOSE]\n\nID\n: The user ID to set for the gpg registration key.\n\n\n\n Command options \n\n--gpg-passphrase-path FILE-PATH\n: Is the path for the file that contains the passphrase that is being used for the registration key. The passphrase must consist of at least 6 characters. To make sure that a new line is not appended, use echo with -n or cat with EOF. If the path is not specified, you are prompted for the passphrase.\n\n-v, --verbose\n: Set to true for verbose output.\n\n\n\n\n\n Example output \n\n$ ibmcloud hpvs registration-key-create abcdefg\nEnter password>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpvs-cli-plugin?topic=hpvs-cli-plugin-hpvs_cli_plugin"},{"document_id":"ibmcld_09087-57974-59599","score":12.008974,"text":"\nShow more\n\n\n\n\n\n JSON response \n\n{\n\"metadata\": {\n\"collectionType\": \"application\/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Bad Request: The key expired on 2020-08-14 19:33:47 +0000 UTC: Key could not be restored. Please see reasons for more details.\",\n\"reasons\":\n{\n\"code\": \"KEY_EXPIRED_ERR\",\n\"message\": \"The action could not be performed on the key because the key is expired.\",\n\"status\": 400,\n\"moreInfo\": \"https:\/\/cloud.ibm.com\/apidocs\/key-protect\"\n}\n]\n}\n]\n}\n\n\n\n\n\n\n\n\n\n\n\n 22 - The encrypted nonce given does not match... \n\n\n\n Message \n\nThe encrypted nonce given does not match existing record: Please ensure the correct nonce was given in the request\n\nReason code: INCORRECT_NONCE_ERR\n\n\n\n\n\n HTTP status code \n\n400 - Bad Request\n\nThe HTTP 400 Bad Request response status code indicates that the server cannot or will not process the request due to something that is perceived to be a client error (e.g., malformed request syntax, invalid request message framing, or deceptive request routing).\n\nThe client should not repeat this request without modification.\n\n\n\n\n\n Context \n\nThis error message is applicable to the restore and rotate key interfaces.\n\nThis example is based on the restore key command and it uses the [CLI](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-reference) because the output is easier to follow than the [API](https:\/\/cloud.ibm.com\/apidocs\/key-protect).\n\nStep 1 - setup the problem by creating a root key using an import token and then delete the key\n\n create an import token that expires in 15 minutes (900 seconds) and allows 10 retrievals","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09159-4-1910","score":11.799088,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Restoring keys \n\nWhen a key is deleted, it is moved to a \"destroyed\" state. However, information about the key (such as its metadata) can still be viewed and you have 30 days to restore the key to an active state. For this reason, a key deletion is considered a \"soft delete\" in that the key still exists but can no longer be used to access the data it has encrypted. This topic describes the process to restore a key and the limitations of the key restoration process.\n\nAs part of a testing and development process, it is normal to create and delete keys often. These keys are not gone forever; rather they are \"soft deleted\" and moved to a destroyed state. This does not mean they have been destroyed in the sense that they are gone forever. Instead, it simply means they cannot be used as part of any key actions such as using the key to encrypt or decrypt data. The key data can only be looked at, and, if the key was deleted in error, it might be possible to restore the key to an active state.\n\nThis intermediate period, in which a key has been deleted but can still be restored, lasts for 30 days. Between 30 days and 90 days, the key data can still be accessed, but the key can no longer be restored. After 90 days, the key becomes eligible to be automatically purged, which can occur at any time after 90 days. Purged keys, unlike destroyed keys, are gone forever.\n\n\n\nTable 1. Ties key states to the time from a key's deletion to what actions are possible with the key.\n\n Time from key deletion Name of key state Can view\/access key data? Can restore? \n\n One-30 days Destroyed Yes Yes \n 30-90 days Destroyed Yes No \n After 90 days Purged* No No \n\n\n\nNote: because purged keys are completely inaccessible and \"destroyed\" in the common usage of the word, there is technically no \"purged\" key state. Purged keys are simply gone and therefore don't have a \"state\" one way or another.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-restore-keys"},{"document_id":"ibmcld_09061-1334-3188","score":11.754699,"text":"\nWhen the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted. When you delete a key, it is \"soft deleted\", meaning that the key and its associated data will be restorable up to 30 days after deletion. You are able to still retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically [purged](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-key-purge), or hard deleted, and its associated data will be permanently removed from the Key Protect service.\n\n\n\n\n\n\n\n Authorize deletion for a key in the console \n\n[After you enable dual authorization for an instance or key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by using the Key Protect IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-4-1966","score":11.669889,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09070-7-2084","score":11.653096,"text":"\nAbout deleting and purging keys \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to delete an encryption key and its key material if you are a manager for your Key Protect instance.\n\nBefore you can delete an instance, you must delete every key in that instance. However, if you close your account, any existing instances and keys are automatically hard deleted. Check out [Account cancelation and data deletion](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-complianceaccount-cancelation) for more information.\n\nIn the event that a key is no longer needed or should be removed, Key Protect allows you to delete and ultimately purge keys, an action that shreds the key material and makes any of the data encrypted with it inaccessible.\n\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n\nThe following table lists the time frames in which you can view, restore, and purge a key after it has been deleted.\n\n\n\nTable 1. Lists how users can interact with keys during certain time intervals after a key has been deleted","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keys"},{"document_id":"ibmcld_09064-8216-9792","score":11.607675,"text":"\n\"algorithmMode\": \"Deprecated\",\n\"lastUpdateDate\": \"2020-03-16T20:41:27Z\",\n\"dualAuthDelete\": {\n\"enabled\": false\n},\n\"deleted\": true,\n\"deletionDate\": \"2020-03-16T21:46:53Z\",\n\"deletedBy\": \"...\"\n}\n]\n}\n\nFor a detailed description of the available parameters, see the Key Protect [REST API reference doc](https:\/\/cloud.ibm.com\/apidocs\/key-protect).\n\n\n\n Using the force query parameter \n\nKey Protect blocks the deletion of a key that's protecting a cloud resource, such as a Cloud Object Storage bucket. You can force delete a key and its contents by making a DELETE call to the following endpoint.\n\nhttps:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>?force=true\n\nWhen you delete a key that has registrations associated with it, you immediately deactivate its key material and the data encrypted by the key. Any data that is encrypted by the key becomes inaccessible. Thirty days after a key is deleted, the key can no longer be restored and the key material will be destroyed after 90 days.\n\nForce deletion on a key won't succeed if the key is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy), which is a Write Once Read Many (WORM) policy set on the your IBM Cloud resource. You can verify whether a key is associated with a non-erasable resource by checking the 'preventKeyDeletion\" field in the [registration details](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) for the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys"},{"document_id":"ibmcld_16727-1212381-1214315","score":11.475943,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1209748-1211682","score":11.475943,"text":"\nDeleting a key moves it into a Destroyed state, a \"soft\" deletion in which the key can still be seen and restored for 30 days. After 90 days, the key will be automatically purged, or \"hard deleted\", and its associated data will be permanently shredded and removed from the Key Protect service. If it is desirable that a key be purged sooner than 90 days, it is also possible to hard delete a key four hours after it has been moved into the Destroyed state.\n\nAfter a key has been deleted, any data that is encrypted by the key becomes inaccessible, though this can be reversed if the key is restored within the 30-day time frame. After 30 days, key metadata, registrations, and policies are available for up to 90 days, at which point the key becomes eligible to be purged. Note that once a key is no longer restorable and has been purged, its associated data can no longer be accessed. As a result, [destroying resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliancedata-deletion) is not recommended for production environments unless absolutely necessary.\n* What happens if I try to delete a key that's actively encrypting data?\n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. If you try to delete a key that's registered with a cloud resource, the action won't succeed.\n\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_08414-28698-30846","score":11.447683,"text":"\nIf the delete key event has a reason.reasonCodeof 409, the key cannot be deleted because it is possibly protecting one or more cloud resources that have a retention policy. Make a GET request to \/keys\/{id}\/registrations to learn which resources this key is associated with. A registration with \"preventKeyDeletion\": true indicates that the associated resource has a retention policy. To enable deletion, contact an account owner to remove the retention policy on each resource that is associated with this key.\n\nA delete key event might also receive a reason.reasonCode of 409 due to a dual auth deletion policy on the key. Make a GET request to \/api\/v2\/keys\/{id}\/policies to see whether a dual authorization policy is associated with your key. If there is a policy set, contact the other authorized user to delete the key.\n\n\n\n\n\n Unable to authenticate while making a request \n\nIf the event has a reason.reasonCode of 401, you might not have the correct authorization to perform Hyper Protect Crypto Services actions in the specified service instance. Verify with an administrator that you are assigned the correct platform and service access roles in the applicable service instance. For more information about roles, see [Roles and permissions](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-access).\n\nCheck that you are using a valid token that is associated with an account that is authorized to perform the service action.\n\n\n\n\n\n Unable to view or list keys in a service instance \n\nYou can call GET api\/v2\/keys to list the keys that are available in your service instance. If responseData.totalResources is 0, query for keys in the deleted state by using the state parameter or adjust the offset and limit parameters in your request.\n\n\n\n\n\n Lifecycle action on a key with registrations did not complete \n\nThe responseData.reasonForFailure and responseData.resourceCRN fields contain information about why the action wasn't able to be completed.\n\nIf the event has a reason.reasonCode of 409, the action cannot be completed due to the adopting service's key state conflicting with the key state that Hyper Protect Crypto Services has.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events"},{"document_id":"ibmcld_08435-3634-5079","score":11.4013405,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09064-4-1760","score":11.378882,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys using a single authorization \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to delete an encryption key and its key material, if you are a manager for your Key Protect instance.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Deleting keys in the console \n\nBy default, Key Protect requires one authorization to delete a key. If you prefer to delete your encryption keys by using a graphical interface, you can use the IBM Cloud console.\n\n[After you create or import your existing keys into the service](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-root-keys), complete the following steps to delete a key:\n\n\n\n1. [Log in to the IBM Cloud console](https:\/\/cloud.ibm.com\/login\/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.\n6. From the options menu, click Delete key and confirm the key deletion in the next screen by ensuring the key has no associated resources. Note that you will not be able to delete the key if it is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy).\n\n\n\nAfter you delete a key, the key transitions to the Destroyed state. Any data encrypted by keys in this state is no longer accessible.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.25,"recall_5":0.25,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.296081911,"ndcg_cut_5":0.2463023887,"ndcg_cut_10":0.3764290721}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09064-8216-9792","score":15.324627,"text":"\n\"algorithmMode\": \"Deprecated\",\n\"lastUpdateDate\": \"2020-03-16T20:41:27Z\",\n\"dualAuthDelete\": {\n\"enabled\": false\n},\n\"deleted\": true,\n\"deletionDate\": \"2020-03-16T21:46:53Z\",\n\"deletedBy\": \"...\"\n}\n]\n}\n\nFor a detailed description of the available parameters, see the Key Protect [REST API reference doc](https:\/\/cloud.ibm.com\/apidocs\/key-protect).\n\n\n\n Using the force query parameter \n\nKey Protect blocks the deletion of a key that's protecting a cloud resource, such as a Cloud Object Storage bucket. You can force delete a key and its contents by making a DELETE call to the following endpoint.\n\nhttps:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>?force=true\n\nWhen you delete a key that has registrations associated with it, you immediately deactivate its key material and the data encrypted by the key. Any data that is encrypted by the key becomes inaccessible. Thirty days after a key is deleted, the key can no longer be restored and the key material will be destroyed after 90 days.\n\nForce deletion on a key won't succeed if the key is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy), which is a Write Once Read Many (WORM) policy set on the your IBM Cloud resource. You can verify whether a key is associated with a non-erasable resource by checking the 'preventKeyDeletion\" field in the [registration details](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) for the key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys"},{"document_id":"ibmcld_01019-1608-2449","score":15.09066,"text":"\nIf you need to delete the key during the soft-deletion period, you have to force delete the key. After the soft-deletion period, the key can be deleted without the force. You can check the association between the key and your deployment to determine when you can delete the key.\n\n\n\n\n\n Deleting data in your database \n\nThe Db2 database stores data in pages on block storage. When DELETE or TRUNCATE operations are performed, that data is no longer accessible unless you are using TEMPORAL tables. The physical pages that contain the data are not immediately erased and might still exist on the disk, but will be overwritten as needed. There is no ability to recover this data. The database provides the REORG and REDUCE MAX capability to reclaim this space for other activities or it will be reused when the database needs to store more data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-del_db"},{"document_id":"ibmcld_09087-30097-31549","score":14.806337,"text":"\nYou must use the force option to delete a root key that is registered with another cloud resource.\n\nRegistrations are associations between root keys and other cloud resources, such as Cloud Object Storage (COS) buckets or Cloud Databases deployments.\n\nFor more information about Registrations, see [viewing associations between root keys and encrypted IBM Cloud resources](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources).\n\n[See this explanation](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-key-protect-cli-referencekp-key-delete) of deleting keys that are registered with another cloud resource (look at the force option).\n\n this CLI request fails because the registration was not deleted\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID\n\nDeleting key: 52a9d772-8982-4620-bfb4-b070dd812a0c, from instance: b0d84b32-09d0-4314-8049-da78e3b9ab6f...\nFAILED\nkp.Error:\ncorrelation_id='c27b7948-4a1f-4cbd-8770-cb3616888e27',\nmsg='Conflict:\nKey could not be deleted.\nPlease see \"reasons\" for more details.',\nreasons='[PROTECTED_RESOURCE_ERR:\nKey is protecting one or more cloud resources -\nFOR_MORE_INFO_REFER: https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-troubleshootingunable-to-delete-keys]'\n\n this CLI request succeeds when using the --force option\n the registration between Key Protect and the cloud resource exists\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID --force --output json\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-error-messages"},{"document_id":"ibmcld_01034-3831-4923","score":14.574598,"text":"\nAfter the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-hpcs"},{"document_id":"ibmcld_09064-9212-10938","score":14.430712,"text":"\nForce deletion on a key won't succeed if the key is protecting a registered IBM Cloud resource that's non-erasable due to a [retention policy](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutableimmutable-terminology-policy), which is a Write Once Read Many (WORM) policy set on the your IBM Cloud resource. You can verify whether a key is associated with a non-erasable resource by checking the 'preventKeyDeletion\" field in the [registration details](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) for the key. Then, you must contact an account owner to remove the retention policy on each registered IBM Cloud resource that is associated with the key before you can delete the key.\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-up-api).\n2. Retrieve the ID of the key that you want to force delete.\n\nYou can retrieve the ID for a specified key by making a GET \/v2\/keys\/ request, or by viewing your keys in the Key Protect dashboard.\n3. Run the following curl command to force delete the key and its contents.\n\n$ curl -X DELETE \"https:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>?force=true\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\" -H \"prefer: <return_preference>\"\n\nReplace the variables in the example request according to the following table.\n\n\n\n\n\nTable 2. Describes the variables that are needed to delete keys with the Key Protect API.\n\n Variable Description \n\n region Required. The region abbreviation, such as us-south or eu-gb, that represents the geographic area where your Key Protect instance resides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys"},{"document_id":"ibmcld_06638-4935-6851","score":14.383197,"text":"\nKey Protect allows you to [initiate a force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events) as kms.secrets.delete.\n\n\n\n\n\n Bring your own key for backups \n\nIf you use Key Protect, when you provision a database you can also designate a key to encrypt the Cloud Object Storage disk that holds your deployment's backups.\n\nBYOK for backups is available only in US regions us-south and us-east, and eu-de.\n\nOnly keys in the us-south and eu-de are durable to region failures. To ensure that your backups are available even if a region failure occurs, you must use a key from us-south or eu-de, regardless of your deployment's location.\n\n\n\n Granting the delegation authorization \n\nTo enable your deployment to use the Key Protect key, you need to [Enable authorization to be delegated](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceauth) when granting the service authorizations. If the delegation authorization is not present before provisioning your deployment with a key, the provision fails.\n\n\n\n\n\n Using the Key at Provision in the CLI \n\nAfter the appropriate authorization and delegation is granted, you supply the [key name or CRN](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keys) when you provision a deployment.\n\nIn the CLI, use the backup_encryption_key_crn parameter in the parameters JSON object.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-key-protect"},{"document_id":"ibmcld_09562-4925-6841","score":14.383197,"text":"\nKey Protect allows you to [initiate a force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events) as kms.secrets.delete.\n\n\n\n\n\n Bring your own key for backups \n\nIf you use Key Protect, when you provision a database you can also designate a key to encrypt the Cloud Object Storage disk that holds your deployment's backups.\n\nBYOK for backups is available only in US regions us-south and us-east, and eu-de.\n\nOnly keys in the us-south and eu-de are durable to region failures. To ensure that your backups are available even if a region failure occurs, you must use a key from us-south or eu-de, regardless of your deployment's location.\n\n\n\n Granting the delegation authorization \n\nTo enable your deployment to use the Key Protect key, you need to [Enable authorization to be delegated](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceauth) when granting the service authorizations. If the delegation authorization is not present before provisioning your deployment with a key, the provision fails.\n\n\n\n\n\n Using the Key at Provision in the CLI \n\nAfter the appropriate authorization and delegation is granted, you supply the [key name or CRN](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keys) when you provision a deployment.\n\nIn the CLI, use the backup_encryption_key_crn parameter in the parameters JSON object.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-key-protect"},{"document_id":"ibmcld_07578-1211120-1213024","score":14.343598,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1213753-1215657","score":14.343598,"text":"\nIf needed, you can [force deletion on a key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01041-3464-4855","score":14.24236,"text":"\nAfter the soft-deletion period the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. Once the key is deleted your data is unrecoverable.\n\nKey Protect or Hyper Protect Crypto Services allows you to initiate a force delete of a key that is in use by IBM Cloud\u00ae services using [Key Protect](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) or [Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys), including your Db2 on Cloud deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks containing your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data contained within them. Key deletion is sent to the Log Analysis Activity Tracker as kms.secrets.delete using [Key Protect](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events) and as hs-crypto.secrets.delete using [Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-key-management-services"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.5437713092,"ndcg_cut_10":0.5437713092}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01034-3831-4923","score":19.916576,"text":"\nAfter the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-hpcs"},{"document_id":"ibmcld_01041-3464-4855","score":19.886354,"text":"\nAfter the soft-deletion period the key can be deleted without the force. You can check the [association between the key and your deployment](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-protected-resources) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. Once the key is deleted your data is unrecoverable.\n\nKey Protect or Hyper Protect Crypto Services allows you to initiate a force delete of a key that is in use by IBM Cloud\u00ae services using [Key Protect](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) or [Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keys), including your Db2 on Cloud deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks containing your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data contained within them. Key deletion is sent to the Log Analysis Activity Tracker as kms.secrets.delete using [Key Protect](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events) and as hs-crypto.secrets.delete using [Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-at-events).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2onCloud?topic=Db2onCloud-key-management-services"},{"document_id":"ibmcld_06381-2433-3517","score":19.122368,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"},{"document_id":"ibmcld_06564-2541-3625","score":19.122368,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-deprovisioning"},{"document_id":"ibmcld_09551-2545-3629","score":19.122368,"text":"\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"},{"document_id":"ibmcld_06443-2410-3623","score":19.076527,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-etcd?topic=databases-for-etcd-deprovisioning"},{"document_id":"ibmcld_06696-2412-3625","score":19.076527,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-redis?topic=databases-for-redis-deprovisioning"},{"document_id":"ibmcld_06627-2422-3635","score":19.076527,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"},{"document_id":"ibmcld_06499-2416-3629","score":19.076527,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"},{"document_id":"ibmcld_06341-2428-3641","score":19.076527,"text":"\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"}],"retriever_scores":{"recall_1":0.1666666667,"recall_3":0.1666666667,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6164336326,"ndcg_cut_10":0.8337883909}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08435-4752-6201","score":15.757757,"text":"\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/setKeyForDeletion'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-8253-9823","score":15.12578,"text":"\nDuring this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps:\/\/api.<region>.hs-crypto.cloud.ibm.com:<port>\/api\/v2\/keys\/<key_ID>\/actions\/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_08435-3634-5079","score":15.002624,"text":"\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"},{"document_id":"ibmcld_09061-7530-9143","score":14.533808,"text":"\nIf no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.\n\nhttps:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-set-up-api).\n2. Retrieve the ID of the key that you would like to delete.\n\nYou can retrieve the ID for a specified key by making a GET \/v2\/keys request, or by viewing your keys in the Key Protect dashboard.\n3. Run the following curl command to delete the key and its contents.\n\n$ curl -X DELETE \"https:\/\/<region>.kms.cloud.ibm.com\/api\/v2\/keys\/<keyID_or_alias>\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\" -H \"prefer: <return_preference>\"\n\nReplace the variables in the example request according to the following table.\n\n\n\n\n\nTable 2. Describes the variables that are needed to delete a key.\n\n Variable Description \n\n region Required. The region abbreviation, such as us-south or eu-gb, that represents the geographic area where your Key Protect instance resides. <br> <br>For more information, see [Regional service endpoints](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-regionsservice-endpoints). \n key_ID_or_alias Required. The unique identifier or alias for the key that you would like to delete. \n IAM_token Required.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-dual-auth-keys"},{"document_id":"ibmcld_09055-23127-24436","score":14.044716,"text":"\nUser 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:policy:2427dbde-6cff-41eb-8b5a-ff26b038cafc\",\n\"lastUpdateDate\": \"2020-06-22T21:29:10Z\",\n\"updatedBy\": \"user id ...<redacted>...\",\n\"dualAuthDelete\": {\n\"enabled\": true\n}\n}\n]\n\n cancel a previously scheduled key delete\n$ ibmcloud kp key cancel-delete $KEY_ID\n\nCancelling key for deletion...","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-cli-reference-five-two"},{"document_id":"ibmcld_09562-7597-9856","score":13.896214,"text":"\nOne is the entry for the deployment that lists its status as delegator. It is \"User Created\".\n\n\n\nTable 1. Example delegator Key Protect Authorization\n\n Role Source Target Type \n\n AuthorizationDelegator, Reader <cloud-databases> Service Key Protect Service User defined \n\n\n\nAnd one for the Cloud Object Storage bucket for its backups, where the deployment is the initiator.\n\n\n\nTable 2. Example Key Protect Authorization for Cloud Object Storage from Cloud Databases\n\n Role Source Target Type \n\n Reader Cloud Object Storage service Key Protect Service Created by <cloud-databases-crn> \n\n\n\n\n\n\n\n Removing Keys \n\nIAM\/Key Protect does not stop you from removing the policy between the key and Cloud Object Storage (the second example), but doing so can make your backups unrestorable. To prevent this, if you delete the Cloud Object Storage policy that governs the ability of Cloud Databases to use the key for Cloud Object Storage, the policy is re-created to continue backing up your deployment.\n\nBe careful when removing keys and authorizations. If you have multiple deployments that use the same keys, it is possible to inadvertently destroy backups to all of those deployments by revoking the delegation authorization. If possible, do not use the same key for multiple deployment's backups.\n\nIf you want to shred the backups, you can delete the key. Cloud Object Storage ensures that the storage is unreadable and unwriteable. However, any other deployments that use that same key for backups encounter subsequent backup failures.\n\nIf you do require that the same key to be used for multiple deployment's backups, removing keys and authorizations can have the following side effects.\n\n\n\n* If you delete just the Cloud Object Storage authorization (as seen in Table 2), then not only is the deployment that is shown as the creator affected, but any deployments that also use the same key are also affected. Those deployments can encounter temporary backup failures until the policy is automatically re-created. There should be no lasting effects, except for missing backups.\n* If you delete just Cloud Databases delegator authorization, which is created by you (as seen in Table 1), nothing immediately breaks because the second authorization is still in place.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-key-protect"},{"document_id":"ibmcld_06638-7607-9866","score":13.896214,"text":"\nOne is the entry for the deployment that lists its status as delegator. It is \"User Created\".\n\n\n\nTable 1. Example delegator Key Protect Authorization\n\n Role Source Target Type \n\n AuthorizationDelegator, Reader <cloud-databases> Service Key Protect Service User defined \n\n\n\nAnd one for the Cloud Object Storage bucket for its backups, where the deployment is the initiator.\n\n\n\nTable 2. Example Key Protect Authorization for Cloud Object Storage from Cloud Databases\n\n Role Source Target Type \n\n Reader Cloud Object Storage service Key Protect Service Created by <cloud-databases-crn> \n\n\n\n\n\n\n\n Removing Keys \n\nIAM\/Key Protect does not stop you from removing the policy between the key and Cloud Object Storage (the second example), but doing so can make your backups unrestorable. To prevent this, if you delete the Cloud Object Storage policy that governs the ability of Cloud Databases to use the key for Cloud Object Storage, the policy is re-created to continue backing up your deployment.\n\nBe careful when removing keys and authorizations. If you have multiple deployments that use the same keys, it is possible to inadvertently destroy backups to all of those deployments by revoking the delegation authorization. If possible, do not use the same key for multiple deployment's backups.\n\nIf you want to shred the backups, you can delete the key. Cloud Object Storage ensures that the storage is unreadable and unwriteable. However, any other deployments that use that same key for backups encounter subsequent backup failures.\n\nIf you do require that the same key to be used for multiple deployment's backups, removing keys and authorizations can have the following side effects.\n\n\n\n* If you delete just the Cloud Object Storage authorization (as seen in Table 2), then not only is the deployment that is shown as the creator affected, but any deployments that also use the same key are also affected. Those deployments can encounter temporary backup failures until the policy is automatically re-created. There should be no lasting effects, except for missing backups.\n* If you delete just Cloud Databases delegator authorization, which is created by you (as seen in Table 1), nothing immediately breaks because the second authorization is still in place.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-key-protect"},{"document_id":"ibmcld_06638-4935-6851","score":13.532549,"text":"\nKey Protect allows you to [initiate a force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events) as kms.secrets.delete.\n\n\n\n\n\n Bring your own key for backups \n\nIf you use Key Protect, when you provision a database you can also designate a key to encrypt the Cloud Object Storage disk that holds your deployment's backups.\n\nBYOK for backups is available only in US regions us-south and us-east, and eu-de.\n\nOnly keys in the us-south and eu-de are durable to region failures. To ensure that your backups are available even if a region failure occurs, you must use a key from us-south or eu-de, regardless of your deployment's location.\n\n\n\n Granting the delegation authorization \n\nTo enable your deployment to use the Key Protect key, you need to [Enable authorization to be delegated](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceauth) when granting the service authorizations. If the delegation authorization is not present before provisioning your deployment with a key, the provision fails.\n\n\n\n\n\n Using the Key at Provision in the CLI \n\nAfter the appropriate authorization and delegation is granted, you supply the [key name or CRN](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keys) when you provision a deployment.\n\nIn the CLI, use the backup_encryption_key_crn parameter in the parameters JSON object.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-postgresql?topic=databases-for-postgresql-key-protect"},{"document_id":"ibmcld_09562-4925-6841","score":13.532549,"text":"\nKey Protect allows you to [initiate a force delete](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-at-events) as kms.secrets.delete.\n\n\n\n\n\n Bring your own key for backups \n\nIf you use Key Protect, when you provision a database you can also designate a key to encrypt the Cloud Object Storage disk that holds your deployment's backups.\n\nBYOK for backups is available only in US regions us-south and us-east, and eu-de.\n\nOnly keys in the us-south and eu-de are durable to region failures. To ensure that your backups are available even if a region failure occurs, you must use a key from us-south or eu-de, regardless of your deployment's location.\n\n\n\n Granting the delegation authorization \n\nTo enable your deployment to use the Key Protect key, you need to [Enable authorization to be delegated](https:\/\/cloud.ibm.com\/docs\/account?topic=account-serviceauth) when granting the service authorizations. If the delegation authorization is not present before provisioning your deployment with a key, the provision fails.\n\n\n\n\n\n Using the Key at Provision in the CLI \n\nAfter the appropriate authorization and delegation is granted, you supply the [key name or CRN](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-view-keys) when you provision a deployment.\n\nIn the CLI, use the backup_encryption_key_crn parameter in the parameters JSON object.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-key-protect"},{"document_id":"ibmcld_08987-93468-94751","score":13.461071,"text":"\nIf a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https:\/\/cloud.ibm.com\/docs\/key-protect-cli-pluginkp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",\n\"crn\": \"crn:v1:bluemix:public:kms:us-south:a\/ea998d3389c3473aa0987652b46fb146:a192d603-0b8d-452f-aac3-f9e1f95e7411:policy:2427dbde-6cff-41eb-8b5a-ff26b038cafc\",\n\"lastUpdateDate\": \"2020-06-22T21:36:16Z\",\n\"updatedBy\": \"user id ...<redacted>...\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect-cli-plugin"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"81afaf82a0d9a5fad6eaa196f8d9641c<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_11147-1878-4251","score":14.455742,"text":"\nWe recommend that you verify possible changes or additional features that might apply to your environment.\n\n\n\n General disaster recovery strategy \n\nThe approach to defining your DR strategy needs to be systematic and start with the application or service, which is defined as a set of compute resources, for example Kubernetes apps, virtual machines, services, and more, that make up a business application.\n\nWhile a holistic approach might be wanted, the reality is that each business application (cloud service) is independent, with its own\n\nrecovery time objective(RTO) andrecovery point objective(RPO) requirements, which for many customers is expressed in the form of a set of service classes.\n\nBecause each business application has a unique set of compute, services, and other resources, each one needs to be reviewed to make sure that the strategy and requirements for DR for that app are understood, documented, and implemented before going to production. To build the framework that will drive that analysis and work, we outlined profiles for continuous availability and advanced recovery applications with common sets of resources to create the scaffolding that application teams can use for their own applications. For more information, see [Designing an architecture for your application resiliency objectives](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-bcdr-app-recovery).\n\n\n\n DR strategy options \n\nThere are many options to implement DR solutions. For the sake of simplicity, we can group the different options in three major categories:\n\nActive\/Passive\n: Active\/Passive options are based on keeping the full application stack active in one location, while another application stack is deployed in a different location but kept idle or shut down. In the case of prolonged unavailability of the primary site, the application stack is activated in the backup site. Often that requires the restoring of backups that are taken in the primary site. This approach is not recommended when losing data can be a problem, for example when the RPO is less than a few hours or when the availability of the service is critical and the RTO objective is less than a few hours.\n\nActive\/Standby\n: In the Active\/Standby case, the full application stack is active in both the primary and backup location. However, user's transactions are served by the primary site only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-understanding-dr"},{"document_id":"ibmcld_13469-0-2152","score":14.358535,"text":"\n\n\n\n\n\n\n  Disaster recovery and backup \n\nIBM Cloud\u00ae Data Engine stores information about submitted jobs, such as SQL statements, job status, job IDs, and database catalog information like table and views. If a disaster occurs, the regular backups ensure that no more than 24 hours of data are at risk of loss. Backups are done automatically, so no action is required on your side.\n\nThe job results are stored in IBM Cloud\u00ae Object Storage and are independent of any Data Engine disaster recovery.\n\nIf a region becomes unavailable due to a disaster, the IBM Cloud\u00ae team works to get the region available again. You can route your workload to a different region by creating a new instance in an available region. In case you worked with tables or views, you must create those tables in the new instance and region again. Indexes are still available, if they are saved in available buckets, such as cross region buckets, but you must set the corresponding base location. Depending on the location and size of your data, it is possible that the jobs take longer.\n\nUntil recovery completes, you cannot use your instances that were created in the affected location. When data recovery completes, job history is available for the instances again.\n\n\n\n  Restoring a deleted service instance \n\nAfter you delete an instance of the Data Engine service, you can restore the deleted service instance within the data retention period of seven days. After the seven-day period expires, the service instance is permanently deleted.\n\nTo view which service instances are available for restoration, use the [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command. To restore a deleted service, use the [ibmcloud resource reclamation-restore](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command. To view the details of a resource reclamation, use the [ibmcloud resource reclamation](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation) command, with the --output JSON option.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-disaster"},{"document_id":"ibmcld_07102-1754-3343","score":13.79396,"text":"\nYour disaster recovery plan includes knowing, preserving, and being prepared to restore all data that is maintained on IBM Cloud.\n\n\n\n\n\n Backing up your data in Watson Discovery \n\nThere are several methods for backing up the data that is stored in IBM Watson\u00ae Discovery. Consider including these methods in your disaster recovery plan. Also, consider backing up the following data types:\n\n\n\n* Data that you might want a copy of, such as source documents\n* Data that Discovery stores and that you want to extract and back up\n\n\n\nThe following table shows the resources that you can download and re-upload to and from an instance.\n\n\n\nResource recovery support details\nThis table has row and column headers. The row headers identify resources. The column headers identify the different types of recovery support. To understand which recovery methods are supported for a resource, go to the row that describes the resource, and find the column for the recovery method that you are interested in.\n\n Resource Download\/Re-upload from the UI API support \n\n Uploaded and crawled files See note. \n Relevancy training data ![checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/icons\/checkmark-icon.svg) \n Expansion list ![checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/icons\/checkmark-icon.svg) \n Stop words list ![checkmark icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f16b1f78a92498247223b337bd9303c2758b9ba8\/icons\/checkmark-icon.svg) \n Smart Document Understanding user-trained model !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-recovery"},{"document_id":"ibmcld_08117-7-2019","score":13.619935,"text":"\nIBM Cloud Disaster Recovery (DR) and Backup and Restore \n\nLocal service interruption can be caused by many things: hardware failures, bugs, power failures, planned and unplanned maintenance. To minimize a single point of failure, IBM Cloud\u00ae architects create resilient designs that have multiple virtual server instances to provide the highest availability.\n\nHowever, extreme failure events, such as data center wide failures due to network outages, natural disasters, or ransomware are harder to anticipate and plan for. Your Business Continuity and Disaster Recovery (BCDR) plan becomes a critical part of recovering from these types of events. Business continuity focuses on the processes and procedures that you implement to help your people minimize interruptions to business operations. Disaster recovery focuses on the IT components and restoring systems after a disaster.\n\n\n\n Disaster recovery components \n\nThe DR model has two main components that deal with what can be tolerated:\n\n\n\n* Recovery Time Objective (RTO) - the maximum time that the service can be down.\n* Recovery Point Objective (RPO) - the maximum amount of data loss.\n\n\n\nZoom\n\n![DR backup diagram.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/df269b100c3499f1efcbb7d030dce8dec25c539b\/ha-infrastructure\/images\/ha-DR-backup-diagram.svg)\n\nFigure 1. DR backup diagram\n\nThese values are directly correlated to both cost and complexity. A lower amount of time and data loss equates to higher cost and complexity.\n\n\n\n\n\n DR Strategies \n\nYou can implement your DR strategy in one of two ways:\n\n\n\n Strategy Description Benefits \n\n Cold (Active\/Standby) With a Cold DR strategy, your solution is running in one environment and duplicate resources are available on standby. When an event occurs, you react and build up the standby site. A cold strategy is a reactive approach, where the upfront cost is minimal, other than storage costs for snapshots and backups. The cold approach typically entails higher RPO\/RTO times and is simple to implement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ha-infrastructure?topic=ha-infrastructure-ha-dr-backup-restore"},{"document_id":"ibmcld_07502-5502-7788","score":13.533138,"text":"\nThe disaster recovery kit is an off-site and protected repository that includes hardware, software, and system secure configurations, one-time keys, and the disaster recovery plan. Use this disaster recovery kit during an incident response to restore services.\n\n\n\n Infrastructure as code \n\nInfrastructure as code ensures that good backup practices are implemented in a uniform way across the organization. Include implementation of backups as part of deployable architectures. Keep backup configuration close to provisioning code so that it is easier to ensure that backups are adjusted as information system changes occur. Create and configure backup accounts as code.\n\n\n\n\n\n Backup accounts \n\nEach BU account group should include a separate backup account and an additional backup account should be used for the centralized accounts. These backup accounts provide an extra layer of protection for the confidentiality and integrity of the backed up data. If credentials to a source account are compromised, it should not be possible to use that access to tamper with backups.\n\nSupporting this effort, authorization to backup data in the backup account should use service-to-service or service to trusted profile authorization where possible. Otherwise, use secure storage of credentials with least privilege access.\n\nIf you are using Cloud Object Storage for backup, at minimum, use separate buckets for backing up different workload accounts. Also, use separate backup credentials for each bucket where service to service policies are not possible. Use Cloud Object Storage versioning or [immutable buckets](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) for maximum security.\n\nServices that provide built in backup facilities might have limitations regarding backup accounts.\n\n\n\n\n\n Service-specific considerations \n\n\n\n IBM Cloud Databases \n\n[IBM Cloud Databases](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-about) provide automatic daily backups that are stored in the same account and geography. Backups are typically stored in [cross-regional storage](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups&interface=uibackup-locations) and should therefore be immune to a single region outage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture?topic=enterprise-account-architecture-bcdr"},{"document_id":"ibmcld_08669-6042-7847","score":13.345645,"text":"\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities \n\n Instance backups Continuously perform in-region and cross-region backups of key resources and perform continuous testing of backups. Back up your master key; validate the backups and restore data when needed. \n Disaster recovery When an in-region disaster occurs, automatically recover and restart service components. When a regional disaster that affects all available zones occurs, ensure that all data except the master key is replicated to another region. IBM will also make additional crypto units available in a different region and manage routing requests to the new crypto units. When a regional disaster that affects all available zones occurs, load your master key to the new crypto units that IBM provisions in a different region for restoring data. You can also enable and initialize failover crypto units before a disaster occurs, which reduces the downtime. \n Availability Provide high availability capabilities, such as IBM-owned infrastructure in multizone regions, to meet local access and low latency requirements for each supported region. Use the list of [available regions](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-regions) to plan for and create new instances of the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-shared-responsibilities"},{"document_id":"ibmcld_09756-3410-5722","score":13.064514,"text":"\nDisaster recovery is about surviving a catastrophic failure or loss of availability in a single location.\n\nIBM Cloud Monitoring follows IBM Cloud requirements for [planning and recovering from disaster events](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimedisaster-recovery).\n\nIf a regional disaster occurs, consider the following information:\n\n\n\n* The estimated recovery time for rebuilding the regional site and restoring the service at another location is 24 hours.\n* You will have to update the endpoints of applications and monitoring agents to point to the ingestion endpoint in the new location.\n* You will have to restore the service instance's metadata, that is, dashboards and alerts definitions, from your backups.\n\n\n\nHistorical data may be lost during a disaster. If you require historical metrics for auditing purposes, backup the metrics regularly by querying the metrics from the service and storing them at a remote backup site.\n\n\n\n Manual recovery of the service \n\nIf a regional disaster occurs, the recovery time of the service depends on the recovery time for the region. To minimize the downtime of the service and impact to your business, you could implement a manual failover to switch to another region while the region is being restored. To reduce the time to get up and running in a new location, consider using access groups to manage permissions working with the service, and backup the monitoring metadata of each instance. You should backup your alerts, notifications, dashboards and team definitions on a regular basis.\n\nHow to continue working while a DR site is rebuilt?\n\nIf the applications and services that you are monitoring through a monitoring instance are all co-located in the same region, then you must wait for the region to be available again for business.\n\nIf you have deployed monitoring agents on your systems, and those systems are not impacted by the regional failure, you may choose to redirect metrics to other instances of monitoring in a different region. To redirect metric data, complete the following steps:\n\n\n\n1. [Provision a monitoring instance](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-provision)\n2. Reconfigure the monitoring agent of each system: Change the access key and ingestion endpoints in the agent configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-ha-dr"},{"document_id":"ibmcld_12584-10119-11773","score":12.852377,"text":"\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Meet disaster recovery objectives IBM follows best practices for disaster recovery. All IBM applications automatically recover and restart after any disaster event. For more information about disaster recovery, see the [IBM Disaster Recovery Plan](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimedisaster-recovery). Customers can help meet disaster recovery objectives by deploying their project in a development or test environment before they deploy to production. <br>\\nThe customer does not have to take other actions to prepare for an event of a catastrophic failure in a region. \n Meet high availability objectives IBM Cloud is available globally and load balanced from a single URL. It is highly available and continues to run even if your resources are unavailable. For more information about high availability, see the [IBM service level objectives](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-slo) and the [sample application architecture](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-bcdr-app-recovery). N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-responsibilities-deployable-architectures"},{"document_id":"ibmcld_12523-0-1829","score":12.752021,"text":"\n\n\n\n\n\n\n  Understanding business continuity and disaster recovery for projects \n\nDisaster recovery involves a set of policies, tools, and procedures for returning a system, an application, or an entire data center to full operation after a catastrophic interruption. It includes procedures for copying and storing an installed system's essential data in a secure location, and for recovering that data to restore normalcy of operation.\n\n\n\n  Responsibilities \n\nFor more information about your responsibilities when using projects, see [Shared responsibilities for projects](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-responsibilities-projects).\n\n\n\n  Disaster recovery strategy \n\nIBM Cloud has business continuity plans in place to provide for the recovery of services within hours if a disaster occurs. You are responsible for your data backup and associated recovery of your content.\n\nIBM Cloud performs regular electronic backups of project data with Recovery Time Objective (RTO) and Recovery Point Objective (RPO) of hours as documented in the [IBM Cloud Disaster Recovery Plan](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimedisaster-recovery). Projects don't replicate data outside of a region, except for backup data. When possible, backup data is kept within the data centers of a country but data is always kept within a geography. European data does not leave the EU.\n\n\n\nTable 1. RPO and RTO for projects\n\n Disaster recovery objective  Target Value \n\n RPO                          1 hour       \n RTO                          4 hours      \n\n\n\n\n\n\n\n\n\n  Locations \n\nFor more information about service availability within regions and data centers, see [Service and infrastructure availability by location](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-services_region).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-bc-dr"},{"document_id":"ibmcld_07502-3631-6171","score":12.690327,"text":"\nIn all cases, after the infrastructure is available, data is then restored from backup before activating the passive deployment.\n\n\n\n\n\n Activating the alternative region \n\nShould a regional outage occur, an alternative region can be activated following pre-established and tested procedures. These procedures can include deploying infrastructure in the region by using project configurations that were created and tested in advance so that error free deployments can readily be accomplished. If pre-existing projects are not maintained, project configurations can be restored from backup and modified to target the alternative region.\n\nPlatform services such as enterprise accounts, accounts, IAM, and catalog are global and thus are not affected by regional outages. The enterprise account hierarchy, private catalogs, and all IAM configuration can continue to be used unchanged during a disaster recovery process. Regional service instances that include networking, VPC, various compute, storage, and databases must be recovered in the new region.\n\n\n\n\n\n\n\n\n\n Backups \n\nBackups must be stored in a different region from the workload, and ideally in a separate backup account. This separation in location and management domain (account) minimizes the chances that an outage, operational error, or security breach that affect the workload will also affect the backup. Backup regions should be multi-zone IBM Cloud regions or highly available Satellite regions. However, each family of services on IBM Cloud has its own backup mechanism that introduces some limitations that impact this overall strategy. For more information, see [service considerations](https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture?topic=enterprise-account-architecture-bcdrservice-considerations).\n\nIn addition, a \"disaster recovery kit\" should be developed and stored outside of IBM Cloud. The disaster recovery kit is an off-site and protected repository that includes hardware, software, and system secure configurations, one-time keys, and the disaster recovery plan. Use this disaster recovery kit during an incident response to restore services.\n\n\n\n Infrastructure as code \n\nInfrastructure as code ensures that good backup practices are implemented in a uniform way across the organization. Include implementation of backups as part of deployable architectures. Keep backup configuration close to provisioning code so that it is easier to ensure that backups are adjusted as information system changes occur. Create and configure backup accounts as code.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture?topic=enterprise-account-architecture-bcdr"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.3228087654}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14682-7-2113","score":19.975367,"text":"\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"},{"document_id":"ibmcld_11282-0-1290","score":19.91595,"text":"\n\n\n\n\n\n\n  Cloud native development and application modernization by using Red Hat OpenShift on Power Systems Virtual Server \n\nCloud-native applications are the applications that are born in the cloud, which means that the applications use microservice-based architecture, containers, and a corresponding container orchestration platform. Red Hat\u00ae OpenShift\u00ae is enterprise Kubernetes platform enabling IT organizations to develop applications faster, deploy them reliably, and manage them efficiently.\n\nIn addition to developing new cloud-native applications, IT organizations are modernizing older, monolithic core business applications to support the faster delivery of new function to the business.\n\nFor information on application modernization on Power Systems, see [Field Guide to Application Modernization on IBM Power Systems](https:\/\/www.ibm.com\/downloads\/cas\/D9POQ3YR).\n\nFor information on deploying Red Hat OpenShift on Power Systems Virtual Server and tutorials to explore the platform, see [Deploying Red Hat OpenShift Container Platform 4.x on IBM Power Systems Virtual Servers](https:\/\/developer.ibm.com\/series\/deploy-ocp-cloud-paks-power-virtual-server\/?mhsrc=ibmsearch_a&mhq=%20Deploying%20Red%20Hat%20OpenShift%20Container%20Platform%20on%20Power%20Virtual%20Servers).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-app-modernization-using-RedHat-openshift"},{"document_id":"ibmcld_14497-7-1724","score":19.629267,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_10154-17039-18368","score":19.62008,"text":"\nContainer-native virtualization You can set up [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads. \n Serverless workloads You can set up [Red Hat OpenShift Serverless](https:\/\/www.redhat.com\/en\/topics\/microservices\/why-choose-openshift-serverless). You can also set up Red Hat OpenShift Serverless. \n Service mesh You can set up the [Red Hat OpenShift Service Mesh](https:\/\/docs.openshift.com\/container-platform\/4.11\/service_mesh\/v1x\/installing-ossm.html). You can also set up the Red Hat OpenShift Service Mesh, but you must [apply a network policy](https:\/\/gist.githubusercontent.com\/kitch\/39c504a2ed9e381c2aadea436d5b52e4\/raw\/d8efa69f41d41425b16bb363a881a98d40d3708c\/mesh-policy.yaml) for the service mesh ingress to work. \n API and CLI tools OpenShift Container Platform clusters are set up with access to Kubernetes and Red Hat OpenShift API resources. You can also install command line tools such as oc and odo. Red Hat OpenShift on IBM Cloud clusters come with the same capabilities to use the Kubernetes and Red Hat OpenShift API and CLI tools.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10407-1492-3206","score":19.173117,"text":"\nContainer-native virtualization The Red Hat OpenShift [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) to run VM workloads alongside container workloads is not supported by IBM. If you choose to install the add-on yourself, you must use bare metal machines, not virtual machines. You are responsible for resolving any issues and impact to your workloads from using container-native virtualization. \n Calico network plug-in Changing the Calico plug-in, components, or default Calico settings is not supported. For example, don't deploy a new Calico plug-in version, or modify the daemon sets or deployments for the Calico components, default IPPool resources, or Calico nodes. Instead, you can follow the documentation to [create a Calico NetworkPolicy or GlobalNetworkPolicy](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-network_policies), to [change the Calico MTU](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelcalico-mtu), or to [disable the port map plug-in for the Calico CNI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelcalico-portmap). \n Cluster quota You can't exceed 100 clusters per region and per [infrastructure provider](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers). If you need more of the resource, [contact IBM Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar). In the support case, include the new quota limit for the region and infrastructure provider that you want. \n IAM access groups You can't scope IBM Cloud IAM service access roles to an IAM access group because the roles are not synced to the RBAC roles within the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitations"},{"document_id":"ibmcld_14683-7-2001","score":18.944836,"text":"\nRed Hat OpenShift architecture \n\nThe IBM Cloud\u00ae for VMware Solutions offerings provide automation to deploy VMware\u00ae technology components in IBM Cloud data centers across the globe. The architecture consists of a single cloud region. It supports the ability to extend into more cloud regions that are located in another geography or into another IBM Cloud pod within the same data center.\n\nZoom\n\n![Red Hat OpenShift architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-components.svg)\n\nFigure 1. Red Hat OpenShift architecture\n\n\n\n Bastion hosts \n\nThe Management host is a Red Hat\u00ae Enterprise Linux\u00ae 8.0 virtual machine (VM). This VM hosts services to install and configure the Red Hat\u00ae OpenShift\u00ae instance and provides utilities to manage the Red Hat OpenShift environment. This host is normally deployed in the VXLAN Subnet.\n\n\n\n\n\n Bootstrap hosts \n\nThe bootstrap node is a Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The node is a temporary node that is used to start the installation.\n\n\n\n\n\n Control Plane hosts \n\nThe control plane hosts are Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The control plane nodes are known as the control plane, where Kubernetes services such as API server, etcd, and controller manager are defined. An NSX\u00ae load balancer is configured to spread load across these VMs for ports 6443 and 22623, exposing the api and api-int functions.\n\n\n\n\n\n Worker hosts \n\nThe worker hosts are Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The worker nodes are known as the data-plane, where the actual Kubernetes workloads are deployed. An NSX load balancer is configured to spread load across these VMs for ports 80 and 443, exposing the wildcard DNS and *.apps.\n\n\n\n\n\n Common services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-redhat-arch"},{"document_id":"ibmcld_10531-7-2246","score":18.519655,"text":"\nRed Hat OpenShift on IBM Cloud partners \n\nTo provide you with all the capabilities that you need to run production workloads in the cloud, Red Hat OpenShift on IBM Cloud partners with other third-party service providers to enhance your cluster with logging, monitoring, and storage tools.\n\nReview the list of partners and the benefits of each solution that they provide. To find other proprietary IBM Cloud and third-party open source services that you can use in your cluster, see [Understanding IBM Cloud and 3rd party integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations).\n\n\n\n Portworx \n\n[Portworx](https:\/\/portworx.com\/products\/portworx-enterprise\/\/) is a highly available software-defined storage solution that you can use to manage local persistent storage for your containerized databases and other stateful apps, or to share data between pods across multiple zones.\n\nAn software defined storage (SDS), such as Portworx, solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n Benefits \n\nReview the following table to find a list of key benefits that you can get by using Portworx.\n\n\n\nBenefits of using Portworx\n\n Benefit Description \n\n Cloud native storage and data management for stateful apps Portworx aggregates available local storage that is attached to your worker nodes and that can vary in size or type, and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using Kubernetes persistent volume claims (PVC), you can add local persistent storage to your apps to store your data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-partners"},{"document_id":"ibmcld_10154-15474-17414","score":18.483349,"text":"\nRed Hat OpenShift on IBM Cloud clusters come with all the same configurable project and build components as OCP clusters. You can also choose to integrate your cluster with IBM Cloud services like [Continuous Delivery](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cicd). \n Cluster health You can also set up logging, monitoring, and metering tools by installing and configuring various operators. These solutions are cluster-specific and not highly available unless you back them up. Your clusters feature one-click integrations with IBM Log Analysis and IBM Cloud Monitoring for enterprise-grade, persistent monitoring and logging solutions across clusters. You can also install the logging and monitoring operators as with standard OCP, but you might have to adjust the configuration settings. For more information, see [Logging and monitoring cluster health](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health). \n Migrating clusters You can use the cluster migrator operator to migrate clusters from one major version to another. Migration requires separate clusters; you can't update a cluster from one major version to another. Various open source tools might be used, but are not officially supported. As with standard OpenShift Container Platform, you can't update a cluster from one major version to another. If you use a third-party open source tool such as the [cluster migrator operator](https:\/\/github.com\/migtools\/mig-operator), the tool is not supported by IBM and might have limitations such as the migration UI being unavailable. \n Container-native virtualization You can set up [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10495-9135-10569","score":18.465004,"text":"\n(https:\/\/cognitiveclass.ai\/courses\/docker-essentials)\n\n\n\n\n\n What is Red Hat OpenShift? \n\nRed Hat OpenShift is a Kubernetes container platform that provides a trusted environment to run enterprise workloads. It extends the Kubernetes platform with built-in software to enhance app lifecycle development, operations, and security. With Red Hat OpenShift, you can consistently deploy your workloads across hybrid cloud providers and environments. For more information about the differences between the community Kubernetes and Red Hat OpenShift cluster offerings, see the [comparison table](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\n\n\n\n\n What compute host infrastructure does the service offer? \n\nYou can create clusters on Classic or IBM Cloud\u00ae Virtual Private Cloud infrastructure. You can also bring your own hosts by using Satellite.\n\nFor more information, see [Supported infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers).\n\n\n\n\n\n Related resources \n\nReview how you can learn about Kubernetes concepts and the terminology.\n\n\n\n* Familiarize yourself with the product by completing the [Creating clusters tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Learn how Kubernetes and Red Hat OpenShift on IBM Cloud work together by completing this [course](https:\/\/cognitiveclass.ai\/courses\/kubernetes-course).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview"},{"document_id":"ibmcld_06752-7-1734","score":18.446898,"text":"\nRed Hat OpenShift Container Platform on VPC landing zone \n\nRed Hat OpenShift Container Platform on VPC landing zone is a deployable architecture solution that is based on the IBM Cloud for Financial Services reference architecture. It creates secure and compliant Red Hat OpenShift Container Platform workload clusters on a Virtual Private Cloud (VPC) network.\n\n\n\n Architecture diagram \n\nZoom\n\n![Architecture diagram of the OpenShift Container Platform on VPC deployable architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9610604e9f8dcd5f7b6b138dd22ba445300be7f5\/deployable-reference-architectures\/terraform-ibm-landing-zone\/roks.drawio.svg)\n\nFigure 1. Single region architecture diagram for Red Hat OpenShift Container Platform on VPC on IBM Cloud\n\n\n\n\n\n Design requirements \n\nZoom\n\n![Design requirements for Secure infrastructure on VPC for regulated industries](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9610604e9f8dcd5f7b6b138dd22ba445300be7f5\/deployable-reference-architectures\/terraform-ibm-landing-zone\/heat-map-deploy-arch-slz-ocp.svg)\n\nFigure 2. Scope of the design requirements\n\n\n\n\n\n Components \n\n\n\n VPC architecture decisions \n\n\n\nTable 1. Architecture decisions\n\n Requirement Component Reasons for choice Alternative choice \n\n Provide access management and tooling for the workload that is deployed in the workload VPC Management VPC service Create a separate VPC service where SSH connectivity from outside is allowed \n Provide compute, storage, and network services to support hosted applications and operations that deliver services to the consumer Workload VPC service Create a separate VPC service as an isolated environment, without direct public internet connectivity and without direct SSH access","title":"","source":"https:\/\/cloud.ibm.com\/docs\/deployable-reference-architectures?topic=deployable-reference-architectures-ocp-ra"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1845756968}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10154-7-1896","score":19.468227,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10531-7-2246","score":18.759293,"text":"\nRed Hat OpenShift on IBM Cloud partners \n\nTo provide you with all the capabilities that you need to run production workloads in the cloud, Red Hat OpenShift on IBM Cloud partners with other third-party service providers to enhance your cluster with logging, monitoring, and storage tools.\n\nReview the list of partners and the benefits of each solution that they provide. To find other proprietary IBM Cloud and third-party open source services that you can use in your cluster, see [Understanding IBM Cloud and 3rd party integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations).\n\n\n\n Portworx \n\n[Portworx](https:\/\/portworx.com\/products\/portworx-enterprise\/\/) is a highly available software-defined storage solution that you can use to manage local persistent storage for your containerized databases and other stateful apps, or to share data between pods across multiple zones.\n\nAn software defined storage (SDS), such as Portworx, solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n Benefits \n\nReview the following table to find a list of key benefits that you can get by using Portworx.\n\n\n\nBenefits of using Portworx\n\n Benefit Description \n\n Cloud native storage and data management for stateful apps Portworx aggregates available local storage that is attached to your worker nodes and that can vary in size or type, and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using Kubernetes persistent volume claims (PVC), you can add local persistent storage to your apps to store your data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-partners"},{"document_id":"ibmcld_10170-10609-12793","score":18.087156,"text":"\nThus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* Red Hat OpenShift on IBM Cloud\n* IBM Cloud\u00ae Continuous Delivery\n* IBM Logging and Monitoring\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae\n* IBM Cloud App ID\n\n\n\nAccelerated development is a key win for the HR Exec. The team gets started by containerizing their apps and putting them in the cloud. With the use of modern containers, Developers can experiment easily with Node.js SDK and push changes to Development and Test systems, which are scaled out on separate clusters. Those pushes were automated with open toolchains and IBM Cloud\u00ae Continuous Delivery. No longer were updates to the HR site languishing in slow, error-prone build processes. They can deliver incremental updates to their site, daily or even more frequently. Moreover, logging and monitoring for the HR site is rapidly integrated, especially for how the site pulls personalized data from back-end benefit systems. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot live systems. Developers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_14682-7-2113","score":18.083986,"text":"\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"},{"document_id":"ibmcld_11282-0-1290","score":17.882118,"text":"\n\n\n\n\n\n\n  Cloud native development and application modernization by using Red Hat OpenShift on Power Systems Virtual Server \n\nCloud-native applications are the applications that are born in the cloud, which means that the applications use microservice-based architecture, containers, and a corresponding container orchestration platform. Red Hat\u00ae OpenShift\u00ae is enterprise Kubernetes platform enabling IT organizations to develop applications faster, deploy them reliably, and manage them efficiently.\n\nIn addition to developing new cloud-native applications, IT organizations are modernizing older, monolithic core business applications to support the faster delivery of new function to the business.\n\nFor information on application modernization on Power Systems, see [Field Guide to Application Modernization on IBM Power Systems](https:\/\/www.ibm.com\/downloads\/cas\/D9POQ3YR).\n\nFor information on deploying Red Hat OpenShift on Power Systems Virtual Server and tutorials to explore the platform, see [Deploying Red Hat OpenShift Container Platform 4.x on IBM Power Systems Virtual Servers](https:\/\/developer.ibm.com\/series\/deploy-ocp-cloud-paks-power-virtual-server\/?mhsrc=ibmsearch_a&mhq=%20Deploying%20Red%20Hat%20OpenShift%20Container%20Platform%20on%20Power%20Virtual%20Servers).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-app-modernization-using-RedHat-openshift"},{"document_id":"ibmcld_10154-17039-18368","score":17.676306,"text":"\nContainer-native virtualization You can set up [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads. \n Serverless workloads You can set up [Red Hat OpenShift Serverless](https:\/\/www.redhat.com\/en\/topics\/microservices\/why-choose-openshift-serverless). You can also set up Red Hat OpenShift Serverless. \n Service mesh You can set up the [Red Hat OpenShift Service Mesh](https:\/\/docs.openshift.com\/container-platform\/4.11\/service_mesh\/v1x\/installing-ossm.html). You can also set up the Red Hat OpenShift Service Mesh, but you must [apply a network policy](https:\/\/gist.githubusercontent.com\/kitch\/39c504a2ed9e381c2aadea436d5b52e4\/raw\/d8efa69f41d41425b16bb363a881a98d40d3708c\/mesh-policy.yaml) for the service mesh ingress to work. \n API and CLI tools OpenShift Container Platform clusters are set up with access to Kubernetes and Red Hat OpenShift API resources. You can also install command line tools such as oc and odo. Red Hat OpenShift on IBM Cloud clusters come with the same capabilities to use the Kubernetes and Red Hat OpenShift API and CLI tools.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_14497-7-1724","score":17.607124,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_10407-1492-3206","score":17.602861,"text":"\nContainer-native virtualization The Red Hat OpenShift [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) to run VM workloads alongside container workloads is not supported by IBM. If you choose to install the add-on yourself, you must use bare metal machines, not virtual machines. You are responsible for resolving any issues and impact to your workloads from using container-native virtualization. \n Calico network plug-in Changing the Calico plug-in, components, or default Calico settings is not supported. For example, don't deploy a new Calico plug-in version, or modify the daemon sets or deployments for the Calico components, default IPPool resources, or Calico nodes. Instead, you can follow the documentation to [create a Calico NetworkPolicy or GlobalNetworkPolicy](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-network_policies), to [change the Calico MTU](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelcalico-mtu), or to [disable the port map plug-in for the Calico CNI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelcalico-portmap). \n Cluster quota You can't exceed 100 clusters per region and per [infrastructure provider](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers). If you need more of the resource, [contact IBM Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar). In the support case, include the new quota limit for the region and infrastructure provider that you want. \n IAM access groups You can't scope IBM Cloud IAM service access roles to an IAM access group because the roles are not synced to the RBAC roles within the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitations"},{"document_id":"ibmcld_10170-12206-14575","score":17.499405,"text":"\nDevelopers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.\n\nRed Hat OpenShift on IBM Cloud provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services as needed. Using industry-standard containers technology apps can be quickly developed and shared across multiple Development, Test, and Production environments. This setup provides the immediate benefit of scalability. Using Kubernetes rich set of deployment and runtime objects, the HR team can monitor and manage upgrades to apps reliably. They can also replicate and scale the apps, by using defined rules and the automated Kubernetes orchestrator.\n\n\n\n Step 1: Containers, microservices, and the Garage Method \n\n\n\n* Apps are built in a set of cooperative microservices that run in Red Hat OpenShift on IBM Cloud. The architecture represents the functional areas of the app with the most quality problems.\n* Deploy apps to container in Red Hat OpenShift on IBM Cloud, continuously scanned with IBM Vulnerability Advisor.\n* Provide standardized DevOps dashboards through Kubernetes.\n* Adopt the essential agile and iterative development practices within the IBM Garage Method to enable frequent releases of new functions, patches, and fixes without downtime.\n\n\n\n\n\n\n\n Step 2: Connections to existing benefits back-end \n\n\n\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure tunnel to on-premises systems that host the benefits systems.\n* Combination of on-premises data and Red Hat OpenShift on IBM Cloud lets them access sensitive data while they adhere to regulations.\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_07986-11524-13676","score":17.42256,"text":"\nVirtual Servers for VPC is an infrastructure-as-a-service (IaaS) offering that gives you access to all of the benefits of VPC, including network isolation, security, and flexibility.\n\nWith Virtual Servers for VPC, you can quickly provision instances with high network performance. When you provision an instance, you select a profile that matches the amount of memory and compute power that you need for the application that you plan to run on the instance. Instances are available on the x86 architecture.\n\n\n\n\n\n Dedicated hosts for VPC (optional) \n\nWith [Dedicated hosts for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-dedicated-hosts-instances), you can carve out a single-tenant compute node, free from users outside of your organization. Within that dedicated space, you can create virtual server instances according to your needs. Additionally, you can create dedicated host groups that contain dedicated hosts for a specific purpose. Because a dedicated host is a single-tenant space, only users within your account that have the required permissions can create instances on the host.\n\nDedicated hosts are highly recommended when you use virtual servers, particularly for any parts of your application that process regulated data and keep it in memory.\n\n\n\n\n\n IBM Cloud Auto Scale for VPC (optional) \n\n[Auto Scale for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-auto-scale-instance-group) is highly recommended if you are using virtual servers. With Auto Scale for VPC, you can improve performance and costs by dynamically creating virtual server instances to meet the demands of your environment. You set scaling policies that define your desired average utilization for metrics like CPU, memory, and network usage. The policies that you define determine when virtual server instances are added or removed from your instance group.\n\n\n\n\n\n\n\n Containers \n\n\n\n Red Hat OpenShift on IBM Cloud \n\nIn addition to Virtual Servers for VPC, you can use [Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview) if you want to run containers. {{site.data.content.openshift-service-description}}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-about"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14682-7-2113","score":17.252697,"text":"\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"},{"document_id":"ibmcld_10154-17039-18368","score":17.10009,"text":"\nContainer-native virtualization You can set up [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads. \n Serverless workloads You can set up [Red Hat OpenShift Serverless](https:\/\/www.redhat.com\/en\/topics\/microservices\/why-choose-openshift-serverless). You can also set up Red Hat OpenShift Serverless. \n Service mesh You can set up the [Red Hat OpenShift Service Mesh](https:\/\/docs.openshift.com\/container-platform\/4.11\/service_mesh\/v1x\/installing-ossm.html). You can also set up the Red Hat OpenShift Service Mesh, but you must [apply a network policy](https:\/\/gist.githubusercontent.com\/kitch\/39c504a2ed9e381c2aadea436d5b52e4\/raw\/d8efa69f41d41425b16bb363a881a98d40d3708c\/mesh-policy.yaml) for the service mesh ingress to work. \n API and CLI tools OpenShift Container Platform clusters are set up with access to Kubernetes and Red Hat OpenShift API resources. You can also install command line tools such as oc and odo. Red Hat OpenShift on IBM Cloud clusters come with the same capabilities to use the Kubernetes and Red Hat OpenShift API and CLI tools.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_14497-7-1724","score":17.004364,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_10407-1492-3206","score":16.967934,"text":"\nContainer-native virtualization The Red Hat OpenShift [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) to run VM workloads alongside container workloads is not supported by IBM. If you choose to install the add-on yourself, you must use bare metal machines, not virtual machines. You are responsible for resolving any issues and impact to your workloads from using container-native virtualization. \n Calico network plug-in Changing the Calico plug-in, components, or default Calico settings is not supported. For example, don't deploy a new Calico plug-in version, or modify the daemon sets or deployments for the Calico components, default IPPool resources, or Calico nodes. Instead, you can follow the documentation to [create a Calico NetworkPolicy or GlobalNetworkPolicy](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-network_policies), to [change the Calico MTU](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelcalico-mtu), or to [disable the port map plug-in for the Calico CNI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelcalico-portmap). \n Cluster quota You can't exceed 100 clusters per region and per [infrastructure provider](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers). If you need more of the resource, [contact IBM Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar). In the support case, include the new quota limit for the region and infrastructure provider that you want. \n IAM access groups You can't scope IBM Cloud IAM service access roles to an IAM access group because the roles are not synced to the RBAC roles within the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitations"},{"document_id":"ibmcld_11282-0-1290","score":16.467241,"text":"\n\n\n\n\n\n\n  Cloud native development and application modernization by using Red Hat OpenShift on Power Systems Virtual Server \n\nCloud-native applications are the applications that are born in the cloud, which means that the applications use microservice-based architecture, containers, and a corresponding container orchestration platform. Red Hat\u00ae OpenShift\u00ae is enterprise Kubernetes platform enabling IT organizations to develop applications faster, deploy them reliably, and manage them efficiently.\n\nIn addition to developing new cloud-native applications, IT organizations are modernizing older, monolithic core business applications to support the faster delivery of new function to the business.\n\nFor information on application modernization on Power Systems, see [Field Guide to Application Modernization on IBM Power Systems](https:\/\/www.ibm.com\/downloads\/cas\/D9POQ3YR).\n\nFor information on deploying Red Hat OpenShift on Power Systems Virtual Server and tutorials to explore the platform, see [Deploying Red Hat OpenShift Container Platform 4.x on IBM Power Systems Virtual Servers](https:\/\/developer.ibm.com\/series\/deploy-ocp-cloud-paks-power-virtual-server\/?mhsrc=ibmsearch_a&mhq=%20Deploying%20Red%20Hat%20OpenShift%20Container%20Platform%20on%20Power%20Virtual%20Servers).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-app-modernization-using-RedHat-openshift"},{"document_id":"ibmcld_11950-7-2002","score":15.894286,"text":"\nSetting up virtualization on a Satellite location \n\nYou can set up your Bare Metal Servers to use Red Hat OpenShift virtualization in your Satellite location. By using virtualization, you can provision Windows or other virtual machines on your Bare Metal Servers in a managed Red Hat OpenShift space.\n\nSupported host operating systems\n: Red Hat CoreOS (RHCOS)\n\n\n\n Prerequisites \n\n\n\n* Create a RHCOS-enabled location. To check whether your location is RHCOS-enabled, see [Is my location enabled for Red Hat CoreOS?](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locationsverify-coreos-location). If your location is not enabled, [create a new one with RHCOS](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-locations).\n* Attach hosts to your location and set up your [location control plane](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-setup-control-plane).\n* Find and record your bare metal host name.\n* Find your bare metal server network information. Record the CIDR and gateway information for the public and private interfaces for your system.\n* If you want to use IBM Cloud Object Storage to store your ignition file, create or identify a bucket.\n* Create or identify a cluster within the Satellite location that runs a supported operating system; for example, this tutorial uses a Red Hat OpenShift cluster that is running 4.11.\n* If you want to use OpenShift Data Foundation as your storage solution, add 2 storage disks to each of your Bare Metal Servers when you provision them.\n\n\n\n\n\n\n\n Bare Metal Server requirements for Satellite \n\nTo set up virtualization, your Bare Metal Server must meet the following requirements.\n\n\n\n* Must support virtualization technology.\n\n\n\n* For Intel CPUs, support for virtualization is referred to as Intel VT or VT-x.\n* For AMD CPUs, support for virtualization is referred to as AMD Virtualization or AMD-V.\n\n\n\n* Must have a minimum of minimum of 8 cores and 32 GB RAM, plus any additional cores that you need for your vCPU overhead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-location"},{"document_id":"ibmcld_14683-7-2001","score":15.827246,"text":"\nRed Hat OpenShift architecture \n\nThe IBM Cloud\u00ae for VMware Solutions offerings provide automation to deploy VMware\u00ae technology components in IBM Cloud data centers across the globe. The architecture consists of a single cloud region. It supports the ability to extend into more cloud regions that are located in another geography or into another IBM Cloud pod within the same data center.\n\nZoom\n\n![Red Hat OpenShift architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-components.svg)\n\nFigure 1. Red Hat OpenShift architecture\n\n\n\n Bastion hosts \n\nThe Management host is a Red Hat\u00ae Enterprise Linux\u00ae 8.0 virtual machine (VM). This VM hosts services to install and configure the Red Hat\u00ae OpenShift\u00ae instance and provides utilities to manage the Red Hat OpenShift environment. This host is normally deployed in the VXLAN Subnet.\n\n\n\n\n\n Bootstrap hosts \n\nThe bootstrap node is a Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The node is a temporary node that is used to start the installation.\n\n\n\n\n\n Control Plane hosts \n\nThe control plane hosts are Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The control plane nodes are known as the control plane, where Kubernetes services such as API server, etcd, and controller manager are defined. An NSX\u00ae load balancer is configured to spread load across these VMs for ports 6443 and 22623, exposing the api and api-int functions.\n\n\n\n\n\n Worker hosts \n\nThe worker hosts are Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The worker nodes are known as the data-plane, where the actual Kubernetes workloads are deployed. An NSX load balancer is configured to spread load across these VMs for ports 80 and 443, exposing the wildcard DNS and *.apps.\n\n\n\n\n\n Common services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-redhat-arch"},{"document_id":"ibmcld_10531-7-2246","score":15.706942,"text":"\nRed Hat OpenShift on IBM Cloud partners \n\nTo provide you with all the capabilities that you need to run production workloads in the cloud, Red Hat OpenShift on IBM Cloud partners with other third-party service providers to enhance your cluster with logging, monitoring, and storage tools.\n\nReview the list of partners and the benefits of each solution that they provide. To find other proprietary IBM Cloud and third-party open source services that you can use in your cluster, see [Understanding IBM Cloud and 3rd party integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations).\n\n\n\n Portworx \n\n[Portworx](https:\/\/portworx.com\/products\/portworx-enterprise\/\/) is a highly available software-defined storage solution that you can use to manage local persistent storage for your containerized databases and other stateful apps, or to share data between pods across multiple zones.\n\nAn software defined storage (SDS), such as Portworx, solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n Benefits \n\nReview the following table to find a list of key benefits that you can get by using Portworx.\n\n\n\nBenefits of using Portworx\n\n Benefit Description \n\n Cloud native storage and data management for stateful apps Portworx aggregates available local storage that is attached to your worker nodes and that can vary in size or type, and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using Kubernetes persistent volume claims (PVC), you can add local persistent storage to your apps to store your data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-partners"},{"document_id":"ibmcld_11950-1571-3276","score":15.624272,"text":"\nTo set up virtualization, your Bare Metal Server must meet the following requirements.\n\n\n\n* Must support virtualization technology.\n\n\n\n* For Intel CPUs, support for virtualization is referred to as Intel VT or VT-x.\n* For AMD CPUs, support for virtualization is referred to as AMD Virtualization or AMD-V.\n\n\n\n* Must have a minimum of minimum of 8 cores and 32 GB RAM, plus any additional cores that you need for your vCPU overhead. For more information, see [CPU overhead](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/install\/preparing-cluster-for-virt.htmlCPU-overhead_preparing-cluster-for-virt) in the Red Hat OpenShift docs.\n* Must include enough memory for your workload needs. For example: 360 MiB + (1.002 * requested memory) + 146 MiB + 8 MiB * (number of vCPUs) + 16 MiB * (number of graphics devices). For more information, see [Memory overhead](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/install\/preparing-cluster-for-virt.htmlmemory-overhead_preparing-cluster-for-virt) in the Red Hat OpenShift docs.\n* Must run Red Hat CoreOS operating system, which is installed during when you attach it to the location.\n\n\n\nIf your servers do not meet these requirements, follow the steps to [create a Bare Metal Server](https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-ordering-baremetal-server). For a list of bare metal options, see [Available options for a bare metal server](https:\/\/cloud.ibm.com\/docs\/bare-metal?topic=bare-metal-about-bmoptions-for-bare-metal-servers).\n\n\n\n\n\n Step 1: Attaching bare metal servers to your location \n\nFollow these general steps to attach your bare metal servers to your location. These steps might vary, depending on your specific hardware.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-virtualization-location"},{"document_id":"ibmcld_11672-1379-3310","score":15.4493065,"text":"\nFor this Bare Metal Server, this information is found in the Network details section on the Overview page. Record the CIDR and gateway information for the public and private interfaces for your system.\n* Create or identify an IBM Cloud Object Storage bucket to store your ignition file.\n* Create or identify a cluster within the Satellite location that runs a supported operating system; for example, this tutorial uses a Red Hat OpenShift cluster that is running 4.11.\n\n\n\nIn addition, the Bare Metal Servers used in this example required the following prerequisites.\n\n\n\n* If you plan to have multiple VLANs for your cluster, multiple subnets on the same VLAN, or are planning for a multizone classic cluster, [enable VRF in your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-vrf-service-endpoint).\n* [Create two VLAN pairs](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-classic-vlanssl_vlan_create) (public and private) in the same IBM Cloud data center pod for each zone for your bare metal host.\n* Later in this tutorial, you deploy [OpenShift Data Foundation for local disks](https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-storage-odf-local&interface=ui). This solution requires additional storage devices on the worker nodes.\n\n\n\n\n\n\n\n Bare Metal Server requirements \n\nTo set up virtualization, your Bare Metal Server must meet the following requirements.\n\n\n\n* Must support virtualization technology.\n\n\n\n* For Intel CPUs, support for virtualization is referred to as Intel VT or VT-x.\n* For AMD CPUs, support for virtualization is referred to as AMD Virtualization or AMD-V.\n\n\n\n* Must have a minimum of minimum of 8 cores and 32 GB RAM, plus any additional cores that you need for your vCPU overhead. For more information, see [CPU overhead](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/install\/preparing-cluster-for-virt.htmlCPU-overhead_preparing-cluster-for-virt) in the Red Hat OpenShift docs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/satellite?topic=satellite-assign-bare-metal"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_14497-7-1724","score":19.848885,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_14682-7-2113","score":19.354542,"text":"\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"},{"document_id":"ibmcld_10531-7-2246","score":19.255775,"text":"\nRed Hat OpenShift on IBM Cloud partners \n\nTo provide you with all the capabilities that you need to run production workloads in the cloud, Red Hat OpenShift on IBM Cloud partners with other third-party service providers to enhance your cluster with logging, monitoring, and storage tools.\n\nReview the list of partners and the benefits of each solution that they provide. To find other proprietary IBM Cloud and third-party open source services that you can use in your cluster, see [Understanding IBM Cloud and 3rd party integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations).\n\n\n\n Portworx \n\n[Portworx](https:\/\/portworx.com\/products\/portworx-enterprise\/\/) is a highly available software-defined storage solution that you can use to manage local persistent storage for your containerized databases and other stateful apps, or to share data between pods across multiple zones.\n\nAn software defined storage (SDS), such as Portworx, solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n Benefits \n\nReview the following table to find a list of key benefits that you can get by using Portworx.\n\n\n\nBenefits of using Portworx\n\n Benefit Description \n\n Cloud native storage and data management for stateful apps Portworx aggregates available local storage that is attached to your worker nodes and that can vary in size or type, and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using Kubernetes persistent volume claims (PVC), you can add local persistent storage to your apps to store your data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-partners"},{"document_id":"ibmcld_14683-7-2001","score":18.71312,"text":"\nRed Hat OpenShift architecture \n\nThe IBM Cloud\u00ae for VMware Solutions offerings provide automation to deploy VMware\u00ae technology components in IBM Cloud data centers across the globe. The architecture consists of a single cloud region. It supports the ability to extend into more cloud regions that are located in another geography or into another IBM Cloud pod within the same data center.\n\nZoom\n\n![Red Hat OpenShift architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-components.svg)\n\nFigure 1. Red Hat OpenShift architecture\n\n\n\n Bastion hosts \n\nThe Management host is a Red Hat\u00ae Enterprise Linux\u00ae 8.0 virtual machine (VM). This VM hosts services to install and configure the Red Hat\u00ae OpenShift\u00ae instance and provides utilities to manage the Red Hat OpenShift environment. This host is normally deployed in the VXLAN Subnet.\n\n\n\n\n\n Bootstrap hosts \n\nThe bootstrap node is a Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The node is a temporary node that is used to start the installation.\n\n\n\n\n\n Control Plane hosts \n\nThe control plane hosts are Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The control plane nodes are known as the control plane, where Kubernetes services such as API server, etcd, and controller manager are defined. An NSX\u00ae load balancer is configured to spread load across these VMs for ports 6443 and 22623, exposing the api and api-int functions.\n\n\n\n\n\n Worker hosts \n\nThe worker hosts are Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The worker nodes are known as the data-plane, where the actual Kubernetes workloads are deployed. An NSX load balancer is configured to spread load across these VMs for ports 80 and 443, exposing the wildcard DNS and *.apps.\n\n\n\n\n\n Common services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-redhat-arch"},{"document_id":"ibmcld_10170-10609-12793","score":18.52393,"text":"\nThus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* Red Hat OpenShift on IBM Cloud\n* IBM Cloud\u00ae Continuous Delivery\n* IBM Logging and Monitoring\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae\n* IBM Cloud App ID\n\n\n\nAccelerated development is a key win for the HR Exec. The team gets started by containerizing their apps and putting them in the cloud. With the use of modern containers, Developers can experiment easily with Node.js SDK and push changes to Development and Test systems, which are scaled out on separate clusters. Those pushes were automated with open toolchains and IBM Cloud\u00ae Continuous Delivery. No longer were updates to the HR site languishing in slow, error-prone build processes. They can deliver incremental updates to their site, daily or even more frequently. Moreover, logging and monitoring for the HR site is rapidly integrated, especially for how the site pulls personalized data from back-end benefit systems. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot live systems. Developers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_transport"},{"document_id":"ibmcld_14682-1497-3767","score":18.36815,"text":"\n[IBM Cloud for VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market. Your existing estate includes not only applications, but data, processes, business logic, and user interfaces, all of which need to adapt to keep up with new business demands.\n\nApplication modernization has the following benefits:\n\n\n\n* Improved developer productivity\n* Increased operational efficiency\n* Reduced cost to build new capabilities\n* Expanded capacity delivered in a short time\n\n\n\nIBM understands that 70% of private cloud adoption is driven by the need to modernize application environments. However, most organizations are approaching application modernization in a staged approach, which requires a hybrid and multi cloud landscape, where:\n\n\n\n* Complex and monolithic legacy applications that typically run on mainframes or UNIX systems remain on-premises.\n* x86 environments used for Systems of Record (SoR), applications that are security sensitive, and regulated workloads are placed on a virtualized infrastructure or a private cloud.\n* Applications such as SAP\u00ae or high-performance computing use bare metal resources.\n* Security sensitive and some regulated workloads, which can move to the public cloud are moving to dedicated environments.\n* Systems of engagement (SoE) such as web, mobile, IoT, AI, or Video are moving to public clouds.\n\n\n\nFor example, a common pattern is to have front-end SOE applications that are deployed as containers with databases and legacy middleware that are deployed on VMs on a private cloud.\n\nBecause your IT infrastructure and business needs are unique, you need an approach to modernization that helps accelerate business value delivery, reduces your risks, and preserves your existing investments.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"},{"document_id":"ibmcld_11282-0-1290","score":18.059591,"text":"\n\n\n\n\n\n\n  Cloud native development and application modernization by using Red Hat OpenShift on Power Systems Virtual Server \n\nCloud-native applications are the applications that are born in the cloud, which means that the applications use microservice-based architecture, containers, and a corresponding container orchestration platform. Red Hat\u00ae OpenShift\u00ae is enterprise Kubernetes platform enabling IT organizations to develop applications faster, deploy them reliably, and manage them efficiently.\n\nIn addition to developing new cloud-native applications, IT organizations are modernizing older, monolithic core business applications to support the faster delivery of new function to the business.\n\nFor information on application modernization on Power Systems, see [Field Guide to Application Modernization on IBM Power Systems](https:\/\/www.ibm.com\/downloads\/cas\/D9POQ3YR).\n\nFor information on deploying Red Hat OpenShift on Power Systems Virtual Server and tutorials to explore the platform, see [Deploying Red Hat OpenShift Container Platform 4.x on IBM Power Systems Virtual Servers](https:\/\/developer.ibm.com\/series\/deploy-ocp-cloud-paks-power-virtual-server\/?mhsrc=ibmsearch_a&mhq=%20Deploying%20Red%20Hat%20OpenShift%20Container%20Platform%20on%20Power%20Virtual%20Servers).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-app-modernization-using-RedHat-openshift"},{"document_id":"ibmcld_10154-7-1896","score":17.748663,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_12640-7-1946","score":17.555708,"text":"\nRed Hat OpenShift Container Platform on VPC landing zone \n\nRed Hat OpenShift Container Platform on VPC landing zone is a deployable architecture solution that is based on the IBM Cloud for Financial Services reference architecture. It creates secure and compliant Red Hat OpenShift Container Platform workload clusters on a Virtual Private Cloud (VPC) network.\n\n\n\n Architecture diagram \n\nZoom\n\n![Architecture diagram of the OpenShift Container Platform on VPC deployable architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bbc046343d620cb2210cb1c62a46d7601ae08e00\/secure-infrastructure-vpc\/includes\/deployable-reference-architectures\/terraform-ibm-landing-zone\/includes\/deployable-reference-architectures\/terraform-ibm-landing-zone\/roks.drawio.svg)\n\nFigure 1. Single region architecture diagram for Red Hat OpenShift Container Platform on VPC on IBM Cloud\n\n\n\n\n\n Design requirements \n\nZoom\n\n![Design requirements for Secure infrastructure on VPC for regulated industries](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bbc046343d620cb2210cb1c62a46d7601ae08e00\/secure-infrastructure-vpc\/includes\/deployable-reference-architectures\/terraform-ibm-landing-zone\/includes\/deployable-reference-architectures\/terraform-ibm-landing-zone\/heat-map-deploy-arch-slz-ocp.svg)\n\nFigure 2. Scope of the design requirements\n\n\n\n\n\n Components \n\n\n\n VPC architecture decisions \n\n\n\nTable 1. Architecture decisions\n\n Requirement Component Reasons for choice Alternative choice \n\n Provide access management and tooling for the workload that is deployed in the workload VPC Management VPC service Create a separate VPC service where SSH connectivity from outside is allowed \n Provide compute, storage, and network services to support hosted applications and operations that deliver services to the consumer Workload VPC service Create a separate VPC service as an isolated environment, without direct public internet connectivity and without direct SSH access","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-infrastructure-vpc?topic=secure-infrastructure-vpc-ocp-ra"},{"document_id":"ibmcld_06752-7-1734","score":17.522358,"text":"\nRed Hat OpenShift Container Platform on VPC landing zone \n\nRed Hat OpenShift Container Platform on VPC landing zone is a deployable architecture solution that is based on the IBM Cloud for Financial Services reference architecture. It creates secure and compliant Red Hat OpenShift Container Platform workload clusters on a Virtual Private Cloud (VPC) network.\n\n\n\n Architecture diagram \n\nZoom\n\n![Architecture diagram of the OpenShift Container Platform on VPC deployable architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9610604e9f8dcd5f7b6b138dd22ba445300be7f5\/deployable-reference-architectures\/terraform-ibm-landing-zone\/roks.drawio.svg)\n\nFigure 1. Single region architecture diagram for Red Hat OpenShift Container Platform on VPC on IBM Cloud\n\n\n\n\n\n Design requirements \n\nZoom\n\n![Design requirements for Secure infrastructure on VPC for regulated industries](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9610604e9f8dcd5f7b6b138dd22ba445300be7f5\/deployable-reference-architectures\/terraform-ibm-landing-zone\/heat-map-deploy-arch-slz-ocp.svg)\n\nFigure 2. Scope of the design requirements\n\n\n\n\n\n Components \n\n\n\n VPC architecture decisions \n\n\n\nTable 1. Architecture decisions\n\n Requirement Component Reasons for choice Alternative choice \n\n Provide access management and tooling for the workload that is deployed in the workload VPC Management VPC service Create a separate VPC service where SSH connectivity from outside is allowed \n Provide compute, storage, and network services to support hosted applications and operations that deliver services to the consumer Workload VPC service Create a separate VPC service as an isolated environment, without direct public internet connectivity and without direct SSH access","title":"","source":"https:\/\/cloud.ibm.com\/docs\/deployable-reference-architectures?topic=deployable-reference-architectures-ocp-ra"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10154-7-1896","score":17.225729,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_11282-0-1290","score":16.365118,"text":"\n\n\n\n\n\n\n  Cloud native development and application modernization by using Red Hat OpenShift on Power Systems Virtual Server \n\nCloud-native applications are the applications that are born in the cloud, which means that the applications use microservice-based architecture, containers, and a corresponding container orchestration platform. Red Hat\u00ae OpenShift\u00ae is enterprise Kubernetes platform enabling IT organizations to develop applications faster, deploy them reliably, and manage them efficiently.\n\nIn addition to developing new cloud-native applications, IT organizations are modernizing older, monolithic core business applications to support the faster delivery of new function to the business.\n\nFor information on application modernization on Power Systems, see [Field Guide to Application Modernization on IBM Power Systems](https:\/\/www.ibm.com\/downloads\/cas\/D9POQ3YR).\n\nFor information on deploying Red Hat OpenShift on Power Systems Virtual Server and tutorials to explore the platform, see [Deploying Red Hat OpenShift Container Platform 4.x on IBM Power Systems Virtual Servers](https:\/\/developer.ibm.com\/series\/deploy-ocp-cloud-paks-power-virtual-server\/?mhsrc=ibmsearch_a&mhq=%20Deploying%20Red%20Hat%20OpenShift%20Container%20Platform%20on%20Power%20Virtual%20Servers).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-app-modernization-using-RedHat-openshift"},{"document_id":"ibmcld_10531-7-2246","score":16.326784,"text":"\nRed Hat OpenShift on IBM Cloud partners \n\nTo provide you with all the capabilities that you need to run production workloads in the cloud, Red Hat OpenShift on IBM Cloud partners with other third-party service providers to enhance your cluster with logging, monitoring, and storage tools.\n\nReview the list of partners and the benefits of each solution that they provide. To find other proprietary IBM Cloud and third-party open source services that you can use in your cluster, see [Understanding IBM Cloud and 3rd party integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations).\n\n\n\n Portworx \n\n[Portworx](https:\/\/portworx.com\/products\/portworx-enterprise\/\/) is a highly available software-defined storage solution that you can use to manage local persistent storage for your containerized databases and other stateful apps, or to share data between pods across multiple zones.\n\nAn software defined storage (SDS), such as Portworx, solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n Benefits \n\nReview the following table to find a list of key benefits that you can get by using Portworx.\n\n\n\nBenefits of using Portworx\n\n Benefit Description \n\n Cloud native storage and data management for stateful apps Portworx aggregates available local storage that is attached to your worker nodes and that can vary in size or type, and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using Kubernetes persistent volume claims (PVC), you can add local persistent storage to your apps to store your data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-partners"},{"document_id":"ibmcld_10154-17039-18368","score":16.322346,"text":"\nContainer-native virtualization You can set up [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads. \n Serverless workloads You can set up [Red Hat OpenShift Serverless](https:\/\/www.redhat.com\/en\/topics\/microservices\/why-choose-openshift-serverless). You can also set up Red Hat OpenShift Serverless. \n Service mesh You can set up the [Red Hat OpenShift Service Mesh](https:\/\/docs.openshift.com\/container-platform\/4.11\/service_mesh\/v1x\/installing-ossm.html). You can also set up the Red Hat OpenShift Service Mesh, but you must [apply a network policy](https:\/\/gist.githubusercontent.com\/kitch\/39c504a2ed9e381c2aadea436d5b52e4\/raw\/d8efa69f41d41425b16bb363a881a98d40d3708c\/mesh-policy.yaml) for the service mesh ingress to work. \n API and CLI tools OpenShift Container Platform clusters are set up with access to Kubernetes and Red Hat OpenShift API resources. You can also install command line tools such as oc and odo. Red Hat OpenShift on IBM Cloud clusters come with the same capabilities to use the Kubernetes and Red Hat OpenShift API and CLI tools.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_14682-7-2113","score":15.963324,"text":"\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"},{"document_id":"ibmcld_10407-1492-3206","score":15.8889065,"text":"\nContainer-native virtualization The Red Hat OpenShift [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) to run VM workloads alongside container workloads is not supported by IBM. If you choose to install the add-on yourself, you must use bare metal machines, not virtual machines. You are responsible for resolving any issues and impact to your workloads from using container-native virtualization. \n Calico network plug-in Changing the Calico plug-in, components, or default Calico settings is not supported. For example, don't deploy a new Calico plug-in version, or modify the daemon sets or deployments for the Calico components, default IPPool resources, or Calico nodes. Instead, you can follow the documentation to [create a Calico NetworkPolicy or GlobalNetworkPolicy](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-network_policies), to [change the Calico MTU](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelcalico-mtu), or to [disable the port map plug-in for the Calico CNI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelcalico-portmap). \n Cluster quota You can't exceed 100 clusters per region and per [infrastructure provider](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers). If you need more of the resource, [contact IBM Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar). In the support case, include the new quota limit for the region and infrastructure provider that you want. \n IAM access groups You can't scope IBM Cloud IAM service access roles to an IAM access group because the roles are not synced to the RBAC roles within the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitations"},{"document_id":"ibmcld_14497-7-1724","score":15.770046,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_10495-9135-10569","score":15.74729,"text":"\n(https:\/\/cognitiveclass.ai\/courses\/docker-essentials)\n\n\n\n\n\n What is Red Hat OpenShift? \n\nRed Hat OpenShift is a Kubernetes container platform that provides a trusted environment to run enterprise workloads. It extends the Kubernetes platform with built-in software to enhance app lifecycle development, operations, and security. With Red Hat OpenShift, you can consistently deploy your workloads across hybrid cloud providers and environments. For more information about the differences between the community Kubernetes and Red Hat OpenShift cluster offerings, see the [comparison table](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\n\n\n\n\n What compute host infrastructure does the service offer? \n\nYou can create clusters on Classic or IBM Cloud\u00ae Virtual Private Cloud infrastructure. You can also bring your own hosts by using Satellite.\n\nFor more information, see [Supported infrastructure providers](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers).\n\n\n\n\n\n Related resources \n\nReview how you can learn about Kubernetes concepts and the terminology.\n\n\n\n* Familiarize yourself with the product by completing the [Creating clusters tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n* Learn how Kubernetes and Red Hat OpenShift on IBM Cloud work together by completing this [course](https:\/\/cognitiveclass.ai\/courses\/kubernetes-course).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-roks-overview"},{"document_id":"ibmcld_11163-34260-36361","score":15.72751,"text":"\nThe Red Hat OpenShift on IBM Cloud registries include Certified Operators, Marketplace Operators, and community Operators. This capability is supported by the beta release of IBM Cloud Partner Center and our general availability release of private catalog capabilities. For more information, see [Onboarding a Certified Operator bundle from a Red Hat registry](https:\/\/cloud.ibm.com\/docs\/third-party?topic=third-party-bundle-register).\n\n\n\n\n\n\n\n June 2021 \n\n\n\n 01 June 2021 \n\nNew invitation flow for existing IBM Cloud users\n: To enhance security and user protection, IBM Cloud\u00ae now requires all users to accept an invitation in order to become an active user within a new account. The new invitation flow has an impact only on inviting existing IBM Cloud\u00ae users. Previously, existing users were being automatically onboarded to each new account as they were invited. After this change, these users need to accept an invitation in their notifications, by email, or by using the CLI to onboard to a new account.\n: To accept invitations in the CLI, existing members of IBM Cloud\u00ae must use the [ibmcloud login](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_cliaccept-invitation-to-join-a-new-account-) command. They need to target the account that they are invited to join and use the new --accept flag.\n\nAs an account administrator, you might want to remind your users to accept these invitations.\n\n\n\n\n\n\n\n May 2021 \n\n\n\n 07 May 2021 \n\nSupport for third-party virtual server images with Terraform\n: Third-party providers can now offer virtual server images deployed by using Terraform in IBM Cloud. This capability is supported by the beta release of IBM Cloud Partner Center and our previously general availability release of private catalog capabilities. For more information, see [Onboarding a virtual server image with Terraform](https:\/\/cloud.ibm.com\/docs\/third-party?topic=third-party-vsimage-register).\n\n\n\n\n\n\n\n April 2021 \n\n\n\n 21 April 2021 \n\nDelivering notifications by using webhooks\n: You can now easily add webhooks to the notification distribution list in addition to adding email addresses.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatsnew"},{"document_id":"ibmcld_08255-0-309","score":15.702559,"text":"\n\n\n\n\n\n\n  Getting help and support \n\nIf you have problems or questions when you are using the Red Hat\u00ae OpenShift\u00ae for HPC offering on IBM Cloud\u00ae, you can:\n\n\n\n*  Call IBM Cloud technical support. For a list of country-based numbers, see [https:\/\/www.ibm.com\/planetwide](https:\/\/www.ibm.com\/planetwide).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hpc-openshift?topic=hpc-openshift-getting-help-and-support"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.6173196815}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06835-5127-5769","score":18.946632,"text":"\n* Deploy your application on your own choice of infrastructure, such as Virtual Server Instances (VSI).\n* Perform custom tasks, such as updating some configurations in a Red Hat\u00ae OpenShift\u00ae cluster.\n\n\n\nIn these cases, select \"custom\" as a deployment target.\n\n\n\n Performing a custom deployment \n\n\n\n* DevSecOps templates are fully customizable. You can provide your own stages and steps in the pipeline-config.yml file of the deployment repository.\n* You can provide your custom scripts in the setup, deploy, and acceptance-test stages in the pipeline-config.yml file.\n* These scripts are run during the continuous deployment (CD) pipeline run.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-custom-deployment-target"},{"document_id":"ibmcld_14493-7-1757","score":18.658009,"text":"\nRed Hat OpenShift Bastion node setup \n\nTo enable the deployment, a virtual machine (VM) is provisioned to run the Red Hat\u00ae OpenShift\u00ae installation steps and host an HTTP Server. This VM is known as the bastion node. The bastion node is connected to the Red Hat OpenShift logical switch and the ESG firewall and NAT rules are configured to allow SSH access from the jump-server or remote device.\n\nThe bastion node runs Red Hat\u00ae Enterprise Linux\u00ae, and it is used to host the scripts, files, and tools to provision the bootstrap, control-plane, and compute nodes. After the deployment, it is recommended to keep the bastion node as an administrative node for the cluster.\n\nThe bastion node setup consists of the following steps:\n\n\n\n1. Provision a Red Hat VM.\n2. Register the Red Hat VM.\n3. Install NGINX (HTTP Server).\n4. Generate an SSH private key and add it to the agent.\n\n\n\n\n\n Provisioning a Red Hat VM \n\nProvision a Red Hat VM based on the following specifications. Use the vCenter Server user interface or by using the PowerCLI script that is documented later in this document to provision the VM. Record you NAT address, which is configured in the NSX ESG.\n\n\n\nTable 1. Red Hat VM - provision\n\n VM IP address Gateway Disk (GB) Memory (GB) vCPU NAT address \n\n bastion 192.168.133.8 192.168.133.1 50 2 1 10.208.59.197 \n\n\n\nUse the following table to record your deployment details:\n\n\n\nTable 2. Red Hat VM deployment\n\n Parameter Example Your deployment \n\n vCenter Server IP address \n vCenter Server user \n vCenter Server password \n Logical Switch OpenShift-LS \n vCenter Server instance data store vsanDatastore \n VM name bastion \n ISO file name rhel-8.x-x86_64-dvd.iso \n IP address 192.168.133.8 \n Netmask 255.255.255.0 \n Default gateway 192.168.133.1","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-bastion-intro"},{"document_id":"ibmcld_10154-17039-18368","score":17.87311,"text":"\nContainer-native virtualization You can set up [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads. \n Serverless workloads You can set up [Red Hat OpenShift Serverless](https:\/\/www.redhat.com\/en\/topics\/microservices\/why-choose-openshift-serverless). You can also set up Red Hat OpenShift Serverless. \n Service mesh You can set up the [Red Hat OpenShift Service Mesh](https:\/\/docs.openshift.com\/container-platform\/4.11\/service_mesh\/v1x\/installing-ossm.html). You can also set up the Red Hat OpenShift Service Mesh, but you must [apply a network policy](https:\/\/gist.githubusercontent.com\/kitch\/39c504a2ed9e381c2aadea436d5b52e4\/raw\/d8efa69f41d41425b16bb363a881a98d40d3708c\/mesh-policy.yaml) for the service mesh ingress to work. \n API and CLI tools OpenShift Container Platform clusters are set up with access to Kubernetes and Red Hat OpenShift API resources. You can also install command line tools such as oc and odo. Red Hat OpenShift on IBM Cloud clusters come with the same capabilities to use the Kubernetes and Red Hat OpenShift API and CLI tools.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_03870-7-2207","score":17.847288,"text":"\nDeploy from Red Hat Marketplace \n\nThe Red Hat Marketplace can be used to deploy the IBM\u00ae Blockchain Platform 2.5.4 operator onto a Kubernetes cluster on OpenShift Container Platform 4.4+. This operator deploys instances of the certificate authority (CA), peer, ordering nodes and the IBM Blockchain Platform console that uses to manage the blockchain components on your network. This deployment option is available for OpenShift clusters that are running in IBM Cloud or your cloud.\n\n\n\n What is Red Hat Marketplace? \n\nRed Hat Marketplace is available directly from your OpenShift web console. It provides an open cloud catalog that makes it easier to discover and access certified software for container-based environments in public clouds. With automated deployment, software is immediately available to deploy on any Red Hat OpenShift cluster, providing a fast, integrated experience. Discover and buy certified software, and quickly deploy. Access open source and proprietary software, with responsive support, streamlined billing and contracting, simplified governance, and single-dashboard visibility across clouds. Built in partnership by Red Hat and IBM, this marketplace helps organizations deliver enterprise software and improve workload portability.\n\nRed Hat Marketplace provides a simplified alternative method for deploying an instance of the IBM Blockchain Platform to your cluster instead of the [manual deployment steps](https:\/\/cloud.ibm.com\/docs\/blockchain-sw-254?topic=blockchain-sw-254-deploy-ocp) or by using [Ansible playbook](https:\/\/cloud.ibm.com\/docs\/blockchain-sw-254?topic=blockchain-sw-254-ansible) scripts.\n\nWith just a few simple steps, you can get started with the IBM Blockchain Platform. After you install the operator to your OpenShift project, you can create a subscription that allows you to deploy the blockchain console UI.\n\nCurrently, you cannot deploy certificate authorities (CAs), peers, and ordering nodes directly, then, use the console to deploy those nodes instead. This tutorial includes only instructions for installing the console.\n\nTo learn more about the Marketplace see the [Red Hat documentation](https:\/\/marketplace.redhat.com).\n\n\n\n\n\n Limitations","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-deploy-ocp-rhm"},{"document_id":"ibmcld_10404-74695-75915","score":17.31836,"text":"\nRed Hat OpenShift Control Plane Operator v4.8.0-20211201 v4.8.0-20220107 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.8.0+20220107). \n Red Hat OpenShift on IBM Cloud Metrics Server v4.8.0-20211201 v4.8.0-20220107 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.8.0+20220107). \n Red Hat OpenShift 4.8.21 4.8.26 Changed the duration of worker node certificates from 3 years to 2 years. See the [Red Hat OpenShift release notes](https:\/\/docs.openshift.com\/container-platform\/4.8\/release_notes\/ocp-4-8-release-notes.htmlocp-4-8-26). \n Red Hat OpenShift on IBM Cloud toolkit 4.8.0+20211201 4.8.0+20220107 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https:\/\/github.com\/openshift\/ibm-roks-toolkit\/releases\/tag\/v4.8.0+20220107). \n OpenVPN client 2.4.6-r3-IKS-463 2.5.4-r0-IKS-556 Update base image to alpine 3.15 to address CVEs, no longer set the --compress config option, updated scripts. \n OpenVPN server 2.4.6-r3-IKS-462 2.5.4-r0-IKS-555 Update base image to alpine 3.15 to address CVEs, no longer set the --compress config option, updated scripts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_changelog_48"},{"document_id":"ibmcld_16729-139037-140928","score":17.314615,"text":"\nIn this tutorial, you learn how to create and deploy a scalable Java Spring application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Creating an IBM Cloud Satellite environment on AWS by using scripts](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-tutorial-trysat)Creating an IBM Cloud Satellite environment on AWS by using scripts\n\nThis tutorial and set of scripts provide a mostly automated way to set up an IBM Cloud Satellite location and Red Hat OpenShift cluster on Amazon Web Services (AWS). This is not a production-ready solution, but it provides a useful tool for proof-of-concepts, learning, and experimenting.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 1.5 hours\n* 2022-02-23\n\n\n\n[Part 4: Set up a Continuous Compliance (CC) toolchain](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-cc-toolchain)Part 4: Set up a Continuous Compliance (CC) toolchain\n\nThis tutorial is part 4 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 4 of this tutorial series, you use the toolchain template for continuous compliance (CC) to ensure that your deployed artifacts and their source repositories are always compliant.\n\nKubernetes service Continuous Delivery\n\n+1\n\nDevSecOps\n\n\n\n* 1 hour","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_14490-7-2135","score":17.28837,"text":"\nManaging Red Hat OpenShift for VMware \n\nReview the following information to manage your Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service after deployment.\n\n\n\n Rotating the Red Hat OpenShift certificates (required) \n\nRed Hat OpenShift for VMware uses kubelet client certificates that must be rotated periodically for security purposes. Red Hat OpenShift mainly automates the rotation process, but requires manual approval of certificate signing requests (CSRs). Therefore, it is important that you understand the Red Hat OpenShift certificate rotation schedule to avoid expired certificates.\n\nThe initial certificates that are created during installation expire 24 hours after they are created. IBM's automation process, which installs Red Hat OpenShift, handles the approval of the CSRs for this initial rotation, which is done by running a script on the bastion for the first 30 hours. The script is named \/root\/approve-csr.sh and its log file is named \/root\/approve-csr.log.\n\nFor the script to run successfully, the initial kubeadmin credentials must be the same until the initial certificate rotation is complete. Do not change the kubeadmin credentials for the first 24 hours. If the credentials are changed, you must monitor and approve the CSRs for the initial certificate rotation. For more information, see [Approving the CSRs for your machines](https:\/\/docs.openshift.com\/container-platform\/4.7\/installing\/installing_vsphere\/installing-vsphere.htmlinstallation-approve-csrs_installing-vsphere).\n\nDo not restart any of the Red Hat OpenShift cluster virtual machines (VMs) or the bastion VM until the first certificate rotation is done.\n\nAfter the initial certificate rotation, certificates are renewed every 30 days. You must establish a process to approve the CSRs for every certificate rotation. According to Red Hat\u00ae, you can approve CSRs when they reach 80% of their expiration period, which is approximately 25 days into the lifespan of the CSRs.\n\nIf you do not approve CSRs in time and the certificates expire, you can recover from expired control plane certificates and get the Red Hat OpenShift cluster operational again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_managing"},{"document_id":"ibmcld_10392-235456-236884","score":17.283272,"text":"\n* [Using the internal registry in Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryopenshift_internal_registry).\n\n\n\nEntitled software\n: If you have licensed products from your [MyIBM.com](https:\/\/myibm.ibm.com) container software library, you can [set up your cluster to pull images from the entitled registry](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registrysecret_entitled_software).\n\nscript update command\n: Added [steps for using the script update command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cliscript_update) to prepare your automation scripts for the release of version 1.0 of the Red Hat OpenShift on IBM Cloud plug-in.\n\n\n\n\n\n 12 September 2019 \n\nIngress ALB change log\n: Updated the ALB [nginx-ingress image to build 552](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-add-ons-changelogkube_ingress_changelog).\n\n\n\n\n\n 6 September 2019 \n\nNew! Chennai, India che01 single zone location for Red Hat OpenShift clusters\n: For more locations, see [Single and multizone locations in Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zones).\n\n\n\n\n\n 5 September 2019 \n\nIngress ALB change log\n: Updated the ALB [ingress-auth image to build 340](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-add-ons-changelogkube_ingress_changelog).\n\n\n\n\n\n 4 September 2019 \n\nCLI change log","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-relnotes"},{"document_id":"ibmcld_09583-9325-11065","score":17.272926,"text":"\nIt builds a docker image for each of the services you need. The producer, consumers and web application are all in different folders. Each folder has its own simple Dockerfile file that is used by the script to create a container image, which is then uploaded to the IBM Container Registry.\n2. It creates a bunch of kubernetes secrets with all the credentials that are going to be needed to access the different IBM services (IBM Cloudant, Redis and Event Streams).\n3. It deploys the application code (and the secretes) to the Red Hat OpenShift on IBM Cloud cluster using the instructions contained in the deployment.yml script.\n\n\n\n\n\n\n\n The deployment.yml script \n\nThis script tells Openshift what to deploy to the machines in the Openshift cluster. In our case this is:\n\n\n\n1. Data producers (trucktrackerproducer).\n2. Data consumers (trucktrackerredisconsumer and trucktrackercloudantconsumer)\n3. Web application (trucktrackerweb)\n\n\n\nIn all cases, they pull an image from the container registry and get fed some environment variables with the credentials they require to access external services.\n\n\n\n\n\n The Truck Tracker system \n\nThe Truck Tracker system is a set of simple Node.js scripts that use four main packages:\n\n\n\n1. [@ibm-cloud\/cloudant](https:\/\/github.com\/IBM\/cloudant-node-sdk) to connect to IBM Cloudant and read\/write data.\n2. [Redis](https:\/\/www.npmjs.com\/package\/redis) to connect to the Redis instance and read\/write data.\n3. [kafkajs](https:\/\/www.npmjs.com\/package\/kafkajs) to connect to the Event Streams instance.\n4. [Express](https:\/\/expressjs.com\/) to enable a simple web server that allows interaction with the data.\n\n\n\nThere are five main files:\n\n\n\n1. server.js: This runs the web server and communicates with Redis.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/messages-for-rabbitmq?topic=messages-for-rabbitmq-truck-tracker-ibmcloud"},{"document_id":"ibmcld_06600-9319-11059","score":17.272926,"text":"\nIt builds a docker image for each of the services you need. The producer, consumers and web application are all in different folders. Each folder has its own simple Dockerfile file that is used by the script to create a container image, which is then uploaded to the IBM Container Registry.\n2. It creates a bunch of kubernetes secrets with all the credentials that are going to be needed to access the different IBM services (IBM Cloudant, Redis and Event Streams).\n3. It deploys the application code (and the secretes) to the Red Hat OpenShift on IBM Cloud cluster using the instructions contained in the deployment.yml script.\n\n\n\n\n\n\n\n The deployment.yml script \n\nThis script tells Openshift what to deploy to the machines in the Openshift cluster. In our case this is:\n\n\n\n1. Data producers (trucktrackerproducer).\n2. Data consumers (trucktrackerredisconsumer and trucktrackercloudantconsumer)\n3. Web application (trucktrackerweb)\n\n\n\nIn all cases, they pull an image from the container registry and get fed some environment variables with the credentials they require to access external services.\n\n\n\n\n\n The Truck Tracker system \n\nThe Truck Tracker system is a set of simple Node.js scripts that use four main packages:\n\n\n\n1. [@ibm-cloud\/cloudant](https:\/\/github.com\/IBM\/cloudant-node-sdk) to connect to IBM Cloudant and read\/write data.\n2. [Redis](https:\/\/www.npmjs.com\/package\/redis) to connect to the Redis instance and read\/write data.\n3. [kafkajs](https:\/\/www.npmjs.com\/package\/kafkajs) to connect to the Event Streams instance.\n4. [Express](https:\/\/expressjs.com\/) to enable a simple web server that allows interaction with the data.\n\n\n\nThere are five main files:\n\n\n\n1. server.js: This runs the web server and communicates with Redis.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-mysql?topic=databases-for-mysql-truck-tracker-ibmcloud"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10154-17039-18368","score":19.913324,"text":"\nContainer-native virtualization You can set up [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads. \n Serverless workloads You can set up [Red Hat OpenShift Serverless](https:\/\/www.redhat.com\/en\/topics\/microservices\/why-choose-openshift-serverless). You can also set up Red Hat OpenShift Serverless. \n Service mesh You can set up the [Red Hat OpenShift Service Mesh](https:\/\/docs.openshift.com\/container-platform\/4.11\/service_mesh\/v1x\/installing-ossm.html). You can also set up the Red Hat OpenShift Service Mesh, but you must [apply a network policy](https:\/\/gist.githubusercontent.com\/kitch\/39c504a2ed9e381c2aadea436d5b52e4\/raw\/d8efa69f41d41425b16bb363a881a98d40d3708c\/mesh-policy.yaml) for the service mesh ingress to work. \n API and CLI tools OpenShift Container Platform clusters are set up with access to Kubernetes and Red Hat OpenShift API resources. You can also install command line tools such as oc and odo. Red Hat OpenShift on IBM Cloud clusters come with the same capabilities to use the Kubernetes and Red Hat OpenShift API and CLI tools.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_14497-7-1724","score":19.490236,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"},{"document_id":"ibmcld_10407-1492-3206","score":19.461887,"text":"\nContainer-native virtualization The Red Hat OpenShift [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) to run VM workloads alongside container workloads is not supported by IBM. If you choose to install the add-on yourself, you must use bare metal machines, not virtual machines. You are responsible for resolving any issues and impact to your workloads from using container-native virtualization. \n Calico network plug-in Changing the Calico plug-in, components, or default Calico settings is not supported. For example, don't deploy a new Calico plug-in version, or modify the daemon sets or deployments for the Calico components, default IPPool resources, or Calico nodes. Instead, you can follow the documentation to [create a Calico NetworkPolicy or GlobalNetworkPolicy](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-network_policies), to [change the Calico MTU](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelcalico-mtu), or to [disable the port map plug-in for the Calico CNI](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kernelcalico-portmap). \n Cluster quota You can't exceed 100 clusters per region and per [infrastructure provider](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers). If you need more of the resource, [contact IBM Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar). In the support case, include the new quota limit for the region and infrastructure provider that you want. \n IAM access groups You can't scope IBM Cloud IAM service access roles to an IAM access group because the roles are not synced to the RBAC roles within the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_limitations"},{"document_id":"ibmcld_10393-7-2069","score":19.263868,"text":"\nInstalling OpenShift Data Foundation on a private cluster \n\nOpenShift Data Foundation is a highly available storage solution that you can use to manage persistent storage for your containerized workloads in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nThis is an experimental feature that is available for evaluation and testing purposes and might change without notice.\n\nIn standard OpenShift Data Foundation configurations, the operators and drivers pull images from public container registries like registry.redhat.io. However, in private-only, air-gapped clusters (without access to the public internet) you must first mirror the ODF images to IBM Cloud Container Registry, then configure your OpenShift Data Foundation deployment to pull those images from a private container registry.\n\nSince this approach involves manually mirroring images from registry.redhat.io to your IBM Cloud Container Registry, this means you are responsible for repeating the mirroring process to get the latest patch updates or security fixes when they are available for OpenShift Data Foundation.\n\n\n\n Prerequisites \n\nBefore you install OpenShift Data Foundation in your cluster, meet the following prerequisite conditions.\n\n\n\n1. Create a Red Hat account if you do not already have one. For more information on creating a Red Hat account, see [Create a Red Hat login](https:\/\/www.redhat.com\/wapps\/ugc\/register.html?_flowId=register-flow&_flowExecutionKey=e1s1).\n2. Create or have access to a private cluster for OpenShift Data Foundation. If you already have a private cluster make sure it meets the following requirements.\n\n\n\n* Your cluster version must be at least version 4.11.\n* Your worker node operating system must be RHEL 8.\n* 1 Virtual Private Cloud (VPC) with 3 subnets (1 per zone) with no public gateway attached.\n* 1 Red Hat OpenShift on IBM Cloud cluster with at least 3 worker nodes spread evenly across 3 zones. The worker nodes must be at least 16x64.\n\n\n\n3. An IBM Cloud Container Registry instance with at least one namespace in the same region as your cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private"},{"document_id":"ibmcld_10154-7-1896","score":19.184597,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_14682-7-2113","score":18.918621,"text":"\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"},{"document_id":"ibmcld_14683-7-2001","score":18.781034,"text":"\nRed Hat OpenShift architecture \n\nThe IBM Cloud\u00ae for VMware Solutions offerings provide automation to deploy VMware\u00ae technology components in IBM Cloud data centers across the globe. The architecture consists of a single cloud region. It supports the ability to extend into more cloud regions that are located in another geography or into another IBM Cloud pod within the same data center.\n\nZoom\n\n![Red Hat OpenShift architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-components.svg)\n\nFigure 1. Red Hat OpenShift architecture\n\n\n\n Bastion hosts \n\nThe Management host is a Red Hat\u00ae Enterprise Linux\u00ae 8.0 virtual machine (VM). This VM hosts services to install and configure the Red Hat\u00ae OpenShift\u00ae instance and provides utilities to manage the Red Hat OpenShift environment. This host is normally deployed in the VXLAN Subnet.\n\n\n\n\n\n Bootstrap hosts \n\nThe bootstrap node is a Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The node is a temporary node that is used to start the installation.\n\n\n\n\n\n Control Plane hosts \n\nThe control plane hosts are Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The control plane nodes are known as the control plane, where Kubernetes services such as API server, etcd, and controller manager are defined. An NSX\u00ae load balancer is configured to spread load across these VMs for ports 6443 and 22623, exposing the api and api-int functions.\n\n\n\n\n\n Worker hosts \n\nThe worker hosts are Red Hat Enterprise Linux CoreOS (RHCOS), a new container-oriented operating system designed for running containers. The worker nodes are known as the data-plane, where the actual Kubernetes workloads are deployed. An NSX load balancer is configured to spread load across these VMs for ports 80 and 443, exposing the wildcard DNS and *.apps.\n\n\n\n\n\n Common services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-redhat-arch"},{"document_id":"ibmcld_11282-0-1290","score":18.703005,"text":"\n\n\n\n\n\n\n  Cloud native development and application modernization by using Red Hat OpenShift on Power Systems Virtual Server \n\nCloud-native applications are the applications that are born in the cloud, which means that the applications use microservice-based architecture, containers, and a corresponding container orchestration platform. Red Hat\u00ae OpenShift\u00ae is enterprise Kubernetes platform enabling IT organizations to develop applications faster, deploy them reliably, and manage them efficiently.\n\nIn addition to developing new cloud-native applications, IT organizations are modernizing older, monolithic core business applications to support the faster delivery of new function to the business.\n\nFor information on application modernization on Power Systems, see [Field Guide to Application Modernization on IBM Power Systems](https:\/\/www.ibm.com\/downloads\/cas\/D9POQ3YR).\n\nFor information on deploying Red Hat OpenShift on Power Systems Virtual Server and tutorials to explore the platform, see [Deploying Red Hat OpenShift Container Platform 4.x on IBM Power Systems Virtual Servers](https:\/\/developer.ibm.com\/series\/deploy-ocp-cloud-paks-power-virtual-server\/?mhsrc=ibmsearch_a&mhq=%20Deploying%20Red%20Hat%20OpenShift%20Container%20Platform%20on%20Power%20Virtual%20Servers).\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-app-modernization-using-RedHat-openshift"},{"document_id":"ibmcld_14492-7-1792","score":18.595434,"text":"\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-ocp_overview"},{"document_id":"ibmcld_14501-1523-3094","score":18.578625,"text":"\nDownloading Red Hat OpenShift 4.7 \n\nAccess the [Red Hat OpenShift Infrastructure Providers page](https:\/\/cloud.redhat.com\/openshift\/install\/vsphere\/user-provisioned).\n\n\n\n1. Download the installer.\n2. Download the Pull Secret.\n3. Download the Red Hat Enterprise Linux CoreOS (RHEL CoreOS) OVA image or download the OVA by using the following code. Replace 4.x and 4.x.3 with the current Red Hat OpenShift version, for example, 4.7. curl -O https:\/\/mirror.openshift.com\/pub\/openshift-v4\/dependencies\/rhcos\/4.x\/latest\/rhcos-4.x.3-x86_64-vmware.x86_64.ova\n4. Download the command-line tools if you want to run the commands from a desktop or outside Bastion host.\n\n\n\n\n\n\n\n Downloading RHEL 8.0 ISO \n\nDownload the ISO image for the bastion host.\n\n\n\n1. Go to the Red Hat [Product downloads](https:\/\/access.redhat.com\/downloads) page.\n2. Click RHEL 8.x Release and select the 8.x version.\n3. Download the source ISO images.\n4. The ISO file name is rhel-8.x-x86_64-dvd.iso.\n\n\n\n\n\n\n\n Collecting vCenter Server instance details \n\nAccess the IBM Cloud environment details.\n\n\n\n1. Log in to the [IBM Cloud for VMware Solutions console](https:\/\/cloud.ibm.com\/vmware).\n2. Click the IBM Cloud for VMware Solutions instance under Deployed Instances.\n3. From the Summary page, collect the vCenter and Active Directory information.\n4. Click Infrastructure and select the cluster.\n5. Under Network Interfaces, collect the Public and Private VLANs.\n\n\n\n\n\n\n\n Downloading and installing govc \n\nThe govc command is used to upload the OVF and ISO to a datastore from the jump-server or remote device.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-prereq-intro"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1772392868}}
{"task_id":"34ac6bedd4b35167cc59e289893e206a<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10154-15474-17414","score":23.281021,"text":"\nRed Hat OpenShift on IBM Cloud clusters come with all the same configurable project and build components as OCP clusters. You can also choose to integrate your cluster with IBM Cloud services like [Continuous Delivery](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cicd). \n Cluster health You can also set up logging, monitoring, and metering tools by installing and configuring various operators. These solutions are cluster-specific and not highly available unless you back them up. Your clusters feature one-click integrations with IBM Log Analysis and IBM Cloud Monitoring for enterprise-grade, persistent monitoring and logging solutions across clusters. You can also install the logging and monitoring operators as with standard OCP, but you might have to adjust the configuration settings. For more information, see [Logging and monitoring cluster health](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health). \n Migrating clusters You can use the cluster migrator operator to migrate clusters from one major version to another. Migration requires separate clusters; you can't update a cluster from one major version to another. Various open source tools might be used, but are not officially supported. As with standard OpenShift Container Platform, you can't update a cluster from one major version to another. If you use a third-party open source tool such as the [cluster migrator operator](https:\/\/github.com\/migtools\/mig-operator), the tool is not supported by IBM and might have limitations such as the migration UI being unavailable. \n Container-native virtualization You can set up [container-native virtualization add-on](https:\/\/docs.openshift.com\/container-platform\/4.11\/virt\/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10531-7-2246","score":22.639668,"text":"\nRed Hat OpenShift on IBM Cloud partners \n\nTo provide you with all the capabilities that you need to run production workloads in the cloud, Red Hat OpenShift on IBM Cloud partners with other third-party service providers to enhance your cluster with logging, monitoring, and storage tools.\n\nReview the list of partners and the benefits of each solution that they provide. To find other proprietary IBM Cloud and third-party open source services that you can use in your cluster, see [Understanding IBM Cloud and 3rd party integrations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations).\n\n\n\n Portworx \n\n[Portworx](https:\/\/portworx.com\/products\/portworx-enterprise\/\/) is a highly available software-defined storage solution that you can use to manage local persistent storage for your containerized databases and other stateful apps, or to share data between pods across multiple zones.\n\nAn software defined storage (SDS), such as Portworx, solution abstracts storage devices of various types, sizes, or from different vendors that are attached to the worker nodes in your cluster. Worker nodes with available storage on hard disks are added as a node to a storage cluster. In this cluster, the physical storage is virtualized and presented as a virtual storage pool to the user. The storage cluster is managed by the SDS software. If data must be stored on the storage cluster, the SDS software decides where to store the data for highest availability. Your virtual storage comes with a common set of capabilities and services that you can leverage without caring about the actual underlying storage architecture.\n\n\n\n Benefits \n\nReview the following table to find a list of key benefits that you can get by using Portworx.\n\n\n\nBenefits of using Portworx\n\n Benefit Description \n\n Cloud native storage and data management for stateful apps Portworx aggregates available local storage that is attached to your worker nodes and that can vary in size or type, and creates a unified persistent storage layer for containerized databases or other stateful apps that you want to run in the cluster. By using Kubernetes persistent volume claims (PVC), you can add local persistent storage to your apps to store your data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-partners"},{"document_id":"ibmcld_10154-7-1896","score":22.609013,"text":"\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https:\/\/www.ibm.com\/products\/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_ov"},{"document_id":"ibmcld_10264-7-2226","score":22.603813,"text":"\nSupported infrastructure providers \n\nWith Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, you can create a cluster from the following infrastructure providers. All the worker nodes in a cluster must be from the same provider. Originally, Red Hat OpenShift on IBM Cloud provisioned your worker nodes in a single provider, classic infrastructure.\n\nVirtual Private Cloud\n\n: Create your cluster on the next generation of IBM Cloud infrastructure virtual servers in your own Virtual Private Cloud (VPC).\n\nSatellite\n\n: Create your cluster on your own hardware, IBM Cloud Classic or VPC, or on virtual servers in another cloud provider like AWS or Azure.\n\nClassic infrastructure\n\n: Create your cluster on a classic compute, networking, and storage environment in IBM Cloud infrastructure.\n\n\n\n Virtual Private Cloud (VPC) \n\nVirtual Private Cloud\n\n\n\nTable 1. VPC infrastructure overview.\n\n Component Description \n\n Compute and worker node resources Worker nodes are created as virtual machines by using either shared infrastructure or dedicated hosts. Unlike classic clusters, VPC cluster worker nodes on shared hardware don't appear in your infrastructure portal or a separate infrastructure bill. Instead, you manage all maintenance and billing activity for the worker nodes through Red Hat OpenShift on IBM Cloud. Your worker node instances are connected to certain VPC instances that do reside in your infrastructure account, such as the VPC subnet or storage volumes. For dedicated hosts, the dedicated host price covers the vCPU, memory, and any instance storage to be used by any workers placed on the host. For dedicated hosts, the dedicated host price covers the vCPU, memory, and any [instance storage](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-instance-storage) to be used by any workers placed on the host. Note that all Intel\u00ae x86-64 servers have Hyper-Threading enabled by default. For more information, see [Intel Hyper-Threading Technology](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profilesvpc-intel-hyper-threading). \n Security Clusters on shared hardware run in an isolated environment in the public cloud. Clusters on dedicated hosts do not run in a shared environment, instead only your clusters are present on your hosts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-infrastructure_providers"},{"document_id":"ibmcld_10242-7-1943","score":22.538164,"text":"\nLogging for clusters \n\nFor cluster and app logs, Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters include built-in tools to help you manage the health of your single cluster instance. You can also set up IBM Cloud tools for multi-cluster analysis or other use cases, such as IBM Cloud Kubernetes Service add-ons: IBM Log Analysis and IBM Cloud Monitoring.\n\n\n\n Understanding options for logging \n\nTo help understand when to use the built-in Red Hat OpenShift tools or IBM Cloud integrations, review the following information.\n\nIBM Log Analysis\n: Customizable user interface for live streaming of log tailing, real-time troubleshooting issue alerts, and log archiving.\n\n\n\n* Quick integration with the cluster via a script.\n* Aggregated logs across clusters and cloud providers.\n* Historical access to logs that is based on the plan you choose.\n* Highly available, scalable, and compliant with industry security standards.\n* Integrated with IBM Cloud IAM for user access management.\n* Flexible plans, including a free Lite option.\n\n\n\nTo get started, see [Forwarding cluster and app logs to IBM Log Analysis](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-healthopenshift_logging).\n\nBuilt-in Red Hat OpenShift logging tools\n: Built-in view of pod logs in the Red Hat OpenShift web console.\n\n\n\n* Built-in pod logs are not configured with persistent storage. You must integrate with a cloud database to back up the logging data and make it highly available, and manage the logs yourself.\n\n\n\nTo set up an [OpenShift Container Platform Elasticsearch, Fluentd, and Kibana EFK stack](https:\/\/docs.openshift.com\/container-platform\/4.11\/logging\/cluster-logging.html), see [installing the cluster logging operator](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-healthoc_logging_operator). Keep in mind that your worker nodes must have at least 4 cores and GB memory to run the cluster logging stack.\n\nService logs: IBM Cloud\u00ae Activity Tracker","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health"},{"document_id":"ibmcld_03870-7-2207","score":22.301064,"text":"\nDeploy from Red Hat Marketplace \n\nThe Red Hat Marketplace can be used to deploy the IBM\u00ae Blockchain Platform 2.5.4 operator onto a Kubernetes cluster on OpenShift Container Platform 4.4+. This operator deploys instances of the certificate authority (CA), peer, ordering nodes and the IBM Blockchain Platform console that uses to manage the blockchain components on your network. This deployment option is available for OpenShift clusters that are running in IBM Cloud or your cloud.\n\n\n\n What is Red Hat Marketplace? \n\nRed Hat Marketplace is available directly from your OpenShift web console. It provides an open cloud catalog that makes it easier to discover and access certified software for container-based environments in public clouds. With automated deployment, software is immediately available to deploy on any Red Hat OpenShift cluster, providing a fast, integrated experience. Discover and buy certified software, and quickly deploy. Access open source and proprietary software, with responsive support, streamlined billing and contracting, simplified governance, and single-dashboard visibility across clouds. Built in partnership by Red Hat and IBM, this marketplace helps organizations deliver enterprise software and improve workload portability.\n\nRed Hat Marketplace provides a simplified alternative method for deploying an instance of the IBM Blockchain Platform to your cluster instead of the [manual deployment steps](https:\/\/cloud.ibm.com\/docs\/blockchain-sw-254?topic=blockchain-sw-254-deploy-ocp) or by using [Ansible playbook](https:\/\/cloud.ibm.com\/docs\/blockchain-sw-254?topic=blockchain-sw-254-ansible) scripts.\n\nWith just a few simple steps, you can get started with the IBM Blockchain Platform. After you install the operator to your OpenShift project, you can create a subscription that allows you to deploy the blockchain console UI.\n\nCurrently, you cannot deploy certificate authorities (CAs), peers, and ordering nodes directly, then, use the console to deploy those nodes instead. This tutorial includes only instructions for installing the console.\n\nTo learn more about the Marketplace see the [Red Hat documentation](https:\/\/marketplace.redhat.com).\n\n\n\n\n\n Limitations","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-deploy-ocp-rhm"},{"document_id":"ibmcld_10166-10513-12864","score":22.186161,"text":"\nDevelopers started by deploying their apps in containers with Red Hat OpenShift on IBM Cloud. They created clusters for a shared Dev environment that allow worldwide Developers to collaboratively deploy app improvements quickly. Containers allow each development team to use the language of their choice.\n\nSecurity first: The IT Execs chose bare metal clusters. With bare metal for Red Hat OpenShift on IBM Cloud, the sensitive customs workloads now have familiar isolation but within the flexibility of public cloud.\n\nBecause the shipping company also wants to work with other ports, app security is crucial. Shipping manifests and customs information are highly confidential. From that secure core, Vulnerability Advisor provides these scans:\n\n\n\n* Image vulnerability scans\n* Policy scans that are based on ISO 27k\n\n\n\nAt the same time, IBM Cloud\u00ae Identity and Access Management helps to control who has which level of access to the resources.\n\nDevelopers focus on domain problems, by using existing tools: Instead of Developers that write unique logging and monitoring code, they snap it into apps, by binding IBM Cloud services to clusters. Developers are also freed up from infrastructure management tasks because IBM takes care of Kubernetes and infrastructure upgrades, security, and more.\n\nCompute, storage, and apps run in the public cloud with secure access to shipping data across the globe, as needed. Compute in clusters is tamper-proof and isolated to bare metal.\n\nTechnical solution:\n\n\n\n* Red Hat OpenShift on IBM Cloud\n* IBM Cloud\u00ae Functions\n* IBM Cloudant\n* IBM Secure Gateway\n\n\n\n\n\n Step 1: Containerize apps, by using microservices \n\n\n\n* Create a Node.js app or deploy an example.\n* Structure apps into a set of cooperative microservices that run within Red Hat OpenShift on IBM Cloud based on functional areas of the app and its dependencies.\n* Deploy the manifest and shipment apps to container that run in Red Hat OpenShift on IBM Cloud.\n* Provide standardized DevOps dashboards through Kubernetes.\n* Use IBM Secure Gateway to maintain secure connections to existing on-premises databases.\n\n\n\n\n\n\n\n Step 2: Ensure global availability \n\n\n\n* After Developers deploy the apps in their Dev and Test clusters, they use the IBM Cloud\u00ae Continuous Delivery toolchains and Helm to deploy country-specific apps into clusters across the globe.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_uc_gov"},{"document_id":"ibmcld_10258-2744-4496","score":22.118715,"text":"\nWith Red Hat OpenShift on IBM Cloud, you can create a standard cluster in a [Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started). A VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud.\n\nBefore you can create a VPC cluster, you must have a VPC and at least one VPC subnet that you provision by using the IBM Cloud console, CLI, or API. You manage these resources in the VPC dashboard directly. When you create your cluster, worker nodes are automatically provisioned as [Virtual Servers for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-advanced-virtual-servers) instances and you can view and manage these instances in Red Hat OpenShift on IBM Cloud only.\n\nTo add persistent storage to your VPC cluster, you can use the [Block Storage for VPC add-on](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-block). The add-on sets up pre-defined Kubernetes storage classes, the storage provider, and the storage driver in your cluster so that you can provision Block Storage for VPC by using Kubernetes persistent volume claims (PVCs).\n\nTo secure your cluster network traffic, you can modify the default security group for your worker nodes. For more information, see [Security in your IBM Cloud VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-security-in-your-vpc).\n\nTo connect to a different VPC or to an on-prem data center, use the [VPN for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpn-onprem-example) service.\n\n\n\n\n\n\n\n Kubernetes community and open source integrations \n\nBecause you own the standard clusters that you create in Red Hat OpenShift on IBM Cloud, you can choose to install third-party solutions to add extra capabilities to your cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ibm-3rd-party-integrations"},{"document_id":"ibmcld_10246-7-2068","score":22.09402,"text":"\nMonitoring cluster health \n\nFor cluster metrics and app monitoring, Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters include built-in tools to help you manage the health of your single cluster instance. You can also set up IBM Cloud tools for multi-cluster analysis or other use cases, such as IBM Cloud Kubernetes Service add-ons: IBM Log Analysis and IBM Cloud Monitoring.\n\n\n\n Understanding options for monitoring \n\nTo help understand when to use the built-in Red Hat OpenShift tools or IBM Cloud integrations, review the following information.\n\n\n\n IBM Cloud Monitoring \n\nReview the following details about IBM Cloud Monitoring.\n\n\n\n* Customizable user interface for a unified look at your cluster metrics, container security, resource usage, alerts, and custom events.\n* Quick integration with the cluster via a script.\n* Aggregated metrics and container monitoring across clusters and cloud providers.\n* Historical access to metrics that is based on the timeline and plan, and ability to capture and download trace files.\n* Highly available, scalable, and compliant with industry security standards.\n* Integrated with IBM Cloud IAM for user access management.\n* Free trial to try out the capabilities.\n* To get started, see [Forwarding cluster and app metrics to IBM Cloud Monitoring](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-monitoropenshift_monitoring).\n\n\n\nFor more information, see [Monitoring](https:\/\/docs.openshift.com\/container-platform\/4.11\/monitoring\/monitoring-overview.html).\n\n\n\n\n\n Built-in Red Hat OpenShift monitoring tools \n\nReview the following details about built-in monitoring tools for your cluster.\n\n\n\n* Built-in Prometheus and Grafana deployments in the openshift-monitoring project for cluster metrics.\n* At-a-glance, real-time view of how your pods consume cluster resources that can be accessed from the Red Hat OpenShift Cluster Console.\n* Monitoring is on a per-cluster basis.\n* The openshift-monitoring project stack is set up in a single zone only. No persistent storage is available to back up or view metric history.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-monitor"},{"document_id":"ibmcld_14497-7-1724","score":22.076654,"text":"\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/5bdb37c0149145723c5437e8176651928565e722\/vmwaresolutions\/images\/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04145-1739-3868","score":14.432456,"text":"\nThe functionality of this plan was split across various tiers and are now available in Enterprise Essential, Enterprise Advanced, and Enterprise Premier plans. See [Transition to Enterprise](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transitioning-next-plan).\n\n\n\n\n\n How do I delete my CIS instance? \n\nTo delete a CIS instance, you must first delete all global load balancers, pools, and health checks. Then delete the associated domain (zone). Go to the Overview page and click the trash can icon next to the domain name located in the Service Details section to start the deletion process.\n\nIf you are moving your domain to a different provider, be sure to migrate your DNS records and other configuration information to the new provider before activating the domain there. Activating the domain before migrating from CIS can cause your domain to changed to a [Moved state](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-domain-moved-status).\n\n\n\n\n\n I added a user to my account and gave that user permission to manage Internet Services instance(s). Why is that user facing authentication issues? \n\nIt's possible that you did not assign \"service access roles\" to the user. Note that there are two separate sets of roles:\n\n\n\n* Platform access\n* Service access\n\n\n\nYou need platform access roles to create and manage service instances, while service access roles perform service-specific operations on service instances. In the console, these settings can be updated by selecting Manage > Security > Identity and Access.\n\n\n\n\n\n Why is my domain in Pending state? How do I activate it? \n\nWhen you add a domain to CIS, we give you a couple of name servers to configure at your registrar (or at your DNS provider, if you are adding a subdomain). The domain or subdomain remains in pending state until you configure the name servers correctly. Make sure you add both the name servers to your registrar or DNS provider. We periodically scan the public DNS system to check whether the name servers have been configured as instructed. As soon as we are able to verify the name server change (which can take up to 24 hours), we activate your domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq"},{"document_id":"ibmcld_04149-3050-4970","score":14.384869,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_13139-19107-19978","score":13.945511,"text":"\nDelete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers)\n* [Building containers from images](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-images)\n* [Best practice to secure traffic and internet application via CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitybest-practice-configure-security-level-selectively)\n* [Improving App Availability with Multizone Clusters](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/improving-app-availability-multizone-clusters)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-multi-region-k8s-cis"},{"document_id":"ibmcld_13139-17831-19468","score":13.913681,"text":"\nIn addition, you can now control what content gets cached by CIS and how long it stays cached. Go to Performance > Caching to define the global caching level and the browser expiration. You can customize the global security and caching rules with Page Rules. Page Rules enable fine-grained configuration using specific domain paths. As example with Page Rules, you could decide to cache all contents under \/assets for 3 days:\n\nZoom\n\n![Page Rules](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-multi-region-k8s-cis"},{"document_id":"ibmcld_04132-3821-5296","score":13.598135,"text":"\nDeleting a webhook using the CLI \n\nTo delete a webhook using the CLI, run the following command.\n\nibmcloud cis alert-webhook-delete WEBHOOK_ID [-i, --instance INSTANCE] [-f, --force]\n\nWhere:\n\n\n\n* WEBHOOK_ID is the ID of webhook.\n* i, --instance value is the instance name or ID. If not set, the context instance specified by 'cis instance-set INSTANCE' is used.\n* -f, --force attempts to delete webhook without prompting for confirmation.\n\n\n\n\n\n\n\n\n\n Configuring webhooks using the API \n\nTo call these methods, you must be assigned one or more IAM access roles.\n\n\n\n* internet-svcs.zones.read\n* internet-svcs.zones.update\n\n\n\nYou can check your access by going to Users > name > Access policies.\n\n\n\n Creating a webhook using the API \n\nCreating a webhook alert is a two step process. First, create the webhook, then use the ID in the response that you receive to create the alert.\n\nTo create a webhook by using the API, follow these steps:\n\n\n\n1. Set up your API environment with the correct variables.\n2. Store your the following variable to be used in the API command:\n\n\n\n* crn: the full url-encoded CRN of the service instance.\n* name: the name of the webhook.\n* url: the URL of the webhook.\n* secret: the optional secret or API key needed to use the webhook.\n\n\n\n3. When all variables are initiated, create the webhook:\n\n\n\ncurl -X POST https:\/\/api.cis.cloud.ibm.com\/v1\/:crn\/alerting\/destinations\/webhooks\n-H 'content-type: application\/json'\n-H 'x-auth-user-token: Bearer xxxxxx'","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks"},{"document_id":"ibmcld_12492-87895-89178","score":13.459613,"text":"\n\"cis_crn\": \"crn:v1:bluemix:public:internet-svcs:global:a\/a5ebf2570dcaedf18d7ed78e216c263a:0f4c764e-dc3d-44d1-bd60-a2f7cd91e0c0::\"\n},\n\"name\": \"my-cis-instance\",\n\"type\": \"cis\"\n},\n\"wrap_info\": null,\n\"warnings\": null,\n\"auth\": null\n}\n\n\n\n\n\n\n\n Delete a configuration \n\nRemoves a configuration for a secrets engine that serves as the backend for a specific type of secret. You can delete configurations for the following secret types: public_cert, private_cert\n\n\n\n Example requests \n\nDelete a public certificate authority configuration.\n\ncurl -X DELETE 'https:\/\/https:\/\/{instance_id}.{region}.secrets-manager.appdomain.cloud\/v1\/ibmcloud\/public_cert\/config\/certificate_authorities\/my-lets-encrypt' -H 'X-Vault-Token: {Vault-Token}'\n\nDelete the DNS provider configuration.\n\ncurl -X DELETE 'https:\/\/https:\/\/{instance_id}.{region}.secrets-manager.appdomain.cloud\/v1\/ibmcloud\/public_cert\/config\/dns_providers\/my-cis-instance' -H 'X-Vault-Token: {Vault-Token}'\n\nDelete a private certificate authority configuration.\n\ncurl -X DELETE 'https:\/\/https:\/\/{instance_id}.{region}.secrets-manager.appdomain.cloud\/v1\/ibmcloud\/private_cert\/config\/root_certificate_authorities\/my-root-ca' -H 'X-Vault-Token: {Vault-Token}'\n\n\n\n\n\n Example response \n\nA successful request returns an HTTP 204 No Content response.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-api"},{"document_id":"ibmcld_04132-1248-2869","score":13.374449,"text":"\n[overflow icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/\/images\/horizontal-overflow-icon.png) of the webhook you want to delete, and select Delete. Select Delete in the confirmation box to confirm, or Cancel to close the confirmation box without completing the delete operation.\n\n\n\n\n\n\n\n Configuring webhooks using the CLI \n\n\n\n Creating a webhook using the CLI \n\nTo create a webhook using the CLI, run the following command.\n\nibmcloud cis alert-webhook-create --name NAME --url URL [--secret SECRET] [-i, --instance INSTANCE] [--output FORMAT]\n\nWhere:\n\n\n\n* --name valueis the name of the webhook.\n* --url value is the POST endpoint to call when dispatching an alert.\n* --secret value is the secret that will be passed in the webhook auth header when dispatching a webhook alert.\n* -i, --instance value is the instance name or ID. If not set, the context instance specified by 'cis instance-set INSTANCE' is used.\n* --output value specifies output format; only JSON is supported.\n\n\n\n\n\n\n\n Listing all webhooks using the CLI \n\nTo list a webhook using the CLI, run the following command.\n\nibmcloud cis alert-webhooks [-i, --instance INSTANCE] [--output FORMAT]\n\nWhere:\n\n\n\n* -i, --instance value is the instance name or ID. If not set, the context instance specified by 'cis instance-set INSTANCE' is used.\n* --output value specifies output format; only JSON is supported.\n\n\n\n\n\n\n\n Getting details for a webhook using the CLI \n\nTo get a webhook using the CLI, run the following command.\n\nibmcloud cis alert-webhook WEBHOOK_ID [-i, --instance INSTANCE] [--output FORMAT]\n\nWhere:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-webhooks"},{"document_id":"ibmcld_04183-0-2205","score":13.320345,"text":"\n\n\n\n\n\n\n  Securing your data in CIS \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Internet Services, it is important to know exactly what data is stored and encrypted and how to delete any stored personal data.\n\n\n\n  How your data is stored and encrypted in CIS \n\nCIS interacts with Cloudflare services using a channel that is fully encrypted end-to-end using Transport Layer Security (TLS) 1.2. CIS does not store any customer data. Configuration data about your specific CIS configuration is encrypted in transit and at rest. CIS configuration data is deleted on your request through the UI, CLI, or API.\n\n\n\n\n\n  Protecting your sensitive data in CIS \n\nAll data related to CIS configuration is not considered sensitive data. The configuration data is encrypted at rest. No customer-managed keys are managed by the CIS offering. Therefore, neither Key Protect nor Hyper Protect Crypto Services are used.\n\n\n\n  Working with customer-managed keys for CIS \n\nNo customer-managed keys are managed by the CIS offering.\n\n\n\n\n\n\n\n  Deleting your data in CIS \n\nThe CIS configuration data is deleted on request through the UI, CLI or API.\n\n\n\n  Deleting CIS instances \n\nThe CIS data retention policy describes how long your data is stored after you delete the service. The data retention policy is included in the CIS service description, which you can find in [IBM Cloud Terms](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-terms). When a CIS instance is deleted by the UI, CLI, or API, the instance data is retained for seven days from deletion.\n\nBefore deleting an instance, all the domains in the instance must be removed.\n\nDeleting the CIS instance removes all data.\n\n\n\n\n\n  Restoring deleted data for CIS \n\nCIS can currently restore the deleted instance. After you delete an instance of CIS, you can restore the deleted service instance within the data retention period of seven days. After the seven-day period expires, the service instance is permanently deleted.\n\nTo view which service instances are available for restoration, use the ibmcloud resource reclamations command. To restore a deleted service instance, use the ibmcloud resource reclamation-restore command.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data"},{"document_id":"ibmcld_04334-285779-286748","score":12.998869,"text":"\nIf not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.-f, --force: Attempt to delete policy without prompting for confirmation.<-- <\/section \"id=\"section-delete-alert-policy-options\" \"> --><-- <section \"id=\"section-delete-alert-policy-examples\" \"> --> Examples delete an alert policy a2633e68-1a64-2512-a321-b64a17c7db7a. ibmcloud cis alert-policy delete a2633e68-1a64-2512-a321-b64a17c7db7a -f -i \"cis-demo\"\n<-- <\/section \"id=\"section-delete-alert-policy-examples\" \"> --><-- <\/section \"id=\"section-delete-alert-policy\" \"> --><-- <\/section \"id=\"section-alert-policy\" \"> --><-- <section \"id=\"section-alert-webhook\" \"> --> Alert Webhook <-- <section \"id=\"section-list-alert-webhooks\" \"> --> ibmcloud cis alert-webhooks List all alert webhooks. ibmcloud cis alert-webhooks -i, --instance INSTANCE] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-opt-list-alert-webhooks\" \"> --> Command options -i, --instance: Instance name or ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-290913-292361","score":12.965114,"text":"\nIf not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.-f, --force: Attempt to delete webhook without prompting for confirmation.<-- <\/section \"id=\"section-delete-alert-webhook-options\" \"> --><-- <section \"id=\"section-delete-alert-webhook-examples\" \"> --> Examples delete an alert webhook b2633e68-9a64-4519-b361-a64a67c8db8e. ibmcloud cis alert-webhook-delete b2633e68-9a64-4519-b361-a64a67c8db8e -f -i \"cis-demo\"\n<-- <\/section \"id=\"section-delete-alert-webhook-examples\" \"> --><-- <\/section \"id=\"section-delete-alert-webhook\" \"> --><-- <\/section \"id=\"section-alert-webhook\" \"> --><-- <section \"id=\"section-private-endpoint-support\" \"> --> Private endpoint support To ensure that you have enhanced control and security over your data when you use the CIS CLI, you have the option of using private routes to CIS endpoints. Private routes are not accessible or reachable over the internet. By using CIS private endpoints, you can protect your data from threats from the public network and logically extend your private network.Regional support is provided for a limited number of CLI commands. The following regions support private endpoints:<-- <ul> --> * us-south * us-east<-- <\/ul> --><-- <section \"id=\"section-logging-in-cli-private-endpoint\" \"> --> Logging in to the CLI with a private endpoint Use the following command to log in to a private endpoint by using the CLI: ibmcloud login -a private.cloud.ibm.com","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.9197207891,"ndcg_cut_5":0.9197207891,"ndcg_cut_10":0.9197207891}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04195-6086-8151","score":17.70976,"text":"\nBecause CIS doesn't support email traffic by default, you must set the PTR record to the location of your email server. Contact your email provider for assistance.\n\n\n\n\n\n\n\n Updating DNS records \n\nIn each record row, you can click the Edit record option from the menu, which opens a dialog box that you can use to update the record.\n\nAfter you are finished making your changes, select Update record to save them, or Cancel to abort the changes.\n\n\n\n\n\n Deleting DNS records \n\nIn each record row, you can select the Delete record option from the menu, which opens a dialog box to confirm the delete process.\n\nYou can select the Delete button to confirm your delete action. Select Cancel if you don't want to delete.\n\n\n\n\n\n Importing and exporting DNS records \n\nDNS records can be imported into and exported from CIS. All files are imported and exported as .txt files in BIND format. Learn more about [BIND format](https:\/\/en.wikipedia.org\/wiki\/Zone_file). Click the overflow menu and select to import or export records.\n\nImport records - By default, a total of 3500 DNS records are allowed (imported and created on CIS). You can import multiple files, one at a time, as long as the total number of records is under the max limit. After importing, you are shown a summary with the number of records successfully added and the number that failed, along with the reason why each record failed.\n\nExport records - Use Export records to create a backup of your zone file, or export it to use with another DNS provider. When this menu option is clicked, the records are downloaded to the location specified by your browser settings (typically the Downloads folder). To select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cis"},{"document_id":"ibmcld_04149-3050-4970","score":16.5004,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04148-0-1895","score":14.935294,"text":"\n\n\n\n\n\n\n  Getting CIS running with a new subdomain \n\nFollow these steps to practice using CIS with a subdomain or CNAME. This example uses the GoDaddy domain registrar. Your case might be different, depending on which registrar you use.\n\n\n\n1.  Deploy a CIS instance by using the IBM Cloud console or API.\n\nIt is recommended that you mirror the name of your CIS instance with the domain or subdomain.\n2.  Click Let\u2019s get started.\n3.  Enter the subdomain in the Domain name field and click Connect and continue.\n4.  For new subdomains click Next Step, for existing subdomains click Import records.\n5.  Make note the New NS records for entry into the GoDaddy DNS Management system.\n6.  Log in to GoDaddy domain Registrar.\n7.  Navigate to the DNS Management page for the candidate CIS domain. IBM Cloud\u00ae must be updated through the API.\n8.  Click ADD to create an NS Host record for each name server entry provided from CIS.\n9.  Set up a DNS record with the supplied CIS NS Records\n\n\n\n*  Type Nameserver\n*  Host subdomain (the name of the subdomain, for example, subdomain.example.com)\n*  Points to ns004.name.cloud.ibm.com\n*  TTL \u00bd hour\n\n\n\n10. The DNS Management page now reflects the two new NS records for the subdomain.\n11. Go back to the IBM Cloud Internet Services instance.\n12. After the NS Records are DNS propagated, it is reflected in the DNS tools, and you are ready to proceed.\n13. With completed NS propagation, click Check name servers.\n14. CIS starts checking NS configuration for the subdomain and might be in a Pending State.\n\nAny typographical errors in can produce a \"silent\" failure. If your subdomain is in the pending state for more than 30 minutes, you might have an error.\n\n\n\nUpon successful subdomain name server and NS record confirmation, the CIS instance reports Active. Customers are now ready to start configuring the service and routing traffic to their services.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-get-started-new-subdomain"},{"document_id":"ibmcld_04334-33215-34565","score":14.830114,"text":"\nValid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-import \n\nImport your BIND config.\n\nibmcloud cis dns-records-import DNS_DOMAIN_ID --file FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: BIND config to import. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nImport BIND config in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-import 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-export \n\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-34286-35758","score":14.256971,"text":"\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nExport BIND config for domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-export 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n Domain \n\nManipulate domains by using the following domain commands.\n\n\n\n ibmcloud cis domain-add \n\nAdd a domain.\n\nibmcloud cis domain-add DNS_DOMAIN_NAME [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\ntype value\n: Specify the domain type setup. Valid values: full, partial (default full).\n\n\n\n* full: A full zone implies that DNS is hosted.\n* partial: A partial zone implies that CNAME setup domain.\n\n\n\njump-start\n: Automatically attempt to fetch existing DNS records.\n\nDNS_DOMAIN_NAME\n: The FQDN of DNS domain. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nAdd a new domain test.com in instance cis-demo.\n\nibmcloud cis domain-add \"test.com\" -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis domain-resume \n\nResume the given domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-32129-33511","score":14.015212,"text":"\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.\n\nibmcloud cis dns-records DNS_DOMAIN_ID [--type TYPE] [--name NAME] [--content CONTENT] [--page PAGE] [--per-page PER_PAGE] [--order ORDER] [--direction DIRECTION] [--match MATCH] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--type\n: Type of DNS records to display.\n\n--name\n: Value of name field to filter by.\n\n--content\n: Value of content field to filter by.\n\n--page\n: Page number of paginated results.\n\n--per_page\n: Maximum number of DNS records per page.\n\n--order\n: Field by which to order list of DNS records. Valid values are type, name, content, ttl, proxied\n\n--direction\n: Direction in which to order results [ascending or descending order]. Valid values are asc, desc\n\n--match\n: Whether to match all or at least one search parameter. Valid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-31256-32402","score":13.769033,"text":"\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nGet a dns record details in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-record-delete \n\nDelete a DNS record for a given domain of a service instance.\n\nibmcloud cis dns-record-delete DNS_DOMAIN_ID DNS_RECORD_ID [-i, --instance INSTANCE]\n\n\n\n Command options \n\n`DNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\nDNS_RECORD_ID\n: The ID of DNS record. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE will be used.\n\n\n\n\n\n Examples \n\nDelete a dns record in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-record-delete 31984fea73a15b45779fa0df4ef62f9b 77335b17ce1853d0d76e08a8379a0376 -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records \n\nList all DNS records for a given domain of a service instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_07411-2937-4769","score":13.472438,"text":"\n* TTL (Default value is 15 min)\n\n\n\n\n\n\n\n SRV type record \n\nTo add this record type, valid values must exist in the Name, Service Name, and Target fields. Use the list menu to select a protocol, which defaults to the UDP protocol. Additionally, you can specify Priority, Weight, and Port. These three fields default to a value of 1. Specify a TTL value from the list menu, with a default value of 15 min.\n\nRequired fields\n\n\n\n* Name\n* Service Name\n* Target\n* TTL (Default value is 15 min)\n* Protocol (Default value is UDP)\n* Priority (Default value is 1)\n* Weight (Default value is 1)\n* Port (Default value is 1)\n\n\n\n\n\n\n\n TXT type record \n\nTo add this record type, valid values must exist in the Name and Content fields. Specify a TTL value from the list menu, with a default value of 15 min.\n\nFor security and privacy reasons, it is recommended that you not use TXT type records for sensitive and confidential data.\n\nRequired fields\n\n\n\n* Name\n* Content\n* TTL (Default value is 15 min)\n\n\n\n\n\n\n\n\n\n Updating DNS records \n\nIn each record row, click the Edit icon to open a panel where you can update the record.\n\n\n\n\n\n Deleting DNS records \n\nIn each record row, click the Delete icon to open a panel where you can confirm the delete process.\n\n\n\n\n\n Importing resource records \n\nTo import resource records, take the following steps:\n\n\n\n1. From your DNS Services instance, select the zone to which you want to import records\n2. Click Select record action in the zone details section and choose Import records\n3. You can drag and drop the import file into the panel that appears, or click the link to upload from your computer\n\nImport files must be plain text format, and cannot exceed 8 MB\n4. Click Import records\n\n\n\nYour import file should follow this sample format:\n\nwww.test.com. 900 IN A 127.0.0.1\nwww.test.com. 900 IN AAAA ::1\nw3.test.com.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-managing-dns-records"},{"document_id":"ibmcld_07411-11870-13124","score":13.436851,"text":"\n}\n\n\n\n\n\n\n\n Deleting a resource record \n\n\n\n Request \n\ncurl -X DELETE $DNSSVCS_ENDPOINT\/v1\/instances\/$INSTANCE_ID\/dnszones\/$DNSZONE_ID\/resource_records\/$RECORD_ID -H \"Authorization: $TOKEN\"\n\n\n\n\n\n Response \n\nHTTP 204 is returned, no content in response.\n\n\n\n\n\n\n\n Importing bulk resource records from a DNS zone file \n\n\n\n Request \n\ncurl -X POST $DNSSVCS_ENDPOINT\/v1\/instances\/$INSTANCE_ID\/dnszones\/$DNSZONE_ID\/import_resource_records --form \"file=@.\/bind.cfg\" -H \"Authorization: $TOKEN\"\n\n\n\n\n\n Response \n\n{\n\"total_records_parsed\": 17,\n\"records_added\": 17,\n\"records_failed\": 0,\n\"records_added_by_type\": {\n\"A\": 10,\n\"AAAA\": 2,\n\"CNAME\": 4,\n\"SRV\": 0,\n\"TXT\": 0,\n\"MX\": 0,\n\"PTR\": 1\n},\n\"records_failed_by_type\": {\n\"A\": 0,\n\"AAAA\": 0,\n\"CNAME\": 0,\n\"SRV\": 0,\n\"TXT\": 0,\n\"MX\": 0,\n\"PTR\": 0\n},\n\"message\": null,\n\"errors\": null\n}\n\n\n\n\n\n\n\n Exporting bulk resource records to a DNS zone file \n\n\n\n Request \n\ncurl -X GET $DNSSVCS_ENDPOINT\/v1\/instances\/$INSTANCE_ID\/dnszones\/$DNSZONE_ID\/export_resource_records -o dns_records.cfg -H \"Authorization: $TOKEN\"\n\n\n\n\n\n Response \n\nHTTP 200 is returned with zone file content in byte format\n\n\n\n\n\n\n\n\n\n Using the CLI \n\nFirst use the ibmcloud dns instance-target command to set the target operating DNS Services instance.\n\n$ ibmcloud dns instances","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dns-svcs?topic=dns-svcs-managing-dns-records"},{"document_id":"ibmcld_04171-7-2143","score":13.296724,"text":"\nKnown limitations \n\nThe following information describes some limitations when working with IBM Cloud\u00ae Internet Services (CIS), as well as some suggested courses of action to improve your experience.\n\n\n\n* It is recommended that you use Chrome.\n* The free trial plan is limited to one instance per account. After you create a resource instance and add a domain to it, you are not allowed to add new resource instances for CIS. This restriction is enforced even if you delete a trial domain and then attempt to add a domain again to the same resource instance. You'll encounter an error if you attempt to do so.\n* For this service, we support subdomain delegation only using NS records from another provider. CNAME delegation is not supported.\n* A, AAAA, and CNAME wildcard records (\"*\") cannot be proxied.\n* When you delete a dedicated certificate, it might reappear in the list for a short time before the deletion is complete.\n* To modify your custom dedicated certificate\u2019s hostnames after ordering, you must order a new certificate and then delete the old one.\n* IP rules created with two letter country codes can only be made with the Challenge action. If you want to block visitors from a country, upgrade to the Enterprise plan or place rules on your server to fully block.\n\n\n\n\n\n Global load balancer \n\n\n\n* Cloud Internet Services allows you to use the character _ in load balancer hostnames. However, Kubernetes clusters cannot use _.\n* The Standard plan permits a maximum of 5 load balancers, pools, and health checks. Each pool can have a total of 6 origins, but only 6 unique origins are permitted throughout each CIS instance.\n* Health check events for deleted pools and origins cannot be filtered, but they still appear in the table.\n* If you filter Health check events by Pool Health, Degraded pools are included because they technically are healthy, but might contain 1 or more critical origins.\n* When adding the request header name for a health check, use Host, capitalized. Using a lower-case host for a health check fails.\n\n\n\n\n\n\n\n DNS \n\n\n\n* Exporting DNS records includes Cloudflare CNAME records that should be hidden.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-known-limitations"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04149-3050-4970","score":15.999285,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04149-1398-3431","score":13.552408,"text":"\nSet up your DNS records (optional).\n4. Configure your DNS information with the name servers provided.\n5. Continue getting started with CIS by following a tutorial, or by setting up other features.\n\n\n\n\n\n Step 1: Open the IBM CIS application \n\nOpen the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog). Then, select the Networking category in the navigation pane. Click the Internet Services tile to open the IBM Cloud Internet Services application.\n\n\n\n The Overview screen \n\nAfter the CIS application starts up, you'll see the CIS Overview screen, and you'll find the tabs for Security, Reliability, and Performance.\n\n\n\n\n\n Which plan do I choose? \n\nThere are several plans to choose from:\n\n\n\n* Enterprise Usage\n* Enterprise Package\n* Enterprise GLB\n* Enterprise Security\n* Standard (Deprecated as of 30 April 2023)\n* Standard Next (Replaces deprecated Standard plan)\n* No-cost Trial\n\n\n\nThe No-cost Trial expires after 30 days, at which point you can upgrade to a plan that best suits your needs. A single Standard or Standard Next instance can manage one domain. You can create as many Standard or Standard Next service instances as you want within a single account, each managing a single domain. The Enterprise Plans allow you to manage multiple domains in a single service instance.\n\nBefore creating a Standard plan, remember that this plan is deprecated and will eventually reach end-of-support.\n\nSelect Create on the Overview screen to begin provisioning your account.\n\nThe No-cost Trial is limited to one instance per account.\n\n\n\n\n\n Begin provisioning \n\nYou'll see the first screen of the CIS application, where you select Add Domain to begin.\n\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04186-9163-11063","score":13.450923,"text":"\n* [Configure the Ingress for the DNS subdomain](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cismulti-region-k8s-cis-ingress)\n\n\n\n\n\n\n\n Step 3: Configure multi-location load-balancing \n\nYour application is now running in two clusters but it is missing one component for the users to access either clusters transparently from a single entry point.\n\nIn this section, you will configure IBM Cloud Internet Services (CIS) to distribute the load between the two clusters. CIS is a one stop-shop service providing Global Load Balancer (GLB), Caching, Web Application Firewall (WAF) and Page rule to secure your applications while ensuring the reliability and performance for your Cloud applications.\n\nTo configure a global load balancer, you will need:\n\n\n\n* to point a custom domain to CIS name servers,\n* to retrieve the Ingress Subdomain of the Kubernetes clusters,\n* to configure health checks to validate the availability of your application,\n* and to define origin pools pointing to the clusters.\n\n\n\n\n\n Register a custom domain with IBM Cloud Internet Services \n\nThe first step is to create an instance of CIS and to point your custom domain to CIS name servers.\n\n\n\n1. If you do not own a domain, you can buy one from a registrar.\n2. Navigate to [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) in the IBM Cloud catalog.\n3. Set the service name, and click Create to create an instance of the service.\n4. When the service instance is provisioned, click on Add domain.\n5. Enter your domain name and click Next.\n6. Setup your DNS records is an optional step and can be skipped for this tutorial. click on Next\n7. When the name servers are assigned, configure your registrar or domain name provider to use the name servers listed.\n8. After you've configured your registrar or the DNS provider, it may require up to 24 hours for the changes to take effect.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cis"},{"document_id":"ibmcld_04148-0-1895","score":13.400158,"text":"\n\n\n\n\n\n\n  Getting CIS running with a new subdomain \n\nFollow these steps to practice using CIS with a subdomain or CNAME. This example uses the GoDaddy domain registrar. Your case might be different, depending on which registrar you use.\n\n\n\n1.  Deploy a CIS instance by using the IBM Cloud console or API.\n\nIt is recommended that you mirror the name of your CIS instance with the domain or subdomain.\n2.  Click Let\u2019s get started.\n3.  Enter the subdomain in the Domain name field and click Connect and continue.\n4.  For new subdomains click Next Step, for existing subdomains click Import records.\n5.  Make note the New NS records for entry into the GoDaddy DNS Management system.\n6.  Log in to GoDaddy domain Registrar.\n7.  Navigate to the DNS Management page for the candidate CIS domain. IBM Cloud\u00ae must be updated through the API.\n8.  Click ADD to create an NS Host record for each name server entry provided from CIS.\n9.  Set up a DNS record with the supplied CIS NS Records\n\n\n\n*  Type Nameserver\n*  Host subdomain (the name of the subdomain, for example, subdomain.example.com)\n*  Points to ns004.name.cloud.ibm.com\n*  TTL \u00bd hour\n\n\n\n10. The DNS Management page now reflects the two new NS records for the subdomain.\n11. Go back to the IBM Cloud Internet Services instance.\n12. After the NS Records are DNS propagated, it is reflected in the DNS tools, and you are ready to proceed.\n13. With completed NS propagation, click Check name servers.\n14. CIS starts checking NS configuration for the subdomain and might be in a Pending State.\n\nAny typographical errors in can produce a \"silent\" failure. If your subdomain is in the pending state for more than 30 minutes, you might have an error.\n\n\n\nUpon successful subdomain name server and NS record confirmation, the CIS instance reports Active. Customers are now ready to start configuring the service and routing traffic to their services.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-get-started-new-subdomain"},{"document_id":"ibmcld_05351-8341-9984","score":13.322096,"text":"\nName your load balancer. Note that this name appears in your custom domain URL. For example, if your custom domain is global-app.example.com and you name your load balancer global-app, your URL is global-app.example.com.\n2. Set Traffic steering to Geo.\n3. Add your Geo routes. You can choose to create a route for all CIS regions or only some regions.\n\n\n\n* If you create a route for all CIS regions, then in each route that you create, add all the origin pools that you created earlier. Sort them so that a region that contains your running app and is closest to the region route that you are configuring. For example, if you created apps in au-syd, eu-de, and br-sao, then for Oceana, put au-syd first. For Eastern and Western Europe, put de-eu first. And for North and South America, put br-sao first.\n* If you create a route for only some CIS regions, add a route for the Default region. This route is the fallback to use when a specified region is not available.\n\n\n\n4. Click Create to create the load balancer.\n\n\n\n\n\n\n\n\n\n Step 8: Verify that your app is available \n\nOpen a browser and enter your load balancer name plus your custom domain name; for example, www.global-app.example.com\n\nNow your applications are highly available.\n\n\n\n\n\n Step 9: Cleaning up your tutorial \n\n\n\n1. Delete the global load balancers and origin pools from CIS.\n2. Delete your DNS records from CIS. For more information, see [Deleting DNS records](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cisdeleting-dns-records).\n3. Delete each project that you created. When you delete a project, all the components contained in that project are also deleted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-deploy-multiple-regions"},{"document_id":"ibmcld_04195-6086-8151","score":13.317915,"text":"\nBecause CIS doesn't support email traffic by default, you must set the PTR record to the location of your email server. Contact your email provider for assistance.\n\n\n\n\n\n\n\n Updating DNS records \n\nIn each record row, you can click the Edit record option from the menu, which opens a dialog box that you can use to update the record.\n\nAfter you are finished making your changes, select Update record to save them, or Cancel to abort the changes.\n\n\n\n\n\n Deleting DNS records \n\nIn each record row, you can select the Delete record option from the menu, which opens a dialog box to confirm the delete process.\n\nYou can select the Delete button to confirm your delete action. Select Cancel if you don't want to delete.\n\n\n\n\n\n Importing and exporting DNS records \n\nDNS records can be imported into and exported from CIS. All files are imported and exported as .txt files in BIND format. Learn more about [BIND format](https:\/\/en.wikipedia.org\/wiki\/Zone_file). Click the overflow menu and select to import or export records.\n\nImport records - By default, a total of 3500 DNS records are allowed (imported and created on CIS). You can import multiple files, one at a time, as long as the total number of records is under the max limit. After importing, you are shown a summary with the number of records successfully added and the number that failed, along with the reason why each record failed.\n\nExport records - Use Export records to create a backup of your zone file, or export it to use with another DNS provider. When this menu option is clicked, the records are downloaded to the location specified by your browser settings (typically the Downloads folder). To select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cis"},{"document_id":"ibmcld_01391-9188-11098","score":13.275102,"text":"\n* [Configure the Ingress for the DNS subdomain](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cismulti-region-k8s-cis-ingress)\n\n\n\n\n\n\n\n Step 3: Configure multi-location load-balancing \n\nYour application is now running in two clusters but it is missing one component for the users to access either clusters transparently from a single entry point.\n\nIn this section, you will configure IBM Cloud Internet Services (CIS) to distribute the load between the two clusters. CIS is a one stop-shop service providing Global Load Balancer (GLB), Caching, Web Application Firewall (WAF) and Page rule to secure your applications while ensuring the reliability and performance for your Cloud applications.\n\nTo configure a global load balancer, you will need:\n\n\n\n* to point a custom domain to CIS name servers,\n* to retrieve the Ingress Subdomain of the Kubernetes clusters,\n* to configure health checks to validate the availability of your application,\n* and to define origin pools pointing to the clusters.\n\n\n\n\n\n Register a custom domain with IBM Cloud Internet Services \n\nThe first step is to create an instance of CIS and to point your custom domain to CIS name servers.\n\n\n\n1. If you do not own a domain, you can buy one from a registrar.\n2. Navigate to [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) in the IBM Cloud catalog.\n3. Set the service name, and click Create to create an instance of the service.\n4. When the service instance is provisioned, click on Add domain.\n5. Enter your domain name and click Next.\n6. Setup your DNS records is an optional step and can be skipped for this tutorial. click on Next\n7. When the name servers are assigned, configure your registrar or domain name provider to use the name servers listed.\n8. After you've configured your registrar or the DNS provider, it may require up to 24 hours for the changes to take effect.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"},{"document_id":"ibmcld_13234-11167-13184","score":12.974155,"text":"\nCIS provides Global Load Balancer (GLB), Caching, Web Application Firewall (WAF) and Page rule to secure your applications while ensuring the reliability and performance for your cloud applications.\n\nTo configure a global load balancer, you will need:\n\n\n\n* to point a custom domain to CIS name servers,\n* to retrieve the IP addresses or hostnames of the VPC load balancers,\n* to configure health checks to validate the availability of your application,\n* and to define origin pools pointing to the VPC load balancers.\n\n\n\n\n\n Add a custom domain to IBM Cloud Internet Services \n\nThe first step is to create an instance of CIS and to point your custom domain to CIS name servers.\n\n\n\n1. If you do not own a domain, you can buy one from a registrar.\n2. Navigate to [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) in the IBM Cloud catalog.\n3. Set the service name, and click Create to create an instance of the service.\n4. When the service instance is provisioned, click on Add domain.\n5. Enter your domain name and click Next.\n6. Setup your DNS records is an optional step and can be skipped for this tutorial. click on Next.\n7. When the name servers are assigned, configure your registrar or domain name provider to use the name servers listed.\n8. At this point you can click on Cancel to get back to the main page, after you've configured your registrar or the DNS provider, it may require up to 24 hours for the changes to take effect.\n\nWhen the domain's status on the Overview page changes from Pending to Active, you can use the dig <your_domain_name> ns command to verify that the new name servers have taken effect.\n\n\n\n\n\n\n\n Configure Health Check for the Global Load Balancer \n\nA health check helps gain insight into the availability of pools so that traffic can be routed to the healthy ones. These checks periodically send HTTP\/HTTPS requests and monitor the responses.\n\n\n\n1. In the IBM Cloud Internet Services dashboard, navigate to Reliability > Global Load Balancers.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-multi-region"},{"document_id":"ibmcld_16079-11208-13225","score":12.974155,"text":"\nCIS provides Global Load Balancer (GLB), Caching, Web Application Firewall (WAF) and Page rule to secure your applications while ensuring the reliability and performance for your cloud applications.\n\nTo configure a global load balancer, you will need:\n\n\n\n* to point a custom domain to CIS name servers,\n* to retrieve the IP addresses or hostnames of the VPC load balancers,\n* to configure health checks to validate the availability of your application,\n* and to define origin pools pointing to the VPC load balancers.\n\n\n\n\n\n Add a custom domain to IBM Cloud Internet Services \n\nThe first step is to create an instance of CIS and to point your custom domain to CIS name servers.\n\n\n\n1. If you do not own a domain, you can buy one from a registrar.\n2. Navigate to [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) in the IBM Cloud catalog.\n3. Set the service name, and click Create to create an instance of the service.\n4. When the service instance is provisioned, click on Add domain.\n5. Enter your domain name and click Next.\n6. Setup your DNS records is an optional step and can be skipped for this tutorial. click on Next.\n7. When the name servers are assigned, configure your registrar or domain name provider to use the name servers listed.\n8. At this point you can click on Cancel to get back to the main page, after you've configured your registrar or the DNS provider, it may require up to 24 hours for the changes to take effect.\n\nWhen the domain's status on the Overview page changes from Pending to Active, you can use the dig <your_domain_name> ns command to verify that the new name servers have taken effect.\n\n\n\n\n\n\n\n Configure Health Check for the Global Load Balancer \n\nA health check helps gain insight into the availability of pools so that traffic can be routed to the healthy ones. These checks periodically send HTTP\/HTTPS requests and monitor the responses.\n\n\n\n1. In the IBM Cloud Internet Services dashboard, navigate to Reliability > Global Load Balancers.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-multi-region"},{"document_id":"ibmcld_05351-9684-10230","score":12.9254,"text":"\nDelete your DNS records from CIS. For more information, see [Deleting DNS records](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-set-up-your-dns-for-cisdeleting-dns-records).\n3. Delete each project that you created. When you delete a project, all the components contained in that project are also deleted. For more information, see [Delete a project](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-manage-projectdelete-project).\n\n\n\nNote that your custom domain is not deleted, but is no longer associated with the application that you created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-deploy-multiple-regions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08001-3949-5750","score":11.804564,"text":"\nThe following table summarizes the fully qualified domain names (FQDNs) used by the three layers:\n\n\n\n Host description Example FQDN DNS How Protected \n\n Range application hostname (user application hostname) www.application.example.com Managed by CIS, no explicit record CIS Layer 3\/4 \n GLB hostname <uuid>-example.com Managed by CIS, no explicit record, public network Obfuscated, BIG-IP Virtual Server accepts only the Range Application Host Header \n BIG-IP hostname f5-app.example.com A record maps to public external IP of BIG-IP, public network Security Group to [only allow traffic from CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-allowlisted-ip-addresses) \n Red Hat OpenShift on IBM Cloud application hostname (not externalized) application-internal.example.com CNAME record maps to private-router ALB, private network Only accessible within network and protected by BIG-IP firewall. Security group restricts traffic to accept traffic only from BIG-IP. \n\n\n\n\n\n\n\n Before you begin \n\nThe following items are needed to deploy and configure the reference architecture with CIS and BIG-IP to create a WAF:\n\n\n\n* [Provisioned and licensed BIG-IP](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-f5-tutorial)\n* Registered domain for CIS\n* Certificate for your registered domain (can be a wildcard certificate)\n* Intermediate certificate for your server-side application\n\n\n\n\n\n\n\n Step 1: Provision CIS \n\n\n\n1. Provision an instance of [CIS](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) that uses the Enterprise Usage plan.\n2. Click Create to provision the service.\n\n\n\n\n\n\n\n Step 2: Configure CIS TLS Mode \n\n\n\n1. [Register your domain name with CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-domain-support).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-waf-tutorial"},{"document_id":"ibmcld_04107-7548-9466","score":10.592308,"text":"\nThese attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address. This allows CIS to ingest, single-pass inspect, and re-encrypt data before sending it to the origin server destination. CIS can also act in DNS-only mode, returning the actual DNS record without obfuscating the IP, which disables DDoS and the other functions of CIS. To enable CIS protections, switch the \"proxy\" slider next to each DNS record to on; to disable protections, switch to off.\n\n\n\n\n\n Unlimited DDoS mitigation \n\nDDoS mitigation is typically an expensive service that can grow in cost when under attack. Unlimited DDoS mitigation is included with CIS at no additional cost.\n\n\n\n\n\n Mitigate Layer 7 attacks (configuration) \n\nThough DDoS is enabled by default in CIS, you can further configure Layer 7 security by:\n\n\n\n* Configuring WAF ruleset sensitivity and response behavior\n* Adding rate limiting\n* Adding firewall rules\n\n\n\nUse these features to customize Layer 7 mitigation of both volumetric and non-volumetric attacks.\n\n\n\n\n\n Mitigate non volumetric attacks \n\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04122-7-1660","score":10.477945,"text":"\nSetting Transport Layer Security (TLS) options \n\nThe Transport Layer Security (TLS) options let you control whether visitors can browse your website over a secure connection, and when they do, how IBM Cloud\u00ae Internet Services connects to your origin server.\n\nUse the latest version of the TLS protocol (TLS 1.3) for improved security and performance by switching from Off to On.\n\n\n\n TLS encryption modes \n\nSet the TLS mode by selecting one of the following options from the Mode list.\n\nThese options are listed in the order from the least secure (Off) to the most secure (End-to-End CA signed).\n\n\n\n* [Off](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-off) (not recommended)\n* [Client-to-Edge](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-client-to-edge) (edge to origin not encrypted, self-signed certificates are not supported)\n* [End-to-End flexible](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-flexible) (edge to origin certificates can be self-signed)\n* [End-to-End CA signed](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-ca-signed) (default and recommended)\n* [HTTPS only origin pull](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-origin-only-pull) (Enterprise only)\n\n\n\n\n\n Off \n\nNo secure connection between your visitor and CIS, and no secure connection between CIS and your web server. Visitors can only view your website over HTTP, and any visitor attempting to connect using HTTPS receives an HTTP 301 Redirect to the plain HTTP version of your website.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-options"},{"document_id":"ibmcld_04136-1771-3582","score":10.4100275,"text":"\nAn attacker can use one or multiple attack vectors, and might even cycle through these attack vectors based on countermeasures taken by the target.\n\nCommon types are:\n\n\n\n* Application layer attacks (Layer 7)\n* Protocol attacks (Layer 3 and Layer 4)\n* Volumetric attacks (amplification attacks)\n\n\n\n\n\n Application layer attacks \n\nAn application layer attack is sometimes referred to as a Layer-7 DDoS attack (in reference to the 7th layer of the OSI model). The goal of these attacks is to exhaust the resources of the victim, by targeting the layer where web pages are generated on the server and delivered to the visitors in response to HTTP requests (that is, the application layer). Layer-7 attacks are challenging, because the traffic can be difficult to identify as malicious.\n\n\n\n\n\n Protocol attacks \n\nProtocol attacks utilize weaknesses in Layer 3 and Layer 4 of the ISO protocol stack to render the target inaccessible. These attacks, also known as a state-exhaustion attacks, cause a service disruption by consuming all the available state table capacity of web application servers, or of intermediate resources such as firewalls and load balancers.\n\n\n\n\n\n Volumetric attacks \n\nThis category of attacks attempts to create congestion by consuming all available bandwidth between the target and the wider internet. Large amounts of data are sent to a target using a form of amplification, or by other means of creating massive traffic, such as requests from a botnet.\n\n\n\n\n\n\n\n What do I do if I\u2019m under a DDoS attack? \n\nStep 1: Turn on \u201cDefense mode\" from the Overview screen.\n\nStep 2: Set your DNS records for maximum security.\n\nStep 3: Do not rate-limit or throttle requests from IBM CIS, we need the bandwidth to assist you with your situation.\n\nStep 4: Block specific countries and visitors if necessary.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-distributed-denial-of-service-ddos-attack-concepts"},{"document_id":"ibmcld_04184-7-1931","score":9.875464,"text":"\nUsing mutual TLS \n\nMutual Transport Layer Security (mTLS) authentication ensures that traffic is both secure and trusted in both directions between a client and server. It is only available for customers at the Enterprise or Security plan level.\n\nWhen mTLS is configured, access is granted only to requests with a corresponding client certificate. When a request reaches the application, CIS responds with a request for the client certificate. If the client fails to present the certificate, the request is not allowed to proceed. Otherwise, the key exchange proceeds.\n\nZoom\n\n![Diagram of mTLS handshake](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/images\/mtls-handshake.png)\n\nFigure 1. Diagram of an mTLS handshake\n\n\n\n Configuring mutual TLS \n\nMutual TLS is not enabled by default. It is an additional service that requires prior authorization and enablement.\n\nTo obtain authorization, you must submit an IBM Support case.\n\nAfter mTLS is turned on for your account, take the following steps to enable it.\n\n\n\n1. Navigate to the Security page in the CIS UI.\n2. Select the Mutual TLS tab.\n3. Click Enable to enable the feature.\n\n\n\nAfter mTLS is enabled, it cannot be disabled.\n\nTo set up mTLS authentication in the IBM Cloud Internet Services UI for a particular endpoint:\n\n\n\n1. In the Root certificates table, click Add to define a new root certificate.\n2. Paste the certificate content into the content field, provide a name for the Root CA, and add one or more fully qualified domain names (FQDN) of the endpoints that you want to use this certificate. These FQDNs are the hostnames that are used for the resources being protected by the application policy. You must associate the Root CA with the FQDN that the application being protected uses.\n3. Click Save.\n\nIf your zone is using an intermediate certificate in addition to the root certificate, upload the entire chain.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mtls-features"},{"document_id":"ibmcld_15141-7808-9997","score":9.424831,"text":"\nTransport layer protocols act as liaisons between the application layer protocols and the services that are provided by the network. Client VPN for VPC supports the following protocols:\n\nUDP is recommended for optimal performance; TCP for reliability.\n\n\n\n* User Datagram Protocol (UDP)\n\nThe User Datagram Protocol (UDP) is a simple, lightweight protocol with minimum overhead. If a process wants to send a small message and doesn't care about reliability, it can use UDP. Sending a message by using UDP takes much less time than using TCP. It performs little error checking and does not add any advantages to IP services except to provide process-to-process communication instead of host-to-host communication.\n* Transmission Control Protocol (TCP)\n\nTransmission Control Protocol (TCP) is a reliable but complex transport-layer protocol. TCP adds connection-oriented features and reliability to IP services.\n\nTCP is a stream delivery service that guarantees delivery of data streams sent from one host to another without duplication or lost data. Since packet transfer is not reliable, a technique known as positive acknowledgment with retransmission is used to guarantee reliability of packet transfers. This fundamental technique requires the receiver to respond with an acknowledgment message as it receives the data.\n\nThe sender keeps a record of each packet it sends, and waits for acknowledgment before sending the next packet. The sender also keeps a timer from when the packet was sent, and retransmits a packet if the timer expires. This timer is needed in case a packet becomes lost or corrupted.\n\n\n\n\n\n\n\n Full versus split-tunnel mode \n\nWhen a VPN connection is set up, an encrypted tunnel is created over the internet to the VPN server. The VPN connection appears as a virtual network interface to the computer in addition to the existing LAN interface. You can now use both interfaces simultaneously by sending the private traffic destined to the VPC inside the VPN tunnel and the public traffic (internet traffic) over the other interface (outside the VPN tunnel). When the traffic is split between the VPN interface and other interfaces, split tunneling is said to be in use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-client-to-site-vpn-planning"},{"document_id":"ibmcld_04149-3050-4970","score":9.3957,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_08001-2578-4399","score":9.31779,"text":"\n[IBM Cloud Network path from client application through CIS and BIG-IP to provider's Red Hat OpenShift on IBM Cloud application](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9ac5c38b41e0aa1cb4ccc6cc7f547751ec805221\/framework-financial-services\/vpc\/images\/f5-bigip\/cis-flow.svg)\n\nFigure 2. Network path from client application to Red Hat OpenShift on IBM Cloud application passing through CIS and BIG-IP.\n\nThe network flow goes through the following steps:\n\n\n\n1. Client applications connect to a CIS Range application through a public hostname that is exposed by CIS. This connection is treated as a TCP connection (not an HTTPS connection) by CIS and passes through CIS without TLS termination. The Range application provides DDoS protection.\n2. A CIS global load balancer routes traffic to the WAF provided by BIG-IP instances. The global load balancer has a public hostname, but it is not advertised for use.\n3. The first TLS termination occurs in BIG-IP running in IBM Cloud. BIG-IP treats the connection as an HTTPS connection. The application's public certificate is used by BIG-IP for TLS termination.\n4. Network traffic is reencrypted between BIG-IP and the application. The Red Hat OpenShift on IBM Cloud ingress controller is configured for pass through so that it does not terminate the TLS connection. The final TLS termination is done by the application.\n\n\n\nThe following table summarizes the fully qualified domain names (FQDNs) used by the three layers:\n\n\n\n Host description Example FQDN DNS How Protected \n\n Range application hostname (user application hostname) www.application.example.com Managed by CIS, no explicit record CIS Layer 3\/4 \n GLB hostname <uuid>-example.com Managed by CIS, no explicit record, public network Obfuscated, BIG-IP Virtual Server accepts only the Range Application Host Header","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-waf-tutorial"},{"document_id":"ibmcld_04149-1398-3431","score":9.291588,"text":"\nSet up your DNS records (optional).\n4. Configure your DNS information with the name servers provided.\n5. Continue getting started with CIS by following a tutorial, or by setting up other features.\n\n\n\n\n\n Step 1: Open the IBM CIS application \n\nOpen the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog). Then, select the Networking category in the navigation pane. Click the Internet Services tile to open the IBM Cloud Internet Services application.\n\n\n\n The Overview screen \n\nAfter the CIS application starts up, you'll see the CIS Overview screen, and you'll find the tabs for Security, Reliability, and Performance.\n\n\n\n\n\n Which plan do I choose? \n\nThere are several plans to choose from:\n\n\n\n* Enterprise Usage\n* Enterprise Package\n* Enterprise GLB\n* Enterprise Security\n* Standard (Deprecated as of 30 April 2023)\n* Standard Next (Replaces deprecated Standard plan)\n* No-cost Trial\n\n\n\nThe No-cost Trial expires after 30 days, at which point you can upgrade to a plan that best suits your needs. A single Standard or Standard Next instance can manage one domain. You can create as many Standard or Standard Next service instances as you want within a single account, each managing a single domain. The Enterprise Plans allow you to manage multiple domains in a single service instance.\n\nBefore creating a Standard plan, remember that this plan is deprecated and will eventually reach end-of-support.\n\nSelect Create on the Overview screen to begin provisioning your account.\n\nThe No-cost Trial is limited to one instance per account.\n\n\n\n\n\n Begin provisioning \n\nYou'll see the first screen of the CIS application, where you select Add Domain to begin.\n\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04214-1728-3555","score":9.225914,"text":"\nMigration to Standard Next plans \n\nTo migrate from your current Standard plan to a Standard Next plan, take the following steps.\n\n\n\n1. Enter your existing CIS instance\n2. Navigate to the Plan page in left side panel\n3. Select Standard Next plan\n4. Check the box to acknowledge the terms and conditions\n5. Click Create and follow any prompts that might block this plan change\n\n\n\n\n\n\n\n\n\n Transitioning to Enterprise Tier plans \n\nStarting 31 August 2023, the current CIS Enterprise Package, Enterprise GLB, and Enterprise Security plans will no longer be available for new instances. Any instance that is created on or after this date will use the new Enterprise Tier plans.\n\nBy moving to a more metered model, the base cost of the Enterprise Tier plans are smaller than the original Enterprise plans. The following table shows what features are available in the Enterprise Tier plans.\n\n\n\nTable 2. Comparison of CIS Enterprise Tier plans\n\n Features Enterprise Essential Enterprise Advanced Enterprise Premier \n\n Included domains 1 2 2 \n Included DNS records 3500 3500 3500 \n Protected traffic included (DDoS, CDN, DNS, WAF, GLB) 5 TB 5 TB 5 TB \n Requests included (CDN, WAF, GLB) in millions 150 150 150 \n Custom uploaded certificates 25 25 25 \n GLB: Origins, pools, GLB included 20 20 20 \n Range (Layer 3\/4) No Yes Yes \n Advanced rate limiting No Yes Yes \n Advanced WAF No Yes Yes \n Bot management No No Yes \n\n\n\n\n\n Migration to Enterprise Tiers plans \n\nTo migrate from your current Enterprise Package, Enterprise GLB, and Enterprise Security plans, take the following steps.\n\n\n\n1. Enter your existing CIS instance\n2. Navigate to the Plan page in left side panel\n3. Select desired Enterprise Tier plan\n4. Check the box to acknowledge the terms and conditions\n5. Click Create and follow any prompts that might block this plan change","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transition-plans"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.5437713092,"ndcg_cut_10":0.5437713092}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04107-7548-9466","score":14.552969,"text":"\nThese attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address. This allows CIS to ingest, single-pass inspect, and re-encrypt data before sending it to the origin server destination. CIS can also act in DNS-only mode, returning the actual DNS record without obfuscating the IP, which disables DDoS and the other functions of CIS. To enable CIS protections, switch the \"proxy\" slider next to each DNS record to on; to disable protections, switch to off.\n\n\n\n\n\n Unlimited DDoS mitigation \n\nDDoS mitigation is typically an expensive service that can grow in cost when under attack. Unlimited DDoS mitigation is included with CIS at no additional cost.\n\n\n\n\n\n Mitigate Layer 7 attacks (configuration) \n\nThough DDoS is enabled by default in CIS, you can further configure Layer 7 security by:\n\n\n\n* Configuring WAF ruleset sensitivity and response behavior\n* Adding rate limiting\n* Adding firewall rules\n\n\n\nUse these features to customize Layer 7 mitigation of both volumetric and non-volumetric attacks.\n\n\n\n\n\n Mitigate non volumetric attacks \n\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_08001-3949-5750","score":14.208602,"text":"\nThe following table summarizes the fully qualified domain names (FQDNs) used by the three layers:\n\n\n\n Host description Example FQDN DNS How Protected \n\n Range application hostname (user application hostname) www.application.example.com Managed by CIS, no explicit record CIS Layer 3\/4 \n GLB hostname <uuid>-example.com Managed by CIS, no explicit record, public network Obfuscated, BIG-IP Virtual Server accepts only the Range Application Host Header \n BIG-IP hostname f5-app.example.com A record maps to public external IP of BIG-IP, public network Security Group to [only allow traffic from CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-allowlisted-ip-addresses) \n Red Hat OpenShift on IBM Cloud application hostname (not externalized) application-internal.example.com CNAME record maps to private-router ALB, private network Only accessible within network and protected by BIG-IP firewall. Security group restricts traffic to accept traffic only from BIG-IP. \n\n\n\n\n\n\n\n Before you begin \n\nThe following items are needed to deploy and configure the reference architecture with CIS and BIG-IP to create a WAF:\n\n\n\n* [Provisioned and licensed BIG-IP](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-f5-tutorial)\n* Registered domain for CIS\n* Certificate for your registered domain (can be a wildcard certificate)\n* Intermediate certificate for your server-side application\n\n\n\n\n\n\n\n Step 1: Provision CIS \n\n\n\n1. Provision an instance of [CIS](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) that uses the Enterprise Usage plan.\n2. Click Create to provision the service.\n\n\n\n\n\n\n\n Step 2: Configure CIS TLS Mode \n\n\n\n1. [Register your domain name with CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-domain-support).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-waf-tutorial"},{"document_id":"ibmcld_04149-3050-4970","score":13.581171,"text":"\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https:\/\/whois.icann.org\/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04183-0-2205","score":13.503291,"text":"\n\n\n\n\n\n\n  Securing your data in CIS \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Internet Services, it is important to know exactly what data is stored and encrypted and how to delete any stored personal data.\n\n\n\n  How your data is stored and encrypted in CIS \n\nCIS interacts with Cloudflare services using a channel that is fully encrypted end-to-end using Transport Layer Security (TLS) 1.2. CIS does not store any customer data. Configuration data about your specific CIS configuration is encrypted in transit and at rest. CIS configuration data is deleted on your request through the UI, CLI, or API.\n\n\n\n\n\n  Protecting your sensitive data in CIS \n\nAll data related to CIS configuration is not considered sensitive data. The configuration data is encrypted at rest. No customer-managed keys are managed by the CIS offering. Therefore, neither Key Protect nor Hyper Protect Crypto Services are used.\n\n\n\n  Working with customer-managed keys for CIS \n\nNo customer-managed keys are managed by the CIS offering.\n\n\n\n\n\n\n\n  Deleting your data in CIS \n\nThe CIS configuration data is deleted on request through the UI, CLI or API.\n\n\n\n  Deleting CIS instances \n\nThe CIS data retention policy describes how long your data is stored after you delete the service. The data retention policy is included in the CIS service description, which you can find in [IBM Cloud Terms](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-terms). When a CIS instance is deleted by the UI, CLI, or API, the instance data is retained for seven days from deletion.\n\nBefore deleting an instance, all the domains in the instance must be removed.\n\nDeleting the CIS instance removes all data.\n\n\n\n\n\n  Restoring deleted data for CIS \n\nCIS can currently restore the deleted instance. After you delete an instance of CIS, you can restore the deleted service instance within the data retention period of seven days. After the seven-day period expires, the service instance is permanently deleted.\n\nTo view which service instances are available for restoration, use the ibmcloud resource reclamations command. To restore a deleted service instance, use the ibmcloud resource reclamation-restore command.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data"},{"document_id":"ibmcld_04122-7-1660","score":13.169107,"text":"\nSetting Transport Layer Security (TLS) options \n\nThe Transport Layer Security (TLS) options let you control whether visitors can browse your website over a secure connection, and when they do, how IBM Cloud\u00ae Internet Services connects to your origin server.\n\nUse the latest version of the TLS protocol (TLS 1.3) for improved security and performance by switching from Off to On.\n\n\n\n TLS encryption modes \n\nSet the TLS mode by selecting one of the following options from the Mode list.\n\nThese options are listed in the order from the least secure (Off) to the most secure (End-to-End CA signed).\n\n\n\n* [Off](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-off) (not recommended)\n* [Client-to-Edge](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-client-to-edge) (edge to origin not encrypted, self-signed certificates are not supported)\n* [End-to-End flexible](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-flexible) (edge to origin certificates can be self-signed)\n* [End-to-End CA signed](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-ca-signed) (default and recommended)\n* [HTTPS only origin pull](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-origin-only-pull) (Enterprise only)\n\n\n\n\n\n Off \n\nNo secure connection between your visitor and CIS, and no secure connection between CIS and your web server. Visitors can only view your website over HTTP, and any visitor attempting to connect using HTTPS receives an HTTP 301 Redirect to the plain HTTP version of your website.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-options"},{"document_id":"ibmcld_04184-7-1931","score":13.053284,"text":"\nUsing mutual TLS \n\nMutual Transport Layer Security (mTLS) authentication ensures that traffic is both secure and trusted in both directions between a client and server. It is only available for customers at the Enterprise or Security plan level.\n\nWhen mTLS is configured, access is granted only to requests with a corresponding client certificate. When a request reaches the application, CIS responds with a request for the client certificate. If the client fails to present the certificate, the request is not allowed to proceed. Otherwise, the key exchange proceeds.\n\nZoom\n\n![Diagram of mTLS handshake](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/images\/mtls-handshake.png)\n\nFigure 1. Diagram of an mTLS handshake\n\n\n\n Configuring mutual TLS \n\nMutual TLS is not enabled by default. It is an additional service that requires prior authorization and enablement.\n\nTo obtain authorization, you must submit an IBM Support case.\n\nAfter mTLS is turned on for your account, take the following steps to enable it.\n\n\n\n1. Navigate to the Security page in the CIS UI.\n2. Select the Mutual TLS tab.\n3. Click Enable to enable the feature.\n\n\n\nAfter mTLS is enabled, it cannot be disabled.\n\nTo set up mTLS authentication in the IBM Cloud Internet Services UI for a particular endpoint:\n\n\n\n1. In the Root certificates table, click Add to define a new root certificate.\n2. Paste the certificate content into the content field, provide a name for the Root CA, and add one or more fully qualified domain names (FQDN) of the endpoints that you want to use this certificate. These FQDNs are the hostnames that are used for the resources being protected by the application policy. You must associate the Root CA with the FQDN that the application being protected uses.\n3. Click Save.\n\nIf your zone is using an intermediate certificate in addition to the root certificate, upload the entire chain.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mtls-features"},{"document_id":"ibmcld_08001-2578-4399","score":12.617488,"text":"\n[IBM Cloud Network path from client application through CIS and BIG-IP to provider's Red Hat OpenShift on IBM Cloud application](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9ac5c38b41e0aa1cb4ccc6cc7f547751ec805221\/framework-financial-services\/vpc\/images\/f5-bigip\/cis-flow.svg)\n\nFigure 2. Network path from client application to Red Hat OpenShift on IBM Cloud application passing through CIS and BIG-IP.\n\nThe network flow goes through the following steps:\n\n\n\n1. Client applications connect to a CIS Range application through a public hostname that is exposed by CIS. This connection is treated as a TCP connection (not an HTTPS connection) by CIS and passes through CIS without TLS termination. The Range application provides DDoS protection.\n2. A CIS global load balancer routes traffic to the WAF provided by BIG-IP instances. The global load balancer has a public hostname, but it is not advertised for use.\n3. The first TLS termination occurs in BIG-IP running in IBM Cloud. BIG-IP treats the connection as an HTTPS connection. The application's public certificate is used by BIG-IP for TLS termination.\n4. Network traffic is reencrypted between BIG-IP and the application. The Red Hat OpenShift on IBM Cloud ingress controller is configured for pass through so that it does not terminate the TLS connection. The final TLS termination is done by the application.\n\n\n\nThe following table summarizes the fully qualified domain names (FQDNs) used by the three layers:\n\n\n\n Host description Example FQDN DNS How Protected \n\n Range application hostname (user application hostname) www.application.example.com Managed by CIS, no explicit record CIS Layer 3\/4 \n GLB hostname <uuid>-example.com Managed by CIS, no explicit record, public network Obfuscated, BIG-IP Virtual Server accepts only the Range Application Host Header","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-waf-tutorial"},{"document_id":"ibmcld_04137-1660-3678","score":12.135191,"text":"\nTo eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).\n\n\n\n\n\n Root record CNAME flattening \n\nIBM CIS supports a feature called \"CNAME Flattening.\" Using this method, root records can overcome the IETF RFC restriction that if a root record is a CNAME, it cannot have any other records for that domain. CIS Authoritative servers overcome this restriction by returning the A records corresponding to the CNAME target instead of returning the CNAME itself, effectively hiding the CNAME. This technique allows other records such as MX records to be added to the domain, even though the root record is a CNAME.\n\n\n\n\n\n Proxying DNS records and global load balancers \n\nIBM CIS supports proxying for global load balancers and DNS records. When a record or load balancer is proxied, it means that its traffic runs directly through CIS.\n\nCurrently, DNS records of type A, AAAA, or CNAME can be proxied.\n\n\n\n Setting proxy modes \n\nLoad balancers and DNS records support both DNS-only and HTTP proxy modes. You can have HTTP proxy and DNS-only domains in the same CIS instance, but the traffic routing behavior differs as follows:\n\n\n\n* Traffic for records that are proxied flows through CIS.\n* Traffic for records that are non-proxied (DNS-only mode) flows directly from the client to the origin.\n\n\n\n\n\n\n\n HTTP proxy mode \n\nIn HTTP proxy mode, CIS announces IBM IP addresses externally, but protects (mask) your origin server IP addresses. The announced IP address records have an automatic TTL.\n\nUsing HTTP proxy mode offers the following benefits:\n\n\n\n* Traffic flows through CIS where all the security, performance, and reliability features such as firewall rules, caching, and so on, are applied.\n* The \"automatic\" TTL (five minutes) reduces the number of authoritative queries made against CIS.\n\n\n\n\n\n\n\n DNS-only mode \n\nIn DNS-only mode, records are resolved to the origin IP and you can customize the TTL for your records.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-dns-concepts"},{"document_id":"ibmcld_04214-1728-3555","score":12.023479,"text":"\nMigration to Standard Next plans \n\nTo migrate from your current Standard plan to a Standard Next plan, take the following steps.\n\n\n\n1. Enter your existing CIS instance\n2. Navigate to the Plan page in left side panel\n3. Select Standard Next plan\n4. Check the box to acknowledge the terms and conditions\n5. Click Create and follow any prompts that might block this plan change\n\n\n\n\n\n\n\n\n\n Transitioning to Enterprise Tier plans \n\nStarting 31 August 2023, the current CIS Enterprise Package, Enterprise GLB, and Enterprise Security plans will no longer be available for new instances. Any instance that is created on or after this date will use the new Enterprise Tier plans.\n\nBy moving to a more metered model, the base cost of the Enterprise Tier plans are smaller than the original Enterprise plans. The following table shows what features are available in the Enterprise Tier plans.\n\n\n\nTable 2. Comparison of CIS Enterprise Tier plans\n\n Features Enterprise Essential Enterprise Advanced Enterprise Premier \n\n Included domains 1 2 2 \n Included DNS records 3500 3500 3500 \n Protected traffic included (DDoS, CDN, DNS, WAF, GLB) 5 TB 5 TB 5 TB \n Requests included (CDN, WAF, GLB) in millions 150 150 150 \n Custom uploaded certificates 25 25 25 \n GLB: Origins, pools, GLB included 20 20 20 \n Range (Layer 3\/4) No Yes Yes \n Advanced rate limiting No Yes Yes \n Advanced WAF No Yes Yes \n Bot management No No Yes \n\n\n\n\n\n Migration to Enterprise Tiers plans \n\nTo migrate from your current Enterprise Package, Enterprise GLB, and Enterprise Security plans, take the following steps.\n\n\n\n1. Enter your existing CIS instance\n2. Navigate to the Plan page in left side panel\n3. Select desired Enterprise Tier plan\n4. Check the box to acknowledge the terms and conditions\n5. Click Create and follow any prompts that might block this plan change","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transition-plans"},{"document_id":"ibmcld_04107-7-1956","score":11.893071,"text":"\nAbout IBM Cloud Internet Services \n\nIBM Cloud\u00ae Internet Services, powered by Cloudflare, provides a fast, highly performant, reliable, and secure internet service for customers running their business on IBM Cloud.\n\nIBM CIS gets you started quickly by establishing defaults for you, which you can change easily by using the UI or API.\n\n\n\n Clock synchronization \n\nISO 27001 requires that clocks of all relevant information processing systems within an organization or security domain must be synchronized with a single reference time source. CIS synchronizes the systems with a Network Time Protocol (NTP) server to ensure that all time-based activities occur synchronously everywhere on the network.\n\nIBM CIS uses the following internal NTP servers:\n\n\n\n* time.adn.networklayer.com\/\n* time.service.networklayer.com\n\n\n\n\n\n\n\n Security features \n\nProxy your [DNS records](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-dns-conceptsdns-concepts-proxying-dns-records) or a [global load balancer](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-global-load-balancer-glb-concepts) to use the security features. The proxy allows traffic to flow through our servers and you can monitor the data.\n\nZoom\n\n![security graphic](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/images\/security-graphic.png)\n\nFigure 1. Security features\n\n\n\n TLS \n\nProtect your site and control your Transport Layer Security (TLS) settings. Manage the certificates used to secure traffic to your site.\n\n\n\n\n\n Origin \n\nManage the TLS certificates that encrypt traffic between your origin server and your users.\n\n\n\n\n\n Rate limiting \n\nUse rate limiting rules to protect your site or API from malicious traffic by blocking client IP addresses that match a URL pattern or exceed a defined threshold.\n\n\n\n\n\n Traffic scrubbing \n\nCIS offers 192 Tbps of global network edge capacity and can mitigate DDoS attacks that have extremely high packet and HTTP request rates.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04107-7548-9466","score":14.93267,"text":"\nThese attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address. This allows CIS to ingest, single-pass inspect, and re-encrypt data before sending it to the origin server destination. CIS can also act in DNS-only mode, returning the actual DNS record without obfuscating the IP, which disables DDoS and the other functions of CIS. To enable CIS protections, switch the \"proxy\" slider next to each DNS record to on; to disable protections, switch to off.\n\n\n\n\n\n Unlimited DDoS mitigation \n\nDDoS mitigation is typically an expensive service that can grow in cost when under attack. Unlimited DDoS mitigation is included with CIS at no additional cost.\n\n\n\n\n\n Mitigate Layer 7 attacks (configuration) \n\nThough DDoS is enabled by default in CIS, you can further configure Layer 7 security by:\n\n\n\n* Configuring WAF ruleset sensitivity and response behavior\n* Adding rate limiting\n* Adding firewall rules\n\n\n\nUse these features to customize Layer 7 mitigation of both volumetric and non-volumetric attacks.\n\n\n\n\n\n Mitigate non volumetric attacks \n\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04122-7-1660","score":14.223286,"text":"\nSetting Transport Layer Security (TLS) options \n\nThe Transport Layer Security (TLS) options let you control whether visitors can browse your website over a secure connection, and when they do, how IBM Cloud\u00ae Internet Services connects to your origin server.\n\nUse the latest version of the TLS protocol (TLS 1.3) for improved security and performance by switching from Off to On.\n\n\n\n TLS encryption modes \n\nSet the TLS mode by selecting one of the following options from the Mode list.\n\nThese options are listed in the order from the least secure (Off) to the most secure (End-to-End CA signed).\n\n\n\n* [Off](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-off) (not recommended)\n* [Client-to-Edge](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-client-to-edge) (edge to origin not encrypted, self-signed certificates are not supported)\n* [End-to-End flexible](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-flexible) (edge to origin certificates can be self-signed)\n* [End-to-End CA signed](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-ca-signed) (default and recommended)\n* [HTTPS only origin pull](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-optionstls-encryption-modes-origin-only-pull) (Enterprise only)\n\n\n\n\n\n Off \n\nNo secure connection between your visitor and CIS, and no secure connection between CIS and your web server. Visitors can only view your website over HTTP, and any visitor attempting to connect using HTTPS receives an HTTP 301 Redirect to the plain HTTP version of your website.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-tls-options"},{"document_id":"ibmcld_04184-7-1931","score":13.798382,"text":"\nUsing mutual TLS \n\nMutual Transport Layer Security (mTLS) authentication ensures that traffic is both secure and trusted in both directions between a client and server. It is only available for customers at the Enterprise or Security plan level.\n\nWhen mTLS is configured, access is granted only to requests with a corresponding client certificate. When a request reaches the application, CIS responds with a request for the client certificate. If the client fails to present the certificate, the request is not allowed to proceed. Otherwise, the key exchange proceeds.\n\nZoom\n\n![Diagram of mTLS handshake](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/images\/mtls-handshake.png)\n\nFigure 1. Diagram of an mTLS handshake\n\n\n\n Configuring mutual TLS \n\nMutual TLS is not enabled by default. It is an additional service that requires prior authorization and enablement.\n\nTo obtain authorization, you must submit an IBM Support case.\n\nAfter mTLS is turned on for your account, take the following steps to enable it.\n\n\n\n1. Navigate to the Security page in the CIS UI.\n2. Select the Mutual TLS tab.\n3. Click Enable to enable the feature.\n\n\n\nAfter mTLS is enabled, it cannot be disabled.\n\nTo set up mTLS authentication in the IBM Cloud Internet Services UI for a particular endpoint:\n\n\n\n1. In the Root certificates table, click Add to define a new root certificate.\n2. Paste the certificate content into the content field, provide a name for the Root CA, and add one or more fully qualified domain names (FQDN) of the endpoints that you want to use this certificate. These FQDNs are the hostnames that are used for the resources being protected by the application policy. You must associate the Root CA with the FQDN that the application being protected uses.\n3. Click Save.\n\nIf your zone is using an intermediate certificate in addition to the root certificate, upload the entire chain.\n4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mtls-features"},{"document_id":"ibmcld_08001-3949-5750","score":13.726195,"text":"\nThe following table summarizes the fully qualified domain names (FQDNs) used by the three layers:\n\n\n\n Host description Example FQDN DNS How Protected \n\n Range application hostname (user application hostname) www.application.example.com Managed by CIS, no explicit record CIS Layer 3\/4 \n GLB hostname <uuid>-example.com Managed by CIS, no explicit record, public network Obfuscated, BIG-IP Virtual Server accepts only the Range Application Host Header \n BIG-IP hostname f5-app.example.com A record maps to public external IP of BIG-IP, public network Security Group to [only allow traffic from CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-allowlisted-ip-addresses) \n Red Hat OpenShift on IBM Cloud application hostname (not externalized) application-internal.example.com CNAME record maps to private-router ALB, private network Only accessible within network and protected by BIG-IP firewall. Security group restricts traffic to accept traffic only from BIG-IP. \n\n\n\n\n\n\n\n Before you begin \n\nThe following items are needed to deploy and configure the reference architecture with CIS and BIG-IP to create a WAF:\n\n\n\n* [Provisioned and licensed BIG-IP](https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-f5-tutorial)\n* Registered domain for CIS\n* Certificate for your registered domain (can be a wildcard certificate)\n* Intermediate certificate for your server-side application\n\n\n\n\n\n\n\n Step 1: Provision CIS \n\n\n\n1. Provision an instance of [CIS](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) that uses the Enterprise Usage plan.\n2. Click Create to provision the service.\n\n\n\n\n\n\n\n Step 2: Configure CIS TLS Mode \n\n\n\n1. [Register your domain name with CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-domain-support).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-waf-tutorial"},{"document_id":"ibmcld_04107-7-1956","score":13.23806,"text":"\nAbout IBM Cloud Internet Services \n\nIBM Cloud\u00ae Internet Services, powered by Cloudflare, provides a fast, highly performant, reliable, and secure internet service for customers running their business on IBM Cloud.\n\nIBM CIS gets you started quickly by establishing defaults for you, which you can change easily by using the UI or API.\n\n\n\n Clock synchronization \n\nISO 27001 requires that clocks of all relevant information processing systems within an organization or security domain must be synchronized with a single reference time source. CIS synchronizes the systems with a Network Time Protocol (NTP) server to ensure that all time-based activities occur synchronously everywhere on the network.\n\nIBM CIS uses the following internal NTP servers:\n\n\n\n* time.adn.networklayer.com\/\n* time.service.networklayer.com\n\n\n\n\n\n\n\n Security features \n\nProxy your [DNS records](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-dns-conceptsdns-concepts-proxying-dns-records) or a [global load balancer](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-global-load-balancer-glb-concepts) to use the security features. The proxy allows traffic to flow through our servers and you can monitor the data.\n\nZoom\n\n![security graphic](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/images\/security-graphic.png)\n\nFigure 1. Security features\n\n\n\n TLS \n\nProtect your site and control your Transport Layer Security (TLS) settings. Manage the certificates used to secure traffic to your site.\n\n\n\n\n\n Origin \n\nManage the TLS certificates that encrypt traffic between your origin server and your users.\n\n\n\n\n\n Rate limiting \n\nUse rate limiting rules to protect your site or API from malicious traffic by blocking client IP addresses that match a URL pattern or exceed a defined threshold.\n\n\n\n\n\n Traffic scrubbing \n\nCIS offers 192 Tbps of global network edge capacity and can mitigate DDoS attacks that have extremely high packet and HTTP request rates.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04179-7-1888","score":13.096528,"text":"\nManaging CIS for optimal security \n\nThe IBM Cloud\u00ae Internet Services (CIS) security settings include safe defaults designed to avoid false positives and negative influence on your traffic. However, these safe default settings do not provide the best security posture for every customer. Take the following steps to be sure that your CIS account is configured in a safe and secure way.\n\nRecommendations and best practices:\n\n\n\n* Secure your origin IP addresses by proxying and increasing obfuscation\n* Configure your security level selectively\n* Activate your Web Application Firewall (WAF) safely\n\n\n\n\n\n Best practice 1: Secure your origin IP addresses \n\nWhen a subdomain is proxied using CIS, all traffic is protected because we actively respond with IP addresses specific to CIS (for example, all of your clients connect to CIS proxies first, and your origin IP addresses are obscured).\n\n\n\n Use CIS proxies for all DNS records for HTTP(S) traffic from your origin \n\nTo improve the security of your origin IP address, you should proxy all HTTP(S) traffic.\n\nSee the difference yourself - Query a non-proxied and a proxied record:\n\ndig nonproxied.theburritobot.com +short\n1.2.3.4 (The origin IP address)\n\n$ dig proxied.theburritobot.com +short\n104.16.22.6 , 104.16.23.6 (CIS IP addresses)\n\n\n\n\n\n Obscure non-proxied origin records with non-standard names \n\nAny records that cannot be proxied through CIS, and that still use your origin IP, such as FTP, can be secured by creating additional obfuscation. In particular, if you require a record for your origin that cannot be proxied by CIS, use a non-standard name. For example, instead of ftp.example.com use [random word or-random characters].example.com. This obfuscation makes dictionary scans of your DNS records less likely to expose your origin IP addresses.\n\n\n\n\n\n Use separate IP ranges for HTTP and non-HTTP traffic if possible","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-security"},{"document_id":"ibmcld_04179-1360-3455","score":12.783028,"text":"\nAny records that cannot be proxied through CIS, and that still use your origin IP, such as FTP, can be secured by creating additional obfuscation. In particular, if you require a record for your origin that cannot be proxied by CIS, use a non-standard name. For example, instead of ftp.example.com use [random word or-random characters].example.com. This obfuscation makes dictionary scans of your DNS records less likely to expose your origin IP addresses.\n\n\n\n\n\n Use separate IP ranges for HTTP and non-HTTP traffic if possible \n\nSome customers use separate IP ranges for HTTP and non-HTTP traffic, thereby allowing them to proxy all records pointing to their HTTP IP range, and to obscure all non-HTTP traffic with a different IP subnet.\n\n\n\n\n\n\n\n Best practice 2: Configure your security level selectively \n\nYour Security Level establishes the sensitivity of our IP Reputation Database. To prevent negative interactions or false positives, configure your Security Level by domain to heighten security where necessary, and to decrease it where appropriate.\n\n\n\n Increase the security level for sensitive areas to 'High' \n\nYou can increase this setting from the Advanced Security page for your domain or by adding a Page Rule for administration pages or login pages, to reduce brute-force attempts:\n\n\n\n1. Create a Page Rule with the URL pattern of your API (for example, www.example.com\/wp-login).\n2. Identify the Security Level setting.\n3. Mark the setting as High.\n4. Select Provision Resource.\n\n\n\n\n\n\n\n Decrease the security level for non-sensitive paths or APIs to reduce false positives \n\nThis setting can be decreased for general pages and API traffic:\n\n\n\n1. Create a Page Rule with the URL pattern of your API (for example, www.example.com\/api\/).\n2. Identify the Security Level setting.\n3. Turn Security Level to Low or Essentially off.\n4. Select Provision Resource.\n\n\n\n\n\n\n\n What do security level settings mean? \n\nOur security level settings are aligned with threat scores that certain IP addresses acquire from malicious behavior on our network. A threat score above 10 is considered high.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-security"},{"document_id":"ibmcld_16729-186060-188072","score":12.505964,"text":"\nThis tutorial highlights how Cloud Internet Services (CIS), a uniform platform to configure and manage the Domain Name System (DNS), Global Load Balancing (GLB), Web Application Firewall (WAF), and protection against Distributed Denial of Service (DDoS) for internet applications, can be integrated with Kubernetes clusters to support this scenario and to deliver a secure and resilient solution across multiple locations.\n\nKubernetes service Container Registry\n\n+1\n\nCloud Internet Services (CIS)\n\n\n\n* 2 hours\n* 2023-05-10\n\n\n\n[Deploy isolated workloads across multiple locations and zones](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-multi-region)Deploy isolated workloads across multiple locations and zones\n\nThis tutorial walks you through steps for setting up highly available and isolated workloads by provisioning IBM Cloud\u00ae Virtual Private Clouds (VPCs). You will create virtual server instances (VSIs) in multiple zones within one region to ensure the high availability of the application. You will create additional VSIs in a second region and configure a global load balancer (GLB) to provide high availability between regions and reduce network latency for users in different geographies.\n\nVirtual Private Cloud (VPC) Cloud Internet Services (CIS)\n\n+1\n\nSecrets Manager\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Centralize communication through a VPC Transit Hub and Spoke architecture - Part one](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-transit1)Centralize communication through a VPC Transit Hub and Spoke architecture - Part one\n\nA Virtual Private Cloud (VPC) provides network isolation and security in the IBM Cloud. A VPC can be a building block that encapsulates a corporate division (marketing, development, accounting, ...) or a collection of microservices owned by a DevSecOps team. VPCs can be connected to an on-premises enterprise and each other. This may create the need to route traffic through centralized firewall-gateway appliances.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_04214-1728-3555","score":12.331545,"text":"\nMigration to Standard Next plans \n\nTo migrate from your current Standard plan to a Standard Next plan, take the following steps.\n\n\n\n1. Enter your existing CIS instance\n2. Navigate to the Plan page in left side panel\n3. Select Standard Next plan\n4. Check the box to acknowledge the terms and conditions\n5. Click Create and follow any prompts that might block this plan change\n\n\n\n\n\n\n\n\n\n Transitioning to Enterprise Tier plans \n\nStarting 31 August 2023, the current CIS Enterprise Package, Enterprise GLB, and Enterprise Security plans will no longer be available for new instances. Any instance that is created on or after this date will use the new Enterprise Tier plans.\n\nBy moving to a more metered model, the base cost of the Enterprise Tier plans are smaller than the original Enterprise plans. The following table shows what features are available in the Enterprise Tier plans.\n\n\n\nTable 2. Comparison of CIS Enterprise Tier plans\n\n Features Enterprise Essential Enterprise Advanced Enterprise Premier \n\n Included domains 1 2 2 \n Included DNS records 3500 3500 3500 \n Protected traffic included (DDoS, CDN, DNS, WAF, GLB) 5 TB 5 TB 5 TB \n Requests included (CDN, WAF, GLB) in millions 150 150 150 \n Custom uploaded certificates 25 25 25 \n GLB: Origins, pools, GLB included 20 20 20 \n Range (Layer 3\/4) No Yes Yes \n Advanced rate limiting No Yes Yes \n Advanced WAF No Yes Yes \n Bot management No No Yes \n\n\n\n\n\n Migration to Enterprise Tiers plans \n\nTo migrate from your current Enterprise Package, Enterprise GLB, and Enterprise Security plans, take the following steps.\n\n\n\n1. Enter your existing CIS instance\n2. Navigate to the Plan page in left side panel\n3. Select desired Enterprise Tier plan\n4. Check the box to acknowledge the terms and conditions\n5. Click Create and follow any prompts that might block this plan change","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transition-plans"},{"document_id":"ibmcld_08001-2578-4399","score":12.326724,"text":"\n[IBM Cloud Network path from client application through CIS and BIG-IP to provider's Red Hat OpenShift on IBM Cloud application](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9ac5c38b41e0aa1cb4ccc6cc7f547751ec805221\/framework-financial-services\/vpc\/images\/f5-bigip\/cis-flow.svg)\n\nFigure 2. Network path from client application to Red Hat OpenShift on IBM Cloud application passing through CIS and BIG-IP.\n\nThe network flow goes through the following steps:\n\n\n\n1. Client applications connect to a CIS Range application through a public hostname that is exposed by CIS. This connection is treated as a TCP connection (not an HTTPS connection) by CIS and passes through CIS without TLS termination. The Range application provides DDoS protection.\n2. A CIS global load balancer routes traffic to the WAF provided by BIG-IP instances. The global load balancer has a public hostname, but it is not advertised for use.\n3. The first TLS termination occurs in BIG-IP running in IBM Cloud. BIG-IP treats the connection as an HTTPS connection. The application's public certificate is used by BIG-IP for TLS termination.\n4. Network traffic is reencrypted between BIG-IP and the application. The Red Hat OpenShift on IBM Cloud ingress controller is configured for pass through so that it does not terminate the TLS connection. The final TLS termination is done by the application.\n\n\n\nThe following table summarizes the fully qualified domain names (FQDNs) used by the three layers:\n\n\n\n Host description Example FQDN DNS How Protected \n\n Range application hostname (user application hostname) www.application.example.com Managed by CIS, no explicit record CIS Layer 3\/4 \n GLB hostname <uuid>-example.com Managed by CIS, no explicit record, public network Obfuscated, BIG-IP Virtual Server accepts only the Range Application Host Header","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-waf-tutorial"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.530721274,"ndcg_cut_10":0.530721274}}
{"task_id":"f3a917e029970190be5ee508ba770d7f<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04119-1639-3490","score":16.681086,"text":"\nIn general, firewall rules are designed for properties exposed in OSI Layer 7 (HTTP), such as request headers and body content characteristics.\n\n\n\n\n\n Adding an application using the console \n\nFollow these steps to add an application using the UI.\n\nIn the console, UDP applications must be enabled through a Support case. After the functionality is enabled, you can create a UDP application through the CLI or API.\n\n\n\n1. Navigate to Security > Range.\n2. Click Create.\n3. Select a type of application from the list menu. You can choose TCP, UDP, HTTP, HTTPS, RDP, SSH, or Minecraft.\n4. Enter the application name. Your application becomes associated with a DNS name on your CIS domain.\n5. Enter the edge port. CIS listens for incoming connections to these addresses on this port. Connections to these addresses are proxied to your origin. You can enter a port range (for example: 8080-8090), but the origin must have the same quantity of ports specified in a consecutive range.\n6. Select the edge IP connectivity.\n7. In the Origin section, enter the origin IP and port of your TCP application. You can also select an existing load balancer and its port.\n8. Enable IP firewall (optional). When enabled, firewall rules with a \"block\" or \"allowlist\" action are enforced for this application.\n9. Enable edge TLS termination (optional). When enabled, select the type of TLS termination you want to use from the list menu.\n10. Select a [PROXY Protocol](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-enable-proxy-protocol) if you have a proxy in-line that supports PROXY Protocol (optional). This feature is useful if you are running a service that requires knowledge of the true client IP. In most cases, this setting remains off.\n11. Click Create.\n\n\n\nProvisioning a Range application incurs additional costs, based on the amount of bandwidth used per application.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-range"},{"document_id":"ibmcld_04109-7-2036","score":16.131062,"text":"\nAssigning firewall rule actions \n\nFirewall rule actions tell CIS how to respond to requests that match the criteria you define.\n\nFor lightweight firewall rules, navigate to Security > IP firewall, which contains IP rules, User Agent rules, and Domain Lockdown rules. Firewall rules are based on IP address, IP address range, Autonomous System Number (ASN), or country\/region.\n\nDomain lockdown rules specify a list of IP addresses, CIDR ranges, or networks that can access a domain, subdomain, or URL. Anything not on the list is blocked.\n\nFor more robust firewall rules, navigate to Security > Firewall rules, where you can create rules that examine incoming HTTP traffic against a set of filters to block, challenge, log, or allow matching requests.\n\nThe following table describes the actions that you can assign to your rules. The priority column shows what precedence the action receives. If a request matches two different rules that have the same priority, precedence determines the action to take.\n\n\n\nTable 1. Firewall rule actions and priority\n\n Action Available in Description Priority \n\n Log <br><br> * Firewall rules<br><br><br> Logs matching requests on the CIS edge for access with Enterprise Logpush and Logpull. Recommended for testing rule effectiveness you commit to a more severe action. Available to Enterprise customers only. 1 \n Bypass <br><br> * Firewall rules<br><br><br> Allows dynamic disabling of security features for a request. Exempts matching requests from evaluation, based on a user-defined list that contains one or more of the following features: Browser Integrity Check, Domain Lockdown, Hotlink Protection, Rate Limiting, Security Level, User Agent Block, WAF Managed Rules. Matching requests are still subject to evaluation within Firewall Rules, based on order of execution. 2 \n Allow <br><br> * Firewall rules<br> * IP firewall<br><br><br> Allows matching requests to access the site, on condition that no other CIS firewall features block the request, such as IP firewall or access rules. 3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-actions"},{"document_id":"ibmcld_04107-4464-6614","score":15.451976,"text":"\n* Specific URLs - For example, you can allow IP 1.2.3.4 access to directory example.com\/foo\/ and allow IP 5.6.7.8 access to directory example.com\/bar\/, but not allow the reverse.\n\n\n\nThis capability is useful when you need more granularity in your access rules because, with IP rules, you can either apply the block to all subdomains of the current domain, or all domains on your account. You cannot specify URIs.\n\n\n\n\n\n\n\n Firewall rules \n\nCreate rules that examine incoming HTTP traffic against a set of filters to block, challenge, log, or allow matching requests.\n\nIn general, firewall rules are designed for properties that are exposed in OSI Layer-7 (HTTP), such as request headers and body content characteristics. Therefore, firewall rules apply to HTTP\/HTTPS [Range](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-range) apps.\n\n\n\n\n\n Events \n\nView events that are triggered by an active web application firewall rule. For each event, you can change the triggered action based on the requesting IP address, or the requesting region as a whole.\n\n\n\n\n\n Range \n\nExtend the power of CIS DDoS, TLS, and IP firewall to your web servers and your TCP-based services by using Range applications, keeping them online and secure.\n\n\n\n\n\n Advanced security \n\nAdvanced security settings include the following features, which you can change, enable, or disable.\n\n\n\n* Browser integrity check - The browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks or challenges visitors that do not have a user agent, or who add a nonstandard user agent. This tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04107-1440-3475","score":15.426672,"text":"\nManage the certificates used to secure traffic to your site.\n\n\n\n\n\n Origin \n\nManage the TLS certificates that encrypt traffic between your origin server and your users.\n\n\n\n\n\n Rate limiting \n\nUse rate limiting rules to protect your site or API from malicious traffic by blocking client IP addresses that match a URL pattern or exceed a defined threshold.\n\n\n\n\n\n Traffic scrubbing \n\nCIS offers 192 Tbps of global network edge capacity and can mitigate DDoS attacks that have extremely high packet and HTTP request rates.\n\nWhen a DDoS attack occurs, CIS doesn't use scrubbing centers; the activity is analyzed on the edge, which helps to mitigate DDoS attacks closest to the source.\n\nTraffic that is identified as being \"dirty\" or part of an attack is not included in the billing. Customers are being billed for protected traffic, which consists of clean traffic that is forwarded to the origin and responses that are returned from the edge to the client.\n\n\n\n\n\n Web Application Firewall (WAF) \n\nWAF is implemented through two rule sets: [OWASP](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-settingsowasp-rule-set-for-waf) and [CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-settingscis-ruleset-for-waf).\n\n\n\n\n\n IP firewall \n\nIBM Cloud Internet Services offers several tools for controlling your traffic so that you protect your domains, URLs, and directories against volumes of traffic, certain groups of requesters, and particular requesting IPs.\n\n\n\n IP rules \n\nWith IP rules you can control access for specific IP addresses, IP ranges, specific countries, specific ASNs, and certain CIDR blocks. Available actions on incoming requests are:\n\n\n\n* Allowlist\n* Block\n* Challenge (Captcha)\n* JavaScript challenge (Defense mode)\n\n\n\nFor example, if you notice that a particular IP is causing malicious requests, you can block that user by IP address.\n\nIP rules apply to TCP, HTTP, and HTTPS [Range](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-range) apps, because IP rules are applied to Open System Interconnection (OSI) Layer 3 and Layer 4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04334-69790-71255","score":15.269821,"text":"\nibmcloud cis firewall-update e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdowns -d 31984fea73a15b45779fa0df4ef62f9b --json '{\"urls\": [\"api.mysite.com\/some\/endpoint\"], \"configurations\": [{\"target\": \"ip\", \"value\": \"127.0.0.1\"}, {\"target\": \"ip_range\", \"value\": \"2.2.2.0\/24\"}]}' -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis firewalls \n\nList firewall rules.\n\nibmcloud cis firewalls (-t, --type Type) [-d, --domain DNS_DOMAIN_ID] [--page PAGE] [--per-page PER_PAGE ] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\n-t, --type\n: Type of firewall rule to create. Valid values: access-rules, ua-rules, lockdowns. Required.\n\n\n\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n--page\n: Page number of paginated results. The default value is 0.\n\n--per-page\n: Maximum number of access rules per page. The minimum value is 5. The default value is 20.\n\n-i, --instance\n: Instance name or ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-60165-61821","score":15.241479,"text":"\nibmcloud cis firewall-create (-t, --type Type) (--json @JSON_FILE | JSON_STRING) [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE] [--output FORMAT]\n[Deprecated] ibmcloud cis firewall-create (-t, --type Type) (-s, --json-str JSON_STR | -j, --json-file JSON_FILE) [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\n-t, --type\n: Type of firewall rule to create. Valid values: access-rules, ua-rules, lockdowns. Required.\n\n\n\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n--json\n: The JSON file or JSON string used to describe a firewall rule. Required.\n\n\n\n* For --type access-rules: The JSON data describing a firewall access rule as follows.\n\n\n\n* Required fields are mode, configuration.\n\n\n\n* mode: The type of action to perform. Valid values: block, challenge, whitelist, js_challenge.\n* configuration: Target\/Value pair to use for this rule.\n\n\n\n* target: The request property to target. Valid values: ip, ip_range, asn, country.\n* value: The value for the selected target.\n\n\n\n* For ip the value is a valid ip address.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-73111-74523","score":15.038257,"text":"\nibmcloud cis firewall 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis firewall-delete \n\nDelete a firewall rule by ID.\n\nibmcloud cis firewall-delete FIREWALL_RULE_ID (-t, --type Type) [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nFIREWALL_RULE_ID\n: The ID of firewall rule. Required.\n\n-t, --type\n: Type of firewall rule to create. Valid values: access-rules, ua-rules, lockdowns. Required.\n\n\n\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nDelete a firewall rule.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-77636-79035","score":14.8321905,"text":"\nibmcloud cis firewall-rule-create DNS_DOMAIN_ID (--json @JSON_FILE | JSON_STRING) -i, --instance INSTANCE] --output FORMAT]\nDeprecated] ibmcloud cis firewall-rule-create DNS_DOMAIN_ID (-s, --json-str JSON_STR | -j, --json-file JSON_FILE) -i, --instance INSTANCE] --output FORMAT] ! !!!!!! ! ! ! ! !\n<-- <section \"id=\"section-create-a-firewall-rule-options\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.--expression: A filter expression. For example, ip.src eq 93.184.216.0.--action: The rule action to perform. Valid values: log, allow, challenge, js_challenge, block, bypass.--priority: The rule's priority. Valid values: 0 2147483647. Value 0 means to set to the default value.--description: To briefly describe the rule.--paused: Indicates if the rule is active. Valid values: on, off. Default value is off.--products: The list of security products to be bypassed. Valid values: zoneLockdown, uaBlock, bic, hot, securityLevel, rateLimit, waf.--json: The JSON file or JSON string used to describe a firewall-rule.\n<-- <ul> -->\n\n* The required fields in JSON data are expression, action.\n\n<-- <ul> -->\n\n* expression: A filter expression. For example, ip.src eq 93.184.216.0\n* action: The rule action to perform. Valid values: log, allow, challenge, js_challenge, block, bypass.\n\n<-- <\/ul> -->\n\n* The optional fields are description, priority, paused, products.\n\n<-- <ul> -->","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04334-65500-67175","score":14.818422,"text":"\n[Deprecated] ibmcloud cis firewall-update FIREWALL_RULE_ID (-t, --type Type) (-s, --json-str JSON_STR | -j, --json-file JSON_FILE) [-d, --domain DNS_DOMAIN_ID] [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\n\n\n* FIREWALL_RULE_ID: The ID of firewall rule. Required.\n\n\n\n-t, --type\n: Type of firewall rule to create. Valid values: access-rules, ua-rules, lockdowns. Required.\n\n\n\n* access-rules: Access Rules are a way to allow, challenge, or block requests to your website. You can apply access rules to one domain only or all domains in the same service instance.\n* ua-rules: Perform access control when matching the exact UserAgent reported by the client. The access control mechanisms can be defined within a rule to help manage traffic from particular clients. This enables you to customize the access to your site.\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n--json\n: The JSON file or JSON string used to describe a firewall rule. Required.\n\n\n\n* For --type access-rules: The JSON data describing a firewall access rule as follows.\n\n\n\n* Option fields are mode, notes.\n\n\n\n* mode: The type of action to perform. Valid values: block, challenge, whitelist, js_challenge.\n* notes: Some useful information about this rule to help identify the purpose of it.\n\n\n\n\n\n\n\nSample JSON data:\n\n{\n\"mode\": \"challenge\",\n\"notes\": \"This rule is added because of event X that occurred on date xyz\",\n}\n\n\n\n* For --type ua-rules: The JSON data describing a user-agent rule as follows.\n\n\n\n* Required fields are mode, configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04177-5203-6606","score":14.7731695,"text":"\n* Turn on WAF using the toggle on the Web Application Firewall page. When you toggle the rules on or off, the changes are applied immediately.\n* Enterprise only - The Rate limiting page allows you to configure rate limiting rules to avoid noisy-neighbor problems and ward off DDoS.\n* On the IP Firewall page, you can configure access rules based on IP, country code, or ASN. You can also configure rules to block user agents. The domain lockdown section of this page allows you to limit access to your domain to certain IP addresses.\n* You can review firewall-related events on the Events page.\n\n\n\n\n\n\n\n Certificates \n\nWhen you configure a domain, IBM CIS automatically deploys a universal certificate for that domain. Thus, you don't need to do anything to have certificate-based protection in that domain. If you want, you can upload your own self-managed certificate. You'll need a separate certificate for each domain, and you'll see an error message if the certificate you are uploading does not match your domain. You can also order custom certificates on this page.\n\nIf you want to upload your own certificate, you must ensure that you replace expiring certificates before they expire, otherwise your visitors might not be able to connect. Enterprise plan users can set up an expiration notice using the [Alerts feature](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-configuring-policies&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-cis-deployment"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10852-44214-45420","score":13.447434,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-2884-4620","score":13.268571,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12339-0-1594","score":12.940743,"text":"\n\n\n\n\n\n\n  Java \n\nAs a standard bearer for enterprise application development and the native application language for Android, Java is a key language to support for your IBM Cloud service.\n\n\n\n  Content \n\n\n\n  Methods \n\nMethod parameters MUST be encapsulated into an \u201coptions\u201d object that can be constructed with a \"Builder\".\n\n\n\n\n\n  Streaming \n\nThe SDK SHOULD accept parameters with potentially large memory requirements as InputStream values, to allow the value to be streamed to the service.\n\n\n\n\n\n\n\n  Style guidelines \n\nFor services that support both a traditional Java SDK and an Android SDK, the Java SDK SHOULD be designed to be Android compatible, to minimize duplication of code.\n\nYou should follow a coding style based on the [Google Java Style Guide](https:\/\/google.github.io\/styleguide\/javaguide.html).\n\nYou should use the standard [development tools](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools) for Java to check style and code coverage.\n\n\n\n\n\n  Documentation \n\nYour SDK is not useful if your audience cannot understand how to consume it in order to do the basic operations for your service. Your SDK needs to contain the following resources to help your users:\n\n\n\n*  README.md\n*  [Contributor guidelines](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentationsdk-contributor-docs)\n*  Code Samples\n*  [Service documentation](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentation)\n\n\n\n\n\n\n\n  Distribution \n\n\n\n  Package management \n\nOfficial SDK releases MUST be published in [Maven Central](https:\/\/search.maven.org\/).\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-java"},{"document_id":"ibmcld_10817-7-1802","score":12.733645,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-4213-5899","score":12.671836,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-7-1743","score":12.483938,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-6582-8092","score":12.478347,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-2964-4516","score":12.36158,"text":"\nThis can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you can get started:\n\n\n\n* API 27 or higher\n* Java 8.x\n* Android SDK Tools 26.1.1+\n* Android SDK Platform Tools 27.0.1+\n* Android Build Tools version 27.0.0+\n\n\n\n\n\n\n\n Installing the SDK \n\n\n\n1. Create an Android Studio project or open an existing project.\n2. Add the JitPack repository to your root build.gradle file.\n\nallprojects {\nrepositories {\n...\nmaven { url 'https:\/\/jitpack.io' }\n}\n}\n3. Find your application's build.gradle file. Note: Be sure to open the file for your app, not the project build.gradle file.\n\n\n\n1. Add the App ID client SDK to the dependencies section.\n\ndependencies {\ncompile group: 'com.github.ibm-cloud-security:appid-clientsdk-android:4.+'\n}\n2. In the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_02680-7-1762","score":11.943356,"text":"\nApp Configuration client SDK for Android \n\nApp Configuration service provides Android client SDK to integrate with your Android application that is written in Kotlin or Java programming language.\n\n\n\n Prerequisites \n\nFollowing are the prerequisites for using the App Configuration service SDK for Android:\n\n\n\n* Android API level 22 or later\n* [Android Studio](https:\/\/developer.android.com\/studio\/index.html)\n* [Gradle](https:\/\/gradle.org\/install)\n\n\n\n\n\n\n\n Integrating client SDK for Android app written in Kotlin \n\nApp Configuration service provides Android client SDK to integrate with your Android application. You can evaluate the values of your property and feature flag by integrating the SDK.\n\n\n\n1. Install the SDK by using either one of the options:\n\n\n\n* [Download](https:\/\/github.com\/IBM\/appconfiguration-android-client-sdk) and import the package to your Android studio project.\n* Get the package through Gradle by adding the:\n\n\n\n* Add App Configuration Android client SDK dependency to Project level build.gradle file.\n\nrepositories {\nmavenCentral()\n}\n* Add App Configuration Android client SDK dependency to Module level build.gradle file.\n\ndependencies {\nimplementation \"com.ibm.cloud:appconfiguration-android-sdk:0.3.1\"\n}\n\n\n\n\n\n2. Configure the AndroidManifest.xml file for internet permission.\n\n<uses-permission android:name=\"android.permission.INTERNET\"\/>\n3. Initialize the SDK.\n\nval appConfiguration = AppConfiguration.getInstance()\n\nappConfiguration.init( application,\n\"region\",\n\"guid\",\n\"apikey\")\n\n\/\/To start the configuration fetching operation, set the collectionId and environmentId in the following way.\nappConfiguration.setContext(\"collectionId\",\"environmentId\")\n\nWhere:\n\n\n\n* region - Region name where the service instance is created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android"},{"document_id":"ibmcld_02698-2493-3586","score":11.843666,"text":"\n[Android SDK](https:\/\/github.com\/IBM\/appconfiguration-android-client-sdk) <br>[Documentation](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android) <br>[JavaScript SDK](https:\/\/github.com\/IBM\/appconfiguration-js-client-sdk) <br>[Documentation](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-javascript) <br>[React SDK](https:\/\/github.com\/IBM\/appconfiguration-react-client-sdk) <br>[Documentation](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-react) \n Admin SDK Admin SDK is designed to perform App Configuration service instance management. Use this SDK to create and manage App Configuration resources like Collections, Environments, Feature flags, and Properties. [App Configuration Admin SDK for Go](https:\/\/cloud.ibm.com\/apidocs\/app-configuration?code=go) \n\n\n\nFor more information about installation and technical concepts, see the 'readme file' document in the SDK.\n\nYou can also access these documents and download the SDKs from the App Configuration console under SDKs on the navigation menu.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-sdks"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.6509209298,"ndcg_cut_10":0.6509209298}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":16.77677,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-7-1802","score":16.21726,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":14.901645,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_02772-4213-5899","score":14.782025,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_07551-14062-16080","score":14.559467,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_04518-1426-3052","score":13.90669,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-43319-44485","score":12.07157,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_12332-1034-2510","score":11.223394,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_06805-51238-53254","score":9.62276,"text":"\nIf both of them are provided, --git-token-path and --git-api-url take precedence.\n\nReturn values:\n\n\n\n* The command lists incident issue URLs found or created according to the result file and subject.\n* If no issues are found, or all found issues have either Exempt or Grace period set, the command exits with zero status.\n* If any of the issues that are found have no Exempt or Grace Period set, the command exits with a nonzero status.\n\n\n\nRunning the command:\n\n$ cocoa incident process --type va --subject us.icr.io\/service-image --drilldown-url us.icr.io\/service-image@sha256:digest path\/to\/scan-result.json\n\n\n\n\n\n cocoa incident process-legacy \n\nThis command creates incident issues in the provided repository for scenarios when a scan file isn't available. Typically, such scenarios would be non-vulnerability related failures like unit-test failure, branch protection failure, acceptance test failure, and image signing failure. These failures would be non-vulnerabilities, yet they would be a deviation from the compliance posture. If issues exist already for incident-subject-tool combinations, the command does not create new ones. By default, high severity rating is set to issues created.\n\nIf --set-due-date is set, the command either creates issues, or updates existing issues with due dates. The due dates are calculated from the grace period of the issue, based on the severity.\n\nIf --close-resolved-issues flag is set, the command searches for open issues with the same tool, subject and the incident ID as the current run. If there are any issues found, while the --current-status was passed as success, the command closes those issues.\n\nIf --read-only is set, the command does not create new issues or amend existing ones. Results are processed, and existing issues are collected for results. The output contains the issue URL list that are supposed to be tracked in issues if the read-only mode is not activated.\n\nUsage:\n\ncocoa incident process-legacy <options>\n\nOptions:\n\n--type (Required) Tool type","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cli"},{"document_id":"ibmcld_06805-52775-54523","score":9.374077,"text":"\nIf there are any issues found, while the --current-status was passed as success, the command closes those issues.\n\nIf --read-only is set, the command does not create new issues or amend existing ones. Results are processed, and existing issues are collected for results. The output contains the issue URL list that are supposed to be tracked in issues if the read-only mode is not activated.\n\nUsage:\n\ncocoa incident process-legacy <options>\n\nOptions:\n\n--type (Required) Tool type\n--subject (Required) Subject of scans (repo, or image name)\n--drilldown-url (Required) URL to the point where the incident was found (can be a pipeline run, a commit hash or an image URL with digest)\n--set-grace-period Should the created incidents have Grace period set\n--git-provider Git service provider [github] Default is \"github\"\n--org The incident issue repository org\n--repo The incident issue repository name\n--label Label(s) to add to the incident issue (optional) e.g: --label=foo --label=bar\n--assignee (Optional) Assignee(s) for the incident issue (github username) e.g: --assignee=jane-doe --assignee=john-smith\n--git-token-path (Optional) Github Token's path\n--git-api-url (Optional) Github API url\n--close-resolved-issues (Optional) Checking and closing resolved issues\n--pipeline-run-url (Optional) The url to the pipeline run running the CLI command\n--is-prod (Optional) Flag for whether or not the command was run in production environment. Default is false.\n--read-only (Optional) Process result file in read-only mode (return found and existing issues, do not create new ones, set processed status to failure or success). Default is false\n--custom-exempt-label (Optional) Defines the custom label with which the incident has been marked as exempted","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cli"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":18.797695,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-7-1802","score":18.276848,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-4213-5899","score":16.963284,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-7-1743","score":16.858707,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_04518-1426-3052","score":15.392857,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_07551-14062-16080","score":14.79844,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10852-43319-44485","score":13.70598,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_12332-1034-2510","score":10.85964,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_10817-2884-4620","score":9.008491,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-6582-8092","score":8.986569,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.9674679835,"ndcg_cut_10":0.9674679835}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":13.765188,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-7-1802","score":13.188176,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07551-14062-16080","score":12.744929,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_04518-7-1743","score":11.74827,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_02772-4213-5899","score":11.639114,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-1426-3052","score":10.799704,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10852-43319-44485","score":10.068125,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_12332-1034-2510","score":9.417378,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_09325-7-1732","score":5.930736,"text":"\nConfiguring the V2 Logging agent for Windows \n\nThe logging agent is responsible for collecting and forwarding logs to your IBM Log Analysis instance. After you provision an instance of IBM\u00ae Log Analysis, you must configure a logging agent for each log source that you want to monitor.\n\nTo configure your Windows server to send logs to your IBM Log Analysis instance, you must install the logdna-agent. The logging agent reads log files from a directory defined in your Windows system and forwards the log data to your logging instance.\n\n\n\n Install the Chocolately package manager \n\nYou need to install the Chocolately package manager to install the Windows agent.\n\nFrom a command prompt run:\n\npowershell -command \"Set-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https:\/\/chocolatey.org\/install.ps1'))\"\n\nor from PowerShell run:\n\nSet-ExecutionPolicy Bypass -Scope Process -Force; [System.Net.ServicePointManager]::SecurityProtocol = [System.Net.ServicePointManager]::SecurityProtocol -bor 3072; iex ((New-Object System.Net.WebClient).DownloadString('https:\/\/chocolatey.org\/install.ps1'))\n\n\n\n\n\n Installing the V2 Logging agent \n\nTo configure your Windows server to forward logs to your logging instance, run the following from a Windows command prompt as an admin user:\n\nchoco install logdna-agent -y\nlogdna-agent -k <INJESTION_KEY> this is your unique Ingestion Key\nlogdna-agent -s LOGDNA_APIHOST=api.us-south.logging.cloud.ibm.com this is your API server host\nlogdna-agent -s LOGDNA_LOGHOST=logs.us-south.logging.cloud.ibm.com this is your Log server host","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-config_agent_windows"},{"document_id":"ibmcld_06879-2703-3533","score":5.86231,"text":"\n* Using the [DevSecOps CLI](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-cli) to download your scan results from the evidence locker by using the information that is printed in the stage log. For more information, see the following resources:\n\n\n\n* [cocoa locker evidence get](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-clilocker-evidence-get)\n* [cocoa locker attachment get](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-clilocker-attachment-get)\n\n\n\n\n\n\n\n\n\n Related links \n\n\n\n* [Navigating to the web UI for IBM Cloud Security and Compliance Center Workload Protection](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-launch)\n* [Sysdig Secure documentation](https:\/\/cloud.ibm.com\/docs\/workload-protection?topic=workload-protection-sysdig_doc)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-sysdig-scan"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.932521092}}
{"task_id":"c01c8cf11437e6bb3bc93efac26528c2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-1342-3184","score":14.95223,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-1426-3052","score":13.047852,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_04518-7-1743","score":12.668605,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_07551-14062-16080","score":12.609975,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10817-7-1802","score":11.9570465,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12332-1034-2510","score":11.184238,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_10852-43319-44485","score":11.023194,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_07551-15747-17355","score":9.534424,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_10852-44214-45420","score":9.41461,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_02772-4213-5899","score":8.081472,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.9469024295,"ndcg_cut_10":0.9469024295}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04334-179782-181318","score":7.564679,"text":"\nThe OR operator is defined using a comma (,) or OR keyword surrounded by whitespace. The AND operator is defined using a semicolon (;) or AND keyword surrounded by whitespace. Comparison options are: ==, =, >, <, >=, <=. An example value for filters is: event==connect AND coloName=SFO.--sort: The sort order for the result set. Sort fields must be included in metrics or dimensions. An example value for sort is: +count,-bytesIngress.--since: Start of time interval to query, defaults to until - 6 hours. This should be an absolute timestamp that conforms to RFC 3339.--until: End of time interval to query, defaults to current time. This should be an absolute timestamp that conforms to RFC 3339.--bytime: Analytics data for range applications grouped by time interval.--time-delta: Used to select time series resolution. Valid values: year, quarter, month, week, day, hour, dekaminute, minute. Only valid when --bytime is given.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-get-analytics-range-app-options\" \"> --><-- <section \"id=\"section-get-analytics-range-app-examples\" \"> --> Examples Get analytics data for range applications in domain 31984fea73a15b45779fa0df4ef62f9b. ibmcloud cis range-analytics 31984fea73a15b45779fa0df4ef62f9b --metrics \"count,bytesIngress\" --dimensions \"event,appID\" --since \"2020-05-22T02:20:00Z\"\n--until \"2020-05-23T02:20:00Z\" -i \"cis-demo\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_02342-3424-4412","score":7.4592485,"text":"\nThe topic must end with the pattern .?.log, implying any single character between the periods . followed by the log string.\n\n{\n\"type\": \"access\",\n\"subjects\": [\n{\n\"attributes\":\n{\n\"name\": \"iam_id\",\n\"value\": \"IBMid-12345\"\n}\n]\n}\n],\n\"roles\": [\n{\n\"role_id\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\"\n}\n],\n\"resources\": [\n{\n\"attributes\":\n{\n\"name\": \"accountId\",\n\"value\": \"d727f71e99b14534b3267fab8cc9b09a\"\n},\n{\n\"name\": \"serviceName\",\n\"value\": \"messagehub\"\n},\n{\n\"name\": \"resourceType\",\n\"operator\": \"stringEquals\"\n\"value\": \"topic\",\n},\n{\n\"name\": \"resource\",\n\"operator\": \"stringMatch\",\n\"value\": \"dev-topic-{{}}-{{?}}.?.log\"\n}\n]\n}\n]\n}\nShow more\n\nOn the line \"value\": \"dev-topic-{{}}-{{?}}.?.log\", the {{}} indicates the character * and the {{?}} indicates the character ?. Therefore, a topic such as dev-topic--?.1.log matches this pattern.\n\n\n\n\n\n\n\n String comparisons \n\nThe following table lists the string comparison operators that you can use to build access policies with \/v2\/policies syntax.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-wildcard"},{"document_id":"ibmcld_00324-12617-14618","score":7.2690625,"text":"\nMetrics with graphical views \n\nMetrics for an individual CDN are provided on the Overview tab of the customer portal for that CDN mapping. Two types of metrics are calculated from the CDN's usage: those that show the metrics over a time period as a graph, and those that are shown as aggregate values.\n\nFor metrics that display the change over a period of time as a graph, you can see three line graphs and a pie chart. The three line graphs are: Bandwidth, Hits by Mapping, and Hits by Type. They display the activity daily over the course of your specified timeframe. The graphs for Bandwidth and Hits by Mapping are single-line graphs, whereas the breakdown of Hits by Type shows a line for each of the hit types provided. The pie chart displays a regional breakdown of the bandwidth for a CDN mapping on a percentage basis.\n\nMetrics that are shown for aggregate values include Bandwidth Usage in GB, Total Hits to the CDN Edge server, and the Hit Ratio. Hit Ratio indicates that the percentage of times content is delivered by the Edge server, not through its origin. Hit ratio currently is shown as a function of all your CDN mappings, not just the one being viewed.\n\nBy default, both the aggregate numbers and the graphs default to show metrics for the last 30 days, but you can change this through the [IBM Cloud console](https:\/\/cloud.ibm.com\/). Both categories can display metrics for 7-, 15-, 30-, 60-, or 90-day periods.\n\n\n\n\n\n Object storage origin support \n\nIBM Cloud CDN can be configured to serve content from an object storage endpoint by providing the endpoint, the bucket name, protocol, and port. Optionally, you can specify a list of file extensions to allow caching for files only with those extensions. All objects in the bucket must be set with anonymous read or public read access.\n\nFor more information, see [Accelerate delivery of static files using a CDN](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-static-files-cdn).\n\n\n\n\n\n Path-based CDN mappings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-about-content-delivery-networks-cdn-"},{"document_id":"ibmcld_09736-4143-5181","score":7.1994057,"text":"\n[Pencil icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/images\/pencil.png). Then, change the scope. If you need to restore the dashboard scope to the panel, delete the custom scope. Click Apply.\n6. In the Compare to field set the time range for the comparison.\n7. For Number and Threshold chart types you can set the panel color based on metric thresholds. Click Override Color Coding, then, Enable. Set values for the different thresholds.\n8. Click Save.\n\n\n\n\n\n\n\n\n\n Changing the scope \n\nInstead of changing the scope of a pre-defined dashboard, copy the dashboard and change the scope in the copied dashboard.\n\nComplete the following steps to change the scope of a dashboard:\n\n\n\n1. Navigate to the Dashboards section in the Web UI, and select a dashboard.\n2. Click the Pencil icon ![Pencil icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/images\/pencil.png) to Edit Dashboard Scope to change default scope.\n3. Select the scope.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-dashboards"},{"document_id":"ibmcld_03036-7-2061","score":6.677724,"text":"\nMetrics overview \n\nThe Overview page provides a summary of the interactions between users and your assistant. You can view the amount of traffic for a given time period, as well as the intents and entities that were recognized most often in user conversations.\n\nThe Analytics page was introduced with version 1.5.0. The Analytics feature is supported only on clusters that are installed on Red Hat OpenShift 4.5 or later.\n\nUse the metrics to answer questions like:\n\n\n\n* What was the average number of conversations per week during the last month?\n* How often did customers need to go elsewhwere for support?\n* Which intents appeared most often last week?\n* Which entity values were recognized the most times during February?\n* Which days had the largest or smallest numbers of conversations in the last month?\n\n\n\nTo see metrics information, select Overview in the navigation bar.\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter. In each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03036-1611-3443","score":6.629176,"text":"\nIn each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.\n\nThe time shown for each conversation is localized to reflect the time zone of your browser. However, API log calls are always shown in UTC time. As a result, if you choose a single day view, for example, the time shown in the visualization might differ from the timestamp specified in the log for the same conversation.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-time2.png)\n* Intents and Entities filters - Use either of these drop-down filters to show data for a specific intent or entity in your skill.\n\nThe intent and entities filters are populated by the intents and entities in the skill, and not what is in the data source. If you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_09791-7-1663","score":6.620863,"text":"\nManaging panels \n\nUse a panel to display a metric or group of metrics in a dashboard. You can copy, change the scope, duplicate, delete, export, and explore panels.\n\nYou can use any of the following panel types:\n\n\n\nTable 1. Panel types\n\n Type Description \n\n Line Use this panel to view trends over time for one or more metrics. \n Top list Use this panel to compare a metric across groups of entities. The bar chart is sorted in descending order. \n Histogram Use this panel to view the frequency distribution of a metric in buckets. \n Number Use this panel to view a single number that represents the value of an aggregated metric over time for one or more entities. \n Table Use this panel to display numerical data for your infrastructure based on metrics and segments. \n Text Use this panel to add text. Use markdown to add your text. \n\n\n\n\n\n Copy a panel into a dashboard \n\nComplete the following steps to copy a panel:\n\n\n\n1. Navigate to the Dashboards section (![dashboard section](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/monitor\/images\/dashboards.png)) in the Web UI. Select a dashboard. Then, identify the panel that displays the metric that you want to copy.\n2. Click the Actions icon ![Three dots icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/monitor\/images\/actions.png) and select Copy to Dashboard![Copy to Dashboard icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/monitor\/images\/copy.png).\n3. Select one of the dashboards that are listed, or enter a name for a new dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-panels"},{"document_id":"ibmcld_13498-70698-72301","score":6.57001,"text":"\n* [arithmeticOperator](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencearithmeticOperator)\n* [comparisonOperator](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencecomparisonOperator)\n* [primaryExpression](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceprimaryExpression)\n* [unaryOperator](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referenceunaryOperator)\n\n\n\n\n\n\n\n Related references - value expression \n\nA value expression is referenced by the following clauses:\n\n\n\n* [booleanExpression](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencebooleanExpression)\n* [functionOrAggregate](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencefunctionOrAggregate)\n* [predicate](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-referencepredicate)\n\n\n\n\n\n\n\n\n\n Primary expressions \n\n\n\n primaryExpression \n\n\n\n\n\n constant \n\n\n\n\n\n interval \n\nWith an interval clause, you can define time duration constants that can be used in expressions to add or subtract time ranges from a timestamp value.\n\n\n\n\n\n timeUnitSpec \n\nThe following time units are valid:\n\n\n\n* Singular form: SECOND, MINUTE, DAY, MONTH, YEAR\n* Plural form: SECONDS, MINUTES, DAYS, MONTHS, YEARS\n\n\n\nBoth singular and plural forms can be used interchangeably.\n\nThe following example demonstrates how to add and subtract several time units from the current timestamp.\n\n-- add and subtract several time units from the current timestamp\nSELECT\nCURRENT_TIMESTAMP\n- INTERVAL 2 YEARS\n+ INTERVAL 1 MONTH\n- INTERVAL 3 DAYS\n+ INTERVAL 10 HOURS\n+ interval 30 MINUTES","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-sql-reference"},{"document_id":"ibmcld_09736-3051-4555","score":6.53356,"text":"\n[Pencil icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/images\/pencil.png). The select the desired scope. By default, Entire infrastructure is selected.\n\n\n\n1. Select the scope.\n2. Optionally, click Override the custom panel scopes to override the scope for all panels which currently have a custom scope defined.\n\nThis action cannot be undone.\n\nTo reset the dashboard scope to the entire infrastructure, or to update an existing dashboard's scope to the entire infrastructure, select Entire infrastructure.\n3. Click Save.\n\n\n\n4. Configure panels. Repeat this step for any of the panels in the dashboard that you want to modify.\n\n\n\n1. Identify the panel that you want to modify.\n2. Select Edit Panel. This is the Pencil icon ![Pencil icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/images\/pencil.png).\n3. Change the a chart type.\n4. Change the metric, and rate. Rate defines the type of aggregation that is done to the data.\n5. Change the scope of the panel. Click the Pencil icon ![Pencil icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/images\/pencil.png). Then, change the scope. If you need to restore the dashboard scope to the panel, delete the custom scope. Click Apply.\n6. In the Compare to field set the time range for the comparison.\n7. For Number and Threshold chart types you can set the panel color based on metric thresholds.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-dashboards"},{"document_id":"ibmcld_00404-5279-6843","score":6.4466224,"text":"\nAre metrics updated in real time? \n\nThe most recent metrics can be updated every 5 minutes, while other metrics are updated every 24 hours.\n\n\n\n\n\n What is the time interval when you select Most recent from the Time frame list? \n\nThe time range and time interval relationships are shown.\n\n\n\nTable 2: Time range and time interval relationships\n\n Time range Time interval (minutes) \n\n (0, 60] 1 \n (60, 300] 5 \n (300, 600] 10 \n (600, 900] 15 \n (900, 1200] 20 \n (1200, 1500] 25 \n (1500, 1800] 30 \n (1800, 2100] 35 \n (2100, 2400] 40 \n (2400, 2700] 45 \n (2700, 2880] 50 \n\n\n\nMath notation ( means \"does not include\" and ] means \"include\".\n\nExample: Start Date timestamp: 1611244800 End Date timestamp: 1611248400 Time range = (End Date timestamp - Start Date timestamp) \/ 60 = 300 Referring to the preceding table, the time interval is 5 minutes.\n\n\n\n\n\n Why does the last point sometimes drop suddenly in the Most Recent Metrics Report? \n\nZoom\n\n![Most recent interval](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/006fd22ab2811b7d19804c763a00568b3da4c03a\/CDN\/images\/metrics-most-recent-interval.png)\n\nFigure 7: Most recent interval\n\nIn the report, each point is a sum of metric data over a time interval, and the interval is calculated by the preceding table. However, for the last point, the interval might be smaller than others. For example, in the bandwidth \"most recent\" report, the time interval is 5 minutes, and all the points are the sum of bandwidth over 5 minutes, except that the last one is only 1-minute bandwidth (January 21 04:00 PM to January 21 05:00 PM).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-metrics"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.3487022475}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09701-12088-14157","score":11.932159,"text":"\nSeverity Severity status \n\n 0 HIGH \n 1 HIGH \n 2 MEDIUM \n 3 MEDIUM \n 4 LOW \n 5 LOW \n 6 INFO \n 7 INFO \n\n\n\n\n\n\n\n segmentBy (array of strings) \n\nDefines additional segmentation criteria.\n\nFor example, you can segment a CPU alert by ['host.mac', 'proc.name'] so the alert can report on any process in any machine for which you get data in the monitoring instance.\n\n\n\n\n\n segmentCondition (string) \n\nDefines when the alert is triggered for each monitored entity that is specified in the segmentBy parameter. This parameter is required for MANUAL alerts only.\n\nValid values are the following:\n\n\n\n* ANY: The alert is triggered when at least one of the monitored entities satisfies the condition.\n* ALL: The alert is triggered when all of the monitored entities satisfy the condition.\n\n\n\n\n\n\n\n teamId (string) \n\nDefines the GUID of the team that owns the alert.\n\n\n\n\n\n type (string) \n\nDefines the type of alert. Valid values are MANUAL, BASELINE, and HOST_COMPARISON.\n\nSet to MANUAL for alerts that you want to control when a notification is sent. You must define the threshold that determines when the alert is triggered.\n\nSet to BASELINE for alerts that you want to notify when unexpected metric values are detected. New metric data is compared with metric values that are collected over time.\n\nSet to HOST_COMPARISON for alerts that you want to notify when 1 host in a group reports metrics values that are different from the other hosts in the group.\n\n\n\n\n\n timespan (integer) \n\nMinimum time interval, in microseconds, for which the alert condition must be met before the alert is triggered.\n\nThe minimum value is 60000000 microseconds, that is, 1 minute.\n\nThe value of this parameter must be a multiple of 60000000 microseconds.\n\n\n\n\n\n version (integer) \n\nVersion of an alert.\n\nThe version changes every time you update an alert.\n\nThe version is used for optimistic locking.\n\n\n\n\n\n\n\n Query parameters \n\n\n\n alertId (integer) \n\nID of an alert.\n\n\n\n\n\n from (long) \n\nDefines the start timestamp, in microseconds, that is used when you request information about alerts that are defined.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_api"},{"document_id":"ibmcld_09336-3279-5476","score":10.972792,"text":"\nThis alert will show all thresholds that have been exceeded during the period. If index rate alerts are configured on each separate threshold, an alert will be sent indicating the first threshold crossed (either Max lines\/s, Max z-score, or both).\n\n\n\n\n\n Types of index rate alerts \n\nThere are two types of index rate alerts:\n\n\n\n* Max lines\/s alerts: Use this alert to monitor and control the number of log lines per second that are indexed and stored for search.\n\n\n\n* To monitor high flow rates, set an index rate threshold by configuring the max lines alert field so that you can get an alert when the value of lines per second is exceeded.\n* When the average index rate changes over time, you must review and configure the threshold accordingly.\n\n\n\n* Max z-score alerts: Use this alert to monitor and control anomalous flow rates.\n\n\n\n* To monitor for spikes on logs and anomalous flow rates, set a threshold value by configuring the max z-score field so that you can get an alert when the hourly index rate is significantly higher than the monthly mean.\n* The baseline value is calculated using data from the last 30 days.\n\n\n\nAfter you provision an instance, you must wait a minimum of 30 days of data that has been indexed to use this feature.\n\n\n\n* Each z-score represents 1 standard deviation that is based on the distribution of index rates as seen over the past 30 days.\n\n0, 1 indicates a small spike of data.\n\n3 indicates a spike of data that requires troubleshooting and control.\n\n5 indicates a spike of data that requires quick action such as defining exclusion rules while you find out what source and app are causing a spike of data.\n\n\n\nSetting a maximum of 3 standard deviations is a good starting point for alert triggering. You can then refine your alerting based on your needs.\n\n\n\n\n\n\n\n Launch the index rate alert page \n\nThe index rate alert page offers an overview of your account's current rate of ingestion and indexing of searchable data. Through this page, you can see the ratio between the log lines that are ingested versus the number of log lines that are being stored.\n\nTo use the index rate feature on an instance, an administrator of the service must turn on the feature.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-control_usage_index_rate"},{"document_id":"ibmcld_02426-3294-5485","score":10.849636,"text":"\nThis alert will show all thresholds that have been exceeded during the period. If index rate alerts are configured on each separate threshold, an alert will be sent indicating the first threshold crossed (either Max lines\/s, Max z-score, or both)\n\n\n\n\n\n Types of index rate alerts \n\nThere are two types of index rate alerts:\n\n\n\n* Max lines\/s alerts: Use this alert to monitor and control the number of log lines per second that are indexed and stored for search.\n\n\n\n* To monitor high flow rates, set an index rate threshold by configuring the max lines alert field so that you can get an alert when the value of lines per second is exceeded.\n* When the average index rate changes over time, you must review and configure the threshold accordingly.\n\n\n\n* Max z-score alerts: Use this alert to monitor and control anomalous flow rates.\n\n\n\n* To monitor for spikes on logs and anomalous flow rates, set a threshold value by configuring the max z-score field so that you can get an alert when the hourly index rate is significantly higher than the monthly mean.\n* The baseline value is calculated using data from the last 30 days.\n\nAfter you provision an instance, you must wait a minimum of 30 days of data that has been indexed to use this feature.\n* Each z-score represents 1 standard deviation that is based on the distribution of index rates as seen over the past 30 days.\n\n0, 1 indicates a small spike of data.\n\n3 indicates a spike of data that requires troubleshooting and control.\n\n5 indicates a spike of data that requires quick action such as defining exclusion rules while you find out what source and app are causing a spike of data.\n\n\n\nSetting a maximum of 3 standard deviations is a good starting point for alert triggering. You can then refine your alerting based on your needs.\n\n\n\n\n\n\n\n Launch the index rate alert page \n\nThe index rate alert page offers an overview of your account's current rate of ingestion and indexing of searchable data. Through this page, you can see the ratio between the log lines that are ingested versus the number of log lines that are being stored.\n\nTo use the index rate feature on an instance, an administrator of the service must turn on the feature.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-control_usage_index_rate"},{"document_id":"ibmcld_09148-8939-9806","score":10.476837,"text":"\nTo setup a metric, complete the follow steps.\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert at the top of the page.\n3. Select Metric as the alert type.\n4. Select the aggregation and the metric that you would like to be performed on.\n5. Select the scope if applicable.\n6. Set the metric and time requirements for the alert to trigger.\n7. Configure and set up the notification channel and notification interval.\n8. Click the CREATE button.\n\n\n\nThe figure as shown provides an example of how to configure an alert when your service instance receives multiple 401 and 403 errors within a 10 minute time span.\n\nZoom\n\n![An example of a 401 and 403 configuration.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc\/key-protect\/images\/monitor-401-alert.png)\n\nFigure 5. The configuration for a 401 alert in a Monitoring dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-operational-metrics"},{"document_id":"ibmcld_09148-3210-5155","score":10.398785,"text":"\nFor example, you can track how many API requests have been made by an authorized user be setting an [alert](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-operational-metricsset-monitor-alerts) that triggers when your monitoring instance notices a frequent amount of 401 status codes being returned from your Key Protect instance.\n\n\n\nTable 1. Describes the API Hits metrics.\n\n Metadata Description \n\n Metric Name ibm_kms_api_request_gauge \n Metric Type Gauge \n Value Type none \n Segment By [Attributes for Segmentation](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-operational-metricsattributes-for-segmentation) \n\n\n\n\n\n\n\n\n\n Latency \n\nThe amount of time it takes Key Protect to receive an API request and respond to it.\n\nThe latency is calculated by getting the average of all requests of the same type that occur within 60 seconds.\n\n\n\nTable 2. Describes the Latency metrics.\n\n Metadata Description \n\n Metric Name ibm_kms_api_latency_gauge \n Metric Type Gauge \n Value Type Milliseconds \n Segment By [Attributes for Segmentation](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-operational-metricsattributes-for-segmentation) \n\n\n\n\n\n\n\n Attributes for Segmentation \n\nYou can filter your metrics by using the following attributes.\n\n\n\nTable 3. Describes the attributes use for segmenting metrics.\n\n Attribute Name Description \n\n ibm_resource_type Supported resource type is instance. \n ibm_kms_response_code Response code for the Key Protect service API request. \n ibm_scope The account, organization, or space GUID associated with the metric. \n ibm_ctype public, dedicated, or local. \n ibm_location Location of the Key Protect service instance. \n ibm_service_name kms. \n ibm_resource Key Protect service instance ID. \n ibm_kms_api Key Protect service API name. \n ibm_resource_group_name Resource group name associated with the Key Protect service instance. \n ibm_service_instance_name Key Protect service instance name.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-operational-metrics"},{"document_id":"ibmcld_09795-10464-12245","score":10.045542,"text":"\nFor example, the following are 4 unique time series:\n\nmetric_name{datacenter=\u201ddc-1\u201d, zone=\u201dzone1\u201d} 23\nmetric_name{datacenter=\u201ddc-2\u201d, zone=\u201dzone1\u201d} 34\nmetric_name{datacenter=\u201ddc-3\u201d, zone=\u201dzone2\u201d} 43\nmetric_name{datacenter=\u201ddc-4\u201d, zone=\u201dzone2\u201d} 23\n\nA data-point is the value generated for a time-series at a given point in time. For example: [timestamp]|website_failedRequests:20|region='Asia', customer_ID='abc'.\n\nThe number of time-series you are ingesting from the different sources are measured hourly and contribute to TIME_SERIES_HOURS pricing concept.\n\n\n\n\n\n Checking the metrics that are collected per agent \n\nIn IBM Cloud Monitoring, you can monitor your monitoring agent by using the dashboard template monitoring agent Health & Status that is available in the dashboard templates available out-of-the-box. In this dashboard, you can see the number of monitoring agents that are deployed and connected to the instance, check the version of the monitoring agents, and find out how many metrics per host the agent is collecting.\n\nIn this dashboard, the panel TimeSeries Usage provides the number of time-series that are collected from each category (Prometheus, JMX, StatsD, Prometheus Remote Write and Platform Metrics). This panel uses the query sum(sysdig_ts_usage)by(metric_category) that you can also run in PromQL Explorer, in your dashboards or for alerts.\n\nIn case you need to investigate which applications or services are contributing more to the Prometheus time-series, you can use the metric scrape_series_added. This metric represents the number of time series scraped and ingested from the monitoring agent via Prometheus and includes several labels to facilitate the analysis such as kube_cluster_name, kube_namespace_name, kube_workload_name or container_name.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-pricing_plans"},{"document_id":"ibmcld_07085-32411-34041","score":9.83393,"text":"\n),\nshow_estimated_matching_results: <true_or_false>, show_total_matching_documents: <true_or_false> )\nThe resulting matrix can be represented in a table.<-- <table \"class=\"row-headers comparison-table\" \"> -->Table 5. Trend aggregation example This table has row and column headers. The row headers identify months of the year 2020. The column headers identify ice cream flavors. Each cell calculates a relevancy score by multiplying the month (row) relevancy value times the flavor (header) relevancy value.| Month in 2020 | Flavor: vanilla | Flavor: chocolate | Flavor: mint || ------------- | --------------- | ----------------- | ------------ || Jan | vanilla x Jan | chocolate x Jan | mint x Jan || Feb | vanilla x Feb | chocolate x Feb | mint x Feb || Mar | vanilla x Mar | chocolate x Mar | mint x Mar || Apr | vanilla x Apr | chocolate x Apr | mint x Apr || May | vanilla x May | chocolate x May | mint x May || Jun | vanilla x Jun | chocolate x Jun | mint x Jun |<-- <\/table \"class=\"row-headers comparison-table\" \"> -->In the following sample response, the key information is the trend_indicator value. The trend indicator measures the increase ratio of the frequency of a given facet value for a given time interval compared to the expected average frequency. The excepted average frequency is calculated based on the changes in the past time interval frequencies of the given facet value, using a weighted arithmetic mean.If the standarized residual value is less than -2, the observed frequency is less than the expected frequency. If it is greater than 2, the observed frequency is greater than the expected frequency.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-aggregations"},{"document_id":"ibmcld_09794-10912-12367","score":9.657892,"text":"\nYou can define a metric alert directly from the Alerts section.\n\nComplete the following steps to define an alert on a metric:\n\n\n\n1. [Launch the monitoring UI](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-launch).\n2. Verify that you have a notification channel that defines how you want to be notified.\n\nYou can enabled 1 or more notification channels when you configure an alert. If you need multiple notification channels, check they are available.\n3. Navigate to the Alerts section ![Alerts module](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/images\/alerts.png)) in the Web UI.\n4. Select Add Alert.\n\nZoom\n\n![Add alert](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/platform\/images\/sysdig-platform-7.png)\n\nAdd alert\n5. Select your desired alert type.\n\nZoom\n\n![Choose alert type](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/220cdcbf6f4421bd7fee83fd1028048dba3f16c8\/monitoring\/platform\/images\/sysdig-platform-16.png)\n\nChoose alert type\n6. Configure the alert. Set the following fields:\n\nName: Enter a name for the alert.\n\nDescription: Add a description that other users can read to get more context. This field is optional.\n\nGroup: The alert group this alert will be part of. If not specified, the alert will be part of the default group.\n\nSeverity: Set the level of criticality of the alert. Valid values are High, Medium, Low, and Info.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-platform_metrics_working"},{"document_id":"ibmcld_09291-4010-5423","score":9.639557,"text":"\nFor example, you can name the view Upload Frankfurt to indicate archive files into the bucket from an IBM Log Analysis instance located in Frankfurt.\n\nThe data that is displayed through the view reports write actions of archive files to the archive bucket.\n\n\n\n\n\n\n\n Step 3. Define an alert to notify the absence of new archive files \n\nComplete the following steps to define an absence alert that notifies you when archiving is not happening:\n\n\n\n1. Select the view name.\n\n![Select view name](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/log-analysis\/images\/archive-view-2.png)\n2. Select Attach an alert. The following page opens.\n\n![Select alert type](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/log-analysis\/images\/archive-view-3.png)\n3. Select View-specific alert.\n4. Choose the notification channel.\n5. Configure an Absence alert.\n\n![Sample absence alert](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a\/log-analysis\/images\/archive-view-3.png)\n\nArchiving is configured hourly. Consider configuring the absence alert over a period of 24 hours to monitor archiving daily.\n\n\n\nFor more details on how to configure an alert, see [Creating alerts](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-create_alert_ui).\n\n\n\n\n\n\n\n Configure an alert to detect unauthorize access to the bucket","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-archiving-la-monitor"},{"document_id":"ibmcld_04334-179782-181318","score":9.582187,"text":"\nThe OR operator is defined using a comma (,) or OR keyword surrounded by whitespace. The AND operator is defined using a semicolon (;) or AND keyword surrounded by whitespace. Comparison options are: ==, =, >, <, >=, <=. An example value for filters is: event==connect AND coloName=SFO.--sort: The sort order for the result set. Sort fields must be included in metrics or dimensions. An example value for sort is: +count,-bytesIngress.--since: Start of time interval to query, defaults to until - 6 hours. This should be an absolute timestamp that conforms to RFC 3339.--until: End of time interval to query, defaults to current time. This should be an absolute timestamp that conforms to RFC 3339.--bytime: Analytics data for range applications grouped by time interval.--time-delta: Used to select time series resolution. Valid values: year, quarter, month, week, day, hour, dekaminute, minute. Only valid when --bytime is given.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.--output: Specify output format, only JSON is supported.<-- <\/section \"id=\"section-get-analytics-range-app-options\" \"> --><-- <section \"id=\"section-get-analytics-range-app-examples\" \"> --> Examples Get analytics data for range applications in domain 31984fea73a15b45779fa0df4ef62f9b. ibmcloud cis range-analytics 31984fea73a15b45779fa0df4ef62f9b --metrics \"count,bytesIngress\" --dimensions \"event,appID\" --since \"2020-05-22T02:20:00Z\"\n--until \"2020-05-23T02:20:00Z\" -i \"cis-demo\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1480409555}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03036-2789-4951","score":9.6767435,"text":"\nIf you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03036-4322-6185","score":9.673816,"text":"\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_16490-7-2216","score":8.504339,"text":"\nAnalyzing machine learning model performance \n\nReview the annotations that were added by the trained model to determine whether any adjustments must be made to the model to improve its ability to find valid entity mentions, relation mentions, and coreferences in the documents.\n\n\n\n About this task \n\nYou can analyze performance by viewing a summary of statistics for entity types, relation types, and coreferenced mentions. You can also analyze statistics that are presented in a confusion matrix. The confusion matrix helps you compare the annotations added by the machine learning model to the annotations in ground truth.\n\nThe model statistics provide the following metrics:\n\n\n\n* F1 score\n\nA measurement that considers both precision and recall to compute the score. The F1 score can be interpreted as a weighted average of the precision and recall values, where an F1 score reaches its best value at 1 and worst value at 0. See [Analyzing low F1 scores](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-mlevaluate-mllowf1).\n* Precision\n\nA measurement that specifies what fraction of the machine learning model's output was accurate when compared to the human annotator output. Precision is determined by the number of correctly labeled annotations divided by the total number of annotations added by the machine learning model. A precision score of 1.0 for entity type A means that every mention that was labeled as entity type A does indeed belong to that classification. A low precision score helps you identify places where the machine learning model created incorrect annotations. The score says nothing about how many other mentions that were labeled as entity type A by the human annotator were missed by the machine learning model; the recall score reflects that information. See [Analyzing low precision scores](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-mlevaluate-mllowp).\n* Recall\n\nA measurement that specifies how many mentions that should have been annotated by a given label were actually annotated with that label - the right mentions being those that human annotators identified in the same documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-evaluate-ml"},{"document_id":"ibmcld_03363-4-2165","score":8.375198,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_13129-16717-17970","score":8.374891,"text":"\nTo understand the quality metrics, refer to [Quality metric overview](https:\/\/cloud.ibm.com\/docs\/ai-openscale?topic=ai-openscale-anlz_metrics)\n\n\n\n\n\n\n\n\n\n Step 7: Remove resources \n\n\n\n1. Navigate to [IBM Cloud\u00ae Resource List](https:\/\/cloud.ibm.com\/resources\/).\n2. Under Name, enter tutorial in the search box.\n3. Delete the services which you created for this tutorial.\n\n\n\nDepending on the resource it might not be deleted immediately, but retained (by default for 7 days). You can reclaim the resource by deleting it permanently or restore it within the retention period. See this document on how to [use resource reclamation](https:\/\/cloud.ibm.com\/docs\/account?topic=account-resource-reclamation).\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Pak for Data Overview](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/getting-started\/welcome-main.html?context=analytics)\n* [Automatic model creation](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/analyze-data\/autoai-overview.html?context=analytics)\n* [Machine learning & AI](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/analyze-data\/wml-ai.html?context=analytics)\n* [Watson OpenScale documentation](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/model\/getting-started.html?context=analytics)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model"},{"document_id":"ibmcld_16425-7-2236","score":8.345232,"text":"\nAnalyzing machine learning model performance \n\nReview the annotations that were added by the trained model to determine whether any adjustments must be made to the model to improve its ability to find valid entity mentions, relation mentions, and coreferences in the documents.\n\n\n\n About this task \n\nYou can analyze performance by viewing a summary of statistics for entity types, relation types, and coreferenced mentions. You can also analyze statistics that are presented in a confusion matrix. The confusion matrix helps you compare the annotations added by the machine learning model to the annotations in ground truth.\n\nThe model statistics provide the following metrics:\n\n\n\n* F1 score\n\nA measurement that considers both precision and recall to compute the score. The F1 score can be interpreted as a weighted average of the precision and recall values, where an F1 score reaches its best value at 1 and worst value at 0. See [Analyzing low F1 scores](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-mlevaluate-mllowf1).\n* Precision\n\nA measurement that specifies what fraction of the machine learning model's output was accurate when compared to the human annotator output. Precision is determined by the number of correctly labeled annotations divided by the total number of annotations added by the machine learning model. A precision score of 1.0 for entity type A means that every mention that was labeled as entity type A does indeed belong to that classification. A low precision score helps you identify places where the machine learning model created incorrect annotations. The score says nothing about how many other mentions that were labeled as entity type A by the human annotator were missed by the machine learning model; the recall score reflects that information. See [Analyzing low precision scores](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-mlevaluate-mllowp).\n* Recall\n\nA measurement that specifies how many mentions that should have been annotated by a given label were actually annotated with that label - the right mentions being those that human annotators identified in the same documents.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-evaluate-ml"},{"document_id":"ibmcld_13129-7227-9128","score":7.854046,"text":"\nOnce the experiment completes running,\n\n\n\n1. Click on Pipeline comparison to view how the top pipelines compare.\n2. Sort the leaderboard by a different metric by clicking on the various column headers.\n3. Click a pipeline to view more detail about the metrics and performance.\n\nSorting by different metrics may not change the leaderboard rankings as the dataset used in this tutorial is very simple and used only for your understanding of the concepts. With other datasets, the rank may vary.\n4. Next to the model with Rank 1 when sorted by Accuracy, click on Save as > Model.\n5. Check the details of the model and click Create.\n6. From the received notification, click View in project.\n\n\n\nThe accuracy of the model will be improved in the later part of the tutorial.\n\n\n\n\n\n Step 4: Deploy and test your model \n\nIn this section, you will deploy the saved model and test the deployed model,\n\n\n\n1. Under the created model, click on Promote to deployment space.\n2. Under Target Space, select Create a new deployment space. You use deployment spaces to deploy models and manage your deployments.\n\n\n\n1. Set the Name to iris_deployment_space.\n2. Select the Object Storage service you use in previous steps and the machine-learning-tutorial service from the respective dropdowns.\n3. Click Create.\n\n\n\n3. Click on Promote.\n4. From the received notification, navigate to the deployment space.\n5. Under the deployment space, click on the name of the model you just created.\n6. Click the New deployment button.\n7. Select Online as the Deployment type, provide iris_deployment as the name and then click Create.\n8. Under Deployments tab, once the status changes to Deployed, Click on the Name of the new web service to check the details.\n\n\n\n\n\n Test the deployed model \n\n\n\n1. Under Test tab of your deployment, click on JSON input icon next to Enter input data and provide the JSONbelow as input.\n\n{\n\"input_data\": [{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model"},{"document_id":"ibmcld_13406-6795-8870","score":7.606207,"text":"\nThe metrics indicate the progress and complexity of the engine's processing:\n\n\n\n* seen_by_engine is audio that the service has read and passed to the engine at least once.\n* received - seen_by_engine is audio that has been buffered at the service but has not yet been seen or processed by the engine.\n* The relationship between the times is received >= seen_by_engine >= transcription >= speaker_labels.\n\n\n\nThe following relationships can also be helpful in understanding the results:\n\n\n\n* The values of the received and seen_by_engine fields are greater than the values of the transcription and speaker_labels fields during speech recognition processing. The service must receive the audio before it can begin to process results.\n* The values of the received and seen_by_engine fields are identical when the service has finished processing the audio. The final values of the fields can be greater than the values of the transcription and speaker_labels fields by a fractional number of seconds.\n* The value of the speaker_labels field typically trails the value of the transcription field during speech recognition processing. The values of the transcription and speaker_labels fields are identical when the service has finished processing the audio.\n\n\n\n\n\n\n\n Processing metrics example: WebSocket interface \n\nThe following example shows the start message that is passed for a request to the WebSocket interface. The request enables processing metrics and sets the processing metrics interval to 0.25 seconds. It also sets the interim_results and speaker_labels parameters to true. The audio contains the simple message \"hello world long pause stop.\"\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/flac',\nprocessing_metrics: true,\nprocessing_metrics_interval: 0.25,\ninterim_results: true,\nspeaker_labels: true\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n\nThe following example output shows the first few processing metrics results that the service returns for the request.\n\n{\n\"processing_metrics\": {\n\"processed_audio\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metrics"},{"document_id":"ibmcld_16563-20012-20766","score":7.5817866,"text":"\nFor example, you might want to take a snapshot before you retrain the model. If the statistics are poorer the next time you train it, you can promote the older version and delete the version that returned poorer results.\n\n\n\n\n\n\n\n Results \n\nYou created a machine learning model, trained it, and evaluated how well it performed when annotating test data and blind data. By exploring the performance metrics, you can identify ways to improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n Tutorial summary \n\nYou created a machine learning model.\n\n\n\n Lessons learned \n\nBy completing this tutorial, you learned about the following concepts:\n\n\n\n* Document sets\n* Machine learning models\n* Human annotation tasks\n* Inter-annotator agreement and adjudication","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"},{"document_id":"ibmcld_16563-18465-20518","score":7.2373495,"text":"\nTo see the annotations that the trained machine learning model created on that same set of documents, click View Decoding Results.\n8. To view details about the precision, recall, and F1 scores for the machine learning model, click the Performance page.\n9. Click the Detailed Statistics links above each of the graphs. On these Statistics pages, you can view the scores for mentions, relations, and coreference chains by using the radio buttons.\n\nYou can analyze performance by viewing a summary of statistics for entity types, relation types, and coreference chains. You can also analyze statistics that are presented in a confusion matrix. To see the matrix, change Summary to Confusion Matrix. The confusion matrix helps you compare the annotations that were added by the machine learning model to the annotations in the ground truth.\n\nIn this tutorial, you annotated documents with only a single dictionary for organizations. Therefore, the scores you see are 0 or N\/A for most entity types except ORGANIZATION. The numbers are low, but that is expected because you did not do any human annotation or correction.\n\nFigure 2. Options on the Statistics page for a machine learning model\n\n![This screen capture shows the Statistics page.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/50eddb8fd81f33092880335ff107a78ff5cd0f65\/watson-knowledge-studio\/images\/wks_tutanno9.png)\n10. Click Versions. On the Versions page, you can take a snapshot of the model and the resources that were used to create it (except for dictionaries and annotation tasks). For example, you might want to take a snapshot before you retrain the model. If the statistics are poorer the next time you train it, you can promote the older version and delete the version that returned poorer results.\n\n\n\n\n\n\n\n Results \n\nYou created a machine learning model, trained it, and evaluated how well it performed when annotating test data and blind data. By exploring the performance metrics, you can identify ways to improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n Tutorial summary","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.6131471928}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03036-4322-6185","score":11.047087,"text":"\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03036-2789-4951","score":10.13196,"text":"\nIf you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03363-1671-3630","score":9.5921,"text":"\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_09701-12088-14157","score":9.072749,"text":"\nSeverity Severity status \n\n 0 HIGH \n 1 HIGH \n 2 MEDIUM \n 3 MEDIUM \n 4 LOW \n 5 LOW \n 6 INFO \n 7 INFO \n\n\n\n\n\n\n\n segmentBy (array of strings) \n\nDefines additional segmentation criteria.\n\nFor example, you can segment a CPU alert by ['host.mac', 'proc.name'] so the alert can report on any process in any machine for which you get data in the monitoring instance.\n\n\n\n\n\n segmentCondition (string) \n\nDefines when the alert is triggered for each monitored entity that is specified in the segmentBy parameter. This parameter is required for MANUAL alerts only.\n\nValid values are the following:\n\n\n\n* ANY: The alert is triggered when at least one of the monitored entities satisfies the condition.\n* ALL: The alert is triggered when all of the monitored entities satisfy the condition.\n\n\n\n\n\n\n\n teamId (string) \n\nDefines the GUID of the team that owns the alert.\n\n\n\n\n\n type (string) \n\nDefines the type of alert. Valid values are MANUAL, BASELINE, and HOST_COMPARISON.\n\nSet to MANUAL for alerts that you want to control when a notification is sent. You must define the threshold that determines when the alert is triggered.\n\nSet to BASELINE for alerts that you want to notify when unexpected metric values are detected. New metric data is compared with metric values that are collected over time.\n\nSet to HOST_COMPARISON for alerts that you want to notify when 1 host in a group reports metrics values that are different from the other hosts in the group.\n\n\n\n\n\n timespan (integer) \n\nMinimum time interval, in microseconds, for which the alert condition must be met before the alert is triggered.\n\nThe minimum value is 60000000 microseconds, that is, 1 minute.\n\nThe value of this parameter must be a multiple of 60000000 microseconds.\n\n\n\n\n\n version (integer) \n\nVersion of an alert.\n\nThe version changes every time you update an alert.\n\nThe version is used for optimistic locking.\n\n\n\n\n\n\n\n Query parameters \n\n\n\n alertId (integer) \n\nID of an alert.\n\n\n\n\n\n from (long) \n\nDefines the start timestamp, in microseconds, that is used when you request information about alerts that are defined.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_api"},{"document_id":"ibmcld_09276-7-2089","score":8.973226,"text":"\nWorking with alerts \n\nYou can configure alerts to notify about the state of your infrastructure, applications, and IBM Cloud services.\n\nA rule specifies the scope of the data that you want to monitor and be notified if certain conditions occur. Per alert rule, consider the following information:\n\n\n\n* You can define 1 or more notification channels.\n* You can configure different alert types for each notification channel that you configure for an alert.\n* You can configure different triggering conditions for each notification channel that you configure for an alert.\n\n\n\nA rule is also the basis of a view. You can see the data that is included by any rule by using it as a view. The two are interchangeable.\n\n\n\n Types of alerts \n\nYou can configure any of the following types of alerts for each notification channel that you configure for an alert:\n\n\n\n Presence alert \n\nYou can configure a presence alert to notify when the number of logs that show in a view is more than what you expect.\n\nFor example, you might have a view that shows logs that report payments that are rejected by your service. You can configure a presence alert that triggers an alert when 1 or more logs show in the view.\n\n\n\n\n\n Absence alert \n\nConfigure an absence alert to notify when the number of logs that show in a view is less than what you expect, or none.\n\nAn absence alert is triggered when the view that has an absence alert attached to it is active. A view is active when the view receives logs within the last 24 hours.\n\nFor example, you might have a view that does not get any logs for 2 days. Therefore, this view is not active. You have an absence alert attached to this view that is configured to send a notification after 30 minutes. Because the view is not active, the absence alert is muted and you do not get notifications. To make the view active and get notifications for the absence condition, logs need to start flowing into the view.\n\n\n\n\n\n\n\n Alert conditions \n\nYou can configure any of the following triggering conditions for each notification channel that you configure for an alert:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-alerts"},{"document_id":"ibmcld_09782-1362-3189","score":8.858504,"text":"\n: Information about the alert.\n\n--type <TYPE>\n: Type of alert. Valid values are MANUAL, BASELINE, and HOST_COMPARISON.\n\n--timespan <TIMESPAN>\n: Minimum time interval, in microseconds, for which the alert condition must be met before the alert is triggered. The default value is 60,000,000 microseconds.\n\n--condition <CONDITION>\n: Threshold of the alert. This parameter is required for manual alerts, and does not apply to other alert types.\n\n--severity <SEVERITY> | -s <SEVERITY>\n: Level of severity. Valid values range from 0 to 7. 0 means emergency and 7 means debug. By default, severity is set to 4.\n\n--severity-label <LOW | MEDIUM | HIGH>\n: Criticality of an alert. Valid values are HIGH, MEDIUM, LOW. A lower severity value indicates a higher severity.\n\n--disable\n: State of the alert. By default, an alert is enabled when it is created. You must set this parameter to disable the alert when it is created.\n\n--segment <SEGMENT>\n: Additional segmentation criteria. For example, you can segment an alert by ['host.mac', 'proc.name'].\n\n--segment-condition <SEGMENT_CONDITION>\n: Defines when the alert is triggered for each monitored entity that is specified in the --segment parameter. This parameter is required for manual alerts, and does not apply to other alert types. Valid values are ANY and ALL. ANY indicates that the alert is triggered when at least one of the monitored entities satisfies the condition. ALL indicates that the alert is triggered when all of the monitored entities satisfy the condition.\n\n--user-filter <USER_FILTER>\n: Boolean expression that you can set to reduce the scope of the alert. Use this parameter to configure segments, such as filters like kubernetes.namespace.name='production' or container.image='nginx'.\n\n--notify <NOTIFY>\n: Type of notification that you want this alert to generate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-monitor-cli"},{"document_id":"ibmcld_13029-7-2115","score":8.464079,"text":"\nWorking with alerts \n\nYou can configure alerts to notify about the activity in your IBM Cloud account and changes in configuration in the account.\n\nA rule specifies the scope of the data that you want to monitor and be notified if certain conditions occur. Per alert rule, consider the following information:\n\n\n\n* You can define 1 or more notification channels.\n* You can configure different alert types for each notification channel that you configure for an alert.\n* You can configure different triggering conditions for each notification channel that you configure for an alert.\n\n\n\nA rule is also the basis of a view. You can see the data that is included by any rule by using it as a view. The two are interchangeable.\n\n\n\n Types of alerts \n\nYou can configure any of the following types of alerts for each notification channel that you configure for an alert:\n\n\n\n Presence alert \n\nYou can configure a presence alert to notify when the number of events that show in a view is more than what you expect.\n\nFor example, you might have a view that shows events that report payments that are rejected by your service. You can configure a presence alert that triggers an alert when 1 or more events show in the view.\n\n\n\n\n\n Absence alert \n\nConfigure an absence alert to notify when the number of events that show in a view is less than what you expect, or none.\n\nAn absence alert is triggered when the view that has an absence alert attached to it is active. A view is active when the view receives events within the last 24 hours.\n\nFor example, you might have a view that does not get any events for 2 days. Therefore, this view is not active. You have an absence alert attached to this view that is configured to send a notification after 30 minutes. Because the view is not active, the absence alert is muted and you do not get notifications. To make the view active and get notifications for the absence condition, events need to start flowing into the view.\n\n\n\n\n\n\n\n Alert conditions \n\nYou can configure any of the following triggering conditions for each notification channel that you configure for an alert:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/activity-tracker?topic=activity-tracker-alerts"},{"document_id":"ibmcld_03363-6198-7991","score":8.369658,"text":"\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter. In each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.\n\nThe time shown for each conversation is localized to reflect the time zone of your browser. However, API log calls are always shown in UTC time. As a result, if you choose a single day view, for example, the time shown in the visualization might differ from the timestamp specified in the log for the same conversation.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-time2.png)\n* Intents and Entities filters - Use either of these drop-down filters to show data for a specific intent or entity in your skill.\n\nThe intent and entities filters are populated by the intents and entities in the skill, and not what is in the data source. If you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_09419-3678-5274","score":8.257737,"text":"\nValid values are: slack, email, webhook, pagerduty, pagerduty-auto-resolve, and sysdig. \n immediate Specified if the alert is sent immediately after the line criteria is met (\"immediate\": true) or after the line and time criteria is met (\"immediate\": false). \n triggerlimit The number of matching log lines to trigger the alert. \n triggerinterval The amount of time to look for the number of matching log lines. <br>Only following triggerinterval values are valid:<br><br><br><br> * 30 - 30 seconds<br> * 1m - 1 minute<br> * 5m - 5 minutes<br> * 30m - 30 minutes<br> * 1h - 1 hour<br> * 6h - 6 hours<br> * 12h - 12 hours<br> * 24h - 24 hours<br><br><br> \n operator Specifies whether the alert is triggered when the condition exists (presence) or when it does not exist (absence). \n blackout (Optional) Specifies the time period when the alert would be active. \n\n\n\nThe following is an example blackout definition specifying that the alert is active Monday through Friday from 8:00 AM to 5:00 PM in (GMT-05:00) America\/New York.\n\nblackout\": {\n\"enabled\": true, A\n\"times\": {\n\"enabled\": true,\n\"periods\": [\n\n\"17:00\",\n\"08:00\"\n]\n]\n},\n\"days\": [\n\"0\",\n\"6\"\n],\n\"timezone\": \"America\/New_York\"\n}\nShow more\n\nThe following values are only valid for the specified preset type:\n\nEmail\n\nPagerDuty\n\nSlack\n\n\n\nChannel configuration values for email presets\n\n Value Description \n\n emails The email addresses where the alert will be sent. \n timezone (Optional) The preferred timezone. \n\n\n\nSysdig (IBM Cloud Monitoring)\n\nWebhook\n\n\n\nChannel configuration values for Sysdig (IBM Cloud Monitoring) presets\n\n Value Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-preset-api"},{"document_id":"ibmcld_02505-3708-5304","score":8.257737,"text":"\nValid values are: slack, email, webhook, pagerduty, pagerduty-auto-resolve, and sysdig. \n immediate Specified if the alert is sent immediately after the line criteria is met (\"immediate\": true) or after the line and time criteria is met (\"immediate\": false). \n triggerlimit The number of matching log lines to trigger the alert. \n triggerinterval The amount of time to look for the number of matching log lines. <br>Only following triggerinterval values are valid:<br><br><br><br> * 30 - 30 seconds<br> * 1m - 1 minute<br> * 5m - 5 minutes<br> * 30m - 30 minutes<br> * 1h - 1 hour<br> * 6h - 6 hours<br> * 12h - 12 hours<br> * 24h - 24 hours<br><br><br> \n operator Specifies whether the alert is triggered when the condition exists (presence) or when it does not exist (absence). \n blackout (Optional) Specifies the time period when the alert would be active. \n\n\n\nThe following is an example blackout definition specifying that the alert is active Monday through Friday from 8:00 AM to 5:00 PM in (GMT-05:00) America\/New York.\n\nblackout\": {\n\"enabled\": true, A\n\"times\": {\n\"enabled\": true,\n\"periods\": [\n\n\"17:00\",\n\"08:00\"\n]\n]\n},\n\"days\": [\n\"0\",\n\"6\"\n],\n\"timezone\": \"America\/New_York\"\n}\nShow more\n\nThe following values are only valid for the specified preset type:\n\nEmail\n\nPagerDuty\n\nSlack\n\n\n\nChannel configuration values for email presets\n\n Value Description \n\n emails The email addresses where the alert will be sent. \n timezone (Optional) The preferred timezone. \n\n\n\nSysdig (IBM Cloud Monitoring)\n\nWebhook\n\n\n\nChannel configuration values for Sysdig (IBM Cloud Monitoring) presets\n\n Value Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-preset-api"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03363-1671-3630","score":10.703659,"text":"\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_03036-4322-6185","score":9.964954,"text":"\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03036-2789-4951","score":9.727623,"text":"\nIf you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03363-4-2165","score":8.52013,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_09795-1650-3805","score":8.459025,"text":"\nIn your monthly usage charges, consumption is measured hourly and your bill breaks down into the following concepts:\n\n\n\nTable 2. Billing usage metrics\n\n Metric Description \n\n NODE_HOURS Tracks the number of agents that are running in an agent for orchestrated environments.<br><br>This does not include the agents tracked by LITE_NODE_HOURS<br><br>For example, if you have 1 agent connected continuously, that agent will be billed 720 NODE_HOURS at the end of the month. \n TIME_SERIES_HOURS Reflects the total number of custom metrics time series you are sending to IBM Cloud Monitoring during a 1 hour time window. This is an aggregation of all time series from agents and other metrics sources. Platform metrics, Prometheus remote write, metric streaming and custom metrics collected with the agent (Prometheus, JMX or StatsD) contribute to TIME_SERIES_HOURS.<br><br>Only custom metrics are counted for TIME_SERIES_HOURS. Default infrastructure metrics (such as host, container, program, or Kubernetes state) and CPU, memory, disk, and network are included in the agent price and do not contribute to TIME_SERIES_HOURS. \n LITE_NODE_HOURS Tracks the number of agents that are monitoring non-containerized infrastructures such as VMs or bare metal servers, and are using the agent for non-orchestrated environments. \n API_CALL_HOURS Represents how many calls are being made to the API per month. All instances include 1M API calls. \n CONTAINER_HOURS Represents how many containers are monitored across all hosts that are being monitored by agents. \n\n\n\nTo monitor how the IBM Cloud Monitoring service is used and the costs associated to its usage, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage).\n\nAll metrics that start with sysdig_* and kube_ are collected automatically by an agent and are included in the agent price.\n\n\n\n\n\n Service plans \n\nThe following service plans are available when you provision an instance of the IBM Cloud Monitoring service:\n\n\n\n Lite plan \n\nYou can provision a Monitoring instance with the Lite service plan to try out the Monitoring service for free for 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-pricing_plans"},{"document_id":"ibmcld_16250-12497-14080","score":8.199275,"text":"\nAt that point, the system can respond by updating the relevant failover metadata to route traffic to the service instance in the other region. Once a failover happens, you can decide to continue using the new region as the active instance, or if you want to resume using the initial region once it has stabilized.\n\nFor an active\/active topology, some form of a load balancing can be used, where two or more service instances in unique regions always receive a percentage of traffic. Additional logic would need to be established to determine when to pull a region out of rotation. This monitoring logic could use a [circuit break pattern](https:\/\/martinfowler.com\/bliki\/CircuitBreaker.html) similar to the active\/passive configuration or rely on a separate dedicated monitoring framework that determines region health. Also similar to active\/passive, determining when to insert a region back in rotation would need to be considered as well.\n\n\n\n\n\n Failover for v2 stateful API \n\nFailover for the v2 stateful API is similar to stateless, with these details to consider:\n\n\n\n* The state of a given conversation is persisted by Watson Assistant in a database that is tied to a particular region. As such, a failover for the stateful v2 \/message may more disruptive.\n* For an active\/passive topology, you should assume that all in-progress conversations are ended.\n* For an active\/active topology, given the region-locked persistence constraints of the v2 stateful \/message architecture, all turns (\/message API calls) of a given conversation (session) should occur within the same region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_03036-7-2061","score":7.656567,"text":"\nMetrics overview \n\nThe Overview page provides a summary of the interactions between users and your assistant. You can view the amount of traffic for a given time period, as well as the intents and entities that were recognized most often in user conversations.\n\nThe Analytics page was introduced with version 1.5.0. The Analytics feature is supported only on clusters that are installed on Red Hat OpenShift 4.5 or later.\n\nUse the metrics to answer questions like:\n\n\n\n* What was the average number of conversations per week during the last month?\n* How often did customers need to go elsewhwere for support?\n* Which intents appeared most often last week?\n* Which entity values were recognized the most times during February?\n* Which days had the largest or smallest numbers of conversations in the last month?\n\n\n\nTo see metrics information, select Overview in the navigation bar.\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter. In each case, the data points on the graph adjust to an appropriate measurement period. For example, when viewing a graph for a day, the data is presented in hourly values, but when viewing a graph for a week, the data is shown by day. A week always runs from Sunday through Saturday.\n\nYou can create custom time periods also, such as a week that runs from Thursday to the following Wednesday, or a month that begins on any date other than the first.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03363-4413-6535","score":7.557133,"text":"\nFor more information, see [Ending the conversation gracefully](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-startdialog-start-anything-else).\n\nThe containment and coverage metrics are available to Plus or Enterprise plan users.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period. This number counts exchanges in which the welcome message is displayed to a user, even if the user doesn't respond.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter to be specified with the messages. This value is typically specified by all integrations because it is used for billing purposes. For more information, see [User-based plans explained](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-managing-planadmin-managing-plan-user-based).\n\n\n\n\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_16274-11413-13206","score":7.547966,"text":"\nenable_dtmf_barge_in dtmf, command_info.type : enable_barge_in \n disable_dtmf_barge_in dtmf, command_info.type : disable_barge_in \n hangup end_session \n\n\n\n\n\n\n\n assistant_interaction_summaries.turns[].response.streaming_statistics \n\nThe assistant_interaction_summaries.turns[].response.streaming_statistics object contains the following properties:\n\n\n\nProperties of the assistant_interaction_summaries.turns[].response.streaming_statistics object\n\n Property Type Description \n\n transaction_id String A unique identifier of the transaction. \n start_timestamp String The time when the transaction started, in ISO format (yyyy-MM-ddTHH:mm:ss.SSSZ). \n stop_timestamp String The time when the transaction ended, in ISO format (yyyy-MM-ddTHH:mm:ss.SSSZ). \n response_milliseconds Number The time (in milliseconds) between when a text utterance is sent to the assistant and when the phone integration receives the first packet of synthesized audio. \n\n\n\n\n\n\n\n\n\n\n\n\n\n warnings_and_errors \n\nThe warnings_and_errors object contains warnings and errors that were logged during the call, listed in order of occurrence. Warnings for the following conditions are included:\n\n\n\n* Messages when utterances are filtered out by the confidence score threshold.\n* Text to Speech underflows, which is when Text to Speech synthesis can't keep up with the phone integration streaming rate and audio might skip.\n* RTP network warnings, such as high packet loss or high average jitter, if RTCP is enabled.\n\n\n\nThe following example shows the structure of the warnings_and_errors object:\n\n\"warnings_and_errors\": [\n{\n\"message\": \"CWSMR0032W: A Watson Speech to Text final utterance has a confidence score of 0.1, which does not meet the confidence score threshold of 0.2. The utterance will be ignored.\",\n\"id\": \"CWSMR0032W\"\n},\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-cdr-log-reference"},{"document_id":"ibmcld_16250-1908-4265","score":7.384324,"text":"\nHowever, using an active\/active topology likely requires using [webhooks](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-webhook-overview) to gather interaction data, and build custom data warehouses and reports to understand total usage.\n\n\n\n\n\n Session history for web chat and the v2 api \n\nSession history allows your web chats to maintain conversation history and context when users refresh a page or change to a different page on the same website. This feature doesn't work across instances, so in-progress conversations need to be restarted.\n\n\n\n\n\n Billing \n\nIBM calculates your bill based on the IBM Cloud Account. Watson Assistant calculates monthly average user (MAU) metrics by aggregating within a given service instance as follows:\n\n\n\n* The same MAU used in 2 different assistant resources in the same service instance counts as 1 MAU\n* The same MAU used in 2 different assistant resources in different service instances counts as 2 MAUs\n\n\n\nNote that for an active\/active topology, under the worst case scenario, the MAU count could end up being doubled for a given billing period.\n\n\n\n\n\n\n\n Phone integration \n\nA Watson Assistant phone integration in one region is unaware of a phone integration in a different region. You need to ensure that your assistants are identically configured in both regions. You also need to rely on the upstream SIP trunking provider to detect and manage failing over between regions.\n\n\n\n Monitoring \n\nSIP trunking providers can be configured to actively health-check the Watson Assistant session border controllers (SBCs) by sending periodic SIP OPTIONS messages to each zone within a region. A failure to receive a response from one of the zones being health-checked can be used to either provide notification of a failure to trigger a manual failover, or it can be used to automate removal of the failed zone from the route list.\n\n\n\n\n\n Failover \n\nThe SIP trunking provider plays an important role in detecting and managing a failover, especially if an automatic failover is expected between regions. In most cases, SIP trunking providers should be configured to treat each zone within a region as active\/active and two regions where an assistant is configured as active\/passive. SIP trunking providers should always be configured to load balance and fail over between zones within a single region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1510196182,"ndcg_cut_10":0.1510196182}}
{"task_id":"1be66272113492407e814eaf21a761d4<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09712-2935-4685","score":11.997205,"text":"\nValid levels are: emergency, alert, critical, error, warning, notice, information, debug and none.\n\nThe values are listed from high priority to low priority.\n\nFor example, to filter out low severity events (notice, information, debug), you must set the log section event_priority to warning:\n\nlog:\nevent_priority: warning\n\nTo block collection of events, you must set the log section event_priority to none:\n\nlog:\nevent_priority: none\n\n\n\n\n\n Including and excluding metrics \n\nTo filter custom metrics, you must customize the metrics_filter section in the dragent.yaml file. You can specify which metrics to include and which ones to filter out by configuring the include and exclude filtering parameters.\n\nThe filtering rule order is set as follows: the first rule that matches a metric is applied.\n\nFor example, if the metrics_filter section of a monitoring agent looks as follows:\n\nmetrics_filter:\n- include: metricA.\n- exclude: metricA.\n- include: metricB.\n- include: haproxy.backend.\n- exclude: haproxy.\n- exclude: metricC.\n\n\n\n* You are configuring the monitoring agent to collect all data from metrics that start with metricA, metricB, and haproxy.backend.\n* You are filtering out metrics that start with metricC and other metrics that start with haproxy.\n* The entry exclude: metricA. is ignored.\n\n\n\n\n\n\n\n Changing the log level \n\nTo configure the log level, you must customize the log section in the dragent.yaml file.\n\nThe monitoring agent generates log entries in \/opt\/draios\/logs\/draios.log.\n\n\n\n* The log file rotates when it reaches 10MB in size.\n* The 10 most recent log files are kept. The date-stamp that is appended to the filename is used to determine which files to keep.\n* Valid log levels are: none, error, warning, info, debug, trace","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-change_agent"},{"document_id":"ibmcld_03036-2789-4951","score":11.953293,"text":"\nIf you have [selected a data source](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-logs-overview"},{"document_id":"ibmcld_03363-1671-3630","score":9.950266,"text":"\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overview"},{"document_id":"ibmcld_09713-6958-8931","score":9.9012985,"text":"\nFor example, if the metrics_filter section of a monitoring agent looks as follows:\n\nmetrics_filter:\n- include: metricA.\n- exclude: metricA.\n- include: metricB.\n- include: haproxy.backend.\n- exclude: haproxy.\n- exclude: metricC.\n\n\n\n* You are configuring the monitoring agent to collect all data from metrics that start with metricA, metricB, and haproxy.backend.\n* You are filtering out metrics that start with metricC and other metrics that start with haproxy.\n* The entry exclude: metricA. is ignored.\n\n\n\n4. Save the changes.\n\n\n\nChanges are applied automatically.\n\n\n\n\n\n Filtering kubernetes objects and containers from which data is collected \n\nA Kubernetes monitoring agent automatically collects metrics from all containers that it detects in a cluster, including Prometheus, StatsD, JMX, app-checks, and built-in metrics.\n\nYou can customize the monitoring agent to exclude containers from metrics collection.\n\nWhen you exclude containers, consider the following information:\n\n\n\n* You reduce agent and backend load.\n* You only collect data from containers that you want to monitor.\n* You can control costs by reporting on important containers, and filtering out unnecessary or not critical containers.\n\n\n\nTo enable the feature where a monitoring agent filters containers, you must customize the sysdig-agent-configmap.yaml file. Set the use_container_filter entry in the containers section to true. Note: By default, this feature is turned off. Then, define the rules that include one or more conditions and that you want to apply.\n\nThe following table outlines the parameters that you can define to set the filtering rules in a cluster:\n\n\n\nTable 1. Parameters to define conditions on containers\n\n Parameter Condition \n\n container.image Container image name \n container.name Container name \n container.label.* Container label \n kubernetes.object.* Kubernetes object. An object can be a pod, a namespace, etc. \n kubernetes.object.annotation.* Kubernetes object annotation","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-change_kube_agent"},{"document_id":"ibmcld_09714-2690-4253","score":9.696084,"text":"\n- include: haproxy.backend.\n- exclude: haproxy.\n- exclude: metricC.\n\n\n\n* You are configuring the monitoring agent to collect all data from metrics that start with metricA, metricB, and haproxy.backend.\n* You are filtering out metrics that start with metricC and other metrics that start with haproxy.\n* The entry exclude: metricA. is ignored.\n\n\n\n\n\n\n\n Changing the log level \n\nTo configure the log level, you must customize the log section in the dragent.yaml file.\n\nThe monitoring agent generates log entries in \/opt\/draios\/logs\/draios.log.\n\n\n\n* The log file rotates when it reaches 10MB in size.\n* The 10 most recent log files are kept. The date-stamp that is appended to the filename is used to determine which files to keep.\n* Valid log levels are: none, error, warning, info, debug, trace\n* The default log level is info, where an entry is created for each aggregated metrics transmission to the backend servers, once per second, in addition to entries for any warnings and errors.\n* You can customize the type of log and the entries that are collected by configuring the monitoring agent configuration file \/opt\/draios\/etc\/dragent.yaml. After you edit the file, you must restart the agent at the shell with service dragent restart to activate the changes.\n\n\n\n\n\nTable 2. Log section entries\n\n Use cases Log section entry \n\n Troubleshoot agent behavior file_priority: debug \n Reduce container console output console_priority: warning \n Filtering events by severity event_priority: warning \n Verify what metrics are included or excluded metrics_excess_log: true","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-change_linux_agent"},{"document_id":"ibmcld_09701-3585-5036","score":9.695623,"text":"\n\"filter\": null,\n\"type\": \"MANUAL\",\n\"condition\": \"avg(timeAvg(uptime)) <= 0\",\n\"timespan\": 600000000,\n\"notificationChannelIds\": [],\n\"reNotify\": false,\n\"reNotifyMinutes\": 30,\n\"segmentBy\": [\n\"host.hostName\"\n],\n\"segmentCondition\": {\n\"type\": \"ANY\"\n},\n\"severityLabel\": \"LOW\"\n}\n}\n\n\n\n\n\n Update an alert \n\nTo update an existing alert, you need the ID of that alert.\n\nYou can use the following cURL command to update an alert:\n\ncurl -X PUT <REST_API_ENDPOINT>\/api\/alerts\/<ALERT_ID> -H \"Authorization: $AUTH_TOKEN\" -H \"IBMInstanceID: $GUID\" -H \"TeamID: $TEAM_ID\" -H \"content-type: application\/json\" -d @alert.json\n\nWhere\n\n\n\n* <REST_API_ENDPOINT> indicates the endpoint targetted by the REST API call. For more information, see [Monitoring REST API endpoints](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-endpointsendpoints_rest_api). For example, the public endpoint for an instance that is available in us-south is the following: https:\/\/us-south.monitoring.cloud.ibm.com\/api\n* You can pass multiple headers by using -H.\n\nAuthorization and IBMInstanceID are headers that are required for authentication.\n\nTeamID is optional. When you specify this header, you limit the request to the data and resources available for the team specified.\n\nTo get an AUTH_TOKEN and the GUID see, [Headers for IAM Tokens](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-mon-curlmon-curl-headers-iam).\n* <ALERT_ID> defines the ID of the alert that you want to modify.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_api"},{"document_id":"ibmcld_09714-1379-3063","score":9.617063,"text":"\nThe yaml file is loacated in \/opt\/draios\/etc\/.\n\nComplete the following steps to edit the file and apply the changes:\n\n\n\n1. Access the dragent.yaml directly. The file is located in \/opt\/draios\/etc\/dragent.yaml.\n2. Edit the file. Use valid YAML syntax.\n3. Restart the agent. Run the following command:\n\nservice dragent restart\n\n\n\n\n\n\n\n Blocking ports \n\nTo block network traffic and metrics from network ports, you must customize the blacklisted_ports section in the dragent.yaml file. You must list the ports from which you want to filter out any data.\n\nNote: Port 53 (DNS) is always blacklisted.\n\nFor example, the following sample shows how to set the blacklisted_ports section of a monitoring agent to exclude data coming from ports 6666 and 6379:\n\nblacklisted_ports:\n- 6666\n- 6379\n\n\n\n\n\n Including and excluding metrics \n\nTo filter custom metrics, you must customize the metrics_filter section in the dragent.yaml file. You can specify which metrics to include and which ones to filter out by configuring the include and exclude filtering parameters.\n\nNote: The filtering rule order is set as follows: the first rule that matches a metric is applied.\n\nFor example, if the metrics_filter section of a monitoring agent looks as follows:\n\nmetrics_filter:\n- include: metricA.\n- exclude: metricA.\n- include: metricB.\n- include: haproxy.backend.\n- exclude: haproxy.\n- exclude: metricC.\n\n\n\n* You are configuring the monitoring agent to collect all data from metrics that start with metricA, metricB, and haproxy.backend.\n* You are filtering out metrics that start with metricC and other metrics that start with haproxy.\n* The entry exclude: metricA. is ignored.\n\n\n\n\n\n\n\n Changing the log level","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-change_linux_agent"},{"document_id":"ibmcld_09713-13038-14918","score":9.27418,"text":"\n* The event_priority in the log section controls the type of events that are sent from the agent\n* The default log level is information. This means that only information and higher severity events are transmitted.\n* Valid levels are: emergency, alert, critical, error, warning, notice, information, debug and none. Note: The values are listed from high priority to low priority.\n* Setting the level to none will block all event collection.\n\n\n\n\n\n\n\n Logging into a file what metrics are included or excluded \n\n\n\n* Setting metrics_excess_log to true in the log section will enable logging of the custom metrics that are included or excluded.\n* Metric logging is disabled by default.\n* Logging occurs at INFO-level every 30 seconds and lasts for 10 seconds.\n* The metricsfile setting is required to specify the location for the metrics to be written by the agent. The metricsfile.location value is a relative path under the \/opt\/draios directory. Note: The metricsfile entry is specified at the same level as log( not as a child in the yaml)\n* Logging data is formatted as follows:\n\n+\/-[type] [metric included\/excluded]: metric.name (filter: +\/-[metric.filter])\n\n\n\n* +\/- is a symbol that indicates if the metric is included or excluded. Plus (+) indicates that a metric is included. Minus (-) indicates that a metric is excluded.\n* [type] specifies the metric type, for example, statsd.\n* [metric included\/excluded] indicates in a human readable way whether the metric is included or excluded.\n* metric.name indicates the metric name.\n* (filter: +\/-[metric.filter]) provides information about any filters that are defined in the metrics_filter section in the sysdig-agent-configmap.yaml file.\n\n\n\n\n\nA sample log entry looks as follows:\n\n-[statsd] metric excluded: mongo.statsd.vsize (filter: -[mongo.statsd.])\n+[statsd] metric included: mongo.statsd.netIn (filter: +[mongo.statsd.net])","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-change_kube_agent"},{"document_id":"ibmcld_16727-744831-746741","score":9.007088,"text":"\nLogs that are filtered out (excluded) are not archived and are not available for search. You do not pay for log lines that are filtered out.\n\nThere are different ways in which you can filter out logs sent to Log Analysis:\n\n\n\n* You can [configure the agent to drop logs](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-exclude_logs_from_agent) before sending them to the Log Analysis service.\n* If you send logs to the Log Analysis service, you can define [exclusion rules](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-exclusion_rules) to drop logs before they are stored for search.\n\n\n\n* You can drop the log lines entirely and not see them at all through the UI.\n* You can view the log lines in the UI, but you cannot search on them. However, you can define views and alerts based on the data from these logs.\n\n\n\n* You can also configure [usage quotas](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-control_usage_quotas) and define conditional usage quota exclusion rules.\n\n\n\n\n\nMonitoring\n\n\n\n* Where can I find the list of Cloud services that generate metrics?\n\nYou can find information about the services that generate metrics in the following documentation topic: [Cloud services](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-cloud_services).\n* Are you seeing errors when there are no problems?\n\nAre you observing monitoring agent connection errors or receiving uptime alerts reporting an host is down when there are no problems?\n\nIBM Cloud Monitoring has identified an issue with a subset of agent versions:\n\n\n\n* monitoring agent 10.3.0\n* monitoring agent 10.3.1\n* monitoring agent 10.4.0\n* monitoring agent 10.4.1\n\n\n\nWhere connectivity between your infrastructure and Monitoring's hosted service may fail.\n\nYou must upgrade all monitoring agents to 10.5. [Learn more](https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-troubleshoottroubleshoot-entry-3).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_09713-10056-11782","score":8.997039,"text":"\nAdd the use_container_filter entry and container_filter section or update the the existing entries.\n\nFor example, see the following extract of a config map:\n\n Enable the feature\nuse_container_filter: true\n\n Include or exclude conditions\ncontainer_filter:\n- include:\ncontainer.image: appdomain\/my-app-image\n- include:\ncontainer.name: my-java-app\n- exclude:\nkubernetes.namespace.name: kube-system\n4. Save the changes.\n\n\n\nChanges are applied automatically.\n\n\n\n\n\n Blocking ports \n\nTo block network traffic and metrics from network ports, you must customize the blacklisted_ports section in the sysdig-agent-configmap.yaml file. You must list the ports from which you want to filter out any data.\n\nPort 53 (DNS) is always in the blocklist and does not need to be specified in the blacklisted_ports.\n\nComplete the following steps:\n\n\n\n1. Set up the cluster environment. Run the following commands:\n\nFirst, get the command to set the environment variable and download the Kubernetes configuration files.\n\nibmcloud ks cluster config --cluster <cluster_name_or_ID>\n2. Edit the sysdig-agent-configmap.yaml file.\n\nRun the following command:\n\nkubectl edit configmap sysdig-agent -n ibm-observe\n3. Make changes. Add the metrics_filter section or update the section.\n\nFor example, the following sample shows how to set the blacklisted_ports section of a monitoring agent to exclude data coming from ports 6666 and 6379:\n\nblacklisted_ports:\n- 6666\n- 6379\n4. Save the changes.\n\n\n\nChanges are applied automatically.\n\n\n\n\n\n Changing the log configurations \n\nTo configure the log configurations, you must customize the log section in the sysdig-agent-configmap.yaml file.\n\nThe monitoring agent generates log entries in \/opt\/draios\/logs\/draios.log.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-change_kube_agent"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03120-4813-6717","score":15.400718,"text":"\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions. For a dialog skill, add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Phone integration: If you want to deploy an assistant that uses the universal language model with the phone integration, you must connect to custom Speech service language models that can understand the language you're using. For more information about supported language models, see the [Speech to Text](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-modelsmodelsList) and [Text to Speech](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices) documentation.\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_16364-163116-165172","score":14.956075,"text":"\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them. For more information, see [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add).\n\n\n\n* Assistants: You can now publish your skill in just two steps. Add your skill to an assistant, and then set up one or more integrations with which to deploy your skill. The assistant adds a layer of function to your skill that enables Watson Assistant to orchestrate and manage the flow of information for you. See [Assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants).\n* Built-in integrations: Instead of going to the Deploy tab to deploy your workspace, you add your dialog skill to an assistant, and add integrations to the assistant through which the skill is made available to your users. You do not need to build a custom front-end application and manage the conversation state from one call to the next. However, you can still do so if you want to. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more information.\n* New major API version: A V2 version of the API is available. This version provides access to methods you can use to interact with an assistant at run time. No more passing context with each API call; the session state is managed for you as part of the assistant layer.\n\n\n\nWhat is presented in the tooling as a dialog skill is effectively a wrapper for a V1 workspace. There are currently no API methods for authoring skills and assistants with the V2 API. However, you can continue to use the V1 API for authoring workspaces.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03049-2703-4536","score":14.886095,"text":"\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).\n* To define your own intents, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Troubleshooting skill import issues \n\nIf you receive warnings when you try to upload a skill, take a moment to try to fix the issues.\n\n\n\n1. Make a note of the warning message that are displayed when you try to upload the JSON file.\n2. Edit the skill to address the issues.\n\n\n\n* If you have access to a public service instance, open the skill from there and make edits. Export the edited skill by downloading it.\n* Otherwise, open the JSON file in a text editor and make edits.\n\n\n\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03126-3707-6008","score":14.783084,"text":"\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_03120-3469-5331","score":14.515486,"text":"\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_03369-16079-18117","score":14.3198805,"text":"\n: The dialog feature is available in the new Watson Assistant experience. If you have a dialog-based assistant that was built using the classic Watson Assistant, you can now migrate your dialog skill to the new Watson Assistant experience. For more information, see [Migrating to the new experience](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-migrate-overview).\n\n\n\n\n\n 25 March 2022 \n\nImproved irrelevance detection for Dutch\n: Irrelevance detection for Dutch disregards any punctuation in an input sentence. For example, you can now expect the same confidence score for the following two inputs: ik ben een kleine krijger? and ik ben een kleine krijger. In this example, the question mark (?) doesn't affect the confidence score.\n\nImproved enhanced intent detection\n: The exact match in enhanced intent detection now better handles small differences between training examples and runtime utterances when the differences do not change the meaning of a sentence.\n\nFor example, suppose in your training examples, covid-19 is in the covid intent and @doctortype_facilitytype around Palm Beach is in the find_provide_master intent. In this example, the @doctortype_facilitytype direct entity reference contains entity values, including hospital. At run time, covid19 is predicted as 100% confident for the covid intent, and hospital around palm beach is predicted as 100% confident for the find_provide_master intent.\n\nThis update applies to the following languages: English, French, Spanish, Italian, and the universal language model. For more information, see [Accessing intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-expression-languageexpression-language-intent).\n\n\n\n\n\n 23 March 2022 \n\nFuzzy matching updates\n: Previously, an update was made so that interactions between the stemming and misspelling fuzzy matching features were not allowed. This change applied to the following languages: English, French, German, and Czech. This was updated so that this change applies only to the English language.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-101992-104197","score":14.314502,"text":"\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time. For more information, see [Improved intent recognition](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intent-detection).\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_02841-1435-2454","score":13.657597,"text":"\n[A sample dialog tree with example content](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/dialog-depiction.png) \n\n\n\nThe dialog skill itself is defined in text, but you can integrate it with Watson Speech to Text and Watson Text to Speech services that enable users to interact with your assistant verbally.\n\n![Out-of-the-box training data](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oob.png) If you want to get started quickly, add prebuilt training data to your dialog skill so your assistant can start helping your customers with the basics.\n\n\n\n\n\n Search skill \n\nA search skill leverages information from existing corporate knowledge bases or other collections of content authored by subject matter experts to address unanticipated or more nuanced customer inquiries.\n\nSee [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add) to get started.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistants"},{"document_id":"ibmcld_03329-1102-2607","score":13.642882,"text":"\n[Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n![Add actions or dialog skill button](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-addskill.png)\n2. Give your skill the name My first skill.\n3. Optional. If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n4. For skill type, choose Dialog.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-add-skill-done.png)\n5. Click Create skill.\n\nThe skill is created and appears in your assistant.\n\n\n\n\n\n\n\n Step 3: Add intents from a content catalog \n\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-gs-dialog"},{"document_id":"ibmcld_03049-7-1790","score":13.631695,"text":"\nAdding a dialog skill \n\nThe natural-language processing for the Watson Assistant service is defined in a dialog skill, which is a container for all of the artifacts that define a conversation flow.\n\nYou can add one dialog skill to an assistant.\n\n\n\n Create the dialog skill \n\nYou can create a skill from scratch, use a sample skill that is provided by IBM, or import a skill from a JSON file.\n\nTo add a skill, complete the following steps:\n\n\n\n1. Click the Skills icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-skills-icon.png).\n\nv1.3: Click the Skills tab. If you don't see the Skills tab, click the breadcrumb link in the page header.\n2. Click Create skill.\n3. Select the dialog skill option, and then click Next.\n4. Take one of the following actions:\n\n\n\n* To create a skill from scratch, click Create skill.\n* To add a sample skill that is provided with the product as a starting point for your own skill or as an example to explore before you create one yourself, click Use sample skill, and then click the sample you want to use.\n\nThe sample skill is added to your list of skills. It is not associated with any assistants. Skip the remaining steps in this procedure.\n* To add an existing skill to this service instance, you can import it as a JSON file. Click Import skill, and then click Choose JSON File, and select the JSON file you want to import.\n\nImportant:\n\n\n\n* The imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding.\n* The maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider importing the intents and entities separately after you have imported the skill. (You can also import larger skills using the REST API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.234639363,"ndcg_cut_10":0.391065605}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02839-1790-3940","score":15.017662,"text":"\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03120-3469-5331","score":14.110379,"text":"\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_03120-1659-3917","score":13.203644,"text":"\nThe precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website. Deploy your German-speaking assistant to the German page of your website. Maybe you have a support phone number for French customers. You can configure your French-speaking assistant to answer those calls, and configure another phone number that German customers can use.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_02839-7-2335","score":12.46603,"text":"\nAdding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03353-5263-7331","score":12.240745,"text":"\nItalian (it) GA Deprecated \n Japanese (ja) GA Deprecated \n Korean (ko) GA Deprecated \n Portuguese (Brazilian) (pt-br) GA Deprecated \n Spanish (es) GA Deprecated \n Universal (xx) GA NA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the tool interface itself (descriptions, labels, etc.) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee has mandated that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing a skill language \n\nOnce a skill has been created, its language cannot be modified. If it is necessary to change the supported language of a skill, you can do so by editing the skill's underlying JSON.\n\nTo change the skill language, take the following steps:\n\n\n\n1. Download the skill that you want to edit.\n2. Open the downloaded skill JSON file in a text editor.\n3. Search for the property named language.\n\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_02839-3583-5403","score":11.910199,"text":"\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03027-4976-6968","score":11.888503,"text":"\nEnglish (en) GA Deprecated \n Arabic (ar) GA Deprecated \n Chinese (Simplified) (zh-cn) GA Deprecated \n Chinese (Traditional) (zh-tw) GA Deprecated \n Czech (cs) GA Deprecated \n Dutch (nl) GA Deprecated \n French (fr) GA Deprecated \n German (de) GA Deprecated \n Italian (it) GA Deprecated \n Japanese (ja) GA Deprecated \n Korean (ko) GA Deprecated \n Portuguese (Brazilian) (pt-br) GA Deprecated \n Spanish (es) GA Deprecated \n Universal (xx) GA NA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the tool interface itself (descriptions, labels, etc.) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee has mandated that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing a skill language \n\nOnce a skill has been created, its language cannot be modified. If it is necessary to change the supported language of a skill, you can do so by editing the skill's underlying JSON.\n\nTo change the skill language, take the following steps:\n\n\n\n1. Download the skill that you want to edit.\n2. Open the downloaded skill JSON file in a text editor.\n3. Search for the property named language.\n\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_03027-7-1946","score":11.888348,"text":"\nSupported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Dialog skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add) [Search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add) \n\n English (en) GA GA \n Arabic (ar) GA GA \n Chinese (Simplified) (zh-cn) GA GA \n Chinese (Traditional) (zh-tw) GA GA \n Czech (cs) GA GA \n Dutch (nl) GA GA \n French (fr) GA GA \n German (de) GA GA \n Italian (it) GA GA \n Japanese (ja) GA GA","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support"},{"document_id":"ibmcld_03120-4813-6717","score":11.847479,"text":"\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions. For a dialog skill, add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Phone integration: If you want to deploy an assistant that uses the universal language model with the phone integration, you must connect to custom Speech service language models that can understand the language you're using. For more information about supported language models, see the [Speech to Text](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-modelsmodelsList) and [Text to Speech](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices) documentation.\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_03369-52023-54183","score":11.666013,"text":"\nSupport for every language!\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it.\n\nThe universal model is available as a beta feature. For more information, see [Understanding the universal language model](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\nActions skill improvement\n: Now you can indicate whether or not to ask for a number when you apply a number reply constraint to a step. Test how changes to this setting might help speed up a customer's interaction. Under the right circumstances, it can be useful to let a number mention be recognized and stored without having to explicitly ask the customer for it.\n\n\n\n\n\n 1 March 2021 \n\nIntroducing the Enterprise plan!\n: The Enterprise plan includes all of the market differentiating features of the Plus plan, but with higher capacity limits, additional security features, custom onboarding support to get you going, and a lower overall cost at higher volumes.\n\nTo have a dedicated environment provisioned for your business, request the Enterprise with Data Isolation plan. To submit a request online, go to [http:\/\/ibm.biz\/contact-wa-enterprise](http:\/\/ibm.biz\/contact-wa-enterprise).\n\nThe Enterprise plan is replacing the Premium plan. The Premium plan is being retired today. Existing Premium plan users are not impacted. They can continue to work in their Premium instances and create instances up to the 30-instance limit. New users do not see the Premium plan as an option when they create a service instance.\n\nFor more information, see the [Pricing](https:\/\/www.ibm.com\/cloud\/watson-assistant\/pricing\/) page.\n\nOther plan changes\n: Our pricing has been revised to reflect the features we've added that help you build an assistant that functions as a powerful omnichannel SaaS application.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03049-2703-4536","score":12.587481,"text":"\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).\n* To define your own intents, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Troubleshooting skill import issues \n\nIf you receive warnings when you try to upload a skill, take a moment to try to fix the issues.\n\n\n\n1. Make a note of the warning message that are displayed when you try to upload the JSON file.\n2. Edit the skill to address the issues.\n\n\n\n* If you have access to a public service instance, open the skill from there and make edits. Export the edited skill by downloading it.\n* Otherwise, open the JSON file in a text editor and make edits.\n\n\n\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_16364-127333-129289","score":11.678481,"text":"\n: Previously, if you included a response type of Search skill in a list of response types for a dialog node, the search results were displayed last despite its placement in the list. This behavior was changed to show the search results in the appropriate order, namely in the sequence in which the search skill response type is listed for the dialog node.\n\n\n\n\n\n 10 March 2020 \n\nContextual entity support is generally available\n: You can add contextual entities to English-language dialog skills. For more information about contextual entities, see [Creating entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-annotations-overview).\n\nFrench language support added for autocorrection\n: Autocorrection helps your assistant understand what your customers want. It corrects misspellings in the input that customers submit before the input is evaluated. With more precise input, your assistant can more easily recognize entity mentions and understand the customer's intent. See [Correcting user input](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-spell-check) for more details.\n\nThe new system entities are used by new skills\n: For new English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills, the new system entities are enabled automatically. If you decide to turn on a system entity and add it to your dialog, it's the new and improved version of the system entity that is used. For more information, see [New system entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 6 March 2020 \n\nTransfer a web chat conversation to a human agent\n: Delight your customers with 360-degree support by integrating your web chat with a third-party service desk solution. When a customer asks to speak to a person, you can connect them to an agent through a service desk solution, such as Zendesk or Salesforce. Service desk support is a beta feature.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03049-7-1790","score":11.58857,"text":"\nAdding a dialog skill \n\nThe natural-language processing for the Watson Assistant service is defined in a dialog skill, which is a container for all of the artifacts that define a conversation flow.\n\nYou can add one dialog skill to an assistant.\n\n\n\n Create the dialog skill \n\nYou can create a skill from scratch, use a sample skill that is provided by IBM, or import a skill from a JSON file.\n\nTo add a skill, complete the following steps:\n\n\n\n1. Click the Skills icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-skills-icon.png).\n\nv1.3: Click the Skills tab. If you don't see the Skills tab, click the breadcrumb link in the page header.\n2. Click Create skill.\n3. Select the dialog skill option, and then click Next.\n4. Take one of the following actions:\n\n\n\n* To create a skill from scratch, click Create skill.\n* To add a sample skill that is provided with the product as a starting point for your own skill or as an example to explore before you create one yourself, click Use sample skill, and then click the sample you want to use.\n\nThe sample skill is added to your list of skills. It is not associated with any assistants. Skip the remaining steps in this procedure.\n* To add an existing skill to this service instance, you can import it as a JSON file. Click Import skill, and then click Choose JSON File, and select the JSON file you want to import.\n\nImportant:\n\n\n\n* The imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding.\n* The maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider importing the intents and entities separately after you have imported the skill. (You can also import larger skills using the REST API.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03369-108318-110450","score":11.520856,"text":"\nYou can use this method to extract a specific occurrence of a regular expression pattern that recurs in user input. For more details, see the [dialog methods](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-methodsdialog-methods-strings-getMatch) topic.\n\n\n\n\n\n 9 August 2019 \n\nIntroductory product tour\n: For some first-time users, a new introductory product tour is shown that the user can choose to follow to perform the initial steps of creating an assistant.\n\n\n\n\n\n 6 August 2019 \n\n\n\n* Webhook callouts and Dialog page improvements are available in Dallas.\n\n\n\n\n\n\n\n 1 August 2019 \n\nWebhook callouts are available\n: Add webhooks to dialog nodes to make programmatic calls to an external application as part of the conversational flow. The new Webhook support simplifies the callout implementation process. (No more action JSON objects required.) For more information, see [Making a programmatic call from a dialog node](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-webhooks).\n\nImproved dialog page responsiveness\n: In all service instances, the user interface of the Dialog page was updated to use a new JavaScript library that increases the page responsiveness. As a result, the look of some graphical user interface elements, such as buttons, changed slightly, but the function did not.\n\n\n\n\n\n 31 July 2019 \n\nSearch skill and autocorrection are generally available\n: The search skill and spelling autocorrection features, which were previously available as beta features, are now generally available.\n\n\n\n* Search skills can be created by users of Plus or Premium plans only.\n* You can enable autocorrection for English-language dialog skills only. It is enabled automatically for new English-language dialog skills.\n\n\n\n\n\n\n\n 26 July 2019 \n\nMissing skills issue is resolved\n: In some cases, workspaces that were created through the API only were not being displayed when you opened the Watson Assistant user interface. This issue has been addressed. All workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-163116-165172","score":11.508357,"text":"\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them. For more information, see [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add).\n\n\n\n* Assistants: You can now publish your skill in just two steps. Add your skill to an assistant, and then set up one or more integrations with which to deploy your skill. The assistant adds a layer of function to your skill that enables Watson Assistant to orchestrate and manage the flow of information for you. See [Assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants).\n* Built-in integrations: Instead of going to the Deploy tab to deploy your workspace, you add your dialog skill to an assistant, and add integrations to the assistant through which the skill is made available to your users. You do not need to build a custom front-end application and manage the conversation state from one call to the next. However, you can still do so if you want to. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more information.\n* New major API version: A V2 version of the API is available. This version provides access to methods you can use to interact with an assistant at run time. No more passing context with each API call; the session state is managed for you as part of the assistant layer.\n\n\n\nWhat is presented in the tooling as a dialog skill is effectively a wrapper for a V1 workspace. There are currently no API methods for authoring skills and assistants with the V2 API. However, you can continue to use the V1 API for authoring workspaces.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03369-74273-76338","score":11.358182,"text":"\n: Try the new autolearning beta feature to empower your skill to improve itself automatically over time. Your skill observes customer choices to understand which choices are most often the best. As its confidence grows, your skill presents better options to get the right answers to your customers with fewer clicks. For more information, see [Empower your skill to learn over time](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-autolearn).\n\nShow more of search results\n: When search results are returned from the search skill, the customer can now click a twistie to expand the search result card to see more of the returned text.\n\n\n\n\n\n 29 July 2020 \n\nThe @sys-location and @sys-person system entities were removed\n: The @sys-location and @sys-person system entities are no longer listed on the System entities page. If your dialog uses one of these entities, a red Entity not created notification is displayed to inform you that the entity is not recognized.\n\nSkill menu actions moved\n: The menu that was displayed in the header of the skill while you were working with a skill was removed. The actions that were available from the menu, such as import and export, are still available. Go to the Skills page, and click the menu on the skill tile.\n\nThe import skill process was updated to support overwriting an existing skill on import. For more information, see [Overwriting a skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-overwrite).\n\nDialog issues were addressed\n: These dialog issues were addressed:\n\n\n\n* Fixed an issue with adding a jump-to from a conditional response in one node to a conditional response in another node.\n* The page now responds better when you scroll horizontally to see multiple levels of child nodes.\n\n\n\n\n\n\n\n 15 July 2020 \n\nSupport ended for @sys-location and @sys-person\n: The person and location system entities, which were available as a beta feature in English dialog skills only, are no longer supported. You cannot enable them. If your dialog uses them, they are ignored by the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03369-109994-112063","score":11.353261,"text":"\nIt is enabled automatically for new English-language dialog skills.\n\n\n\n\n\n\n\n 26 July 2019 \n\nMissing skills issue is resolved\n: In some cases, workspaces that were created through the API only were not being displayed when you opened the Watson Assistant user interface. This issue has been addressed. All workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do. For more information about disambiguation, see [Disambiguation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation).\n\nDialog search issue\n: In some skills, the search function is not working in the Dialog page. A new user interface library, which increases the page responsiveness, is being rolled out to existing service instances in phases. This search issue affects only dialog skills for which the new library is not yet enabled.\n\nMissing skills issue\n: In some cases, workspaces that were created through the API only are not being displayed when you open the Watson Assistant user interface. Normally, these workspaces are displayed as dialog skills. If you do not see your skills from the UI, don't worry; they are not gone. Contact support to report the issue, so the team can enable the workspaces to be displayed properly.\n\n\n\n\n\n 15 July 2019 \n\nNumeric system entities upgrade available in Dallas\n: The new system entities are now also available as a beta feature for instances that are hosted in Dallas. See [New system entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entities)\n\n\n\n\n\n 12 June 2019 \n\nNumeric system entities upgrade\n: New system entities are available as a beta feature that you can enable in dialog skills that are written in English or German.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03120-3469-5331","score":11.217858,"text":"\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_03354-4186-6431","score":11.20714,"text":"\n[Open conversation panel that shows the original text for a term to which spelling correction logic was applied](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/open_convo_spellchecked.jpg)\n\n\n\n\n\n Improving across assistants \n\nCreating a dialog skill is an iterative process. While you develop your skill, you use the Try it out pane to verify that your assistant recognizes the correct intents and entities in test inputs, and to make corrections as needed.\n\nFrom the User conversations page, you can analyze actual interactions between the assistant you used to deploy the skill and your users. Based on those interactions, you can make corrections to improve the accuracy with which intents and entities are recognized by your dialog skill. It is difficult to know exactly how your users will ask questions, or what random messages they might submit, so it is important to frequently analyze real conversations to improve your dialog skills.\n\nFor a Watson Assistant instance that includes multiple assistants, there might be times when it is useful to use message data from the dialog skill of one assistant to improve the dialog skill used by another assistant within that same instance.\n\nAs an example, say you have a Watson Assistant instance named HelpDesk. You might have both a Production assistant and a Development assistant in your HelpDesk instance. When working in the dialog skill for the Development assistant, you can use logs from the Production assistant messages to improve the Development assistant's dialog skill.\n\nAny edits you then make within the dialog skill for the Development assistant will only affect the Development assistant's dialog skill, even though you\u2019re using data from messages sent to the Production assistant.\n\nSimilarly, if you create multiple versions of a skill, you might want to use message data from one version to improve the training data of another version.\n\nYou cannot access log data from assistants that were created in other service instances.\n\n\n\n Picking a data source \n\nThe term data source refers to the logs compiled from conversations between customers and the assistant or custom application by which a dialog skill was deployed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs"},{"document_id":"ibmcld_03329-1102-2607","score":11.201023,"text":"\n[Finish creating the new assistant](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n![Add actions or dialog skill button](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-addskill.png)\n2. Give your skill the name My first skill.\n3. Optional. If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n4. For skill type, choose Dialog.\n\n![Finish creating the skill](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/gs-add-skill-done.png)\n5. Click Create skill.\n\nThe skill is created and appears in your assistant.\n\n\n\n\n\n\n\n Step 3: Add intents from a content catalog \n\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-gs-dialog"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02839-1790-3940","score":14.848714,"text":"\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03120-3469-5331","score":14.653212,"text":"\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_02839-3583-5403","score":13.528242,"text":"\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_03120-1659-3917","score":11.94812,"text":"\nThe precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\nFor example, use the web chat integration with your French-speaking assistant to deploy to a French-language page on your website. Deploy your German-speaking assistant to the German page of your website. Maybe you have a support phone number for French customers. You can configure your French-speaking assistant to answer those calls, and configure another phone number that German customers can use.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_02839-7-2335","score":11.783767,"text":"\nAdding support for global audiences \n\nYour customers come from all around the globe. You need an assistant that can talk to them in their own language and in a familiar style. Choose the approach that best fits your business needs.\n\n\n\n* Quickest solution: The simplest way to add language support is to author the conversational skill in a single language. You can translate each message that is sent to your assistant from the customer's local language to the skill language. Later you can translate each response from the skill language back to the customer's local language.\n\nThis approach simplifies the process of authoring and maintaining the conversational skill. You can build one skill and use it for all languages. However, the intention and meaning of the customer message can be lost in the translation.\n\nFor more information about webhooks you can use for translation, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-webhook-overview).\n* Most precise solution: If you have the time and resources, the best user experience can be achieved when you build multiple conversational skills, one for each language that you want to support. Watson Assistant has built-in support for all languages. Use one of 13 language-specific models or the universal model, which adapts to any other language you want to support.\n\nWhen you build a skill that is dedicated to a language, a language-specific classifier model is used by the skill. The precision of the model means that your assistant can better understand and recognize the goals of even the most colloquial message from a customer.\n\nUse the new universal language model to create an assistant that is fluent even in languages that Watson Assistant doesn't support with built-in models.\n\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-language"},{"document_id":"ibmcld_09913-7-1696","score":11.768234,"text":"\nLanguage support \n\nNatural Language Understanding supports a variety of languages depending on which features you analyze. Currently, English is the only language that is supported across all features. The rest of the languages have limited support. To jump to the list of features that are compatible with a language, click the language in the following list.\n\n\n\n* [Arabic](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportarabic)\n* [Chinese (Simplified)](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportchinese-simplified)\n* [Czech](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportczech)\n* [Danish](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportdanish)\n* [Dutch](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportdutch)\n* [English](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportenglish)\n* [Finnish](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportfinnish)\n* [French](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportfrench)\n* [German](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportgerman)\n* [Hebrew](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supporthebrew)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"},{"document_id":"ibmcld_03369-52023-54183","score":11.549215,"text":"\nSupport for every language!\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it.\n\nThe universal model is available as a beta feature. For more information, see [Understanding the universal language model](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\nActions skill improvement\n: Now you can indicate whether or not to ask for a number when you apply a number reply constraint to a step. Test how changes to this setting might help speed up a customer's interaction. Under the right circumstances, it can be useful to let a number mention be recognized and stored without having to explicitly ask the customer for it.\n\n\n\n\n\n 1 March 2021 \n\nIntroducing the Enterprise plan!\n: The Enterprise plan includes all of the market differentiating features of the Plus plan, but with higher capacity limits, additional security features, custom onboarding support to get you going, and a lower overall cost at higher volumes.\n\nTo have a dedicated environment provisioned for your business, request the Enterprise with Data Isolation plan. To submit a request online, go to [http:\/\/ibm.biz\/contact-wa-enterprise](http:\/\/ibm.biz\/contact-wa-enterprise).\n\nThe Enterprise plan is replacing the Premium plan. The Premium plan is being retired today. Existing Premium plan users are not impacted. They can continue to work in their Premium instances and create instances up to the 30-instance limit. New users do not see the Premium plan as an option when they create a service instance.\n\nFor more information, see the [Pricing](https:\/\/www.ibm.com\/cloud\/watson-assistant\/pricing\/) page.\n\nOther plan changes\n: Our pricing has been revised to reflect the features we've added that help you build an assistant that functions as a powerful omnichannel SaaS application.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03126-3707-6008","score":11.281507,"text":"\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_03120-4813-6717","score":11.0251255,"text":"\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions. For a dialog skill, add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Phone integration: If you want to deploy an assistant that uses the universal language model with the phone integration, you must connect to custom Speech service language models that can understand the language you're using. For more information about supported language models, see the [Speech to Text](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-modelsmodelsList) and [Text to Speech](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices) documentation.\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_03353-5263-7331","score":11.012994,"text":"\nItalian (it) GA Deprecated \n Japanese (ja) GA Deprecated \n Korean (ko) GA Deprecated \n Portuguese (Brazilian) (pt-br) GA Deprecated \n Spanish (es) GA Deprecated \n Universal (xx) GA NA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the tool interface itself (descriptions, labels, etc.) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee has mandated that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing a skill language \n\nOnce a skill has been created, its language cannot be modified. If it is necessary to change the supported language of a skill, you can do so by editing the skill's underlying JSON.\n\nTo change the skill language, take the following steps:\n\n\n\n1. Download the skill that you want to edit.\n2. Open the downloaded skill JSON file in a text editor.\n3. Search for the property named language.\n\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"}],"retriever_scores":{"recall_1":0.2,"recall_3":0.2,"recall_5":0.4,"recall_10":0.6,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.4852285551,"ndcg_cut_10":0.5982819569}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13429-155971-158020","score":12.050986,"text":"\nNew sort parameter for methods that list words for custom language models\n: The GET \/v1\/customizations\/{customization_id}\/words method now includes a sort query parameter that controls the order in which the words are to be listed. The parameter accepts two arguments, alphabetical or count, to indicate how the words are to be sorted. You can prepend an optional + or - to an argument to indicate whether the results are to be sorted in ascending or descending order. By default, the method displays the words in ascending alphabetical order. For more information, see [Listing custom words from a custom language model](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-manageWordslistWords).\n\nFor custom models created prior to the introduction of the count field, use of the count argument with the sort parameter is meaningless. Use the default alphabetical argument with such models.\n\nNew error field format for methods that list words for custom language models\n: The error field that can be returned as part of the JSON response from the GET \/v1\/customizations\/{customization_id}\/words and GET \/v1\/customizations\/{customization_id}\/words\/{word_name} methods is now an array. If the service discovered one or more problems with a custom word's definition, the field lists each problem element from the definition and provides a message that describes the problem. For more information, see [Listing custom words from a custom language model](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-manageWordslistWords).\n\nThe keywords_threshold and word_alternatives_threshold parameters no longer accept a null value\n: The keywords_threshold and word_alternatives_threshold parameters of the recognition methods no longer accept a null value. To omit keywords and word alternatives from the response, omit the parameters. A specified value must be a float.\n\n\n\n\n\n 22 September 2016 \n\nNew beta language model customization interface\n: The service now offers a new beta language model customization interface for US English.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_16471-74601-76664","score":11.860739,"text":"\nFor all supported languages, the Multilingual tokenizer uses the part-of-speech tags that are listed in the following table.\n\n\n\n Tag Descriptions \n\n ADJ adjective \n ADP adposition \n ADV adverb \n AUX auxiliary \n CCONJ coordinating conjunction \n DET determiner \n INTJ interjection \n NOUN noun \n NUM numeral \n PART particle \n PRON pronoun \n PROPN proper noun \n PUNCT punctuation \n SCONJ subordinating conjunction \n SYM symbol \n VERB verb \n X other \n\n\n\n\n\n\n\n Examples \n\nExample 1: Using a part of speech tag directly in an extract statement\n\nThe view EnglishNoun extracts English nouns (singular or mass) or proper nouns (singular).\n\ncreate view EnglishNoun\nas extract parts_of_speech 'NOUN' and 'PROPN'\nwith language 'en' on D.text\nas noun from Document D;\n\n\n\n\n\n\n\n Sequence patterns \n\nUse the pattern extraction specification to perform pattern matching across an input document and other spans extracted from the input document.\n\n\n\n Syntax \n\nThe general syntax of a sequence pattern is to first specify the pattern to be matched in the text, and then to specify what is to be returned by the extractor. The final part of the sequence pattern specifies what is the input to the pattern; it might be a column from a previously defined view, or it might be the entire document text.\n\npattern <pattern specification> [return clause] [with inline_match on <viewname.colname>]\n\n\n\n\n\n Description \n\n\n\n* <pattern specification>\n\nA <pattern specification> is composed of multiple Atoms. An individual Atom can be a column from an already-defined view, a fixed string, or a regular expression. You can specify your Atoms to be optional and repeating, and specify token gaps between Atoms.\n\nThe pattern specification is part of a larger AQL statement, which includes an extract clause.\n\nHere is a simple example of how to create a view that contains three adjacent matches from earlier defined views. In this example, the entire combination is returned, which is what group 0 refers to:\n\ncreate view Money as\nextract pattern <C.match> <N.match> <Q.match>\nreturn group 0 as match","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_16485-5134-7047","score":11.649194,"text":"\nFor details about how Knowledge Studio handles Arabic character shaping and numeric shaping, see [Configuring support for Arabic](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_langsupp_ar).\n\n\n\n\n\n\n\n CSV file dictionary \n\nAlso referred to as the standard dictionary format, a dictionary in comma-separated value (CSV) format is a file that you can edit after you upload it. The maximum size of a CSV file that you can upload is 1 MB. If you have a larger dictionary file, then break the large file into multiple files and upload them one at a time into a single dictionary in your Knowledge Studio workspace.\n\nTo summarize the requirements, you must use a text editor to create the CSV file, not software like Microsoft Excel, and the file must use UTF-8 encoding that does not include the byte order mark (BOM) at the start of the text stream. The first row in the file must specify the following column headers:\n\nlemma,poscode,surface\n\nThe remaining lines in the file specify the dictionary entries, where:\n\n\n\n* lemma\n\nSpecifies the most representative word form for the entry.\n* poscode (Arabic, Brazilian Portuguese, English, French, German, Italian, and Spanish)\n\nSpecifies a code that identifies the part of speech. This part of speech information is used by the dictionary annotator to help with sentence tokenization.\n\n\n\n* 0 - Unknown\n\n> Note: This code supports the scenario where you want to upload a large machine-generated dictionary that does not include part of speech information in each entry. You can assign unknown to all entries by default. Avoid using this code, if possible.\n* 1 - Pronoun\n* 2 - Verb\n* 3 - Noun\n* 4 - Adjective\n* 5 - Adverb\n* 6 - Adposition\n* 7 - Interjection\n* 8 - Conjunction\n* 9 - Determiner\n* 10 - Quantifier\n\n\n\nIn English, noun (3), verb (2), and adjective (4) are the most common parts of speech that are used for dictionary entries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-dictionaries"},{"document_id":"ibmcld_02747-17013-18675","score":11.616775,"text":"\nSupported languages \n\nYou can use [the language management APIs](https:\/\/us-south.appid.cloud.ibm.com\/swagger-ui\/\/Management%20API%20-%20Config\/mgmt.updateLocalization) to set the language in which your user communication can be written. However, only English is available out of the box. You are responsible for the conversion of the messages. After you set the configuration with the API, the GUI updates so that you are able to change the template text.\n\n\n\nTable 6. Languages that are supported\n\n Code Language Region \n\n af-ZA Afrikaans South Africa \n sq-AL Albanian Albania \n am-ET Amharic Ethiopia \n ar-DZ Arabic Algeria \n ar-BH Arabic Bahrain \n ar-EG Arabic Egypt \n ar-IQ Arabic Iraq \n ar-JO Arabic Jordan \n ar-KW Arabic Kuwait \n ar-LB Arabic Lebanon \n ar-LY Arabic Libya \n ar-MR Arabic Mauritania \n ar-MA Arabic Morocco \n ar-OM Arabic Oman \n ar-QA Arabic Qatar \n ar-SA Arabic Saudi Arabia \n ar-SY Arabic Syria \n ar-YE Arabic Tunisia \n ar-AE Arabic United Arab Emirates \n ar-YE Arabic Yemen \n hy-AM Armenian Armenia \n as-IN Assamese India \n az-AZ Azerbaijani Azerbaijan \n eu-ES Basque Spain \n be-BY Belarusian Belarus \n bn-BD Bengali Bangladesh \n be-BY Belarusian Belarus \n bn-BD Bengali Bangladesh \n bn-IN Bengali India \n bs-Latn-BA Bosnian Bosnia \n bg-BG Bulgarian Bulgaria \n my-MM Burmese Myanmar \n ca-ES Catalan Spain \n zh-Hans-CN Chinese-simplified China \n zh-Hans-SG Chinese-simplified Singapore \n zh-Hant-HK Chinese-traditional Hong Kong S.A.R. of China \n zh-Hant-MO Chinese-traditional Macao S.A.R. of the PRC \n zh-Hant-TW Chinese-traditional Taiwan \n hr-HR Croatian Croatia \n cs-CZ Czech Czech Republic \n da-DK Danish Denmark \n nl-BE Dutch Belgium","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-cd-types"},{"document_id":"ibmcld_16542-10301-12424","score":11.536214,"text":"\nThe following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11. For tokens that have annotations that were added indirectly from a dictionary annotation or regular expression match, you can choose whether the pattern should require any word with the same annotation type or the actual underlying words that were annotated instead.\n\nIn the lower layer of cells, you can see which cells are included in the pattern because a horizontal line connects them to one another. Where an annotation has been applied, there is a split. Cells with the original words are displayed below a cell with the annotation label. You can click one set of cells or the other to change the path of the line, and thus change the cells that are included in the pattern.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_rule_creation"},{"document_id":"ibmcld_16460-10316-12439","score":11.536214,"text":"\nThe following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11. For tokens that have annotations that were added indirectly from a dictionary annotation or regular expression match, you can choose whether the pattern should require any word with the same annotation type or the actual underlying words that were annotated instead.\n\nIn the lower layer of cells, you can see which cells are included in the pattern because a horizontal line connects them to one another. Where an annotation has been applied, there is a split. Cells with the original words are displayed below a cell with the annotation label. You can click one set of cells or the other to change the path of the line, and thus change the cells that are included in the pattern.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_rule_creation"},{"document_id":"ibmcld_16441-32500-34658","score":11.532216,"text":"\nExtracting in languages other than English \n\nTo extract text from non-English documents, you can sometimes use or modify the provided extractors or define new extractors based on linguistic patterns. Also, if target terms are based on a pattern, you can design a sequence pattern.\n\nYou can use the workspace to build extractors to be used with any language, such as Spanish and French, that is based on tokens defined by white space and punctuation. For example, the results of using the Person extractor with Spanish text might extract names as shown here.\n\n![Results of applying the Person extractor to Spanish text](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/Spanish.png)\n\n\n\n Extending the provided extractors for use in a different language \n\nIf your target language is based on tokens defined by white space and punctuation, you can extend a provided extractor that has customization points or dictionaries by adding terms to the appropriate dictionaries in the target language.\n\n\n\n Provided extractor Included in folder: How to extend \n\n All generic extractors Generic extractors Define a regular expression for the target text pattern. If the provided extractor produces results, create a union with the provided extractor and the regular expression. \n Email address, Phone number, Zip code Named Entity Recognition Define a regular expression for the target text pattern. If the provided extractor produces results, create a union with the provided extractor and the regular expression. \n Currency Named Entity Recognition Combine a decimal number extractor with a literal to represent the local currency symbol in a sequence or define a regular expression. If more than one currency symbol is required, use a dictionary rather than a literal. \n Date and time Named Entity Recognition For numeric formats, define a regular expression for the target text pattern. <br> <br>For alphabetic formats, define a sequence using integers for the days and years and a mapping table to represent the months. Use the full names and abbreviations for each month in the mapping table.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-managing-projects-and-extractors"},{"document_id":"ibmcld_09913-7-1696","score":11.406649,"text":"\nLanguage support \n\nNatural Language Understanding supports a variety of languages depending on which features you analyze. Currently, English is the only language that is supported across all features. The rest of the languages have limited support. To jump to the list of features that are compatible with a language, click the language in the following list.\n\n\n\n* [Arabic](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportarabic)\n* [Chinese (Simplified)](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportchinese-simplified)\n* [Czech](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportczech)\n* [Danish](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportdanish)\n* [Dutch](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportdutch)\n* [English](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportenglish)\n* [Finnish](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportfinnish)\n* [French](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportfrench)\n* [German](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supportgerman)\n* [Hebrew](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-supporthebrew)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-language-support"},{"document_id":"ibmcld_09226-10727-12672","score":11.364949,"text":"\n: Added support for new file types for customization: CSV, TSV, XLSX (Microsoft Excel), XLIFF, and JSON. For more information, see [Supported document formats for training data](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-customizingsupported-document-formats-for-training-data).\n\nNew translation models\n: Added Welsh-to-English (cy-en) support in translation, and added support for Welsh (cy) in language detection. For more information, see [List of supported languages](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-modelslist-languages-supported).\n\n\n\n\n\n 11 June 2020 \n\nNew customizable translation models\n: Added the following customizable translation models for Ukrainian:\n\n\n\n* Ukrainian to English (uk-en)\n* English to Ukrainian (en-uk)\n\n\n\nFor more information, see [List of supported languages](https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-translation-modelslist-languages-supported).\n\nImproved translation between Spanish and English\n: Improved results for the translation models between Spanish and English:\n\n\n\n* Spanish to English (es-en)\n* English to Spanish (en-es)\n\n\n\nImproved document translation for Microsoft PowerPoint\n: Improved table handling with document translation for Microsoft PowerPoint.\n\n\n\n\n\n 28 May 2020 \n\nExpanded language support for translation and identification\n: Expanded language support:\n\n\n\n* Support for translating the following languages is now available:\n\n\n\n* Nepali (ne)\n* Sinhala (si)\n\n\n\n* Support for identifying the following languages is now available:\n\n\n\n* Burmese (my)\n* Lao (lo)\n* Marathi (mr)\n* Nepali (ne)\n* Punjabi (Shahmukhi script, Pakistan) (pa-PK)\n* Sinhala (si)\n* Tagalog (tl)\n\n\n\n\n\nImproved translation results for Catalan and Chinese\n: Improved results when translating to and from the following languages:\n\n\n\n* Catalan (ca)\n* Chinese (Simplified) (zh)\n\n\n\nNew translation limits for Lite plan","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-release-notes"},{"document_id":"ibmcld_16421-5126-7041","score":11.357562,"text":"\nFor details about how Knowledge Studio handles Arabic character shaping and numeric shaping, see [Configuring support for Arabic](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_langsupp_ar).\n\n\n\n\n\n\n\n CSV file dictionary \n\nAlso referred to as the standard dictionary format, a dictionary in comma-separated value (CSV) format is a file that you can edit after you upload it. The maximum size of a CSV file that you can upload is 1 MB. If you have a larger dictionary file, then break the large file into multiple files and upload them one at a time into a single dictionary in your Knowledge Studio workspace.\n\nTo summarize the requirements, you must use a text editor to create the CSV file, not software like Microsoft Excel, and the file must use UTF-8 encoding that does not include the byte order mark (BOM) at the start of the text stream. The first row in the file must specify the following column headers:\n\nlemma,poscode,surface\n\nThe remaining lines in the file specify the dictionary entries, where:\n\n\n\n* lemma\n\nSpecifies the most representative word form for the entry.\n* poscode (Arabic, Brazilian Portuguese, English, French, German, Italian, and Spanish)\n\nSpecifies a code that identifies the part of speech. This part of speech information is used by the dictionary annotator to help with sentence tokenization.\n\n\n\n* 0 - Unknown\n\nThis code supports the scenario where you want to upload a large machine-generated dictionary that does not include part of speech information in each entry. You can assign unknown to all entries by default. Avoid using this code, if possible.\n* 1 - Pronoun\n* 2 - Verb\n* 3 - Noun\n* 4 - Adjective\n* 5 - Adverb\n* 6 - Adposition\n* 7 - Interjection\n* 8 - Conjunction\n* 9 - Determiner\n* 10 - Quantifier\n\n\n\nIn English, noun (3), verb (2), and adjective (4) are the most common parts of speech that are used for dictionary entries.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-dictionaries"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"e1b602e47ded79a35d8df4eefe194e39<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16471-82072-84273","score":10.720721,"text":"\nIn addition, the syntax allows a special token gap construct to be specified in a sequence expression to indicate a match between min and max number of tokens.\n* <token>\n\nA match for any token.\n* [return clause]\n\nGenerates extracted values for each match of the pattern expression according to the return clause. The return clause has the same semantics as the return clause in an extract regex statement.\n* [with inline_match on <viewname.colname>]\n\nFor the Atoms such as string and regex Atoms, the with inline_match clause determines which text object the system uses for string or regex extraction. For example, if the clause is with inline_match on Email.subject, then all dictionaries and regular expressions defined inline in the pattern specification are applied to the subject field of the Email view. If the with inline_match is absent, string and regular expression extraction are run by default on the entire Document.text. In this case, viewname must be the name of a view or table that is defined in the current module, or imported from another module; references to table functions are not allowed in the with inline_match clause.\n* [with language as <language code(s)>]\n\nSpecifies a comma-delimited list of two-letter language codes, such as en (English) or zh (Chinese) for the languages on which to evaluate the string. There is no match on documents whose language code is not contained in this string. If the language parameter is omitted, the evaluation language defaults to one of the following language sets:\n\n\n\n* If it is declared, the language sets that are specified through the set default language statement in the containing module.\n* The language sets that contain German (de), Spanish (es), English (en), French (fr), Italian (it), and the unspecified language (x_unspecified)\n\n\n\n\n\n\n\n\n\n Usage notes \n\n\n\n* The semantics of an extract pattern statement is driven by the pattern specification. Each match constructs an output result according to the return clause of the pattern specification and the select list at the top of the extract statement. The results are filtered and consolidated according to the having, consolidate, and limit clauses of the extract statement.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_16471-83734-86065","score":10.6077385,"text":"\n* The language sets that contain German (de), Spanish (es), English (en), French (fr), Italian (it), and the unspecified language (x_unspecified)\n\n\n\n\n\n\n\n\n\n Usage notes \n\n\n\n* The semantics of an extract pattern statement is driven by the pattern specification. Each match constructs an output result according to the return clause of the pattern specification and the select list at the top of the extract statement. The results are filtered and consolidated according to the having, consolidate, and limit clauses of the extract statement. If multiple overlapping matches exist for the pattern specification, a pattern extraction outputs all possible matches. Use consolidation to filter redundant outputs.\n* The semantics of the from clause of an extract pattern statement are different from other forms of extract statements that do not have a pattern specification. The general semantics of an extract statement require that the extraction specification is evaluated over each combination of the views that are defined in the <from list>. If at least one of the views in the <from list> does not contain any results on a particular document, then the output of the extract statement is empty because the set of all combinations of results in the input views is empty. In the special case of extract pattern statements, the from clause is a placeholder that declares the names of relations that are involved in the pattern specification. The semantics of the statement are driven only by the pattern specification. In particular, the output of the statement can be non-empty even when some of the input views are empty.\n* An extract statement that uses sequence pattern extraction can carry forward the columns of any view in the from list, but only if the view name does not appear in a repeat element of the pattern specification. For example, the statement CapsWordOneToThree results in a compilation error. The error occurs because the carried forward column CW.type at the top of the extract statement belongs to the view name CW, which is in the repeat element <CW.word>{1,3} of the pattern specification.\n\ncreate view CapsWord as\nextract 'UpperCase' as type,\nregex \/[A-Z].\/ on 1 token in D.text as word\nfrom Document D;\n\n---> This results in and error due to the repeating element CW.word\ncreate view CapsWordOneToThree as","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_16471-74601-76664","score":10.274456,"text":"\nFor all supported languages, the Multilingual tokenizer uses the part-of-speech tags that are listed in the following table.\n\n\n\n Tag Descriptions \n\n ADJ adjective \n ADP adposition \n ADV adverb \n AUX auxiliary \n CCONJ coordinating conjunction \n DET determiner \n INTJ interjection \n NOUN noun \n NUM numeral \n PART particle \n PRON pronoun \n PROPN proper noun \n PUNCT punctuation \n SCONJ subordinating conjunction \n SYM symbol \n VERB verb \n X other \n\n\n\n\n\n\n\n Examples \n\nExample 1: Using a part of speech tag directly in an extract statement\n\nThe view EnglishNoun extracts English nouns (singular or mass) or proper nouns (singular).\n\ncreate view EnglishNoun\nas extract parts_of_speech 'NOUN' and 'PROPN'\nwith language 'en' on D.text\nas noun from Document D;\n\n\n\n\n\n\n\n Sequence patterns \n\nUse the pattern extraction specification to perform pattern matching across an input document and other spans extracted from the input document.\n\n\n\n Syntax \n\nThe general syntax of a sequence pattern is to first specify the pattern to be matched in the text, and then to specify what is to be returned by the extractor. The final part of the sequence pattern specifies what is the input to the pattern; it might be a column from a previously defined view, or it might be the entire document text.\n\npattern <pattern specification> [return clause] [with inline_match on <viewname.colname>]\n\n\n\n\n\n Description \n\n\n\n* <pattern specification>\n\nA <pattern specification> is composed of multiple Atoms. An individual Atom can be a column from an already-defined view, a fixed string, or a regular expression. You can specify your Atoms to be optional and repeating, and specify token gaps between Atoms.\n\nThe pattern specification is part of a larger AQL statement, which includes an extract clause.\n\nHere is a simple example of how to create a view that contains three adjacent matches from earlier defined views. In this example, the entire combination is returned, which is what group 0 refers to:\n\ncreate view Money as\nextract pattern <C.match> <N.match> <Q.match>\nreturn group 0 as match","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_16542-10301-12424","score":10.055944,"text":"\nThe following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11. For tokens that have annotations that were added indirectly from a dictionary annotation or regular expression match, you can choose whether the pattern should require any word with the same annotation type or the actual underlying words that were annotated instead.\n\nIn the lower layer of cells, you can see which cells are included in the pattern because a horizontal line connects them to one another. Where an annotation has been applied, there is a split. Cells with the original words are displayed below a cell with the annotation label. You can click one set of cells or the other to change the path of the line, and thus change the cells that are included in the pattern.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_rule_creation"},{"document_id":"ibmcld_16460-10316-12439","score":10.055944,"text":"\nThe following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11. For tokens that have annotations that were added indirectly from a dictionary annotation or regular expression match, you can choose whether the pattern should require any word with the same annotation type or the actual underlying words that were annotated instead.\n\nIn the lower layer of cells, you can see which cells are included in the pattern because a horizontal line connects them to one another. Where an annotation has been applied, there is a split. Cells with the original words are displayed below a cell with the annotation label. You can click one set of cells or the other to change the path of the line, and thus change the cells that are included in the pattern.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_rule_creation"},{"document_id":"ibmcld_16471-29441-31519","score":9.569064,"text":"\nSpecifies the language for compilation and matching for dictionaries of the module that are declared without an explicit with language as specification. The <language codes> set must be a comma-separated list, with no white spaces around each language code. Failure to observe this requirement can result in a compilation error.\n\nThis statement affects the following dictionaries:\n\n\n\n* Dictionaries that are explicitly declared in the current module by using the create dictionary or create external dictionary statement, and that statement does not have a with language as clause.\n* Dictionaries from external files.\n* In a pattern specification of an extract pattern statement, atoms of type 'string' and atoms of type <'string' [match parameters]> without an explicit with language as specification. When this statement is absent from inside a module, the runtime component defaults to a language set of German, Spanish, English, French, Italian, and the unspecified language x. It is defined as a set: [de,es,en,fr,it,x_unspecified]. Within a module, only one instance of this statement can exist.\n\n\n\n\n\n\n\n\n\n Usage notes \n\n\n\n* The set default dictionary language statement can be updated to improve the extent of languages that are covered by the extractor. This ability to add languages promotes ease of customization and the reuse of existing extractors.\n\n\n\n\n\n\n\n Examples \n\nExample 1: Specifying languages to be used to match dictionary entries\n\nmodule Dictionaries;\n\n-- Set the default dictionary matching language\n-- for this module to English and French\n\nset default dictionary language as 'en,fr';\n\n\/\n* Dictionary of English and French names. Because no language clause\n* exists in dictionary definition, module level dictionary matching\n* setting will be applied.\n\/\n\ncreate dictionary EnglishFrenchNames\nfrom file 'en_fr_names.dict';\n\n\/\n* Dictionary of Italian names. Language clause in the dictionary\n* definition will override the module level dictionary matching setting.\n\/\n\ncreate dictionary ItalianNames\nwith language as 'it'\nas\n(\n'firstEntry','secondEntry'\n);\n\n\/","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"},{"document_id":"ibmcld_16441-32500-34658","score":9.523939,"text":"\nExtracting in languages other than English \n\nTo extract text from non-English documents, you can sometimes use or modify the provided extractors or define new extractors based on linguistic patterns. Also, if target terms are based on a pattern, you can design a sequence pattern.\n\nYou can use the workspace to build extractors to be used with any language, such as Spanish and French, that is based on tokens defined by white space and punctuation. For example, the results of using the Person extractor with Spanish text might extract names as shown here.\n\n![Results of applying the Person extractor to Spanish text](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/148d3bd95f946aa1bb53ea1540475f522e6b61c9\/watson-knowledge-studio-data\/images\/Spanish.png)\n\n\n\n Extending the provided extractors for use in a different language \n\nIf your target language is based on tokens defined by white space and punctuation, you can extend a provided extractor that has customization points or dictionaries by adding terms to the appropriate dictionaries in the target language.\n\n\n\n Provided extractor Included in folder: How to extend \n\n All generic extractors Generic extractors Define a regular expression for the target text pattern. If the provided extractor produces results, create a union with the provided extractor and the regular expression. \n Email address, Phone number, Zip code Named Entity Recognition Define a regular expression for the target text pattern. If the provided extractor produces results, create a union with the provided extractor and the regular expression. \n Currency Named Entity Recognition Combine a decimal number extractor with a literal to represent the local currency symbol in a sequence or define a regular expression. If more than one currency symbol is required, use a dictionary rather than a literal. \n Date and time Named Entity Recognition For numeric formats, define a regular expression for the target text pattern. <br> <br>For alphabetic formats, define a sequence using integers for the days and years and a mapping table to represent the months. Use the full names and abbreviations for each month in the mapping table.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-managing-projects-and-extractors"},{"document_id":"ibmcld_16460-9978-11758","score":9.48611,"text":"\nThe following types are supported:<br><br><br><br> * adjective<br> * adposition<br> * adverb<br> * conjunction<br> * determiner<br> * interjection<br> * noun<br> * numeral<br> * pronoun<br> * residual<br> * verb<br><br><br> \n Lemma Must have the same lemma as this token. \n Character Type Must have the same character type as this token. The following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_rule_creation"},{"document_id":"ibmcld_16542-9963-11743","score":9.48611,"text":"\nThe following types are supported:<br><br><br><br> * adjective<br> * adposition<br> * adverb<br> * conjunction<br> * determiner<br> * interjection<br> * noun<br> * numeral<br> * pronoun<br> * residual<br> * verb<br><br><br> \n Lemma Must have the same lemma as this token. \n Character Type Must have the same character type as this token. The following types are supported:<br><br><br><br> * Arabic: Contains a sequence of Arabic characters<br> * ChineseNumeral: Contains only Chinese numerals<br> * ClauseEndingPunctuation: Punctuation characters that separate one clause or sentence from the next<br> * Han: Contains Han characters<br> * Hangul: Contains Korean Hangul syllabic characters<br> * Hebrew: Contains a sequence of Hebrew characters<br> * Hiragana: Contains Japanese Hiragana syllabic characters<br> * Ideographic: Contains an ideogram, or symbol representing an idea or thing<br> * Katakana: Contains Japanese Katakana syllabic characters<br> * Lowercase: Contains only lower case alphabetic characters<br> * Numeric: Contains only numeric characters<br> * Punctuation: One or more characters that provide punctuation in the text<br> * Syllabic: Contains syllabic characters<br> * Thai: Contains Thai characters<br> * Titlecase: Starts with a single upper case alphabetic character, followed by one or more lower case alphabetic characters<br> * Uppercase: A token containing only upper case alphabetic characters<br><br><br> \n\n\n\n* Rule Match:\n\nTable 4. Rule matching\n\n\n\n Setting option Description \n\n Rule Match Must match the named class. Remember, a class can be derived from a regex, a dictionary, or a rule. If the class specified here was derived from a regular expression, for example, then this token must match the search pattern of the expression. \n\n\n\n\n\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-wks_rule_creation"},{"document_id":"ibmcld_16471-124267-126334","score":9.301896,"text":"\nSpecifies a comma-delimited list of two-letter language codes, such as en (English) or zh (Chinese) for the languages, or for the document languages for external dictionaries, on which to evaluate the dictionary. The dictionary produces no results on documents whose language code is not contained in this string.\n\nIf the language parameter is omitted, the dictionary language defaults to one of the following language sets:\n\n\n\n* The language sets that are specified through the set default language statement, if it is declared, in the containing module.\n* The language sets that contain German (de), Spanish (es), English (en), French (fr), Italian (it), and the unspecified language (x_unspecified).\n\n\n\n* lemma_match\n\nUse lemmatization to find matches for similar words to a dictionary term in your documents.\n\nLemmatization is the process of determining the lemma for a given word. A lemma is a word that can be used as a match for a single given term. For example, the term \u201cgo\u201d can be matched to the terms \u201cgoes\u201d, \u201cgoing\u201d, \u201cgone\u201d, or \u201cwent\u201d. This process involves complex tasks such as understanding context and determining the part of speech of a word in a sentence. Lemmatization is available for all languages for which IBM Multilingual tokenizer provides part-of-speech support.\n\nLemma match is performed only for dictionaries declared with the lemma match clause.\n\nThe semantics for dictionary extraction with the lemma_match clause are as follows:\n\n\n\n* The lemmatized form for each token of the input document is computed.\n* The dictionary is evaluated against the lemmatized document. You cannot use the lemma_match option with the case exact option. If both are used, a compiler error is returned.\n\n\n\n* case (exact | insensitive)\n\nSpecifies the type of case-folding that the dictionary performs when it determines whether a specific region of the document matches.\n\n\n\n* exact\n\nSpecifies an exact case-sensitive match.\n* insensitive\n\nSpecifies a match that is not case-sensitive match. This option is the default value.\n\n\n\n* '<entry 1>', '<entry 2>', ...","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15020-3827-5719","score":25.637403,"text":"\nBehind the scenes, the [Snapshot for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about) service is used to create a point-in-time copy of your data. When the first backup snapshot is taken, the entire contents of the volume are copied and retained in IBM Cloud\u00ae Object Storage. Subsequent backups of the same volume capture the changes that occurred since the previous backup. You can take up to [750 backups of a volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots_vpc_considerations).\n\nYou can [restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=uibackup-service-restore-concepts) data from a backup snapshot to a new, fully provisioned volume. If the backup is of a boot volume, you can use it to provision a new instance. However, when you provision an instance by restoring a boot volume from a bootable backup snapshot, you can expect degraded performance in the beginning. During the restoration process, the data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC, and thus the provisioned IOPS cannot be fully realized until that process finishes.\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. The [cross-regional copy](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=uibackup-service-crc) can be used in disaster recovery scenarios when you need to turn on your virtual server instance and data volumes in a different region. The remote copy can be created automatically as part of a backup plan, or manually later.\n\nWith the fast restore feature, you can cache snapshots in a specified zone of your choosing. This way, volumes can be restored from snapshots nearly immediately and the new volumes operate with full IOPS instantly. The fast restore feature can achieve a","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=ui"},{"document_id":"ibmcld_15007-3814-5680","score":25.570135,"text":"\nBehind the scenes, the [Snapshot for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about) service is used to create a point-in-time copy of your data. When the first backup snapshot is taken, the entire contents of the volume are copied and retained in IBM Cloud\u00ae Object Storage. Subsequent backups of the same volume capture the changes that occurred since the previous backup. You can take up to [750 backups of a volume](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots_vpc_considerations).\n\nYou can [restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-aboutbackup-service-restore-concepts) data from a backup snapshot to a new, fully provisioned volume. If the backup is of a boot volume, you can use it to provision a new instance. However, when you provision an instance by restoring a boot volume from a bootable backup snapshot, you can expect degraded performance in the beginning. During the restoration process, the data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC, and thus the provisioned IOPS cannot be fully realized until that process finishes.\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. The [cross-regional copy](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-aboutbackup-service-crc) can be used in disaster recovery scenarios when you need to turn on your virtual server instance and data volumes in a different region. The remote copy can be created automatically as part of a backup plan, or manually later.\n\nWith the fast restore feature, you can cache snapshots in a specified zone of your choosing. This way, volumes can be restored from snapshots nearly immediately and the new volumes operate with full IOPS instantly. The fast restore feature can achieve a","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about"},{"document_id":"ibmcld_15007-13930-15825","score":24.767857,"text":"\nRestoring from a bootable snapshot is slower than using a regular boot volume.\n\nWhile the creation of the backup requires the volumes to be attached to a running virtual server instance, you can also restore a data volume from a snapshot of an unattached volume. Backups, like snapshots, have a lifecycle that is independent from the source Block Storage for VPC volume.\n\nThe restored volume has the same capacity and IOPS tier profile as the original volume. For more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Restoring a volume by using fast restore \n\nWhen you restore a volume by using fast restore, a fully hydrated volume is created.\n\nYou can create a [backup policy plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=uibackup-plan-ui) with fast restore zones, and add or remove zones later as needed. The fast restore feature caches one or more copies of a backup snapshot to the zones that you selected. Later, you can use these backup clones to create volumes in any zone within the same region.\n\nFor more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Cross-regional backup copies \n\nNew\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. You can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about"},{"document_id":"ibmcld_15020-13969-15864","score":24.767857,"text":"\nRestoring from a bootable snapshot is slower than using a regular boot volume.\n\nWhile the creation of the backup requires the volumes to be attached to a running virtual server instance, you can also restore a data volume from a snapshot of an unattached volume. Backups, like snapshots, have a lifecycle that is independent from the source Block Storage for VPC volume.\n\nThe restored volume has the same capacity and IOPS tier profile as the original volume. For more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Restoring a volume by using fast restore \n\nWhen you restore a volume by using fast restore, a fully hydrated volume is created.\n\nYou can create a [backup policy plan](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=uibackup-plan-ui) with fast restore zones, and add or remove zones later as needed. The fast restore feature caches one or more copies of a backup snapshot to the zones that you selected. Later, you can use these backup clones to create volumes in any zone within the same region.\n\nFor more information, see [Restoring a volume from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Cross-regional backup copies \n\nNew\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. You can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about&interface=ui"},{"document_id":"ibmcld_15883-3044-4932","score":24.767143,"text":"\nYou can also restore a fully provisioned volume by using the [fast restore feature](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=apisnapshots-fast-restore) after initial provisioning.\n\nSnapshots have a lifecycle that is independent from the source Block Storage for VPC volume. You can delete the original volume and the snapshot persists. However, do not detach the volume from the instance during snapshot creation. You need to wait until the snapshot is stable before you detach, otherwise you can't reattach the volume to an instance. Snapshots are crash-consistent. If the virtual server stops for any reason, the snapshot data is safe on the disk.\n\nCost for snapshots is calculated based on GB capacity that is stored per month, unless the duration is less than one month. Because the snapshot is based on the capacity that was provisioned for the original volume, the snapshot capacity does not vary.\n\nWith IBM Cloud\u00ae Identity and Access Management, you can set up resource groups in your account to provide user-access to your snapshots. Your IAM role determines whether you can create and manage snapshots. For more information, see [IAM roles for creating and managing snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-managesnapshots-vpc-iam).\n\nBefore you take a snapshot, make sure that all cached data is present on disk, especially when you're taking snapshots of instances with Windows and Linux\u00ae operating systems. For example, on Linux operating systems, run the sync command to force an immediate write of all cached data to disk.\n\nFor customers with special access, data isolation is provided to store snapshots that you created from your dedicated hosts. With data isolation's extra security, your data is encrypted at rest with a unique key and access to your data is protected by a private firewall.\n\n\n\n\n\n How snapshots work","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=api"},{"document_id":"ibmcld_15111-10169-12034","score":24.748028,"text":"\nBy using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n\n\n\n\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot. For more information, see [Restoring a volume from a snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore).\n\nFor best performance, you can enable snapshots for fast restore. By using the fast restore feature, you can create a volume from a snapshot that is fully provisioned when the volume is created. For more information, see [Snapshots fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\n\n\n\n\n Can I add tags to a volume? \n\nYes, you can add user tags and access management tags to your volumes. User tags are used by the backup service to automatically create backup snapshots of the volume. Access management tags help organize access to your Block Storage for VPC volumes. For more information, see [Tags for Block Storage for VPC volumes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about&interface=uistorage-about-tags).\n\n\n\n\n\n\n\n Performance questions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-vpc-faq"},{"document_id":"ibmcld_15896-3043-4930","score":24.720879,"text":"\nYou can also restore a fully provisioned volume by using the [fast restore feature](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=uisnapshots-fast-restore) after initial provisioning.\n\nSnapshots have a lifecycle that is independent from the source Block Storage for VPC volume. You can delete the original volume and the snapshot persists. However, do not detach the volume from the instance during snapshot creation. You need to wait until the snapshot is stable before you detach, otherwise you can't reattach the volume to an instance. Snapshots are crash-consistent. If the virtual server stops for any reason, the snapshot data is safe on the disk.\n\nCost for snapshots is calculated based on GB capacity that is stored per month, unless the duration is less than one month. Because the snapshot is based on the capacity that was provisioned for the original volume, the snapshot capacity does not vary.\n\nWith IBM Cloud\u00ae Identity and Access Management, you can set up resource groups in your account to provide user-access to your snapshots. Your IAM role determines whether you can create and manage snapshots. For more information, see [IAM roles for creating and managing snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-managesnapshots-vpc-iam).\n\nBefore you take a snapshot, make sure that all cached data is present on disk, especially when you're taking snapshots of instances with Windows and Linux\u00ae operating systems. For example, on Linux operating systems, run the sync command to force an immediate write of all cached data to disk.\n\nFor customers with special access, data isolation is provided to store snapshots that you created from your dedicated hosts. With data isolation's extra security, your data is encrypted at rest with a unique key and access to your data is protected by a private firewall.\n\n\n\n\n\n How snapshots work","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about&interface=ui"},{"document_id":"ibmcld_15869-3030-5030","score":24.700285,"text":"\nYou can also restore a fully provisioned volume by using the [fast restore feature](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots-fast-restore) after initial provisioning.\n\nSnapshots have a lifecycle that is independent from the source Block Storage for VPC volume. You can delete the original volume and the snapshot persists. However, do not detach the volume from the instance during snapshot creation. You need to wait until the snapshot is stable before you detach, otherwise you can't reattach the volume to an instance. Snapshots are crash-consistent. If the virtual server stops for any reason, the snapshot data is safe on the disk.\n\nCost for snapshots is calculated based on GB capacity that is stored per month, unless the duration is less than one month. Because the snapshot is based on the capacity that was provisioned for the original volume, the snapshot capacity does not vary.\n\nWith IBM Cloud\u00ae Identity and Access Management, you can set up resource groups in your account to provide user-access to your snapshots. Your IAM role determines whether you can create and manage snapshots. For more information, see [IAM roles for creating and managing snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-managesnapshots-vpc-iam).\n\nBefore you take a snapshot, make sure that all cached data is present on disk, especially when you're taking snapshots of instances with Windows and Linux\u00ae operating systems. For example, on Linux operating systems, run the sync command to force an immediate write of all cached data to disk.\n\nFor customers with special access, data isolation is provided to store snapshots that you created from your dedicated hosts. With data isolation's extra security, your data is encrypted at rest with a unique key and access to your data is protected by a private firewall.\n\n\n\n\n\n How snapshots work \n\nWhen you take a snapshot, read and write operations from your virtual server instance to the volume continue uninterrupted.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about"},{"document_id":"ibmcld_08133-3246-5117","score":24.613722,"text":"\nThe volume can be restored to another virtual server instance, to a temporary database that is created from the backup snapshot, and the deleted file or dropped table can be restored.\n\nYou can also restore the snapshots to a higher capacity and IOPS profiles and not necessarily to the same volume profiles as the source volume.\n\n\n\n\n\n Taking manual snapshots of your 3-tier applications \n\nA bootable snapshot can be taken for the web, app, and db machines. A non-bootable snapshot can be taken for the database block storage. To get a crash consistent snapshots for critical applications like databases, quiesce the database.\n\nYou can create snapshots either from Cloud UI, or with CLI or API. For more information, see [Creating Snapshots](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-create). After the first snapshot, all additional snapshots are incremental.\n\n\n\n\n\n Scheduling snapshots \n\nSnapshots can be scheduled by running an API through a cron job. However, before you run the API you need to create a service ID and retrieve the access token. For more information, see [Retrieving an access token](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-retrieve-access-token) for creating the service ID and retrieving the access token.\n\nAfter the service ID is set up, the iam token can be retrieved programmatically and the token can be passed to API call, for creating the snapshots. For more information, see [API documentation for snapshots](https:\/\/cloud.ibm.com\/apidocs\/vpccreate-snapshot). The process of quiescing your apps, retrieving the access token, and passing the token to API for creating the snapshots, can be scripted and passed to a cron job. You can create a schedule to delete the snapshots as well.\n\n\n\n\n\n Restoring Snapshots \n\nYou can restore the volumes either boot or data volumes from the snapshots that were created earlier.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ha-infrastructure?topic=ha-infrastructure-regional-snapshots-3-tier-arch"},{"document_id":"ibmcld_07578-891912-893651","score":24.564632,"text":"\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https:\/\/www.ibm.com\/cloud\/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1681275363,"ndcg_cut_10":0.3071837158}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09081-1687-4004","score":17.155943,"text":"\nData encryption keys (DEKs) are designed to encrypt your data and can be generated and managed by your service or an IBM Cloud service.\n\nEnvelope encryption offers several benefits for protecting your data:\n\n\n\n* Protection under a combination of multiple algorithms Envelope encryption uses the best benefits from symmetric and public key algorithms to keep your keys secure.\n\n\n\n1. Symmetric key algorithms work faster, are more scalable, and more secure than public key algorithms. Public key algorithms use complicated mathematics that increase computational overhead, especially when dealing with large volumes of data. Public key algorithms are also more susceptible to brute force attacks due to having a private key algorithm component that is easily recognizable by hackers. Symmetric key algorithms requires less computed power and are resistant to brute force attacks due to having a less recognizable structure.\n2. Public key algorithms allow for easier access control when granting access to keys at an individual level compared to symmetric key algorithms. Symmetric key algorithms have a key exchange problem, which is that access to a secret key can only be exchanged through a secure transfer. By using public key algorithms, encrypted DEKs (wDEKs) can be shared and unencrypted only by those with access to the encrypting root key, mitigating the key exchange problem of symmetric algorithms.\n\n\n\n* Easier key management You can encrypt multiple DEKs under a singular root key, which minimizes the amount of keys that you might need to manage in a key management service. You can also choose to save time on key maintenance by only rotating your root keys, instead of rotating and re-encrypting all of your DEKs. Note that in cases such as personnel turnover, process malfunctions, or the detection of a security issue, it is recommended to rotate all DEKs and root keys associated with the incident.\n* Data Key Protection Since your DEKs are wrapped by a root key, you do not have to worry about how to store the encrypted data key. Due to this, you can store the wDEK with alongside the associated encrypted data.\n\n\n\nKey Protect uses the Advanced Encryption Standard algorithm in Galois\/Counter Mode (AES GCM) to wrap and unwrap DEKs. CRKs that are not imported are created with 256-bit key material.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption"},{"document_id":"ibmcld_13108-7-2001","score":16.879738,"text":"\nAbout Key Protect \n\nIBM\u00ae Key Protect for IBM Cloud\u00ae is a full-service encryption solution that allows data to be secured and stored in IBM Cloud using the latest envelope encryption techniques that leverage FIPS 140-2 Level 3 certified cloud-based hardware security modules.\n\nSensitive data should not be stored on any cloud provider unencrypted (as \"plaintext\", in other words). But just as with any method of encryption, going back to the earliest known ciphertexts created thousands of years ago, the trick is not just to encrypt information so that it cannot be decoded easily but to protect the ciphers used to encrypt and decrypt it (since having a cipher is as good as having the data).\n\nWhile it is possible to set up a hardware security module (HSM) on premises to manage your data, this kind of system can be very expensive to establish and manage. Cloud-based storage, where encrypted data must be accessible at scale and at speed from a variety of permissioned actors, is less expensive, but has its own difficulties. How can you be sure that the data is secure when the key used to encrypt it (what's known as a \"data encryption key\") could exist on dozens if not hundreds of computers spread all over the world? In that scenario, your data is only as secure as the computers and connections of those with the data encryption key.\n\nThe solution is a key management system like Key Protect, which keeps data secure by encrypting the data encryption keys (DEKs) that encrypt your plaintext data with root keys managed by IBM via an impenetrable HSM. In this kind of a system, known as \"envelope encryption\", the process of decrypting the data means first \"unwrapping\" the encrypted DEK (opening its envelope, in other words) and then using the DEK to decrypt the data.\n\nFor more information about envelope encryption works, check out [Protecting data with envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption).\n\n\n\n What Key Protect offers","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/key-protect?topic=key-protect-about"},{"document_id":"ibmcld_12655-1658-4229","score":16.340511,"text":"\nThe encryption process manages keys that are generated by a commercially available key management service such as IBM\u00ae Key Protect and Hyper Protect Crypto Services.\n\nApplication performance is minimally impacted allowing for enterprise workflows to continue to operate in a secure environment. The Data Security Broker Manager is the cloud-based management console providing scalability, fault tolerance, and manageability of the software.\n\n\n\n\n\n Encryption Technology Configuration Overview: \n\nData Security Broker supports data protection services that can be configured in four main modes.\n\n\n\n Data Encryption: \n\nData Security Broker functions as an application-level encryption (ALE) software in this mode for encrypting data on a field-level basis. This is performed using Data Security Broker Manager to enumerate the data schema and enable an encryption key mapping.\n\n\n\n\n\n Data Tokenization: \n\nData Security Broker supports length preserving and data type preserving tokenization method to anonymize data at the field level databases or in semi-structured data files.\n\n\n\n\n\n Record Level Encryption: \n\nData Security Broker can be configured for record level encryption to support multiple keys within a single column that are mapped to respective data owners or entities. This encryption mode can be used effectively in multi-tenant or shared data environments where segmenting of the data can be challenging. In this mode, data shredding can be enabled by deleting public keys and private keys for a respective entity.\n\n\n\n\n\n Data Masking: \n\nData Security Broker can enable simplified data masking to prevent decryption of data and sensitive file information based on configuration or deleted keys. This mode can minimize data exposure in public cloud environment and provides a better control of data exfiltration to external parties.\n\n\n\n\n\n\n\n Deployment Plans in IBM Cloud Data Data Security Broker: \n\nWhen you assign and customize default Data Protection Policies with Data Security Broker Manager, there are three options that you can choose to implement your data encryption policy:\n\n\n\n Save Policy: \n\nSave Policy option is selected by default. This option saves your selected data, but does not execute encryption or data protection on your database. Your policy remains saved with the application until a new policy is saved to overwrite it. You can use the saved policy to deploy or migrate it later.\n\n\n\n\n\n Deploy Policy: \n\nDeploy Policy option saves your policy and deploys your configured Data Security Broker Shield as a proxy for the configured database.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-broker?topic=security-broker-sb_about"},{"document_id":"ibmcld_15710-4633-6509","score":15.973728,"text":"\nFor more information, see [Introduction to encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-basics).\n\nData is automatically encrypted on the physical media at the drive level. However, customer-managed keys are not supported for instance storage. For sensitive data, it is strongly recommended that users utilize software-based file system encryption such as LUKS for Linux\u00ae or BitLocker for Windows\u00ae. This technology allows end users to encrypt entirely within the instance, and can provide additional protection for sensitive data in-transit between the instances and the physical drive media. Some operating systems also provide FIPS certified encryption algorithms that may also be used. See [Encrypting block devices using LUKS](https:\/\/access.redhat.com\/documentation\/en-us\/red_hat_enterprise_linux\/8\/html\/security_hardening\/encrypting-block-devices-using-luks_security-hardening) for an example of how to encrypt on Red Hat Enterprise Linux\u00ae however, refer to the Operating System documentation or specific information on how to encrypt each device.\n\n\n\n\n\n\n\n Protecting your sensitive data in VPC \n\nKey Protect or Hyper Protect Crypto Services provide a higher level of protection called envelope encryption.\n\n[Envelope encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-envelope-ecryption-byok) encrypts one encryption key with another encryption key. A DEK encrypts your actual data. The DEK is never stored. Rather, it's encrypted by a key encryption key. The LUKS passphrase is then encrypted by a root key, which creates a WDEK. To decrypt data, the WDEK is unwrapped so you can access the data that's stored on the volume. This process is possible only by accessing the root key that is stored in your KMS instance. Root keys in HPCS service instances are also protected by a\n\nhardware security module (HSM)master key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-mng-data"},{"document_id":"ibmcld_01061-0-2080","score":15.918823,"text":"\n\n\n\n\n\n\n  Inter-node encryption \n\nFor the current generation of plans hosted on AWS, inter-node encryption is always enabled. For the Flex and Flex Performance plans hosted on IBM Cloud, you can optionally choose to enable this form of encryption.\n\nInter-node encryption is an additional layer of security that protects inter-node traffic between internal Db2 nodes in a massively parallel processing (MPP) cluster. It supplements the SSL encryption that is already in use between the server and your applications.\n\nInter-node encryption ensures that your data is processed with encryption at all points from your application to physical storage and back, which protects your information from physical and software-based attacks. Leaving inter-node traffic unencrypted means that your data is transferred in plain text between the physical hardware nodes that make up your Db2 MPP instance. IBM already employs a variety of security protocols to protect such traffic to ensure the security and integrity of the unencrypted internal data flows. With this new feature, IBM provides an additional security layer to protect the data.\n\nDue to the additional processing required to encrypt data on send and decrypt on receive, workloads with significant data movement may see a performance impact as little as 5% or as much as 20%. If your instance is hosted on IBM Cloud, your solution architect must evaluate this performance impact against your need to encrypt internal traffic flows. In some cases, it might be warranted (for instance in heavily regulated industries or where end users demand such encryption). In other cases, the existing in-depth security protocols may be sufficient.\n\nIBM Cloud plans only: To enable inter-node encryption, open the web console, select Administration, and navigate to the Security -> Encryption tab. Enabling or disabling inter-node encryption can be done online, and takes effect immediately. Choosing to enable inter-node encryption does not impact the Service Level Agreement (SLA), self-service backups, database replication, or scaling.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Db2whc?topic=Db2whc-Inter-node"},{"document_id":"ibmcld_02568-0-478","score":15.800569,"text":"\n\n\n\n\n\n\n  Encryption \n\nServices MUST support HTTPS and MUST NOT allow clients to make unencrypted, HTTP-only requests.\n\nServices MUST use TLS 1.2 or higher. Deprecated encryption protocols including (as of this writing) TLS 1.0 and 1.1 and all versions of SSL MUST be fully disabled such that they are not supported for clients that attempt to negotiate use of them.\n\nServices MUST comply with all current IBM security policies on cipher support and certificate management.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/api-handbook?topic=api-handbook-encryption"},{"document_id":"ibmcld_01145-7-1486","score":15.7445135,"text":"\nData security and privacy \n\nIBM\u00ae uses the following methods to help ensure the security and privacy of your data.\n\n\n\n Cryptographic protocols \n\n\n\n* Connections are restricted to the following strong cipher suites:\n\n\n\nFor TLS v1.2:\n\n* TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256\n* TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384\n* TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256\n\nFor TLS v1.3:\n\n* TLS_AES_128_GCM_SHA256\n* TLS_AES_256_GCM_SHA384\n* TLS_CHACHA20_POLY1305_SHA256\n\n\n\n* To be a fully supported configuration, all clients must support the following:\n\n\n\n* TLS v1.2 or v1.3\n* Elliptic curve cryptography\n* TLS server name indication (SNI)\n\n\n\n* Additionally, you must use TLS v1.2 or v1.3 in the following cases:\n\n\n\n* To make connections to the Kafka native and REST interfaces.\n* The browser that you use to access the Event Streams dashboard must support TLS v1.2 or v1.3.\n\n\n\n\n\n\n\n\n\n Encryption of message payloads, topic names, and consumer groups \n\nMessage data is encrypted for transmission between Event Streams and clients as a result of TLS. Event Streams stores message data at rest and message logs on encrypted disks.\n\nTopic names and consumer groups are encrypted for transmission between Event Streams and clients as a result of TLS. However, Event Streams does not encrypt these values at rest. Therefore, do not use confidential information in your topic names.\n\nOn the Satellite plan, all encryption is determined by the options that you specify on your chosen storage provider.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-data_security"},{"document_id":"ibmcld_08742-1480-3488","score":15.732123,"text":"\nYou can manage standard keys by following steps in [Manage your keys](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-get-startedmanage-keys).\n\n\n\n\n\n Data encryption keys \n\nData encryption keys (DEKs) are cryptographic keys that you use for data encryption. They are provided by user-owned applications and are used to encrypt data stored in applications. Root keys that you manage in Hyper Protect Crypto Services serve as wrapping keys to protect DEKs. To learn more, see [Introduction to envelope encryption](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-envelope-encryption).\n\n\n\n\n\n Envelope encryption \n\nEnvelope encryption is the practice of encrypting data with a DEK and then encrypting the DEK with a root key that you can fully manage. To learn more, see [Introduction to envelope encryption](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-envelope-encryption).\n\n\n\n\n\n\n\n Cloud hardware security module \n\nThis section covers concepts that are related to Hyper Protect Crypto Services [Cloud Hardware Security Module (HSM) feature](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-overviewcloud-hsm). The list starts with the most fundamental concepts.\n\n\n\n Hardware security module \n\nA hardware security module (HSM) is a physical device that safeguards and manages digital keys for strong authentication and provides crypto-processing. HSMs of IBM Cloud Hyper Protect Crypto Services are FIPS 140-2 Level 4 certified, which is the highest level of security for cryptographic hardware. At this security level, the physical security mechanisms provide a complete envelope of protection around the cryptographic module with the intent of detecting and responding to all unauthorized attempts at physical access.\n\n\n\n\n\n Crypto units \n\nA crypto unit is a single unit that represents an HSM and the corresponding software stack that is dedicated to the HSM for cryptography. In Hyper Protect Crypto Services, the following types of crypto unit are available:\n\n\n\n* Operational crypto unit","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-understand-concepts"},{"document_id":"ibmcld_16035-7-2023","score":15.664256,"text":"\nAbout data encryption for VPC \n\nIBM Cloud\u00ae takes security seriously and understands the importance of encrypting data to keep it safe. Block Storage for VPC volumes, snapshots, and File Storage for VPC file shares are automatically encrypted by using IBM-managed encryption. You can also choose to manage your own encryption for volumes, file shares, and custom images by using customer-managed encryption.\n\n\n\n IBM-managed encryption \n\nBy default, VPC volumes and file shares are encrypted at rest with IBM-managed encryption. The service comes with no additional cost.\n\nIBM-managed encryption uses the following industry standard protocols:\n\n\n\n* AES-256 encryption.\n* Keys are managed in-house with Key Management Interoperability Protocol (KMIP).\n* The self-encrypting drives in the Storage architecture are validated for Federal Information Processing Standard (FIPS) Publication 140-2 Level 2.\n* Storage architecture is validated for Federal Information Security Management Act (FISMA), and the Health Insurance Portability and Accountability Act (HIPAA)\n* Storage architecture is also validated for Payment Card Industry (PCI), Basel II, California Security Breach Information Act (SB 1386), and EU Data Protection Directive 95\/46\/EC compliance.\n\n\n\n\n\n\n\n Customer-managed encryption \n\nFor end-to-end encryption in the IBM Cloud, you can use customer-managed encryption. Your data is protected while at rest, and also in transit from the storage to the hypervisor and host. You are responsible for encrypting your data outside the VPC.\n\nWith customer-managed encryption, you can bring your own customer root key (CRK) to the cloud or have a [key management service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutkms-for-byok) (KMS) generate a key for you. Root keys are used to encrypt volume, file share, and custom image passphrases with [envelope encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-envelope-encryption-byok), a process that wraps a key with another key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-about"},{"document_id":"ibmcld_08766-9493-11228","score":15.616818,"text":"\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS\/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS\/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.\n\nIn the context of web servers, the TLS\/SSL protocol allows a website to establish the identity. Users of the website can be sure that no one else is masquerading as the website. It is done through a public-private key pair.\n\nHyper Protect Crypto Services provides a way to offload the cryptographic operations that are done during the TLS handshake to establish a secure connection to the web server, while it keeps the TLS\/SSL private key securely stored in the dedicated HSM. In this way, you have control over your TLS\/SSL keys and processing. As a result, security is improved and reputational risk is decreased.\n\nTLS\/SSL offloading to the Hyper Protect Crypto Services HSM enables data in transit protection for web, API, and mobile transactions by using the standard PKCS #11 API. With Hyper Protect Crypto Services, you can integrate TLS\/SSL offloading with other cloud proxies.\n\nFor a tutorial on how to offload the SSL workload to a load balancer such as NGINX while managing keys by using Hyper Protect Crypto Services, see [Using IBM Cloud Hyper Protect Crypto Services to offload NGINX TLS](https:\/\/developer.ibm.com\/components\/ibmz\/tutorials\/use-hyper-protect-crypto-services-to-offload-nginx-tls\/).\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-use-cases"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.25,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.39038005}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08511-1920-3732","score":21.063074,"text":"\nFor more information, see [Disaster recovery](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimedisaster-recovery).\n\n\n\n\n\n Cross-region disaster recovery \n\nIBM also performs cross-region backup for your key resources. Your data is automatically backed up in another supported region daily. Depending on where you create your instance and your requirements for recovery time, you can restore your data in case of a regional disaster with the following options:\n\n\n\n* If you create your instance in Dallas (us-south) or Washington DC (us-east) and you enable failover crypto units, the failover crypto units back up the operational crypto units and keystores in another region. When a regional disaster occurs, your data is restored automatically with the failover crypto units to reduce the downtime and data loss. For more information about how to use failover crypto units to restore data, see [Restoring your data by using failover crypto units](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-datarestore-data-failover-crypto-units).\n* If you don't enable failover crypto units, you can use the default daily backup to restore your data. In this case, you need to open a support ticket so that IBM can create a new service instance in another supported region to restore your data from the backup. Then, you need to manually load your master key to the new instance again to make it work. In this process, you're the only person who owns the master key. IBM administrators or any third-party users can't access your data or keys in the backup or the restored service instance. For more information about the recovery process, see [Restoring your data by opening an IBM support ticket](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-datarestore-data-open-support-ticket).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-dr"},{"document_id":"ibmcld_08669-6042-7847","score":20.829311,"text":"\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities \n\n Instance backups Continuously perform in-region and cross-region backups of key resources and perform continuous testing of backups. Back up your master key; validate the backups and restore data when needed. \n Disaster recovery When an in-region disaster occurs, automatically recover and restart service components. When a regional disaster that affects all available zones occurs, ensure that all data except the master key is replicated to another region. IBM will also make additional crypto units available in a different region and manage routing requests to the new crypto units. When a regional disaster that affects all available zones occurs, load your master key to the new crypto units that IBM provisions in a different region for restoring data. You can also enable and initialize failover crypto units before a disaster occurs, which reduces the downtime. \n Availability Provide high availability capabilities, such as IBM-owned infrastructure in multizone regions, to meet local access and low latency requirements for each supported region. Use the list of [available regions](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-regions) to plan for and create new instances of the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-shared-responsibilities"},{"document_id":"ibmcld_09494-7-2307","score":20.659718,"text":"\nBackups and Disaster Recovery \n\n\n\n Application Backups \n\nData used by applications within the Maximo Application Suite portfolio are backed up according to the following:\n\nAll backups are encrypted. Communication between applications, backup scripts the storage layer and DB services are perfromed via secure transport and accessed only via private endpoints that are offered by the service. Production backups are performed once a day. Backups are stored in a separate IBM Cloud data center location.\n\n\n\n\n\n System Configuration Backups \n\nMaximo Application Suite utilizes different components to deliver the applications to clients. Each of these services are backed up using the appropriate backup tool for that component. In general, all component backups:\n\n\n\n* are encrypted\n* are taken daily\n* are stored in a separate data center\n* are saved for 30 days\n\n\n\n\n\n\n\n Database Backup Retention \n\nDatabase backups will be retained for the standard duration of 14 days for Production environments and 7 days for Non-Production environments. In scenarios where the customer would like to retain a backup for longer than the standard duration outlined, the IBM SRE team will perform a database backup and save it to the COS bucket. It will then be the responsibility of the customer to download and maintain these backups. If a restore using one of these downloaded backups is required, the customer will need to upload the backup back to the COS bucket and open a case specifying which backup to use and for which environment they would like the restore.\n\n\n\n\n\n Restore \n\nRestore requests must be submitted via case (ticket) through the IBM Support Community Portal. The expected turn around time will depend on the severity and the size of the restore required. Generally for non-production systems, expect 1 - 3 days for a restore to happen. Database restore can only be done to one of the previous daily backups (cannot restore to point in time).\n\n\n\n\n\n Disaster Recovery \n\nIn the event of a DR issue with the Maximo Application Suite Dedicated Service offering for a specific customer, IBM's focus will be in the following order:\n\n\n\n1. Recover the existing infrastructure in place\n2. Recover within the same IBM Cloud data center to a new infrastructure\n3. Recover to a secondary IBM Cloud data center","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-ms?topic=mas-ms-backups-and-disaster-recovery"},{"document_id":"ibmcld_07502-5502-7788","score":20.497042,"text":"\nThe disaster recovery kit is an off-site and protected repository that includes hardware, software, and system secure configurations, one-time keys, and the disaster recovery plan. Use this disaster recovery kit during an incident response to restore services.\n\n\n\n Infrastructure as code \n\nInfrastructure as code ensures that good backup practices are implemented in a uniform way across the organization. Include implementation of backups as part of deployable architectures. Keep backup configuration close to provisioning code so that it is easier to ensure that backups are adjusted as information system changes occur. Create and configure backup accounts as code.\n\n\n\n\n\n Backup accounts \n\nEach BU account group should include a separate backup account and an additional backup account should be used for the centralized accounts. These backup accounts provide an extra layer of protection for the confidentiality and integrity of the backed up data. If credentials to a source account are compromised, it should not be possible to use that access to tamper with backups.\n\nSupporting this effort, authorization to backup data in the backup account should use service-to-service or service to trusted profile authorization where possible. Otherwise, use secure storage of credentials with least privilege access.\n\nIf you are using Cloud Object Storage for backup, at minimum, use separate buckets for backing up different workload accounts. Also, use separate backup credentials for each bucket where service to service policies are not possible. Use Cloud Object Storage versioning or [immutable buckets](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) for maximum security.\n\nServices that provide built in backup facilities might have limitations regarding backup accounts.\n\n\n\n\n\n Service-specific considerations \n\n\n\n IBM Cloud Databases \n\n[IBM Cloud Databases](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-about) provide automatic daily backups that are stored in the same account and geography. Backups are typically stored in [cross-regional storage](https:\/\/cloud.ibm.com\/docs\/cloud-databases?topic=cloud-databases-dashboard-backups&interface=uibackup-locations) and should therefore be immune to a single region outage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/enterprise-account-architecture?topic=enterprise-account-architecture-bcdr"},{"document_id":"ibmcld_14774-27023-28718","score":20.398167,"text":"\nIf a local restore is needed, the VMware datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the protected region HPCS instance through the KMIP for VMware service.\n5. Veeam network encryption is used for file and backup copy jobs to the recovery region.\n6. VM backup files are encrypted on disk in the recovery region Veeam Repository with Veeam encryption.\n7. If a restore is needed in the recovery region, the Veeam datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the recovery region HPCS instance through the KMIP for VMware service.\n\n\n\nFor more information about Veeam encryption, see [Encryption standards](https:\/\/helpcenter.veeam.com\/docs\/backup\/vsphere\/encryption_standards.html?ver=100).\n\nIn the IBM Cloud for VMware\u00ae Regulated Workloads dual region design for SaaS Consumer key management, then the same encryption keys are required in the recovery region as used in the protected region. Currently, HPCS does not support the same encryption keys in two regions. If a failure of the first HPCS instance occurs, keys can be restored to another HPCS instance in another region.\n\nFor more information, see:\n\n\n\n* [HPCS cross-region disaster recovery](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-drcross-region-disaster-recovery)\n* [Restoring your data from another region](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data)\n\n\n\n\n\n\n\n Related links \n\n\n\n* [Caveonix integration](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-caveonix)\n* [Veeam on IBM Cloud overview](https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeamvm_overview)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vrw-dualregion-design"},{"document_id":"ibmcld_08622-1505-3356","score":20.378963,"text":"\nTo use failover crypto units to restore data in a regional disaster, make sure that you initialize and configure all the failover crypto units the same as the operational crypto units before the disaster happens. For more information about initialization approaches, see [Introducing service instance initialization approaches](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-initialize-instance-mode).\n\n\n\n\n\n Restoring your data by opening an IBM support ticket \n\nIf you don't enable failover crypto units or you are using Hyper Protect Crypto Services with Unified Key Orchestrator, you need to open an IBM support ticket to restore your data. IBM can then provision a new service instance for you in another region by using the same instance ID, and restore all the key resources from the backup. And then, you need to load your\n\nmaster keyto the new service instance in the new region.\n\nIn the process, you're the only person who owns the master key. IBM administrators or any third-party users cannot access your data or keys in the backup or the restored service instance.\n\nTo restore a backup to an existing service instance, follow these steps:\n\n\n\n1. In the IBM Cloud console, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/217f108cc44e2ce15fb692d4b57b4c628464e908\/icons\/help.svg) > Support center from the IBM Cloud console menu barto enter the Support Center. Click View all in the Recent support cases panel and click Create new case. Or, you can directly go to the [Manage cases page](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) and click Create new case.\n2. On the Create a case page displayed, select the offering Hyper Protect Crypto Services, and then specify the following values:\n\n\n\nTable 1. Describes the fields required for creating a case\n\n Field name Action \n\n Subject Enter Disaster recovery.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-restore-data"},{"document_id":"ibmcld_09515-7-2313","score":20.228333,"text":"\nBackups and Disaster Recovery \n\n\n\n Application Backups \n\nData used by applications within the Maximo Application Suite portfolio are backed up according to the following:\n\nAll backups are encrypted. Communication between applications, backup scripts the storage layer and DB services are perfromed via secure transport and accessed only via private endpoints that are offered by the service. Production backups are performed once a day. Backups are stored in a separate AWS data center location.\n\n\n\n\n\n System Configuration Backups \n\nMaximo Application Suite utilizes different components to deliver the applications to clients. Each of these services are backed up using the appropriate backup tool for that component. In general, all component backups:\n\n\n\n* are encrypted\n* are taken daily\n* are stored in a separate data center\n* are saved for 30 days\n\n\n\n\n\n\n\n Database Backup Retention \n\nDatabase backups will be retained for the standard duration of 14 days for Production environments and 7 days for Non-Production environments. In scenarios where the customer would like to retain a backup for longer than the standard duration outlined, the IBM SRE team will perform a database backup and save it to the COS bucket. It will then be the responsibility of the customer to download and maintain these backups. If a restore using one of these downloaded backups is required, the customer will need to upload the backup back to the COS bucket and open a case specifying which backup to use and for which environment they would like the restore.\n\n\n\n\n\n Restore \n\nRestore requests must be submitted via case (ticket) through the IBM Support Community Portal. The expected turn around time will depend on the severity and the size of the restore required. Generally expect 1 - 3 days for a restore to happen. Database restore can only be done to one of the previous daily backups (cannot restore to point in time).\n\n\n\n\n\n Disaster Recovery \n\nIn the event of a DR issue with the Maximo Application Suite SaaS offering for a specific customer, IBM's focus will be in the following order:\n\n\n\n1. Recover the existing infrastructure in place\n2. Recover within the same AWS data center to a new infrastructure\n3. Recover to a secondary AWS data center\n\n\n\nIn the event a disaster is declared, the base parameters are:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mas-saas?topic=mas-saas-backups-and-disaster-recovery"},{"document_id":"ibmcld_08511-7-2392","score":20.225323,"text":"\nHigh availability and disaster recovery \n\nIBM Cloud\u00ae Hyper Protect Crypto Services is a highly available, regional service with automatic features that help keep your applications secure and operational.\n\nLearn more about availability and disaster recovery strategies of Hyper Protect Crypto Services.\n\n\n\n Locations, tenancy, and availability \n\nYou can create Hyper Protect Crypto Services resources in one of the supported [IBM Cloud regions](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-regions), which represent the geographic area where your Hyper Protect Crypto Services requests are handled and processed. Each IBM Cloud region contains [multiple availability zones](https:\/\/www.ibm.com\/cloud\/data-centers\/) to meet local access, low latency, and security requirements for the region.\n\nAs you plan your encryption at rest strategy with IBM Cloud, keep in mind that provisioning Hyper Protect Crypto Services in a region that is nearest to you is more likely to result in faster, more reliable connections when you interact with the Hyper Protect Crypto Services APIs. Choose a specific region if the users, apps, or services that depend on a Hyper Protect Crypto Services resource are geographically concentrated. Users and services who are far away from the region might experience higher latency.\n\nYour encryption keys are confined to the region that you created them in. Hyper Protect Crypto Services does not copy or export encryption keys to other regions.\n\n\n\n\n\n In-region data redundancy and failover \n\nMultiple\n\ncrypto unitsin a service instance are automatically synchronized and load balanced across multiple availability zones. If one available zone that contains your provisioned service instance cannot be accessed, Hyper Protect Crypto Services has automatic in-region data failover in place. The service follows IBM Cloud requirements for planning and recovering from disaster events. For more information, see [Disaster recovery](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-zero-downtimedisaster-recovery).\n\n\n\n\n\n Cross-region disaster recovery \n\nIBM also performs cross-region backup for your key resources. Your data is automatically backed up in another supported region daily. Depending on where you create your instance and your requirements for recovery time, you can restore your data in case of a regional disaster with the following options:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-ha-dr"},{"document_id":"ibmcld_14533-1761-4064","score":20.076101,"text":"\nThe encryption key is not stored and is unavailable to IBM. After the VMware Cloud Director Data Center is deleted, all backups are deleted, and cannot be recovered.\n\n\n\n\n\n High availability and disaster recovery \n\nThe VMware Shared management service is initially only offered in the IBM Cloud NA South and Europe regions. Recovering from potential disasters that affect an entire location requires planning and preparation.\n\n\n\n* You are responsible for understanding your configuration, customization, and usage of the service.\n* You are responsible for enabling your VMs or virtual applications (vApps) to participate in the provided backup service.\n* You are responsible for being ready to restore all instances of your VMs or vApps used in the service in the restored location or new location.\n\n\n\n\n\n High availability \n\nVMware Shared supports high availability of the VMware Cloud Director service itself. The service achieves high availability automatically and transparently by using the Multizone region (MZR) feature that is provided by IBM Cloud.\n\nHowever, you cannot configure workloads that are running VMs and vApps in a high availability manner across multiple IBM Cloud data center sites. VMware Shared currently allows workloads to operate in only one IBM Cloud data center site.\n\nUse VMware Shared with vCenter Server to achieve high availability. You can deploy vCenter Server in multiple IBM Cloud data center regions.\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery can become an issue if an IBM Cloud location experiences a significant failure that includes the potential loss of data. Because MZRs are not available across locations, you must wait for IBM to bring a location back online if it becomes unavailable. If underlying data services are compromised by the failure, you must also wait for IBM to restore those data services.\n\nIf a catastrophic failure occurs, IBM might not be able to recover data from database backups. In this case, you need to restore your data to return your service instance to its most recent state. You can restore the data to the same or to a different location, including a vCenter Server instance.\n\nYour disaster recovery plan includes knowing, preserving, and being prepared to restore all data that is maintained on IBM Cloud.\n\n\n\n\n\n\n\n Related links","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_data"},{"document_id":"ibmcld_14738-7598-10031","score":20.013391,"text":"\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Encryption Provide secure SSL connections to administration portals and replication endpoints. Workload can be deployed by using AES 256-bit encrypted data stores with unique key per customer instance. Backups are encrypted uniquely per customer. Choose encrypted data stores when you are deploying workloads into the environment where appropriate. Use encrypted networking for workload to workload and workload to IBM Cloud Service connections. Use the IBM Cloud private network where appropriate. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Backup of management configuration data Conduct backups of the management component configurations. These backups include single-tenant vCenter Server, VMware NSX-T, VMware Cloud Director\u2122, and service configurations. Offsite immutable backup copies are enabled in an independent backup account and they run daily. \n Backup of workloads Enable backup services for customer workload. Choose and implement a backup provider for critical workloads. For more information, see [Understanding business continuity and disaster recovery](https:\/\/cloud.ibm.com\/docs\/vmware-service?topic=vmware-service-bc-dr). \n Recovery of configuration Conduct recovery in the original data center after the infrastructure is available. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, provide customer restore services after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-vmaas-understand-responsib"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2021073465,"ndcg_cut_10":0.2021073465}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16035-7-2023","score":15.593822,"text":"\nAbout data encryption for VPC \n\nIBM Cloud\u00ae takes security seriously and understands the importance of encrypting data to keep it safe. Block Storage for VPC volumes, snapshots, and File Storage for VPC file shares are automatically encrypted by using IBM-managed encryption. You can also choose to manage your own encryption for volumes, file shares, and custom images by using customer-managed encryption.\n\n\n\n IBM-managed encryption \n\nBy default, VPC volumes and file shares are encrypted at rest with IBM-managed encryption. The service comes with no additional cost.\n\nIBM-managed encryption uses the following industry standard protocols:\n\n\n\n* AES-256 encryption.\n* Keys are managed in-house with Key Management Interoperability Protocol (KMIP).\n* The self-encrypting drives in the Storage architecture are validated for Federal Information Processing Standard (FIPS) Publication 140-2 Level 2.\n* Storage architecture is validated for Federal Information Security Management Act (FISMA), and the Health Insurance Portability and Accountability Act (HIPAA)\n* Storage architecture is also validated for Payment Card Industry (PCI), Basel II, California Security Breach Information Act (SB 1386), and EU Data Protection Directive 95\/46\/EC compliance.\n\n\n\n\n\n\n\n Customer-managed encryption \n\nFor end-to-end encryption in the IBM Cloud, you can use customer-managed encryption. Your data is protected while at rest, and also in transit from the storage to the hypervisor and host. You are responsible for encrypting your data outside the VPC.\n\nWith customer-managed encryption, you can bring your own customer root key (CRK) to the cloud or have a [key management service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutkms-for-byok) (KMS) generate a key for you. Root keys are used to encrypt volume, file share, and custom image passphrases with [envelope encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-envelope-encryption-byok), a process that wraps a key with another key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-about"},{"document_id":"ibmcld_15710-7-2109","score":15.566457,"text":"\nSecuring your data in VPC \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Virtual Private Cloud, it's important to know exactly what data is stored and encrypted and how you can delete any stored personal data. Data encryption with your own root keys is available by using a supported key management service (KMS).\n\nVPN for VPC does not store any customer data other than what is required to configure VPN gateways, connections, and policies. Data that is transmitted through a VPN gateway is not encrypted by IBM. Data about your specific VPN and policy configurations are encrypted in transit and at rest. VPN configuration data is deleted upon your request through API or User Interface.\n\n\n\n How your data is stored and encrypted in VPC \n\nAll block storage volumes are encrypted by default with IBM-managed encryption. IBM\u00ae-managed keys are generated and securely stored in a block storage vault that is backed by Consul and maintained by IBM Cloud\u00ae operations.\n\nFor more security and control, you can protect your data with your own root keys (also called a customer root key or CRK). This feature is commonly called Bring Your Own Key, or BYOK. Root keys encrypt the keys that safeguard your data. You can import your root keys to Key Protect or Hyper Protect Crypto Services, or have either key management service create one for you.\n\nThe KMS stores your key and makes it available during volume and custom image encryption. Key Protect provides FIPS 140-2 Level 3 compliance. Hyper Protect Crypto Services offers the highest level of security with FIPS 140-2 Level 4 compliance. Your key material is protected in transit (when it's transported) and at rest (when it is stored).\n\nCustomer-managed encryption is available for custom images, boot volumes, and data volumes. When an instance is provisioned from an encrypted custom image, its boot volume is encrypted by using the image\u2019s root key. You can also choose a different root key. Data volumes are encrypted by using root keys when you provision a virtual server instance or when you create a stand-alone volume.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-mng-data"},{"document_id":"ibmcld_08007-5991-8147","score":15.431693,"text":"\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage) is an alternative storage option that is useful for certain use cases, including backup and recovery, data archiving, cloud-native application building, and AI and big data analytics. Object Storage stores encrypted and dispersed data across multiple geographic locations.\n\nBy default, all objects that are stored in Object Storage are encrypted by using randomly generated keys and an all-or-nothing-transform (AONT). While this default encryption model provides at-rest security, financial service workloads need full control over the data encryption keys used. Again, Hyper Protect Crypto Services should be used for this purpose.\n\n\n\n\n\n\n\n Using IBM Cloud services outside of a VPC \n\nTo connect to IBM Cloud services from your VPC, you need to use [Virtual Private Endpoints (VPE) for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpe). In the reference architecture diagram, VPEs appear in the middle subnets of the workload VPC. With VPEs, you can connect to supported IBM Cloud services from your VPC network by using the IP addresses of your choosing, which is allocated from a subnet within your VPC.\n\nVPE is an evolution of the private connectivity to IBM Cloud services. VPEs are virtual IP interfaces that are bound to an endpoint gateway created on a per service, or service instance, basis (depending on the service operation model). The endpoint gateway is a virtualized function that scales horizontally, is redundant and highly available, and spans all availability zones of your VPC. Endpoint gateways enable communications from virtual server instances within your VPC and IBM Cloud service on the private backbone. VPE for VPC gives you the experience of controlling all the private addressing within your cloud.\n\n\n\n\n\n\n\n Variation with edge\/transit VPC for public internet access \n\nYou might want to allow consumers to access your service through the public internet. This base architecture can be adapted to securely enable this type of access as shown in the following diagram, which introduces a new edge VPC.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-vsi"},{"document_id":"ibmcld_15851-3239-3883","score":15.219133,"text":"\nEnd-to-end encryption \n\nAlthough IBM Cloud VPC doesn't provide end-to-end encryption, it allows for it. For example, if you have a secure endpoint on a virtual server instance (such as an HTTPS server on port 443), you can attach a floating IP to that instance, and then your connection is end-to-end encrypted from the client to the server on port 443. Nothing in the path forces a decryption. However, if you use an insecure protocol such as HTTP on port 80, your data is not encrypted from end to end.\n\nIf your application requires end-to-end encryption, then it is your responsibility to ensure that your connection is encrypted end-to-end.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-security-in-your-vpc&interface=ui"},{"document_id":"ibmcld_16035-10237-12019","score":15.088312,"text":"\nIBM-managed encryption on the storage system is always applied, even when you use customer-managed encryption. This key protects your data while in transit and while at rest.\n\nEncryption of the network link between your workload outside of IBM Cloud and a workload inside IBM Cloud is your responsibility. For more information, see [Encryption in Security and regulation compliance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-responsibilities-vpcsecurity-compliance).\n* A data encryption key (DEK) encrypts data within the QCOW2 file and secures the block data clusters in the virtual disk. The DEK is managed by open source QEMU technology and auto-generated when a QCOW2 file is created.\n\nFor Block Storage for VPC volumes that are created from stock images, the DEK is generated by QEMU running on IBM-provided KVM hypervisors. For Block Storage for VPC volumes that are created from custom images, it is generated by QEMU that runs on your on-premises node. The DEK (an AES-256 key) is encrypted with a LUKS passphrase and stored encrypted in the QCOW2 file.\n* A LUKS passphrase (also called a \"key encryption key\") encrypts and decrypts the DEK. This key is managed by the VPC generation 2 infrastructure and is encrypted by your root key. It is stored as metadata that is associated with the Block Storage for VPC volume that contains the QCOW2 file.\n* A customer root key that encrypts volume, share, and custom image passphrases with envelope encryption, which creates a wrapped DEK or WDEK. Root keys are customer-managed from KMS instances (Key Protect or Hyper Protect Crypto Services), and stored and managed securely within the KMS instance. The root key also unwraps (decrypts) the WDEK, providing access to your encrypted data.\n\n\n\n\n\n\n\n Supported key management services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-about"},{"document_id":"ibmcld_15710-1620-3492","score":14.930093,"text":"\nYour key material is protected in transit (when it's transported) and at rest (when it is stored).\n\nCustomer-managed encryption is available for custom images, boot volumes, and data volumes. When an instance is provisioned from an encrypted custom image, its boot volume is encrypted by using the image\u2019s root key. You can also choose a different root key. Data volumes are encrypted by using root keys when you provision a virtual server instance or when you create a stand-alone volume.\n\nImages and volumes are often referred to as being encrypted with a root key when, in fact,\n\nenvelope encryptionis used. Internally, each image or volume is encrypted with adata encryption key (DEK), which is an open source QEMU technology that is used by the IBM Cloud VPC Generation 2 infrastructure. A LUKS passphrase, also called a key encryption key, encrypts the DEK. The LUKS passphrase is then encrypted with a root key, creating what is called a wrapped DEK (WDEK). For more information about IBM Cloud VPC key encryption technology, see [IBM Cloud VPC Generation 2 encryption technology](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutbyok-technologies).\n\nFor example, if you provision two volumes by using the same root key, unique passphrases are generated for each volume, which are then encrypted with the root key. Envelope encryption provides more protection for your data, and ensures that the root key can be rotated without having to reencrypt the data. For more information about envelope encryption, see [Protecting your sensitive data in VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-mng-datadata-encryption).\n\nAll your interaction with VPN for VPC is encrypted. For example, when you use an API or interact with the service through the User Interface to configure VPN gateways and VPN connections, all such interactions are encrypted end-to-end.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-mng-data"},{"document_id":"ibmcld_01289-5532-6265","score":14.897224,"text":"\nIn fact, the system can lose multiple disks in the cluster simultaneously without degrading customer performance or adverse risk of data loss. Redundant network ports and paths protect against network failures across the cloud connections.\n\n\n\n\n\n Encryption \n\nIBM Cloud\u00ae provides full-disk encryption without compromising storage application performance. For more information about encryption of File Storage for Classic, see [Securing your data in File Storage](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-mng-data). For more information about provider- and customer-managed encryption in a VPC, see [Data encryption for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-storageavailability"},{"document_id":"ibmcld_15389-4053-5815","score":14.85391,"text":"\nEncryption Specifies provider-managed or [customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-encryption). \n Encryption instance For customer-managed encryption, link to the Key Protect or Hyper Protect Crypto Services instance. \n Key ID Copiable customer root key ID. \n ID For customer-managed encryption, the UUID generated when you created the file share. \n Size File share size in GB. \n Created Date the file share was created. \n Mount target access mode <br><br>New Access to the file share is granted by either a security group within a subnet or to any virtual server instance in the VPC. Click the pencil icon to switch access modes. Security group access is available only to file shares created with the [dp2 profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-profiles&interface=uidp2-profile). For more information, see the [Mount target access modes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-about&interface=apifs-mount-access-mode). \n Profile, size, and IOPS \n Size File share size in GB. \n IOPS tier IOPS tier [profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-profiles) that defines the file share performance. For example, a 3 IOPS\/GB general-purpose profile. \n Max IOPS Maximum IOPS for the specified profile. \n Mount targets Number of mount targets associated with the file share. You can have one mount target per VPC per file share. You can create more mount targets for other VPCs. \n Name Name of the mount target. \n Virtual private cloud Click the name to go to the details page for that VPC, where you can see a [list of file shares](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-view&interface=clifs-view-shares-vpc) that have a mount target to the VPC.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-view&interface=cli"},{"document_id":"ibmcld_15388-4053-5815","score":14.839874,"text":"\nEncryption Specifies provider-managed or [customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-encryption). \n Encryption instance For customer-managed encryption, link to the Key Protect or Hyper Protect Crypto Services instance. \n Key ID Copiable customer root key ID. \n ID For customer-managed encryption, the UUID generated when you created the file share. \n Size File share size in GB. \n Created Date the file share was created. \n Mount target access mode <br><br>New Access to the file share is granted by either a security group within a subnet or to any virtual server instance in the VPC. Click the pencil icon to switch access modes. Security group access is available only to file shares created with the [dp2 profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-profiles&interface=uidp2-profile). For more information, see the [Mount target access modes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-about&interface=apifs-mount-access-mode). \n Profile, size, and IOPS \n Size File share size in GB. \n IOPS tier IOPS tier [profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-profiles) that defines the file share performance. For example, a 3 IOPS\/GB general-purpose profile. \n Max IOPS Maximum IOPS for the specified profile. \n Mount targets Number of mount targets associated with the file share. You can have one mount target per VPC per file share. You can create more mount targets for other VPCs. \n Name Name of the mount target. \n Virtual private cloud Click the name to go to the details page for that VPC, where you can see a [list of file shares](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-view&interface=apifs-view-shares-vpc) that have a mount target to the VPC.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-view&interface=api"},{"document_id":"ibmcld_15391-4053-5814","score":14.834153,"text":"\nEncryption Specifies provider-managed or [customer-managed encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-encryption). \n Encryption instance For customer-managed encryption, link to the Key Protect or Hyper Protect Crypto Services instance. \n Key ID Copiable customer root key ID. \n ID For customer-managed encryption, the UUID generated when you created the file share. \n Size File share size in GB. \n Created Date the file share was created. \n Mount target access mode <br><br>New Access to the file share is granted by either a security group within a subnet or to any virtual server instance in the VPC. Click the pencil icon to switch access modes. Security group access is available only to file shares created with the [dp2 profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-profiles&interface=uidp2-profile). For more information, see the [Mount target access modes](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-about&interface=apifs-mount-access-mode). \n Profile, size, and IOPS \n Size File share size in GB. \n IOPS tier IOPS tier [profile](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-profiles) that defines the file share performance. For example, a 3 IOPS\/GB general-purpose profile. \n Max IOPS Maximum IOPS for the specified profile. \n Mount targets Number of mount targets associated with the file share. You can have one mount target per VPC per file share. You can create more mount targets for other VPCs. \n Name Name of the mount target. \n Virtual private cloud Click the name to go to the details page for that VPC, where you can see a [list of file shares](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-view&interface=uifs-view-shares-vpc) that have a mount target to the VPC.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-view&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01289-5532-6265","score":16.205202,"text":"\nIn fact, the system can lose multiple disks in the cluster simultaneously without degrading customer performance or adverse risk of data loss. Redundant network ports and paths protect against network failures across the cloud connections.\n\n\n\n\n\n Encryption \n\nIBM Cloud\u00ae provides full-disk encryption without compromising storage application performance. For more information about encryption of File Storage for Classic, see [Securing your data in File Storage](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-mng-data). For more information about provider- and customer-managed encryption in a VPC, see [Data encryption for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-storageavailability"},{"document_id":"ibmcld_08007-5991-8147","score":16.14744,"text":"\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage) is an alternative storage option that is useful for certain use cases, including backup and recovery, data archiving, cloud-native application building, and AI and big data analytics. Object Storage stores encrypted and dispersed data across multiple geographic locations.\n\nBy default, all objects that are stored in Object Storage are encrypted by using randomly generated keys and an all-or-nothing-transform (AONT). While this default encryption model provides at-rest security, financial service workloads need full control over the data encryption keys used. Again, Hyper Protect Crypto Services should be used for this purpose.\n\n\n\n\n\n\n\n Using IBM Cloud services outside of a VPC \n\nTo connect to IBM Cloud services from your VPC, you need to use [Virtual Private Endpoints (VPE) for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpe). In the reference architecture diagram, VPEs appear in the middle subnets of the workload VPC. With VPEs, you can connect to supported IBM Cloud services from your VPC network by using the IP addresses of your choosing, which is allocated from a subnet within your VPC.\n\nVPE is an evolution of the private connectivity to IBM Cloud services. VPEs are virtual IP interfaces that are bound to an endpoint gateway created on a per service, or service instance, basis (depending on the service operation model). The endpoint gateway is a virtualized function that scales horizontally, is redundant and highly available, and spans all availability zones of your VPC. Endpoint gateways enable communications from virtual server instances within your VPC and IBM Cloud service on the private backbone. VPE for VPC gives you the experience of controlling all the private addressing within your cloud.\n\n\n\n\n\n\n\n Variation with edge\/transit VPC for public internet access \n\nYou might want to allow consumers to access your service through the public internet. This base architecture can be adapted to securely enable this type of access as shown in the following diagram, which introduces a new edge VPC.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-vsi"},{"document_id":"ibmcld_07986-17657-19794","score":16.050808,"text":"\n[Block Storage for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about) provides hypervisor-mounted, high-performance data storage for your virtual server instances that you can provision within a VPC. The VPC infrastructure provides rapid scaling across zones and extra performance and security.\n\nBlock Storage for VPC provides primary boot volumes and secondary data volumes. Boot volumes are automatically created and attached during instance provisioning. Data volumes can be created and attached during instance provisioning as well, or as stand-alone volumes that you can later attach to an instance. To protect your data, you can use your own encryption keys with Hyper Protect Crypto Services.\n\n\n\n\n\n IBM Cloud Object Storage \n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage) stores encrypted and dispersed data across multiple geographic locations. Object Storage is available with three types of resiliency: Cross Region, Regional, and Single Data Center. Cross Region provides higher durability and availability than using a single region at the cost of slightly higher latency. Regional service reverses those tradeoffs, and distributes objects across multiple availability zones within a single region. If a given region or availability zone is unavailable, the object store continues to function without impediment. Single Data Center distributes objects across multiple machines within the same physical location.\n\nUsers of Object Storage refer to their binary data, such as files, images, media, archives, or even entire databases as objects. Objects are stored in a bucket, the container for their unstructured data. Buckets contain both inherent and user-defined metadata. Finally, objects are defined by a globally unique combination of the bucket name and the object key, or name.\n\n\n\n\n\n\n\n Security \n\n\n\n IBM Cloud Hyper Protect Crypto Services \n\n[Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-overview) is a dedicated key management service and hardware security module (HSM) based on IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-about"},{"document_id":"ibmcld_15175-5320-7097","score":15.826206,"text":"\nSelect the encryption type, either customer-managed encryption or IBM-managed encryption (see [Table 2](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-ifvencrypt-custom-images)).\n5. On the side panel, click Create custom image.\n\n\n\n\n\n\n\n Select the encryption type \n\nTo complete your image from volume, select either IBM-managed encryption or customer-managed encryption. Table 2 describes these options as they appear in the UI.\n\n\n\nTable 2. Encryption types\n\n Field Value \n\n Encryption The default selection is No encryption. If you have not encrypted your image by using QEMU, use the default value, No encryption. If you are importing an image that you encrypted by using QEMU and your own passphrase, select the key management service where your customer root key (CRK) that protects your passphrase is stored. Select either Key Protect or Hyper Protect Crypto Services. \n Encryption service instance For an encrypted image, select the specific instance of the key management service where your CRK that wraps your encryption passphrase is stored. \n Key name Select the customer root key (CRK) that you used to wrap your encryption passphrase. \n Key ID Shows the key ID that is associated with the data encryption key that you selected. \n\n\n\nFor more information, see [Setting up your key management service and keys](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-encrypted-custom-imagekms-prereqs).\n\n\n\n\n\n View and use your image from volume \n\nWhen the image from a volume is created, it appears in the list of custom images.\n\n\n\n1. In the [IBM Cloud console](https:\/\/cloud.ibm.com\/login), go to the menu ![menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/icons\/icon_hamburger.svg) > VPC Infrastructure > Compute > Images.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-ifv"},{"document_id":"ibmcld_16035-10237-12019","score":15.132951,"text":"\nIBM-managed encryption on the storage system is always applied, even when you use customer-managed encryption. This key protects your data while in transit and while at rest.\n\nEncryption of the network link between your workload outside of IBM Cloud and a workload inside IBM Cloud is your responsibility. For more information, see [Encryption in Security and regulation compliance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-responsibilities-vpcsecurity-compliance).\n* A data encryption key (DEK) encrypts data within the QCOW2 file and secures the block data clusters in the virtual disk. The DEK is managed by open source QEMU technology and auto-generated when a QCOW2 file is created.\n\nFor Block Storage for VPC volumes that are created from stock images, the DEK is generated by QEMU running on IBM-provided KVM hypervisors. For Block Storage for VPC volumes that are created from custom images, it is generated by QEMU that runs on your on-premises node. The DEK (an AES-256 key) is encrypted with a LUKS passphrase and stored encrypted in the QCOW2 file.\n* A LUKS passphrase (also called a \"key encryption key\") encrypts and decrypts the DEK. This key is managed by the VPC generation 2 infrastructure and is encrypted by your root key. It is stored as metadata that is associated with the Block Storage for VPC volume that contains the QCOW2 file.\n* A customer root key that encrypts volume, share, and custom image passphrases with envelope encryption, which creates a wrapped DEK or WDEK. Root keys are customer-managed from KMS instances (Key Protect or Hyper Protect Crypto Services), and stored and managed securely within the KMS instance. The root key also unwraps (decrypts) the WDEK, providing access to your encrypted data.\n\n\n\n\n\n\n\n Supported key management services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-about"},{"document_id":"ibmcld_10545-13079-15322","score":15.121907,"text":"\nNon-ideal use cases Multizone clusters, geographically distributed data, or sharing data across multiple app instances. \n\n\n\n\n\n\n\n File Storage for VPC \n\nVirtual Private Cloud\n\n\n\nFile Storage for VPC characteristics\n\n Characteristic Description \n\n Multizone-capable No, as specific to a data center. Data can't be shared across zones, unless you implement your own data replication. \n Ideal data types All \n Data usage pattern Random read-write operations, sequential read-write operations, or write-intensive workloads \n Access Via file system on mounted volume \n Supported Kubernetes access writes ReadWriteOnce (RWO) \n Performance Predictable due to assigned IOPS and size. IOPS are not shared between pods. \n Consistency Strong \n Durability High \n Resiliency Medium as specific to a data center. File storage server is clustered by IBM with redundant networking. \n Availability Medium as specific to a data center. \n Scalability Difficult to extend beyond the data center. You can't change an existing storage tier. \n Encryption None \n Backup and recovery Run kubectl cp. \n Common use cases Mass or single file storage or file sharing across a single zone cluster. \n Non-ideal use cases Multizone clusters, geographically distributed data, or sharing data across multiple app instances. \n\n\n\n\n\n\n\n Block Storage for VPC \n\nVirtual Private Cloud\n\n\n\nBlock Storage for VPC characteristics.\n\n Characteristics Description \n\n Multizone-capable No, as specific to a data center. Data can't be shared across zones, unless you implement your own data replication. \n Ideal data types All \n Data usage pattern Random read-write operations, sequential read-write operations, or write-intensive workloads \n Access Via file system on mounted volume \n Supported Kubernetes access writes ReadWriteOnce (RWO) \n Performance Predictable due to assigned IOPS and size. IOPS are not shared between pods. \n Consistency Strong \n Durability High \n Resiliency Medium as specific to a data center. Block storage server is clustered by IBM with redundant networking. \n Availability Medium as specific to a data center. \n Scalability Difficult to extend beyond the data center. You can't change an existing storage tier. \n Encryption Encryption in transit with Key Protect","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan"},{"document_id":"ibmcld_06104-13071-15314","score":15.121907,"text":"\nNon-ideal use cases Multizone clusters, geographically distributed data, or sharing data across multiple app instances. \n\n\n\n\n\n\n\n File Storage for VPC \n\nVirtual Private Cloud\n\n\n\nFile Storage for VPC characteristics\n\n Characteristic Description \n\n Multizone-capable No, as specific to a data center. Data can't be shared across zones, unless you implement your own data replication. \n Ideal data types All \n Data usage pattern Random read-write operations, sequential read-write operations, or write-intensive workloads \n Access Via file system on mounted volume \n Supported Kubernetes access writes ReadWriteOnce (RWO) \n Performance Predictable due to assigned IOPS and size. IOPS are not shared between pods. \n Consistency Strong \n Durability High \n Resiliency Medium as specific to a data center. File storage server is clustered by IBM with redundant networking. \n Availability Medium as specific to a data center. \n Scalability Difficult to extend beyond the data center. You can't change an existing storage tier. \n Encryption None \n Backup and recovery Run kubectl cp. \n Common use cases Mass or single file storage or file sharing across a single zone cluster. \n Non-ideal use cases Multizone clusters, geographically distributed data, or sharing data across multiple app instances. \n\n\n\n\n\n\n\n Block Storage for VPC \n\nVirtual Private Cloud\n\n\n\nBlock Storage for VPC characteristics.\n\n Characteristics Description \n\n Multizone-capable No, as specific to a data center. Data can't be shared across zones, unless you implement your own data replication. \n Ideal data types All \n Data usage pattern Random read-write operations, sequential read-write operations, or write-intensive workloads \n Access Via file system on mounted volume \n Supported Kubernetes access writes ReadWriteOnce (RWO) \n Performance Predictable due to assigned IOPS and size. IOPS are not shared between pods. \n Consistency Strong \n Durability High \n Resiliency Medium as specific to a data center. Block storage server is clustered by IBM with redundant networking. \n Availability Medium as specific to a data center. \n Scalability Difficult to extend beyond the data center. You can't change an existing storage tier. \n Encryption Encryption in transit with Key Protect","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan"},{"document_id":"ibmcld_06104-11364-13631","score":14.961457,"text":"\nScalability Difficult to extend beyond the data center. You can't change an existing storage tier. \n Encryption At rest \n Backup and recovery Set up periodic snapshots, replicate snapshots, duplicate storage, back up data to IBM Cloud Object Storage, or copy data to and from pod and containers. \n Common use cases Mass or single file storage or file sharing across a single zone cluster. \n Non-ideal use cases Multizone clusters or geographically distributed data. \n\n\n\n\n\n\n\n Classic Block Storage for Classic \n\nClassic infrastructure\n\n\n\nClassic Block Storage characteristics\n\n Characteristics Description \n\n Multizone-capable No, as specific to a data center. Data can't be shared across zones, unless you implement your own data replication. \n Ideal data types All \n Data usage pattern Random read-write operations, sequential read-write operations, or write-intensive workloads \n Access Via file system on mounted volume \n Supported Kubernetes access writes ReadWriteOnce (RWO) \n Performance Predictable due to assigned IOPS and size. IOPS are not shared between pods. \n Consistency Strong \n Durability High \n Resiliency Medium as specific to a data center. Block storage server is clustered by IBM with redundant networking. \n Availability Medium as specific to a data center. \n Scalability Difficult to extend beyond the data center. You can't change an existing storage tier. \n Encryption At rest. \n Backup and recovery Set up periodic snapshots, replicate snapshots, duplicate storage, back up data to IBM Cloud Object Storage, or copy data to and from pod and containers. \n Common use cases Stateful sets, backing storage when you run your own database, or high-performance access for single pods. \n Non-ideal use cases Multizone clusters, geographically distributed data, or sharing data across multiple app instances. \n\n\n\n\n\n\n\n File Storage for VPC \n\nVirtual Private Cloud\n\n\n\nFile Storage for VPC characteristics\n\n Characteristic Description \n\n Multizone-capable No, as specific to a data center. Data can't be shared across zones, unless you implement your own data replication. \n Ideal data types All \n Data usage pattern Random read-write operations, sequential read-write operations, or write-intensive workloads \n Access Via file system on mounted volume","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan"},{"document_id":"ibmcld_10545-11372-13639","score":14.961457,"text":"\nScalability Difficult to extend beyond the data center. You can't change an existing storage tier. \n Encryption At rest \n Backup and recovery Set up periodic snapshots, replicate snapshots, duplicate storage, back up data to IBM Cloud Object Storage, or copy data to and from pod and containers. \n Common use cases Mass or single file storage or file sharing across a single zone cluster. \n Non-ideal use cases Multizone clusters or geographically distributed data. \n\n\n\n\n\n\n\n Classic Block Storage for Classic \n\nClassic infrastructure\n\n\n\nClassic Block Storage characteristics\n\n Characteristics Description \n\n Multizone-capable No, as specific to a data center. Data can't be shared across zones, unless you implement your own data replication. \n Ideal data types All \n Data usage pattern Random read-write operations, sequential read-write operations, or write-intensive workloads \n Access Via file system on mounted volume \n Supported Kubernetes access writes ReadWriteOnce (RWO) \n Performance Predictable due to assigned IOPS and size. IOPS are not shared between pods. \n Consistency Strong \n Durability High \n Resiliency Medium as specific to a data center. Block storage server is clustered by IBM with redundant networking. \n Availability Medium as specific to a data center. \n Scalability Difficult to extend beyond the data center. You can't change an existing storage tier. \n Encryption At rest. \n Backup and recovery Set up periodic snapshots, replicate snapshots, duplicate storage, back up data to IBM Cloud Object Storage, or copy data to and from pod and containers. \n Common use cases Stateful sets, backing storage when you run your own database, or high-performance access for single pods. \n Non-ideal use cases Multizone clusters, geographically distributed data, or sharing data across multiple app instances. \n\n\n\n\n\n\n\n File Storage for VPC \n\nVirtual Private Cloud\n\n\n\nFile Storage for VPC characteristics\n\n Characteristic Description \n\n Multizone-capable No, as specific to a data center. Data can't be shared across zones, unless you implement your own data replication. \n Ideal data types All \n Data usage pattern Random read-write operations, sequential read-write operations, or write-intensive workloads \n Access Via file system on mounted volume","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-storage-plan"},{"document_id":"ibmcld_15710-1620-3492","score":14.861198,"text":"\nYour key material is protected in transit (when it's transported) and at rest (when it is stored).\n\nCustomer-managed encryption is available for custom images, boot volumes, and data volumes. When an instance is provisioned from an encrypted custom image, its boot volume is encrypted by using the image\u2019s root key. You can also choose a different root key. Data volumes are encrypted by using root keys when you provision a virtual server instance or when you create a stand-alone volume.\n\nImages and volumes are often referred to as being encrypted with a root key when, in fact,\n\nenvelope encryptionis used. Internally, each image or volume is encrypted with adata encryption key (DEK), which is an open source QEMU technology that is used by the IBM Cloud VPC Generation 2 infrastructure. A LUKS passphrase, also called a key encryption key, encrypts the DEK. The LUKS passphrase is then encrypted with a root key, creating what is called a wrapped DEK (WDEK). For more information about IBM Cloud VPC key encryption technology, see [IBM Cloud VPC Generation 2 encryption technology](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutbyok-technologies).\n\nFor example, if you provision two volumes by using the same root key, unique passphrases are generated for each volume, which are then encrypted with the root key. Envelope encryption provides more protection for your data, and ensures that the root key can be rotated without having to reencrypt the data. For more information about envelope encryption, see [Protecting your sensitive data in VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-mng-datadata-encryption).\n\nAll your interaction with VPN for VPC is encrypted. For example, when you use an API or interact with the service through the User Interface to configure VPN gateways and VPN connections, all such interactions are encrypted end-to-end.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-mng-data"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_08007-5991-8147","score":19.666222,"text":"\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage) is an alternative storage option that is useful for certain use cases, including backup and recovery, data archiving, cloud-native application building, and AI and big data analytics. Object Storage stores encrypted and dispersed data across multiple geographic locations.\n\nBy default, all objects that are stored in Object Storage are encrypted by using randomly generated keys and an all-or-nothing-transform (AONT). While this default encryption model provides at-rest security, financial service workloads need full control over the data encryption keys used. Again, Hyper Protect Crypto Services should be used for this purpose.\n\n\n\n\n\n\n\n Using IBM Cloud services outside of a VPC \n\nTo connect to IBM Cloud services from your VPC, you need to use [Virtual Private Endpoints (VPE) for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpe). In the reference architecture diagram, VPEs appear in the middle subnets of the workload VPC. With VPEs, you can connect to supported IBM Cloud services from your VPC network by using the IP addresses of your choosing, which is allocated from a subnet within your VPC.\n\nVPE is an evolution of the private connectivity to IBM Cloud services. VPEs are virtual IP interfaces that are bound to an endpoint gateway created on a per service, or service instance, basis (depending on the service operation model). The endpoint gateway is a virtualized function that scales horizontally, is redundant and highly available, and spans all availability zones of your VPC. Endpoint gateways enable communications from virtual server instances within your VPC and IBM Cloud service on the private backbone. VPE for VPC gives you the experience of controlling all the private addressing within your cloud.\n\n\n\n\n\n\n\n Variation with edge\/transit VPC for public internet access \n\nYou might want to allow consumers to access your service through the public internet. This base architecture can be adapted to securely enable this type of access as shown in the following diagram, which introduces a new edge VPC.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-vsi"},{"document_id":"ibmcld_16035-7-2023","score":18.865282,"text":"\nAbout data encryption for VPC \n\nIBM Cloud\u00ae takes security seriously and understands the importance of encrypting data to keep it safe. Block Storage for VPC volumes, snapshots, and File Storage for VPC file shares are automatically encrypted by using IBM-managed encryption. You can also choose to manage your own encryption for volumes, file shares, and custom images by using customer-managed encryption.\n\n\n\n IBM-managed encryption \n\nBy default, VPC volumes and file shares are encrypted at rest with IBM-managed encryption. The service comes with no additional cost.\n\nIBM-managed encryption uses the following industry standard protocols:\n\n\n\n* AES-256 encryption.\n* Keys are managed in-house with Key Management Interoperability Protocol (KMIP).\n* The self-encrypting drives in the Storage architecture are validated for Federal Information Processing Standard (FIPS) Publication 140-2 Level 2.\n* Storage architecture is validated for Federal Information Security Management Act (FISMA), and the Health Insurance Portability and Accountability Act (HIPAA)\n* Storage architecture is also validated for Payment Card Industry (PCI), Basel II, California Security Breach Information Act (SB 1386), and EU Data Protection Directive 95\/46\/EC compliance.\n\n\n\n\n\n\n\n Customer-managed encryption \n\nFor end-to-end encryption in the IBM Cloud, you can use customer-managed encryption. Your data is protected while at rest, and also in transit from the storage to the hypervisor and host. You are responsible for encrypting your data outside the VPC.\n\nWith customer-managed encryption, you can bring your own customer root key (CRK) to the cloud or have a [key management service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutkms-for-byok) (KMS) generate a key for you. Root keys are used to encrypt volume, file share, and custom image passphrases with [envelope encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-envelope-encryption-byok), a process that wraps a key with another key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-about"},{"document_id":"ibmcld_07986-17657-19794","score":18.651651,"text":"\n[Block Storage for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about) provides hypervisor-mounted, high-performance data storage for your virtual server instances that you can provision within a VPC. The VPC infrastructure provides rapid scaling across zones and extra performance and security.\n\nBlock Storage for VPC provides primary boot volumes and secondary data volumes. Boot volumes are automatically created and attached during instance provisioning. Data volumes can be created and attached during instance provisioning as well, or as stand-alone volumes that you can later attach to an instance. To protect your data, you can use your own encryption keys with Hyper Protect Crypto Services.\n\n\n\n\n\n IBM Cloud Object Storage \n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage) stores encrypted and dispersed data across multiple geographic locations. Object Storage is available with three types of resiliency: Cross Region, Regional, and Single Data Center. Cross Region provides higher durability and availability than using a single region at the cost of slightly higher latency. Regional service reverses those tradeoffs, and distributes objects across multiple availability zones within a single region. If a given region or availability zone is unavailable, the object store continues to function without impediment. Single Data Center distributes objects across multiple machines within the same physical location.\n\nUsers of Object Storage refer to their binary data, such as files, images, media, archives, or even entire databases as objects. Objects are stored in a bucket, the container for their unstructured data. Buckets contain both inherent and user-defined metadata. Finally, objects are defined by a globally unique combination of the bucket name and the object key, or name.\n\n\n\n\n\n\n\n Security \n\n\n\n IBM Cloud Hyper Protect Crypto Services \n\n[Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-overview) is a dedicated key management service and hardware security module (HSM) based on IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-about"},{"document_id":"ibmcld_15710-7-2109","score":18.475374,"text":"\nSecuring your data in VPC \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Virtual Private Cloud, it's important to know exactly what data is stored and encrypted and how you can delete any stored personal data. Data encryption with your own root keys is available by using a supported key management service (KMS).\n\nVPN for VPC does not store any customer data other than what is required to configure VPN gateways, connections, and policies. Data that is transmitted through a VPN gateway is not encrypted by IBM. Data about your specific VPN and policy configurations are encrypted in transit and at rest. VPN configuration data is deleted upon your request through API or User Interface.\n\n\n\n How your data is stored and encrypted in VPC \n\nAll block storage volumes are encrypted by default with IBM-managed encryption. IBM\u00ae-managed keys are generated and securely stored in a block storage vault that is backed by Consul and maintained by IBM Cloud\u00ae operations.\n\nFor more security and control, you can protect your data with your own root keys (also called a customer root key or CRK). This feature is commonly called Bring Your Own Key, or BYOK. Root keys encrypt the keys that safeguard your data. You can import your root keys to Key Protect or Hyper Protect Crypto Services, or have either key management service create one for you.\n\nThe KMS stores your key and makes it available during volume and custom image encryption. Key Protect provides FIPS 140-2 Level 3 compliance. Hyper Protect Crypto Services offers the highest level of security with FIPS 140-2 Level 4 compliance. Your key material is protected in transit (when it's transported) and at rest (when it is stored).\n\nCustomer-managed encryption is available for custom images, boot volumes, and data volumes. When an instance is provisioned from an encrypted custom image, its boot volume is encrypted by using the image\u2019s root key. You can also choose a different root key. Data volumes are encrypted by using root keys when you provision a virtual server instance or when you create a stand-alone volume.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-mng-data"},{"document_id":"ibmcld_01289-5532-6265","score":18.362,"text":"\nIn fact, the system can lose multiple disks in the cluster simultaneously without degrading customer performance or adverse risk of data loss. Redundant network ports and paths protect against network failures across the cloud connections.\n\n\n\n\n\n Encryption \n\nIBM Cloud\u00ae provides full-disk encryption without compromising storage application performance. For more information about encryption of File Storage for Classic, see [Securing your data in File Storage](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-mng-data). For more information about provider- and customer-managed encryption in a VPC, see [Data encryption for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-storageavailability"},{"document_id":"ibmcld_16033-7-1880","score":18.292128,"text":"\nCross-account encryption for file storage resources \n\nFile Storage for VPC supports cross-account customer-managed encryption. IBM Cloud\u00ae Virtual Private Cloud customers can authorize access to a customer root key (CRK) for users of another account. Then, those users can use the CRK to encrypt a new file share in their own account.\n\nIBM Cloud\u00ae File Storage for VPC is available for customers with special approval to preview this service in the Frankfurt, London, Madrid, Dallas, Toronto, Washington, Sao Paulo, Sydney, Osaka, and Tokyo regions. Contact your IBM Sales representative if you are interested in getting access.\n\n\n\n About cross account key access and use \n\nCustomer root keys in one account can be made available to users of another account to use when they create an encrypted file share.\n\nA privileged user from the account that owns the root key must [invite the user](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamuserinv) of the second account, and set the IAM delegated policy to the root keys. For more information, see [Granting access to keys with Key Protect](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grant-access-keys) and [Granting access to keys with Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-grant-access-keys).\n\nIf the invited user is already a member of IBM Cloud, they receive an invitation link in their notifications and by email. The user in the account that's creating the file share can be the same user as the owner of the root key in the other account.\n\nWhen the invited user makes the [API request](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-byok-cross-acct-key-filebyok-cross-key-acct-create-API) to create the encrypted file share in their own account, they can specify the CRN of the root key of the first account in the encryption_key property.\n\n\n\n\n\n Restrictions","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-byok-cross-acct-key-file"},{"document_id":"ibmcld_16035-10237-12019","score":18.174099,"text":"\nIBM-managed encryption on the storage system is always applied, even when you use customer-managed encryption. This key protects your data while in transit and while at rest.\n\nEncryption of the network link between your workload outside of IBM Cloud and a workload inside IBM Cloud is your responsibility. For more information, see [Encryption in Security and regulation compliance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-responsibilities-vpcsecurity-compliance).\n* A data encryption key (DEK) encrypts data within the QCOW2 file and secures the block data clusters in the virtual disk. The DEK is managed by open source QEMU technology and auto-generated when a QCOW2 file is created.\n\nFor Block Storage for VPC volumes that are created from stock images, the DEK is generated by QEMU running on IBM-provided KVM hypervisors. For Block Storage for VPC volumes that are created from custom images, it is generated by QEMU that runs on your on-premises node. The DEK (an AES-256 key) is encrypted with a LUKS passphrase and stored encrypted in the QCOW2 file.\n* A LUKS passphrase (also called a \"key encryption key\") encrypts and decrypts the DEK. This key is managed by the VPC generation 2 infrastructure and is encrypted by your root key. It is stored as metadata that is associated with the Block Storage for VPC volume that contains the QCOW2 file.\n* A customer root key that encrypts volume, share, and custom image passphrases with envelope encryption, which creates a wrapped DEK or WDEK. Root keys are customer-managed from KMS instances (Key Protect or Hyper Protect Crypto Services), and stored and managed securely within the KMS instance. The root key also unwraps (decrypts) the WDEK, providing access to your encrypted data.\n\n\n\n\n\n\n\n Supported key management services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-about"},{"document_id":"ibmcld_15710-1620-3492","score":18.171818,"text":"\nYour key material is protected in transit (when it's transported) and at rest (when it is stored).\n\nCustomer-managed encryption is available for custom images, boot volumes, and data volumes. When an instance is provisioned from an encrypted custom image, its boot volume is encrypted by using the image\u2019s root key. You can also choose a different root key. Data volumes are encrypted by using root keys when you provision a virtual server instance or when you create a stand-alone volume.\n\nImages and volumes are often referred to as being encrypted with a root key when, in fact,\n\nenvelope encryptionis used. Internally, each image or volume is encrypted with adata encryption key (DEK), which is an open source QEMU technology that is used by the IBM Cloud VPC Generation 2 infrastructure. A LUKS passphrase, also called a key encryption key, encrypts the DEK. The LUKS passphrase is then encrypted with a root key, creating what is called a wrapped DEK (WDEK). For more information about IBM Cloud VPC key encryption technology, see [IBM Cloud VPC Generation 2 encryption technology](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutbyok-technologies).\n\nFor example, if you provision two volumes by using the same root key, unique passphrases are generated for each volume, which are then encrypted with the root key. Envelope encryption provides more protection for your data, and ensures that the root key can be rotated without having to reencrypt the data. For more information about envelope encryption, see [Protecting your sensitive data in VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-mng-datadata-encryption).\n\nAll your interaction with VPN for VPC is encrypted. For example, when you use an API or interact with the service through the User Interface to configure VPN gateways and VPN connections, all such interactions are encrypted end-to-end.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-mng-data"},{"document_id":"ibmcld_15710-4633-6509","score":18.009,"text":"\nFor more information, see [Introduction to encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-basics).\n\nData is automatically encrypted on the physical media at the drive level. However, customer-managed keys are not supported for instance storage. For sensitive data, it is strongly recommended that users utilize software-based file system encryption such as LUKS for Linux\u00ae or BitLocker for Windows\u00ae. This technology allows end users to encrypt entirely within the instance, and can provide additional protection for sensitive data in-transit between the instances and the physical drive media. Some operating systems also provide FIPS certified encryption algorithms that may also be used. See [Encrypting block devices using LUKS](https:\/\/access.redhat.com\/documentation\/en-us\/red_hat_enterprise_linux\/8\/html\/security_hardening\/encrypting-block-devices-using-luks_security-hardening) for an example of how to encrypt on Red Hat Enterprise Linux\u00ae however, refer to the Operating System documentation or specific information on how to encrypt each device.\n\n\n\n\n\n\n\n Protecting your sensitive data in VPC \n\nKey Protect or Hyper Protect Crypto Services provide a higher level of protection called envelope encryption.\n\n[Envelope encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-envelope-ecryption-byok) encrypts one encryption key with another encryption key. A DEK encrypts your actual data. The DEK is never stored. Rather, it's encrypted by a key encryption key. The LUKS passphrase is then encrypted by a root key, which creates a WDEK. To decrypt data, the WDEK is unwrapped so you can access the data that's stored on the volume. This process is possible only by accessing the root key that is stored in your KMS instance. Root keys in HPCS service instances are also protected by a\n\nhardware security module (HSM)master key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-mng-data"},{"document_id":"ibmcld_16035-4222-6333","score":17.914116,"text":"\n[File shares](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-encryption) provide a customer-managed encryption option similar to Block Storage for VPC volumes.\n\n\n\n\n\n Advantages of customer-managed encryption \n\nCustomer-managed encryption has several advantages over IBM-managed encryption.\n\nYou control your keys:\n\n\n\n* Because you bring your own keys (BYOK) to the cloud, you control encryption of your Block Storage for VPC volumes, file shares, and custom images.\n* You grant the IBM VPC service access to use your root keys to encrypt your data. You can revoke access at any time for any reason.\n* Your data is protected while in transit from the storage system to the hypervisor and host within the VPC, and at rest in Block Storage for VPC and File Storage for VPC.\n\n\n\nEncrypt boot and data volumes:\n\n\n\n* Your Block Storage for VPC data is always encrypted with your own keys both at rest and in motion.\n* Each boot and data volume is encrypted at rest with a unique master encryption key. If the key is compromised, no other Block Storage for VPC volume is impacted because the compromised key protects only a single volume.\n* Primary boot volumes that are created from Linux or Windows stock images are encrypted by default with IBM-managed encryption. If you create an instance from a stock image and specify customer-managed encryption for data volumes, the data that is written to those volumes is protected by customer-managed encryption.\n* You control the number and usage of root keys to use for envelope encryption at the volume level. For example, you can choose to encrypt your boot volume with one root key and data volumes with a different root key.\n* Snapshots that are created from boot and data volumes inherit the customer-managed encryption from the source volume.\n\n\n\nEncrypt file shares:\n\n\n\n* File share data is always encrypted with your own keys at rest.\n* You control the number and usage of root keys to use for envelope encryption at the file shares level. That is, you can choose to encrypt all your file shares with same root key or each file share with different keys.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-about"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15160-7105-8981","score":20.892248,"text":"\nUnder Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled. You can also specify the maximum number of fast restore snapshots that you want to retain. Fast restore is billed at an [extra rate per hour](https:\/\/www.ibm.com\/cloud\/virtual-servers\/pricing) for each zone in which it is enabled.\n* Tagging, specify more tags that apply to the backup when the plan runs.\n\n\n\n* Select the box to copy all tags from the source volume to all backups.\n* Under Tags for backups, you can manually add any extra plan tags in this field.\n\n\n\n\n\n5. Click Next to proceed to configure remote copies, which are optional part of the plan.\n\n\n\n1. To create cross-regional copies of your backup, select the geography and regions where you want to have a copy. Remember, you can have only one copy per region.\n2. Click the toggle to enable remote copy in the selected region.\n3. If the source snapshot is encrypted by using a customer-managed key, you must select the encryption service instance and provide the key name. If you prefer, you can create a new service instance or encryption key by following the links.\n\n\n\n* Key Protect - it can be used when the original back is encrypted by using the Key Protect service.\n* Hyper Protect Crypto Services - it can be used when the original back is encrypted by using the Hyper Protect Crypto Services service.\n\n\n\n\n\nTags are automatically copied over from the parent backup.\n6. Click Save.\n7. The Summary updates automatically with the selections that you made. For example, the plan might be \"Every Monday at -5:53 UTC (12:30 AM CDT) starting on 26 March 2022.\" The Plan status toggle is enabled by default.\n8. Click Create to save the new plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan"},{"document_id":"ibmcld_15949-6658-8180","score":20.60236,"text":"\nEncryption Provider-managed or customer-managed encryption. For customer-managed encryption, the KMS instance, root key name, and root key ID are shown. \n Fast restore panel Use [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) to create a volume from this snapshot that is fully provisioned. Click edit to [enable fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-manage&interface=uisnapshots-edit-fast-restore) in a zone. \n Actions menu [Create a volume from the snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restoresnapshots-restore-create-vol-ui), [Edit fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-managesnapshots-edit-fast-restore), or delete a snapshot. \n\n\n\n\n\n\n\n\n\n Viewing snapshots from the CLI \n\nYou can use the CLI to list all snapshots, all snapshots for a volume, and details about a particular snapshot.\n\n\n\n Before you begin \n\nBefore you can use the CLI, you must install the IBM Cloud CLI and the VPC CLI plug-in. For more information, see the [CLI prerequisites](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-set-up-environmentcli-prerequisites-setup).\n\n\n\n1. Log in to IBM Cloud\u00ae.\n\nibmcloud login --sso -a cloud.ibm.com\n\nThis command returns a URL and prompts for a passcode. Go to that URL in your browser and log in. If successful, you get a one-time passcode. Copy this passcode and paste it as a response on the prompt. After successful authentication, you are prompted to choose your account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-view&interface=cli"},{"document_id":"ibmcld_15947-6644-8166","score":20.60236,"text":"\nEncryption Provider-managed or customer-managed encryption. For customer-managed encryption, the KMS instance, root key name, and root key ID are shown. \n Fast restore panel Use [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) to create a volume from this snapshot that is fully provisioned. Click edit to [enable fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-manage&interface=uisnapshots-edit-fast-restore) in a zone. \n Actions menu [Create a volume from the snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restoresnapshots-restore-create-vol-ui), [Edit fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-managesnapshots-edit-fast-restore), or delete a snapshot. \n\n\n\n\n\n\n\n\n\n Viewing snapshots from the CLI \n\nYou can use the CLI to list all snapshots, all snapshots for a volume, and details about a particular snapshot.\n\n\n\n Before you begin \n\nBefore you can use the CLI, you must install the IBM Cloud CLI and the VPC CLI plug-in. For more information, see the [CLI prerequisites](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-set-up-environmentcli-prerequisites-setup).\n\n\n\n1. Log in to IBM Cloud\u00ae.\n\nibmcloud login --sso -a cloud.ibm.com\n\nThis command returns a URL and prompts for a passcode. Go to that URL in your browser and log in. If successful, you get a one-time passcode. Copy this passcode and paste it as a response on the prompt. After successful authentication, you are prompted to choose your account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-view"},{"document_id":"ibmcld_15926-2839-5137","score":20.480892,"text":"\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.\n* If snapshot is protected with customer-managed encryption and you don't specify a different root key CRN, the restored volume is encrypted with the snapshot's encryption key. The encryption cannot be changed later.\n* When the new volume is created, data restoration begins immediately, but performance is degraded until the volume is fully hydrated.\n\n\n\n\n\n Performance impact \n\nThe performance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background.\n\nAt first, the restored volume appears as pending or degraded, and the service begins pulling data from the snapshot that is stored in Object Storage. While the data is restoring, the volume's health state is monitored by the volume resource. If the volume that was created from snapshot is attached to an instance before its data is fully restored, volume hydration pauses on the service node and continues on the compute node. If the volume is detached while the hydration is in progress, the hydration pauses on compute node and continues on the storage node. You cannot delete a snapshot that is used to hydrate a volume. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones don't require hydration. The data is available as soon as the volume is created. However, to achieve the best performance and efficiency when you provision multiple instances, boot from an existing image. Custom images that you provide are better than stock images for this purpose. Images have a maximum size of 250 GB.\n\n\n\n\n\n\n\n Restoring a volume with fast restore","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore"},{"document_id":"ibmcld_15937-2839-5137","score":20.480892,"text":"\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.\n* If snapshot is protected with customer-managed encryption and you don't specify a different root key CRN, the restored volume is encrypted with the snapshot's encryption key. The encryption cannot be changed later.\n* When the new volume is created, data restoration begins immediately, but performance is degraded until the volume is fully hydrated.\n\n\n\n\n\n Performance impact \n\nThe performance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background.\n\nAt first, the restored volume appears as pending or degraded, and the service begins pulling data from the snapshot that is stored in Object Storage. While the data is restoring, the volume's health state is monitored by the volume resource. If the volume that was created from snapshot is attached to an instance before its data is fully restored, volume hydration pauses on the service node and continues on the compute node. If the volume is detached while the hydration is in progress, the hydration pauses on compute node and continues on the storage node. You cannot delete a snapshot that is used to hydrate a volume. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones don't require hydration. The data is available as soon as the volume is created. However, to achieve the best performance and efficiency when you provision multiple instances, boot from an existing image. Custom images that you provide are better than stock images for this purpose. Images have a maximum size of 250 GB.\n\n\n\n\n\n\n\n Restoring a volume with fast restore","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=cli"},{"document_id":"ibmcld_15938-2839-5137","score":20.480892,"text":"\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.\n* If snapshot is protected with customer-managed encryption and you don't specify a different root key CRN, the restored volume is encrypted with the snapshot's encryption key. The encryption cannot be changed later.\n* When the new volume is created, data restoration begins immediately, but performance is degraded until the volume is fully hydrated.\n\n\n\n\n\n Performance impact \n\nThe performance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background.\n\nAt first, the restored volume appears as pending or degraded, and the service begins pulling data from the snapshot that is stored in Object Storage. While the data is restoring, the volume's health state is monitored by the volume resource. If the volume that was created from snapshot is attached to an instance before its data is fully restored, volume hydration pauses on the service node and continues on the compute node. If the volume is detached while the hydration is in progress, the hydration pauses on compute node and continues on the storage node. You cannot delete a snapshot that is used to hydrate a volume. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones don't require hydration. The data is available as soon as the volume is created. However, to achieve the best performance and efficiency when you provision multiple instances, boot from an existing image. Custom images that you provide are better than stock images for this purpose. Images have a maximum size of 250 GB.\n\n\n\n\n\n\n\n Restoring a volume with fast restore","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=terraform"},{"document_id":"ibmcld_15934-2839-5137","score":20.480892,"text":"\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.\n* If snapshot is protected with customer-managed encryption and you don't specify a different root key CRN, the restored volume is encrypted with the snapshot's encryption key. The encryption cannot be changed later.\n* When the new volume is created, data restoration begins immediately, but performance is degraded until the volume is fully hydrated.\n\n\n\n\n\n Performance impact \n\nThe performance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background.\n\nAt first, the restored volume appears as pending or degraded, and the service begins pulling data from the snapshot that is stored in Object Storage. While the data is restoring, the volume's health state is monitored by the volume resource. If the volume that was created from snapshot is attached to an instance before its data is fully restored, volume hydration pauses on the service node and continues on the compute node. If the volume is detached while the hydration is in progress, the hydration pauses on compute node and continues on the storage node. You cannot delete a snapshot that is used to hydrate a volume. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones don't require hydration. The data is available as soon as the volume is created. However, to achieve the best performance and efficiency when you provision multiple instances, boot from an existing image. Custom images that you provide are better than stock images for this purpose. Images have a maximum size of 250 GB.\n\n\n\n\n\n\n\n Restoring a volume with fast restore","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=api"},{"document_id":"ibmcld_15939-2839-5137","score":20.480892,"text":"\n* When you create an unattached (stand-alone) Block Storage for VPC volume from a snapshot, you can still attach the volume to an instance later.\n\n\n\n\n\n\n\n Limitations of restoring a volume from a snapshot \n\nThe following limitations apply when you restore a volume from a snapshot.\n\n\n\n* To restore a volume, the snapshot must be in a stable state.\n* You can delete the new volume at any time. However, you can't delete the snapshot from which the volume is restored from unless the hydration is complete or the volume is deleted.\n* If snapshot is protected with customer-managed encryption and you don't specify a different root key CRN, the restored volume is encrypted with the snapshot's encryption key. The encryption cannot be changed later.\n* When the new volume is created, data restoration begins immediately, but performance is degraded until the volume is fully hydrated.\n\n\n\n\n\n Performance impact \n\nThe performance of boot and data volumes is initially degraded when data is restored from a snapshot. Performance degradation occurs during the restoration because your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC in the background.\n\nAt first, the restored volume appears as pending or degraded, and the service begins pulling data from the snapshot that is stored in Object Storage. While the data is restoring, the volume's health state is monitored by the volume resource. If the volume that was created from snapshot is attached to an instance before its data is fully restored, volume hydration pauses on the service node and continues on the compute node. If the volume is detached while the hydration is in progress, the hydration pauses on compute node and continues on the storage node. You cannot delete a snapshot that is used to hydrate a volume. After the restoration process is complete, you can realize full IOPS on the new volume.\n\nVolumes that are restored from fast restore clones don't require hydration. The data is available as soon as the volume is created. However, to achieve the best performance and efficiency when you provision multiple instances, boot from an existing image. Custom images that you provide are better than stock images for this purpose. Images have a maximum size of 250 GB.\n\n\n\n\n\n\n\n Restoring a volume with fast restore","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-restore&interface=ui"},{"document_id":"ibmcld_15161-7076-8939","score":20.44476,"text":"\nFor example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled. You can also specify the maximum number of fast restore snapshots that you want to retain. Fast restore is billed at an [extra rate per hour](https:\/\/www.ibm.com\/cloud\/virtual-servers\/pricing) for each zone in which it is enabled.\n* Tagging, specify more tags that apply to the backup when the plan runs.\n\n\n\n* Select the box to copy all tags from the source volume to all backups.\n* Under Tags for backups, you can manually add any extra plan tags in this field.\n\n\n\n\n\n5. Click Next to proceed to configure remote copies, which are optional part of the plan.\n\n\n\n1. To create cross-regional copies of your backup, select the geography and regions where you want to have a copy. Remember, you can have only one copy per region.\n2. Click the toggle to enable remote copy in the selected region.\n3. If the source snapshot is encrypted by using a customer-managed key, you must select the encryption service instance and provide the key name. If you prefer, you can create a new service instance or encryption key by following the links.\n\n\n\n* Key Protect - it can be used when the original back is encrypted by using the Key Protect service.\n* Hyper Protect Crypto Services - it can be used when the original back is encrypted by using the Hyper Protect Crypto Services service.\n\n\n\n\n\nTags are automatically copied over from the parent backup.\n6. Click Save.\n7. The Summary updates automatically with the selections that you made. For example, the plan might be \"Every Monday at -5:53 UTC (12:30 AM CDT) starting on 26 March 2022.\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=api"},{"document_id":"ibmcld_15163-7094-8957","score":20.44476,"text":"\nFor example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled. You can also specify the maximum number of fast restore snapshots that you want to retain. Fast restore is billed at an [extra rate per hour](https:\/\/www.ibm.com\/cloud\/virtual-servers\/pricing) for each zone in which it is enabled.\n* Tagging, specify more tags that apply to the backup when the plan runs.\n\n\n\n* Select the box to copy all tags from the source volume to all backups.\n* Under Tags for backups, you can manually add any extra plan tags in this field.\n\n\n\n\n\n5. Click Next to proceed to configure remote copies, which are optional part of the plan.\n\n\n\n1. To create cross-regional copies of your backup, select the geography and regions where you want to have a copy. Remember, you can have only one copy per region.\n2. Click the toggle to enable remote copy in the selected region.\n3. If the source snapshot is encrypted by using a customer-managed key, you must select the encryption service instance and provide the key name. If you prefer, you can create a new service instance or encryption key by following the links.\n\n\n\n* Key Protect - it can be used when the original back is encrypted by using the Key Protect service.\n* Hyper Protect Crypto Services - it can be used when the original back is encrypted by using the Hyper Protect Crypto Services service.\n\n\n\n\n\nTags are automatically copied over from the parent backup.\n6. Click Save.\n7. The Summary updates automatically with the selections that you made. For example, the plan might be \"Every Monday at -5:53 UTC (12:30 AM CDT) starting on 26 March 2022.\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-backup-policy-and-plan&interface=terraform"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4175fcce99c56af0e02be5b8990fc16a<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09081-1687-4004","score":16.706144,"text":"\nData encryption keys (DEKs) are designed to encrypt your data and can be generated and managed by your service or an IBM Cloud service.\n\nEnvelope encryption offers several benefits for protecting your data:\n\n\n\n* Protection under a combination of multiple algorithms Envelope encryption uses the best benefits from symmetric and public key algorithms to keep your keys secure.\n\n\n\n1. Symmetric key algorithms work faster, are more scalable, and more secure than public key algorithms. Public key algorithms use complicated mathematics that increase computational overhead, especially when dealing with large volumes of data. Public key algorithms are also more susceptible to brute force attacks due to having a private key algorithm component that is easily recognizable by hackers. Symmetric key algorithms requires less computed power and are resistant to brute force attacks due to having a less recognizable structure.\n2. Public key algorithms allow for easier access control when granting access to keys at an individual level compared to symmetric key algorithms. Symmetric key algorithms have a key exchange problem, which is that access to a secret key can only be exchanged through a secure transfer. By using public key algorithms, encrypted DEKs (wDEKs) can be shared and unencrypted only by those with access to the encrypting root key, mitigating the key exchange problem of symmetric algorithms.\n\n\n\n* Easier key management You can encrypt multiple DEKs under a singular root key, which minimizes the amount of keys that you might need to manage in a key management service. You can also choose to save time on key maintenance by only rotating your root keys, instead of rotating and re-encrypting all of your DEKs. Note that in cases such as personnel turnover, process malfunctions, or the detection of a security issue, it is recommended to rotate all DEKs and root keys associated with the incident.\n* Data Key Protection Since your DEKs are wrapped by a root key, you do not have to worry about how to store the encrypted data key. Due to this, you can store the wDEK with alongside the associated encrypted data.\n\n\n\nKey Protect uses the Advanced Encryption Standard algorithm in Galois\/Counter Mode (AES GCM) to wrap and unwrap DEKs. CRKs that are not imported are created with 256-bit key material.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption"},{"document_id":"ibmcld_16035-4222-6333","score":16.461843,"text":"\n[File shares](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-file-storage-vpc-encryption) provide a customer-managed encryption option similar to Block Storage for VPC volumes.\n\n\n\n\n\n Advantages of customer-managed encryption \n\nCustomer-managed encryption has several advantages over IBM-managed encryption.\n\nYou control your keys:\n\n\n\n* Because you bring your own keys (BYOK) to the cloud, you control encryption of your Block Storage for VPC volumes, file shares, and custom images.\n* You grant the IBM VPC service access to use your root keys to encrypt your data. You can revoke access at any time for any reason.\n* Your data is protected while in transit from the storage system to the hypervisor and host within the VPC, and at rest in Block Storage for VPC and File Storage for VPC.\n\n\n\nEncrypt boot and data volumes:\n\n\n\n* Your Block Storage for VPC data is always encrypted with your own keys both at rest and in motion.\n* Each boot and data volume is encrypted at rest with a unique master encryption key. If the key is compromised, no other Block Storage for VPC volume is impacted because the compromised key protects only a single volume.\n* Primary boot volumes that are created from Linux or Windows stock images are encrypted by default with IBM-managed encryption. If you create an instance from a stock image and specify customer-managed encryption for data volumes, the data that is written to those volumes is protected by customer-managed encryption.\n* You control the number and usage of root keys to use for envelope encryption at the volume level. For example, you can choose to encrypt your boot volume with one root key and data volumes with a different root key.\n* Snapshots that are created from boot and data volumes inherit the customer-managed encryption from the source volume.\n\n\n\nEncrypt file shares:\n\n\n\n* File share data is always encrypted with your own keys at rest.\n* You control the number and usage of root keys to use for envelope encryption at the file shares level. That is, you can choose to encrypt all your file shares with same root key or each file share with different keys.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-about"},{"document_id":"ibmcld_01289-5532-6265","score":16.19999,"text":"\nIn fact, the system can lose multiple disks in the cluster simultaneously without degrading customer performance or adverse risk of data loss. Redundant network ports and paths protect against network failures across the cloud connections.\n\n\n\n\n\n Encryption \n\nIBM Cloud\u00ae provides full-disk encryption without compromising storage application performance. For more information about encryption of File Storage for Classic, see [Securing your data in File Storage](https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-mng-data). For more information about provider- and customer-managed encryption in a VPC, see [Data encryption for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/FileStorage?topic=FileStorage-storageavailability"},{"document_id":"ibmcld_15710-7-2109","score":15.850168,"text":"\nSecuring your data in VPC \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Virtual Private Cloud, it's important to know exactly what data is stored and encrypted and how you can delete any stored personal data. Data encryption with your own root keys is available by using a supported key management service (KMS).\n\nVPN for VPC does not store any customer data other than what is required to configure VPN gateways, connections, and policies. Data that is transmitted through a VPN gateway is not encrypted by IBM. Data about your specific VPN and policy configurations are encrypted in transit and at rest. VPN configuration data is deleted upon your request through API or User Interface.\n\n\n\n How your data is stored and encrypted in VPC \n\nAll block storage volumes are encrypted by default with IBM-managed encryption. IBM\u00ae-managed keys are generated and securely stored in a block storage vault that is backed by Consul and maintained by IBM Cloud\u00ae operations.\n\nFor more security and control, you can protect your data with your own root keys (also called a customer root key or CRK). This feature is commonly called Bring Your Own Key, or BYOK. Root keys encrypt the keys that safeguard your data. You can import your root keys to Key Protect or Hyper Protect Crypto Services, or have either key management service create one for you.\n\nThe KMS stores your key and makes it available during volume and custom image encryption. Key Protect provides FIPS 140-2 Level 3 compliance. Hyper Protect Crypto Services offers the highest level of security with FIPS 140-2 Level 4 compliance. Your key material is protected in transit (when it's transported) and at rest (when it is stored).\n\nCustomer-managed encryption is available for custom images, boot volumes, and data volumes. When an instance is provisioned from an encrypted custom image, its boot volume is encrypted by using the image\u2019s root key. You can also choose a different root key. Data volumes are encrypted by using root keys when you provision a virtual server instance or when you create a stand-alone volume.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-mng-data"},{"document_id":"ibmcld_16035-10237-12019","score":15.7408285,"text":"\nIBM-managed encryption on the storage system is always applied, even when you use customer-managed encryption. This key protects your data while in transit and while at rest.\n\nEncryption of the network link between your workload outside of IBM Cloud and a workload inside IBM Cloud is your responsibility. For more information, see [Encryption in Security and regulation compliance](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-responsibilities-vpcsecurity-compliance).\n* A data encryption key (DEK) encrypts data within the QCOW2 file and secures the block data clusters in the virtual disk. The DEK is managed by open source QEMU technology and auto-generated when a QCOW2 file is created.\n\nFor Block Storage for VPC volumes that are created from stock images, the DEK is generated by QEMU running on IBM-provided KVM hypervisors. For Block Storage for VPC volumes that are created from custom images, it is generated by QEMU that runs on your on-premises node. The DEK (an AES-256 key) is encrypted with a LUKS passphrase and stored encrypted in the QCOW2 file.\n* A LUKS passphrase (also called a \"key encryption key\") encrypts and decrypts the DEK. This key is managed by the VPC generation 2 infrastructure and is encrypted by your root key. It is stored as metadata that is associated with the Block Storage for VPC volume that contains the QCOW2 file.\n* A customer root key that encrypts volume, share, and custom image passphrases with envelope encryption, which creates a wrapped DEK or WDEK. Root keys are customer-managed from KMS instances (Key Protect or Hyper Protect Crypto Services), and stored and managed securely within the KMS instance. The root key also unwraps (decrypts) the WDEK, providing access to your encrypted data.\n\n\n\n\n\n\n\n Supported key management services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-about"},{"document_id":"ibmcld_16035-7-2023","score":15.583052,"text":"\nAbout data encryption for VPC \n\nIBM Cloud\u00ae takes security seriously and understands the importance of encrypting data to keep it safe. Block Storage for VPC volumes, snapshots, and File Storage for VPC file shares are automatically encrypted by using IBM-managed encryption. You can also choose to manage your own encryption for volumes, file shares, and custom images by using customer-managed encryption.\n\n\n\n IBM-managed encryption \n\nBy default, VPC volumes and file shares are encrypted at rest with IBM-managed encryption. The service comes with no additional cost.\n\nIBM-managed encryption uses the following industry standard protocols:\n\n\n\n* AES-256 encryption.\n* Keys are managed in-house with Key Management Interoperability Protocol (KMIP).\n* The self-encrypting drives in the Storage architecture are validated for Federal Information Processing Standard (FIPS) Publication 140-2 Level 2.\n* Storage architecture is validated for Federal Information Security Management Act (FISMA), and the Health Insurance Portability and Accountability Act (HIPAA)\n* Storage architecture is also validated for Payment Card Industry (PCI), Basel II, California Security Breach Information Act (SB 1386), and EU Data Protection Directive 95\/46\/EC compliance.\n\n\n\n\n\n\n\n Customer-managed encryption \n\nFor end-to-end encryption in the IBM Cloud, you can use customer-managed encryption. Your data is protected while at rest, and also in transit from the storage to the hypervisor and host. You are responsible for encrypting your data outside the VPC.\n\nWith customer-managed encryption, you can bring your own customer root key (CRK) to the cloud or have a [key management service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutkms-for-byok) (KMS) generate a key for you. Root keys are used to encrypt volume, file share, and custom image passphrases with [envelope encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-envelope-encryption-byok), a process that wraps a key with another key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-about"},{"document_id":"ibmcld_15710-4633-6509","score":15.5442095,"text":"\nFor more information, see [Introduction to encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-basics).\n\nData is automatically encrypted on the physical media at the drive level. However, customer-managed keys are not supported for instance storage. For sensitive data, it is strongly recommended that users utilize software-based file system encryption such as LUKS for Linux\u00ae or BitLocker for Windows\u00ae. This technology allows end users to encrypt entirely within the instance, and can provide additional protection for sensitive data in-transit between the instances and the physical drive media. Some operating systems also provide FIPS certified encryption algorithms that may also be used. See [Encrypting block devices using LUKS](https:\/\/access.redhat.com\/documentation\/en-us\/red_hat_enterprise_linux\/8\/html\/security_hardening\/encrypting-block-devices-using-luks_security-hardening) for an example of how to encrypt on Red Hat Enterprise Linux\u00ae however, refer to the Operating System documentation or specific information on how to encrypt each device.\n\n\n\n\n\n\n\n Protecting your sensitive data in VPC \n\nKey Protect or Hyper Protect Crypto Services provide a higher level of protection called envelope encryption.\n\n[Envelope encryption](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutvpc-envelope-ecryption-byok) encrypts one encryption key with another encryption key. A DEK encrypts your actual data. The DEK is never stored. Rather, it's encrypted by a key encryption key. The LUKS passphrase is then encrypted by a root key, which creates a WDEK. To decrypt data, the WDEK is unwrapped so you can access the data that's stored on the volume. This process is possible only by accessing the root key that is stored in your KMS instance. Root keys in HPCS service instances are also protected by a\n\nhardware security module (HSM)master key.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-mng-data"},{"document_id":"ibmcld_08007-5991-8147","score":15.538817,"text":"\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage) is an alternative storage option that is useful for certain use cases, including backup and recovery, data archiving, cloud-native application building, and AI and big data analytics. Object Storage stores encrypted and dispersed data across multiple geographic locations.\n\nBy default, all objects that are stored in Object Storage are encrypted by using randomly generated keys and an all-or-nothing-transform (AONT). While this default encryption model provides at-rest security, financial service workloads need full control over the data encryption keys used. Again, Hyper Protect Crypto Services should be used for this purpose.\n\n\n\n\n\n\n\n Using IBM Cloud services outside of a VPC \n\nTo connect to IBM Cloud services from your VPC, you need to use [Virtual Private Endpoints (VPE) for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpe). In the reference architecture diagram, VPEs appear in the middle subnets of the workload VPC. With VPEs, you can connect to supported IBM Cloud services from your VPC network by using the IP addresses of your choosing, which is allocated from a subnet within your VPC.\n\nVPE is an evolution of the private connectivity to IBM Cloud services. VPEs are virtual IP interfaces that are bound to an endpoint gateway created on a per service, or service instance, basis (depending on the service operation model). The endpoint gateway is a virtualized function that scales horizontally, is redundant and highly available, and spans all availability zones of your VPC. Endpoint gateways enable communications from virtual server instances within your VPC and IBM Cloud service on the private backbone. VPE for VPC gives you the experience of controlling all the private addressing within your cloud.\n\n\n\n\n\n\n\n Variation with edge\/transit VPC for public internet access \n\nYou might want to allow consumers to access your service through the public internet. This base architecture can be adapted to securely enable this type of access as shown in the following diagram, which introduces a new edge VPC.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-vsi"},{"document_id":"ibmcld_15710-1620-3492","score":15.368708,"text":"\nYour key material is protected in transit (when it's transported) and at rest (when it is stored).\n\nCustomer-managed encryption is available for custom images, boot volumes, and data volumes. When an instance is provisioned from an encrypted custom image, its boot volume is encrypted by using the image\u2019s root key. You can also choose a different root key. Data volumes are encrypted by using root keys when you provision a virtual server instance or when you create a stand-alone volume.\n\nImages and volumes are often referred to as being encrypted with a root key when, in fact,\n\nenvelope encryptionis used. Internally, each image or volume is encrypted with adata encryption key (DEK), which is an open source QEMU technology that is used by the IBM Cloud VPC Generation 2 infrastructure. A LUKS passphrase, also called a key encryption key, encrypts the DEK. The LUKS passphrase is then encrypted with a root key, creating what is called a wrapped DEK (WDEK). For more information about IBM Cloud VPC key encryption technology, see [IBM Cloud VPC Generation 2 encryption technology](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-encryption-aboutbyok-technologies).\n\nFor example, if you provision two volumes by using the same root key, unique passphrases are generated for each volume, which are then encrypted with the root key. Envelope encryption provides more protection for your data, and ensures that the root key can be rotated without having to reencrypt the data. For more information about envelope encryption, see [Protecting your sensitive data in VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-mng-datadata-encryption).\n\nAll your interaction with VPN for VPC is encrypted. For example, when you use an API or interact with the service through the User Interface to configure VPN gateways and VPN connections, all such interactions are encrypted end-to-end.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-mng-data"},{"document_id":"ibmcld_07986-17657-19794","score":15.049248,"text":"\n[Block Storage for VPC](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-block-storage-about) provides hypervisor-mounted, high-performance data storage for your virtual server instances that you can provision within a VPC. The VPC infrastructure provides rapid scaling across zones and extra performance and security.\n\nBlock Storage for VPC provides primary boot volumes and secondary data volumes. Boot volumes are automatically created and attached during instance provisioning. Data volumes can be created and attached during instance provisioning as well, or as stand-alone volumes that you can later attach to an instance. To protect your data, you can use your own encryption keys with Hyper Protect Crypto Services.\n\n\n\n\n\n IBM Cloud Object Storage \n\n[Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cloud-object-storage) stores encrypted and dispersed data across multiple geographic locations. Object Storage is available with three types of resiliency: Cross Region, Regional, and Single Data Center. Cross Region provides higher durability and availability than using a single region at the cost of slightly higher latency. Regional service reverses those tradeoffs, and distributes objects across multiple availability zones within a single region. If a given region or availability zone is unavailable, the object store continues to function without impediment. Single Data Center distributes objects across multiple machines within the same physical location.\n\nUsers of Object Storage refer to their binary data, such as files, images, media, archives, or even entire databases as objects. Objects are stored in a bucket, the container for their unstructured data. Buckets contain both inherent and user-defined metadata. Finally, objects are defined by a globally unique combination of the bucket name and the object key, or name.\n\n\n\n\n\n\n\n Security \n\n\n\n IBM Cloud Hyper Protect Crypto Services \n\n[Hyper Protect Crypto Services](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-overview) is a dedicated key management service and hardware security module (HSM) based on IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services?topic=framework-financial-services-vpc-architecture-about"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02873-7270-8670","score":11.8551655,"text":"\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots. It also conditions on an intent value. It defines a set of slots, one for each piece of information that you want to collect from the user. Each slot asks a question to elicit the answer from the user. It looks for a specific entity value in the user's reply to the prompt, which it then saves in a slot context variable.\n\nThis type of node is useful for collecting details you might need to perform a transaction on the user's behalf. For example, if the user's intent is to book a flight, the slots can collect the origin and destination location information, travel dates, and so on.\n\n\n\n\n\n\n\n Ready to get started? \n\nFor more information, see [Building a dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview).\n\nNext topic:[Planning the dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-plan)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build"},{"document_id":"ibmcld_03185-6701-8694","score":11.76265,"text":"\n[A sample dialog tree with example content](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog-depiction-full.png)\n\nThe dialog tree in this diagram contains two root dialog nodes. A typical dialog tree would likely have many more nodes, but this depiction provides a glimpse of what a subset of nodes might look like.\n\n\n\n* The first root node conditions on an intent value. It has two child nodes that each condition on an entity value. The second child node defines two responses. The first response is returned to the user if the value of the context variable matches the value specified in the condition. Otherwise, the second response is returned.\n\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots. It also conditions on an intent value. It defines a set of slots, one for each piece of information that you want to collect from the user. Each slot asks a question to elicit the answer from the user. It looks for a specific entity value in the user's reply to the prompt, which it then saves in a slot context variable.\n\nThis type of node is useful for collecting details you might need to perform a transaction on the user's behalf. For example, if the user's intent is to book a flight, the slots can collect the origin and destination location information, travel dates, and so on.\n\n\n\n\n\n\n\n Ready to get started? \n\nFor more information, see [Creating a dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-build"},{"document_id":"ibmcld_03113-1615-3683","score":11.723769,"text":"\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.\n\n\n\n* event_handler: A handler that is defined for a frame node or an individual slot node.\n\n\n\nFrom the tool, you can define a frame node handler by clicking the Manage handlers link from a node with slots. (The tool user interface does not expose the slot-level event handler, but you can define one through the API.)\n\n\n\n* frame: A node with one or more child nodes of type slot. Any child slot nodes that are required must be filled before the service can exit the frame node.\n\n\n\nThe frame node type is represented as a node with slots in the tool. The node that contains the slots is represented as a node of type=frame. It is the parent node to each slot, which is represented as a child node of type slot.\n\n\n\n* response_condition: A conditional response.\n\n\n\nIn the tool, you can add one or more conditional responses to a node. Each conditional response that you define is represented in the underlying JSON as an individual node of type=response_condition.\n\n\n\n* slot: A child node of a node of type frame.\n\n\n\nThis node type is represented in the tool as being one of multiple slots added to a single node. That single node is represented in the JSON as a parent node of type frame.\n\n\n\n* standard: A typical dialog node. This is the default type.\n\n\n\n* For nodes of type slot that have the same parent node, the sibling order (specified by the previous_sibling property) reflects the order in which the slots will be processed.\n* A node of type slot must have a parent node of type frame.\n* A node of type frame must have at least one child node of type slot.\n* A node of type response_condition must have a parent node of type standard or frame.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03113-7328-8943","score":11.610036,"text":"\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_3.png)\n\nIn addition to creating node_9, the service automatically updates the previous_sibling property of node_6 so that it points to the new node.\n\n\n\n\n\n Moving a node to a different parent \n\nLet's move node_5 to a different parent by using the POST \/dialog_nodes\/node_5 method with the following body:\n\n{\n\"parent\": \"node_1\"\n}\n\nThe specified value for parent must be valid:\n\n\n\n* It must refer to an existing node.\n* It must not refer to the node being modified (a node cannot be its own parent).\n* It must not refer to a descendant of the node being modified.\n* It must not refer to a node of type response_condition or event_handler.\n\n\n\nThis results in the following changed structure:\n\n![Example dialog 4](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_4.png)\n\nSeveral things have happened here:\n\n\n\n* When node_5 moved to its new parent, node_7 went with it (because the parent value for node_7 did not change). When you move a node, all descendants of that node stay with it.\n* Because we did not specify a previous_sibling value for node_5, it is now the first sibling under node_1.\n* The previous_sibling property of node_4 was updated to node_5.\n* The previous_sibling property of node_9 was updated to null, because it is now the first sibling under node_2.\n\n\n\n\n\n\n\n Resequencing siblings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02900-4643-6783","score":11.345687,"text":"\n* a digression that starts elsewhere and enters the node must return to the interrupted dialog flow after the current dialog flow is completed\n\n\n\nTo change the digression behavior for an individual node, complete the following steps:\n\n\n\n1. Click the node to open its edit view.\n2. Click Customize, and then click the Digressions tab.\n\nThe configuration options differ depending on whether the node you are editing is a root node, a child node, a node with children, or a node with slots.\n\n\n\n Digressions away from this node \n\nIf the circumstances listed earlier do not apply, then you can make the following choices:\n\n\n\n* All node types: Choose whether to allow users to digress away from the current node before they reach the end of the current dialog branch.\n* All nodes that have children: Choose whether you want the conversation to come back to the current node after a digression if the current node's response has already been displayed and its child nodes are incidental to the node's goal. Set the Allow return from digressions triggered after this node's response toggle to No to prevent the dialog from returning to the current node and continuing to process its branch.\n\nFor example, if the user asks, Do you sell cupcakes? and the response, We offer cupcakes in a variety of flavors and sizes is displayed before the user changes subjects, you might not want the dialog to return to where it was. Especially, if the child nodes only address possible follow-up questions from the user and can safely be ignored.\n\nHowever, if the node relies on its child nodes to address the question, then you might want to force the conversation to return and continue processing the nodes in the current branch. For example, the initial response might be, We offer cupcakes in all shapes and sizes. Which menu do you want to see: gluten-free, dairy-free, or regular? If the user changes subjects at this point, you might want the dialog to return so the user can pick a menu type and get the information they wanted.\n* Nodes with slots: Choose whether you want to allow users to digress away from the node before all of the slots are filled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime"},{"document_id":"ibmcld_02914-1593-3315","score":11.11734,"text":"\nThe following example shows how the output object is represented in the dialog JSON editor:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"This is my response text.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n}\n]\n}\n}\n\n\n\nIn the resulting API \/message response, the text response is formatted as follows:\n\n{\n\"text\": \"This is my response text.\",\n\"response_type\": \"text\"\n}\n\nThe following output object JSON format is supported for backwards compatibility. With the introduction of rich response types, the output.text structure was augmented with the output.generic structure to facilitate supporting other types of responses in addition to text. Use the new format when you create new nodes to give yourself more flexibility, because you can subsequently change the response type, if needed.\n\n{\n\"output\": {\n\"text\": {\n\"values\": [\n\"This is my response text.\"\n]\n}\n}\n}\n\nThere are response types other than a text response that you can define. See [Responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-responses) for more details.\n\nYou can learn more about the \/message API call from the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2).\n\n\n\n Retaining information across dialog turns \n\nThe dialog in a dialog skill is stateless, meaning that it does not retain information from one interaction with the user to the next. When you add a dialog skill to an assistant and deploy it, the assistant saves the context from one message call and then re-submits it on the next request throughout the current session. The current session lasts for as long a user interacts with the assistant plus the designated session inactivity time frame.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-context"},{"document_id":"ibmcld_02882-18936-21214","score":11.104327,"text":"\nYou can return responses with multimedia or interactive elements such as images or clickable buttons to simplify the interaction model of your application and enhance the user experience.\n\nIn addition to the default response type of Text, for which you specify the text to return to the user as a response, the following response types are supported:\n\n\n\n* Connect to human agent: The dialog calls a service that you designate, typically a service that manages human agent support ticket queues, to pass off the conversation to a person. You can optionally include a message that summarizes the user's issue to be provided to the human agent. It is the responsibility of the external service to display a message that is shown to the user that explains that the conversation is being transferred. The dialog does not manage that communication itself. The dialog transfer does not occur when you are testing nodes with this response type in the Try it out pane. You must access a node that uses this response type from a test deployment to see how your users will experience it.\n* Image: Embeds an image into the response. The source image file must be hosted somewhere and have a URL that you can use to reference it. It cannot be a file that is stored in a directory that is not publicly accessible.\n* Option: Adds a list of one or more options. When a user clicks one of the options, an associated user input value is sent to your assistant. How options are rendered can differ depending on where you deploy the dialog. For example, in one integration channel the options might be displayed as clickable buttons, but in another they might be displayed as a dropdown list.\n* Pause: Forces the application to wait for a specified number of milliseconds before continuing with processing. You can choose to show an indicator that the dialog is working on typing a response. Use this response type if you need to perform an action that might take some time. For example, a parent node makes a Cloud Function call and displays the result in a child node. You could use this response type as the response for the parent node to give the programmatic call time to complete, and then jump to the child node to show the result. This response type does not render in the Try it out pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_02952-3289-5462","score":11.102929,"text":"\nAdd meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\n\n\n\n\n Measuring containment \n\nFrom the Analytics page, you can measure conversation containment. Containment is the rate at which your assistant is able to satisfy a customer's request without human intervention per conversation.\n\nTo measure containment accurately, the metric must be able to identify when a human intervention occurs. The metric primarily uses the Connect to human agent response type as an indicator. If a user conversation log includes a call to a Connect to human agent response type, then the conversation is considered to be not contained.\n\nHowever, not all human interventions are transacted by using a Connect to human agent response type. If you use an alternate method to deliver additional support, you must take additional steps to register the fact that the customer's need was not fulfilled by the assistant. For example, you might direct customers to your call center phone number or to an online support ticket form URL.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03113-4-2033","score":11.028103,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Modifying a dialog using the API \n\nThe Watson Assistant REST API supports modifying your dialog programmatically, without using the Watson Assistant tool. You can use the \/dialog_nodes API to create, delete, or modify dialog nodes.\n\nRemember that the dialog is a tree of interconnected nodes, and that it must conform to certain rules in order to be valid. This means that any change you make to a dialog node might have cascading effects on other nodes, or on the structure of your dialog. Before using the \/dialog_nodes API to modify your dialog, make sure you understand how your changes will affect the rest of the dialog. You can make a backup copy of the current dialog by exporting the conversational skill in which it resides. See [Downloading a skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-download) for details.\n\nA valid dialog always satisfies the following criteria:\n\n\n\n* Each dialog node has a unique ID (the dialog_node property).\n* A child node is aware of its parent node (the parent property). However, a parent node is not aware of its children.\n* A node is aware of its immediate previous sibling, if any (the previous_sibling property). This means that all siblings that share the same parent form a linked list, with each node pointing to the previous node.\n* Only one child of a given parent can be the first sibling (meaning that its previous_sibling is null).\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03218-24900-26959","score":10.941644,"text":"\nFor each node, you configure whether:<-- <ul> --> * a digression can start from and leave the node * a digression that starts elsewhere can target and enter the node * a digression that starts elsewhere and enters the node must return to the interrupted dialog flow after the current dialog flow is completed<-- <\/ul> -->To change the digression behavior for an individual node, complete the following steps:<-- <ol> -->1. Click the node to open its edit view.2. Click Customize, and then click the Digressions tab.\nThe configuration options differ depending on whether the node you are editing is a root node, a child node, a node with children, or a node with slots.\n\nDigressions away from this node\n\nIf the circumstances listed earlier do not apply, then you can make the following choices:\n\n<-- <ul> -->\n\n* All node types: Choose whether to allow users to digress away from the current node before they reach the end of the current dialog branch.\n* All nodes that have children: Choose whether you want the conversation to come back to the current node after a digression if the current node's response has already been displayed and its child nodes are incidental to the node's goal. Set the Allow return from digressions triggered after this node's response switch to No to prevent the dialog from returning to the current node and continuing to process its branch.\n\nFor example, if the user asks, Do you sell cupcakes? and the response, We offer cupcakes in a variety of flavors and sizes is displayed before the user changes subjects, you might not want the dialog to return to where it left off. Especially, if the child nodes only address possible follow-up questions from the user and can safely be ignored.\n\nHowever, if the node relies on its child nodes to address the question, then you might want to force the conversation to return and continue processing the nodes in the current branch. For example, the initial response might be, We offer cupcakes in all shapes and sizes. Which menu do you want to see: gluten-free, dairy-free, or regular?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02952-1632-3754","score":11.421785,"text":"\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03196-1602-3602","score":11.163681,"text":"\nFor example, Open an account, Get policy information, or Get a weather forecast.\n\nThe name can be up to 512 characters in length.\n\nThis node name is shown to customers or service desk personnel to express the purpose of this branch of the dialog, so take some time to add a name that is concise and descriptive.\n4. In the If assistant recognizes field, enter a condition that, when met, triggers your assistant to process the node.\n\nTo start off, you typically want to add an intent as the condition. For example, if you add open_account here, it means that you want the response that you will specify in this node to be returned to the user if the user input indicates that the user wants to open an account.\n\nAs you begin to define a condition, a box is displayed that shows you your options. You can enter one of the following characters, and then pick a value from the list of options that is displayed.\n\n\n\nCondition builder syntax\n\n Character Lists defined values for these artifact types \n\n `#` intents \n `@` entities \n `@{entity-name}:` {entity-name} values \n `$` context-variables that you defined or referenced elsewhere in the dialog \n\n\n\nYou can create a new intent, entity, entity value, or context variable by defining a new condition that uses it. If you create an artifact this way, be sure to go back and complete any other steps that are necessary for the artifact to be created completely, such as defining sample utterances for an intent.\n\nTo define a node that triggers based on more than one condition, enter one condition, and then click the plus sign (+) icon next to it. If you want to apply an OR operator to the multiple conditions instead of AND, click the and that is displayed between the fields to change the operator type. AND operations are executed before OR operations, but you can change the order by using parentheses. For example: $isMember:true AND ($memberlevel:silver OR $memberlevel:gold)\n\nThe condition you define must be less than 2,048 characters in length.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"},{"document_id":"ibmcld_02873-7-1949","score":10.867111,"text":"\nDialog overview \n\nThe dialog uses the intents that are identified in the user's input, plus context from the application, to interact with the user and ultimately provide a useful response.\n\nThe dialog matches intents (what users say) to responses (what the bot says back). The response might be the answer to a question such as Where can I get some gas? or the execution of a command, such as turning on the radio. The intent and entity might be enough information to identify the correct response, or the dialog might ask the user for more input that is needed to respond correctly. For example, if a user asks, Where can I get some food? you might want to clarify whether they want a restaurant or a grocery store, to dine in or take out, and so on. You can ask for more details in a text response and create one or more child nodes to process the new input.\n\nThe dialog is represented graphically in Watson Assistant as a tree. Create a branch to process each intent that you want your conversation to handle. A branch is composed of multiple nodes.\n\n\n\n Dialog nodes \n\nEach dialog node contains, at a minimum, a condition and a response.\n\n![Shows user input going to a box that contains the statement If: CONDITION, Then: RESPONSE](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/node1-empty.png)\n\n\n\n* Condition: Specifies the information that must be present in the user input for this node in the dialog to be triggered. The information is typically a specific intent. It might also be an entity type, an entity value, or a context variable value. See [Conditions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-builddialog-overview-conditions) for more information.\n* Response: The utterance that your assistant uses to respond to the user. The response can also be configured to show an image or a list of options, or to trigger programmatic actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build"},{"document_id":"ibmcld_03040-43198-45083","score":10.858472,"text":"\nRich response types support\n: Rich response types are now supported in a dialog node with slots. You can display a list of options for a user to choose from as the prompt for a slot, for example. For more information, see [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots).\n\nImproved Entities, Dialog, and Intents page responsiveness\n: The Entities, Dialog, and Intents pages were updated to use a new JavaScript library that increases the page responsiveness. As a result, the look of some graphical user interface elements, such as buttons, changed slightly, but the function did not.\n\nCreating contextual entities is easier\n: The process you use to annotate entity mentions from intent user examples was improved. You can now put the intent page into annotation mode to more easily select and label mentions. For more information, see [Adding contextual entities](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entitiesentities-create-annotation-based).\n\nWebhook callouts are available\n: Add webhooks to dialog nodes to make programmatic calls to an external application as part of the conversational flow. This capability is being introduced as a beta feature. For more details, see [Making a programmatic call from dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-webhooks).\n\nTesting improvement\n: You can now see the top three intents that were recognized in a test user input from the Try it out pane. For more details, see [Testing your dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasksdialog-tasks-test).\n\n\n\n\n\n 3 September 2019 \n\nIBM Watson\u00ae Assistant for IBM Cloud Pak\u00ae for Data version 1.3 is available\n: Watson Assistant for IBM Cloud Pak\u00ae for Data version 1.3 is compatible with IBM Cloud Pak\u00ae for Data versions 2.1.0.1 and 2.1.0.2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-release-notes"},{"document_id":"ibmcld_03185-6701-8694","score":10.537568,"text":"\n[A sample dialog tree with example content](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog-depiction-full.png)\n\nThe dialog tree in this diagram contains two root dialog nodes. A typical dialog tree would likely have many more nodes, but this depiction provides a glimpse of what a subset of nodes might look like.\n\n\n\n* The first root node conditions on an intent value. It has two child nodes that each condition on an entity value. The second child node defines two responses. The first response is returned to the user if the value of the context variable matches the value specified in the condition. Otherwise, the second response is returned.\n\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots. It also conditions on an intent value. It defines a set of slots, one for each piece of information that you want to collect from the user. Each slot asks a question to elicit the answer from the user. It looks for a specific entity value in the user's reply to the prompt, which it then saves in a slot context variable.\n\nThis type of node is useful for collecting details you might need to perform a transaction on the user's behalf. For example, if the user's intent is to book a flight, the slots can collect the origin and destination location information, travel dates, and so on.\n\n\n\n\n\n\n\n Ready to get started? \n\nFor more information, see [Creating a dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-build"},{"document_id":"ibmcld_03369-131609-133663","score":10.504854,"text":"\n: Fixed a bug in the Dialogs tool which prevented you from being able to configure a jump-to that targets the response of a node with the anything_else special condition.\n\nDigression return message\n: You can now specify text to display when the user returns to a node after a digression. The user will have seen the prompt for the node already. You can change the message slightly to let users know they are returning to where they left off. For example, specify a response like, Where were we? Oh, yes... See [Digressions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-digressions) for more details.\n\n\n\n\n\n 12 July 2018 \n\nRich response types\n: You can now add rich responses that include elements such as images or buttons in addition to text, to your dialog. See [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-multimedia) for more information.\n\nContextual entities (Beta)\n: Contextual entities are entities that you define by labeling mentions of the entity type that occur in intent user examples. These entity types teach your assistant not only terms of interest, but also the context in which terms of interest typically appear in user utterances, enabling your assistant to recognize never-seen-before entity mentions based solely on how they are referenced in user input. For example, if you annotate the intent user example, I want a flight to Boston by labeling Boston as a @destination entity, then your assistant can recognize Chicago as a @destination mention in a user input that says, I want a flight to Chicago. This feature is currently available for English only. See [Adding contextual entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-create-annotation-based) for more information.\n\nWhen you access the tool with an Internet Explorer web browser, you cannot label entity mentions in intent user examples nor edit user example text.\n\nEntity recommendations\n: Watson can now recommend synonyms for your entity values.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-210685-212822","score":10.486619,"text":"\nYou cannot rename or delete an intent with this name; to change the name, export your intents to a file, rename the intent in the file, and import the updated file into your workspace. Paying customers can contact support for a database change.\n\n\n\n\n\n 1 March 2017 \n\nSystem entities are now enabled in German\n: System entities are now enabled in German.\n\n\n\n\n\n 22 February 2017 \n\nMessages are now limited to 2,048 characters\n: Messages are now limited to 2,048 characters.\n\n\n\n\n\n 3 February 2017 \n\nUpdates\n: This release includes the following updates:\n\n\n\n* We changed how intents are scored and added the ability to mark input as irrelevant to your application. For details, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents) and search for Mark as irrelevant.\n* This release introduced a major change to the workspace. To benefit from the changes, you must manually upgrade your workspace.\n* The processing of Jump to actions changed to prevent loops that can occur under certain conditions. Previously, if you jumped to the condition of a node and neither that node nor any of its peer nodes had a condition that was evaluated as true, the system would jump to the root-level node and look for a node whose condition matched the input. In some situations this processing created a loop, which prevented the dialog from progressing.\n\n\n\nUnder the new process, if neither the target node nor its peers is evaluated as true, the dialog turn is ended. To reimplement the old model, add a final peer node with a condition of true. In the response, use a Jump to action that targets the condition of the first node at the root level of your dialog tree.\n\n\n\n\n\n 11 January 2017 \n\nCustomize node titles\n: In this release, you can customize node titles in dialog.\n\n\n\n\n\n 22 December 2016 \n\nNode title section\n: In this release, dialog nodes display a new section for node title. The ability to customize the node title is not available. When collapsed, the node title displays the node condition of the dialog node. If there is not a node condition, \"Untitled Node\" is displayed as the title.\n\n\n\n\n\n 19 December 2016","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03282-4605-6541","score":10.452551,"text":"\n* Dealing with multiple intents: A user enters input that expresses a wish to complete two separate tasks. I want to open a savings account and apply for a credit card. How does the dialog recognize and address both of them? See the [Compound questions](https:\/\/sodoherty.ai\/2017\/02\/06\/compound-questions\/) entry from Simon O'Doherty's blog for strategies you can try. (Simon is a developer on the Watson Assistant team.)\n* Dealing with ambiguous intents: A user enters input that expresses a wish that is ambiguous enough that your assistant finds two or more nodes with intents that could potentially address it. How does the dialog know which dialog branch to follow? If you enable disambiguation, it can show users their options and ask the user to pick the correct one. See [Disambiguation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation) for more details.\n* Handling multiple entities in input: If you want to evaluate only the value of the first detected instance of an entity type, you can use the syntax @entity == 'specific-value' instead of the @entity:(specific-value) format.\n\nFor example, when you use @appliance == 'air conditioner', you are evaluating only the value of the first detected @appliance entity. But, using @appliance:(air conditioner) gets expanded to entity['appliance'].contains('air conditioner'), which matches whenever there is at least one @appliance entity of value 'air conditioner' detected in the user input.\n* Hiding data from the log: You can prevent information from being stored in Watson logs by storing it in a context variable and nesting the context variable within the $private section of the message context. For example: $private.my_info. Storing data in the private object hides it from the logs only. The information is still stored in the underlying JSON object. Do not allow this information to be exposed to the client application.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tips"},{"document_id":"ibmcld_03191-3683-5706","score":10.441693,"text":"\nFor this Dialog runtime context which is set by a previous node or external application:\n\n{\n\"context\": {\n\"toppings_array\": [\"onion\", \"olives\", \"ham\"]\n}\n}\n\nDialog node or response condition:\n\n$toppings_array.containsIgnoreCase('HAM')\n\nResult: true because the array contains the element ham and the case is ignored.\n\n\n\n\n\n JSONArray.containsIntent(String intent_name, Double min_score, [Integer top_n]) \n\nThis method returns true if the intents JSONArray specifically contains the specified intent, and that intent has a confidence score that is equal to or higher than the specified minimum score. Optionally, you can specify a number to indicate that the intent must be included within that number of top elements in the array. The top_n parameter is ignored if you specify a negative number.\n\nReturns false if the specified intent is not in the array, does not have a confidence score that is equal to or greater than the minimum confidence score, or the array index of the intent is lower than the specified index location.\n\nThe service automatically generates an intents array that lists the intents that the service detects in the input whenever user input is submitted. The array lists all intents that are detected by the service in order of highest confidence first.\n\nYou can use this method in a node condition to not only check for the presence of an intent, but to set a confidence score threshold that must be met before the node can be processed and its response returned.\n\nFor example, use the following expression in a node condition when you want to trigger the dialog node only when the following conditions are met:\n\n\n\n* The General_Ending intent is present.\n* The confidence score of the General_Ending intent is over 80%.\n* The General_Ending intent is one of the top 2 intents in the intents array.\n\n\n\nintents.containsIntent(\"General_Ending\", 0.8, 2)\n\n\n\n\n\n JSONArray.filter(temp, \"temp.property operator comparison_value\") \n\nFilters an array by comparing each array element value to a value you specify.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-methods"},{"document_id":"ibmcld_02877-2458-4452","score":10.435151,"text":"\nThis method returns true if the input JSONArray contains the input value.\n\nFor this Dialog runtime context which is set by a previous node or external application:\n\n{\n\"context\": {\n\"toppings_array\": [\"onion\", \"olives\", \"ham\"]\n}\n}\n\nDialog node or response condition:\n\n$toppings_array.contains('ham')\n\nResult: True because the array contains the element ham.\n\n\n\n\n\n JSONArray.containsIntent(String intent_name, Double min_score, [Integer top_n]) \n\nThis method returns true if the intents JSONArray specifically contains the specified intent, and that intent has a confidence score that is equal to or higher than the specified minimum score. Optionally, you can specify a number to indicate that the intent must be included within that number of top elements in the array.\n\nReturns false if the specified intent is not in the array, does not have a confidence score that is equal to or higher than the minimum confidence score, or the intent is lower in the array than the specified index location.\n\nThe service automatically generates an intents array that lists the intents that the service detects in the input whenever user input is submitted. The array lists all intents that are detected by the service in order of highest confidence first.\n\nYou can use this method in a node condition to not only check for the presence of an intent, but to set a confidence score threshold that must be met before the node can be processed and its response returned.\n\nFor example, use the following expression in a node condition when you want to trigger the dialog node only when the following conditions are met:\n\n\n\n* The General_Ending intent is present.\n* The confidence score of the General_Ending intent is over 80%.\n* The General_Ending intent is one of the top two intents in the intents array.\n\n\n\nintents.containsIntent(\"General_Ending\", 0.8, 2)\n\n\n\n\n\n JSONArray.filter(temp, \"temp.property operator comparison_value\") \n\nFilters an array by comparing each array element value to a value you specify.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-methods"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03191-3683-5706","score":11.758634,"text":"\nFor this Dialog runtime context which is set by a previous node or external application:\n\n{\n\"context\": {\n\"toppings_array\": [\"onion\", \"olives\", \"ham\"]\n}\n}\n\nDialog node or response condition:\n\n$toppings_array.containsIgnoreCase('HAM')\n\nResult: true because the array contains the element ham and the case is ignored.\n\n\n\n\n\n JSONArray.containsIntent(String intent_name, Double min_score, [Integer top_n]) \n\nThis method returns true if the intents JSONArray specifically contains the specified intent, and that intent has a confidence score that is equal to or higher than the specified minimum score. Optionally, you can specify a number to indicate that the intent must be included within that number of top elements in the array. The top_n parameter is ignored if you specify a negative number.\n\nReturns false if the specified intent is not in the array, does not have a confidence score that is equal to or greater than the minimum confidence score, or the array index of the intent is lower than the specified index location.\n\nThe service automatically generates an intents array that lists the intents that the service detects in the input whenever user input is submitted. The array lists all intents that are detected by the service in order of highest confidence first.\n\nYou can use this method in a node condition to not only check for the presence of an intent, but to set a confidence score threshold that must be met before the node can be processed and its response returned.\n\nFor example, use the following expression in a node condition when you want to trigger the dialog node only when the following conditions are met:\n\n\n\n* The General_Ending intent is present.\n* The confidence score of the General_Ending intent is over 80%.\n* The General_Ending intent is one of the top 2 intents in the intents array.\n\n\n\nintents.containsIntent(\"General_Ending\", 0.8, 2)\n\n\n\n\n\n JSONArray.filter(temp, \"temp.property operator comparison_value\") \n\nFilters an array by comparing each array element value to a value you specify.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-methods"},{"document_id":"ibmcld_02877-2458-4452","score":11.73002,"text":"\nThis method returns true if the input JSONArray contains the input value.\n\nFor this Dialog runtime context which is set by a previous node or external application:\n\n{\n\"context\": {\n\"toppings_array\": [\"onion\", \"olives\", \"ham\"]\n}\n}\n\nDialog node or response condition:\n\n$toppings_array.contains('ham')\n\nResult: True because the array contains the element ham.\n\n\n\n\n\n JSONArray.containsIntent(String intent_name, Double min_score, [Integer top_n]) \n\nThis method returns true if the intents JSONArray specifically contains the specified intent, and that intent has a confidence score that is equal to or higher than the specified minimum score. Optionally, you can specify a number to indicate that the intent must be included within that number of top elements in the array.\n\nReturns false if the specified intent is not in the array, does not have a confidence score that is equal to or higher than the minimum confidence score, or the intent is lower in the array than the specified index location.\n\nThe service automatically generates an intents array that lists the intents that the service detects in the input whenever user input is submitted. The array lists all intents that are detected by the service in order of highest confidence first.\n\nYou can use this method in a node condition to not only check for the presence of an intent, but to set a confidence score threshold that must be met before the node can be processed and its response returned.\n\nFor example, use the following expression in a node condition when you want to trigger the dialog node only when the following conditions are met:\n\n\n\n* The General_Ending intent is present.\n* The confidence score of the General_Ending intent is over 80%.\n* The General_Ending intent is one of the top two intents in the intents array.\n\n\n\nintents.containsIntent(\"General_Ending\", 0.8, 2)\n\n\n\n\n\n JSONArray.filter(temp, \"temp.property operator comparison_value\") \n\nFilters an array by comparing each array element value to a value you specify.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-methods"},{"document_id":"ibmcld_02873-7-1949","score":11.699889,"text":"\nDialog overview \n\nThe dialog uses the intents that are identified in the user's input, plus context from the application, to interact with the user and ultimately provide a useful response.\n\nThe dialog matches intents (what users say) to responses (what the bot says back). The response might be the answer to a question such as Where can I get some gas? or the execution of a command, such as turning on the radio. The intent and entity might be enough information to identify the correct response, or the dialog might ask the user for more input that is needed to respond correctly. For example, if a user asks, Where can I get some food? you might want to clarify whether they want a restaurant or a grocery store, to dine in or take out, and so on. You can ask for more details in a text response and create one or more child nodes to process the new input.\n\nThe dialog is represented graphically in Watson Assistant as a tree. Create a branch to process each intent that you want your conversation to handle. A branch is composed of multiple nodes.\n\n\n\n Dialog nodes \n\nEach dialog node contains, at a minimum, a condition and a response.\n\n![Shows user input going to a box that contains the statement If: CONDITION, Then: RESPONSE](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/node1-empty.png)\n\n\n\n* Condition: Specifies the information that must be present in the user input for this node in the dialog to be triggered. The information is typically a specific intent. It might also be an entity type, an entity value, or a context variable value. See [Conditions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-builddialog-overview-conditions) for more information.\n* Response: The utterance that your assistant uses to respond to the user. The response can also be configured to show an image or a list of options, or to trigger programmatic actions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build"},{"document_id":"ibmcld_02952-1632-3754","score":11.698892,"text":"\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_03069-7-2188","score":11.41057,"text":"\nTutorial: Building a complex dialog \n\nIn this tutorial, you will use the Watson Assistant service to create a dialog for an assistant that helps users with inquiries about a fictitious restaurant called Truck Stop Gourmand.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Plan a dialog\n* Define custom intents\n* Add dialog nodes that can handle your intents\n* Add entities to make your responses more specific\n* Add a pattern entity, and use it in the dialog to find patterns in user input\n* Set and reference context variables\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 2 to 3 hours to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started).\n\nYou will use the dialog skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\n\n\n\n\n\n\n Step 1: Plan the dialog \n\nYou are building an assistant for a restaurant named Truck Stop Gourmand that has one location and a thriving cake-baking business. You want the simple assistant to answer user questions about the restaurant, its menu, and to cancel customer cake orders. Therefore, you need to create intents that handle inquiries related to the following subjects:\n\n\n\n* Restaurant information\n* Menu details\n* Order cancellations\n\n\n\nYou'll start by creating intents that represent these subjects, and then build a dialog that responds to user questions about them.\n\n\n\n\n\n Step 2: Answer questions about the restaurant \n\nAdd an intent that recognizes when customers ask for details about the restaurant itself. An intent is the purpose or goal expressed in user input. The General_About_You intent that is provided with the General content catalog serves a similar function, but its user examples are designed to focus on queries about the assistant as opposed to the business that is using the assistant to help its customers. So, you will add your own intent.\n\n\n\n Add the about_restaurant intent \n\n\n\n1. From the Intents tab, click Create intent.\n\n![Shows the the Create intent button on the Intents page.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial"},{"document_id":"ibmcld_02998-8791-9815","score":11.360754,"text":"\nYou created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:\n\n\n\n* Add standard nodes with the [Building a complex dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial) tutorial.\n* Learn about slots with the [Adding a node with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots) tutorial.\n\n\n\n* Check out more [sample apps](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-sample-apps) to get ideas.\n\n\n\nWhen you're ready to deploy your assistant, see [Deploying](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-custom-app).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03334-12430-14290","score":11.174467,"text":"\nIf the top intent has a low confidence score (less than 0.2), the top intent is included in the intents array that is returned by the API, but any nodes that condition on the intent are not triggered. If you want to detect the case when no intents with good confidence scores were detected, use the irrelevant special condition in your dialog node. See [Special conditions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-special-conditions) for more information.\n\nAs intent confidence scores change, your dialogs might need restructuring. For example, if a dialog node uses an intent in its condition, and the intent's confidence score starts to consistently drop below 0.2, the dialog node stops being processed. If the confidence score changes, the behavior of the dialog can also change.\n\n\n\n\n\n Intent limits \n\nThe number of intents and examples you can create depends on your Watson Assistant plan type:\n\n\n\nPlan details\n\n Plan Intents per skill Examples per skill \n\n Enterprise 2,000 25,000 \n Premium (legacy) 2,000 25,000 \n Plus 2,000 25,000 \n Lite, Trial 100 25,000 \n\n\n\n\n\n\n\n Editing intents \n\nYou can click any intent in the list to open it for editing. You can make the following changes:\n\n\n\n* Rename the intent.\n* Delete the intent.\n* Add, edit, or delete examples.\n* Move an example to a different intent.\n\n\n\nYou can tab from the intent name to each example.\n\n\n\n1. To move or delete an example, click the checkbox that is associated with it, and then click Move or Delete.\n\n![Screen capture showing how to move or delete an example](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/move_example.png)\n\n\n\n\n\n\n\n Searching intents \n\nUse the Search feature to find user examples, intent names, and descriptions.\n\n\n\n1. From the Intents page, click the Search icon.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-intents"},{"document_id":"ibmcld_03071-7-2056","score":11.072307,"text":"\nTutorial: Adding a node with slots to a dialog \n\nIn this tutorial, you will add slots to a dialog node to collect multiple pieces of information from a user within a single node. The node you create will collect the information that is needed to make a restaurant reservation.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Define the intents and entities that are needed by your dialog\n* Add slots to a dialog node\n* Test the node with slots\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 30 minutes to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started). You will use the Watson Assistant tutorial skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\nYou can also start with a new dialog skill if you want. Just be sure to create the skill before you begin this tutorial.\n\n\n\n\n\n\n\n Step 1: Add intents and examples \n\nAdd an intent on the Intents tab. An intent is the purpose or goal that is expressed in user input. You will add a #reservation intent that recognizes user input that indicates that the user wants to make a restaurant reservation.\n\n\n\n1. From the Intents page of the tutorial skill, click Add intent.\n2. Add the following intent name, and then click Create intent:\n\nreservation\n\nThe #reservation intent is added. A number sign () is prepended to the intent name to label it as an intent. This naming convention helps you and others recognize the intent as an intent. It has no example user utterances associated with it yet.\n3. In the Add user examples field, type the following utterance, and then click Add example:\n\ni'd like to make a reservation\n4. Add these additional examples to help Watson recognize the reservation intent.\n\nI want to reserve a table for dinner\nCan 3 of us get a table for lunch?\ndo you have openings for next Wednesday at 7?\nIs there availability for 4 on Tuesday night?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots"},{"document_id":"ibmcld_02998-7662-9256","score":10.987687,"text":"\n[An ending node was added to the dialog also.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/gs-ending-node-added.png)\n\n\n\n\n\n Testing intent recognition \n\nYou built a simple dialog to recognize and respond to both greeting and ending inputs. Let's see how well it works.\n\n\n\n1. Click the ![Try it](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/try-it.png) icon to open the Try it out pane. There's that reassuring welcome message.\n2. In the text field, type Hello and press Enter. The output indicates that the General_Greetings intent was recognized, and the appropriate response (Good day to you.) is displayed.\n3. Try the following input:\n\n\n\n* bye\n* howdy\n* see ya\n* good morning\n* sayonara\n\n\n\n\n\nWatson can recognize your intents even when your input doesn't exactly match the examples that you included. The dialog uses intents to identify the purpose of the user's input regardless of the precise wording used, and then responds in the way you specify.\n\n\n\n\n\n Result of building a dialog \n\nThat's it. You created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03185-6701-8694","score":10.960864,"text":"\n[A sample dialog tree with example content](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog-depiction-full.png)\n\nThe dialog tree in this diagram contains two root dialog nodes. A typical dialog tree would likely have many more nodes, but this depiction provides a glimpse of what a subset of nodes might look like.\n\n\n\n* The first root node conditions on an intent value. It has two child nodes that each condition on an entity value. The second child node defines two responses. The first response is returned to the user if the value of the context variable matches the value specified in the condition. Otherwise, the second response is returned.\n\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots. It also conditions on an intent value. It defines a set of slots, one for each piece of information that you want to collect from the user. Each slot asks a question to elicit the answer from the user. It looks for a specific entity value in the user's reply to the prompt, which it then saves in a slot context variable.\n\nThis type of node is useful for collecting details you might need to perform a transaction on the user's behalf. For example, if the user's intent is to book a flight, the slots can collect the origin and destination location information, travel dates, and so on.\n\n\n\n\n\n\n\n Ready to get started? \n\nFor more information, see [Creating a dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-build"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.234639363,"ndcg_cut_10":0.234639363}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02841-1435-2454","score":11.442493,"text":"\n[A sample dialog tree with example content](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/dialog-depiction.png) \n\n\n\nThe dialog skill itself is defined in text, but you can integrate it with Watson Speech to Text and Watson Text to Speech services that enable users to interact with your assistant verbally.\n\n![Out-of-the-box training data](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/oob.png) If you want to get started quickly, add prebuilt training data to your dialog skill so your assistant can start helping your customers with the basics.\n\n\n\n\n\n Search skill \n\nA search skill leverages information from existing corporate knowledge bases or other collections of content authored by subject matter experts to address unanticipated or more nuanced customer inquiries.\n\nSee [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add) to get started.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistants"},{"document_id":"ibmcld_03126-5596-6966","score":10.814685,"text":"\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n\n\n\n\n\n Do you have existing content to leverage? \n\nThe answer to many a common question is already documented somewhere in your organization's technical information collateral. If only you could find it!\n\nGive your assistant access to this information by adding a search skill to your assistant. The search skill uses Discovery to return smart answers to natural language questions.\n\n\n\n\n\n Expand your assistant's responsibilities \n\nIf you start small, and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. The built-in metrics of active user conversations help you understand what your customers are asking about and how well your assistant is able to meet their needs.\n\nNothing beats real customer data. It will tell you what areas to tackle next.\n\n\n\n\n\n Ready to start building? \n\nSee [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add) to get started.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_03126-3707-6008","score":10.051202,"text":"\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants"},{"document_id":"ibmcld_02841-7-1807","score":9.994252,"text":"\nAssistants \n\nAn assistant is a cognitive bot that you can customize for the unique needs of your business. You teach it about the types of things your customers want to know and do, and then design a script for the assistant to follow as it converses with your customers to help them accomplish their business goals.\n\n![Skills](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/skill-icon.png) An assistant routes your customer queries to a skill, which then provides the appropriate response. Dialog skills return responses that are authored by you to answer common questions, while search skills search for and return passages from existing self-service content to answer more complex inquiries.\n\n\n\n Dialog skill \n\nA dialog skill can understand and address questions or requests that your customers typically need help with. You provide information about the subjects or tasks your users ask about, and how they ask about them, and the product dynamically builds a machine learning model that is tailored to understand the same and similar user requests.\n\n\n\n Dialog tree Graphical user interface \n\n You can use graphical tools to create a dialog for your assistant to read from when interacting with your users, a dialog that simulates a real conversation. The dialog keys off the common customer goals that you teach it to recognize, and provides useful responses. ![A sample dialog tree with example content](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/dialog-depiction.png) \n\n\n\nThe dialog skill itself is defined in text, but you can integrate it with Watson Speech to Text and Watson Text to Speech services that enable users to interact with your assistant verbally.\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistants"},{"document_id":"ibmcld_03043-7-2031","score":9.94872,"text":"\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add"},{"document_id":"ibmcld_03120-4813-6717","score":9.911777,"text":"\nFor more information, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions. For a dialog skill, add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Phone integration: If you want to deploy an assistant that uses the universal language model with the phone integration, you must connect to custom Speech service language models that can understand the language you're using. For more information about supported language models, see the [Speech to Text](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-modelsmodelsList) and [Text to Speech](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices) documentation.\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-web-chat-basicsweb-chat-basics-global).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-language"},{"document_id":"ibmcld_03403-33406-33957","score":9.746694,"text":"\nUnlike when you send test utterances to your assistant from the \"Try it out\" pane, standard usage charges apply to API calls that result from utterances that are submited to the chat widget.\n\n\n\n\n\n\n\n Next steps \n\nNow that you have built and tested your dialog skill, you can share it with customers. Deploy your skill by first connecting it to an assistant, and then deploying the assistant. There are several ways you can do this. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more details.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial"},{"document_id":"ibmcld_16364-163116-165172","score":9.520339,"text":"\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them. For more information, see [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add).\n\n\n\n* Assistants: You can now publish your skill in just two steps. Add your skill to an assistant, and then set up one or more integrations with which to deploy your skill. The assistant adds a layer of function to your skill that enables Watson Assistant to orchestrate and manage the flow of information for you. See [Assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistants).\n* Built-in integrations: Instead of going to the Deploy tab to deploy your workspace, you add your dialog skill to an assistant, and add integrations to the assistant through which the skill is made available to your users. You do not need to build a custom front-end application and manage the conversation state from one call to the next. However, you can still do so if you want to. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more information.\n* New major API version: A V2 version of the API is available. This version provides access to methods you can use to interact with an assistant at run time. No more passing context with each API call; the session state is managed for you as part of the assistant layer.\n\n\n\nWhat is presented in the tooling as a dialog skill is effectively a wrapper for a V1 workspace. There are currently no API methods for authoring skills and assistants with the V2 API. However, you can continue to use the V1 API for authoring workspaces.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03049-2703-4536","score":9.394224,"text":"\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-catalog).\n* To define your own intents, see [Defining intents](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Troubleshooting skill import issues \n\nIf you receive warnings when you try to upload a skill, take a moment to try to fix the issues.\n\n\n\n1. Make a note of the warning message that are displayed when you try to upload the JSON file.\n2. Edit the skill to address the issues.\n\n\n\n* If you have access to a public service instance, open the skill from there and make edits. Export the edited skill by downloading it.\n* Otherwise, open the JSON file in a text editor and make edits.\n\n\n\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03373-4-1923","score":9.280926,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n Adding skills to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nConversational skills return responses that are authored by you to answer common questions, while a search skill searches for and returns passages from existing self-service content.\n\nYou can add the following types of skills to your assistant:\n\n\n\n* Conversational skills: Understand and address questions or requests that your customers typically ask about. You provide information about the subjects or tasks that your users need help with, and how they ask about them, and the product dynamically builds a machine learning model that is tailored to understand the same and similar user requests.\n\n\n\n* Actions skill : Offers a simple interface where anyone can build a conversational flow for your assistant to follow. The complex process of training data creation occurs behind the scenes automatically. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-actions-skill)\n* Dialog skill: Offers a set of editors that you use to define both your training data and the conversation. The conversation is represented as a dialog tree. You use the graphical dialog editor to create a script of sorts for your assistant to read from when it interacts with your customers. The dialog keys off the common customer goals that you teach it to recognize, and provides useful responses. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-addskill-add-dialog-skill)\n\n\n\nIf you can't decide which type of conversational skill to create, see [Choosing a conversational skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skills-choose).\n* Search skill!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1815417925,"ndcg_cut_10":0.1815417925}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02873-7270-8670","score":11.552783,"text":"\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots. It also conditions on an intent value. It defines a set of slots, one for each piece of information that you want to collect from the user. Each slot asks a question to elicit the answer from the user. It looks for a specific entity value in the user's reply to the prompt, which it then saves in a slot context variable.\n\nThis type of node is useful for collecting details you might need to perform a transaction on the user's behalf. For example, if the user's intent is to book a flight, the slots can collect the origin and destination location information, travel dates, and so on.\n\n\n\n\n\n\n\n Ready to get started? \n\nFor more information, see [Building a dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview).\n\nNext topic:[Planning the dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-plan)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-build"},{"document_id":"ibmcld_03185-6701-8694","score":11.521629,"text":"\n[A sample dialog tree with example content](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog-depiction-full.png)\n\nThe dialog tree in this diagram contains two root dialog nodes. A typical dialog tree would likely have many more nodes, but this depiction provides a glimpse of what a subset of nodes might look like.\n\n\n\n* The first root node conditions on an intent value. It has two child nodes that each condition on an entity value. The second child node defines two responses. The first response is returned to the user if the value of the context variable matches the value specified in the condition. Otherwise, the second response is returned.\n\nThis standard type of node is useful to capture questions about a certain topic and then in the root response ask a follow-up question that is addressed by the child nodes. For example, it might recognize a user question about discounts and ask a follow-up question about whether the user is a member of any associations with which the company has special discount arrangements. And the child nodes provide different responses based on the user's answer to the question about association membership.\n* The second root node is a node with slots. It also conditions on an intent value. It defines a set of slots, one for each piece of information that you want to collect from the user. Each slot asks a question to elicit the answer from the user. It looks for a specific entity value in the user's reply to the prompt, which it then saves in a slot context variable.\n\nThis type of node is useful for collecting details you might need to perform a transaction on the user's behalf. For example, if the user's intent is to book a flight, the slots can collect the origin and destination location information, travel dates, and so on.\n\n\n\n\n\n\n\n Ready to get started? \n\nFor more information, see [Creating a dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-build"},{"document_id":"ibmcld_02900-4643-6783","score":11.258973,"text":"\n* a digression that starts elsewhere and enters the node must return to the interrupted dialog flow after the current dialog flow is completed\n\n\n\nTo change the digression behavior for an individual node, complete the following steps:\n\n\n\n1. Click the node to open its edit view.\n2. Click Customize, and then click the Digressions tab.\n\nThe configuration options differ depending on whether the node you are editing is a root node, a child node, a node with children, or a node with slots.\n\n\n\n Digressions away from this node \n\nIf the circumstances listed earlier do not apply, then you can make the following choices:\n\n\n\n* All node types: Choose whether to allow users to digress away from the current node before they reach the end of the current dialog branch.\n* All nodes that have children: Choose whether you want the conversation to come back to the current node after a digression if the current node's response has already been displayed and its child nodes are incidental to the node's goal. Set the Allow return from digressions triggered after this node's response toggle to No to prevent the dialog from returning to the current node and continuing to process its branch.\n\nFor example, if the user asks, Do you sell cupcakes? and the response, We offer cupcakes in a variety of flavors and sizes is displayed before the user changes subjects, you might not want the dialog to return to where it was. Especially, if the child nodes only address possible follow-up questions from the user and can safely be ignored.\n\nHowever, if the node relies on its child nodes to address the question, then you might want to force the conversation to return and continue processing the nodes in the current branch. For example, the initial response might be, We offer cupcakes in all shapes and sizes. Which menu do you want to see: gluten-free, dairy-free, or regular? If the user changes subjects at this point, you might want the dialog to return so the user can pick a menu type and get the information they wanted.\n* Nodes with slots: Choose whether you want to allow users to digress away from the node before all of the slots are filled.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime"},{"document_id":"ibmcld_03113-7328-8943","score":11.242354,"text":"\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_3.png)\n\nIn addition to creating node_9, the service automatically updates the previous_sibling property of node_6 so that it points to the new node.\n\n\n\n\n\n Moving a node to a different parent \n\nLet's move node_5 to a different parent by using the POST \/dialog_nodes\/node_5 method with the following body:\n\n{\n\"parent\": \"node_1\"\n}\n\nThe specified value for parent must be valid:\n\n\n\n* It must refer to an existing node.\n* It must not refer to the node being modified (a node cannot be its own parent).\n* It must not refer to a descendant of the node being modified.\n* It must not refer to a node of type response_condition or event_handler.\n\n\n\nThis results in the following changed structure:\n\n![Example dialog 4](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_4.png)\n\nSeveral things have happened here:\n\n\n\n* When node_5 moved to its new parent, node_7 went with it (because the parent value for node_7 did not change). When you move a node, all descendants of that node stay with it.\n* Because we did not specify a previous_sibling value for node_5, it is now the first sibling under node_1.\n* The previous_sibling property of node_4 was updated to node_5.\n* The previous_sibling property of node_9 was updated to null, because it is now the first sibling under node_2.\n\n\n\n\n\n\n\n Resequencing siblings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03218-24900-26959","score":11.124673,"text":"\nFor each node, you configure whether:<-- <ul> --> * a digression can start from and leave the node * a digression that starts elsewhere can target and enter the node * a digression that starts elsewhere and enters the node must return to the interrupted dialog flow after the current dialog flow is completed<-- <\/ul> -->To change the digression behavior for an individual node, complete the following steps:<-- <ol> -->1. Click the node to open its edit view.2. Click Customize, and then click the Digressions tab.\nThe configuration options differ depending on whether the node you are editing is a root node, a child node, a node with children, or a node with slots.\n\nDigressions away from this node\n\nIf the circumstances listed earlier do not apply, then you can make the following choices:\n\n<-- <ul> -->\n\n* All node types: Choose whether to allow users to digress away from the current node before they reach the end of the current dialog branch.\n* All nodes that have children: Choose whether you want the conversation to come back to the current node after a digression if the current node's response has already been displayed and its child nodes are incidental to the node's goal. Set the Allow return from digressions triggered after this node's response switch to No to prevent the dialog from returning to the current node and continuing to process its branch.\n\nFor example, if the user asks, Do you sell cupcakes? and the response, We offer cupcakes in a variety of flavors and sizes is displayed before the user changes subjects, you might not want the dialog to return to where it left off. Especially, if the child nodes only address possible follow-up questions from the user and can safely be ignored.\n\nHowever, if the node relies on its child nodes to address the question, then you might want to force the conversation to return and continue processing the nodes in the current branch. For example, the initial response might be, We offer cupcakes in all shapes and sizes. Which menu do you want to see: gluten-free, dairy-free, or regular?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime"},{"document_id":"ibmcld_03113-1615-3683","score":11.1224785,"text":"\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.\n\n\n\n* event_handler: A handler that is defined for a frame node or an individual slot node.\n\n\n\nFrom the tool, you can define a frame node handler by clicking the Manage handlers link from a node with slots. (The tool user interface does not expose the slot-level event handler, but you can define one through the API.)\n\n\n\n* frame: A node with one or more child nodes of type slot. Any child slot nodes that are required must be filled before the service can exit the frame node.\n\n\n\nThe frame node type is represented as a node with slots in the tool. The node that contains the slots is represented as a node of type=frame. It is the parent node to each slot, which is represented as a child node of type slot.\n\n\n\n* response_condition: A conditional response.\n\n\n\nIn the tool, you can add one or more conditional responses to a node. Each conditional response that you define is represented in the underlying JSON as an individual node of type=response_condition.\n\n\n\n* slot: A child node of a node of type frame.\n\n\n\nThis node type is represented in the tool as being one of multiple slots added to a single node. That single node is represented in the JSON as a parent node of type frame.\n\n\n\n* standard: A typical dialog node. This is the default type.\n\n\n\n* For nodes of type slot that have the same parent node, the sibling order (specified by the previous_sibling property) reflects the order in which the slots will be processed.\n* A node of type slot must have a parent node of type frame.\n* A node of type frame must have at least one child node of type slot.\n* A node of type response_condition must have a parent node of type standard or frame.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02961-7-1871","score":10.7007065,"text":"\nDialog building tips \n\nGet tips about ways to address common tasks.\n\n\n\n Adding nodes \n\n\n\n* Add a node name that describes the purpose of the node.\n\nYou currently know what the node does, but months from now you might not. Your future self and any team members will thank you for adding a descriptive node name. And the node name is displayed in the log, which can help you debug a conversation later.\n* To gather the information that is required to perform a task, try using a node with slots instead of a bunch of separate nodes to elicit information from users. See [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots).\n* For a complex process flow, tell users about any information they will need to provide at the start of the process.\n* Understand how your assistant travels through the dialog tree and the impact that folders, branches, jump-tos, and digressions have on the route. See [Dialog flow](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-builddialog-build-flow).\n* Do not add jump-tos everywhere. They increase the complexity of the dialog flow, and make it harder to debug the dialog later.\n* To jump to a node in the same branch as the current node, use Skip user input instead of a Jump-to.\n\nThis choice prevents you from having to edit the current node's settings when you remove or reorder the child nodes being jumped to. See [Defining what to do next](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-jump-to).\n* Before you enable digressions away from a node, test the most common user scenarios. And be sure that likely digressed-to nodes are configured to return. See [Digressions](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtimedialog-runtime-digressions).\n\n\n\n\n\n\n\n Adding responses","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tips"},{"document_id":"ibmcld_02882-7-2075","score":10.651235,"text":"\nBuilding a conversational flow \n\nThe dialog defines what your assistant says in response to customers.\n\n\n\n Creating a dialog \n\nTo create a dialog, complete the following steps:\n\n\n\n1. Click the Dialog tab, and then click Create dialog.\n\nWhen you open the dialog editor for the first time, the following nodes are created for you:\n\n\n\n* Welcome: The first node. It contains a greeting that is displayed to your users when they first engage with your assistant. You can edit the greeting.\n\n\n\nThis node is not triggered in dialog flows that are initiated by users. For example, dialogs that are deployed in environments such as messaging channels where customers start the conversation do not process nodes with the welcome special condition.\n\n\n\n* Anything else: The final node. It contains phrases that are used to reply to users when their input is not recognized. You can replace the responses that are provided or add more responses with a similar meaning to add variety to the conversation. You can also choose whether you want your assistant to return each response that is defined in turn or return them in random order.\n\n\n\n2. To add more nodes to the dialog tree, click the More![More icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/kabob.png) icon on the Welcome node, and then select Add node below.\n3. In the If assistant recognizes field, enter a condition that, when met, triggers your assistant to process the node.\n\nTo start off, you typically want to add an intent as the condition. For example, if you add open_account here, it means that you want the response that you will specify in this node to be returned to the user if the user input indicates that the user wants to open an account.\n\nAs you begin to define a condition, a box is displayed that shows you your options. You can enter one of the following characters, and then pick a value from the list of options that is displayed.\n\n\n\nCondition builder syntax\n\n Character Lists defined values for these artifact types \n\n `#` intents","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_02952-3289-5462","score":10.567381,"text":"\nAdd meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\n\n\n\n\n Measuring containment \n\nFrom the Analytics page, you can measure conversation containment. Containment is the rate at which your assistant is able to satisfy a customer's request without human intervention per conversation.\n\nTo measure containment accurately, the metric must be able to identify when a human intervention occurs. The metric primarily uses the Connect to human agent response type as an indicator. If a user conversation log includes a call to a Connect to human agent response type, then the conversation is considered to be not contained.\n\nHowever, not all human interventions are transacted by using a Connect to human agent response type. If you use an alternate method to deliver additional support, you must take additional steps to register the fact that the customer's need was not fulfilled by the assistant. For example, you might direct customers to your call center phone number or to an online support ticket form URL.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-support"},{"document_id":"ibmcld_02914-1593-3315","score":10.549406,"text":"\nThe following example shows how the output object is represented in the dialog JSON editor:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"This is my response text.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n}\n]\n}\n}\n\n\n\nIn the resulting API \/message response, the text response is formatted as follows:\n\n{\n\"text\": \"This is my response text.\",\n\"response_type\": \"text\"\n}\n\nThe following output object JSON format is supported for backwards compatibility. With the introduction of rich response types, the output.text structure was augmented with the output.generic structure to facilitate supporting other types of responses in addition to text. Use the new format when you create new nodes to give yourself more flexibility, because you can subsequently change the response type, if needed.\n\n{\n\"output\": {\n\"text\": {\n\"values\": [\n\"This is my response text.\"\n]\n}\n}\n}\n\nThere are response types other than a text response that you can define. See [Responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-responses) for more details.\n\nYou can learn more about the \/message API call from the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2).\n\n\n\n Retaining information across dialog turns \n\nThe dialog in a dialog skill is stateless, meaning that it does not retain information from one interaction with the user to the next. When you add a dialog skill to an assistant and deploy it, the assistant saves the context from one message call and then re-submits it on the next request throughout the current session. The current session lasts for as long a user interacts with the assistant plus the designated session inactivity time frame.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-context"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03113-1615-3683","score":12.310515,"text":"\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.\n\n\n\n* event_handler: A handler that is defined for a frame node or an individual slot node.\n\n\n\nFrom the tool, you can define a frame node handler by clicking the Manage handlers link from a node with slots. (The tool user interface does not expose the slot-level event handler, but you can define one through the API.)\n\n\n\n* frame: A node with one or more child nodes of type slot. Any child slot nodes that are required must be filled before the service can exit the frame node.\n\n\n\nThe frame node type is represented as a node with slots in the tool. The node that contains the slots is represented as a node of type=frame. It is the parent node to each slot, which is represented as a child node of type slot.\n\n\n\n* response_condition: A conditional response.\n\n\n\nIn the tool, you can add one or more conditional responses to a node. Each conditional response that you define is represented in the underlying JSON as an individual node of type=response_condition.\n\n\n\n* slot: A child node of a node of type frame.\n\n\n\nThis node type is represented in the tool as being one of multiple slots added to a single node. That single node is represented in the JSON as a parent node of type frame.\n\n\n\n* standard: A typical dialog node. This is the default type.\n\n\n\n* For nodes of type slot that have the same parent node, the sibling order (specified by the previous_sibling property) reflects the order in which the slots will be processed.\n* A node of type slot must have a parent node of type frame.\n* A node of type frame must have at least one child node of type slot.\n* A node of type response_condition must have a parent node of type standard or frame.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02882-20723-22759","score":12.253166,"text":"\nYou can choose to show an indicator that the dialog is working on typing a response. Use this response type if you need to perform an action that might take some time. For example, a parent node makes a Cloud Function call and displays the result in a child node. You could use this response type as the response for the parent node to give the programmatic call time to complete, and then jump to the child node to show the result. This response type does not render in the Try it out pane. You must access a node that uses this response type from a test deployment to see how your users will experience it.\n* Search skill: Searches an external data source for relevant information to return to the user. The data source that is searched is a Discovery service data collection that you configure when you add a search skill to the assistant that uses this dialog skill. For more information, see [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add).\n\n\n\n\n\n Adding rich responses \n\nTo add a rich response, complete the following steps:\n\n\n\n1. Click the drop-down menu in the response field to choose a response type, and then provide any required information:\n\n\n\n* Connect to human agent. You can optionally add a message to share with the human agent to whom the conversation is transferred.\n\nYou must program the client application to recognize when this response type is triggered.\n* Image. Add the full URL to the hosted image file into the Image source field. The image must be in .jpg, .gif, or .png format. The image file must be stored in a location that is publicly addressable by URL.\n\nFor example: https:\/\/www.example.com\/assets\/common\/logo.png.\n\nIf you want to display an image title and description before the embedded image in the response, then add them in the fields provided.\n* Option. Complete the following steps:\n\n\n\n1. Click Add option.\n2. In the List label field, enter the option to display in the list. The label must be less than 2,048 characters in length.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_03113-7328-8943","score":12.235426,"text":"\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_3.png)\n\nIn addition to creating node_9, the service automatically updates the previous_sibling property of node_6 so that it points to the new node.\n\n\n\n\n\n Moving a node to a different parent \n\nLet's move node_5 to a different parent by using the POST \/dialog_nodes\/node_5 method with the following body:\n\n{\n\"parent\": \"node_1\"\n}\n\nThe specified value for parent must be valid:\n\n\n\n* It must refer to an existing node.\n* It must not refer to the node being modified (a node cannot be its own parent).\n* It must not refer to a descendant of the node being modified.\n* It must not refer to a node of type response_condition or event_handler.\n\n\n\nThis results in the following changed structure:\n\n![Example dialog 4](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_4.png)\n\nSeveral things have happened here:\n\n\n\n* When node_5 moved to its new parent, node_7 went with it (because the parent value for node_7 did not change). When you move a node, all descendants of that node stay with it.\n* Because we did not specify a previous_sibling value for node_5, it is now the first sibling under node_1.\n* The previous_sibling property of node_4 was updated to node_5.\n* The previous_sibling property of node_9 was updated to null, because it is now the first sibling under node_2.\n\n\n\n\n\n\n\n Resequencing siblings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_02882-27313-29495","score":12.038592,"text":"\nThis response type only returns a valid response if the assistant to which you added this dialog skill also has a search skill associated with it.\n\n\n\n2. Click Add response to add another response type to the current response.\n\nYou might want to add multiple response types to a single response to provide a richer answer to a user query. For example, if a user asks for store locations, you could show a map and display a button for each store location that the user can click to get address details. To build that type of response, you can use a combination of image, options, and text response types. Another example is using a text response type before a pause response type so you can warn users before pausing the dialog.\n\nYou cannot add more than 5 response types to a single response. Meaning, if you define three conditional responses for a dialog node, each conditional response can have no more than 5 response types added to it.\n\nA single dialog node cannot have more than one Connect to human agent or more than one Search skill response.\n3. If you added more than one response type, you can click the Move up or down arrows to arrange the response types in the order you want your assistant to process them.\n\n\n\n\n\n\n\n\n\n Conditional responses \n\nA single dialog node can provide different responses, each one triggered by a different condition. Use this approach to address multiple scenarios in a single node.\n\nThe node still has a main condition, which is the condition for using the node and processing the conditions and responses that it contains.\n\nIn this example, your assistant uses information that it collected earlier about the user's location to tailor its response, and provide information about the store nearest the user. See [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables) for more information about how to store information collected from the user.\n\n![Shows a node that shows a user ask, Where are you located, and the dialog has three different responses depending on conditions that use info from the $state context variable to specify locations in those states.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_03113-6206-7586","score":11.613929,"text":"\n[Example dialog](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_1.png)\n\nWe can create a new node by making a POST request to \/dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n![Example dialog 2](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_2.png)\n\nBecause node_8 was created without specifying a value for parent or previous_sibling, it is now the first node in the dialog. Note that in addition to creating node_8, the service also modified node_1 so that its previous_sibling property points to the new node.\n\nYou can create a node somewhere else in the dialog by specifying the parent and previous sibling:\n\n{\n\"dialog_node\": \"node_9\",\n\"parent\": \"node_2\",\n\"previous_sibling\": \"node_5\"\n}\n\nThe values you specify for parent and previous_node must be valid:\n\n\n\n* Both values must refer to existing nodes.\n* The specified parent must be the same as the parent of the previous sibling (or null, if the previous sibling has no parent).\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/dialog_api_3.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-api-dialog-modify"},{"document_id":"ibmcld_03188-1732-3801","score":11.546103,"text":"\n* To add an entire dialog branch that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.chat, to the If assistant recognizes field of the dialog root node.\n* To add a single dialog node that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.zendesk, to the If assistant recognizes field of the dialog child node.\n* To add slightly different responses for a single dialog node based on the integration type, complete the following steps:\n\n\n\n* From the node's edit view, click Customize and then set the Multiple conditioned responses switch to On. Click Apply.\n* In the dialog node response section, add the appropriate condition and corresponding response for each custom response type.\n\n\n\nThe following examples show how to specify a hypertext link in the best format for the integration where the text response will be displayed. For the Web chat integration, which supports Markdown formatting, you can include a link label in the response text to make the response look nicer. For the SMS with Twilio integration, you can skip the formatting that makes sense in a web page, and add the straight URL.\n\n\n\nCustom conditioned responses\n\n Integration type Condition Sample text response \n\n SMS with Twilio `$integrations.text_messaging` `For more information, go to https:\/\/www.ibm.com.` \n Web chat `$integrations.chat` `For more information, go to [the ibm.com site](https:\/\/www.ibm.com).` \n Response to show if no other conditions are met. `true` `For more information, go to ibm.com.` \n\n\n\n\n\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-integrations"},{"document_id":"ibmcld_03191-34440-36259","score":11.417932,"text":"\nYou can call this method on any object or field. If the conversion fails, null is returned.\n\n\n\n\n\n toInt() \n\nConverts the object or field to the Integer number type. You can call this method on any object or field. If the conversion fails, null is returned.\n\n\n\n\n\n toLong() \n\nConverts the object or field to the Long number type. You can call this method on any object or field. If the conversion fails, null is returned.\n\nIf you specify a Long number type in a SpEL expression, you must append an L to the number to identify it as such. For example, 5000000000L. This syntax is required for any numbers that do not fit into the 32-bit Integer type. For example, numbers that are greater than 2^31 (2,147,483,648) or lower than -2^31 (-2,147,483,648) are considered Long number types. Long number types have a minimum value of -2^63 and a maximum value of 2^63-1 (or 9,223,372,036,854,775,807).\n\nIf you need to find out if a number is too long to be recognized properly in the dialog, you can check whether there are more than 18 integers in the number by using an expression like this:\n\n {: codeblock}\n\n18 ?>\n\nIf you need to work with numbers that are longer than 18 integers, consider using a pattern entity (with a regular expression such as d{20}) to work with them instead of using @sys-number.\n\n Standard math {: dialog-methods-numbers-standard-math}\n\nUse SpEL expressions to define standard math equations, where the operators are represented by using these symbols:\n\n Arithmetic operation Symbol \n\n addition + \n division \/ \n multiplication * \n subraction \n\nFor example, in a dialog node response, you might add a context variable that captures a number specified in the user input (@sys-number), and saves it as $your_number. You can then add the following text as a text response:\n\n {: codeblock}\nI'm doing math.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-methods"},{"document_id":"ibmcld_02882-18936-21214","score":11.401372,"text":"\nYou can return responses with multimedia or interactive elements such as images or clickable buttons to simplify the interaction model of your application and enhance the user experience.\n\nIn addition to the default response type of Text, for which you specify the text to return to the user as a response, the following response types are supported:\n\n\n\n* Connect to human agent: The dialog calls a service that you designate, typically a service that manages human agent support ticket queues, to pass off the conversation to a person. You can optionally include a message that summarizes the user's issue to be provided to the human agent. It is the responsibility of the external service to display a message that is shown to the user that explains that the conversation is being transferred. The dialog does not manage that communication itself. The dialog transfer does not occur when you are testing nodes with this response type in the Try it out pane. You must access a node that uses this response type from a test deployment to see how your users will experience it.\n* Image: Embeds an image into the response. The source image file must be hosted somewhere and have a URL that you can use to reference it. It cannot be a file that is stored in a directory that is not publicly accessible.\n* Option: Adds a list of one or more options. When a user clicks one of the options, an associated user input value is sent to your assistant. How options are rendered can differ depending on where you deploy the dialog. For example, in one integration channel the options might be displayed as clickable buttons, but in another they might be displayed as a dropdown list.\n* Pause: Forces the application to wait for a specified number of milliseconds before continuing with processing. You can choose to show an indicator that the dialog is working on typing a response. Use this response type if you need to perform an action that might take some time. For example, a parent node makes a Cloud Function call and displays the result in a child node. You could use this response type as the response for the parent node to give the programmatic call time to complete, and then jump to the child node to show the result. This response type does not render in the Try it out pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overview"},{"document_id":"ibmcld_02914-1593-3315","score":11.394714,"text":"\nThe following example shows how the output object is represented in the dialog JSON editor:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"This is my response text.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n}\n]\n}\n}\n\n\n\nIn the resulting API \/message response, the text response is formatted as follows:\n\n{\n\"text\": \"This is my response text.\",\n\"response_type\": \"text\"\n}\n\nThe following output object JSON format is supported for backwards compatibility. With the introduction of rich response types, the output.text structure was augmented with the output.generic structure to facilitate supporting other types of responses in addition to text. Use the new format when you create new nodes to give yourself more flexibility, because you can subsequently change the response type, if needed.\n\n{\n\"output\": {\n\"text\": {\n\"values\": [\n\"This is my response text.\"\n]\n}\n}\n}\n\nThere are response types other than a text response that you can define. See [Responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-responses) for more details.\n\nYou can learn more about the \/message API call from the [API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2).\n\n\n\n Retaining information across dialog turns \n\nThe dialog in a dialog skill is stateless, meaning that it does not retain information from one interaction with the user to the next. When you add a dialog skill to an assistant and deploy it, the assistant saves the context from one message call and then re-submits it on the next request throughout the current session. The current session lasts for as long a user interacts with the assistant plus the designated session inactivity time frame.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-runtime-context"},{"document_id":"ibmcld_03040-43198-45083","score":11.316178,"text":"\nRich response types support\n: Rich response types are now supported in a dialog node with slots. You can display a list of options for a user to choose from as the prompt for a slot, for example. For more information, see [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots).\n\nImproved Entities, Dialog, and Intents page responsiveness\n: The Entities, Dialog, and Intents pages were updated to use a new JavaScript library that increases the page responsiveness. As a result, the look of some graphical user interface elements, such as buttons, changed slightly, but the function did not.\n\nCreating contextual entities is easier\n: The process you use to annotate entity mentions from intent user examples was improved. You can now put the intent page into annotation mode to more easily select and label mentions. For more information, see [Adding contextual entities](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-entitiesentities-create-annotation-based).\n\nWebhook callouts are available\n: Add webhooks to dialog nodes to make programmatic calls to an external application as part of the conversational flow. This capability is being introduced as a beta feature. For more details, see [Making a programmatic call from dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-webhooks).\n\nTesting improvement\n: You can now see the top three intents that were recognized in a test user input from the Try it out pane. For more details, see [Testing your dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-tasksdialog-tasks-test).\n\n\n\n\n\n 3 September 2019 \n\nIBM Watson\u00ae Assistant for IBM Cloud Pak\u00ae for Data version 1.3 is available\n: Watson Assistant for IBM Cloud Pak\u00ae for Data version 1.3 is compatible with IBM Cloud Pak\u00ae for Data versions 2.1.0.1 and 2.1.0.2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03406-34893-35432","score":15.244338,"text":"\nIn this tutorial you tested a node with slots and made changes that optimize how it interacts with real users. For more information about this subject, see [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots).\n\n\n\n\n\n\n\n Next steps \n\nDeploy your dialog skill by first connecting it to an assistant, and then deploying the assistant. There are several ways you can do this. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more details.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-slots-complex"},{"document_id":"ibmcld_03054-19820-21851","score":15.0081625,"text":"\nClick Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses any user input that it has a high confidence it can answer correctly. You can configure the dialog such that any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead. To do so, add a search skill response type to the Anything else node.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-disable).\n* If you want a specific search query to be triggered for specific questions, add a search skill response type to the appropriate dialog node. See [Responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia) for more details.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* Anything else node: Searches an external data source for a relevant answer when none of the dialog nodes can address the user's query.\n\nInstead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help: followed by the passage returned by the search. If a search skill is linked to your assistant, then whenever the anything_else node is triggered, rather than displaying the node response, you can set it up to trigger a search instead. The assistant passes the user input as the query to your search skill, and returns the search results as the response.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03383-17365-19519","score":14.799217,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-17392-19546","score":14.799217,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03049-3966-5647","score":14.713701,"text":"\nYou might need to remove the @sys-person and @sys-location entities from your training data, and any references to them from dialog nodes, for example.\n3. Try again to import the edited skill.\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/a2b18c153837bce00a5b4de496e4b4ca64bbf56e\/assistant-data\/images\/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Dialog Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nWhen you add a dialog skill from here, you get the development version. If you want to add a specific skill version, add it from the skill's Versions tab instead.\n\n\n\n\n\n\n\n Downloading a dialog skill \n\nYou can download a dialog skill in JSON format. You might want to download a skill if you want to use the same dialog skill in a different instance of the Watson Assistant service, for example. You can download it from one instance and import it to another instance as a new dialog skill.\n\nTo download a dialog skill, complete the following steps:\n\n\n\n1. Find the dialog skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-dialog-add"},{"document_id":"ibmcld_03273-14436-16185","score":14.279179,"text":"\nhttps:\/\/{location}.assistant.watson.cloud.ibm.com\/{location}\/{instance-id}\/skills\/{skill-id}\/build\/dialognode={node-id}\n4. Edit the URL by replacing the current {node-id} value with the ID of the node you want to find, and then submit the new URL.\n5. If necessary, highlight the edited URL again, and resubmit it.\n\n\n\nThe page refreshes, and shifts focus to the dialog node with the node ID that you specified. If the node ID is for a slot, a Found or Not found slot condition, a slot handler, or a conditional response, then the node in which the slot or conditional response is defined gets focus and the corresponding modal is displayed.\n\nIf you still cannot find the node, you can export the dialog skill and use a JSON editor to search the skill JSON file.\n\n\n\n How many nodes are in my dialog? \n\nTo see the number of dialog nodes in a dialog skill, do one of the following things:\n\n\n\n* If it is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n* Send a GET request to the \/dialog_nodes API endpoint, and include the include_count=true parameter. For example:\n\ncurl -u \"apikey:{apikey}\" \"{url}\/v1\/workspaces\/{workspace_id}\/dialog_nodes?version=2018-09-20&include_count=true\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1service-endpoint).\n\nIn the response, the total attribute in the pagination object contains the number of dialog nodes.\n\n\n\nIf the total seems larger than you expected, it might be because the dialog that you build from the application is translated into a JSON object.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasks"},{"document_id":"ibmcld_16727-82547-84483","score":14.2560215,"text":"\nThe dialog node response is equivalent to a Then statement in If-Then-Else programming logic. \n Skill Does the work of the assistant. A dialog skill has the training data and dialog that your assistant uses to chat with customers. An actions skill is a new way to build a conversation. Actions offers step-by-step flows for a range of simple or complex conversations and is made so that anybody can build. A search skill is configured to search the appropriate external data sources for answers to customer inquiries. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add). \n Skill version Versions are snapshots of a skill that you can create at key points during the development lifecycle. You can deploy one version to production, while you continue to make and test improvements that you make to another version of the skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-versions). \n Slots A special set of fields that you can add to a dialog node that enable the assistant to collect necessary pieces of information from the customer. For example, the assistant can require a customer to provide valid date and location details before it gets weather forecast information on the customer's behalf. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots). \n System entity Prebuilt entities that recognize references to common things like dates and numbers. You can add these to your skill and start using them immediately. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's Try it out pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-82572-84508","score":14.2560215,"text":"\nThe dialog node response is equivalent to a Then statement in If-Then-Else programming logic. \n Skill Does the work of the assistant. A dialog skill has the training data and dialog that your assistant uses to chat with customers. An actions skill is a new way to build a conversation. Actions offers step-by-step flows for a range of simple or complex conversations and is made so that anybody can build. A search skill is configured to search the appropriate external data sources for answers to customer inquiries. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-add). \n Skill version Versions are snapshots of a skill that you can create at key points during the development lifecycle. You can deploy one version to production, while you continue to make and test improvements that you make to another version of the skill. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-versions). \n Slots A special set of fields that you can add to a dialog node that enable the assistant to collect necessary pieces of information from the customer. For example, the assistant can require a customer to provide valid date and location details before it gets weather forecast information on the customer's behalf. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-slots). \n System entity Prebuilt entities that recognize references to common things like dates and numbers. You can add these to your skill and start using them immediately. [Learn more](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's Try it out pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03282-1477-3454","score":14.104495,"text":"\nThis choice prevents you from having to edit the current node's settings when you remove or reorder the child nodes being jumped to. See [Defining what to do next](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-jump-to).\n* Before you enable digressions away from a node, test the most common user scenarios. And be sure that likely digressed-to nodes are configured to return. See [Digressions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtimedialog-runtime-digressions).\n\n\n\n\n\n\n\n Adding responses \n\n\n\n* Keep answers short and useful.\n* Reflect the user's intent in the response.\n\nDoing so assures users that the bot is understanding them, or if it is not, gives users a chance to correct a misunderstanding immediately.\n* Only include links to external sites in responses if the answer depends on data that changes frequently.\n* Avoid overusing buttons. Encouraging users to pick predefined options from a set of buttons is less like a real conversation, and decreases your ability to learn what users really want to do. When you let real users ask for things in their own words, you can use the input to train the system and derive better intents.\n* Avoid using a bunch of nodes when one node will do. For example, add multiple conditional responses to a single node to return different responses depending on details provided by the user. See [Conditional responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-multiple).\n* Word your responses carefully. You can change how someone reacts to your system based simply on how you phrase a response. Changing one line of text can prevent you from having to write multiple lines of code to implement a complex programmatic solution.\n* Back up your skill frequently. See [Downloading a skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-tasksskill-tasks-download).\n\n\n\n\n\n\n\n Tips for capturing information from user input","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tips"},{"document_id":"ibmcld_16364-158662-160553","score":14.026203,"text":"\nDialog node limit changes\n: The dialog node limit was temporarily changed from 100,000 to 500 for new Standard plan instances. This limit change was later reversed. If you created a Standard plan instance during the time frame in which the limit was in effect, your dialogs might be impacted. The limit was in effect for skills created between 10 December and 12 December 2018. The lower limits will be removed from all impacted instances in January. If you need to have the lower limit lifted before then, open a support ticket.\n\n\n\n\n\n 1 December 2018 \n\nDetermine the number of dialog nodes\n: To determine the number of dialog nodes in a dialog skill, do one of the following things:\n\n\n\n* From the tool, if it is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n* Send a GET request to the \/dialog_nodes API endpoint, and include the include_count=true parameter. For example:\n\ncurl -u \"apikey:{apikey}\" \"https:\/\/{service-hostname}\/assistant\/api\/v1\/workspaces\/{workspace_id}\/dialog_nodes?version=2018-09-20&include_count=true\"\n\nwhere {service-hostname} is the appropriate URL for your instance. For more details, see [Service endpoint](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1service-endpoint).\n\nIn the response, the total attribute in the pagination object contains the number of dialog nodes.\n\nSee [Troubleshooting skill import issues](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors) for information about how to edit skills that you want to continue using.\n\n\n\n\n\n\n\n 27 November 2018 \n\nA new service plan, the Plus plan, is available\n: The new plan offers premium-level features at a lower price point. Unlike previous plans, the Plus plan is a user-based billing plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"f5a8ca2f2bc12180940167fb920bb018<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03054-19820-21851","score":15.256076,"text":"\nClick Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses any user input that it has a high confidence it can answer correctly. You can configure the dialog such that any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead. To do so, add a search skill response type to the Anything else node.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-disable).\n* If you want a specific search query to be triggered for specific questions, add a search skill response type to the appropriate dialog node. See [Responses](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia) for more details.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* Anything else node: Searches an external data source for a relevant answer when none of the dialog nodes can address the user's query.\n\nInstead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help: followed by the passage returned by the search. If a search skill is linked to your assistant, then whenever the anything_else node is triggered, rather than displaying the node response, you can set it up to trigger a search instead. The assistant passes the user input as the query to your search skill, and returns the search results as the response.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_16364-152318-154321","score":15.010492,"text":"\nSee [Building a search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add) for more details.\n\n\n\n\n\n 4 March 2019 \n\nSimplified navigation\n: The sidebar navigation with separate Build, Improve, and Deploy tabs has been removed. Now, you can get to all the tools you need to build a dialog skill from the main skill page.\n\nImprove page is now called Analytics\n: The informational metrics that Watson generates from conversations between your users and your assistant moved from the Improve tab of the sidebar to a new tab on the main skill page called Analytics.\n\n\n\n\n\n 28 February 2019 \n\nNew API version\n: The current API version is now 2019-02-28. The following changes were made with this version:\n\n\n\n* The order in which conditions are evaluated in nodes with slots has changed. Previously, if you had a node with slots that allowed for digressions away, the anything_else root node was triggered before any of the slot level Not found conditions could be evaluated. The order of operations has been changed to address this behavior. Now, when a user digresses away from a node with slots, all the root nodes except the anything_else node are processed. Next, the slot level Not found conditions are evaluated. And, finally, the root level anything_else node is processed. To better understand the full order of operations for a node with slots, see [Slot usage tips](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slotsdialog-slots-node-level-handler).\n* Strings that begin with a number sign (#) in the context or output objects of a message are no longer treated as intent references.\n\nPreviously, these strings were treated as intents automatically. For example, if you specified a context variable, such as \"color\":\"FFFFFF\", then the hex color code (FFFFFF) would be treated as an intent. Your assistant would check whether an intent named FFFFFF was detected in the user's input, and if not, would replace FFFFFF with false. This replacement no longer occurs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03383-17365-19519","score":14.853555,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-17392-19546","score":14.853555,"text":"\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_13042-19029-21139","score":14.766131,"text":"\nWhen the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.\n\n\n\n* From the dialog skill's Anything else node: If the assistant has a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses user input that it has a high confidence it can answer correctly. Any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead.\n\nFor example, instead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help:. The assistant passes the user input as the query to your search skill, and returns the search results as the response.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-addsearch-skill-add-disable).\n* When only a search skill is used: If only a search skill is linked to an assistant, and no conversational skill is configured, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03383-19002-21103","score":14.693212,"text":"\nWhen the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.\n\n\n\n* From the dialog skill's Anything else node: If the assistant has a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses user input that it has a high confidence it can answer correctly. Any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead.\n\nFor example, instead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help:. The assistant passes the user input as the query to your search skill, and returns the search results as the response.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-addsearch-skill-add-disable).\n* When only a search skill is used: If only a search skill is linked to an assistant, and no conversational skill is configured, then a search query is sent to the Discovery service when any user input is received from one of the assistant's integration channels.\n\n\n\n\n\n\n\n Test the search skill \n\nAfter you configure the search, you can send test queries to see the search results that get returned from Discovery by using the Preview pane of the search skill.\n\nTo test the full experience that customers will have when they ask questions that are either answered by the dialog or trigger a search, use the Preview button for your assistant.\n\nYou cannot test the full end-to-end user experience from the dialog \"Try it out\" pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add"},{"document_id":"ibmcld_03054-21355-23324","score":14.524314,"text":"\nInstead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help: followed by the passage returned by the search. If a search skill is linked to your assistant, then whenever the anything_else node is triggered, rather than displaying the node response, you can set it up to trigger a search instead. The assistant passes the user input as the query to your search skill, and returns the search results as the response.\n\nTo see how this works at run time (where v2 API is used) from the Try it out pane (where v1 API is used), you must add a search skill response type to the Anything else node in your dialog. Doing so mimics the behavior that occurs at run time. Only keep this response type on the Anything else node for the duration of your dialog testing, and then remove it when you're done. The best way to see how the assistant will behave from end-to-end is to test by using the API. See [Test the search skill](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-test-via-api).\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-disable).\n* Search response type: If you add a search skill response type to a dialog node, then your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed.\n\nThis approach is useful if you want to narrow down a user query before you trigger a search. For example, the dialog branch might collect information about the type of device the customer wants to buy. When you know the make and model, you can then send a model keyword in the query that is submitted to the search skill, and get better results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-skill-search-add"},{"document_id":"ibmcld_03369-114617-116733","score":14.489734,"text":"\nOver time, you can build dialog responses to answer customer queries that require follow-up questions to clarify the user's meaning or for which a short and clear response is suitable. And you can use search skill responses to address more open-ended customer queries that require a longer explanation. This beta feature is available to users of Premium and Plus service plans only.\n\nSee [Building a search skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-add) for more details.\n\n\n\n\n\n 14 March 2019 \n\n\n\n\n\n 4 March 2019 \n\nSimplified navigation\n: The sidebar navigation with separate Build, Improve, and Deploy tabs has been removed. Now, you can get to all the tools you need to build a dialog skill from the main skill page.\n\nImprove page is now called Analytics\n: The informational metrics that Watson generates from conversations between your users and your assistant moved from the Improve tab of the sidebar to a new tab on the main skill page called Analytics.\n\n\n\n\n\n 1 March 2019 \n\n\n\n\n\n 28 February 2019 \n\nNew API version\n: The current API version is now 2019-02-28. The following changes were made with this version:\n\n\n\n* The order in which conditions are evaluated in nodes with slots has changed. Previously, if you had a node with slots that allowed for digressions away, the anything_else root node was triggered before any of the slot level Not found conditions could be evaluated. The order of operations has been changed to address this behavior. Now, when a user digresses away from a node with slots, all the root nodes except the anything_else node are processed. Next, the slot level Not found conditions are evaluated. And, finally, the root level anything_else node is processed. To better understand the full order of operations for a node with slots, see [Slot usage tips](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slotsdialog-slots-node-level-handler).\n* Strings that begin with a number sign (#) in the context or output objects of a message are no longer treated as intent references.\n\nPreviously, these strings were treated as intents automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03269-4919-6270","score":14.39019,"text":"\n* The skill's analytics feature uses this node to learn about the topics that your dialog can't address. The coverage metric looks for occurrences of nodes with the anything_else condition being processed in the user conversation logs. It uses this information to determine the frequency with which your dialog is able to match user requests to intents that can address them. The node is registered by the metric if it conditions on anything_else alone or when it's used in combination with another condition, such as anything_else && positive_feedback.\n\nFor more information about the coverage metric, see [Graphs and statistics](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-overviewlogs-overview-graphs).\n* If you want your assistant to redirect queries to the search skill when the dialog is unable to address them, this node recognizes when it's time to initiate the search. It's when a customer's message reaches the anything_else node that the message is sent to the search skill to find a relevant answer in your configured data collections. For more information about searching for an answer, see [Search triggers](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-search-addskill-search-add-trigger).\n\nMessages that trigger search in this way are still registered by the coverage metric as messages that are not covered.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-start"},{"document_id":"ibmcld_03196-49298-51137","score":14.096377,"text":"\nThe search skill sends a natural language query to Discovery automatically. If you want to use the Discovery query language instead, you can specify it. To do so, open the JSON editor for the node response.\n\nEdit the JSON code snippet to replace natural_language with discovery_query_language. For example:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"query\": \"\",\n\"filter\": \"enriched_text.sentiment.document.label:positive\",\n\"query_type\": \"discovery_query_language\",\n\"response_type\": \"search_skill\"\n}\n]\n}\n}\n\n\n\nTest this response type from the assistant Preview. You cannot test it from the dialog skill's \"Try it out\" pane. For more information about testing dialog and search skills together, see [Testing your assistant from a web page](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-link).\n\n\n\n\n\n Conditional responses \n\nA single dialog node can provide different responses, each one triggered by a different condition. Use this approach to address multiple scenarios in a single node.\n\nThe node still has a main condition, which is the condition for using the node and processing the conditions and responses that it contains.\n\nIn this example, your assistant uses information that it collected earlier about the user's location to tailor its response, and provide information about the store nearest the user. See [Context variables](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-runtime-context) for more information about how to store information collected from the user.\n\n![Shows a node that shows a user ask, Where are you located, and the dialog has three different responses depending on conditions that use info from the $state context variable to specify locations in those states.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/multiple-responses.png)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10852-44214-45420","score":13.447434,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-2884-4620","score":13.268571,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_12339-0-1594","score":12.940743,"text":"\n\n\n\n\n\n\n  Java \n\nAs a standard bearer for enterprise application development and the native application language for Android, Java is a key language to support for your IBM Cloud service.\n\n\n\n  Content \n\n\n\n  Methods \n\nMethod parameters MUST be encapsulated into an \u201coptions\u201d object that can be constructed with a \"Builder\".\n\n\n\n\n\n  Streaming \n\nThe SDK SHOULD accept parameters with potentially large memory requirements as InputStream values, to allow the value to be streamed to the service.\n\n\n\n\n\n\n\n  Style guidelines \n\nFor services that support both a traditional Java SDK and an Android SDK, the Java SDK SHOULD be designed to be Android compatible, to minimize duplication of code.\n\nYou should follow a coding style based on the [Google Java Style Guide](https:\/\/google.github.io\/styleguide\/javaguide.html).\n\nYou should use the standard [development tools](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools) for Java to check style and code coverage.\n\n\n\n\n\n  Documentation \n\nYour SDK is not useful if your audience cannot understand how to consume it in order to do the basic operations for your service. Your SDK needs to contain the following resources to help your users:\n\n\n\n*  README.md\n*  [Contributor guidelines](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentationsdk-contributor-docs)\n*  Code Samples\n*  [Service documentation](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentation)\n\n\n\n\n\n\n\n  Distribution \n\n\n\n  Package management \n\nOfficial SDK releases MUST be published in [Maven Central](https:\/\/search.maven.org\/).\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-java"},{"document_id":"ibmcld_10817-7-1802","score":12.733645,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-4213-5899","score":12.671836,"text":"\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_04518-7-1743","score":12.483938,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-6582-8092","score":12.478347,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_02772-2964-4516","score":12.36158,"text":"\nThis can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you can get started:\n\n\n\n* API 27 or higher\n* Java 8.x\n* Android SDK Tools 26.1.1+\n* Android SDK Platform Tools 27.0.1+\n* Android Build Tools version 27.0.0+\n\n\n\n\n\n\n\n Installing the SDK \n\n\n\n1. Create an Android Studio project or open an existing project.\n2. Add the JitPack repository to your root build.gradle file.\n\nallprojects {\nrepositories {\n...\nmaven { url 'https:\/\/jitpack.io' }\n}\n}\n3. Find your application's build.gradle file. Note: Be sure to open the file for your app, not the project build.gradle file.\n\n\n\n1. Add the App ID client SDK to the dependencies section.\n\ndependencies {\ncompile group: 'com.github.ibm-cloud-security:appid-clientsdk-android:4.+'\n}\n2. In the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/appid?topic=appid-mobile-apps"},{"document_id":"ibmcld_02680-7-1762","score":11.943356,"text":"\nApp Configuration client SDK for Android \n\nApp Configuration service provides Android client SDK to integrate with your Android application that is written in Kotlin or Java programming language.\n\n\n\n Prerequisites \n\nFollowing are the prerequisites for using the App Configuration service SDK for Android:\n\n\n\n* Android API level 22 or later\n* [Android Studio](https:\/\/developer.android.com\/studio\/index.html)\n* [Gradle](https:\/\/gradle.org\/install)\n\n\n\n\n\n\n\n Integrating client SDK for Android app written in Kotlin \n\nApp Configuration service provides Android client SDK to integrate with your Android application. You can evaluate the values of your property and feature flag by integrating the SDK.\n\n\n\n1. Install the SDK by using either one of the options:\n\n\n\n* [Download](https:\/\/github.com\/IBM\/appconfiguration-android-client-sdk) and import the package to your Android studio project.\n* Get the package through Gradle by adding the:\n\n\n\n* Add App Configuration Android client SDK dependency to Project level build.gradle file.\n\nrepositories {\nmavenCentral()\n}\n* Add App Configuration Android client SDK dependency to Module level build.gradle file.\n\ndependencies {\nimplementation \"com.ibm.cloud:appconfiguration-android-sdk:0.3.1\"\n}\n\n\n\n\n\n2. Configure the AndroidManifest.xml file for internet permission.\n\n<uses-permission android:name=\"android.permission.INTERNET\"\/>\n3. Initialize the SDK.\n\nval appConfiguration = AppConfiguration.getInstance()\n\nappConfiguration.init( application,\n\"region\",\n\"guid\",\n\"apikey\")\n\n\/\/To start the configuration fetching operation, set the collectionId and environmentId in the following way.\nappConfiguration.setContext(\"collectionId\",\"environmentId\")\n\nWhere:\n\n\n\n* region - Region name where the service instance is created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android"},{"document_id":"ibmcld_02698-2493-3586","score":11.843666,"text":"\n[Android SDK](https:\/\/github.com\/IBM\/appconfiguration-android-client-sdk) <br>[Documentation](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-integrate-sdks-android) <br>[JavaScript SDK](https:\/\/github.com\/IBM\/appconfiguration-js-client-sdk) <br>[Documentation](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-javascript) <br>[React SDK](https:\/\/github.com\/IBM\/appconfiguration-react-client-sdk) <br>[Documentation](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-react) \n Admin SDK Admin SDK is designed to perform App Configuration service instance management. Use this SDK to create and manage App Configuration resources like Collections, Environments, Feature flags, and Properties. [App Configuration Admin SDK for Go](https:\/\/cloud.ibm.com\/apidocs\/app-configuration?code=go) \n\n\n\nFor more information about installation and technical concepts, see the 'readme file' document in the SDK.\n\nYou can also access these documents and download the SDKs from the App Configuration console under SDKs on the navigation menu.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-sdks"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.4306765581,"ndcg_cut_10":0.4306765581}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10852-44214-45420","score":12.180555,"text":"\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10817-1342-3184","score":11.030677,"text":"\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk\/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage\/build\/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_04518-7-1743","score":10.563192,"text":"\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https:\/\/cocoapods.org) or [Carthage](https:\/\/github.com\/Carthage\/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_07551-15747-17355","score":10.035366,"text":"\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https:\/\/github.com\/IBM\/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n\/Register iOS devices\/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_04518-1426-3052","score":9.899534,"text":"\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https:\/\/guides.cocoapods.org\/using\/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https:\/\/github.com\/Carthage\/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services\/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https:\/\/github.com\/Carthage\/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) \/\/ Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-sdk_BMSClient"},{"document_id":"ibmcld_10817-7-1802","score":9.086169,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10852-43319-44485","score":8.428553,"text":"\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_07551-14062-16080","score":8.029183,"text":"\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https:\/\/jsonpath.com\/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM\/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-push-apns"},{"document_id":"ibmcld_12332-1034-2510","score":7.864517,"text":"\nYour Go SDK should be packaged as a [Go Module](https:\/\/blog.golang.org\/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https:\/\/search.maven.org\/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https:\/\/www.npmjs.com\/) package within the [ibm-cloud](https:\/\/www.npmjs.com\/org\/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https:\/\/pypi.python.org\/) \/ [pip](https:\/\/pypi.python.org\/pypi\/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https:\/\/swift.org\/package-manager\/) \/ [CocoaPods](https:\/\/cocoapods.org\/) \/ [Carthage](https:\/\/github.com\/Carthage\/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https:\/\/github.com\/IBM\/ibm-cloud-sdk-common).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtools"},{"document_id":"ibmcld_10817-6582-8092","score":6.520601,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.530721274,"ndcg_cut_10":0.6978817289}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12334-1720-2763","score":8.758769,"text":"\nAll IBM-developed coding examples and sample applications for the service SHOULD use the SDK.\n\n\n\n\n\n Contributor documentation \n\nThe SDK MUST include documentation for developers that would like to contribute to the SDK either by opening issues or submitting pull requests.\n\nIn particular:\n\n\n\n Issue template and pull request template \n\nProvide issue and pull request templates to guide contributors on what information should be provided and what processes to follow when making contributions to the SDK.\n\n\n\n\n\n CONTRIBUTING.md \n\nProvide a CONTRIBUTING.md file in the root of the SDK repo containing the following information:\n\n\n\n* The coding style established for the SDK. This is typically a reference to an externally documented coding style for the language, with perhaps some exceptions specific to the SDK.\n* How to build the SDK\n* How to run the code style checker and use the autofix feature if available\n* How to run the unit tests and integration tests\n* How to run a single test (for debugging)\n* How to run the code coverage tooling","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentation"},{"document_id":"ibmcld_11542-5856-7635","score":8.726943,"text":"\n* Text to Speech Example\n* Natural Language Understanding Example\n* Personality Insights Example\n* Language Translator Example\n\n\n\nEach of these example code snippets is included in the Git repository under the #Usage section of the documentation:\n\n\n\n[#Usage section with sample code for the ABAP SDK for IBM Watson, using SAP NetWeaver](https:\/\/github.com\/watson-developer-cloud\/abap-sdk-nwasusage)\n\n[#Usage section with sample code for the ABAP SDK for IBM Watson, using SAP Cloud Platform ABAP Environment](https:\/\/github.com\/watson-developer-cloud\/abap-sdk-scpusage)\n\n\n\n\n\n\n\n API Reference \n\nThe API Reference is built into the open source Git repository, and is therefore hosted by GitHub Pages:\n\n\n\n* [ABAP Client Library for Watson API Reference](https:\/\/watson-developer-cloud.github.io\/abap-sdk-nwas\/).\n\n\n\n\n\n\n\n\n\n Release and Support \n\nAs the ABAP SDK is a community release, it is not updated with the same schedule as IBM-supported SDKs. It is the choice and responsibility of application developers how this Community SDK is used.\n\nThe ABAP SDK is a Community SDK for IBM Watson, created by the IBM Watson development community and SAP's ABAP development community - written by ABAPers from IBM Cloud, IBM Services, and IBM Systems.\n\nTherefore, as a community release it is not updated with the same schedule as IBM-supported SDKs, and does not include support by IBM. For more information about IBM-supported SDKs and the update policy, see [Watson SDKs Reference information](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-using-sdks).\n\nIf you have questions about the IBM Watson services or are having difficulties with using the APIs, ask a question on [Stack Overflow under tag ibm-watson-cognitive](http:\/\/stackoverflow.com\/questions\/ask?tags=ibm-watson-cognitive).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-abap-sdk-watson"},{"document_id":"ibmcld_12336-0-1003","score":8.662553,"text":"\n\n\n\n\n\n\n  Examples \n\n\n\n  SDK working examples \n\nThe SDK SHOULD contain a set of working examples for each service contained in the SDK. These working examples SHOULD provide a clear, concise example of how to use each operation within the service.\n\nThese examples SHOULD be relatively easy for users to execute, similar to test cases contained in the SDK.\n\n\n\n  Guidelines for examples \n\nThe SDK examples for a service SHOULD:\n\n\n\n*  Include a clear, concise example of how to invoke each operation\n*  Use realistic values for operation parameters and model properties which enhance the user's understanding of the operation\n*  Use consistent parameter\/property values across the various SDK languages (Go, Java, Node.js, and Python) as well as Curl; ideally, the parameter\/property values used in the examples code are defined within \"example\" fields in the service's API definition\n\n\n\nThe examples can be used to provide the example code fragments displayed in the service's API Reference docs.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-examples"},{"document_id":"ibmcld_12333-0-1273","score":8.15621,"text":"\n\n\n\n\n\n\n  Distribution \n\n\n\n  Open-source \n\nThe SDK MUST be open-source and hosted on a public GitHub repository in the [IBM organization](https:\/\/github.com\/IBM). The repository name SHOULD follow the pattern of <service>-<language>-sdk (for example, platform-services-node-sdk). The SDK SHOULD be discoverable through simple GitHub and Google searches. The SDK SHOULD use the Apache 2.0 license.\n\n\n\n\n\n  Package management \n\nThe SDK SHOULD be distributed using the most popular package management systems for the language. See [package management](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtoolsdevtools-pkg-mgmt) for the recommended package managers by language and their respective requirements.\n\n\n\n\n\n  Package dependencies \n\nThe SDK SHOULD use the common dependency management system for declaring its dependencies, including \"lock\" files wherever supported to specify checksummed versions of dependencies used in an SDK release. Dependency versions should be specified with a fixed major version to avoid incompatible changes that might occur in major version updates.\n\n\n\n\n\n  Semantic versioning \n\nThe SDK MUST use [semantic versioning](https:\/\/semver.org\/) for SDK releases (this requirement is enforced by some package management systems).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-distribution"},{"document_id":"ibmcld_10817-2884-4620","score":7.6214714,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_07549-9127-11441","score":7.552751,"text":"\nA \"Major Component\", in this context, means a major essential component (kernel, window system, and so on) of the specific operating system (if any) on which the executable work runs, or a compiler used to produce the work, or an object code interpreter used to run it.The \"Corresponding Source\" for a work in object code form means all the source code needed to generate, install, and (for an executable work) run the object code and to modify the work, including scripts to control those activities. However, it does not include the work's System Libraries, or general-purpose tools or generally available free programs which are used unmodified in performing those activities but which are not part of the work. For example, Corresponding Source includes interface definition files associated with source files for the work, and the source code for shared libraries and dynamically linked subprograms that the work is specifically designed to require, such as by intimate data communication or control flow between those subprograms and other parts of the work.The Corresponding Source need not include anything that users can regenerate automatically from other parts of the Corresponding Source.The Corresponding Source for a work in source code form is that same work.<-- <\/section \"id=\"section-en-notice-source-code\" \"> --><-- <section \"id=\"section-en-notice-permissions\" \"> --> 2. Basic Permissions All rights granted under this License are granted for the term of copyright on the Program, and are irrevocable provided the stated conditions are met. This License explicitly affirms your unlimited permission to run the unmodified Program. The output from running a covered work is covered by this License only if the output, given its content, constitutes a covered work. This License acknowledges your rights of fair use or other equivalent, as provided by copyright law.You may make, run and propagate covered works that you do not convey, without conditions so long as your license otherwise remains in force. You may convey covered works to others for the sole purpose of having them make modifications exclusively for you, or provide you with facilities for running those works, provided that you comply with the terms of this License in conveying all material for which you do not control copyright.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/event-notifications?topic=event-notifications-en-notices"},{"document_id":"ibmcld_05070-1291-3060","score":7.546151,"text":"\nAfter generating a [Service Credential](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-service-credentials), the resulting JSON document can be saved to \/.bluemix\/cos_credentials. The SDK will automatically source credentials from this file unless other credentials are explicitly set during client creation. If the cos_credentials file contains HMAC keys the client authenticates with a signature, otherwise the client uses the provided API key to authenticate with a bearer token.\n\nThe default section heading specifies a default profile and associated values for credentials. You can create more profiles in the same shared configuration file, each with its own credential information. The following example shows a configuration file with the default profile:\n\n[default]\nibm_api_key_id = <DEFAULT_IBM_API_KEY>\nibm_service_instance_id = <DEFAULT_IBM_SERVICE_INSTANCE_ID>\nibm_auth_endpoint = <DEFAULT_IBM_AUTH_ENDPOINT>\n\nIf migrating from AWS S3, you can also source credentials data from \/.aws\/credentials in the format:\n\naws_access_key_id = <DEFAULT_ACCESS_KEY_ID>\naws_secret_access_key = <DEFAULT_SECRET_ACCESS_KEY>\n\nIf both \/.bluemix\/cos_credentials and \/.aws\/credentials exist, cos_credentials takes preference.\n\n\n\n\n\n\n\n Code Examples \n\nIn your code, you must remove the angled brackets or any other excess characters that are provided here as illustration.\n\nGetting started with [Node.js](https:\/\/nodejs.org\/en\/about\/)\u2014once it's installed\u2014usually involves configuration and invocation, like in [this example from Nodejs.org](https:\/\/nodejs.org\/en\/docs\/guides\/getting-started-guide\/). We'll follow a similar model\n\n\n\n Initializing configuration \n\nconst IBM = require('ibm-cos-sdk');\n\nvar config = {\nendpoint: '<endpoint>',","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_12344-0-1245","score":7.537835,"text":"\n\n\n\n\n\n\n  Why generate SDKs? \n\n\n\n  Leverage code generation \n\nThe basic service-level elements of the SDK SHOULD be generated from the API definition.\n\nThe reasons for using SDK generation include:\n\n\n\n*  Faster time to market. Reduce the time it takes to add SDK support for new features in a service.\n*  Improved quality. Avoid \u201ccopy-and-paste\u201d and typo errors that occur in hand-written SDKs.\n*  Enforced compliance. Improve and enforce agreement with the API definition.\n*  Enforced consistency. Establish a common style for a particular language SDK across a family of APIs.\n*  Increased adoption. Generated SDKs have common style, making them easier for developers to learn.\n\n\n\n\n\n\n\n  Core SDK libraries \n\nSDKs produced with generation require a common set of capabilities, such as networking operations or authentication mechanisms. Handwritten SDKs are also welcome to leverage these common operations.\n\nCore libraries:\n\n\n\n*  [IBM go-sdk-core](https:\/\/github.com\/IBM\/go-sdk-core)\n*  [IBM java-sdk-core](https:\/\/github.com\/IBM\/java-sdk-core)\n*  [IBM node-sdk-core](https:\/\/github.com\/IBM\/node-sdk-core)\n*  [IBM python-sdk-core](https:\/\/github.com\/IBM\/python-sdk-core)\n*  [IBM swift-sdk-core](https:\/\/github.com\/IBM\/swift-sdk-core)\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-sdkgen"},{"document_id":"ibmcld_12329-0-894","score":7.454434,"text":"\n\n\n\n\n\n\n  Coding style \n\n\n\n  Coding conventions \n\nThe SDK MUST adhere to coding style that is clearly documented in the SDK CONTRIBUTING file. The SDK SHOULD adopt the coding style recommendation that is given in the appropriate language-specific section of these guidelines.\n\n\n\n\n\n  Idiomatic style \n\nThe SDK SHOULD employ the generally accepted best practices and common idioms of the specific language. The SDK SHOULD feel \"natural\" to developers with experience in that language. In particular, the JSON structure of the underlying API request and response structures SHOULD be converted to native language objects with appropriately typed member variables.\n\n\n\n\n\n  Use style checkers \n\nThe SDK SHOULD employ a code style checker to enforce the established coding style. See [style checkers](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtoolsdevtools-style-checkers).\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-coding-style"},{"document_id":"ibmcld_12334-7-2246","score":7.400228,"text":"\nDocumentation \n\n\n\n Interface documentation \n\nThe SDK MUST have accompanying documentation that clearly describes all public methods and classes of the SDK. This includes full documentation for method parameters and responses and all member variables of classes.\n\nThe interface documentation SHOULD use terminology that is appropriate for the programming language (e.g. Java objects should not be described as \"JSON\", and methods for service invocations should not be described as a \"GET \/v3\/path\/to\/the\/service\").\n\n\n\n\n\n Delivery format \n\nSDK interface documentation SHOULD be integrated into the [IBM Cloud API Reference](https:\/\/cloud.ibm.com\/apidocs) for the service, where the SDK for each language appears in a separate tab.\n\nSDK interface documentation SHOULD also be delivered in a format and location that experienced developers for a particular language \/ platform will find familiar:\n\n\n\n* Javadoc for a Java SDK\n* [TypeDoc](https:\/\/typedoc.org\/api\/index.html) for a Node SDK\n* [Sphinx](http:\/\/www.sphinx-doc.org\/en\/master\/) for a Python SDK\n* [Package](https:\/\/pkg.go.dev) for a Go SDK\n* Jazzy for a Swift SDK\n\n\n\n\n\n\n\n Tutorials and user guides \n\nTutorials and user guides for the service SHOULD provide prominent references to the SDK. This should include how the SDK can be accessed through the package management systems appropriate for each language and how this can be automated in a DevOps pipeline flow for an application using the SDK.\n\n\n\n\n\n Migration guides \n\nYour SDK SHOULD provide a migration guide to help users upgrade to the latest version of your SDK.\n\n\n\n\n\n Examples \n\nThe SDK MUST include or have accompanying examples that illustrate common usage flows involving multiple service APIs.\n\nAll IBM-developed coding examples and sample applications for the service SHOULD use the SDK.\n\n\n\n\n\n Contributor documentation \n\nThe SDK MUST include documentation for developers that would like to contribute to the SDK either by opening issues or submitting pull requests.\n\nIn particular:\n\n\n\n Issue template and pull request template \n\nProvide issue and pull request templates to guide contributors on what information should be provided and what processes to follow when making contributions to the SDK.\n\n\n\n\n\n CONTRIBUTING.md","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-documentation"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05337-28650-29915","score":7.8272653,"text":"\n1.0.0 30 March 2021 This version is the generally available release of Code Engine CLI.- Important Introduced a breaking change to Code Engine service binding functions. Service bindings that were created with releases of the CLI earlier than release 1.0.0 will no longer work after you update to the CLI 1.0.0 release. Unbind pre-existing service bindings before you update to CLI 1.0.0.<br><br><br><br> * Updated service bindings to use a new naming convention. Binding names are now autogenerated to ensure uniqueness.<br> * Updated the app unbind and job unbind commands to accept the --binding option. The --binding option replaces the --service-instance option.<br> * Renamed the service binding VCAP_SERVICES environment variable, which is injected into running containers, to CE_SERVICES.<br> * Updated application and job service bindings to support multiple service bindings to the same service instance.<br> * Updated support for service bindings such that service bindings that are created without existing service credentials always generate a new, unique service credential.<br> * Added more information to output for bad request errors encountered by the CLI.<br><br><br> \n 0.6.3 26 March 2021 <br><br> * Updated translations for the CLI.<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cli_versions"},{"document_id":"ibmcld_04702-35310-37044","score":7.818473,"text":"\nibmcloud fn rule update RULE_NAME TRIGGER_NAME ACTION_NAME\n\n\n\n Example \n\nibmcloud fn rule update myrule mytrigger myaction\n\n\n\n\n\n\n\n\n\n SDK command \n\nInstall SDK components, such as docker, iOS, and bashauto.\n\nTo see CLI help for the sdk command, run ibmcloud fn sdk.\n\n\n\n ibmcloud fn sdk install \n\nInstall an SDK.\n\nibmcloud fn sdk install COMPONENT [--limit NUMBER_OF_TRIGGERS]\n\n\n\n Command options \n\nCOMPONENT\n: The SDK component, such as docker, iOS, and bashauto. This value is required.\n\n--stdout, --s\n: Prints the bash command results to STDOUT. This flag is optional.\n\n\n\n\n\n Example \n\nibmcloud fn sdk install docker\n\n\n\n\n\n\n\n\n\n Service commands \n\nService commands bind and unbind service credentials to an action or package.\n\nTo see CLI help for the service command, run ibmcloud fn service.\n\nIf you receive the error Unable to refresh user access token: CloudFoundry API endpoint is not set when running the service command, run ibmcloud target --cf.\n\n\n\n ibmcloud fn service bind \n\nBind service credentials to an action or package.\n\nibmcloud fn service bind SERVICE PACKAGE_or_ACTION_NAME [--instance SERVICE_INSTANCE] [--keyname SERVICE_KEY]\n\n\n\n Command options \n\nSERVICE\n: The name of the service.\n\nPACKAGE_or_ACTION_NAME\n: The name of the package or action to bind the credentials to.\n\n--instance SERVICE_INSTANCE\n: The service instance name.\n\n--keyname SERVICE_KEY\n: The name of the service KEY credentials to bind.\n\n\n\n\n\n Example \n\nibmcloud fn service bind cloudant hello --instance CLOUDANT_SERVICE\n\n\n\n\n\n\n\n ibmcloud fn service unbind \n\nUnbind service credentials from an action or package.\n\nibmcloud fn service unbind SERVICE PACKAGE_or_ACTION_NAME\n\n\n\n Command options \n\nSERVICE\n: The name of the service.\n\nPACKAGE_or_ACTION_NAME","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-functions-cli-plugin?topic=cloud-functions-cli-plugin-functions-cli"},{"document_id":"ibmcld_04348-35264-36998","score":7.818473,"text":"\nibmcloud fn rule update RULE_NAME TRIGGER_NAME ACTION_NAME\n\n\n\n Example \n\nibmcloud fn rule update myrule mytrigger myaction\n\n\n\n\n\n\n\n\n\n SDK command \n\nInstall SDK components, such as docker, iOS, and bashauto.\n\nTo see CLI help for the sdk command, run ibmcloud fn sdk.\n\n\n\n ibmcloud fn sdk install \n\nInstall an SDK.\n\nibmcloud fn sdk install COMPONENT [--limit NUMBER_OF_TRIGGERS]\n\n\n\n Command options \n\nCOMPONENT\n: The SDK component, such as docker, iOS, and bashauto. This value is required.\n\n--stdout, --s\n: Prints the bash command results to STDOUT. This flag is optional.\n\n\n\n\n\n Example \n\nibmcloud fn sdk install docker\n\n\n\n\n\n\n\n\n\n Service commands \n\nService commands bind and unbind service credentials to an action or package.\n\nTo see CLI help for the service command, run ibmcloud fn service.\n\nIf you receive the error Unable to refresh user access token: CloudFoundry API endpoint is not set when running the service command, run ibmcloud target --cf.\n\n\n\n ibmcloud fn service bind \n\nBind service credentials to an action or package.\n\nibmcloud fn service bind SERVICE PACKAGE_or_ACTION_NAME [--instance SERVICE_INSTANCE] [--keyname SERVICE_KEY]\n\n\n\n Command options \n\nSERVICE\n: The name of the service.\n\nPACKAGE_or_ACTION_NAME\n: The name of the package or action to bind the credentials to.\n\n--instance SERVICE_INSTANCE\n: The service instance name.\n\n--keyname SERVICE_KEY\n: The name of the service KEY credentials to bind.\n\n\n\n\n\n Example \n\nibmcloud fn service bind cloudant hello --instance CLOUDANT_SERVICE\n\n\n\n\n\n\n\n ibmcloud fn service unbind \n\nUnbind service credentials from an action or package.\n\nibmcloud fn service unbind SERVICE PACKAGE_or_ACTION_NAME\n\n\n\n Command options \n\nSERVICE\n: The name of the service.\n\nPACKAGE_or_ACTION_NAME","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-functions-cli"},{"document_id":"ibmcld_10717-35293-37027","score":7.818473,"text":"\nibmcloud fn rule update RULE_NAME TRIGGER_NAME ACTION_NAME\n\n\n\n Example \n\nibmcloud fn rule update myrule mytrigger myaction\n\n\n\n\n\n\n\n\n\n SDK command \n\nInstall SDK components, such as docker, iOS, and bashauto.\n\nTo see CLI help for the sdk command, run ibmcloud fn sdk.\n\n\n\n ibmcloud fn sdk install \n\nInstall an SDK.\n\nibmcloud fn sdk install COMPONENT [--limit NUMBER_OF_TRIGGERS]\n\n\n\n Command options \n\nCOMPONENT\n: The SDK component, such as docker, iOS, and bashauto. This value is required.\n\n--stdout, --s\n: Prints the bash command results to STDOUT. This flag is optional.\n\n\n\n\n\n Example \n\nibmcloud fn sdk install docker\n\n\n\n\n\n\n\n\n\n Service commands \n\nService commands bind and unbind service credentials to an action or package.\n\nTo see CLI help for the service command, run ibmcloud fn service.\n\nIf you receive the error Unable to refresh user access token: CloudFoundry API endpoint is not set when running the service command, run ibmcloud target --cf.\n\n\n\n ibmcloud fn service bind \n\nBind service credentials to an action or package.\n\nibmcloud fn service bind SERVICE PACKAGE_or_ACTION_NAME [--instance SERVICE_INSTANCE] [--keyname SERVICE_KEY]\n\n\n\n Command options \n\nSERVICE\n: The name of the service.\n\nPACKAGE_or_ACTION_NAME\n: The name of the package or action to bind the credentials to.\n\n--instance SERVICE_INSTANCE\n: The service instance name.\n\n--keyname SERVICE_KEY\n: The name of the service KEY credentials to bind.\n\n\n\n\n\n Example \n\nibmcloud fn service bind cloudant hello --instance CLOUDANT_SERVICE\n\n\n\n\n\n\n\n ibmcloud fn service unbind \n\nUnbind service credentials from an action or package.\n\nibmcloud fn service unbind SERVICE PACKAGE_or_ACTION_NAME\n\n\n\n Command options \n\nSERVICE\n: The name of the service.\n\nPACKAGE_or_ACTION_NAME","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=cloud-functions-cli-plugin-functions-cli"},{"document_id":"ibmcld_05386-7-2149","score":7.6441298,"text":"\nLimits and quotas for Code Engine \n\nThe following sections provide technical details about the IBM Cloud\u00ae Code Engine limitation and quota settings.\n\nHow does my resource allocation effect my project quotas and billing?\n\nFrom the console, you can view information about your current Code Engine resource allocation from your project overview page. If you want to display information about the allocated memory and vCPU values based on what you configured for each specific application or job, then view the listing of your applications or jobs in your project. With the CLI, you can also get information about your current resource allocation usage for the project with the [project get](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-project-get) command.\n\nWith Code Engine, you pay for only the resources that you use based on the configured memory and vCPU that your workloads consume, and any incoming HTTP calls. If your app scales to zero or your job or build isn't running, you are not consuming resources, and so you are not charged. To host all your applications and jobs, Code Engine deploys and manages the necessary infrastructure for you. However, while you are not billed for this infrastructure, it does count toward the project quotas. For more information about quotas, see the following tables.\n\nThe use of ephemeral storage is now bounded by memory. The ephemeral storage in Code Engine cannot exceed the default value of 0.4 GB (400 MB) or the configured value for memory. If you need more than the default for ephemeral storage, you must increase your memory according to the valid combinations of vCPU and memory.\n\nSee [Supported memory and CPU combinations](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-mem-cpu-combo) for more information about the relationship between ephemeral storage and memory.\n\n\n\n Application defaults and limits \n\nThe following table lists the limits for applications.\n\n\n\nApplication limits\n\n Category Default Maximum value Need to extend the maximum? \n\n CPU 1.0 12.0 [Contact IBM support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case&interface=ui)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-limits"},{"document_id":"ibmcld_08413-1647-3709","score":7.5087743,"text":"\n: A CLI plug-in working with IBM Cloud CLI for you to initialize service instances. Depending on whether recovery crypto units are assigned to your instance, the plug-in provides two ways for instance initialization: by using recovery crypto units and by using key part files.\n\nOperational crypto unit\n: Each service instance is composed of multiple operational crypto units. The operational crypto units are located in different availability zones of the same region for high availability. They are used to manage encryption keys and perform cryptographic operations. The number of crypto units that you specify when you create your instance is the number of operational crypto units.\n\nRecovery crypto unit\n: The purpose of recovery crypto units is to generate a random master key value and to save a backup copy of the master key value. You can use recovery crypto units to load the master key and restore the master key when it is destroyed or lost.\n\nCurrently, recovery crypto units are enabled only in the region of Dallas (us-south) and Washington DC (us-east). If you create your instance in either of the two regions, two recovery crypto units are automatically assigned to your instance without extra costs: one is in the us-south; the other is in the us-east.\n\nIf smart cards are used to load the master key, the recovery crypto units are not applicable and can be ignored. The backup of the master key relies on the backup of the smart cards in that case.\n\nFailover crypto unit\n: Failover crypto units back up the operational crypto units in another region, which includes keystores that store encryption keys. When a regional disaster occurs, you can use failover crypto units to ensure production workloads and avoid data loss.\n\nCurrently, failover crypto units are available only in the region of Dallas (us-south) and Washington DC (us-east). If you create your instance in either of the two regions, you can choose whether to enable the failover crypto units with [extra charges](https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-faq-pricing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-architecture-workload-isolation"},{"document_id":"ibmcld_11408-2439-3664","score":7.3884206,"text":"\nFor detailed usage and billing information, you can refer to the part number in your invoice. The part numbers in the invoice represent the charge unit. Refer to the following table to view the part numbers and its corresponding description.\n\n\n\n Part number Description \n\n SOS_VIRTUAL_PROCESSOR_CORE_HOURS Scale out shared uncapped processor per core-hour \n SOD_VIRTUAL_PROCESSOR_CORE_HOURS Scale out dedicated processor per core-hour \n\n\n\n| MHU_GIGABYTE_HOURS | High use RAM (>64 Gb per core) gigabyte-hour | | TIER_ONE_STORAGE_GIGABYTE_HOURS | Tier-1 storage gigabyte-hour | | TIER_THREE_STORAGE_GIGABYTE_HOURS | Tier-3 storage gigabyte-hour | | AIX_SMALL_APPLICATION_INSTANCE_HOURS | AIX scale out license per core-hour | | AIX_MEDIUM_APPLICATION_INSTANCE_HOURS | AIX enterprise license per core-hour | | IBMI_OS_PTEN_APPLICATION_INSTANCE_HOURS | IBM i OS P10 license per core-hour | | IBMI_OS_PTHIRTY_APPLICATION_INSTANCE_HOURS | IBM i OS P30 license per core-hour | | IBMI_LPP_PTEN_APPLICATION_INSTANCE_HOURS | IBM i LPP P10 license per core-hour | | IBMI_LPP_PTHIRTY_APPLICATION_INSTANCE_HOURS | IBM i LPP P30 license per core-hour | | SOC_VIRTUAL_PROCESSOR_CORE_HOURS | Scale out shared capped processor per core-hour |","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_00099-7-1786","score":7.1668468,"text":"\nUsing the Python SDK \n\nThe IBM Analytics Engine SDK can be installed by installing the library iaesdk from the Python Package Index.\n\nType the following command into a command line:\n\npip install --upgrade \"iaesdk>=1.1.1\"\n\nSource code can be found at [GitHub](https:\/\/github.com\/IBM\/ibm-iae-python-sdk). The iaesdk library provides complete access to the IBM Analytics Engine API.\n\nYou need to provide the service endpoints and the API key when you create a IBM Analytics Engine service resource or a low-level client.\n\nThe service instance ID is also referred to as a instance GUID. You can retrieve the service instance ID when you create service credentials or through the CLI. See [Retrieving service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverless).\n\nTo use the iaesdk library, you need the following values:\n\n\n\n* IAM_API_KEY: The API key generated when creating the service credentials. You can retrieve by viewing the service credentials on the [IBM Cloud dashboard](https:\/\/cloud.ibm.com\/resources).\n* instance_guid: The value in resource_instance_id generated when the service credentials are created. You can retrieve by viewing the service credentials on the [IBM Cloud dashboard](https:\/\/cloud.ibm.com\/resources).\n* IAE_ENDPOINT_URL: The service endpoint URL including the https:\/\/ protocol. See [Service endpoints](https:\/\/cloud.ibm.com\/apidocs\/ibm-analytics-engineservice-endpoints).\n\n\n\n\n\n Code samples using iaesdk \n\nGetting started with the Python SDK after you have installed it, involves sourcing credentials to the IBM Analytics Engine service, invoking the service and then issuing different cluster commands as shown in the following sample code snippets. The code examples are written for Python 3.7.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-using-python-sdk-serverless"},{"document_id":"ibmcld_05442-7-1697","score":7.0602098,"text":"\nWorking with service bindings to integrate IBM Cloud services with Code Engine \n\nFind out how to integrate an IBM Cloud service instance to resources in an IBM Cloud\u00ae Code Engine project by using service binding.\n\nService bindings provide applications and jobs access to IBM Cloud services.\n\nIf you are using the CLI to work with service bindings, and you have service bindings that were created with a version of the CLI before CLI 1.27.0, see [considerations](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-service-bindingconsiderations-previmpl-binding) for information about replacing service bindings that use the previous implementation. To take advantage of the latest enhancements of the CLI, update to the [latest IBM Cloud Code Engine CLI version](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cli_versions).\n\n\n\n What is IBM Cloud Code Engine service binding? \n\nBinding a service instance to a Code Engine application or job automatically adds credentials for a service instance to the environment variables of the container for your application or the job, or the code bundle of your Function. To see the contents of a service credential, go to the dashboard for the service instance and locate the Service credentials page. Service credentials are shown as a JSON object, which, when bound, are added to the application or job environment.\n\n{\n\"apikey\": \"xxxxxxx\",\n\"endpoints\": \"https:\/\/control.cloud-object-storage.cloud.ibm.com\/v2\/endpoints\",\n\"iam_apikey_description\": \"Auto-generated for key abcdabcd-abcd-4d8c-78cf-abcdabcdabcd\",\n\"iam_apikey_name\": \"my-object-storage-codeengine-credential\",\n\"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-service-binding"},{"document_id":"ibmcld_00097-7-1769","score":7.0201845,"text":"\nUsing the Go SDK \n\nThe IBM Analytics Engine Go SDK allows you to interact programmatically with the IBM Analytics Engine service API for serverless instances.\n\nYou can get the source code for the SDK from GitHub. See [ ibm-iae-go-sdk](https:\/\/github.com\/IBM\/ibm-iae-go-sdk). The iaesdk library provides complete access to the IBM Analytics Engine API.\n\n\n\n Getting the SDK \n\nYou need to download and install the SDK to use it in your Go applications. You can do this by entering the following command:\n\ngo get -u github.com\/IBM\/ibm-iae-go-sdk\n\nIf your application uses Go modules, you can add a suitable import to your Go application, and run:\n\ngo mod tidy\n\n\n\n\n\n Importing packages \n\nAfter you have installed the SDK, you need to import the SDK packages that you want to use in your Go applications.\n\nFor example:\n\nimport (\n\"github.com\/IBM\/go-sdk-core\/v3\/core\"\n\"github.com\/IBM\/ibm-iae-go-sdk\/ibmanalyticsengineapiv3\"\n)\n\n\n\n\n\n Creating a client and sourcing credentials \n\nWhen you connect to IBM Analytics Engine, a client is created and configured using the credential information (API key and service instance ID) that you provide. If you don't provide this information manually, these credentials can be sourced from a credentials file or from environment variables.\n\nYou can retrieve the service instance ID when you create service credentials or through the CLI. See [Retrieving service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverless).\n\nTo use the IBM Analytics Engine Go SDK, you need the following values:\n\n\n\n* IAM_API_KEY: The API key generated when creating the service credentials. You can retrieve by viewing the service credentials on the [IBM Cloud dashboard](https:\/\/cloud.ibm.com\/resources).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-using-go-serverless"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13455-24911-26512","score":9.3561125,"text":"\n\"content-type\": \"audio\/l16;rate=22050\",\n\"interim_results\": true\n}\n<binary audio data>\n{\n\"action\": \"stop\"\n}\n* The service responds:\n\n{\"results\": [{\"alternatives\": {\"transcript\": \"name \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name may \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name may flour \"}],\n\"final\": false}], \"result_index\": 0}\n{\"results\": [{\"alternatives\": {\"transcript\": \"name the mayflower \",\n\"confidence\": 0.91}], \"final\": true}], \"result_index\": 0}\n{\"state\":\"listening\"}\n\n\n\n\n\n\n\n\n\n WebSocket return codes \n\nThe service can send the following return codes to the client over the WebSocket connection:\n\n\n\n* 1000 indicates normal closure of the connection, meaning that the purpose for which the connection was established has been fulfilled.\n* 1002 indicates that the service is closing the connection due to a protocol error.\n* 1006 indicates that the connection closed abnormally.\n* 1009 indicates that the frame size exceeded the 4 MB limit.\n* 1011 indicates that the service is terminating the connection because it encountered an unexpected condition that prevents it from fulfilling the request.\n\n\n\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_10817-6582-8092","score":8.996891,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10863-7246-8495","score":8.777569,"text":"\n\/\/ returning the result here, makes sure that the top-most promise, we returned in main() returns the combined results of all\n\/\/ chained action invokes\n\n\/\/ since the result needs to be a valid JSON object, we cannot directly return the array, so we wrap it\nreturn {\naction_results: chained_action_results\n};\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\nconsole.log('Custom SEQUENCE with openwhisk-node-js-sdk FAILED');\n\n\/\/ This last throw is absolutely important to make the top-most promise, which we initially returned at the\n\/\/ top of the main() function REJECTS with the given error. If we did not throw here, it would still RESOLVE\n\/\/ even though the code herein failed.\nthrow error;\n});\n}\nShow more\n6. Click Save.\n7. Test your action by clicking Invoke and waiting for the following output to display.\n\nExample output\n\nResults:\n{\n\"action_results\": [\n{\n\"cos_message\": \"SUCCESS\"\n},\n{\n\"cloudant_result\": \"SUCCESS\"\n},\n{\n\"cos_message\": \"SUCCESS\"\n}\n]\n}\n\nLogs:\n[\n\"2020-04-17T04:31:20.965176Z stdout: Building custom sequence, using openwhisk node-js SDK...\",\n\"2020-04-17T04:31:31.670466Z stdout: Result from cos-access {\"cos_message\":\"SUCCESS\"}\",\n\"2020-04-17T04:31:31.670501Z stdout: Now invoking db-access...\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_10863-6347-7636","score":8.281031,"text":"\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\/\/ IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {\nconsole.log('Result from db-access ' + JSON.stringify(result));\n\n\/\/ storing result\nchained_action_results.push(result);\n\nconsole.log('Now invoking cos-access...');\n\nreturn ow.actions.invoke({\nname: 'action-tutorial\/cos-access',\nblocking: true,\nresult: true,\nparams: {}\n});\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));\n\/\/ IMPORTANT! Re-throw the error, to avoid following .then() block to be executed!\nthrow error;\n})\n.then((result) => {\nconsole.log('Result from cos-access ' + JSON.stringify(result));\n\n\/\/ storing result\nchained_action_results.push(result);\n\nconsole.log('Custom SEQUENCE with openwhisk-node-js-sdk completed.');\n\n\/\/ returning the result here, makes sure that the top-most promise, we returned in main() returns the combined results of all\n\/\/ chained action invokes\n\n\/\/ since the result needs to be a valid JSON object, we cannot directly return the array, so we wrap it\nreturn {\naction_results: chained_action_results\n};\n})\n.catch((error) => {\nconsole.log('An error occurred! ' + JSON.stringify(error));","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-tutorial_action"},{"document_id":"ibmcld_13455-26115-26611","score":8.270065,"text":"\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13790-12066-13970","score":8.199751,"text":"\nif (typeof evt.data === string) {\nmessages += evt.data;\n} else {\nconsole.log('Received ' + evt.data.size() + ' binary bytes');\naudioStream += evt.data;\n}\n}\n\nfunction onClose(evt) {\n\/\/ The service's response is complete.\n}\n\n\n\n\n\n WebSocket return codes \n\nThe service can send the following return codes to the client over the WebSocket connection:\n\n\n\n* 1000 indicates normal closure of the connection, meaning that the purpose for which the connection was established has been fulfilled.\n* 1002 indicates that the service is closing the connection due to a protocol error.\n* 1006 indicates that the connection closed abnormally.\n* 1009 indicates that the frame size exceeded the 4 MB limit.\n* 1011 indicates that the service is terminating the connection because it encountered an unexpected condition that prevents it from fulfilling the request, such as an invalid argument. The return code can also indicate that the input text was too large.\n\n\n\nIf the socket closes with an error, the service sends the client an informative message of the form {\"error\": \"Specific error message\"} before closing. The service can also send non-fatal warning messages for unknown parameters. For more information about WebSocket return codes, see the Internet Engineering Task Force (IETF) [Request for Comments (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes.\n\n\n\n Example error and warning messages \n\nThe following examples show error responses. They include a JSON text message and a formatted message from the client's onClose() callback method. The formatted messages begin with the boolean true because the connection is closed. They also include the WebSocket error code that caused the closure.\n\n\n\n* This example shows error messages for an invalid argument for the accept parameter:\n\n{\n\"error\": \"Unsupported mimetype.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13429-166159-168045","score":8.184104,"text":"\nNew UK English and Arabic models\n: The service supports more languages with its transcription models: en-UK_BroadbandModel and en-UK_NarrowbandModel for UK English, and ar-AR_BroadbandModel for Modern Standard Arabic. For more information, see [Previous-generation languages and models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-models).\n\nNew session_closed field for session-based methods\n: In the JSON responses that it returns for errors with session-based methods, the service now also includes a new session_closed field. The field is set to true if the session is closed as a result of the error. For more information about possible return codes for any method, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nHTTP platform timeout no longer applies\n: HTTP recognition requests are no longer subject to a 10-minute platform timeout. The service now keeps the connection alive by sending a space character in the response JSON object every 20 seconds as long as recognition is ongoing. For more information, see [Timeouts](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtimeouts).\n\nRate limiting with curl command no longer needed\n: When you use the curl command to transcribe audio with the service, you no longer need to use the --limit-rate option to transfer data at a rate no faster than 40,000 bytes per second.\n\nChanges to HTTP error codes\n: The service no longer returns HTTP status code 490 for the session-based HTTP methods GET \/v1\/sessions\/{session_id}\/observe_result and POST \/v1\/sessions\/{session_id}\/recognize. The service now responds with HTTP status code 400 instead.\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile SDKs are available for the speech services. The SDKs enable mobile applications to interact with both the Speech to Text and Text to Speech services.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_12330-3469-4959","score":8.044806,"text":"\nThis is to allow values that may have been returned from a newer version of the service to be supplied on subsequent method invocations.\n\n\n\n\n\n Retry \n\nThe SDK MAY provide an automated retry mechanism provided that the user can specify:\n\n\n\n* The maximum number of retry attempts, including zero.\n* The minimum and maximum time interval between retry attempts.\n* The HTTP status codes or error classes that should be retried.\n\n\n\nThe retry mechanism should respect a \"retry-after\" response header if one is returned from the service.\n\n\n\n\n\n Logging \n\nThe SDK MAY provide a logging mechanism provided that the user can specify a logging level, such as \"error\", \"warning\", \"informational\", or \"verbose\" that determines the frequency and volume of log entries.\n\nThe SDK logging mechanism SHOULD employ the common logging framework for the language.\n\n\n\n\n\n Centralize common features \n\nThe SDK SHOULD minimize the developer burden for common tasks such as authentication, and expose service versioning in a highly consumable fashion. In particular, these aspects are generally best provided as methods on a client object rather than being exposed on each method of the SDK.\n\n\n\n\n\n Tests \n\nThe SDK SHOULD include both unit and integration tests. The SDK SHOULD use a test coverage tool to measure code coverage and establish a coverage target (recommended > 80%) to be achieved for SDK releases. See [code coverage](https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-devtoolsdevtools-codecov).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-content"},{"document_id":"ibmcld_09853-9612-11616","score":7.971098,"text":"\nThis return code was added at version 9.0.3 of IBM MQ, clients that are older than version 9.0.3 will not recognize this return code and so are likely to return MQRC_UNEXPECTED_ERROR (2195) instead.\n\nThe following features have been disabled:\n\n\n\n* The following queue manager attributes: CONNAUTH, CHADEXIT, CLWLEXIT, CLWLDATA, SSLCRYP, SSLKEYR\n* Authentication information objects of type IDPWOS & IDPWLDAP\n* The following channel attributes: MSGEXIT, MSGDATA, SCYEXIT, SCYDATA, SENDEXIT, SENDDATA, RCVEXIT, RCVDATA\n* Listener objects.\n* Service objects. Note: You can start or stop an existing service object.\n* Process objects.\n* The following queue attributes: PROCESS\n* COMMINFO objects.\n\n\n\n\n\n\n\n\n\n MQRC_MAX_CONNS_LIMIT_REACHED (2025) when attempting to connect to a queue manager \n\nWhile attempting to connect a client application or queue manager to your IBM MQ on Cloud queue manager you receive a return code of MQRC_MAX_CONNS_LIMIT_REACHED (2025) and the client cannot connect.\n\nAdditionally, an error message is outputted with title AMQ9694E: Program cannot connect because connection limit reached.\n\n\n\n Explanation \n\nIBM MQ on Cloud applies limits to queue managers resources based on size. The values of each limit, and what are limited, are detailed in the information about each queue manager size when you create a new queue manager.\n\nOne of the limits applied to the queue manager is the number of concurrent client connections, this applies to both client applications and client queue managers. If you attempt to exceed the number of allowed connections your client application is blocked with the return code MQRC_MAX_CONNS_LIMIT_REACHED (2025) and an AMQ9694E error message is printed in the queue manager logs.\n\nBecause JMS uses two client connections to pass messages you need to be aware that if your queue manager connection limit is 10 you can only connect 5 JMS clients to your queue manager before reaching the connection limit.\n\n\n\n\n\n Solution \n\nTo resolve this problem either:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/mqcloud?topic=mqcloud-mqoc_common_problems"},{"document_id":"ibmcld_12335-0-917","score":7.7810163,"text":"\n\n\n\n\n\n\n  Errors \n\n\n\n  Error delivery \n\nSDK methods MUST surface errors to the caller in the manner that is idiomatic for the particular language. For example, a Go SDK should return an error value from the method, but a Java SDK should raise an Exception.\n\n\n\n\n\n  Error content \n\nWhen an SDK method encounters an error, it MUST capture all relevant information about the error and return it in the error structure that is returned to the caller. Relevant information includes the entire contents of the error response and all response headers. The SDK documentation MUST clearly describe how this information is returned and how it can be accessed by the calling program.\n\nErrors that are generated within the SDK MUST give a clear and specific description of the problem. For example, if a method parameter failed a validation, the message should state which parameter is invalid and the reason it is invalid.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sdk-handbook?topic=sdk-handbook-errors"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"1065ea5ad1ae2b90e6fce67d851a7a66<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10817-6582-8092","score":16.696821,"text":"\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http:\/\/localhost:8080\"\n\nIn this example, you use an installation that is running at http:\/\/localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https:\/\/us-south.functions.cloud.ibm.com](https:\/\/us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n\/\/ create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n\/\/ create an NSURLSession that uses the trusting delegate","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-7-1802","score":15.411238,"text":"\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https:\/\/github.com\/apache\/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10817-2884-4620","score":15.154612,"text":"\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https:\/\/github.com\/apache\/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in \/Library\/Developer\/Xcode\/DerivedData\/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_mobile_sdk"},{"document_id":"ibmcld_10818-3433-5196","score":14.834714,"text":"\nInstalling from the Cloud Functions CLI \n\nInstall the Natural Language Classifier package from the CLI. Be sure to [install the Cloud Functions plug-in for the IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-cli_install) first.\n\nTo install the Natural Language Classifier package, run the following command.\n\n\n\n1. Clone the Natural Language Classifier package repo.\n\ngit clone https:\/\/github.com\/watson-developer-cloud\/openwhisk-sdk\n2. Deploy the package.\n\nibmcloud fn deploy -m openwhisk-sdk\/packages\/natural-language-classifier-v1\/manifest.yaml\n3. Verify that the package is added to your package list.\n\nibmcloud fn package list\n\nExample output\n\npackages\n\/myOrg_mySpace\/natural-language-classifier-v1 private\n4. Bind the credentials from the Natural Language Classifier instance you created to the package.\n\nibmcloud fn service bind natural_language_classifier natural-language-classifier-v1\n\nDepending on the region where you created the service instance, the service instance might be named differently because it is an IAM service. If the command fails, use the following service name for the bind command.\n\nibmcloud fn service bind natural-language-classifier natural-language-classifier-v1\n\nExample output\n\nCredentials 'Credentials-1' from 'natural_language_classifier' service instance 'Watson Natural Language Classifier' bound to 'natural-language-classifier-v1'.\n5. Verify that the package is configured with your Natural Language Classifier service instance credentials.\n\nibmcloud fn package get natural-language-classifier-v1 parameters\n\nExample output\n\nok: got package natural-language-classifier-v1, displaying field parameters\n[\n{\n\"key\": \"__bx_creds\",\n\"value\": {\n\"natural_language_classifier\": {\n\"credentials\": \"Credentials-1\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_natlang_classifier"},{"document_id":"ibmcld_10725-7-1914","score":14.4733095,"text":"\nHow Cloud Functions works \n\nIBM Cloud\u00ae Functions service is an event-driven compute platform, also referred to as Serverless computing, or as Function as a Service (FaaS), that runs code in response to events or direct invocations.\n\n\n\n Cloud Functions terminology \n\nLearn the basic concepts of the technology behind Cloud Functions. Then, test your knowledge and [!take a quiz](https:\/\/quizzes.12dekrh4l1b4.us-south.codeengine.appdomain.cloud\/functions\/terms_quiz\/quiz.php)\n\n\n\nTable 1. Cloud Functions Terms\n\n Term Description \n\n Namespace [Namespaces](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-namespaces) contain Cloud Functions entities, such as actions and triggers, and belong to a resource group. You can let users access your Cloud Functions entities by granting them access to the namespace. \n Action An [action](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-actions) is a piece of code that performs one specific task. An action can be written in the language of your choice, such as small snippets of JavaScript or Swift code or custom binary code embedded in a Docker container. You provide your action to Cloud Functions either as source code or a Docker image. An action performs work when it is directly invoked by using the Cloud Functions API, CLI, or iOS SDK. An action can also automatically respond to events from IBM Cloud services and third-party services by using a trigger. \n Sequence A set of actions can be chained together into a [sequence](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sequences) without having to write any code. A sequence is a chain of actions, invoked in order, where the output of one action is passed as input to the next action. By creating a sequence, you can combine existing actions together for quick and easy reuse. A sequence can then be invoked just like an action, through a REST API or automatically in response to events.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-about"},{"document_id":"ibmcld_10820-21590-23317","score":14.336445,"text":"\n* For batch requests, each object change is handled individually and the trigger is fired for each successful change event.\n* All characters are permitted in an object key except for ASCII control character NUL.\n* Naming limitations for Cloud Functions triggers can be found on the [System details and limits](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-limitslimits_fullnames) page.\n\n\n\n\n\n\n\n\n\n\n\n Configuring the IBM Cloud Object Storage package \n\nAfter you have [created an IBM Cloud Object Storage service instance](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-gs-devgs-dev-provision) and [created at least one bucket](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storagegs-create-buckets), you can install the IBM Cloud Object Storage package into your namespace to work with your buckets and objects.\n\nThe installable IBM Cloud Object Storage package deploys a set of pre-built actions that you can use to work with your IBM Cloud Object Storage buckets and objects. These actions are executed in either Node.js or Python. You can select a runtime when you install the package. If you want to use a different runtime, you can use the [COS SDK](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-sdk-gs). You can also [build your own actions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-actions) or [web actions](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-actions_web) to respond to the trigger.\n\nFor a list of the actions in the cloud-object-storage package, see [Available entities](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_actions).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorage"},{"document_id":"ibmcld_10852-55987-57267","score":14.270289,"text":"\n* [Installing from the Cloud Functions console](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_text_to_speechtexttospeech_ui)\n* [Using the Text to Speech package](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_text_to_speechusage_texttospeech)\n\n\n\n[Discovery](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_discoverypkg_discovery)\n\n\n\n* [Creating a Discovery service instance](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_discoveryservice_instance_discovery)\n* [Installing the Discovery package](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_discoveryinstall_discovery)\n\n\n\n* [Installing from the Cloud Functions CLI](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_discoverydiscovery_cli)\n* [Installing from the Cloud Functions console](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_discoverydiscovery_ui)\n\n\n\n* [Using the Discovery package](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_discoveryusage_discovery)\n\n\n\n\n\n\n\n\n\n Setting up an automated tool chain \n\n[Deploying entities with a manifest file](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-deploydeploy)\n\n\n\n* [Creating the Hello World API example](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-deploydeploy_helloworld_example)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-sitemap"},{"document_id":"ibmcld_10835-32519-34249","score":14.264672,"text":"\nCloud Functions has a size limit for the app code, see maximum codeSize described in the [Action Limits](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-limitslimits_actions). However, you can install large packages and dependencies into a custom Docker image and deploy it with your app code when you create an action. You can then import the packages at run time.\n\nIn this example, install large Python packages such as matplotlib and seaborn to build a Cloud Functions web action that generates a PNG file of a joint plot with seaborn.\n\nBefore you begin\n\n\n\n* Review the packages that are included with the [Python runtime](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-runtimesopenwhisk_ref_python_environments) to see whether a dependency of your app is already included with the runtime. If your dependency is not included, you must package it with your app.\n* The following steps assume that you are running the commands on a Linux-based distribution on a processor with AMD64-based architecture.\n\n\n\nOnly public Docker images are supported.\n\nPackage the app in a custom Docker image by completing the following steps.\n\n\n\n1. Create a directory that you can use to create your Dockerfile. In this example, a functions directory is created on the desktop. After you create the functions directory, cd to it.\n\ncd desktop; mkdir functions; cd functions\n2. Create a [Dockerfile ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/adc643f3bedeea02b638bc1c34732852dcb40a45\/icons\/launch-glyph.svg)](https:\/\/docs.docker.com\/engine\/reference\/builder\/) in your functions directory.\n\ntouch Dockerfile\n3. Use vim to edit the Dockerfile file. Enter the names of the pip modules and versions you want to install.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-prep"},{"document_id":"ibmcld_02683-7-1658","score":14.224763,"text":"\nApp Configuration server SDK for Java \n\nApp Configuration service provides SDKs to integrate with your applications, microservices, and distributed environments.\n\n\n\n Integrating server SDK for Java \n\nApp Configuration service provides SDK to integrate with your Java applications. You can evaluate the values of your feature flag by integrating the App Configuration SDK.\n\n\n\n1. Install the SDK in one of the following ways.\n\nUsing Maven\n\n<dependency>\n<groupId>com.ibm.cloud<\/groupId>\n<artifactId>appconfiguration-java-sdk<\/artifactId>\n<version>0.3.3<\/version>\n<\/dependency>\n\nGet the package through Gradle by adding:\n\nimplementation group: 'com.ibm.cloud', name: 'appconfiguration-java-sdk', version: '0.3.3'\n2. In your Java microservice or application, include the SDK with:\n\nimport com.ibm.cloud.appconfiguration.sdk.AppConfiguration;\n3. Initialize the SDK to connect with your App Configuration service instance.\n\nString region = AppConfiguration.REGION_US_SOUTH;\nString guid = \"guid\";\nString apikey = \"apikey\";\n\nString collectionId = \"airlines-webapp\";\nString environmentId = \"dev\";\n\nAppConfiguration appConfigClient = AppConfiguration.getInstance();\nappConfigClient.init(region, guid, apikey);\nappConfigClient.setContext(collectionId, environmentId);\n\nWhere,\n\n\n\n* region: Region name where the service instance is created. Use AppConfiguration.REGION_US_SOUTH for Dallas, AppConfiguration.REGION_US_EAST for Washington DC, AppConfiguration.REGION_EU_GB for London, and AppConfiguration.REGION_AU_SYD for Sydney.\n* guid: GUID of the App Configuration service. Get it from the service credentials section of the App Configuration service dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-java"},{"document_id":"ibmcld_10825-5713-7405","score":14.048928,"text":"\nYou can create a package of local code or a clone of any GitHub repository.\n\nBefore you begin\n\n\n\n* [Install the Cloud Functions plug-in for the IBM Cloud CLI](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-cli_install).\n* Create a manifest.yaml or manifest.yml file for your app and store it in the root directory. The manifest.yaml file specifies the overall structure of the package, including any metadata that must be included with the ibmcloud fn deploy command. To learn more about manifest.yaml files, see the [wskdeploy documentation](https:\/\/github.com\/apache\/openwhisk-wskdeploy\/blob\/master\/docs\/programming_guide.md).\n\n\n\nTo add a package:\n\n\n\n1. Clone the package repo.\n\ngit clone https:\/\/github.com\/ORG_NAME\/REPOSITORY_NAME\n2. Navigate to the directory that contains the manifest.yaml file.\n\ncd <filepath>\/<package_name>\n3. Deploy the package.\n\nibmcloud fn deploy -m manifest.yaml\n\nSome packages require certain environment variables to enable the package to function properly. If so, include the environment variables with the deploy command. For example, you can choose a name for the package and specify it with the PACKAGE_NAME variable.\n\nPACKAGE_NAME=CUSTOM_PACKAGE_NAME VARIABLE_NAME=VARIABLE_VALUE ibmcloud fn deploy -m manifest.yaml\n\n\n\n\n\n IBM Cloud Object Storage package example \n\nTo see an example of how to install a package, check out the [IBM Cloud Object Storage package](https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_obstorage). IBM Cloud\u00ae Object Storage is a service that allows users to store all types of files, such as images, videos, music, and text. To interact with the files, a Cloud-based datastore of key-value pairs is stored in a bucket.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-pkg_ov"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16233-7-2298","score":16.182308,"text":"\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-about"},{"document_id":"ibmcld_03330-4-2191","score":15.010934,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_07578-19989-21995","score":14.305198,"text":"\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)\n* What does the \"Only one free environment is allowed per resource group\" error message mean?\n\nIf you have recently deleted a Lite instance and then receive a 400 - Only one free environment is allowed per resource group error message when creating a new environment in a new Lite instance, you need to finish deleting the original Lite instance. See [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) and follow the reclamation-delete instructions.\n* Is there size limitation on the length of Natural Language Queries (NLQ)?\n\nThe maximum query string length for a natural language query is 2048. For more information, see [Natural language query](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersnlq).\n* How do you improve query results?\n\nThe relevance of natural language query results can be improved in IBM Watson Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. For information, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n* How do you know that relevancy training is complete?\n\nFor answers to common questions about training a collection and explanations of common error and warning messages, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-19989-21995","score":14.305198,"text":"\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)\n* What does the \"Only one free environment is allowed per resource group\" error message mean?\n\nIf you have recently deleted a Lite instance and then receive a 400 - Only one free environment is allowed per resource group error message when creating a new environment in a new Lite instance, you need to finish deleting the original Lite instance. See [ibmcloud resource reclamations](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) and follow the reclamation-delete instructions.\n* Is there size limitation on the length of Natural Language Queries (NLQ)?\n\nThe maximum query string length for a natural language query is 2048. For more information, see [Natural language query](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parametersnlq).\n* How do you improve query results?\n\nThe relevance of natural language query results can be improved in IBM Watson Discovery with training. You can train your private collections using either the Discovery tooling, or the Discovery APIs. For information, see [Improving result relevance with the tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n* How do you know that relevancy training is complete?\n\nFor answers to common questions about training a collection and explanations of common error and warning messages, see [Relevancy training tips](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-relevancy-tips).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_13160-7-1812","score":14.246876,"text":"\nBuild a database-driven Slackbot \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\nThe Slack integration sends messages between Slack and Watson Assistant. A custom extension, written in Python and deployed as serverless Code Engine app, exposes a REST API against the database backend.\n\nThis tutorial uses the new experience of Watson Assistant and an action skill. A former version was based on the dialog skill and the database was integrated using IBM Cloud\u00ae Functions with code written in Node.js. You can find that version of the tutorial in the [cloud-functions branch of the related code repository](https:\/\/github.com\/IBM-Cloud\/slack-chatbot-database-watson\/tree\/cloud-functions).\n\n\n\n Objectives \n\n\n\n* Build a chatbot using Watson Assistant which interacts with a database backend\n* Connect Watson Assistant to Slack using an integration\n* Create and deploy a Python database app to Code Engine\n* Access a Db2 on Cloud database via a Watson Assistant custom extension\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution19\/SlackbotArchitecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The user interacts with [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant), either through Slack or using a web chat client\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"},{"document_id":"ibmcld_09228-1610-2667","score":13.995635,"text":"\n* [View on GitHub](https:\/\/github.com\/with-watson\/multilingual-chatbot)\n* [Try the demo](https:\/\/multilingual-chatbot.mybluemix.net\/)\n* [Read more](https:\/\/medium.com\/ibm-watson\/build-multilingual-chatbots-with-watson-language-translator-watson-assistant-8c38247e8af1)\n\n\n\n\n\n\n\n Real-time translation (Node.js) \n\nBy using Node.js and React components, you can create a web app that can be your personal translator. The app uses Watson Speech to Text, Watson Language Translator, and Watson Text to Speech services to transcribe, translate, and synthesize from your microphone to your headphones.\n\n\n\n* [Code Pattern](https:\/\/developer.ibm.com\/components\/watson-apis\/patterns\/build-a-real-time-translation-service-with-watson-api-kit)\n* [View on GitHub](https:\/\/github.com\/ibm\/watson-speech-translator)\n\n\n\n\n\n\n\n Korean Character Recognition (TensorFlow, Android) \n\nThis mobile application uses TensorFlow and Language Translator to recognize and translate handwritten Korean characters.\n\n\n\n* [View on GitHub](https:\/\/github.com\/IBM\/tensorflow-hangul-recognition)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/language-translator?topic=language-translator-sample-apps"},{"document_id":"ibmcld_13160-7754-9761","score":13.913742,"text":"\nClick on Launch Watson Assistant to get to the Watson Assistant Tool.\n3. In the welcome dialog, create a new assistant by using slackbot as Assistant name, then click Next to start personalizing.\n4. For the first question on deployment pick Web.\n5. For the other questions answer for your role or with Other \/ Not sure at this time.\n6. Click Next for the opportunity to customize the chat UI if desired.\n7. Click Next and finalize by clicking Create.\n\nThe new page includes a guided tour which you might want to complete if you are new to Watson Assistant.\n\n\n\n\n\n\n\n Step 3: Add and configure a custom extension \n\nNext, you are going to add and then configure a custom extension to Watson Assistant and the newly created assistant.\n\n\n\n1. In the dashboard on the lower left, click on Integrations, then on Build custom extension under Extensions.\n2. In the multi-step dialog click Next, then enter events as Extension name and API for events database as Extension description. Click Next.\n3. Select and upload the local file slackbot-openapi-spec.json, then click Next.\n4. The last step lets you review the extension with included servers and operations. Once done click Finish.\n5. Back on the Integrations page note the new events tile in the Extensions section. Click Add on that tile to configure the extension for the assistant.\n6. The new dialog starts with a short overview. Click Next to get to the actual configuration. In the dropdown for Authentication type select API key auth and enter your chosen API key (MY_SECRET replacement).\n7. For the Server variables use your deployment region, slackbot-backend as appname, and the Code Engine projectid of your app. Thereafter, the generated URL should match that of your Code Engine app. When done, click Next to get to the review page, then Finish and Close to get back to the Integrations page.\n\n\n\n\n\n\n\n Step 4: Create the first action \n\nFirst, you are going to create an action to retrieve information about a single event identified by its name.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"},{"document_id":"ibmcld_16293-7-1797","score":13.857738,"text":"\nIntegrating with Slack \n\nIBM Cloud\n\nSlack is a cloud-based messaging application that helps people collaborate with one another.\n\nAfter you create an action, you can integrate your assistant with Slack.\n\nWhen integrated, depending on the events that you configure the assistant to support, your assistant can respond to questions that are asked in direct messages or in channels where the assistant is directly mentioned.\n\nAn example and instructions on how to create a Slackbot using Watson Assistant, Slack, and Db2 are given in the solution tutorial, [Build a database-driven Slackbot](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson).\n\n\n\n Adding the Slack integration \n\n\n\n1. Go to the Integrations page by clicking the integrations icon (![Integrations icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/integrations-icon.png)) in the left menu.\n2. Click Add on the Slack tile.\n3. Click Confirm.\n4. You need to have a Slack app to connect to.\n\nIf you don\u2019t have a Slack app, create one now. See [Starting with Slack apps](https:\/\/api.slack.com\/start).\n5. Go to the [Your Apps](https:\/\/api.slack.com\/apps) page on the Slack website, and then click the app you want to use.\n\nOpen the Slack app in a new browser tab, so you can easily switch back and forth between the Slack app settings page and Watson Assistant Slack integration configuration page.\n6. From the settings page for your Slack app, open the App Home page.\n7. Add access scopes for your Slack app.\n\nThe button label might be Review Scopes to Add or Update scopes depending on whether you are creating a new app or editing an app that you created before February 2020.\n\nThe method for Slack access changed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-slack"},{"document_id":"ibmcld_16384-7-2422","score":13.79084,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_13160-1449-3062","score":13.719606,"text":"\n[Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution19\/SlackbotArchitecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The user interacts with [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/watson-assistant), either through Slack or using a web chat client\n2. The chatbot utilizes a custom extension with REST API deployed as Python app on [Code Engine](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-getting-started)\n3. The custom extension app retrieves data from and inserts data into a [Db2 on Cloud](https:\/\/cloud.ibm.com\/docs\/Db2onCloud) database\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI,\n\n\n\n* Code Engine plugin,\n\n\n\n* git to clone source code repository,\n* jq to query JSON data.\n\n\n\nTo avoid the installation of these tools you can use the [Cloud Shell](https:\/\/cloud.ibm.com\/shell) from the IBM Cloud console.\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\n\n\n\n\n Step 1: Set up services and deploy backend \n\nIn this section, you are going to set up the needed services and deploy the backend app. All of this can be accomplished from the command line interface (CLI) in a terminal.\n\n\n\n1. Clone the [GitHub repository](https:\/\/github.com\/IBM-Cloud\/slack-chatbot-database-watson) and navigate into the cloned directory:\n\ngit clone https:\/\/github.com\/IBM-Cloud\/slack-chatbot-database-watson","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_09118-10321-12086","score":16.506535,"text":"\n[View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Natural Language Understanding](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-startedgetting-started) You can use IBM Watson\u00ae Natural Language Understanding to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Personality Insights](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-about) You can use IBM Watson\u00ae Personality Insights to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n\n\n\n\n\n\n\n Container service integrations \n\nYou can integrate Key Protect with the following container services.\n\n\n\nTable 4. Supported container services.\n\n Service Description Integration docs \n\n [IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-started) You can use the IBM Cloud Kubernetes Service service to deploy highly available apps in Docker containers that run in Kubernetes clusters. [View docs](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionkeyprotect)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-integrate-services"},{"document_id":"ibmcld_09920-5038-6185","score":15.848222,"text":"\nCreate a Banking Chatbot \n\nUse Node.js and Watson to detect emotion, identify entities, and discover answers.\n\n\n\n* [Learn more ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/developer.ibm.com\/patterns\/create-cognitive-banking-chatbot\/)\n* [Get the Code ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/github.com\/IBM\/watson-banking-chatbot?cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-Get-the-Code)\n* [View the Demo ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.youtube.com\/watch?v=Jxi7U7VOMYg&cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-View-the-Demo)\n* [Build from a Starter Kit ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/console.bluemix.net\/developer\/watson\/create-project?starterKit=a5819b41-0f6f-34cb-9067-47fd16835d04&cm_sp=dw-bluemix-_-code-_-devcenter)\n\n\n\n\n\n\n\n Enrich multimedia files using Watson services \n\nBuild an app that enriches audio and visual files using IBM Watson services.\n\n\n\n* [Learn more !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-sample-apps"},{"document_id":"ibmcld_16233-7-2298","score":15.407566,"text":"\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ca9232b3702768f24bb897f48f10778fcda28718\/watson-assistant\/images\/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-about"},{"document_id":"ibmcld_03330-4-2191","score":14.511044,"text":"\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https:\/\/cloud.ibm.com\/docs\/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_09920-3951-5345","score":14.41206,"text":"\n[External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/developer.ibm.com\/patterns\/snap-translate-using-tesseract-ocr-watson-language-translator\/)\n* [Get the Code ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/github.com\/IBM\/snap-and-translate)\n\n\n\n\n\n\n\n Analyze product reviews and generate a shopping guide \n\nCreate a Node.js app to make cognitive decisions using product reviews evaluated by Watson Natural Language Understanding.\n\n\n\n* [Learn more ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/developer.ibm.com\/patterns\/analyze-product-reviews-and-generate-a-shopping-guide\/)\n* [Get the Code ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/github.com\/IBM\/watson-second-opinion?cm_sp=Developer-_-slug-_-Get-the-Code)\n* [View the Demo ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.youtube.com\/watch?v=wwNAEvbxd54)\n\n\n\n\n\n\n\n Create a Banking Chatbot \n\nUse Node.js and Watson to detect emotion, identify entities, and discover answers.\n\n\n\n* [Learn more ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/developer.ibm.com\/patterns\/create-cognitive-banking-chatbot\/)\n* [Get the Code !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-sample-apps"},{"document_id":"ibmcld_16364-199341-201521","score":14.322523,"text":"\nAnd the links between nodes are represented in a way that makes it easier to understand the relationships between the nodes.\n\n\n\n\n\n 21 June 2017 \n\nArabic support\n: Language support for Arabic is now generally available. For details, see [Configuring bidirectional languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\nLanguage updates\n: The Watson Assistant service algorithms have been updated to improve overall language support. See the [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support) topic for details.\n\n\n\n\n\n 16 June 2017 \n\nRecommendations (Beta - Premium users only)\n: The Improve panel also includes a Recommendations page that recommends ways to improve your system by analyzing the conversations that users have with your chatbot, and taking into account your system's current training data and response certainty.\n\n\n\n\n\n 14 June 2017 \n\nFuzzy matching for additional languages (Beta)\n: Fuzzy matching for entities is now available for additional languages, as noted in the [Supported languages](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support) topic. You can turn on fuzzy matching per entity to improve the ability of your assistant to recognize terms in user input with syntax that is similar to the entity, without requiring an exact match. The feature is able to map user input to the appropriate corresponding entity despite the presence of misspellings or slight syntactical differences. For example, if you define giraffe as a synonym for an animal entity, and the user input contains the terms giraffes or girafe, the fuzzy match is able to map the term to the animal entity correctly. See [Fuzzy matching](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-fuzzy-matching) for details.\n\n\n\n\n\n 13 June 2017 \n\nUser conversations\n: The Improve panel now includes a User conversations page, which provides a list of user interactions with your chatbot that can be filtered by keyword, intent, entity, or number of days. You can open individual conversations to correct intents, or to add entity values or synonyms.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_09118-9294-10691","score":14.175052,"text":"\n[Text to Speech](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-gettingStarted) You can use Text to Speech's speech-synthesis capabilities to convert written text into natural-sounding speech. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [Tone Analyzer](https:\/\/cloud.ibm.com\/docs\/tone-analyzer?topic=tone-analyzer-gettingStarted) You can use Tone Analyzer to detect emotional and language tones in your written texts. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/tone-analyzer?topic=tone-analyzer-gettingStarted) You can use Knowledge Studio to understand the linguistic nuances, meaning, and relationships specific to your industry. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [Watson OpenScale](https:\/\/dataplatform.cloud.ibm.com\/docs\/content\/wsj\/model\/getting-started.html) You can use Watson OpenScale to automate and maintain the AI lifecycle in your business applications. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-keyservice)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-integrate-services"},{"document_id":"ibmcld_07128-1500-3450","score":14.122993,"text":"\n* Crawl, convert, enrich and normalize data.\n* Securely explore your proprietary content as well as free and licensed public content.\n* Apply additional enrichments such as concepts, relations, and sentiment through Natural Language Understanding (NLU).\n* Simplify development while still providing direct access to APIs.\n\n\n\nTo try out Discovery, see the [IBM Watson\u2122 Discovery Query Demo](https:\/\/www.ibm.com\/demos\/live\/watson-discovery\/self-service\/home).\n\nYou can use Smart Document Understanding (SDU) to train IBM Watson\u2122 Discovery to extract custom fields in your documents. See [Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu) for more information.\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https:\/\/cloud.ibm.com\/docs\/services\/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)\n\nFor information about language support, see [Discovery language support](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-language-support).\n\nFor information about IBM Cloud security, see the [IBM Cloud Service Description](https:\/\/www.ibm.com\/software\/sla\/sladb.nsf\/searchsaas\/?searchview&searchorder=4&searchmax=0&query=%28IBM+Cloud+Service+description%29)\n\nUS Health Insurance Portability and Accountability Act (HIPAA) support is available for Premium plans in the Washington, DC location created on or after 1 April 2019. See [Enabling EU and HIPAA supported settings](https:\/\/cloud.ibm.com\/docs\/account?topic=account-eu-hipaa-supportedeu-hipaa-supported) for more information.\n\n\n\n Browser support and prerequisites","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-about"},{"document_id":"ibmcld_03330-3253-5192","score":13.866204,"text":"\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.\n\n\n\n\n\nFor more information about the architecture, read the [How to Make Chatbot Orchestration Easier](https:\/\/medium.com\/ibm-watson\/how-to-make-chatbot-orchestration-easier-c8ed61620b8d) blog on Medium.com.\n\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https:\/\/www.ibm.com\/blogs\/watson\/2020\/03\/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits\/) blog on ibm.com.\n\nThis documentation describes managed instances of Watson Assistant that are offered in IBM Cloud or in Cloud Pak for Data as a Service. If you are interested in on-premises or installed deployments, see [this documentation](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-index).\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Creating an assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-assistant-add)\n* [Adding skills to your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-index"},{"document_id":"ibmcld_16729-22725-24649","score":13.404042,"text":"\n[Build a database-driven Slackbot](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson)Build a database-driven Slackbot\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\nCode Engine Watson Assistant\n\n+1\n\nDb2 on Cloud\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[SQL Database for Cloud data](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-sql-database)SQL Database for Cloud data\n\nThis tutorial shows how to provision a SQL (relational) database service. As administrator, you create a table and load a large data set (city information) into the database. Then, you deploy a web app \"worldcities\" to Code Engine. The app allows regular users to look up records from the cloud database. The app is written in Python using the Flask framework.\n\nCode Engine Db2 Warehouse on Cloud\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Text analysis with Code Engine](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-text-analysis-code-engine)Text analysis with Code Engine\n\nIn this tutorial, you will learn about IBM Cloud\u00ae Code Engine by deploying a text analysis with Natural Language Understanding application. You will create a Code Engine project, select the project and deploy Code Engine entities - applications and jobs - to the project. You will learn how to bind IBM Cloud services to your Code Engine entities. You will also understand the auto-scaling capability of Code Engine where instances are scaled up or down (to zero) based on incoming workload.\n\nCode Engine Kubernetes service\n\n+2\n\nObject Storage,Natural Language Understanding\n\n\n\n* 2 hours\n* 2023-05-05","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16364-174190-176246","score":14.658729,"text":"\nFor all new and existing service instances in other regions, you continue to use service credentials ({username}:{password}) for authentication.\n\nWhen you use any of the Watson SDKs, you can pass the API key and let the SDK manage the lifecycle of the tokens. For more information and examples, see [Authentication](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2authentication) in the API reference.\n\nIf you are not sure which type of authentication to use, view the Watson Assistant credentials by clicking the service instance from the Services section of the [IBM Cloud Resource List](https:\/\/cloud.ibm.com).\n\n\n\n\n\n 25 May 2018 \n\nNew sample workspace\n: The sample workspace that is provided for you to explore or to use as a starting point for your own workspace has changed. The Car Dashboard sample was replaced by a Customer Service sample. The new sample showcases how to use content catalog intents and other newer features to build a bot. It can answer common questions, such as inquiries about store hours and locations, and illustrates how to use a node with slots to schedule in-store appointments.\n\nHTML rendering was added to Try it out\n: The \"Try it out\" pane now renders HTML formatting that is included in response text. Previously, if you included a hypertext link as an HTML anchor tag in a text response, you would see the HTML source in the \"Try it out\" pane during testing. It used to look like this:\n\nContact us at <a href=\"https:\/\/www.ibm.com\">ibm.com<\/a>.\n\nNow, the hypertext link is rendered as if on a web page. It is displayed like this:\n\nContact us at[ibm.com](https:\/\/www.ibm.com).\n\nRemember, you must use the appropriate type of syntax in your responses for the client application to which you will deploy the conversation. Only use HTML syntax if your client application can interpret it properly. Other integration channels might expect other formats.\n\nDeployment changes\n: The Test in Slack option was removed.\n\n\n\n\n\n 11 May 2018 \n\nInformation security\n: The documentation includes some new details about data privacy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_07578-7341-9464","score":13.663094,"text":"\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* I'm being asked to log in repeatedly\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan you were using has expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n* I'm getting a 401 response\n\nThe 401 response code is returned for many reasons, including:\n\n\n\n* You exceeded the API call limit for your plan for this month. For example, for Lite plans, the monthly limit for API calls 10,000 messages per month. If you reach your limit for the month, but the logs show that you have made fewer calls than the limit, remember that the Lite plan stores log information for 7 days only. The 401 response will go away as soon as the next billing cycle begins, which is the first day of the calendar month.\n* You are trying to use an instance-level API key that you created in one data center location to connect to a service instance that is hosted from another location. You must create an API key in the same data center location where your service instance is hosted.\n\n\n\n* Getting Unable to fetch access token for account message","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-7341-9464","score":13.663094,"text":"\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n* I'm being asked to log in repeatedly\n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan you were using has expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n* I'm getting a 401 response\n\nThe 401 response code is returned for many reasons, including:\n\n\n\n* You exceeded the API call limit for your plan for this month. For example, for Lite plans, the monthly limit for API calls 10,000 messages per month. If you reach your limit for the month, but the logs show that you have made fewer calls than the limit, remember that the Lite plan stores log information for 7 days only. The 401 response will go away as soon as the next billing cycle begins, which is the first day of the calendar month.\n* You are trying to use an instance-level API key that you created in one data center location to connect to a service instance that is hosted from another location. You must create an API key in the same data center location where your service instance is hosted.\n\n\n\n* Getting Unable to fetch access token for account message","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03313-7474-9676","score":13.57072,"text":"\nIf you are having trouble logging in to a service instance or see messages about tokens, such as unable to fetch access token or 400 bad request - header or cookie too large, it might mean that you need to clear your browser cache. Open a private browser window, and then try again.\n\n\n\n* If accessing the page by using a private browsing window fixes the issue, then consider always using a private window or clear the cache of your browser. You can typically find an option for clearing the cache or deleting cookies in the browser's privacy and security settings.\n* If accessing the page by using a private browsing window doesn't fix the issue, then try deleting the API key for the instance and creating a new one.\n\n\n\n\n\n\n\n I'm being asked to log in repeatedly \n\nIf you keep getting messages, such as you are getting redirected to login, it might be due to one of the following things:\n\n\n\n* The Lite plan you were using has expired. Lite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n\n\n\n\n I'm getting a 401 response \n\nThe 401 response code is returned for many reasons, including:\n\n\n\n* You exceeded the API call limit for your plan for this month. For example, for Lite plans, the monthly limit for API calls 10,000 messages per month. If you reach your limit for the month, but the logs show that you have made fewer calls than the limit, remember that the Lite plan stores log information for 7 days only. The 401 response will go away as soon as the next billing cycle begins, which is the first day of the calendar month.\n* You are trying to use an instance-level API key that you created in one data center location to connect to a service instance that is hosted from another location. You must create an API key in the same data center location where your service instance is hosted.\n\n\n\n\n\n\n\n Getting Unable to fetch access token for account message \n\nThe full message is, Assistants could not be loaded at this time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-faqs"},{"document_id":"ibmcld_13429-170776-173003","score":13.527598,"text":"\n: For the US English language models, en_US_BroadbandModel and en_US_NarrowbandModel, the service now correctly capitalizes many proper nouns. For example, the service would new return text that reads \"Barack Obama graduated from Columbia University\" instead of \"barack obama graduated from columbia university.\" This change might be of interest to you if your application is sensitive in any way to the case of proper nouns.\n\nNew HTTP error code\n: The HTTP DELETE \/v1\/sessions\/{session_id} request does not return status code 415 \"Unsupported Media Type.\" This return code is removed from the documentation for the method.\n\n\n\n\n\n 1 July 2015 \n\nThe Speech to Text service is now generally available\n: The service moved from beta to general availability (GA) on July 1, 2015. The following differences exist between the beta and GA versions of the Speech to Text APIs. The GA release requires that users upgrade to the new version of the service.\n\nThe GA version of the HTTP API is compatible with the beta version. You need to change your existing application code only if you explicitly specified a model name. For example, the sample code available for the service from GitHub included the following line of code in the file demo.js:\n\nmodel: 'WatsonModel'\n\nThis line specified the default model, WatsonModel, for the beta version of the service. If your application also specified this model, you need to change it to use one of the new models that are supported by the GA version. For more information, see the next bullet.\n\nNew token-based programming model\n: The service now supports a new programming model for direct interaction between a client and the service over a WebSocket connection. By using this model, a client can obtain an authentication token for communicating directly with the service. The token bypasses the need for a server-side proxy application in IBM Cloud to call the service on the client's behalf. Tokens are the preferred means for clients to interact with the service.\n\nThe service continues to support the old programming model that relied on a server-side proxy to relay audio and messages between the client and the service. But the new model is more efficient and provides higher throughput.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_03369-136468-138457","score":13.39241,"text":"\n* Washington, DC (us-east) as of 14 June 2018\n* Sydney, Australia (au-syd) as of 7 May 2018\n\n\n\nIBM Cloud\u00ae is migrating to token-based Identity and Access Management (IAM) authentication.\n\nFor new service instances in the regions listed, you use IAM for authentication. You can pass either a bearer token or an API key. Tokens support authenticated requests without embedding service credentials in every call. API keys use basic authentication.\n\nFor all new and existing service instances in other regions, you continue to use service credentials ({username}:{password}) for authentication.\n\nWhen you use any of the Watson SDKs, you can pass the API key and let the SDK manage the lifecycle of the tokens. For more information and examples, see [Authentication](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2authentication) in the API reference.\n\nIf you are not sure which type of authentication to use, view the Watson Assistant credentials by clicking the service instance from the Services section of the [IBM Cloud Resource List](https:\/\/cloud.ibm.com).\n\n\n\n\n\n 25 May 2018 \n\nNew sample workspace\n: The sample workspace that is provided for you to explore or to use as a starting point for your own workspace has changed. The Car Dashboard sample was replaced by a Customer Service sample. The new sample showcases how to use content catalog intents and other newer features to build a bot. It can answer common questions, such as inquiries about store hours and locations, and illustrates how to use a node with slots to schedule in-store appointments.\n\nHTML rendering was added to Try it out\n: The \"Try it out\" pane now renders HTML formatting that is included in response text. Previously, if you included a hypertext link as an HTML anchor tag in a text response, you would see the HTML source in the \"Try it out\" pane during testing. It used to look like this:\n\nContact us at <a href=\"https:\/\/www.ibm.com\">ibm.com<\/a>.\n\nNow, the hypertext link is rendered as if on a web page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16334-10647-12550","score":13.334228,"text":"\n* A new servers property is now available in the web chat configuration options. You can use this property to set up a proxy between your users' browsers and Watson Assistant. For more information, see [Setting up a proxy](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationserversconfig).\n\n\n\n\n\n\n\n 6.5.2 \n\nRelease date: 11 July 2022\n\n\n\n* Bug fix for date response type.\n\n\n\n\n\n\n\n 6.5.1 \n\nRelease date: 15 June 2022\n\n\n\n* Bug fix for the Zendesk integration.\n\n\n\n\n\n\n\n 6.5.0 \n\nRelease date: 6 June 2022\n\n\n\n* New agent events: New events are now fired by the web chat when messages are sent or received during a conversation with a human agent using a service desk integration. For more information, see [Agent events summary](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-eventsagent-summary).\n* Bug fixes.\n\n\n\n\n\n\n\n 6.4.1 \n\nRelease date: 16 May 2022\n\n\n\n* Minimum size: The minimum allowed size of the rendered web chat window has been reduced to satisfy the accessibility requirements defined by the [Web Content Accessibility Guidelines (WCAG) 2.1](https:\/\/www.w3.org\/TR\/WCAG21\/) standard.\n* Pop-up windows and tabs from iframes: The web chat now allows pop-up windows and new tabs to be opened from content rendered inside iframe responses.\n* Faster responses: Responses received from the assistant are now displayed more quickly and without a ... typing indicator.\n\n\n\n\n\n\n\n 6.4.0 \n\nRelease date: 18 April 2022\n\n\n\n* Date picker: If you configure a step to collect a Date customer response, the step now uses the new date response type to request that the web chat display a graphical date picker the customer can use to select a date, as an alternative to typing the date in the input field. Existing steps do not automatically inherit this behavior; if you want to use the date picker, you must delete the existing Date response and then re-add it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_16334-33767-35711","score":13.163152,"text":"\nYou can use it to check for specific conditions, such as isWebChatOpen, before you perform an action that might rely on the condition being true.\n\n\n\nFor more information about the new methods, see [Instance methods](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methods).\n\n\n\n\n\n 3.3.2 \n\nRelease date: 17 December 2020\n\n\n\n* Addressed accessibility issues.\n\n\n\n\n\n\n\n 3.3.1 \n\nRelease date: 3 December 2020\n\n\n\n* The translated strings in the [language files](https:\/\/github.com\/watson-developer-cloud\/assistant-web-chat\/tree\/main\/languages) were revised and improved.\n* An error message is shown now if a Java Web Token (JWT) that is provided with an incoming message is invalid. If the first JWT fails when the web chat opens, an error message is displayed in place of the web chat window that says, There was an error communicating with Watson Assistant. If the initial JWT is valid, but the token for a subsequent message is invalid, a more discreet error message is displayed in response to the insecure input.\n* Bug fixes.\n\n\n\n\n\n\n\n 3.3.0 \n\nRelease date: 23 November 2020\n\n\n\n* Added support for passing contextual information to a service desk agent from web chat.\n* You can now customize a user_defined response type. For more information, see the [Custom response type tutorial](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-user-defined-response).\n* Bug fixes.\n\n\n\n\n\n\n\n 3.2.1 \n\nRelease date: 2 November 2020\n\n\n\n* Bug fix: Fixing a bug that prevented the web chat integration preview from working after security was enabled.\n\n\n\n\n\n\n\n 3.2.0 \n\nRelease date: 26 October 2020\n\n\n\n* Security improvement: If you enable security, you no longer need to include the identityToken property when the web chat is loaded on a web page. If a token is not initially provided, the existing identityTokenExpired event will be fired when the web chat is first opened to obtain one from your handler.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_01719-4-2161","score":12.96872,"text":"\n* UI\n* API\n\n\n\n\n\n\n\n Using services with classic infrastructure assets \n\nYou can easily use API-based public IBM Cloud\u00ae services with your classic infrastructure assets. All APIs are secure and encrypted so that your data is protected.\n\nYou can gain insights and cognitive knowledge by calling Watson APIs from your apps to make them more personalized. Or, use data and analytics services to tap into high-performance analytics for your apps. Or, choose database-as-a-service where you can leave the management to IBM Cloud.\n\nModernize your application development by using containers with services like Active Deploy and Delivery Pipeline. You can then use the IBM\u00ae VPN service to communicate and connect your container in a private network to the classic infrastructure private network. All of the usage charges of the compute resources and services are reflected in your IBM Cloud invoice.\n\n\n\n Add a service to classic infrastructure assets \n\nFor example, do you want to add cognitive capabilities from Watson to your apps that are running on classic infrastructure bare metal servers? You can add a service such as Personality Insights to help understand your app's user by completing the following steps:\n\n\n\n1. In the IBM Cloud console, search for the service in the catalog.\n2. Create an instance of the service with just a few clicks.\n3. Set up the service to run with your existing code by copying the service credentials and adding them to your application.\n4. After the update to the app, deploy the new version to your classic infrastructure assets.\n\n\n\n\n\n\n\n Add a service to classic infrastructure assets by using the API \n\nFor example, do you want to add cognitive capabilities from Watson to your apps that are running on classic infrastructure bare metal servers? You can add a service such as Personality Insights to help understand your app's user by completing the following steps:\n\n\n\n1. Create an instance of the service by calling [Resource Controller API](https:\/\/cloud.ibm.com\/apidocs\/resource-controller\/resource-controller?code=gocreate-resource-instance) as shown in the following example request:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-api-services-infrastructure"},{"document_id":"ibmcld_06308-0-500","score":12.81776,"text":"\n\n\n\n\n\n\n  APIs and SDKs \n\nWatson Query provides REST APIs that you can use to interact with your instance.\n\nTo access data, view and create database objects, administer, and monitor your service, use the [Watson Query APIs](https:\/\/cloud.ibm.com\/apidocs\/data-virtualization-on-cloud).\n\nThe following Watson Query SDKs are supported by IBM:\n\n\n\n*  [Go SDK](https:\/\/github.com\/IBM\/data-virtualization-on-cloud-go-sdk\/)\n*  [Java SDK](https:\/\/github.com\/IBM\/data-virtualization-on-cloud-java-sdk\/)\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/data-virtualization?topic=data-virtualization-con_rest_api"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13074-16820-18514","score":16.419302,"text":"\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https:\/\/cloud.ibm.com\/catalog\/services\/discovery).\n\n\n\n\n\n Enrichment language support","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_13074-15255-17243","score":11.866252,"text":"\nSee [Entity extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceentity-extraction) and [Keyword extraction](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configservicekeyword-extraction) about those enrichments.\n\nThe subject, action, and object are extracted for every sentence that contains a relation.\n\n\n\n\n\n Sentiment analysis \n\nIdentifies attitude, opinions, or feelings in the content that is being analyzed. Discovery can calculate overall sentiment within a document, sentiment for user-specified targets, entity-level sentiment, quotation-level sentiment, directional-sentiment, and keyword-level sentiment. The combination of these capabilities supports a variety of use cases ranging from social media monitoring to trend analysis.\n\nExample portion of a document enriched with Sentiment Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"sentiment\": {\n\"document\": {\n\"score\": 0.459813,\n\"label\": \"positive\"\n}\n}\n\nIn the preceding example, you could query the sentiment label by accessing enriched_text.sentiment.document.label\n\nThe label is the overall sentiment of the document (positive, negative, or neutral). The sentiment label is based on the score; a score of 0.0 would indicate that the document is neutral, a positive number would indicate the document is positive, a negative number would indicate the document is negative.\n\n\n\n\n\n Emotion analysis \n\nDetects anger, disgust, fear, joy, and sadness implied in English text. Emotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/discovery?topic=discovery-configservice"},{"document_id":"ibmcld_09906-2727-4077","score":10.212466,"text":"\nThe targets option for sentiment in the following example tells the service to search for the targets \"apples\", \"oranges\", and \"broccoli\". Since \"apples\" and \"oranges\" are located in the text, sentiment scores are returned for those targets.\n\nYou can also get sentiment and emotion results for entities and keywords that are detected in your text. In the example, the emotion option for keywords tells the service to analyze each detected keyword for emotion results.\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data '{\n\"text\": \"I love apples! I do not like oranges.\",\n\"features\": {\n\"sentiment\": {\n\"targets\": [\n\"apples\",\n\"oranges\",\n\"broccoli\"\n]\n},\n\"keywords\": {\n\"emotion\": true\n}\n}\n}' \"{url}\/v1\/analyze?version=2019-07-12\"\nShow more\n\nRunnable command for Windows users:\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data \"{\"text\":\"I love apples! I do not like oranges.\",\"features\":{\"sentiment\":{\"targets\":[\"apples\",\"oranges\",\"broccoli\"]},\"keywords\":{\"emotion\":true}}}\" \"{url}\/v1\/analyze?version=2019-07-12\"\n\n\n\n\n\n Next steps \n\n\n\n* View the [API reference](https:\/\/cloud.ibm.com\/apidocs\/natural-language-understanding).\n* Learn how to identify [custom entities and relations](https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-customizing).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-started"},{"document_id":"ibmcld_09906-1621-3194","score":10.040755,"text":"\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data '{\n\"url\": \"http:\/\/newsroom.ibm.com\/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\n\"features\": {\n\"sentiment\": {},\n\"categories\": {},\n\"concepts\": {},\n\"entities\": {},\n\"keywords\": {}\n}\n}' \"{url}\/v1\/analyze?version=2019-07-12\"\n\nWindows users: This command might not run on Windows. Run the following command instead:\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --data \"{\"url\":\"http:\/\/newsroom.ibm.com\/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\"features\":{\"sentiment\":{},\"categories\":{},\"concepts\":{},\"entities\":{},\"keywords\":{}}}\" \"{url}\/v1\/analyze?version=2019-07-12\"\n\nThe next step demonstrates how to specify options that customize the analysis for each feature.\n\n\n\n\n\n Step 2: Analyze target phrases and keywords \n\nNatural Language Understanding can analyze target phrases in context of the surrounding text for focused sentiment and emotion results. The targets option for sentiment in the following example tells the service to search for the targets \"apples\", \"oranges\", and \"broccoli\". Since \"apples\" and \"oranges\" are located in the text, sentiment scores are returned for those targets.\n\nYou can also get sentiment and emotion results for entities and keywords that are detected in your text. In the example, the emotion option for keywords tells the service to analyze each detected keyword for emotion results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-getting-started"},{"document_id":"ibmcld_13443-7-2262","score":9.802443,"text":"\nKeyword spotting and word alternatives \n\nThe IBM Watson\u00ae Speech to Text service can identify user-specified keywords in its transcription results. It can also suggest alternative words that are acoustically similar to the words of a transcript. In both cases, the keywords and word alternatives must meet a user-specified level of confidence.\n\n\n\n Keyword spotting \n\nThe keywords and keywords_threshold parameters are supported only with previous-generation models, not with next-generation models.\n\nThe keyword spotting feature detects specified strings in a transcript. The service can spot the same keyword multiple times and report each occurrence. The service spots keywords only in the final results, not in interim results. By default, the service does no keyword spotting.\n\nTo use keyword spotting, you must specify both of the following parameters:\n\n\n\n* Use the keywords parameter to specify an array of strings to be spotted. The service spots no keywords if you omit the parameter or specify an empty array. A keyword string can include more than one token. For example, the keyword Speech to Text has three tokens. Keyword matching is case-insensitive, so Speech to Text is effectively equivalent to speech to text.\n\nFor US English, the service normalizes each keyword to match spoken versus written strings. For example, it normalizes numbers to match how they are spoken as opposed to written. For other languages, keywords must be specified as they are spoken.\n* Use the keywords_threshold parameter to specify a probability between 0.0 and 1.0 for a keyword match. The threshold indicates the lower bound for the level of confidence the service must have for a word to match the keyword. A keyword is spotted in the transcript only if its confidence is greater than or equal to the specified threshold.\n\nSpecifying a small threshold can potentially produce many matches. If you specify a threshold, you must also specify one or more keywords. Omit the parameter to return no matches.\n\n\n\nThe following limits apply to keyword spotting:\n\n\n\n* You can spot a maximum of 1000 keywords with a single request.\n* A single keyword can have a maximum length of 1024 characters. The maximum effective length for double-byte languages might be shorter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-spotting"},{"document_id":"ibmcld_03353-8238-10149","score":9.605046,"text":"\n[Bidi options](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever for some languages, like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as \"u\u00f1a\" vs. \"una\". In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-language-support"},{"document_id":"ibmcld_07140-17709-19868","score":9.600777,"text":"\nThe emotion enrichment evaluates the overall emotional tone (for example anger) of entire document or specified target strings in the entire document. This enrichment can only be used with English content.\n\n\n\n* \"document\" : booleanoptional - When true the emotional tone of the entire document is evaluated.\n* \"targets\" : arrayoptional - A comma-separated array of target strings of which to evaluate the emotional state within the document.\n\n\n\n\n\n\n\n entities \n\nThe entities enrichment extracts instances of known entities such as people, places, and organizations. Optionally, a Knowledge Studio custom model can be specified to extract custom entities.\n\n\n\n* \"sentiment\" : boolean - optional - When true, sentiment analysis is performed on the extracted entity in the context of the surrounding content.\n* \"emotion\" : boolean - optional - When true, emotional tone analysis is performed on the extracted entity in the context of the surrounding content.\n* \"limit\" : INT - optional - The maximum number of entities to extract from the ingested document. The default is 50.\n* \"mentions\": boolean - optional - When true, the number of times that this entity is mentioned is recorded. The default is false.\n* \"mention_types\": boolean - optional - When true, the mention type for each mention of this entity is stored. The default is false.\n* \"sentence_location\": boolean - optional - When true, the sentence location of each entity mention is stored. The default is false.\n* \"model\" : string - optional - When specified, the custom model is used to extract entities instead of the public model. This option requires a Knowledge Studio custom model to be associated with your instance of Discovery. See [Integrating with Watson Knowledge Studio](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-integrating-with-wks) for more information.\n\n\n\n\n\n\n\n keywords \n\nThe keywords enrichment extracts instances of significant words within the text. To understand the difference between keywords, concepts, and entities, see [Understanding the difference between Entities, Concepts, and Keywords](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceudbeck).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configref"},{"document_id":"ibmcld_16364-21733-23882","score":9.569823,"text":"\n: Use the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent, when it\u2019s important for a customer to speak with a live agent rather than activate any further actions. The second group shows customers a customizable warning message, used to discourage customers from interacting with your assistant in unacceptable ways, such as using profanity. This action is included with all new assistants created as of this date. This is a beta feature that is available for evaluation and testing purposes. For more information, see [Detecting trigger words](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-trigger-phrases).\n\nChanges to unrecognized requests algorithm\n: In Analyze, the Recognition page lets you view groups of similar unrecognized requests. You can use the requests as example phrases in new or existing actions to address questions and issues that aren't being answered by your assistant. With this release, the criteria for grouping the requests is relaxed for customers with lesser amounts of data. Also, the group names have been improved with better grammar and to be more representative of the requests. For more information, see [Use unrecognized requests to get action recommendations](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-analytics-recognition).\n\n\n\n\n\n 1 February 2023 \n\nActions templates updated with new design and new choices\n: The actions template catalog has a new design that lets you select multiple templates at the same time. It also has new and updated templates, including starter kits you can use with external services such as Google and HubSpot. For more information, see [Building actions from a template](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-templates).\n\n\n\n\n\n 26 January 2023 \n\nDisplay formats for variables\n: In Global settings for actions, Display formats lets you specify the display formats for variables that use date, time, numbers, currency, or percentages. You can also choose a default locale to use if one isn't provided by the client application.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_03369-156643-158642","score":9.514724,"text":"\nFor example, for the word barri\u00f3, which has an accent and corresponds to the past tense of the verb barrer (to sweep), your assistant can also match the word barrio (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as u\u00f1a vs. una. In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.\n\nNote: Accent normalization is enabled for Portuguese, Spanish, French, and Czech.\n\nWorkspace opt-out flag\n: The Watson Assistant REST API now supports an opt-out flag for workspaces. This flag indicates that workspace training data such as intents and entities are not to be used by IBM for general service improvements. For more information, see the [API Reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v1?curl=data-collection)\n\n\n\n\n\n 7 August 2017 \n\nNext and last date interpretation\n: The Watson Assistant service treats last and next dates as referring to the most immediate last or next day referenced, which may be in either the same or a previous week. See the [system entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-system-entitiessystem-entities-sys-date-time) topic for additional information.\n\n\n\n\n\n 3 August 2017 \n\nFuzzy matching for additional languages (Beta)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_09920-5038-6185","score":9.441746,"text":"\nCreate a Banking Chatbot \n\nUse Node.js and Watson to detect emotion, identify entities, and discover answers.\n\n\n\n* [Learn more ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/developer.ibm.com\/patterns\/create-cognitive-banking-chatbot\/)\n* [Get the Code ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/github.com\/IBM\/watson-banking-chatbot?cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-Get-the-Code)\n* [View the Demo ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/www.youtube.com\/watch?v=Jxi7U7VOMYg&cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-View-the-Demo)\n* [Build from a Starter Kit ![External link icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/icons\/launch-glyph.svg)](https:\/\/console.bluemix.net\/developer\/watson\/create-project?starterKit=a5819b41-0f6f-34cb-9067-47fd16835d04&cm_sp=dw-bluemix-_-code-_-devcenter)\n\n\n\n\n\n\n\n Enrich multimedia files using Watson services \n\nBuild an app that enriches audio and visual files using IBM Watson services.\n\n\n\n* [Learn more !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/natural-language-understanding?topic=natural-language-understanding-sample-apps"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.921786879}}
{"task_id":"674aa142d92a6b4262de254df0c3f7b2<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13373-7-1706","score":13.058375,"text":"\nKnown limitations \n\nThe Speech to Text service has the following known limitations. These issues apply to service functionality that spans releases for all platforms. For information about known limitations specific to Speech to Text for IBM Cloud Pak for Data version 4.6.x, see [Limitations and known issues in Watson Speech services](https:\/\/www.ibm.com\/docs\/en\/cloud-paks\/cp-data\/4.6.x?topic=issues-watson-speech-services).\n\n\n\n Issue: Interim results for previous-generation models \n\n27 April 2021: When you use previous-generation models with the WebSocket interface, if you request both speaker labels and interim results, the speaker labels response includes an extra object. The final results duplicate the object for the last speaker label. Instead of appearing once with \"final\": true, the object appears twice: once with \"final\": false and once with \"final\": true.\n\nFor example, a WebSocket request that includes both speaker labels and interim results sends a start message like the following:\n\nvar message = {\naction: 'start',\nspeaker_labels: true,\ninterim_results: true\n};\nwebsocket.send(JSON.stringify(message));\n\nTo indicate final results for speaker labels, the service is supposed to return a response of the following form:\n\n{\n\"speaker_labels\": [\n. . .\n{\n\"from\": 1.01,\n\"to\": 1.75,\n\"speaker\": 0,\n\"confidence\": 0.75,\n\"final\": false\n},\n{\n\"from\": 1.76,\n\"to\": 2.50,\n\"speaker\": 1,\n\"confidence\": 0.80,\n\"final\": true\n}\n]\n}\nShow more\n\nInstead, the service returns final results like the following. Note that the object for the last speaker label, which begins at 1.76 and ends at 2.50, is returned twice. The \"final\": true indication is associated with the second instance of the label.\n\n{","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-known-limitations"},{"document_id":"ibmcld_16364-174190-176246","score":12.3527155,"text":"\nFor all new and existing service instances in other regions, you continue to use service credentials ({username}:{password}) for authentication.\n\nWhen you use any of the Watson SDKs, you can pass the API key and let the SDK manage the lifecycle of the tokens. For more information and examples, see [Authentication](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2authentication) in the API reference.\n\nIf you are not sure which type of authentication to use, view the Watson Assistant credentials by clicking the service instance from the Services section of the [IBM Cloud Resource List](https:\/\/cloud.ibm.com).\n\n\n\n\n\n 25 May 2018 \n\nNew sample workspace\n: The sample workspace that is provided for you to explore or to use as a starting point for your own workspace has changed. The Car Dashboard sample was replaced by a Customer Service sample. The new sample showcases how to use content catalog intents and other newer features to build a bot. It can answer common questions, such as inquiries about store hours and locations, and illustrates how to use a node with slots to schedule in-store appointments.\n\nHTML rendering was added to Try it out\n: The \"Try it out\" pane now renders HTML formatting that is included in response text. Previously, if you included a hypertext link as an HTML anchor tag in a text response, you would see the HTML source in the \"Try it out\" pane during testing. It used to look like this:\n\nContact us at <a href=\"https:\/\/www.ibm.com\">ibm.com<\/a>.\n\nNow, the hypertext link is rendered as if on a web page. It is displayed like this:\n\nContact us at[ibm.com](https:\/\/www.ibm.com).\n\nRemember, you must use the appropriate type of syntax in your responses for the client application to which you will deploy the conversation. Only use HTML syntax if your client application can interpret it properly. Other integration channels might expect other formats.\n\nDeployment changes\n: The Test in Slack option was removed.\n\n\n\n\n\n 11 May 2018 \n\nInformation security\n: The documentation includes some new details about data privacy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_16632-1751-4226","score":12.2341795,"text":"\nWhen an AZ fails, sufficient capacity to initiate the required services on the available AZs is ensured. This minimizes any impact that is caused by an AZ outage.\n\n\n\n\n\n Responsibilities \n\n\n\nTable 1. Responsibilities\n\n Task IBM Responsibilities Your Responsibilities \n\n Backups watsonx.data is responsible for automatic daily backups, of all watsonx.data provided resources. The Client is responsible for:1) Create a new instance of IBM watsonx.data to restore the backups and validate that the IBM backups that are restored properly. 2) Restore backups of external components that they brought into watsonx.data. \n Restore watsonx.data handles the restoration of backups for provided resources. The Client is responsible for:1) Create a new instance of watsonx.data to restore the backups and validate that the IBM backups that are restored properly. 2) Restore backups of external components that they brought into watsonx.data. \n\n\n\n\n\n\n\n Application-level high availability \n\nApplications that communicate over networks and cloud services are subject to transient connection failures. Design your applications to retry connections when a temporary loss in connectivity to your deployment or to IBM Cloud, causes errors. As watsonx.data is a managed service, regular updates and maintenance occur as part of normal operations. Such maintenance occasionally causes a temporary service interruption.\n\nYour applications must be designed to handle temporary interruptions to the service, implement error handling for failed commands, and implement retry logic to recover from a temporary interruption.\n\nFollowing are some of the error codes that might be expected during the temporary service interruptions:\n\nIf a Presto coordinator node restarts, be it for maintenance purposes or due to a system failure, applications are required to reestablish their connection with the Presto engine.\n\nSeveral minutes of unavailability or connection interruptions are not expected. Open a support ticket with details if you have time periods longer than a minute with no connectivity so that the interruptions are investigated.\n\n\n\n\n\n Disaster Recovery Strategy \n\nIBM\u00ae watsonx.data provides mechanisms to protect your data and restore service functions. Business continuity plans are in place to achieve targeted recovery point objective (RPO) and recovery time objective (RTO) for the service. The following table outlines the targets for watsonx.data.\n\n\n\nTable 2. Disaster Recovery Strategy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hadr_wxd"},{"document_id":"ibmcld_16362-4518-6470","score":11.843972,"text":"\nLite plans expire if they are not used within a 30-day span. To begin again, log in to IBM Cloud and create a new service instance of Watson Assistant.\n* An instance is locked when you exceed the plan limits for the month. To log in successfully, wait until the start of the next month when the plan limit totals are reset.\n\n\n\n\n\n\n\n Why don't I see the Analytics page? \n\nTo view the Analytics page, you must have a service role of Manager and a platform role of at least Viewer. For more information about access roles and how to request an access role change, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-access-control).\n\n\n\n\n\n Why am I unable to view the API details, API key, or service credentials? \n\nIf you cannot view the API details or service credentials, it is likely that you do not have Manager access to the service instance in which the resource was created. Only people with Manager access to the instance can use the service credentials.\n\n\n\n\n\n Can I export the user conversations from the Analytics page? \n\nYou cannot directly export conversations from the conversation page. However, you can use the \/logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [V2 API reference](https:\/\/cloud.ibm.com\/apidocs\/assistant\/assistant-v2listlogs). Or, you can use a Python script to export logs. For more information, see [export_logs_py](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py).\n\n\n\n\n\n Can I change my plan to a Lite plan? \n\nNo, you cannot change from a Trial, Plus, or Standard plan to a Lite plan. And you cannot upgrade from a Trial to a Standard plan.\n\n\n\n\n\n How many Lite plan instances of Watson Assistant can I create? \n\nYou can have only one Lite plan instance of Watson Assistant per resource group.\n\n\n\n\n\n How do I create a webhook?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-faqs"},{"document_id":"ibmcld_13716-0-1670","score":11.618619,"text":"\n\n\n\n\n\n\n  Known limitations \n\nThe Text to Speech service has the following known limitations. These issues apply to service functionality that spans releases on all platforms. For information about known limitations specific to Text to Speech for IBM Cloud Pak for Data version 4.6.x, see [Limitations and known issues in Watson Speech services](https:\/\/www.ibm.com\/docs\/en\/cloud-paks\/cp-data\/4.6.x?topic=issues-watson-speech-services).\n\n\n\n  Issue: The Ogg audio format is not supported with the Safari browser \n\n9 September 2022: By default, the service returns audio in the Ogg audio format with the Opus codec (audio\/ogg;codecs=opus). However, the Ogg audio format is not supported with the Safari browser. If you are using the the Text to Speech service with the Safari browser, you must specify a different format in which you want the service to return the audio.\n\n\n\n*  For more information about the available formats, see [Supported audio formats](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-audio-formatsformats-supported).\n*  For more information about specifying a format, see [Specifying an audio format](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-audio-formatsformats-specify).\n\n\n\n\n\n\n\n  Issue: Sampling rate for ogg format with opus codec is always 48 kHz \n\n22 August 2019: When you specify the audio\/ogg;codecs=opus audio format, you can optionally specify a sampling rate other than the default 48,000 Hz. However, although the service accepts 48000, 24000, 16000, 12000, or 8000 as a valid sampling rate, it currently disregards a specified value and always returns the audio with a sampling rate of 48 kHz.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-known-limitations"},{"document_id":"ibmcld_07214-86173-88123","score":11.561058,"text":"\n: Enrichments from IBM Watson\u2122 Knowledge Studio custom models are not limited, but split documents into 10-kB chunks. No relationships are annotated across chunk boundaries.\n\n\n\n\n\n Query limitations \n\nUpdate : Query concepts [Update](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-concepts)\n\nQuery limitations : Excessive query load can cause the search-index process to restart automatically. : Applications that issue queries must enforce reasonable limits on the number of concurrent queries.\n\n\n\n\n\n\n\n Known issues \n\nUpdates : API Reference [Update: API reference](https:\/\/cloud.ibm.com\/apidocs\/discovery) : Tooling [Update: tooling](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-getting-started) : Data Crawler [Update: Data Crawler](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-adding-content-with-data-crawler) : Enrichments [Update: Enrichments](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-configserviceadding-enrichments) : Adding content [Update: Adding content](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-addcontent)\n\nKnown issues : You cannot delete a document by using the tooling. If you need to delete a document, you must use the API's [Delete a document](https:\/\/cloud.ibm.com\/apidocs\/discoverydelete-a-document) method as described in the API reference. : The API does not currently support getting a list of notices (warnings and error) that are generated during document ingestion. The tooling is therefore unable to show a list of ingestion notices, and there is no easy way to determine which, if any, documents crawled by the Data Crawler failed to be ingested. : Document status information is not always accurate. : If an ingestion operation takes longer than the configured timeout of 10 minutes, the service reports that the document is not known to the service until the ingestion operation completes. After the operation completes, the document status is available and accurate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-release-notes"},{"document_id":"ibmcld_03166-22295-24113","score":11.497139,"text":"\n* [Genesys Cloud](https:\/\/github.com\/watson-developer-cloud\/assistant-web-chat-service-desk-starter\/tree\/main\/src\/genesys\/webChat)\n* [NICE inContact](https:\/\/github.com\/watson-developer-cloud\/assistant-web-chat-service-desk-starter\/tree\/main\/src\/incontact\/webChat)\n* [Twilio Flex](https:\/\/github.com\/watson-developer-cloud\/assistant-web-chat-service-desk-starter\/tree\/main\/src\/flex\/webChat)\n* [Oracle B2C Service](https:\/\/github.com\/watson-developer-cloud\/assistant-web-chat-service-desk-starter\/tree\/main\/src\/oracle\/webChat)\n\n\n\nThe starter kit reference implementations, while functional, are examples only, and have not been vetted for production use. You should perform robust testing before deploying these integrations in production.\n\n\n\n* [Bring your own](https:\/\/github.com\/watson-developer-cloud\/assistant-web-chat-service-desk-starter): A web chat service desk extension starter kit that enables you to develop your own service desk integrations.\n\n\n\nAfter you set up the service desk integration, you must update your dialog to ensure it understands user requests to speak to someone, and can transfer the conversation properly. For more information, see [Adding chat transfer support](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-supportdialog-support-transfers).\n\n\n\n\n\n Web chat integration limits \n\nThe usage is measured differently depending on the plan type. For Lite plans, usage is measured by the number of \/message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chat"},{"document_id":"ibmcld_16334-33767-35711","score":11.493012,"text":"\nYou can use it to check for specific conditions, such as isWebChatOpen, before you perform an action that might rely on the condition being true.\n\n\n\nFor more information about the new methods, see [Instance methods](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-instance-methods).\n\n\n\n\n\n 3.3.2 \n\nRelease date: 17 December 2020\n\n\n\n* Addressed accessibility issues.\n\n\n\n\n\n\n\n 3.3.1 \n\nRelease date: 3 December 2020\n\n\n\n* The translated strings in the [language files](https:\/\/github.com\/watson-developer-cloud\/assistant-web-chat\/tree\/main\/languages) were revised and improved.\n* An error message is shown now if a Java Web Token (JWT) that is provided with an incoming message is invalid. If the first JWT fails when the web chat opens, an error message is displayed in place of the web chat window that says, There was an error communicating with Watson Assistant. If the initial JWT is valid, but the token for a subsequent message is invalid, a more discreet error message is displayed in response to the insecure input.\n* Bug fixes.\n\n\n\n\n\n\n\n 3.3.0 \n\nRelease date: 23 November 2020\n\n\n\n* Added support for passing contextual information to a service desk agent from web chat.\n* You can now customize a user_defined response type. For more information, see the [Custom response type tutorial](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=tutorials-user-defined-response).\n* Bug fixes.\n\n\n\n\n\n\n\n 3.2.1 \n\nRelease date: 2 November 2020\n\n\n\n* Bug fix: Fixing a bug that prevented the web chat integration preview from working after security was enabled.\n\n\n\n\n\n\n\n 3.2.0 \n\nRelease date: 26 October 2020\n\n\n\n* Security improvement: If you enable security, you no longer need to include the identityToken property when the web chat is loaded on a web page. If a token is not initially provided, the existing identityTokenExpired event will be fired when the web chat is first opened to obtain one from your handler.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-release-notes-chat"},{"document_id":"ibmcld_03364-6793-8946","score":11.485968,"text":"\nSee [Log limits](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logslogs-limits) for details.\n\nFor a Python script you can run to export logs and convert them to CSV format, download the export_logs_py.py file from the [Watson Assistant GitHub)](https:\/\/github.com\/watson-developer-cloud\/community\/blob\/master\/watson-assistant\/export_logs_py.py) repository.\n\n\n\n\n\n Understanding logs-related terminology \n\nFirst, review the definitions of terms that are associated with Watson Assistant logs:\n\n\n\n* Assistant: An application - sometimes referred to as a 'chat bot' - that implements your Watson Assistant content.\n* Assistant ID: The unique identifier of an assistant.\n* Conversation: A set of messages consisting of the messages that an individual user sends to your assistant, and the messages your assistant sends back.\n* Conversation ID: Unique identifier that is added to individual message calls to link related message exchanges together. App developers using the V1 version of the Watson Assistant API add this value to the message calls in a conversation by including the ID in the metadata of the context object.\n* Customer ID: A unique ID that can be used to label customer data such that it can be subsequently deleted if the customer requests the removal of their data.\n* Deployment ID: A unique label that app developers using the V1 version of the Watson Assistant API pass with each user message to help identify the deployment environment that produced the message.\n* Instance: Your deployment of Watson Assistant, accessible with unique credentials. A Watson Assistant instance might contain multiple assistants.\n* Message: A message is a single utterance a user sends to the assistant.\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resources"},{"document_id":"ibmcld_13785-5763-7073","score":11.468797,"text":"\n* [Protecting sensitive information in your Watson service](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-keyservice)\n* [Public and private network endpoints](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-public-private-endpoints)\n* [Virtual Private Endpoints](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-virtual-private-endpoints)\n\n\n\n* Service background\n\n\n\n* [The science behind the service](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-science)\n* [Research references](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-references)\n\n\n\n\n\n* Reference\n\n\n\n* [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech)\n* [High availability and disaster recovery](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-ha-dr)\n* [Activity Tracker events](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-at-events)\n* [Watson SDKs](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-using-sdks)\n* [Watson GitHub repos](https:\/\/github.com\/watson-developer-cloud\/)\n\n\n\n* Help\n\n\n\n* [Known limitations](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-known-limitations)\n* [Usage FAQs](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-faq-usage)\n* Developer community","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingHTTP"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02998-8791-9815","score":12.7496,"text":"\nYou created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:\n\n\n\n* Add standard nodes with the [Building a complex dialog](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial) tutorial.\n* Learn about slots with the [Adding a node with slots](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-tutorial-slots) tutorial.\n\n\n\n* Check out more [sample apps](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-sample-apps) to get ideas.\n\n\n\nWhen you're ready to deploy your assistant, see [Deploying](https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-deploy-custom-app).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant-data?topic=assistant-data-getting-started"},{"document_id":"ibmcld_03329-9694-10633","score":11.02985,"text":"\nFor a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can integrate it with web sites or channels, such as Slack, that your customers already use. As traffic increases between the assistant and your customers, you can use the tools that are provided in the Analytics page to analyze real conversations, and identify areas for improvement.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:\n\n\n\n* Add more dialog nodes to design complex conversational exchanges. See [Building a complex dialog](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial).\n* Learn techniques for getting customers to share information that the assistant needs before it can provide a useful response. See [Adding a node with slots](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-slots).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-gs-dialog"},{"document_id":"ibmcld_03406-34893-35432","score":10.927472,"text":"\nIn this tutorial you tested a node with slots and made changes that optimize how it interacts with real users. For more information about this subject, see [Gathering information with slots](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-slots).\n\n\n\n\n\n\n\n Next steps \n\nDeploy your dialog skill by first connecting it to an assistant, and then deploying the assistant. There are several ways you can do this. See [Adding integrations](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-integration-add) for more details.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-tutorial-slots-complex"},{"document_id":"ibmcld_03891-15856-17974","score":10.646836,"text":"\nIf you followed the steps for creating a node from a different console, this would be Console 2.\n\nAfter the ordering node has been successfully added, a new tile with the name of the node will appear on the Ordering nodes page. It will say it \"Requires attention\". This state reflects the fact that, while the node creation process has been successful, the node is not yet part of the consenter set of the system channel. The node must be added to the system channel before it can be added to any of the application channels.\n\nRecall that the \"consenter set\" refers to the ordering service nodes actively participating in the ordering process on a channel, while the \"system channel\", which is managed by the ordering service, forms the template for application channels.\n\nTo add the node you created to the system channel, click on the node. You will see a Add node to ordering service button. Click this button. After the node has been added to the ordering service, the node should now be part of the system channel.\n\nNote that it will take a few minutes for the new node to sync with ordering service in the system channel. During this time, you may see a message that your ordering service is down. This is normal --- the ordering service must come down while the new node is syncing. Any transactions proposed during this time will fail and will have to be resubmitted by the client application.\n\nIf you created this new node and added it to the system channel from a different console (Console 2), you must then export it to the console that originated the ordering service (Console 1). If the new node was added in Console 1, you can skip down to [Adding the node to the application channel](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-add-remove-ordereribp-console-add-remove-orderer-consenters-add).\n\n\n\n\n\n\n\n Console 2: export the Ordering Service_2 node \n\nAfter the Ordering Service_2 node has successfully been created and added to the system channel, Console 2 must export a JSON representing the node to every channel member (in this tutorial, this means exporting it to Console 1).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-add-remove-orderer"},{"document_id":"ibmcld_05171-3109-4618","score":10.478427,"text":"\nGo ahead and create a Docker account online at [Docker hub](https:\/\/hub.docker.com), run the Docker app, and sign in.\n\n\n\n\n\n Installing Node.js \n\nThe app that you build uses [Node.JS](https:\/\/nodejs.org\/) as the server-side engine to run the JavaScript code for this web application. To use the Node Package Manager (npm) to manage your app's dependencies, you must install Node locally. Also, a local installation of Node simplifies testing, speeding up development.\n\nBefore you start, you might consider a version manager, like Node Version Manager, or nvm, to install Node. A version manager reduces the complexity of managing different versions of Node.js.\n\ncurl -o- https:\/\/raw.githubusercontent.com\/nvm-sh\/nvm\/v0.34.0\/install.sh | bash\n\n...or wget (just one is necessary, but not both; use whichever is available on your system):\n\nwget -qO- https:\/\/raw.githubusercontent.com\/nvm-sh\/nvm\/v0.34.0\/install.sh | bash\n\nOr, for Windows, you can use [nvm for Windows](https:\/\/github.com\/coreybutler\/nvm-windows) with installers and source code at the link.\n\nUsing nvm, install Node.\n\nnvm install v6.17.1\n\nWhichever approach you use after you install Node.js and npm (included with Node) on your computer, congratulate yourself on a job well started!\n\n\n\n\n\n Installing Git \n\nYou're probably already familiar with Git, as it's the most widely used source code versioning system. We use Git later when we create a Continuous Deployment (CD) Toolchain in the IBM Cloud Platform for continuous delivery and deployment.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-web-application"},{"document_id":"ibmcld_03871-24729-26603","score":10.453466,"text":"\nMake sure you have either the [Node Test Runner extension](https:\/\/marketplace.visualstudio.com\/items?itemName=oshri6688.javascript-test-runner), [Java Test Runner extension](https:\/\/marketplace.visualstudio.com\/items?itemName=vscjava.vscode-java-test) or [Go extension](https:\/\/marketplace.visualstudio.com\/items?itemName=golang.Go) installed.\n\n\n\nAfter the test file is built, the tests can be run by clicking the Run Tests button in the file.\n\n\n\n\n\n Step six: Connect to your IBM Blockchain Platform network \n\nYou can also use the extension to interact with your network on the IBM Blockchain Platform.\n\n\n\n Invoke a smart contract that has been instantiated or committed on your channels \n\nYou can download your connection profile from the IBM Blockchain Platform console to build a gateway in the Fabric Gateways pane. You can then use the gateway to invoke the smart contracts that were deployed on your channel.\n\nOpen the IBM Blockchain Platform console that is associated with your instance of the IBM Blockchain Platform. Navigate to the Organizations tab and click the Organization MSP tile for the organization that your client application will interact with. Click Create connection profile to open a side panel that allows you to [build and download your connection profile](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-appibp-console-app-profile) to your local file system. Then, [create an application identity](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-appibp-console-app-identities) by using your CA and save the enrollID and secret. Use the following steps to connect to the IBM Blockchain Platform from VS Code.\n\n\n\n1. Open the IBM Blockchain Platform tab.\n2. Hover your mouse over the Fabric Gateways pane and click +.\n3. Choose Create a gateway from a connection profile.\n4. Enter a name for the connection.\n5.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-develop-vscode"},{"document_id":"ibmcld_13144-10995-12568","score":10.378176,"text":"\nClick on the URL under Routes to visit your application. Enter any string for username and password, for instance test:test because the app is running in demonstration mode.\n\n\n\nThe Node.js app has been deployed to Red Hat OpenShift Container Platform. To recap:\n\n\n\n* The \"Example Health\" Node.js application was deployed directly from GitHub into your cluster.\n* The application was examined in the Red Hat OpenShift on IBM Cloud console.\n* A Build Configuration was created - a new commit can be both built and deployed by clicking Start Build in the Builds section of the application details.\n\n\n\n\n\n\n\n\n\n Step 3: Logging and monitoring \n\nIn this section, you will explore the out-of-the-box logging and monitoring capabilities that are offered in Red Hat OpenShift on IBM Cloud.\n\n\n\n Simulate Load on the Application \n\nCreate a script to simulate load.\n\n\n\n1. Make sure you're connected to the project where you deployed your app.\n\noc project example-health\n2. Retrieve the public route to access your application:\n\noc get routes\n\nOutput looks similar to this, note your value for Host:\n\nNAME HOST\/PORT PATH SERVICES PORT TERMINATION WILDCARD\npatient-health-frontend patient-health-frontend-example-health.roks07-872b77d77f69503584da5a379a38af9c-0000.eu-de.containers.appdomain.cloud patient-health-frontend 8080-tcp None\n3. Define a variable with the host:\n\nHOST=$(oc get routes -o json | jq -r '.items[0].spec.host')\n4. Verify access to the application. It outputs patient information:\n\ncurl -s -L http:\/\/$HOST\/info\n\nOutput should look like:\n\n$ curl -s -L http:\/\/$HOST\/info","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-openshift-microservices"},{"document_id":"ibmcld_03916-8219-9928","score":10.376851,"text":"\nThis tutorial focuses on using the High-level Fabric Gateway SDKs.\n\nIBM recommends the High-level Fabric Gateway SDKs which allow client applications to interact with IBM Blockchain Platform networks. These SDKs, available for Node, Java, and Go, allow a client application to invoke smart contracts for the purpose of submitting transactions and evaluating queries. It is recommended that administrative tasks, such as creating channels, deploying smart contracts, are done by using the console, APIs, or Ansible scripts.\n\nThe SDKs use the concept of a \"Gateway\" object to represent the connection of a single identity (user) to a blockchain network. For performance reasons, applications need to keep a gateway object instance in scope for as long as it is required, and can use it to submit multiple transactions across different smart contracts and network channels. If an application needs to handle multiple user identities, then a separate gateway object instance should be maintained for each identity.\n\nRefer to the SDK documentation for each language for details:\n\n\n\n* [Java](https:\/\/hyperledger.github.io\/fabric-gateway-java\/release-2.2\/)\n* [Node](https:\/\/hyperledger.github.io\/fabric-sdk-node\/release-2.2\/)\n* [Go](https:\/\/pkg.go.dev\/github.com\/hyperledger\/fabric-sdk-go\/pkg\/gateway)\n\n\n\nFor best practices and examples of how to use the SDKs see the Fabric [Asset Transfer Sample](https:\/\/github.com\/hyperledger\/fabric-samples\/tree\/master\/asset-transfer-basic)\n\nFor information about migrating your applications created using the v1.4 SDK to the 2.x SDK, check out [Migrating client applications from v1.4 to v2.0](https:\/\/hyperledger.github.io\/fabric-sdk-node\/release-2.2\/tutorial-migration.html).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-app"},{"document_id":"ibmcld_03891-20101-22403","score":10.278397,"text":"\nBecause this tutorial presumes that a user is adding a node to a channel that was created as part of the [Build a network tutorial](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-build-network), the channel the Ordering Service_2 node is being added to, channel1, does not yet have the newly created ordering service organization, Ordering Service2 MSP, as one of the administrators of the channel. While a new ordering node can be added to a channel even if the organization that owns the node is not an administrator of the ordering service, it is a best practice to add the organization that owns the node when you add the node.\n\nBecause you are editing a part of the channel configuration that is governed by ordering service organization admins, you will be asked to send the channel configuration update to an ordering service organization admin to be signed as part of the configuration update process. This organization can be any of the organizations that is an admin of the ordering service, not just one of the organizations that owns one of the consenters that is already in the channel. In this tutorial, that means selecting Ordering Service MSP. Do not select Ordering Service2 MSP here as it is being added as part of this channel configuration update.\n\n\n\n\n\n Add Ordering Service2 MSP to channel1 \n\nTo add an ordering service organization to an application channel, navigate to the channel and click the Settings button. First, specify which peer organization and which peer organization admin is making the update request. If the application channel was created before the ordering organization was added to the system channel, click Ordering service administrator and add Ordering Service2 MSP as an administrator.\n\nIf your console is at a build before 2.1.3-104, you will not see this option. To see the version of your build, click on the support icon in the upper right hand corner (it resembles a question mark). The version will be listed below IBM Blockchain Platform version on the upper left.\n\nAfter the organization has been added, we can add the consenter.\n\nIt is possible to add a node to the consenter and add the MSP of the organization that owns the node as part of the same channel configuration update.\n\n\n\n\n\n Add the node to the application channel","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-add-remove-orderer"},{"document_id":"ibmcld_10841-16431-17955","score":10.232092,"text":"\n[semver](https:\/\/www.npmjs.com\/package\/semver) Semantic Versioning for Node.js. \n [serialize-error](https:\/\/www.npmjs.com\/package\/serialize-error) Serialize an error into a plain object. \n [serve-favicon](https:\/\/www.npmjs.com\/package\/serve-favicon) Node.js middleware for serving a favicon. \n [socket.io](https:\/\/www.npmjs.com\/package\/socket.io) Socket.io enables real-time bidirectional event-based communication. \n [socket.io-client](https:\/\/www.npmjs.com\/package\/socket.io-client) Realtime application framework for socket.io. \n [superagent](https:\/\/www.npmjs.com\/package\/superagent) SuperAgent is a small progressive client-side HTTP request library, and Node.js module with the same API, sporting many high-level HTTP client features. \n [swagger-tools](https:\/\/www.npmjs.com\/package\/swagger-tools) Package that provides various tools for integrating and interacting with Swagger. \n [tmp](https:\/\/www.npmjs.com\/package\/tmp) A simple temporary file and directory creator for Node.js. \n [ts-jest](https:\/\/www.npmjs.com\/package\/ts-jest) A TypeScript preprocessor with source map support for Jest that enables you use Jest to test projects written in TypeScript. \n [twilio](https:\/\/www.npmjs.com\/package\/twilio) A wrapper for the Twilio API, related to voice, video, and messaging. \n [underscore](https:\/\/www.npmjs.com\/package\/underscore) Underscore.js is a utility-belt library for JavaScript that supports the usual functional suspects (each, map, reduce, filter, and so on) without extending any core JavaScript objects.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openwhisk?topic=openwhisk-runtimes"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10510-17837-19983","score":15.00163,"text":"\nWorker nodes carry the deployments and services that make up your app. When you host workloads in the public cloud, you want to ensure that your app is protected from being accessed, changed, or monitored by an unauthorized user or software.\n\n\n\n Who owns the worker node and am I responsible to secure it? \n\nThe ownership of a worker node depends on the type of cluster that you create and the infrastructure provider that you choose.\n\n\n\n* Classic clusters: Worker nodes are provisioned in to your IBM Cloud account. The worker nodes are dedicated to you and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n* VPC clusters: Worker nodes are provisioned in to an IBM Cloud account that is owned by IBM to enable monitoring of malicious activities and apply security updates. You can't access your worker nodes by using the VPC dashboard. However, you can manage your worker nodes by using the IBM Cloud Kubernetes Service console, CLI, or API. The virtual machines that make up your worker nodes are dedicated to you and you are responsible to request timely updates so that your worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n\n\n\nFor more information, see [Your responsibilities by using Red Hat OpenShift on IBM Cloud](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iks).\n\nUse the ibmcloud oc worker update[command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_update) regularly (such as monthly) to deploy updates and security patches to the operating system and to update the Red Hat OpenShift version that your worker nodes run. When updates are available, you are notified when you view information about the master and worker nodes in the IBM Cloud console or CLI, such as with the ibmcloud oc clusters ls or ibmcloud oc workers ls --cluster <cluster_name> commands. Worker node updates are provided by IBM as a full worker node image that includes the latest security patches.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_10463-8360-9835","score":14.798557,"text":"\nkube-dal10-cr18e61e63c6e94b658596ca93d087eed9-w3 169.xx.xxx.xxx 10.176.48.78 u3c.2x4.encrypted normal Ready dal10 1.26_1513\n3. Copy the public IP of the worker node and the node port into your text cheat sheet to use in later lessons.\n4. Verify that you can access the public IP address the worker node through the node port. Note: Because worker nodes in VPC clusters don't have a public IP address, you can access an app through a NodePort only if you are connected to your private VPC network, such as through a VPN connection. Then, you can use the worker node's private IP address and NodePort: <worker_private_IP>:<NodePort>.\n\ncurl --connect-timeout 10 <worker_IP>:<NodePort>\n\nThe following example output confirms that the request to your app came through the private IP address 10.1.1.1 for the worker node and the 31024 node port. The webserver-855556f688-xd849 app pod received the curl request:\n\nHostname: webserver-855556f688-xd849\nPod Information:\n-no pod information available-\nServer values:\nserver_version=nginx: 1.13.3 - lua: 10008\nRequest Information:\nclient_address=1.1.1.1\nmethod=GET\nreal path=\/\nquery=\nrequest_version=1.1\nrequest_scheme=http\nrequest_uri=http:\/\/10.1.1.1:8080\/\nRequest Headers:\naccept=\/\nhost=10.1.1.1:31024\nuser-agent=curl\/7.60.0\nRequest Body:\n-no body in request-\n\n\n\n\n\nAt this point, your app is exposed from multiple IP addresses and ports. Most of these IPs are internal to the cluster and can be accessed only over the private network.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-policy_tutorial"},{"document_id":"ibmcld_06079-10297-12436","score":14.727864,"text":"\nWorker node With IBM Cloud Kubernetes Service, the virtual machines that your cluster manages are instances that are called worker nodes. These worker nodes virtual machines and all the worker node components are dedicated to you only and are not shared with other IBM customers. However, the underlying hardware is shared with other IBM customers. For more information, see [Virtual machines](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesvm). You manage the worker nodes through the automation tools that are provided by IBM Cloud Kubernetes Service, such as the API, CLI, or console. Unlike classic clusters, you don't see VPC compute worker nodes in your infrastructure portal or separate infrastructure bill, but instead manage all maintenance and billing activity for the worker nodes from IBM Cloud Kubernetes Service. Worker nodes include the same [components](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-archworker-components) as described in the Classic architecture. Community Kubernetes worker nodes run on Ubuntu 18.04 x86_64, 16.04 x86_64 (deprecated). \n Cluster networking Your worker nodes are created in a VPC subnet in the zone that you specify. By default, the public and private cloud service endpoints for your cluster are enabled. Communication between the master and worker nodes is over the private network. Authenticated external users can communicate with the master over the public network, such as to run kubectl commands. You can optionally set up your cluster to communicate with on-prem services by setting up a VPC VPN on the private network. \n App networking You can create a Kubernetes LoadBalancer service for your apps in the cluster, which automatically provisions a VPC load balancer in your VPC outside the cluster. The load balancer is multizonal and routes requests for your app through the private NodePorts that are automatically opened on your worker nodes. For more information, see [Exposing apps with VPC load balancers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-lbaas). Calico is used as the cluster networking policy fabric.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch"},{"document_id":"ibmcld_05964-11806-13757","score":14.490631,"text":"\nIf you replace multiple worker nodes at the same time, they are deleted and replaced concurrently, not one by one. Make sure that you have enough capacity in your cluster to reschedule your workloads before you replace worker nodes. \n\n\n\n\n\n\n\n Networking \n\nKeep in mind that the [service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-limitationstech_limits) limitations also apply.\n\n\n\nVPC cluster networking limitations\n\n Category Description \n\n App URL length DNS resolution is managed by the cluster's [virtual private endpoint (VPE)](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-subnetsvpc_basics_vpe), which can resolve URLs up to 130 characters. If you expose apps in your cluster with URLs, such as the Ingress subdomain, ensure that the URLs are 130 characters or fewer. \n Istio managed add-on See [Istio add-on limitations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio-aboutistio_limitations). \n Network speeds [VPC profile network speeds](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profiles) refer to the speeds of the worker node interfaces. The maximum speed available to your worker nodes is 25Gbps. Because IP in IP encapsulation is required for traffic between pods that are on different subnets, data transfer speeds between pods on different subnets might be slower, about half the compute profile network speed. Overall network speeds for apps that you deploy to your cluster depend on the worker node size and application's architecture. \n NodePort You can access an app through a NodePort only if you are connected to your private VPC network, such as through a VPN connection. To access an app from the internet, you must use a VPC load balancer or Ingress service instead. \n Pod network VPC access control lists (ACLs) filter incoming and outgoing traffic for your cluster at the subnet level, and security groups filter incoming and outgoing traffic for your cluster at the worker nodes level.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-limitations"},{"document_id":"ibmcld_05558-22392-24219","score":14.456356,"text":"\nAdd stand-alone worker nodes to the cluster. For bare metal flavors, specify dedicated.\n\nibmcloud ks worker add --cluster <cluster_name_or_ID> --workers <number_of_worker_nodes> --public-vlan <public_VLAN_ID> --private-vlan <private_VLAN_ID> --flavor <flavor> --hardware <shared_or_dedicated>\n5. Verify that the worker nodes are created.\n\nibmcloud ks worker ls --cluster <cluster_name_or_ID>\n\n\n\n\n\n\n\n Installing SGX drivers and platform software on SGX-capable worker nodes \n\nIntel Software Guard Extensions (SGX) is a technology that can protect data-in-use through hardware-based server security. With Intel SGX, you can protect select code and data from disclosure or modification. Through the use of trusted execution environments (TEE), known as enclaves, you can encrypt the pieces of your app memory that contain sensitive data while the data or code is being used. To use Intel SGX, you must install the SGX drivers and platform software on SGX-capable worker nodes. Then, design your app to run in an SGX environment.\n\nZoom\n\n![An example SGX application.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/cc-iks.png)\n\nFigure. Example SGX application set up\n\nWhen you develop a confidential computing application, you must design it in a way that you can segment the information that needs to be encrypted. At runtime, the segmented information is kept confidential through attestation. When a request for information from the segmented code or app data is received, the enclave verifies that the request comes from the part of the application that exists outside of the enclave within the same application before sharing any information. Through the attestation process, information is kept confidential and data leakage is prevented.\n\n\n\n Installing with a script","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-add_workers"},{"document_id":"ibmcld_06057-8483-10325","score":14.352757,"text":"\nWorker nodes <br><br> * Provide worker node patch operating system (OS), version, and security updates.<br> * Fulfill automation requests to update and recover worker nodes.<br><br><br> <br><br> * Use the API, CLI, or console tools to [apply](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) the provided worker node updates that include operating system patches; or to request that worker nodes are rebooted, reloaded, or replaced.<br><br><br> \n Cluster version <br><br> * Provide a suite of tools to automate cluster management, such as the IBM Cloud Kubernetes Service [API](https:\/\/containers.cloud.ibm.com\/global\/swagger-global-api\/\/), [CLI plug-in](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli), and [console](https:\/\/cloud.ibm.com\/kubernetes\/clusters).<br> * Automatically apply Kubernetes master patch OS, version, and security updates.<br> * Make major and minor updates for master nodes available for you to apply.<br> * Provide worker node major, minor, and patch OS, version, and security updates.<br> * Fulfill automation requests to update cluster master and worker nodes.<br><br><br> <br><br> * Use the API, CLI, or console tools to [apply](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) the provided major and minor Kubernetes master updates and major, minor, and patch worker node updates.<br><br><br> \n\n\n\n\n\n\n\n Identity and access management \n\nYou and IBM share responsibilities for controlling access to your IBM Cloud Kubernetes Service instances. For IBM Cloud\u00ae Identity and Access Management responsibilities, consult that product's documentation. You are responsible for identity and access management to your application data.\n\n\n\nTable 4. Responsibilities for identity and access management\n\n Resource IBM responsibilities Your responsibilities","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks"},{"document_id":"ibmcld_10505-8460-10320","score":14.32603,"text":"\nWorker nodes <br><br> * Provide worker node patch operating system (OS), version, and security updates.<br> * Fulfill automation requests to update and recover worker nodes.<br><br><br> <br><br> * Use the API, CLI, or console tools to [apply](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) the provided worker node updates that include operating system patches; or to request that worker nodes are rebooted, reloaded, or replaced.<br><br><br> \n Cluster version <br><br> * Provide a suite of tools to automate cluster management, such as the Red Hat OpenShift on IBM Cloud [API](https:\/\/containers.cloud.ibm.com\/global\/swagger-global-api\/\/), [CLI plug-in](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-cli), and [console](https:\/\/cloud.ibm.com\/kubernetes\/clusters).<br> * Automatically apply Red Hat OpenShift master patch OS, version, and security updates.<br> * Make major and minor updates for master nodes available for you to apply.<br> * Provide worker node major, minor, and patch OS, version, and security updates.<br> * Fulfill automation requests to update cluster master and worker nodes.<br><br><br> <br><br> * Use the API, CLI, or console tools to [apply](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) the provided major and minor Red Hat OpenShift master updates and major, minor, and patch worker node updates.<br><br><br> \n\n\n\n\n\n\n\n Identity and access management \n\nYou and IBM share responsibilities for controlling access to your Red Hat OpenShift on IBM Cloud instances. For IBM Cloud\u00ae Identity and Access Management responsibilities, consult that product's documentation. You are responsible for identity and access management to your application data.\n\n\n\nTable 4. Responsibilities for identity and access management\n\n Resource IBM responsibilities Your responsibilities","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-satellite-responsibilities"},{"document_id":"ibmcld_10527-23624-25627","score":14.28714,"text":"\n: When you run oc get nodes, you might notice that the ROLES of your worker nodes are marked as both master,worker. These nodes are worker nodes in IBM Cloud, and don't include the master components that are managed by IBM. Instead, these nodes are marked as master because they run OpenShift Container Platform components that are required to set up and manage default resources within the cluster, such as the OperatorHub and internal registry.\n\nCluster networking\n: Your worker nodes are created in a VPC subnet in the zone that you specify. Communication between the master and worker nodes is over the private network. If you create a cluster with the public and private cloud service endpoints enabled, authenticated external users can communicate with the master over the public network, such as to run oc commands. If you create a cluster with only the private cloud service endpoints enabled, authenticated external users can communicate with the master over the private network only. You can set up your cluster to communicate with resources in on-premises networks, other VPCs, or classic infrastructure by setting up a VPC VPN, IBM Cloud Direct Link, or IBM Cloud Transit Gateway on the private network.\n\nApp networking\n: Virtual Private Cloud load balancers are automatically created in your VPC outside the cluster for any networking services that you create in your cluster. For example, a VPC load balancer exposes the router services in your cluster by default. Or, you can create a Kubernetes LoadBalancer service for your apps, and a VPC load balancer is automatically generated. VPC load balancers are multizone and route requests for your app through the private node ports that are automatically opened on your worker nodes. If the public and private cloud service endpoints are enabled, the routers and VPC load balancers are created as public by default. If only the private cloud service endpoint is enabled, the routers and VPC load balancers are created as private by default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-service-architecture"},{"document_id":"ibmcld_10488-8451-10309","score":14.281488,"text":"\nWorker nodes <br><br> * Provide worker node patch operating system (OS), version, and security updates.<br> * Fulfill automation requests to update and recover worker nodes.<br><br><br> <br><br> * Use the API, CLI, or console tools to [apply](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) the provided worker node updates that include operating system patches; or to request that worker nodes are rebooted, reloaded, or replaced.<br><br><br> \n Cluster version <br><br> * Provide a suite of tools to automate cluster management, such as the Red Hat OpenShift on IBM Cloud [API](https:\/\/containers.cloud.ibm.com\/global\/swagger-global-api\/\/), [CLI plug-in](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cli), and [console](https:\/\/cloud.ibm.com\/kubernetes\/clusters).<br> * Automatically apply Red Hat OpenShift master patch OS, version, and security updates.<br> * Make major and minor updates for master nodes available for you to apply.<br> * Provide worker node major, minor, and patch OS, version, and security updates.<br> * Fulfill automation requests to update cluster master and worker nodes.<br><br><br> <br><br> * Use the API, CLI, or console tools to [apply](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) the provided major and minor Red Hat OpenShift master updates and major, minor, and patch worker node updates.<br><br><br> \n\n\n\n\n\n\n\n Identity and access management \n\nYou and IBM share responsibilities for controlling access to your Red Hat OpenShift on IBM Cloud instances. For IBM Cloud\u00ae Identity and Access Management responsibilities, consult that product's documentation. You are responsible for identity and access management to your application data.\n\n\n\nTable 4. Responsibilities for identity and access management\n\n Resource IBM responsibilities Your responsibilities","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iks"},{"document_id":"ibmcld_05717-6925-8385","score":14.130133,"text":"\nkubectl apply -f enable-ssh.yaml\n5. Use the private or public network to access the worker node by using your SSH key.\n\n\n\n\n\n Private network \n\nCreate a new or choose an existing server instance that has access to the same private network as the worker node. For VPC clusters, the [virtual server instance](https:\/\/cloud.ibm.com\/vpc-ext\/compute\/vs) must exist in the same VPC as the worker node.\n\nFor classic clusters, the [device](https:\/\/cloud.ibm.com\/gen1\/infrastructure\/devices) can access the worker node from any private VLAN if a [Virtual Router Function (VRF)](https:\/\/cloud.ibm.com\/docs\/account?topic=account-vrf-service-endpointvrf) or [VLAN spanning](https:\/\/cloud.ibm.com\/docs\/vlans?topic=vlans-vlan-spanningvlan-spanning) is enabled. Otherwise, the device must exist on the same private VLAN as the worker node.\n\n\n\n1. Copy your SSH private key from step 1 from your local machine to this server instance.\n\nscp <SSH_private_key_location> <user@host>:\/.ssh\/id_rsa_worker_private\n2. SSH into the server instance.\n3. Set the correct permissions for using the SSH private key that you copied.\n\nchmod 400 \/.ssh\/id_rsa_worker_private\n4. Use the private key to SSH into the worker node that you found in step 2.\n\nssh -i \/.ssh\/id_rsa_worker_private root@<WORKER_PRIVATE_IP>\n\n\n\n\n\n\n\n Public network classic clusters that are connected to a public VLAN only \n\nDebug classic clusters that are connected to a public VLAN by logging in to your worker nodes.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ssh_worker"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.703918089,"ndcg_cut_10":0.703918089}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_06007-1457-3349","score":13.805211,"text":"\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone. After the worker node is provisioned, the worker node IP address persists after a reboot operation, but the worker node IP address changes after replace and update operations.\n\nSubnets provide a channel for connectivity among the worker nodes within the cluster. Additionally, any system that is connected to any of the private subnets in the same VPC can communicate with workers. For example, all subnets in one VPC can communicate through private layer 3 routing with a built-in VPC router. If you have multiple clusters that must communicate with each other, you can create the clusters in the same VPC. However, if your clusters don't need to communicate, you can achieve better network segmentation by creating the clusters in separate VPCs. You can also create [access control lists (ACLs)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-acls) for your VPC subnets to mediate traffic on the private network. ACLs consist of inbound and outbound rules that define which ingress and egress is permitted for each VPC subnet.\n\nIf your worker nodes must access a public endpoint outside of the cluster, you can enable a public gateway on the VPC subnet that the worker nodes are deployed to. A public gateway can be attached to or detached from a subnet at any time.\n\nThe default IP address range for VPC subnets is 10.0.0.0 \u2013 10.255.255.255.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basics"},{"document_id":"ibmcld_06007-7-1994","score":13.714441,"text":"\nUnderstanding network basics of VPC clusters \n\nWhen you create your cluster, you must choose a networking setup so that certain cluster components can communicate with each other and with networks or services outside of the cluster.\n\n\n\n* [Worker-to-worker communication](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-worker-worker): All worker nodes must be able to communicate with each other on the private network through VPC subnets.\n* [Worker-to-master and user-to-master communication](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-workeruser-master): Your worker nodes and your authorized cluster users can communicate with the Kubernetes master securely over virtual private endpoints or cloud service endpoints.\n* [Worker communication to other services or networks](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-worker-services-onprem): Allow your worker nodes to securely communicate with other IBM Cloud services, such as IBM Cloud\u00ae Container Registry, to on-premises networks, to other VPCs, or to classic infrastructure resources.\n* [External communication to apps that run on worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basicsvpc-external-workers): Allow public or private requests into the cluster as well as requests out of the cluster to a public endpoint.\n\n\n\n\n\n Worker-to-worker communication using VPC subnets \n\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basics"},{"document_id":"ibmcld_10442-1449-3496","score":13.704302,"text":"\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone. After the worker node is provisioned, the worker node IP address persists after a reboot operation, but the worker node IP address changes after replace and update operations.\n\nSubnets provide a channel for connectivity among the worker nodes within the cluster. Additionally, any system that is connected to any of the private subnets in the same VPC can communicate with workers. For example, all subnets in one VPC can communicate through private layer 3 routing with a built-in VPC router. If you have multiple clusters that must communicate with each other, you can create the clusters in the same VPC. However, if your clusters don't need to communicate, you can achieve better network segmentation by creating the clusters in separate VPCs. You can also create [access control lists (ACLs)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-acls) for your VPC subnets to mediate traffic on the private network. ACLs consist of inbound and outbound rules that define which ingress and egress is permitted for each VPC subnet.\n\nWhen you create a VPC cluster and enable both the public and private cloud service endpoints during cluster creation, the public cloud service endpoint is used by default for access to components such as the Red Hat OpenShift web console for your cluster. In order for console pods to establish a secure, public connection over the internet through the public service endpoint, you must enable a public gateway on each VPC subnet that your worker nodes are deployed to.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basics"},{"document_id":"ibmcld_05858-3083-5003","score":13.602265,"text":"\nCluster networking Unlike classic infrastructure, the worker nodes of your VPC cluster are attached to VPC subnets and assigned private IP addresses. The worker nodes are not connected to the public network, which instead is accessed through a public gateway, floating IP, or VPN gateway. For more information, see [Overview of VPC networking in IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-subnetsvpc_basics). \n Apps and container platform You can choose to create [community Kubernetes or Red Hat OpenShift clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqscontainer_platforms) to manage your containerized apps. Your app build processes don't differ because of the infrastructure provider, but how you expose the app does. For more information, see [Choosing an app exposure service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_network_planning). \n App networking All pods that are deployed to a worker node are assigned a private IP address in the 172.30.0.0\/16 range and are routed between worker nodes on the worker node private IP address of the private VPC subnet. To expose the app on the public network, you can create a Kubernetes LoadBalancer service, which provisions a VPC load balancer and public hostname address for your worker nodes. For more information, see [Exposing apps with VPC load balancers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-lbaas). \n Storage For persistent storage, use [block](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-block). For the number of volumes that can be attached per worker node, see [Volume attachment limits](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-attaching-block-storagevol-attach-limits). The storage class limits the volume size to 20TB and IOPS capacity to 20,000. For non-persistent storage, secondary storage on the local worker node is not available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers"},{"document_id":"ibmcld_10442-7-1871","score":13.582558,"text":"\nUnderstanding network basics of VPC clusters \n\nWhen you create your cluster, you must choose a networking setup so that certain cluster components can communicate with each other and with networks or services outside of the cluster.\n\n\n\n* [Worker-to-worker communication](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basicsvpc-worker-worker): All worker nodes must be able to communicate with each other on the private network through VPC subnets.\n* [Worker-to-master and user-to-master communication](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basicsvpc-workeruser-master): Your worker nodes and your authorized cluster users can communicate with the Kubernetes master securely over virtual private endpoints or cloud service endpoints.\n* [Worker communication to other services or networks](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basicsvpc-worker-services-onprem): Allow your worker nodes to securely communicate with other IBM Cloud services, such as IBM Cloud\u00ae Container Registry, to on-premises networks, to other VPCs, or to classic infrastructure resources.\n* [External communication to apps that run on worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basicsvpc-external-workers): Allow public or private requests into the cluster as well as requests out of the cluster to a public endpoint.\n\n\n\n\n\n Worker-to-worker communication using VPC subnets \n\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basics"},{"document_id":"ibmcld_06063-18145-20200","score":13.533666,"text":"\n* VPC clusters: Worker nodes are provisioned in to an IBM Cloud account that is owned by IBM to enable monitoring of malicious activities and apply security updates. You can't access your worker nodes by using the VPC dashboard. However, you can manage your worker nodes by using the IBM Cloud Kubernetes Service console, CLI, or API. The virtual machines that make up your worker nodes are dedicated to you and you are responsible to request timely updates so that your worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches.\n\n\n\nFor more information, see [Your responsibilities by using IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks).\n\nUse the ibmcloud ks worker update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_update) regularly (such as monthly) to deploy updates and security patches to the operating system and to update the Kubernetes version that your worker nodes run. When updates are available, you are notified when you view information about the master and worker nodes in the IBM Cloud console or CLI, such as with the ibmcloud ks clusters ls or ibmcloud ks workers ls --cluster <cluster_name> commands. Worker node updates are provided by IBM as a full worker node image that includes the latest security patches. To apply the updates, the worker node must be reimaged and reloaded with the new image. Keys for the root user are automatically rotated when the worker node is reloaded.\n\n\n\n\n\n How does my worker node setup look? \n\nThe following image shows the components that are set up for every worker node to protect your worker node from malicious attacks.\n\nThe image does not include components that ensure secure end-to-end communication to and from the worker node. For more information, see [network security](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork).\n\nZoom\n\n![Worker node setup in IBM Cloud Kubernetes Service excluding network security.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_05653-99788-101413","score":13.530203,"text":"\n: You can now create VPC clusters in the Sao Paulo, Brazil [location](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zones).\n\nVPC disk encryption on worker nodes\n: Now, you can manage the encryption for the disk on your VPC worker nodes. For more information, see [VPC worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryptionworker-encryption-vpc).\n\n\n\n\n\n 30 August 2021 \n\nReview the release notes for 30 August 2021.\n\nWorker node fix pack update\n: Change log documentation is available for version [1.17.17_1568](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-117_changelog11717_1568), [1.18.20_1563](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-118_changelog11820_1563), [1.19.14_1558](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_11911914_1558), [1.20.10_1551](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_12012010_1551), and [1.21.4_1529](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog_12112104_1529).\n\n\n\n\n\n 25 August 2021 \n\nNew! Create a cluster with a template\n: No longer do you have to manually specify the networking and worker node details to create a cluster, or enable security integrations such as logging and monitoring after creation. Instead, you can try out the technical preview to create a multizone cluster with nine worker nodes and encryption, logging, and monitoring already enabled. For more information, see [Creating a cluster by using an IBM Cloud Schematics template](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-templates&interface=ui).\n\nIBM Cloud Object Storage plug-in","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-containers-relnotes"},{"document_id":"ibmcld_10691-9697-11578","score":13.414572,"text":"\nVirtual private endpoints (VPE) \n\nWorker nodes can communicate with the Kubernetes master through the cluster's [virtual private endpoint (VPE)](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpe).\n\nA VPE is a virtual IP address that is bound to an endpoint gateway. One VPE gateway resource is created per cluster in your VPC. One IP address from one subnet in each zone where your cluster has worker nodes is automatically used for the VPE gateway, and the worker nodes in this zone use this IP address to communicate with the Kubernetes master. To view the VPE gateway details for your cluster, open the [Virtual private endpoint gateways for VPC dashboard](https:\/\/cloud.ibm.com\/vpc-ext\/network\/endpointGateways) and look for the VPE gateway in the format iks-<cluster_ID>.\n\nNote that your worker nodes automatically use the VPE that is created by default in your VPC. However, if you enabled the [public cloud service endpoint for your cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basicsvpc-workeruser-master), worker-to-master traffic is established half over the public endpoint and half over the VPE for protection from potential outages of the public or private network.\n\nDo not delete any IP addresses on your subnets that are used for VPEs.\n\n\n\n\n\n Network segmentation \n\nNetwork segmentation describes the approach to divide a network into multiple sub-networks. Apps that run in one sub-network can't see or access apps in another sub-network. For more information about network segmentation options for VPC subnets, see [this cluster security topic](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitynetwork_segmentation_vpc).\n\nSubnets provide a channel for connectivity among the worker nodes within the cluster. Additionally, any system that is connected to any of the private subnets in the same VPC can communicate with workers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-subnets"},{"document_id":"ibmcld_10444-2675-4364","score":13.166395,"text":"\nVPC clusters can be provisioned as standard clusters on shared [virtual](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodesvm) worker nodes only, and must be created in one of the supported [multizone locations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zoneszones-vpc). Free VPC clusters are not supported.\n\nVPC clusters can be provisioned using virtual worker nodes on standard infrastructure or dedicated hosts. Free VPC clusters are not supported.\n\n\n\n\n\n Can I combine different flavors in a cluster? \n\nYes. To add different flavors to your cluster, you must [create another worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-clics_worker_pool_create). You can't resize existing worker pools to have different compute resources such as CPU or memory.\n\n\n\n\n\n How can I change worker node flavors? \n\nSee [updating flavors](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemachine_type).\n\n\n\n\n\n Are the worker nodes encrypted? \n\nThe secondary disk of the worker node is encrypted. For more information, see [Overview of cluster encryption](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-encryptionencrypt_ov). After you create a worker pool, you might notice that the worker node flavor has .encrypted in the name, such as b3c.4x16.encrypted.\n\n\n\n\n\n How do I manage my worker nodes? \n\nWorker nodes in classic clusters are provisioned into your IBM Cloud account. You can manage your worker nodes by using Red Hat OpenShift on IBM Cloud, but you can also use the [classic infrastructure dashboard](https:\/\/cloud.ibm.com\/classic\/) in the IBM Cloud console to work with your worker node directly.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-planning_worker_nodes"},{"document_id":"ibmcld_10235-1083-2772","score":13.139148,"text":"\nClusters with public network connectivity: [Multiple clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha_clustersmultiple-clusters-glb) that are set up across zones or regions and that are connected via a global load balancer.\n\n\n\n\n\n Single zone clusters \n\nSingle zone clusters can be created in one of the supported [single zone locations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zoneszones-sz). To improve availability for your app and to allow failover for the case that one worker node is not available in your cluster, add additional worker nodes to your single zone cluster.\n\nVPC clusters are supported only in [multizone metro locations](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zoneszones-vpc). If your cluster must reside in one of the single zone cities, create a classic cluster instead.\n\nZoom\n\n![High availability for clusters in a single zone.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/openshift\/images\/ha-cluster-singlezone.svg)\n\nFigure 1. High availability for clusters in a single zone\n\nYou can add more worker nodes to your cluster by [resizing an existing worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersresize_pool) or by [adding a new worker pool](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersadd_pool). When you add more worker nodes, app instances can be distributed across multiple worker nodes. If one worker node goes down, app instances on available worker nodes continue to run. Red Hat OpenShift automatically reschedules pods from unavailable worker nodes to ensure performance and capacity for your app.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha_clusters"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13115-3024-4814","score":13.758169,"text":"\nA minimal cluster with one (1) zone, one (1) worker node and the smallest available size (Flavor) is sufficient for this tutorial. The name mycluster will be used in this tutorial.\n\nOpen the [Kubernetes clusters](https:\/\/cloud.ibm.com\/kubernetes\/clusters) and click Create cluster. See the documentation referenced below for more details based on the cluster type. Summary:\n\n\n\n* Click Standard tier cluster\n* For Kubernetes on VPC infrastructure see reference documentation[Creating VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2&interface=ui).\n\n\n\n* Click Create VPC:\n\n\n\n* Enter a name for the VPC.\n* Chose the same resource group as the cluster.\n* Click Create.\n\n\n\n* Attach a Public Gateway to each of the subnets that you create:\n\n\n\n* Navigate to the [Virtual private clouds](https:\/\/cloud.ibm.com\/vpc-ext\/network\/vpcs).\n* Click the previously created VPC used for the cluster.\n* Scroll down to subnets section and click a subnet.\n* In the Public Gateway section, click Detached to change the state to Attached.\n* Click the browser back button to return to the VPC details page.\n* Repeat the previous three steps to attach a public gateway to each subnet.\n\n\n\n\n\n* For Kubernetes on Classic infrastructure see reference documentation [Creating classic cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-classic&interface=ui).\n* Choose a resource group.\n* Uncheck all zones except one.\n* Scale down to 1 Worker nodes per zone.\n* Choose the smallest Worker Pool flavor.\n* Enter a Cluster name.\n* Click Create.\n\n\n\n\n\n\n\n Step 2: Deploy and configure a Kubernetes app to forward logs \n\nThe ready-to-run [code for the logging app is located in this GitHub repository](https:\/\/github.com\/IBM-Cloud\/application-log-analysis).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-application-log-analysis"},{"document_id":"ibmcld_05819-1301-3152","score":13.657173,"text":"\nGive your cluster a unique name, such as mycluster-free.\n4. Select a resource group to create the cluster in, such as default.\n5. In the Summary pane, review the order summary and then click Create. A worker pool is created that contains one worker node in the default resource group.\n\n\n\nThe worker node can take a few minutes to provision, but you can see the progress in the Worker nodes tab. When the status reaches Ready, you can start working with your cluster by [deploying your first app](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-starteddeploy-app)!\n\n\n\n\n\n Creating a VPC cluster in the IBM Cloud console \n\nCreate a standard VPC cluster by using the IBM Cloud console. For more detailed information about your cluster customization options, see [Creating a standard VPC cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2&interface=ui).\n\nVPC clusters can be created as standard clusters only, and as such incur costs. Be sure to review the order summary at the end of this tutorial to review the costs for your cluster. To keep your costs to a minimum, set up your cluster as a single zone cluster with one worker node only.\n\n\n\n1. Create a Virtual Private Cloud (VPC) on generation 2 compute.\n\n\n\n1. Navigate to the [VPC create console](https:\/\/cloud.ibm.com\/vpc\/provision\/vpc).\n2. Give the VPC a name and select a resource group to deploy the VPC into.\n3. Give the VPC subnet a name and select the location where you want to create the cluster.\n4. Attach a public gateway to your subnet so that you can access public endpoints from your cluster. This public gateway is used later on to access container images from Docker Hub.\n5. Click Create virtual private cloud.\n\n\n\n2. From the [IBM Cloud Kubernetes Service dashboard](https:\/\/cloud.ibm.com\/kubernetes\/clusters), click Create cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-getting-started"},{"document_id":"ibmcld_16098-2598-4239","score":13.59368,"text":"\nThis tutorial creates a cluster that runs version 1.26.\n\n\n\n\n\n\n\n Step 1: Create a cluster in VPC \n\nCreate an IBM Cloud Kubernetes Service cluster in your IBM Cloud Virtual Private Cloud (VPC) environment. For more information about VPC, see [Getting Started with Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started).\n\n\n\n1. Log in to the account, resource group, and IBM Cloud region where you want to create your VPC environment. The VPC must be set up in the same multizone metro location where you want to create your cluster. In this tutorial you create a VPC in us-south. For other supported regions, see [Multizone metros for VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zoneszones-vpc). If you have a federated ID, include the --sso option.\n\nibmcloud login -r us-south [-g <resource_group>] [--sso]\n2. Create a VPC for your cluster. For more information, see the docs for creating a VPC in the [console](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-the-ibm-cloud-console) or [CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-vpc-resources-with-cli-and-api&interface=clicreate-a-vpc-cli).\n\n\n\n1. Create a VPC called myvpc and note the ID in the output. VPCs provide an isolated environment for your workloads to run within the public cloud. You can use the same VPC for multiple clusters, such as if you plan to have different clusters host separate microservices that need to communicate with each other. If you want to separate your clusters, such as for different departments, you can create a VPC for each cluster.\n\nibmcloud is vpc-create myvpc\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc_ks_tutorial"},{"document_id":"ibmcld_06294-2598-4239","score":13.59368,"text":"\nThis tutorial creates a cluster that runs version 1.26.\n\n\n\n\n\n\n\n Step 1: Create a cluster in VPC \n\nCreate an IBM Cloud Kubernetes Service cluster in your IBM Cloud Virtual Private Cloud (VPC) environment. For more information about VPC, see [Getting Started with Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-started).\n\n\n\n1. Log in to the account, resource group, and IBM Cloud region where you want to create your VPC environment. The VPC must be set up in the same multizone metro location where you want to create your cluster. In this tutorial you create a VPC in us-south. For other supported regions, see [Multizone metros for VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zoneszones-vpc). If you have a federated ID, include the --sso option.\n\nibmcloud login -r us-south [-g <resource_group>] [--sso]\n2. Create a VPC for your cluster. For more information, see the docs for creating a VPC in the [console](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-a-vpc-using-the-ibm-cloud-console) or [CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-creating-vpc-resources-with-cli-and-api&interface=clicreate-a-vpc-cli).\n\n\n\n1. Create a VPC called myvpc and note the ID in the output. VPCs provide an isolated environment for your workloads to run within the public cloud. You can use the same VPC for multiple clusters, such as if you plan to have different clusters host separate microservices that need to communicate with each other. If you want to separate your clusters, such as for different departments, you can create a VPC for each cluster.\n\nibmcloud is vpc-create myvpc\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc_ks_tutorial"},{"document_id":"ibmcld_06294-7-1823","score":13.516701,"text":"\nCreating a cluster in your Virtual Private Cloud (VPC) \n\nCreate an IBM Cloud\u00ae Kubernetes Service cluster in your Virtual Private Cloud (VPC).\n\nWith IBM Cloud Kubernetes Service clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc). VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of IBM Cloud Kubernetes Service [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality. You can create only standard clusters for VPC.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create an IBM Cloud Kubernetes Service cluster in a Virtual Private Cloud (VPC). Then, you deploy an app and expose the app publicly by using a load balancer.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in IBM Cloud Kubernetes Service in VPC for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.\n\nPermissions\n: If you are the account owner, you already have the required permissions to create a cluster and can continue to the next step. Otherwise, ask the account owner to [set up the API key and assign you the minimum user permissions in IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_referencecluster_create_permissions).\n\nCommand-line tools\n: For quick access to your resources from the command line, try the [IBM Cloud Shell](https:\/\/cloud.ibm.com\/shell). Otherwise, set up your local command-line environment by completing the following steps.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc_ks_tutorial"},{"document_id":"ibmcld_16098-7-1823","score":13.516701,"text":"\nCreating a cluster in your Virtual Private Cloud (VPC) \n\nCreate an IBM Cloud\u00ae Kubernetes Service cluster in your Virtual Private Cloud (VPC).\n\nWith IBM Cloud Kubernetes Service clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-about-vpc). VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of IBM Cloud Kubernetes Service [infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality. You can create only standard clusters for VPC.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create an IBM Cloud Kubernetes Service cluster in a Virtual Private Cloud (VPC). Then, you deploy an app and expose the app publicly by using a load balancer.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in IBM Cloud Kubernetes Service in VPC for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.\n\nPermissions\n: If you are the account owner, you already have the required permissions to create a cluster and can continue to the next step. Otherwise, ask the account owner to [set up the API key and assign you the minimum user permissions in IBM Cloud IAM](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-access_referencecluster_create_permissions).\n\nCommand-line tools\n: For quick access to your resources from the command line, try the [IBM Cloud Shell](https:\/\/cloud.ibm.com\/shell). Otherwise, set up your local command-line environment by completing the following steps.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc_ks_tutorial"},{"document_id":"ibmcld_10087-31644-32957","score":13.300406,"text":"\nFor more ideas of what to do with your cluster, review the [Next steps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-clustersnext_steps).\n\n\n\n\n\n Example commands to create VPC clusters \n\nVPC Gen 2 cluster flavors with instance storage are available for allowlisted accounts. To get added to the allowlist, [open a case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) with support.\n\nibmcloud oc cluster create vpc-gen2 --name my_cluster --version 4.11_openshift --zone us-east-1 --vpc-id <VPC_ID> --subnet-id <VPC_SUBNET_ID> --cos-instance <COS_CRN>--flavor bx2.4x16 --workers 3\n\nFor a VPC multizone cluster, after you created the cluster in a [multizone metro](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zoneszones-vpc), [add zones](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersvpc_add_zone).\n\nibmcloud oc zone add vpc-gen2 --zone <zone> --cluster <cluster_name_or_ID> --worker-pool <pool_name> --subnet-id <VPC_SUBNET_ID>\n\nVPC cluster provisioned at version 4.9 with worker nodes that run the RHEL 8 operating system. For a complete list of available RHEL versions and which cluster versions they are compatible with, see [Available Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versionsopenshift_versions_available).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2"},{"document_id":"ibmcld_10088-31657-32970","score":13.300406,"text":"\nFor more ideas of what to do with your cluster, review the [Next steps](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-clustersnext_steps).\n\n\n\n\n\n Example commands to create VPC clusters \n\nVPC Gen 2 cluster flavors with instance storage are available for allowlisted accounts. To get added to the allowlist, [open a case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form) with support.\n\nibmcloud oc cluster create vpc-gen2 --name my_cluster --version 4.11_openshift --zone us-east-1 --vpc-id <VPC_ID> --subnet-id <VPC_SUBNET_ID> --cos-instance <COS_CRN>--flavor bx2.4x16 --workers 3\n\nFor a VPC multizone cluster, after you created the cluster in a [multizone metro](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zoneszones-vpc), [add zones](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workersvpc_add_zone).\n\nibmcloud oc zone add vpc-gen2 --zone <zone> --cluster <cluster_name_or_ID> --worker-pool <pool_name> --subnet-id <VPC_SUBNET_ID>\n\nVPC cluster provisioned at version 4.9 with worker nodes that run the RHEL 8 operating system. For a complete list of available RHEL versions and which cluster versions they are compatible with, see [Available Red Hat OpenShift versions](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versionsopenshift_versions_available).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cluster-create-vpc-gen2&interface=ui"},{"document_id":"ibmcld_06007-1457-3349","score":13.268828,"text":"\nBefore you create a VPC cluster for the first time, you must [create a VPC subnet](https:\/\/cloud.ibm.com\/vpc\/provision\/network) in each zone where you want to deploy worker nodes. A VPC subnet is a specified private IP address range (CIDR block) and configures a group of worker nodes and pods as if they are attached to the same physical wire.\n\nWhen you create a cluster, you specify an existing VPC subnet for each zone. Each worker node that you add in a cluster is deployed with a private IP address from the VPC subnet in that zone. After the worker node is provisioned, the worker node IP address persists after a reboot operation, but the worker node IP address changes after replace and update operations.\n\nSubnets provide a channel for connectivity among the worker nodes within the cluster. Additionally, any system that is connected to any of the private subnets in the same VPC can communicate with workers. For example, all subnets in one VPC can communicate through private layer 3 routing with a built-in VPC router. If you have multiple clusters that must communicate with each other, you can create the clusters in the same VPC. However, if your clusters don't need to communicate, you can achieve better network segmentation by creating the clusters in separate VPCs. You can also create [access control lists (ACLs)](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-vpc-acls) for your VPC subnets to mediate traffic on the private network. ACLs consist of inbound and outbound rules that define which ingress and egress is permitted for each VPC subnet.\n\nIf your worker nodes must access a public endpoint outside of the cluster, you can enable a public gateway on the VPC subnet that the worker nodes are deployed to. A public gateway can be attached to or detached from a subnet at any time.\n\nThe default IP address range for VPC subnets is 10.0.0.0 \u2013 10.255.255.255.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_vpc_basics"},{"document_id":"ibmcld_06294-3784-5599","score":13.236614,"text":"\nCreate a VPC called myvpc and note the ID in the output. VPCs provide an isolated environment for your workloads to run within the public cloud. You can use the same VPC for multiple clusters, such as if you plan to have different clusters host separate microservices that need to communicate with each other. If you want to separate your clusters, such as for different departments, you can create a VPC for each cluster.\n\nibmcloud is vpc-create myvpc\n2. Create a subnet for your VPC, and note its ID. Consider the following information when you create the VPC subnet:\n\n\n\n* Zones: You must have one VPC subnet for each zone in your cluster. The available zones depend on the metro location that you created the VPC in. To list available zones in the region, run ibmcloud is zones.\n* IP addresses: VPC subnets provide private IP addresses for your worker nodes and load balancer services in your cluster, so make sure to [create a subnet with enough IP addresses](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc-subnetsvpc_basics_subnets), such as 256. You can't change the number of IP addresses that a VPC subnet has later.\n* Public gateways: You don't need to attach a public gateway to complete this tutorial. Instead, you can keep your worker nodes isolated from public access by using VPC load balancers to expose workloads securely. You might attach a public gateway if your worker nodes need to access a public URL. For more information, see [Planning your cluster network setup](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_clusters).\n\n\n\nibmcloud is subnet-create mysubnet1 <vpc_ID> --zone us-south-1 --ipv4-address-count 256\n\n\n\n3. Create a cluster in your VPC in the same zone as the subnet. By default, your cluster is created with a public and a private cloud service endpoint.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc_ks_tutorial"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12104-9776-11234","score":13.6081,"text":"\nSoftware deployments with Schematics\n\n\n\n1. Choose a template: The [IBM software solutions catalog](https:\/\/cloud.ibm.com\/catalogsoftware) offers a wide variety of infrastructure and software templates that you can choose from. These templates help to quickly install software, such as IBM Cloud Paks, IBM\u00ae WebSphere Application Server for IBM Cloud\u00ae, or Kibana and Grafana into the target service of your choice.\n2. Configure your workspace and target: When you choose one of the provided templates, you must select the target where you want to install the template. Depending on the template that you choose, the target can be an IBM Cloud Kubernetes Service cluster, a Red Hat OpenShift on IBM Cloud cluster, or a classic or Virtual Servers for VPC. Because Schematics is used to install the software, you must configure the workspace that is automatically created for you.\n3. Run the template: When you run the template, Schematics uses the built-in Terraform, Ansible, Helm, OpenShift Operator, or Cloud Pak capabilities to install your software or spin up infrastructure resources. You can use your workspace to monitor the progress of your template execution.\n\n\n\n\n\n\n\n Next steps \n\n\n\n* Explore blueprint samples by using Schematics [tutorials](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-provisioning-terraform-template).\n* Click [here](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-how-it-works) to revisit the Schematics use cases.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-how-it-works"},{"document_id":"ibmcld_12581-17606-19704","score":13.487637,"text":"\nIf you are validating a deployable architecture that references modules from the catalog, make sure that the modules were onboarded to the catalog.\n\n\n\n1. From the Validate version page, enter the name of your Schematics service, select a resource group, select a Schematics region, and click Next.\n\nIn the Tags field, you can enter a name of a specific tag to attach to your template. This tag is put on the IBM Cloud Schematics workspace. Tags provide a way to organize, track usage costs, and manage access to the resources in your account.\n2. From the input variables section, review your parameter values, and click Next.\n3. In the Validation version section, select I have read and agree to the following license agreements.\n4. Click Validate.\n\nTo monitor the progress of the validation process, click View logs.\n\n\n\n\n\n\n\n Validating a test deployment by using the CLI \n\nTo validate a version of your deployable architecture into an existing product, run the [ibmcloud catalog offering version validate](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-manage-catalogs-pluginvalidate-offering) command:\n\nibmcloud catalog offering version validate --vl <VERSION_LOCATOR>\n\n\n\n\n\n Reviewing cost by using the CLI \n\nReview the cost of your deployable architecture by using the console. To view the steps, see [Reviewing or defining cost by using the console](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-onboard-custom&interface=uicustom-cost-ui).\n\n\n\n\n\n Reviewing or defining cost by using the console \n\nYou can review the estimated starting cost of your product. If you included the resource metadata in your source repository, the information is parsed during validation and pulled into a starting cost per hour (USD) summary table. The table is displayed in the catalog for customers to compare across variations of a deployable architecture or to get a general idea of what a base configuration of your deployable architecture might cost.\n\nThe summary table lists the resources that your product uses and their estimated costs. Starting cost is an estimate based on available data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-onboard-custom"},{"document_id":"ibmcld_12104-8356-10191","score":12.732912,"text":"\nBrowse the [IBM software solutions catalog](https:\/\/cloud.ibm.com\/catalogsoftware) and choose among a wide range of software and infrastructure templates that you can use to set up cloud resources, and to install IBM and Third party software in your IBM Cloud Kubernetes Service cluster, Red Hat OpenShift on IBM Cloud cluster, or a classic or Virtual Servers for VPC.\n\nSoftware templates are installed by using the built-in Terraform, Ansible, Helm, Red Hat OpenShift on IBM Cloud Operator, and Cloud Pak capabilities in Schematics. When you choose to install one of the provided templates, you create a Schematics Workspaces and choose the target service or host where you want run the installation. You can review which of the integrated technologies in Schematics is used to install your template.\n\nYou can also create your own software and infrastructure templates and import them in to your own private catalog in IBM Cloud. For more information, see [Adding products to a private catalog](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-private-catalog)\n\nTo get started with software deployment in Schematics, see the [Getting started tutorial](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-get-started-software).\n\nZoom\n\n![Software deployments with Schematics](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ba89e173287b28d1453d2a327d8a1f74ae2f1662\/schematics\/images\/software_flow.png)\n\nFigure 3. Software deployments with Schematics\n\n\n\n1. Choose a template: The [IBM software solutions catalog](https:\/\/cloud.ibm.com\/catalogsoftware) offers a wide variety of infrastructure and software templates that you can choose from. These templates help to quickly install software, such as IBM Cloud Paks, IBM\u00ae WebSphere Application Server for IBM Cloud\u00ae, or Kibana and Grafana into the target service of your choice.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-how-it-works"},{"document_id":"ibmcld_11951-3-1851","score":12.466825,"text":"\nIBM Cloud Schematics docs \n\nExplore the capabilities of IBM Cloud Schematics. You can get started with deploying platform services by using Schematics Workspaces, and automating cloud operations with Schematics Actions. Learn more about how Schematics works and the benefits of using the service.\n\n Developer tools \n\n[API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/schematics)[CLI reference](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-schematics-cli-reference)[Terraform reference](https:\/\/registry.terraform.io\/providers\/IBM-Cloud\/ibm\/latest\/docs\/resources\/schematics_action)\n\n Recommended content \n\n[Automate cloud operations with actions Learn how to automatically start and stop a Virtual Servers for VPC instance with an IBM-provided Ansible playbook.](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-getting-started-ansible)[Extend provisioning through Agents Learn how to provision, configure, and operate your private or on-premises cloud cluster resources without any time, network, or software restrictions.](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-agentb1-about-intro)[Deploy complex application environments using Blueprints Learn how to deploy large-scale and complex application environments from reusable building blocks and used across multiple environments.](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-blueprint-intro)[Deploy cloud services with workspaces Use an IBM-provided Terraform template to create an Object Storage service instance to store your data in IBM Cloud.](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-get-started-terraform)[Explore the IBM Cloud software catalog Try out one of the IBM-provided software templates to quickly spin up a classic virtual server instance (VSI), and automatically configure the instance to connect to an IBM Cloud Database.]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics"},{"document_id":"ibmcld_08870-4153-5691","score":12.450414,"text":"\n: For the latest fixes for schematics template metadata on VPC, see Updates and fixes in [v1.44.2](https:\/\/github.com\/IBM-Cloud\/terraform-provider-ibm\/releases\/tag\/v1.44.2) release.\n\n\n\n\n\n 3 Aug 2022 \n\nEnhancements with the bug fixes\n: For the latest fixes for ibm_cos_bucket data sources on Object Storage, see Updates and fixes in [v1.44.1](https:\/\/github.com\/IBM-Cloud\/terraform-provider-ibm\/releases\/tag\/v1.44.1) release.\n\n\n\n\n\n 2 Aug 2022 \n\nFeatures and enhancements with the bug fixes\n: This release contains the features for Support Internt Services, Support Security and Compilance, Support Virtual Private Cloud, Support IBM Cloud Storage, Support Private DNS from [v1.44.0](https:\/\/github.com\/IBM-Cloud\/terraform-provider-ibm\/releases\/tag\/v1.44.0). For the latest Resources, Data sources, Enhancements, and Bug fixes, see [Updates and fixes in v1.44.0](https:\/\/github.com\/IBM-Cloud\/terraform-provider-ibm\/releases\/tag\/v1.44.0).\n\n\n\n\n\n\n\n July 2022 \n\nReview the release notes for July 2022.\n\n\n\n 1 July 2022 \n\nFeatures and enhancements with the bug fixes\n: This release contains the features for Support Kubernetes, Support EventNotification, Support HPCS, Support CD Toolchain, Support CD Tekton Pipeline from [v1.43.0](https:\/\/github.com\/IBM-Cloud\/terraform-provider-ibm\/releases\/tag\/v1.43.0). For the latest Resources, Data sources, Enhancements, and Bug fixes, see [Updates and fixes in v1.43.0](https:\/\/github.com\/IBM-Cloud\/terraform-provider-ibm\/releases\/tag\/v1.43.0).\n\n\n\n\n\n\n\n June 2022 \n\nReview the release notes for June 2022.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-release-notes"},{"document_id":"ibmcld_07578-1226351-1228411","score":12.417021,"text":"\nThe VPC landing zone deployable architectures use [Terraform](https:\/\/www.terraform.io\/) to specify the infrastructure and [IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-getting-started) to manage the deployment.\n* How do I estimate costs?\n\nYou can view and estimate of starting costs for a variation of the deployable architecture from the IBM Cloud catalog details page. When you deploy by using IBM Cloud\u00ae projects, the starting costs for the project are estimated from the validation window after your changes to the configuration are saved and validated.\n* Are new releases compatible with previous ones?\n\nChanges adhere to semantic versioning, with releases labeled as {major}.{minor}.{patch}. For more information, see the [release compatiblity](https:\/\/terraform-ibm-modules.github.io\/documentation\/\/versioning) in the IBM Cloud Terraform modules documentation.\n\n\n\nStorage Block Storage - Classic\n\n\n\n* How many instances can share the use of a Block Storage for Classic volume?\n\nThe default limit for the number of authorizations per block volume is eight. That means that up to eight hosts can be authorized to access the Block Storage for Classic LUN. Customers who use Block Storage for Classic in their VMware\u00ae deployment can request the authorization limit to be increased to 64. To request a limit increase, contact your sales representative or raise a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/add).\n\nIf multiple hosts mount the same Block Storage for Classic volume without being cooperatively managed, your data is at risk for corruption. Volume corruption can occur if changes are made to the volume by multiple hosts at the same time. You need a cluster-aware, shared-disk file system to prevent data loss such as Microsoft\u00ae Cluster Shared Volumes (CSV), Red Hat Global File System (GFS2), VMware\u00ae VMFS, and others. For more information, see your host's OS Documentation.\n* Our compute hosts have multiple network cards with different IP addresses for network redundancy and expanded bandwidth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1228984-1231044","score":12.417021,"text":"\nThe VPC landing zone deployable architectures use [Terraform](https:\/\/www.terraform.io\/) to specify the infrastructure and [IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-getting-started) to manage the deployment.\n* How do I estimate costs?\n\nYou can view and estimate of starting costs for a variation of the deployable architecture from the IBM Cloud catalog details page. When you deploy by using IBM Cloud\u00ae projects, the starting costs for the project are estimated from the validation window after your changes to the configuration are saved and validated.\n* Are new releases compatible with previous ones?\n\nChanges adhere to semantic versioning, with releases labeled as {major}.{minor}.{patch}. For more information, see the [release compatiblity](https:\/\/terraform-ibm-modules.github.io\/documentation\/\/versioning) in the IBM Cloud Terraform modules documentation.\n\n\n\nStorage Block Storage - Classic\n\n\n\n* How many instances can share the use of a Block Storage for Classic volume?\n\nThe default limit for the number of authorizations per block volume is eight. That means that up to eight hosts can be authorized to access the Block Storage for Classic LUN. Customers who use Block Storage for Classic in their VMware\u00ae deployment can request the authorization limit to be increased to 64. To request a limit increase, contact your sales representative or raise a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/add).\n\nIf multiple hosts mount the same Block Storage for Classic volume without being cooperatively managed, your data is at risk for corruption. Volume corruption can occur if changes are made to the volume by multiple hosts at the same time. You need a cluster-aware, shared-disk file system to prevent data loss such as Microsoft\u00ae Cluster Shared Volumes (CSV), Red Hat Global File System (GFS2), VMware\u00ae VMFS, and others. For more information, see your host's OS Documentation.\n* Our compute hosts have multiple network cards with different IP addresses for network redundancy and expanded bandwidth.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04031-1609-3779","score":12.404818,"text":"\nFor IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges. You will not be charged for the cluster that the Operational Tooling instance, also known as the console, is running on. See the [Architecture reference](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-architecture) topic for an illustration. More details on how to calculate charges are described below.\n\n\n\n Benefits of the new pricing model \n\n\n\n* No membership fees: Freedom from membership fees means that you can invest directly in your blockchain components.\n* Estimation clarity: A simple hourly pricing model makes cost estimation clear and easy by using the cost estimator tool that is available in the IBM Cloud dashboard.\n* No minimum fee required: Pay for only what you use, no minimum VPC hourly package is required, which makes it very inexpensive to get started.\n* Scalability of compute: You have the option to scale your compute up during peak usage periods or down to a minute fraction of capacity for when the compute is not needed to minimize expense.\n\n\n\nIn summary, these features remove the complexity of accounting for membership limitations or purchasing compute ahead of your needs.\n\n\n\n\n\n Find out how to preview the platform free for 30 days \n\nYou can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n\nLimitations of the free preview\n\n\n\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_13237-2789-4600","score":12.39416,"text":"\nIn this section, you will create the following cloud services required for the application using IBM Cloud Schematics: IBM Cloud Databases for PostgreSQL and IBM Cloud Object Storage.\n\n\n\n1. Navigate to [Schematics Workspaces](https:\/\/cloud.ibm.com\/schematics\/workspaces), click on Create workspace.\n\n\n\n1. Under the Specify Template section, provide https:\/\/github.com\/IBM-Cloud\/vpc-scaling-dedicated-host under GitHub or GitLab repository URL.\n2. Select terraform_v1.2 as the Terraform version and click Next.\n\n\n\n2. Under Workspace details,\n\n\n\n1. Provide a workspace name : vpc-scaling-workspace.\n2. Choose a Resource Group and a Location.\n3. Click on Next.\n\n\n\n3. Verify the details and then click on Create.\n4. Under Variables, set step1_create_services to true by clicking the action menu in the row > Edit, uncheck Use default, choose true from the Override Value dropdown, and click on Save.\n5. Set any additional variables you would like to override, the most typical ones are region, resource_group_name.\n6. Scroll to the top of the page and click Generate plan. This is the same as terraform plan command.\n7. Click on Show more to check the resources to be provisioned.\n8. Navigate to the workspace page using the breadcrumb menu and click on Apply plan. Check the logs to see the status of the services created.\n\n\n\nNavigate to the [resource list](https:\/\/cloud.ibm.com\/resources). Here, you can filter by the basename used to create the resources, i.e., vpc-scaling, and you will see the cloud services required for this tutorial provisioned in the resource group you specified. All the data stored with these services is encrypted with a key generated and stored in IBM Key Protect for IBM Cloud.\n\n\n\n Enable logging and monitoring \n\nYou can have multiple IBM Cloud Log Analysis instances in a location.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-scaling-dedicated-compute"},{"document_id":"ibmcld_01805-2511-4214","score":12.290732,"text":"\nIf required, create your [Terraform template](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-create-tf-config). Virtual server image for VPC does not require a Terraform template.\n3. Create an instance of [IBM Cloud Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage) and add your image to a bucket.\n\n\n\nBefore you can onboard software to your account by using Terraform, make sure that you have completed the following:\n\n\n\n* Install the Terraform CLI and configure the IBM Cloud Provider plug-in for Terraform. For more information, see the tutorial for [Getting started with Terraform on IBM Cloud\u00ae](https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-getting-started). The plug-in abstracts the IBM Cloud APIs that are used to complete this task.\n* Create a Terraform configuration file that is named main.tf. In this file, you define resources by using HashiCorp Configuration Language. For more information, see the [Terraform documentation](https:\/\/www.terraform.io\/docs\/language\/index.html).\n\n\n\nTo share software with other accounts, your software must be approved in Partner Center. For more information, see [Getting set up to sell software](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-sw-getting-started).\n\n\n\n\n\n Creating a private catalog \n\nPrivate catalogs provide a way for you to manage access to products for users in your account.\n\n\n\n1. Go to Manage > Catalogs in the IBM Cloud console, and click Create a catalog.\n2. Enter a name and description of your catalog.\n3. Select to exclude or include all products in the IBM Cloud catalog in your private catalog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-private-catalog&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04031-1609-3779","score":13.63119,"text":"\nFor IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges. You will not be charged for the cluster that the Operational Tooling instance, also known as the console, is running on. See the [Architecture reference](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-architecture) topic for an illustration. More details on how to calculate charges are described below.\n\n\n\n Benefits of the new pricing model \n\n\n\n* No membership fees: Freedom from membership fees means that you can invest directly in your blockchain components.\n* Estimation clarity: A simple hourly pricing model makes cost estimation clear and easy by using the cost estimator tool that is available in the IBM Cloud dashboard.\n* No minimum fee required: Pay for only what you use, no minimum VPC hourly package is required, which makes it very inexpensive to get started.\n* Scalability of compute: You have the option to scale your compute up during peak usage periods or down to a minute fraction of capacity for when the compute is not needed to minimize expense.\n\n\n\nIn summary, these features remove the complexity of accounting for membership limitations or purchasing compute ahead of your needs.\n\n\n\n\n\n Find out how to preview the platform free for 30 days \n\nYou can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n\nLimitations of the free preview\n\n\n\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_05666-8826-10757","score":12.967019,"text":"\nReview each product documentation and use the IBM Cloud console to [estimate costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\n\n\n\n\n Operators and other third-party integrations \n\nOperators and other [third-party integrations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrations) are a convenient way to add services to your cluster from community, third-party, your own, or other providers. Keep in mind that you are responsible for additional charges and how these services operate in your cluster, from deployment and maintenance to integration with your apps. If you have issues with an operator or third-party integration, work with the appropriate provider to troubleshoot the issue.\n\n\n\n\n\n VPC worker nodes \n\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zoneszones-vpc) that you create the cluster in. The uplift charge is a percentage (%) of the hourly rate (r), and is added to the hourly rate of the worker node. The total hourly rate cost for a worker node can be calculated as r + (r \u00d7 %). In the [Kubernetes cluster creation console](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/create), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_10116-16035-17814","score":12.803557,"text":"\nPricing for VPC infrastructure varies based on regional location and sustained usage.\n\nThis information applies to VPC worker nodes only.\n\nRegional uplift charges\n: When you create a cluster on VPC infrastructure, the worker nodes might incur an uplift charge that varies by the [multizone location](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-regions-and-zoneszones-vpc) that you create the cluster in. The uplift charge is a percentage (%) of the hourly rate (r), and is added to the hourly rate of the worker node. The total hourly rate cost for a worker node can be calculated as r + (r \u00d7 %). In the [Red Hat OpenShift cluster creation console](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/create?platformType=openshift), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month. For more information, expand the Sustained usage discounts on IBM Cloud Virtual Servers for VPC section on the [Pricing for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs) page.\n\n\n\n\n\n\n\n Estimating costs \n\nSee [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as tiered pricing for increased hourly usage. For more information, see [Understanding costs for your clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costscosts-for-clusters).\n\n\n\n\n\n Managing costs","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_16727-883439-885357","score":12.459503,"text":"\nBilling for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create? \n\nYou can create up to 300 total Block Storage for VPC volumes (data and boot) per account in a region. To increase this [quota](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-quotasblock-storage-quotas), open a [support case](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-help) and specify the zone where you need more volumes.\n* After a data volume is created with a specific capacity, can the capacity later be increased?\n\n After a data volume is created with a specific capacity, can the capacity later be increased? \n\nYou can increase the capacity of data volumes that are attached to a virtual server instance. You can indicate capacity in GB increments up to 16,000 GB capacity, depending on your volume profile. For more information, see [Increasing Block Storage for VPC volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes).\n* Can I increase capacity of a boot volume?\n\n Can I increase capacity of a boot volume? \n\nBoot volume capacity can be increased during instance provisioning or later, by directly modifying the boot volume. This feature applies to instances that are created from stock or custom images. You can also specify a larger boot volume capacity when you create an instance template. The boot volume can't be unattached from an instance (that is, stored as stand-alone data volume). For more information, see [Increasing boot volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-883562-885480","score":12.459503,"text":"\nBilling for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create? \n\nYou can create up to 300 total Block Storage for VPC volumes (data and boot) per account in a region. To increase this [quota](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-quotasblock-storage-quotas), open a [support case](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-help) and specify the zone where you need more volumes.\n* After a data volume is created with a specific capacity, can the capacity later be increased?\n\n After a data volume is created with a specific capacity, can the capacity later be increased? \n\nYou can increase the capacity of data volumes that are attached to a virtual server instance. You can indicate capacity in GB increments up to 16,000 GB capacity, depending on your volume profile. For more information, see [Increasing Block Storage for VPC volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes).\n* Can I increase capacity of a boot volume?\n\n Can I increase capacity of a boot volume? \n\nBoot volume capacity can be increased during instance provisioning or later, by directly modifying the boot volume. This feature applies to instances that are created from stock or custom images. You can also specify a larger boot volume capacity when you create an instance template. The boot volume can't be unattached from an instance (that is, stored as stand-alone data volume). For more information, see [Increasing boot volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_11408-13151-14243","score":12.074078,"text":"\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change. To calculate your pricing, use the [IBM cost estimator](https:\/\/cloud.ibm.com\/estimator) in IBM Cloud console.\n\n\n\n\n\n End of billing \n\nThe monthly billing cycle ends when you delete the LPAR. If you scale your infrastructure up and down in response to workload requirements, your billing follows the timing of the LPAR provision change. If you stop the LPAR, the billing process is not stopped. You must delete the LPAR to stop the billing cycle.\n\nYou are still charged if the VM is in a suspended state. When your VM is inactive, you can use Dynamic Logical Partitioning (DLPAR) to resize it to a minimal state. You can drastically decrease the price per hour by reducing the VM's core count and memory.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"},{"document_id":"ibmcld_16727-871736-873537","score":12.028686,"text":"\nFor more information, see [About restoring from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n* Am I charged for usage?\n\nYes. Cost for backups is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The backup exists on the account until it reaches its retention period, or when you delete it manually, or when you reach the end of a billing cycle, whichever comes first.\n\nPricing of subsequent backups can also increase or decrease when you [increase source volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile for the source volume. For example, expanding volume capacity increases costs. However, changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for backups is also set by region of the source volume. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n Can I use data backups for disaster recovery? \n\nUsing the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-871859-873660","score":12.028686,"text":"\nFor more information, see [About restoring from a backup snapshot](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-baas-vpc-restore).\n* Am I charged for usage?\n\nYes. Cost for backups is calculated based on GB capacity that is stored per month, unless the duration is less than one month. The backup exists on the account until it reaches its retention period, or when you delete it manually, or when you reach the end of a billing cycle, whichever comes first.\n\nPricing of subsequent backups can also increase or decrease when you [increase source volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes) or [adjust IOPS](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-adjusting-volume-iops) by specifying a different IOPS profile for the source volume. For example, expanding volume capacity increases costs. However, changing an IOPS profile from a 5-IOPS\/GB tier to a 3-IOPS\/GB tier decreases the monthly and hourly rate. Billing for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for backups is also set by region of the source volume. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n\n\n\n Can I use data backups for disaster recovery? \n\nUsing the [backup service](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_05666-3176-5101","score":11.769039,"text":"\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.\n* Longer ordering process: After you order or cancel a bare metal server, the process is completed manually in your IBM Cloud infrastructure account. Therefore, it can take more than one business day to complete.\n\nVPC Generation 2 only: Prices vary by region where the underlying worker node infrastructure resides, and you can get sustained usage discounts. For more information, see [What are the regional uplift charges and sustained usage discounts for VPC worker nodes?](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costscharges_vpc_gen2).\n\n\n\nFor more information about worker node specifications, see [Available hardware for worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-planning_worker_nodesplanning_worker_nodes).\n\n\n\n\n\n Public bandwidth \n\nBandwidth refers to the public data transfer of inbound and outbound network traffic, both to and from IBM Cloud resources in data centers around the globe.\n\nClassic clusters: Public bandwidth is charged per GB. You can review your current bandwidth summary by logging into the [IBM Cloud console](https:\/\/cloud.ibm.com\/), from the menu ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/icons\/icon_hamburger.svg) selecting Classic Infrastructure, and then selecting the Network > Bandwidth > Summary page.\n\nReview the following factors that impact public bandwidth charges:\n\n\n\n* Location: As with worker nodes, charges vary depending on the zone that your resources are deployed in.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_07578-278658-280528","score":11.764915,"text":"\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?\n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n\n\n\nSlurm on IBM Cloud\n\n\n\n* What Slurm version is used in cluster nodes deployed with this offering?\n\nCluster nodes that are deployed with this offering include Slurm 19.05.5-1 Advanced Edition.\n* What locations are available for deploying VPC resources?\n\nAvailable regions and zones for deploying VPC resources, and a mapping of those to city locations and data centers can be found in [Locations for resource deployment](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locations).\n* What permissions do I need in order to create a cluster using the offering?\n\nInstructions for setting the appropriate permissions for IBM Cloud services that are used by the offering to create a cluster can be found in [Granting user permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources), [Managing user access for Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access), and [Assigning access to Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-assign-access).\n* How do I SSH among nodes?\n\nAll of the nodes in the HPC cluster have the same public key that you register at your cluster creation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.469278726,"ndcg_cut_10":0.469278726}}
{"task_id":"747a810abfd6da4a9c37cdb74feec95e<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04031-1609-3779","score":13.982135,"text":"\nFor IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges. You will not be charged for the cluster that the Operational Tooling instance, also known as the console, is running on. See the [Architecture reference](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overviewibp-console-overview-architecture) topic for an illustration. More details on how to calculate charges are described below.\n\n\n\n Benefits of the new pricing model \n\n\n\n* No membership fees: Freedom from membership fees means that you can invest directly in your blockchain components.\n* Estimation clarity: A simple hourly pricing model makes cost estimation clear and easy by using the cost estimator tool that is available in the IBM Cloud dashboard.\n* No minimum fee required: Pay for only what you use, no minimum VPC hourly package is required, which makes it very inexpensive to get started.\n* Scalability of compute: You have the option to scale your compute up during peak usage periods or down to a minute fraction of capacity for when the compute is not needed to minimize expense.\n\n\n\nIn summary, these features remove the complexity of accounting for membership limitations or purchasing compute ahead of your needs.\n\n\n\n\n\n Find out how to preview the platform free for 30 days \n\nYou can preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n\nLimitations of the free preview\n\n\n\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_07578-1226351-1228411","score":13.690762,"text":"\nThe VPC landing zone deployable architectures use [Terraform](https:\/\/www.terraform.io\/) to specify the infrastructure and [IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-getting-started) to manage the deployment.\n* How do I estimate costs?\n\nYou can view and estimate of starting costs for a variation of the deployable architecture from the IBM Cloud catalog details page. When you deploy by using IBM Cloud\u00ae projects, the starting costs for the project are estimated from the validation window after your changes to the configuration are saved and validated.\n* Are new releases compatible with previous ones?\n\nChanges adhere to semantic versioning, with releases labeled as {major}.{minor}.{patch}. For more information, see the [release compatiblity](https:\/\/terraform-ibm-modules.github.io\/documentation\/\/versioning) in the IBM Cloud Terraform modules documentation.\n\n\n\nStorage Block Storage - Classic\n\n\n\n* How many instances can share the use of a Block Storage for Classic volume?\n\nThe default limit for the number of authorizations per block volume is eight. That means that up to eight hosts can be authorized to access the Block Storage for Classic LUN. Customers who use Block Storage for Classic in their VMware\u00ae deployment can request the authorization limit to be increased to 64. To request a limit increase, contact your sales representative or raise a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/add).\n\nIf multiple hosts mount the same Block Storage for Classic volume without being cooperatively managed, your data is at risk for corruption. Volume corruption can occur if changes are made to the volume by multiple hosts at the same time. You need a cluster-aware, shared-disk file system to prevent data loss such as Microsoft\u00ae Cluster Shared Volumes (CSV), Red Hat Global File System (GFS2), VMware\u00ae VMFS, and others. For more information, see your host's OS Documentation.\n* Our compute hosts have multiple network cards with different IP addresses for network redundancy and expanded bandwidth.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1228984-1231044","score":13.690762,"text":"\nThe VPC landing zone deployable architectures use [Terraform](https:\/\/www.terraform.io\/) to specify the infrastructure and [IBM Cloud Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-getting-started) to manage the deployment.\n* How do I estimate costs?\n\nYou can view and estimate of starting costs for a variation of the deployable architecture from the IBM Cloud catalog details page. When you deploy by using IBM Cloud\u00ae projects, the starting costs for the project are estimated from the validation window after your changes to the configuration are saved and validated.\n* Are new releases compatible with previous ones?\n\nChanges adhere to semantic versioning, with releases labeled as {major}.{minor}.{patch}. For more information, see the [release compatiblity](https:\/\/terraform-ibm-modules.github.io\/documentation\/\/versioning) in the IBM Cloud Terraform modules documentation.\n\n\n\nStorage Block Storage - Classic\n\n\n\n* How many instances can share the use of a Block Storage for Classic volume?\n\nThe default limit for the number of authorizations per block volume is eight. That means that up to eight hosts can be authorized to access the Block Storage for Classic LUN. Customers who use Block Storage for Classic in their VMware\u00ae deployment can request the authorization limit to be increased to 64. To request a limit increase, contact your sales representative or raise a [Support case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/add).\n\nIf multiple hosts mount the same Block Storage for Classic volume without being cooperatively managed, your data is at risk for corruption. Volume corruption can occur if changes are made to the volume by multiple hosts at the same time. You need a cluster-aware, shared-disk file system to prevent data loss such as Microsoft\u00ae Cluster Shared Volumes (CSV), Red Hat Global File System (GFS2), VMware\u00ae VMFS, and others. For more information, see your host's OS Documentation.\n* Our compute hosts have multiple network cards with different IP addresses for network redundancy and expanded bandwidth.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05666-7536-9272","score":13.038497,"text":"\n* VPC clusters: A Load Balancer for VPC is automatically created in your VPC for your cluster. For cost information, see [Pricing for Load Balancer for VPC](https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs).\n\n\n\n\n\n\n\n Storage \n\nWhen you provision storage, you can choose the storage type and storage class that is correct for your use case. Charges vary depending on the type of storage, the location, and the specs of the storage instance. Some storage solutions, such as file and block storage offer hourly and monthly rates that you can choose from.\n\nTo choose the correct storage solution, see [Planning highly available persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan). For more information, see:\n\n\n\n* [File Storage for Classic](https:\/\/www.ibm.com\/products\/file-storage)\n* [Block Storage for Classic](https:\/\/www.ibm.com\/products\/block-storage)\n* [File Storage for VPC](https:\/\/www.ibm.com\/products\/file-storage)\n* [Block Storage for VPC](https:\/\/www.ibm.com\/products\/block-storage)\n* [IBM Cloud Object Storage](https:\/\/www.ibm.com\/cloud\/object-storage)\n* [Portworx Enterprise pricing](https:\/\/cloud.ibm.com\/catalog\/services\/portworx-enterprise)\n\n\n\n\n\n\n\n IBM Cloud services \n\nEach service that you integrate with your cluster has its own pricing model. Review each product documentation and use the IBM Cloud console to [estimate costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\n\n\n\n\n Operators and other third-party integrations \n\nOperators and other [third-party integrations](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-supported_integrations) are a convenient way to add services to your cluster from community, third-party, your own, or other providers.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_04031-7-2093","score":12.718704,"text":"\nPricing for IBM Blockchain Platform for IBM Cloud \n\nATTENTION!! IBM Blockchain Platform SaaS Edition is being replaced by IBM Support for Hyperledger Fabric!! IBM Blockchain Platform SaaS Edition will no longer be supported after July 31, 2023. Customers have been directed to migrate their networks by July 31, 2023. After this date, IBM Blockchain Platform SaaS networks that are not migrated to IBM Support for Hyperledger Fabric will be at risk for potential security vulnerabilities. A migration tool is provided from your console, and the disruption to your network is minimal. See [Migrating to IBM Support for Hyperledger Fabric](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-migrating-to-hlf-support) for details.\n\nThis guide helps you understand the pricing model for IBM\u00ae Blockchain Platform for IBM Cloud, and how much you will pay when you develop and grow your blockchain network of peers, ordering nodes, and Certificate Authorities components, which are based on Hyperledger Fabric v2.2.10.\n\n\n\n Pricing model \n\nIBM Blockchain Platform introduces a new hourly pricing model that is based on virtual processor core (VPC) allocation. This simplified model is based on the amount of CPU (or VPC) that your IBM Blockchain Platform nodes are allocated on an hourly basis, at a flat rate of $0.29 USD\/VPC-hour.\n\nA VPC is a unit of measurement that is used to determine the licensing cost of IBM products. It is based on the number of virtual cores (vCPUs) that are available to the product. A vCPU is a virtual core that is assigned to a virtual machine or a physical processor core. For IBM Blockchain Platform cost estimation purposes, 1 VPC = 1 CPU = 1 vCPU = 1 Core. The term \"VPC\" is also used to refer to a type of infrastructure on IBM Cloud and is unrelated to this topic.\n\nFor a total cost estimate, remember that your blockchain network consists of an Kubernetes cluster on IBM Cloud that contains IBM Blockchain Platform components and uses storage of your choice. Your Kubernetes cluster on IBM Cloud and the storage that you choose incur separate charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing"},{"document_id":"ibmcld_11553-5984-8085","score":12.715892,"text":"\nThe IBM Cloud Provider plug-in for Terraform on IBM Cloud uses these configuration files to provision a VPC in your IBM Cloud account.\n\n\n\n\n\n Schematics deployment \n\nYou use the Schematics user interface on IBM Cloud\u00ae and enter the [GitHub repository for S\/4HANA Schematics](https:\/\/github.com\/ibm-cloud\/sap-s4hana\/tree\/main\/schematics).\n\nWhen you run the scripts with the Schematics interface, you:\n\n\n\n* Enter Workspace information.\n* Enter the Github path.\n* Modify the parameters in the Schematics interface.\n\n\n\n\n\n\n\n Catalog Tile deployment \n\nWhen you use the Catalog Tile for deployment, you:\n\n\n\n* Select the SAP S\/4HANA tile from the catalog\n* Enter information for your workspace. The Catalog Tile creates a Schematics workspace for you.\n* Modify the parameters for your bastion server, personal credential information, and other parameters specific to your solution.\n\n\n\n\n\n\n\n SAP Kits \n\nFor each IBM Cloud region, IBM allocates temporary storage on a dedicated Jump host. It is your responsibility to download the necessary SAP and DB kits to your Deployment Server. All files archives are decompressed by Ansible during the automation deployment process. For more information, see the readme file.\n\n\n\n\n\n Support - Schematics and Terraform \n\nThere are no warranties of any kind, and there is no service or technical support available for these materials from IBM. As a recommended practice, review carefully any materials that you download from this site before using them on a live system.\n\nThough the materials provided herein are not supported by the IBM Service organization, your comments are welcomed by the developers, who reserve the right to revise, re-adapt or remove the materials at any time. To report a problem, or provide suggestions or comments, open a GitHub issue.\n\n\n\n\n\n Support - Catalog Tile \n\nThe Catalog Tile offering is IBM Cloud supported. For more information, see [Getting help and support from IBM Cloud or SAP](https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-help-support&interface=ui).\n\nIf client issues are identified with SAP software, then SAP Support will assist client.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sap?topic=sap-automate-s4hana-terraform-ansible"},{"document_id":"ibmcld_08870-4153-5691","score":12.487372,"text":"\n: For the latest fixes for schematics template metadata on VPC, see Updates and fixes in [v1.44.2](https:\/\/github.com\/IBM-Cloud\/terraform-provider-ibm\/releases\/tag\/v1.44.2) release.\n\n\n\n\n\n 3 Aug 2022 \n\nEnhancements with the bug fixes\n: For the latest fixes for ibm_cos_bucket data sources on Object Storage, see Updates and fixes in [v1.44.1](https:\/\/github.com\/IBM-Cloud\/terraform-provider-ibm\/releases\/tag\/v1.44.1) release.\n\n\n\n\n\n 2 Aug 2022 \n\nFeatures and enhancements with the bug fixes\n: This release contains the features for Support Internt Services, Support Security and Compilance, Support Virtual Private Cloud, Support IBM Cloud Storage, Support Private DNS from [v1.44.0](https:\/\/github.com\/IBM-Cloud\/terraform-provider-ibm\/releases\/tag\/v1.44.0). For the latest Resources, Data sources, Enhancements, and Bug fixes, see [Updates and fixes in v1.44.0](https:\/\/github.com\/IBM-Cloud\/terraform-provider-ibm\/releases\/tag\/v1.44.0).\n\n\n\n\n\n\n\n July 2022 \n\nReview the release notes for July 2022.\n\n\n\n 1 July 2022 \n\nFeatures and enhancements with the bug fixes\n: This release contains the features for Support Kubernetes, Support EventNotification, Support HPCS, Support CD Toolchain, Support CD Tekton Pipeline from [v1.43.0](https:\/\/github.com\/IBM-Cloud\/terraform-provider-ibm\/releases\/tag\/v1.43.0). For the latest Resources, Data sources, Enhancements, and Bug fixes, see [Updates and fixes in v1.43.0](https:\/\/github.com\/IBM-Cloud\/terraform-provider-ibm\/releases\/tag\/v1.43.0).\n\n\n\n\n\n\n\n June 2022 \n\nReview the release notes for June 2022.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-release-notes"},{"document_id":"ibmcld_16727-883439-885357","score":12.425864,"text":"\nBilling for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create? \n\nYou can create up to 300 total Block Storage for VPC volumes (data and boot) per account in a region. To increase this [quota](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-quotasblock-storage-quotas), open a [support case](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-help) and specify the zone where you need more volumes.\n* After a data volume is created with a specific capacity, can the capacity later be increased?\n\n After a data volume is created with a specific capacity, can the capacity later be increased? \n\nYou can increase the capacity of data volumes that are attached to a virtual server instance. You can indicate capacity in GB increments up to 16,000 GB capacity, depending on your volume profile. For more information, see [Increasing Block Storage for VPC volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes).\n* Can I increase capacity of a boot volume?\n\n Can I increase capacity of a boot volume? \n\nBoot volume capacity can be increased during instance provisioning or later, by directly modifying the boot volume. This feature applies to instances that are created from stock or custom images. You can also specify a larger boot volume capacity when you create an instance template. The boot volume can't be unattached from an instance (that is, stored as stand-alone data volume). For more information, see [Increasing boot volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes).","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-883562-885480","score":12.425864,"text":"\nBilling for an updated volume is automatically updated to add the prorated difference of the new price to the current billing cycle. The new full amount is then billed in the next billing cycle.\n\nPricing for Block Storage for VPC volumes is also set by region. For more information, see [Pricing](https:\/\/www.ibm.com\/cloud\/vpc\/pricing).\n* Are there limits on the number of volumes I can create?\n\n Are there limits on the number of volumes I can create? \n\nYou can create up to 300 total Block Storage for VPC volumes (data and boot) per account in a region. To increase this [quota](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-quotasblock-storage-quotas), open a [support case](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-help) and specify the zone where you need more volumes.\n* After a data volume is created with a specific capacity, can the capacity later be increased?\n\n After a data volume is created with a specific capacity, can the capacity later be increased? \n\nYou can increase the capacity of data volumes that are attached to a virtual server instance. You can indicate capacity in GB increments up to 16,000 GB capacity, depending on your volume profile. For more information, see [Increasing Block Storage for VPC volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-expanding-block-storage-volumes).\n* Can I increase capacity of a boot volume?\n\n Can I increase capacity of a boot volume? \n\nBoot volume capacity can be increased during instance provisioning or later, by directly modifying the boot volume. This feature applies to instances that are created from stock or custom images. You can also specify a larger boot volume capacity when you create an instance template. The boot volume can't be unattached from an instance (that is, stored as stand-alone data volume). For more information, see [Increasing boot volume capacity](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-resize-boot-volumes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_15770-2447-4326","score":12.385267,"text":"\n[GPU](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profilesgpu) GPU enabled profiles provide on-demand access to NVIDIA V100 and A100 GPUs to accelerate AI, high-performance computing, data science, and graphics workloads. \n [Storage Optimized](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profilesstorageopt) Storage Optimized profiles offer temporary SSD instance storagedisks at a ratio of 1 vCPU to 300 GB instance storage with a lower price point per GB. These profiles are designed for storage-dense workloads and offer virtio interface type for attached disks. \n\n\n\nProfiles with instance storage and profiles with 64 or more vCPUs are deployed exclusively on the Intel\u00ae's second-generation quad processor Xeon\u00ae Platinum 8260 Cascade Lake with 96 cores that are running at a base speed of 2.4 GHz and an all-core turbo frequency of 3.1 GHz or Intel\u00ae's quad processor Xeon\u00ae Gold 6248 Cascade Lake with 80 cores that are running at a base speed of 2.5 GHz and an all-core turbo frequency of 3.1 GHz.\n\nProfiles with AMD manufactured processors are available in the Toronto region.\n\n\n\n Balanced \n\nBalanced profiles provide a mix of performance and scalability for more common workloads with a ratio of 4 GiB of memory for every 1 vCPU of compute. The Balanced profile family includes profiles with and without [instance storage](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-instance-storage). The following table shows all Balanced profiles available for Intel\u00ae x86-64, and AMD x86-64 processors.\n\nBalanced profiles with the bx2d prefix are available in the US South (Dallas), US East (Washington DC), Canada (Toronto), United Kingdom (London), EU Germany (Frankfurt), Japan (Tokyo), Japan (Osaka), and Australia (Sydney) regions.\n\nIntel x86-64\n\nAMD x86-64\n\n\n\nTable 3. Balance profiles options for Intel x86-64 instances\nBalanced profiles options for Intel x86-64 virtual server instances.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-profiles"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.5585075863,"ndcg_cut_10":0.5585075863}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01660-8584-10307","score":22.222143,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_01705-7-1620","score":21.570856,"text":"\nAccount types \n\nWhen you register with IBM Cloud\u00ae, you are set up with a Pay-As-You-Go account. Even though you provide your credit card information for account security and identity verification purposes, you can still use IBM Cloud for free by selecting products in the catalog that offer Free and Lite pricing plans. Another account type, called a Subscription account, is also available. With a Subscription account, you get many of the same features of a Pay-As-You-Go account, plus discounts for platform services and support with a more consistent billing structure that uses subscriptions.\n\n\n\n Comparing accounts \n\nThe following table provides a comparison of Trial, Pay-As-You-Go, and Subscription accounts. For more details about each account, see the sections that follow.\n\n\n\nTable 1. Comparison of IBM Cloud accounts\nThis table has row and column headers. The row headers identify the feature. The column headers identify the account type. To understand which features apply to the account types, navigate to the row, and find the feature that you're interested in.\n\n Trial Pay-As-You-Go Subscription \n\n [Free community buildpacks](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-available_buildpacks) 186 GBH 186 GBH 186 GBH \n Access to [Lite service plans](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_16727-1079289-1081125","score":20.22346,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":20.22346,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01705-2818-4572","score":18.778555,"text":"\n[Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) \n Invoiced on monthly consumption ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) \n\n\n\nNew accounts as of 25 October 2021 are created as Pay-As-You-Go or Subscription accounts. You're asked to provide credit card information for identity verification or a code for a purchased subscription. If you created an account before this date, you might be using a [Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount) and Lite pricing plans, which aren't affected by the recent account registraton update.\n\n\n\n\n\n Trial account \n\nTrial accounts offer timed access to a limited range of service plans and allow you to test out the platform without financial commitment. You can access Lite service plans and Free plans for a limited time with a trial account. To qualify for a trial account, go to [Harness the Power of IBM](https:\/\/ibm.biz\/academic) and validate your institution credentials or reach out to your educational program or course leader. If you don't have an account, select 'Register with a Code' during IBM Cloud registration to apply a code. If you have an account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console to apply the code.\n\nIf you upgrade your trial account to a Pay-As-You-Go account by entering a credit card, it can't be converted back to a trial account. IBM Cloud trial accounts are available for faculty and students at accredited academic institutions. Trial accounts expire after 30 days. Your account is deactivated when the trial period ends.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_01660-7085-8964","score":18.740204,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_01705-13208-15001","score":18.705889,"text":"\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/Lite.svg) in the catalog. To gain access to all Free plans, you can go ahead and [upgrade to a Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqschangeacct) by adding your credit card information.\n\nStarting 25 October 2021, all new accounts are created as Pay-As-You-Go based on an update to our account registration process. As part of this update, you're asked to provide credit card information for identity verification. You have full access to the catalog, including all Free and Lite plans, and you get a $200 credit that you can apply in your first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nLite accounts have access to a single resource group that's created for you with the name Default. All of your service's instances are automatically added to this resource group. You can update the name of this resource group at any time. See [Renaming a resource group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rgsrename_rgs) for the detailed steps.\n\n\n\n What's available in a lite account? \n\nCheck out the following list of key features that are available in a Lite account:\n\n\n\n* The account is free - no credit card required.\n* The account never expires.\n* You receive email notifications about your account status and quota limits.\n* You can create one instance of any service in the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite%20lite) that has a Lite plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_08069-7-2230","score":18.64608,"text":"\nBasic, Advanced, and Premium Support plans \n\nYou can choose a Basic, Advanced, or Premium support plan to customize your IBM Cloud\u00ae support experience for your business needs. The level of support that you select determines the severity that you can assign to support cases and your level of access to the tools available in the Support Center.\n\nIf you have free support, you're provided technical support through [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud?tab=Newest). Also, with a Lite account and free support, you can open cases that are related to access management, accounts, and billing and usage. If you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative.\n\nInitial response Service Level Objectives (SLO) do not apply to any billing, invoice, or sales related inquiry or cases.\n\nThe following table shows the support types available for Pay-As-You-Go accounts, Subscription accounts, and the Enterprise Savings Plan billing model. For more information about accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\nTable 1. Support plans\n\n Basic Support Advanced Support Premium Support \n\n Description Basic business protection that is included with your IBM Cloud Pay-As-You-Go or Subscription account Prioritized case handling and support experience that is aligned with your business needs for your Pay-As-You-Go account, Subscription account, or Enterprise Savings Plan billing model Client engagement that is aligned with your business outcomes to accelerate time-to-value for your Pay-As-You-Go account, Subscription account, or Enterprise Savings Plan billing model \n Availability 24 x 7 access to the IBM Cloud technical support team through cases <br>Phone and chat are available only for Pay-As-You-Go and Subscription accounts 24 x 7 access to the IBM Cloud technical support team through cases, phone, and chat 24 x 7 access to the IBM Cloud technical support team through cases, phone, and chat \n [Case severity](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity) Not applicable Case severity ranking available Case severity ranking available","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans"},{"document_id":"ibmcld_03776-3313-5682","score":18.64315,"text":"\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_02660-1509-3609","score":18.161898,"text":"\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-create-an-instance"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.8772153153,"ndcg_cut_10":0.8772153153}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01660-8584-10307","score":24.911076,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_01705-7-1620","score":24.687326,"text":"\nAccount types \n\nWhen you register with IBM Cloud\u00ae, you are set up with a Pay-As-You-Go account. Even though you provide your credit card information for account security and identity verification purposes, you can still use IBM Cloud for free by selecting products in the catalog that offer Free and Lite pricing plans. Another account type, called a Subscription account, is also available. With a Subscription account, you get many of the same features of a Pay-As-You-Go account, plus discounts for platform services and support with a more consistent billing structure that uses subscriptions.\n\n\n\n Comparing accounts \n\nThe following table provides a comparison of Trial, Pay-As-You-Go, and Subscription accounts. For more details about each account, see the sections that follow.\n\n\n\nTable 1. Comparison of IBM Cloud accounts\nThis table has row and column headers. The row headers identify the feature. The column headers identify the account type. To understand which features apply to the account types, navigate to the row, and find the feature that you're interested in.\n\n Trial Pay-As-You-Go Subscription \n\n [Free community buildpacks](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-available_buildpacks) 186 GBH 186 GBH 186 GBH \n Access to [Lite service plans](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_16727-1079289-1081125","score":22.532454,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":22.532454,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01705-13208-15001","score":21.74751,"text":"\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/Lite.svg) in the catalog. To gain access to all Free plans, you can go ahead and [upgrade to a Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqschangeacct) by adding your credit card information.\n\nStarting 25 October 2021, all new accounts are created as Pay-As-You-Go based on an update to our account registration process. As part of this update, you're asked to provide credit card information for identity verification. You have full access to the catalog, including all Free and Lite plans, and you get a $200 credit that you can apply in your first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nLite accounts have access to a single resource group that's created for you with the name Default. All of your service's instances are automatically added to this resource group. You can update the name of this resource group at any time. See [Renaming a resource group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rgsrename_rgs) for the detailed steps.\n\n\n\n What's available in a lite account? \n\nCheck out the following list of key features that are available in a Lite account:\n\n\n\n* The account is free - no credit card required.\n* The account never expires.\n* You receive email notifications about your account status and quota limits.\n* You can create one instance of any service in the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite%20lite) that has a Lite plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_11142-7-1829","score":21.230398,"text":"\nTry out IBM Cloud, for free \n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\n\n\n Before you begin \n\nGo to the [IBM Cloud console](https:\/\/cloud.ibm.com) and create an account. You're asked to enter your credit card information to secure your account and verify your identity. There are no costs that are associated with signing up, and you can try out IBM Cloud for free. You pay only for billable services that you choose to use, with no long-term contracts or commitments.\n\nYou're set up with a [Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountspaygo), and you can access the full IBM Cloud catalog, including all Lite and Free plans. You receive a $200 credit to help get you started. You can use the $200 credit on IBM Cloud products that are used in the first 30 days.\n\n\n\n\n\n Step 1: Explore the catalog \n\nExplore the catalog for services that are free to use by filtering for Lite and Free pricing plans. You can work on your projects worry free, without the risk of generating a bill.\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-tutorial-try-for-free"},{"document_id":"ibmcld_01705-2818-4572","score":21.072592,"text":"\n[Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) \n Invoiced on monthly consumption ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) \n\n\n\nNew accounts as of 25 October 2021 are created as Pay-As-You-Go or Subscription accounts. You're asked to provide credit card information for identity verification or a code for a purchased subscription. If you created an account before this date, you might be using a [Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount) and Lite pricing plans, which aren't affected by the recent account registraton update.\n\n\n\n\n\n Trial account \n\nTrial accounts offer timed access to a limited range of service plans and allow you to test out the platform without financial commitment. You can access Lite service plans and Free plans for a limited time with a trial account. To qualify for a trial account, go to [Harness the Power of IBM](https:\/\/ibm.biz\/academic) and validate your institution credentials or reach out to your educational program or course leader. If you don't have an account, select 'Register with a Code' during IBM Cloud registration to apply a code. If you have an account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console to apply the code.\n\nIf you upgrade your trial account to a Pay-As-You-Go account by entering a credit card, it can't be converted back to a trial account. IBM Cloud trial accounts are available for faculty and students at accredited academic institutions. Trial accounts expire after 30 days. Your account is deactivated when the trial period ends.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_12838-9061-11120","score":21.00654,"text":"\nDescribe the details of your plan.\n7. Choose the locations where your plan is available. All plans for a product use either global or per location. By selecting per location, you can specify different regions or data centers for each plan that you add.\n8. Select a broker to link to the plan.\n\nIf you haven't finished adding the broker to your account, you will not see this option, and you can continue and save your pricing plan. However, you can't submit your pricing plan for approval until the broker is linked.\n9. Click Save.\n\n\n\nBefore you can submit your pricing plan for approval, you must complete the following tasks:\n\n\n\n* If you had to skip the step to link your broker to the plan because you didn't have one yet, start to develop your broker, and come back to link it to your plan when you're done.\n* [Add metrics to your plan](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-add-metrics) to determine how customers are charged, and request metering approval.\n* [Add plan features](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-pricing-infoservice-add-feature) to describe why a customer might want to choose a specific plan.\n* When your metrics are approved, you can test the pricing and usage from a customer's perspective and provide evidence from your testing to get the final approval for your pricing plan.\n\n\n\n\n\n\n\n Listing pricing plan features \n\nIf you completed the steps to define your pricing plan, you can add a list of features for the plan. These features uniquely identify your product's attributes and differentiate your pricing plan from others. By providing a list of features for your product, you can help customers choose the most suitable pricing plan for their use case.\n\nYou can add up to five features for your product, but you must add at least one. The first feature that you add appears more prominently. Include the most important and differentiating details as the first feature.\n\nTo add features for your service, complete the following steps:\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-pricing-info"},{"document_id":"ibmcld_11143-1499-3764","score":20.91647,"text":"\nOr, if you want to explore everything that IBM Cloud has to offer, go to the catalog to browse over 350 unique products [Click Catalog menu item]. Choose from our broad portfolio of managed services [Click Services], explore software products to take advantage of simplified installation [Click Software], or consult with IBM Cloud experts [Click Consulting]. If you're just here to try it out, filter the catalog by products that offer Lite plans, which are free to use [Click Services, and select the Lite pricing plan option].\n\nWhen you're working in IBM Cloud [Click IBM Cloud menu option], check out your dashboard to get a high-level overview of your account's resources, users, support cases, compliance monitoring, and usage, with quick links out to each area. You can tailor the information that's displayed to only what you need by creating custom dashboards and adding widgets for specific resources, team notes, management tasks, and more [Click the Actions menu icon > Create dashboard > Management > Create].\n\nFor any account management tasks that you need to take care of, go to Manage > Account [Click Manage menu option > Account]. Here you can create and manage your resource groups, Cloud Foundry orgs, create tags to organize resources, manage your account settings, and more.\n\nFrom the same Manage menu, you can go to Billing and usage [Click Manage menu option > Billing and usage] to view your usage, view invoices, and set spending notifications to help keep track of your costs.\n\nThen, through the Manage > Access (IAM) option [Click Manage menu item > Access (IAM)], you can invite users to your account and manage their access to account resources including IAM-enabled, Cloud Foundry, and classic infrastructure resources.\n\nIn a connected world, security is more important than ever, and we've built it right into the platform [Click Menu icon > Security and Compliance]. With the IBM Cloud Security and Compliance Center [Click Dashboard], you can set up a unified dashboard to monitor security and compliance, govern configuration, and gain insights into threats.\n\nIf you prefer to work from the command line [Click IBM Cloud Shell menu item], you can manage your IBM Cloud account and resources from your browser with IBM Cloud Shell.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-ui"},{"document_id":"ibmcld_01660-7085-8964","score":20.89323,"text":"\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.570641719,"ndcg_cut_10":0.570641719}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01705-7-1620","score":20.062742,"text":"\nAccount types \n\nWhen you register with IBM Cloud\u00ae, you are set up with a Pay-As-You-Go account. Even though you provide your credit card information for account security and identity verification purposes, you can still use IBM Cloud for free by selecting products in the catalog that offer Free and Lite pricing plans. Another account type, called a Subscription account, is also available. With a Subscription account, you get many of the same features of a Pay-As-You-Go account, plus discounts for platform services and support with a more consistent billing structure that uses subscriptions.\n\n\n\n Comparing accounts \n\nThe following table provides a comparison of Trial, Pay-As-You-Go, and Subscription accounts. For more details about each account, see the sections that follow.\n\n\n\nTable 1. Comparison of IBM Cloud accounts\nThis table has row and column headers. The row headers identify the feature. The column headers identify the account type. To understand which features apply to the account types, navigate to the row, and find the feature that you're interested in.\n\n Trial Pay-As-You-Go Subscription \n\n [Free community buildpacks](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-available_buildpacks) 186 GBH 186 GBH 186 GBH \n Access to [Lite service plans](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_01660-8584-10307","score":18.17825,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_11133-1287-2850","score":18.003036,"text":"\nApplicable Additional SDs for any service ordered using your IBM Cloud account are available at [https:\/\/www.ibm.com\/terms\/?id=i126-6605](https:\/\/www.ibm.com\/terms\/?id=i126-6605). The additional SDs contain links to the applicable Data Sheet for each service.\n\n\n\n\n\n All other accounts \n\nAs of 10 December 2020, this section describes the Terms of Use for the following types of IBM Cloud accounts:\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n* New and existing contracts for IBM Global Technology Services and Cloud Services\n* New and existing Lite accounts worldwide\n\n\n\nYour IBM Cloud account and any services that are ordered from the IBM Cloud are provided under the terms of the Service Description for IBM Cloud available at [https:\/\/www.ibm.com\/terms\/?id=i126-6605](https:\/\/www.ibm.com\/terms\/?id=i126-6605) and one of the following base agreements:\n\n\n\n* IBM Cloud Services Agreement (local country version*) for Lite accounts, non-US Dollar credit card billing, or if you select invoicing from IBM, available at [https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/) (select your country);\n* SoftLayer Cloud Service Agreement for US Dollar credit card billing, available at\n\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=softlayer#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=softlayerdetail-document)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-terms"},{"document_id":"ibmcld_01705-13208-15001","score":17.916636,"text":"\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/Lite.svg) in the catalog. To gain access to all Free plans, you can go ahead and [upgrade to a Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqschangeacct) by adding your credit card information.\n\nStarting 25 October 2021, all new accounts are created as Pay-As-You-Go based on an update to our account registration process. As part of this update, you're asked to provide credit card information for identity verification. You have full access to the catalog, including all Free and Lite plans, and you get a $200 credit that you can apply in your first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nLite accounts have access to a single resource group that's created for you with the name Default. All of your service's instances are automatically added to this resource group. You can update the name of this resource group at any time. See [Renaming a resource group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rgsrename_rgs) for the detailed steps.\n\n\n\n What's available in a lite account? \n\nCheck out the following list of key features that are available in a Lite account:\n\n\n\n* The account is free - no credit card required.\n* The account never expires.\n* You receive email notifications about your account status and quota limits.\n* You can create one instance of any service in the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite%20lite) that has a Lite plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_02301-7-1933","score":17.874496,"text":"\nUpgrading your account \n\nLite accounts make it easy to get started with IBM Cloud\u00ae and try out services. When you are ready for more, you can upgrade your account to a Pay-As-You-Go, or Subscription account to unlock the entire catalog of production-ready services.\n\nYou can check your current account type by going to Manage > Account > Account settings in the IBM Cloud console and looking in the Account Type section.\n\nNot sure which type of account you want to upgrade to? Get detailed information about the benefits of each account type in [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\nTo upgrade your account, you must have an access policy with the Editor role or higher on all account management services. For more information about IAM roles for managing accounts, see [Platform management roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userrolesplatformroles).\n\n\n\n Upgrading to a Pay-As-You-Go account \n\nWith a Pay-As-You-Go account, you pay for only what you use beyond the free runtime and service allowances. After you upgrade, you can continue to use any instances that you created with your Lite account.\n\nTo upgrade to a Pay-As-You-Go account, complete the following steps.\n\n\n\n1. Go to Manage > Account in the IBM Cloud console.\n2. Select Account settings, and click Add credit card.\n3. Enter your payment information, click Next, and submit your information.\n\n\n\nAfter your payment information is processed, your account is upgraded, and you can explore and access the full IBM Cloud catalog. For any billable services that you use beyond any free allowances, you receive a monthly invoice.\n\nIf you're upgrading to reactivate a deactivated account, your account might take a few days to be fully available. If your account continues to be in a pending state, see [Why can't I upgrade my account?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-ts_upgrade_cc) for help.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account"},{"document_id":"ibmcld_01705-2818-4572","score":17.771128,"text":"\n[Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) \n Invoiced on monthly consumption ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) \n\n\n\nNew accounts as of 25 October 2021 are created as Pay-As-You-Go or Subscription accounts. You're asked to provide credit card information for identity verification or a code for a purchased subscription. If you created an account before this date, you might be using a [Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount) and Lite pricing plans, which aren't affected by the recent account registraton update.\n\n\n\n\n\n Trial account \n\nTrial accounts offer timed access to a limited range of service plans and allow you to test out the platform without financial commitment. You can access Lite service plans and Free plans for a limited time with a trial account. To qualify for a trial account, go to [Harness the Power of IBM](https:\/\/ibm.biz\/academic) and validate your institution credentials or reach out to your educational program or course leader. If you don't have an account, select 'Register with a Code' during IBM Cloud registration to apply a code. If you have an account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console to apply the code.\n\nIf you upgrade your trial account to a Pay-As-You-Go account by entering a credit card, it can't be converted back to a trial account. IBM Cloud trial accounts are available for faculty and students at accredited academic institutions. Trial accounts expire after 30 days. Your account is deactivated when the trial period ends.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_01660-23838-25711","score":17.137053,"text":"\nFor more information, see [Adding orgs and spaces](https:\/\/cloud.ibm.com\/docs\/account?topic=account-orgsspacesuserscreateorg).\n\n\n\n\n\n Why do I get logged out of my account? \n\nThe administrator of your account has customized the duration of active and inactive accounts, which requires users to enter their credentials after a specific time. For more information, see [Managing user's login session durations](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-work-sessions).\n\n\n\n\n\n Why can't I create a Lite account? \n\nBased on an update to our account registration that released starting 25 October 2021, new accounts are created as Pay-As-You-Go. As part of this update, you're asked to provide credit card information for identity verification. After you register and create your new account, you can access the full IBM Cloud catalog, including all Free and Lite plans. And, you get a $200 credit that you can use on products in the first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nIf you created a Lite account before 25 October 2021, you can continue working as you always have. However, you can go ahead and [upgrade to a Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqschangeacct) by adding your credit card information. This way, you can gain access to all Free service plans in the catalog.\n\n\n\n\n\n How do I see who created a service instance and when? \n\nFrom the [Resource list](https:\/\/cloud.ibm.com\/resources), expand the appropriate section, and click the row for the instance that you want more details about. Additional details about the resource display including when the resource was created and by whom.\n\nFor classic infrastructure services, you can get similar information by using the [Audit log](https:\/\/cloud.ibm.com\/docs\/account?topic=account-audit-log).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_01705-14609-15453","score":17.038486,"text":"\nCheck out the following list of key features that are available in a Lite account:\n\n\n\n* The account is free - no credit card required.\n* The account never expires.\n* You receive email notifications about your account status and quota limits.\n* You can create one instance of any service in the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite%20lite) that has a Lite plan.\n* After 10 days of no development activity, your apps go to sleep. You can wake up your apps by continuing to work on them.\n* After 30 days of no development activity, your service instances with Lite plans are deleted\n\n\n\nOnly Lite accounts created before 12 August 2021 can use 186 GBH of free buildpacks and Cloud Foundry apps with up to 256 MB of free instantaneous runtime memory per month. The use of one org in one IBM Cloud region is supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_03704-1531-3564","score":16.840904,"text":"\nWhat's the difference between a Pay-As-You-Go and Subscription account? \n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\n\n\n What happens if my Lite plan instance reaches the monthly quota? \n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n\n\n\n\n\n Can I use PayPal as a payment method? \n\nAs of March 31, 2023, PayPal is no longer accepted.\n\n\n\n\n\n Can I update my credit card? \n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_16727-1042765-1044817","score":16.735138,"text":"\nContact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01660-8584-10307","score":18.830986,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_01705-13208-15001","score":18.7255,"text":"\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/Lite.svg) in the catalog. To gain access to all Free plans, you can go ahead and [upgrade to a Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqschangeacct) by adding your credit card information.\n\nStarting 25 October 2021, all new accounts are created as Pay-As-You-Go based on an update to our account registration process. As part of this update, you're asked to provide credit card information for identity verification. You have full access to the catalog, including all Free and Lite plans, and you get a $200 credit that you can apply in your first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nLite accounts have access to a single resource group that's created for you with the name Default. All of your service's instances are automatically added to this resource group. You can update the name of this resource group at any time. See [Renaming a resource group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rgsrename_rgs) for the detailed steps.\n\n\n\n What's available in a lite account? \n\nCheck out the following list of key features that are available in a Lite account:\n\n\n\n* The account is free - no credit card required.\n* The account never expires.\n* You receive email notifications about your account status and quota limits.\n* You can create one instance of any service in the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite%20lite) that has a Lite plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_12904-1535-3460","score":18.360613,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_01705-14609-15453","score":18.283566,"text":"\nCheck out the following list of key features that are available in a Lite account:\n\n\n\n* The account is free - no credit card required.\n* The account never expires.\n* You receive email notifications about your account status and quota limits.\n* You can create one instance of any service in the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite%20lite) that has a Lite plan.\n* After 10 days of no development activity, your apps go to sleep. You can wake up your apps by continuing to work on them.\n* After 30 days of no development activity, your service instances with Lite plans are deleted\n\n\n\nOnly Lite accounts created before 12 August 2021 can use 186 GBH of free buildpacks and Cloud Foundry apps with up to 256 MB of free instantaneous runtime memory per month. The use of one org in one IBM Cloud region is supported.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_00558-1499-3456","score":18.261003,"text":"\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-ibm-cloud-public"},{"document_id":"ibmcld_01660-23838-25711","score":18.103806,"text":"\nFor more information, see [Adding orgs and spaces](https:\/\/cloud.ibm.com\/docs\/account?topic=account-orgsspacesuserscreateorg).\n\n\n\n\n\n Why do I get logged out of my account? \n\nThe administrator of your account has customized the duration of active and inactive accounts, which requires users to enter their credentials after a specific time. For more information, see [Managing user's login session durations](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iam-work-sessions).\n\n\n\n\n\n Why can't I create a Lite account? \n\nBased on an update to our account registration that released starting 25 October 2021, new accounts are created as Pay-As-You-Go. As part of this update, you're asked to provide credit card information for identity verification. After you register and create your new account, you can access the full IBM Cloud catalog, including all Free and Lite plans. And, you get a $200 credit that you can use on products in the first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nIf you created a Lite account before 25 October 2021, you can continue working as you always have. However, you can go ahead and [upgrade to a Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqschangeacct) by adding your credit card information. This way, you can gain access to all Free service plans in the catalog.\n\n\n\n\n\n How do I see who created a service instance and when? \n\nFrom the [Resource list](https:\/\/cloud.ibm.com\/resources), expand the appropriate section, and click the row for the instance that you want more details about. Additional details about the resource display including when the resource was created and by whom.\n\nFor classic infrastructure services, you can get similar information by using the [Audit log](https:\/\/cloud.ibm.com\/docs\/account?topic=account-audit-log).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_11142-1400-2265","score":18.095293,"text":"\nGo to the [catalog](https:\/\/cloud.ibm.com\/catalog).\n2. Select the Lite and Free pricing plan options.\n\n\n\n\n\n\n\n Step 2: Create an instance \n\nCreate an instance of product that includes a free Lite plan or a Free tier pricing plan.\n\n\n\n1. Select the tile from the catalog after reviewing the filtered list of products.\n2. Enter any required information to create the instance.\n3. Click Create.\n\n\n\n\n\n\n\n Step 3: Check out the tutorials \n\nCheck out our [tutorials for Lite plans](https:\/\/cloud.ibm.com\/docs?tab=tutorials&filters=lite-account) for detailed steps about using IBM Cloud services that provide free Lite plans for you to implement common patterns based on best practices and proven technologies at no cost.\n\n\n\n\n\n Next steps \n\nBuild your apps! For more information, see the [Getting started tutorial](https:\/\/cloud.ibm.com\/docs\/apps?topic=apps-getting-started).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-tutorial-try-for-free"},{"document_id":"ibmcld_01705-2818-4572","score":17.73033,"text":"\n[Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) \n Invoiced on monthly consumption ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) \n\n\n\nNew accounts as of 25 October 2021 are created as Pay-As-You-Go or Subscription accounts. You're asked to provide credit card information for identity verification or a code for a purchased subscription. If you created an account before this date, you might be using a [Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount) and Lite pricing plans, which aren't affected by the recent account registraton update.\n\n\n\n\n\n Trial account \n\nTrial accounts offer timed access to a limited range of service plans and allow you to test out the platform without financial commitment. You can access Lite service plans and Free plans for a limited time with a trial account. To qualify for a trial account, go to [Harness the Power of IBM](https:\/\/ibm.biz\/academic) and validate your institution credentials or reach out to your educational program or course leader. If you don't have an account, select 'Register with a Code' during IBM Cloud registration to apply a code. If you have an account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console to apply the code.\n\nIf you upgrade your trial account to a Pay-As-You-Go account by entering a credit card, it can't be converted back to a trial account. IBM Cloud trial accounts are available for faculty and students at accredited academic institutions. Trial accounts expire after 30 days. Your account is deactivated when the trial period ends.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_07578-1075256-1077185","score":17.602926,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1077752-1079681","score":17.602926,"text":"\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel\/close\/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https:\/\/cloud.ibm.com\/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-474233-476319","score":19.046824,"text":"\nHere you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n\n\n\n* Can I change my capacity setting?\n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard. Launch IBM Cloudant Dashboard > Account > Capacity to view and change your provisioned throughput capacity and see the hourly and approximate monthly costs. You can also use the IBM Cloud\u00ae pricing calculator to see estimates in other currencies.\n* How do I know I exceeded the capacity limit that I set?\n\nThe Lite plan includes 1 GB of storage. If you exceed the limit, IBM Cloudant blocks your account from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan.\n\nThe first 20 GB of storage comes free with the Standard plan. You can store as much data as you want. Any storage over the 20 GB limit costs $0.0014 per GB per hour, which is approximately $1 per GB per month.\n* Where can I see my usage data?\n\nYou can see your current and historical usage bills in the IBM Cloud Dashboard. Go to Manage > Billing and usage > Usage. Here you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n* Provisioned throughput capacity model FAQ\n\n Provisioned throughput capacity model FAQ \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae calculates your provisioned throughput capacity based on these operation types: Read, Write, and Global Query.\n\n\n\nIBM Cloudant calculates provisioned throughput capacity by totaling the usage for each request class per second, where 1 second is a sliding window.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-474215-476301","score":19.046824,"text":"\nHere you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n\n\n\n* Can I change my capacity setting?\n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard. Launch IBM Cloudant Dashboard > Account > Capacity to view and change your provisioned throughput capacity and see the hourly and approximate monthly costs. You can also use the IBM Cloud\u00ae pricing calculator to see estimates in other currencies.\n* How do I know I exceeded the capacity limit that I set?\n\nThe Lite plan includes 1 GB of storage. If you exceed the limit, IBM Cloudant blocks your account from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan.\n\nThe first 20 GB of storage comes free with the Standard plan. You can store as much data as you want. Any storage over the 20 GB limit costs $0.0014 per GB per hour, which is approximately $1 per GB per month.\n* Where can I see my usage data?\n\nYou can see your current and historical usage bills in the IBM Cloud Dashboard. Go to Manage > Billing and usage > Usage. Here you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n* Provisioned throughput capacity model FAQ\n\n Provisioned throughput capacity model FAQ \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae calculates your provisioned throughput capacity based on these operation types: Read, Write, and Global Query.\n\n\n\nIBM Cloudant calculates provisioned throughput capacity by totaling the usage for each request class per second, where 1 second is a sliding window.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12918-3224-4645","score":17.59707,"text":"\nUse the slider to select the number of blocks of provisioned throughput capacity based on the maximum limit of either reads per second, writes per second, or global queries per second as required for your application. For example, if your application requires 1,000 reads per second, use the slider to select the capacity that offers 1,000 reads per second, 500 writes per second, and 50 global queries per second. Select this capacity even if you don't need the corresponding number of writes or global queries.\n\n\n\n\n\n Data usage pricing \n\nWhat about pricing for data overage? How does that work?\n\n\n\nTable 1. Pricing for data overage\n\n Plan Storage included Overage limit \n\n Lite 1 GB Your account is blocked from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan. \n Standard 20 GB Extra storage costs charged per GB per hour, for each GB over the included 20 GB. \n\n\n\n\n\n\n\n IBM Cloud Usage Dashboard \n\nHow does data populate the IBM Cloud Usage Dashboard?\n\nCurrent and historical usage bills can be seen in the IBM Cloud Dashboard, under Manage > Billing and usage > Usage. This view shows the totals for usage that are accrued during a particular month at the service, plan, or instance level. The Estimated Total reflects the bill so far for the month or for past complete months. It shows only the hourly costs that are accrued up to that point for the current month.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-pricing"},{"document_id":"ibmcld_07578-472680-474726","score":16.901247,"text":"\nIBM Cloudant pricing is based on the provisioned throughput capacity that you set for your instance, and the amount of data storage you use.\n\nWith IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae, you can increase or decrease your provisioned throughput capacity as needed, and pay pro-rated hourly. The provisioned throughput capacity is a reserved number of reads per second, writes per second, and global queries per second allocated to an instance. The throughput capacity setting is the maximum usage level for a given second.\n\nFor more information, see [IBM Cloudant Pricing](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-pricing).\n\n\n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard. Launch IBM Cloudant Dashboard > Account > Capacity to view and change your provisioned throughput capacity and see the hourly and approximate monthly costs. You can also use the IBM Cloud\u00ae pricing calculator to see estimates in other currencies.\n\n\n\n\n\nThe Lite plan includes 1 GB of storage. If you exceed the limit, IBM Cloudant blocks your account from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan.\n\nThe first 20 GB of storage comes free with the Standard plan. You can store as much data as you want. Any storage over the 20 GB limit costs $0.0014 per GB per hour, which is approximately $1 per GB per month.\n\n\n\n\n\nYou can see your current and historical usage bills in the IBM Cloud Dashboard. Go to Manage > Billing and usage > Usage. Here you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n\n\n\n* Can I change my capacity setting?\n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-472662-474708","score":16.901247,"text":"\nIBM Cloudant pricing is based on the provisioned throughput capacity that you set for your instance, and the amount of data storage you use.\n\nWith IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae, you can increase or decrease your provisioned throughput capacity as needed, and pay pro-rated hourly. The provisioned throughput capacity is a reserved number of reads per second, writes per second, and global queries per second allocated to an instance. The throughput capacity setting is the maximum usage level for a given second.\n\nFor more information, see [IBM Cloudant Pricing](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-pricing).\n\n\n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard. Launch IBM Cloudant Dashboard > Account > Capacity to view and change your provisioned throughput capacity and see the hourly and approximate monthly costs. You can also use the IBM Cloud\u00ae pricing calculator to see estimates in other currencies.\n\n\n\n\n\nThe Lite plan includes 1 GB of storage. If you exceed the limit, IBM Cloudant blocks your account from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan.\n\nThe first 20 GB of storage comes free with the Standard plan. You can store as much data as you want. Any storage over the 20 GB limit costs $0.0014 per GB per hour, which is approximately $1 per GB per month.\n\n\n\n\n\nYou can see your current and historical usage bills in the IBM Cloud Dashboard. Go to Manage > Billing and usage > Usage. Here you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n\n\n\n* Can I change my capacity setting?\n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03781-1481-2683","score":16.883522,"text":"\nThe number of GB used per month is 4 x 256 = 1024 MB or 1 GB per month. Assume that there are 24 x 30 = 720 hours in a month, so the application is charged for 1 x 720 = 720 GB-hours.\n\nIBM Cloud offers a free tier of [Cloud Foundry application usage](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts) that affects the overall cost for an application that's running, by reducing your costs.\n\nTwo Auto-Scaling policies (processor and memory)\n: The Auto-Scaling policies are free of charge.\n\n150 GB per month IBM Cloudant\n: The IBM Cloudant for IBM Cloud service charges are based on data storage and the ability to access that data by provisioned throughput capacity denoted by lookups, writes, and queries per second.\n\nAdd up the number of GB and deduct the 20-GB free allowance. 130 GB is charged per month. The total storage price includes the following parts:\n\n130 x 1 = $130\n(1,000 \/ 100) x 0.25 = $2.50\n(500 \/ 50) x 0.50 = $5.00\n(50 \/ 5) x 5.00 = $50.00\n\nThe total price is 130 + 2.50 + 5.00 + 50.00 = $187.50.\n\n20 GB inbound or outbound network traffic\n: Inbound and outbound network traffic is free of charge.\n\nWhen all the items are added, the total price of the application is $211.65.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-sample"},{"document_id":"ibmcld_00536-0-2049","score":16.662413,"text":"\n\n\n\n\n\n\n  Pricing FAQ \n\nIBM Cloudant pricing is based on the provisioned throughput capacity that you set for your instance, and the amount of data storage you use.\n\nWith IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae, you can increase or decrease your provisioned throughput capacity as needed, and pay pro-rated hourly. The provisioned throughput capacity is a reserved number of reads per second, writes per second, and global queries per second allocated to an instance. The throughput capacity setting is the maximum usage level for a given second.\n\nFor more information, see [IBM Cloudant Pricing](https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-pricing).\n\n\n\n  Can I change my capacity setting? \n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard. Launch IBM Cloudant Dashboard > Account > Capacity to view and change your provisioned throughput capacity and see the hourly and approximate monthly costs. You can also use the IBM Cloud\u00ae pricing calculator to see estimates in other currencies.\n\n\n\n\n\n  How do I know I exceeded the capacity limit that I set? \n\nThe Lite plan includes 1 GB of storage. If you exceed the limit, IBM Cloudant blocks your account from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan.\n\nThe first 20 GB of storage comes free with the Standard plan. You can store as much data as you want. Any storage over the 20 GB limit costs $0.0014 per GB per hour, which is approximately $1 per GB per month.\n\n\n\n\n\n  Where can I see my usage data? \n\nYou can see your current and historical usage bills in the IBM Cloud Dashboard. Go to Manage > Billing and usage > Usage. Here you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-faq-pricing"},{"document_id":"ibmcld_01660-8584-10307","score":16.472189,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_06420-7-2098","score":15.524126,"text":"\nPricing \n\nA IBM Cloud\u00ae Databases for EnterpriseDB Standard plan deploys as one highly available cluster with three data members. Your data is replicated on all three members. The Standard plan is priced based on the total amount of disk storage, RAM, dedicated cores, and backup storage that is allocated to deployments, prorated hourly. Databases for EnterpriseDB deployments have a minimum of 20 GB of disk and 1 GB of RAM per data member.\n\n\n\n Using the Pricing Calculator \n\nTemplates are provided for ease of use and provide balanced resource allocations appropriate for general purpose workloads. The Custom tab can be used to configure Disk, RAM, and vCPU, as desired.\n\nFor pricing estimation, use the Add to Estimate button on the [Databases for EnterpriseDB catalog page](https:\/\/cloud.ibm.com\/catalog\/databases-for-enterprisedb). Input your total consumption across three data members into the calculator. This is roughly tripled the size of your data because your data is replicated to all three members. For example, 20 GB of disk and 1 GB of RAM across two data members would be priced at 60 GB of disk and 3 GB of RAM respectively.\n\n\n\n\n\n Backups Pricing \n\nYou receive your total disk space purchased, per database, in free backup storage. For example, in a given month, if you have a Databases for DataStax deployment that has 20 GB of disk per member, and has three data members, you receive 60 GB of backup storage free for that month. If your backup storage utilization is greater than 60 GB for the month (in this scenario), you are charged an overage of $0.03\/month per gigabyte.\n\nBy default, Cloud Databases provides a daily backup that is stored for 30 days. These backups, and any on-demand backups you make, all count toward the above allocation.\n\nIn the above example, if your database contains 2 GB of data and you have not taken any on-demand backups, then your total backup size is 2 GB x 30 = 60 GB. Your backup costs are nil.\n\nIf your database contains 15 GB of data and you have not taken any on-demand backups, then your total backup size is 15 GB x 30 = 450 GB.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/databases-for-enterprisedb?topic=databases-for-enterprisedb-pricing"},{"document_id":"ibmcld_03729-3519-5413","score":15.507561,"text":"\nThese resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings\n* Encrypted data storage limit, for example 1 GB\n* Provisioned throughput capacity\n\n\n\nYou can easily find services for Lite plans in the catalog. By default, all services with a Lite plan are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/Lite.svg). Select a service to view the quota details for the associated Lite plan.\n\n\n\n\n\n Charges for compute resources \n\nYou're charged for the time that your apps run and the memory that's used in GB-hours. GB-hours is the calculation of the number of application instances that are multiplied by the memory per instance and by the hours that the instances run. You can customize the number of instances and the amount of memory per instance based on your needs. You can also add memory or instances to scale for more users. To get the amount charged, take your application instances that are multiplied by memory per instance and by hours running.\n\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01660-8584-10307","score":17.326452,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_01705-7-1620","score":17.277493,"text":"\nAccount types \n\nWhen you register with IBM Cloud\u00ae, you are set up with a Pay-As-You-Go account. Even though you provide your credit card information for account security and identity verification purposes, you can still use IBM Cloud for free by selecting products in the catalog that offer Free and Lite pricing plans. Another account type, called a Subscription account, is also available. With a Subscription account, you get many of the same features of a Pay-As-You-Go account, plus discounts for platform services and support with a more consistent billing structure that uses subscriptions.\n\n\n\n Comparing accounts \n\nThe following table provides a comparison of Trial, Pay-As-You-Go, and Subscription accounts. For more details about each account, see the sections that follow.\n\n\n\nTable 1. Comparison of IBM Cloud accounts\nThis table has row and column headers. The row headers identify the feature. The column headers identify the account type. To understand which features apply to the account types, navigate to the row, and find the feature that you're interested in.\n\n Trial Pay-As-You-Go Subscription \n\n [Free community buildpacks](https:\/\/cloud.ibm.com\/docs\/cloud-foundry-public?topic=cloud-foundry-public-available_buildpacks) 186 GBH 186 GBH 186 GBH \n Access to [Lite service plans](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_02301-7-1933","score":15.325591,"text":"\nUpgrading your account \n\nLite accounts make it easy to get started with IBM Cloud\u00ae and try out services. When you are ready for more, you can upgrade your account to a Pay-As-You-Go, or Subscription account to unlock the entire catalog of production-ready services.\n\nYou can check your current account type by going to Manage > Account > Account settings in the IBM Cloud console and looking in the Account Type section.\n\nNot sure which type of account you want to upgrade to? Get detailed information about the benefits of each account type in [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\nTo upgrade your account, you must have an access policy with the Editor role or higher on all account management services. For more information about IAM roles for managing accounts, see [Platform management roles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userrolesplatformroles).\n\n\n\n Upgrading to a Pay-As-You-Go account \n\nWith a Pay-As-You-Go account, you pay for only what you use beyond the free runtime and service allowances. After you upgrade, you can continue to use any instances that you created with your Lite account.\n\nTo upgrade to a Pay-As-You-Go account, complete the following steps.\n\n\n\n1. Go to Manage > Account in the IBM Cloud console.\n2. Select Account settings, and click Add credit card.\n3. Enter your payment information, click Next, and submit your information.\n\n\n\nAfter your payment information is processed, your account is upgraded, and you can explore and access the full IBM Cloud catalog. For any billable services that you use beyond any free allowances, you receive a monthly invoice.\n\nIf you're upgrading to reactivate a deactivated account, your account might take a few days to be fully available. If your account continues to be in a pending state, see [Why can't I upgrade my account?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-ts_upgrade_cc) for help.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account"},{"document_id":"ibmcld_03704-1531-3564","score":15.262255,"text":"\nWhat's the difference between a Pay-As-You-Go and Subscription account? \n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\n\n\n What happens if my Lite plan instance reaches the monthly quota? \n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n\n\n\n\n\n Can I use PayPal as a payment method? \n\nAs of March 31, 2023, PayPal is no longer accepted.\n\n\n\n\n\n Can I update my credit card? \n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_16727-1042765-1044817","score":14.79693,"text":"\nContact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1042894-1044946","score":14.79693,"text":"\nContact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_11133-1287-2850","score":14.786066,"text":"\nApplicable Additional SDs for any service ordered using your IBM Cloud account are available at [https:\/\/www.ibm.com\/terms\/?id=i126-6605](https:\/\/www.ibm.com\/terms\/?id=i126-6605). The additional SDs contain links to the applicable Data Sheet for each service.\n\n\n\n\n\n All other accounts \n\nAs of 10 December 2020, this section describes the Terms of Use for the following types of IBM Cloud accounts:\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n* New and existing contracts for IBM Global Technology Services and Cloud Services\n* New and existing Lite accounts worldwide\n\n\n\nYour IBM Cloud account and any services that are ordered from the IBM Cloud are provided under the terms of the Service Description for IBM Cloud available at [https:\/\/www.ibm.com\/terms\/?id=i126-6605](https:\/\/www.ibm.com\/terms\/?id=i126-6605) and one of the following base agreements:\n\n\n\n* IBM Cloud Services Agreement (local country version*) for Lite accounts, non-US Dollar credit card billing, or if you select invoicing from IBM, available at [https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/) (select your country);\n* SoftLayer Cloud Service Agreement for US Dollar credit card billing, available at\n\n[https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=softlayer#detail-document](https:\/\/www.ibm.com\/support\/customer\/csol\/terms\/?cat=softlayerdetail-document)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-terms"},{"document_id":"ibmcld_16727-1079289-1081125","score":14.543118,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1076793-1078629","score":14.543118,"text":"\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_01705-13208-15001","score":14.38946,"text":"\nIf you created a Lite account before 25 October 2021, your account doesn't expire and you can work in IBM Cloud for free by accessing services with select Lite plans, which are displayed with a Lite tag ![Lite tag](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/Lite.svg) in the catalog. To gain access to all Free plans, you can go ahead and [upgrade to a Pay-As-You-Go account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqschangeacct) by adding your credit card information.\n\nStarting 25 October 2021, all new accounts are created as Pay-As-You-Go based on an update to our account registration process. As part of this update, you're asked to provide credit card information for identity verification. You have full access to the catalog, including all Free and Lite plans, and you get a $200 credit that you can apply in your first 30 days. You pay only for billable services that you use, with no long-term contracts or commitments.\n\nLite accounts have access to a single resource group that's created for you with the name Default. All of your service's instances are automatically added to this resource group. You can update the name of this resource group at any time. See [Renaming a resource group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rgsrename_rgs) for the detailed steps.\n\n\n\n What's available in a lite account? \n\nCheck out the following list of key features that are available in a Lite account:\n\n\n\n* The account is free - no credit card required.\n* The account never expires.\n* You receive email notifications about your account status and quota limits.\n* You can create one instance of any service in the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog\/?search=label:lite%20lite) that has a Lite plan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3868528072,"ndcg_cut_5":0.3868528072,"ndcg_cut_10":0.3868528072}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03749-1776-3774","score":19.730612,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/enterprise-billing-usage.svg)\n\nFigure 1.Enterprise billing and usage management\n\n\n\n\n\n Billing options \n\nEnterprises require subscription billing or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). In subscription billing, you purchase a subscription for an amount of credit to spend during the subscription term, and usage is deducted from the subscription credit at a discounted rate. The Enterprise Savings Plan billing model is similar to subscription billing. You commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nThe account that you use to create the enterprise must be a [Subscription account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountssubscription-account) or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). After the enterprise is created, you can add more accounts to the enterprise. If you add a Lite or trial account, the account is automatically upgraded to a Pay-As-You-Go account.\n\nSome Pay-As-You-Go accounts can't be directly imported into an enterprise, such as many Pay-As-You-Go accounts that are billed in United States dollars (USD). However, you can still import these accounts into your enterprise by converting them to Subscription accounts and then importing them. To convert an account, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\nEach enterprise supports only a single billing currency. All accounts must use the enterprise billing currency before you add them to the enterprise. Existing accounts that are imported into the enterprise no longer separately manage their billing.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise&interface=ui"},{"document_id":"ibmcld_01183-1670-3629","score":18.638117,"text":"\n* Scaling options to customize throughput, storage capacity, or both.\n\n\n\nThe architecture is highly available when you choose to deploy into a multi-zone region. The service is distributed across three availability zones, which means that the cluster is resilient to the failure of a single zone or any component within that zone.\n\n\n\n\n\n Satellite plan \n\nThe IBM Cloud Satellite\u00ae plan is appropriate if you want to deploy an Enterprise plan into Satellite locations of your own choice. Using Satellite, you can create a hybrid environment that brings the scalability and on-demand flexibility of public cloud services to the applications and data that run in your secure private cloud.\n\nThe Event Streams Satellite plan does not yet provide the compliance certifications that the Enterprise or Standard plans conform to.\n\n\n\n\n\n What is supported by the Lite, Standard, Enterprise, and Satellite plans \n\nThe following table summarizes what is supported by the plans:\n\n\n\nTable 1. Plan comparison table\n\n Lite plan Standard plan Enterprise plan Satellite plan \n\n Tenancy Multi-tenant Multi-tenant Single tenant Single tenant \n Availability zones 3 3 3 <br>(1 in single zone locations) 3 \n Availability 99.99% <br><br>[1] 99.99% 99.99% (99.9% in single zone locations) <br><br>[2] Not applicable \n Kafka version on cluster Kafka 3.3 Kafka 3.3 Kafka 3.3 Kafka 3.3 \n Kafka Connect and Kafka Streams supported No Yes Yes Yes \n Stream to Cloud Object Storage by using SQL Query No Yes Yes No \n Managed Schema Registry supported No No Yes Yes <br><br>[3] \n Customer-managed encryption No No Yes <br><br>[4] No \n Fine-grained access control Yes Yes Yes Yes \n Activity tracker events No Yes Yes No \n Monitoring Event Streams metrics by using IBM Cloud Monitoring Yes Yes Yes Yes \n Cloud Service Endpoint support No No Yes Not applicable \n Scale plan capacity No No Yes No \n Maximum number of partitions 1 <br><br>[5] 100 3000 - 9000 scales with throughput <br><br>[6] 3000","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose"},{"document_id":"ibmcld_03735-2945-4853","score":18.19967,"text":"\nClick the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Share.\n3. Click Copy link and share the link with users in your account.\n\n\n\n\n\n\n\n Creating quotes for classic infrastructure services \n\nYou can generate and view quotes for only Bare Metal Servers, Virtual Server, and Gateway add-ons. Any user with access to the account can create quotes. To view quotes, you need to either be the account owner or have the Add\/Upgrade Storage (StorageLayer), Add Server, or Add\/Upgrade Services [classic infrastructure permission](https:\/\/cloud.ibm.com\/docs\/account?topic=account-mngclassicinfra).\n\n\n\n1. Generate a quote by clicking Save as quote from the Order Summary section on the product details page. Or contact a IBM Cloud sales representative.\n\nIf you're in a Lite account, select Email quote when you enter your contact details so that you can view your quote after you create it. Only billable accounts can view quotes in the console.\n2. View your quote by going to Manage > Billing and usage, and select Sales > Device quotes. If you have access, you can purchase the quoted product by clicking the quote and confirming the order.\n\n\n\n\n\n\n\n Supported billing currencies \n\nThe following table lists the supported billing currencies.\n\nAny Pay-As-You-Go accounts created after 25 October 2021 are billed in USD. There are exceptions that apply to users in India who are billed in INR by using a credit card. Also, if you're working with IBM Cloud Sales to set up a Subscription account or the Enterprise Savings Plan billing model, you can still be billed in your local currency.\n\n\n\nTable 1. Supported currencies\n\n ISO 4217 code Currency \n\n AUD Australian dollar \n BRL Brazilian real \n CAD Canadian dollar \n CHF Swiss franc \n DKK Danish krone \n EUR Euro \n GBP Pound sterling \n INR Indian rupee \n JPY Japanese yen","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_16729-268102-270004","score":18.179138,"text":"\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\nIBM Cloud overview\n\n\n\n* 10 minutes\n* 2023-04-03\n\n\n\n[Setting up an enterprise](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial)Setting up an enterprise\n\nThis tutorial walks you through how to set up an enterprise by department so you can manage and track usage costs for multiple IBM Cloud\u00ae accounts. By completing this tutorial, you learn how to create an enterprise, add accounts and organize them in account groups, invite users, and explore subscriptions.\n\nRunning secure enterprise workloads\n\n\n\n* 10 minutes\n* 2023-04-17\n\n\n\n[Use trusted profiles as foundation for secure cloud environments](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-trusted-profile-for-enterprise-security)Use trusted profiles as foundation for secure cloud environments\n\nThis tutorial may incur costs. Use the Cost Estimator to generate a cost estimate based on your projected usage.\n\nRunning secure enterprise workloads Kubernetes service\n\n+2\n\nActivity Tracker hosted event search,Container Registry\n\n\n\n* 2 hours\n* 2023-07-14\n\n\n\n[Getting set up to sell services](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-started)Getting set up to sell services\n\nWelcome to IBM Cloud\u00ae! To start onboarding your service to our cloud platform, first complete a few tasks: provide your company and product details, create a test environment, and set up access for your team to help with the onboarding process.\n\nSelling on IBM Cloud\n\n\n\n* 60 minutes\n* 2023-02-09","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_12544-1669-3632","score":17.970343,"text":"\nUsage access is managed separately and can be targeted to the enterprise, an account group, or an account.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d4595e5202a9a27767cf034e81b038cdf772e0d5\/secure-enterprise\/includes\/billing-usage\/includes\/billing-usage\/images\/enterprise-billing-usage.svg)\n\nFigure 1.Enterprise billing and usage management\n\n\n\n\n\n Billing options \n\nEnterprises require subscription billing or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). In subscription billing, you purchase a subscription for an amount of credit to spend during the subscription term, and usage is deducted from the subscription credit at a discounted rate. The Enterprise Savings Plan billing model is similar to subscription billing. You commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nThe account that you use to create the enterprise must be a [Subscription account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountssubscription-account) or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). After the enterprise is created, you can add more accounts to the enterprise. If you add a Lite or trial account, the account is automatically upgraded to a Pay-As-You-Go account.\n\nSome Pay-As-You-Go accounts can't be directly imported into an enterprise, such as many Pay-As-You-Go accounts that are billed in United States dollars (USD). However, you can still import these accounts into your enterprise by converting them to Subscription accounts and then importing them. To convert an account, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\nEach enterprise supports only a single billing currency.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"},{"document_id":"ibmcld_01183-7-2154","score":17.732346,"text":"\nChoosing your plan \n\nEvent Streams is available as Lite plan, Standard plan, Enterprise plan, or Satellite plan depending on your requirements.\n\nFor information about Event Streams plan pricing, see the [catalog](https:\/\/cloud.ibm.com\/catalog). Search for Event Streams, then click the Event Streams tile to go to the provisioning page.\n\n\n\n Lite plan \n\nThe Lite plan is free for users who want to try out Event Streams or build a proof-of-concept. Do not use the Lite plan for production use. It offers shared access to a multi-tenant Event Streams cluster.\n\n\n\n\n\n Standard plan \n\nThe Standard plan is appropriate if you require event ingest and distribution capabilities but do not require any additional benefits of the Enterprise plan. The Standard plan offers shared access to a multi-tenant Event Streams cluster that seamlessly autoscales as you increase the number of partitions you are using for your workload.\n\nThe architecture is highly available by default. The service is distributed across three availability zones, which means that the cluster is resilient to the failure of a single zone or any component within that zone.\n\n\n\n\n\n Enterprise plan \n\nThe Enterprise plan is appropriate if data isolation, performance, and increased retention are important considerations. The Enterprise plan includes the following features:\n\n\n\n* Exclusive access to a single-tenant Event Streams service instance deployed in a highly available multi zone region (MZR).\n* Option to provision a single-tenant Event Streams service instance in a geographically local but single zone location [(SZR)](https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-slasla_szr).\n* Scaling options to customize throughput, storage capacity, or both.\n\n\n\nThe architecture is highly available when you choose to deploy into a multi-zone region. The service is distributed across three availability zones, which means that the cluster is resilient to the failure of a single zone or any component within that zone.\n\n\n\n\n\n Satellite plan \n\nThe IBM Cloud Satellite\u00ae plan is appropriate if you want to deploy an Enterprise plan into Satellite locations of your own choice.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/EventStreams?topic=EventStreams-plan_choose"},{"document_id":"ibmcld_01705-8543-10743","score":17.666306,"text":"\nLarge organizations and other users with large cloud workloads can benefit from the savings and predictable billing that are provided by subscriptions. IBM Cloud offers multiple types of subscriptions to fit your usage needs.\n\nA subset of subscription accounts are eligible for the new Enterprise Savings Plan billing model. For more information, see [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountscommitment-model).\n\n\n\n Platform subscriptions \n\nWhen you purchase a subscription for the IBM Cloud platform, you get discounted credit that pays for services and other resources that you create from the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog).\n\nYour resource usage is deducted from your total subscription amount. Even if your usage varies from month to month, you get predictable, consistent billing. If your usage exceeds your total subscription amount, you're charged the non-discounted rate for the overage. For more information about tracking your subscription usage, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYour subscription applies to most services in the catalog. However, some services use a specific pricing plan that requires you to purchase it separately.\n\n\n\n\n\n Support subscriptions \n\nBasic support is included with your Subscription account. If you want to enhance your support experience for production-critical resources, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) to purchase a support subscription for an Advanced or Premium support plan. With a support subscription, you commit to a monthly spending amount that goes towards your support costs.\n\nSupport subscription credit is separate from any platform or service subscription credit in your account and can't be spent on resource usage. For more information, see [How subscription credit is spent](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptionssubscription-basics).\n\n\n\n\n\n Service bundle subscriptions \n\nService bundle subscriptions give you access and credit toward a set of services within a particular domain that are targeted for popular use cases.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_07067-6420-8417","score":17.63307,"text":"\nMany other API methods changed and some are not available in v2. For a detailed comparison of the v1 and v2 API methods, see [API version comparison](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2-api).\n\n\n\n\n\n\n\n Picking a service plan \n\nChoose among the Plus, Enterprise, and Premium managed plans or opt for an on-premises installation by purchasing the Discovery Cartridge for IBM Cloud Pak for Data. Review the benefits and limits of each type of plan before you choose one.\n\n\n\n* For more information about the plans, see [Discovery pricing plans](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-pricing-plans).\n* For more information about artifact limits, see [Limit details](https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-version-chooseplan-limit-links).\n\n\n\nThe following table shows plan types for managed deployments that are generally similar between v1 and v2.\n\n\n\nSimilar plans\n\n Current v1 plan Example v1 data usage Similar v2 plan \n\n Lite Not applicable Plus Trial (no charge for 30 days only) \n Advanced (low usage) 10,000 documents, 10,000 queries per month Plus \n Advanced (high usage) 100,000 documents, 100,000 queries per month Enterprise \n Premium Not applicable Enterprise or Premium \n\n\n\nTo get information about the current storage, documents, and collections used, click the Environment details icon from the product user interface header.\n\nYou cannot do an in-place upgrade from a v1 plan, such as Lite or Advanced, to a v2 plan. You must create a new v2 plan, and then move your data to the new service instance. While you migrate your data from v1 to v2, you will likely have both a v1 and v2 instance deployed at the same time. Consider using the 30-day no charge trial that is available with your first Plus plan instance during this time.\n\n\n\n\n\n\n\n Collecting metrics \n\nMake a note of the following information so you can compare it to your service instance data after the migration:\n\n\n\n* Number of collections","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-migrate-to-v2"},{"document_id":"ibmcld_01660-8584-10307","score":17.496183,"text":"\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountfaqs"},{"document_id":"ibmcld_10906-5101-6829","score":17.278522,"text":"\nConsider the following when determining whether you need an enterprise or a stand-alone account:<br><br><br><br> * In an enterprise, subscription discounts and cloud credits are available to all accounts that are in the enterprise.<br> * Stand-alone accounts control their own billing. If your company is globally distributed, you might have a mix of multiple enterprises and stand-alone accounts to support regional billing requirements.<br><br><br><br>Review the [What is an enterprise?](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise) documentation to determine whether you need an enterprise. \n <br><br> * Create and configure your IBM Cloud account<br><br><br> Even if you plan on using an enterprise, you need to create an IBM Cloud account. You can create your account by going to the [account registration](https:\/\/cloud.ibm.com\/registration) page and providing an email address and other additional information. The email address that is used to register becomes the account owner, but you can change this if required later on by following the steps in [Transferring ownership of your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-transfer&interface=ui).<br><br>When setting up an account for your company or organization, it is best to use a functional ID, some teams call them service accounts, associated with your company. Keep in mind that you will need to monitor for automated emails sent to this email address for warnings about service usage, services being deprecated, new services available, and more.<br><br>When you log in to the account for the first time, you are required to provide a credit card or subscription code to complete your account set up.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklist"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"47b2471404382af6e973013ab1cf96b9<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03735-2945-4853","score":21.224895,"text":"\nClick the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Share.\n3. Click Copy link and share the link with users in your account.\n\n\n\n\n\n\n\n Creating quotes for classic infrastructure services \n\nYou can generate and view quotes for only Bare Metal Servers, Virtual Server, and Gateway add-ons. Any user with access to the account can create quotes. To view quotes, you need to either be the account owner or have the Add\/Upgrade Storage (StorageLayer), Add Server, or Add\/Upgrade Services [classic infrastructure permission](https:\/\/cloud.ibm.com\/docs\/account?topic=account-mngclassicinfra).\n\n\n\n1. Generate a quote by clicking Save as quote from the Order Summary section on the product details page. Or contact a IBM Cloud sales representative.\n\nIf you're in a Lite account, select Email quote when you enter your contact details so that you can view your quote after you create it. Only billable accounts can view quotes in the console.\n2. View your quote by going to Manage > Billing and usage, and select Sales > Device quotes. If you have access, you can purchase the quoted product by clicking the quote and confirming the order.\n\n\n\n\n\n\n\n Supported billing currencies \n\nThe following table lists the supported billing currencies.\n\nAny Pay-As-You-Go accounts created after 25 October 2021 are billed in USD. There are exceptions that apply to users in India who are billed in INR by using a credit card. Also, if you're working with IBM Cloud Sales to set up a Subscription account or the Enterprise Savings Plan billing model, you can still be billed in your local currency.\n\n\n\nTable 1. Supported currencies\n\n ISO 4217 code Currency \n\n AUD Australian dollar \n BRL Brazilian real \n CAD Canadian dollar \n CHF Swiss franc \n DKK Danish krone \n EUR Euro \n GBP Pound sterling \n INR Indian rupee \n JPY Japanese yen","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_10906-10094-12223","score":19.71063,"text":"\n<br><br> * Activate a subscription code<br><br><br> With an IBM Cloud subscription, you get discounted usage for platform services and support by committing to a minimum spending commitment for a certain period of time. After you buy a subscription for platform or support credit, you must add the credit to your account by applying a subscription code to your stand-alone account or enterprise. Applying the code ensures that the credit is added to your account, and you don't have unexpected overage charges. Make sure to add any purchased subscriptions to your account before creating resources. For more information, see [applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code). \n <br><br> * Create and configure an enterprise<br><br><br> When you create an enterprise, the account that you used to initiate the process is automatically added to the enterprise, and a new enterprise account is created to manage the billing for the enterprise. Follow the steps in the [Setting up an enterprise](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial) documentation to create an enterprise. Keep in mind that when using an enterprise, users within each account in the enterprise can create, use, and collaborate on resources just as they can in a stand-alone account. \n <br><br> * Assign enterprise access to users<br><br><br> If you chose to create an enterprise, you might require that administrators manage the enterprise performing functions, such as creating account groups, creating and managing accounts. Review the access that is required, and add users as needed. For more information, see [Assigning access for enterprise management](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-assign-access-enterprise). \n <br><br> * Create resource groups<br><br><br> Use resource groups to organize an account's resources for access control and billing purposes. For example, creating a resource group per project allows costs to be tracked at the project level even when your resources are distributed across regions.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklist"},{"document_id":"ibmcld_03749-1776-3774","score":19.15464,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/enterprise-billing-usage.svg)\n\nFigure 1.Enterprise billing and usage management\n\n\n\n\n\n Billing options \n\nEnterprises require subscription billing or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). In subscription billing, you purchase a subscription for an amount of credit to spend during the subscription term, and usage is deducted from the subscription credit at a discounted rate. The Enterprise Savings Plan billing model is similar to subscription billing. You commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nThe account that you use to create the enterprise must be a [Subscription account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountssubscription-account) or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). After the enterprise is created, you can add more accounts to the enterprise. If you add a Lite or trial account, the account is automatically upgraded to a Pay-As-You-Go account.\n\nSome Pay-As-You-Go accounts can't be directly imported into an enterprise, such as many Pay-As-You-Go accounts that are billed in United States dollars (USD). However, you can still import these accounts into your enterprise by converting them to Subscription accounts and then importing them. To convert an account, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\nEach enterprise supports only a single billing currency. All accounts must use the enterprise billing currency before you add them to the enterprise. Existing accounts that are imported into the enterprise no longer separately manage their billing.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise&interface=ui"},{"document_id":"ibmcld_01705-2818-4572","score":19.076263,"text":"\n[Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) \n Invoiced on monthly consumption ![Feature available](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d8c6eec891cff72b666dc24bd3211810c77fb42\/icons\/icon_enabled.svg) \n\n\n\nNew accounts as of 25 October 2021 are created as Pay-As-You-Go or Subscription accounts. You're asked to provide credit card information for identity verification or a code for a purchased subscription. If you created an account before this date, you might be using a [Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountsliteaccount) and Lite pricing plans, which aren't affected by the recent account registraton update.\n\n\n\n\n\n Trial account \n\nTrial accounts offer timed access to a limited range of service plans and allow you to test out the platform without financial commitment. You can access Lite service plans and Free plans for a limited time with a trial account. To qualify for a trial account, go to [Harness the Power of IBM](https:\/\/ibm.biz\/academic) and validate your institution credentials or reach out to your educational program or course leader. If you don't have an account, select 'Register with a Code' during IBM Cloud registration to apply a code. If you have an account, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console to apply the code.\n\nIf you upgrade your trial account to a Pay-As-You-Go account by entering a credit card, it can't be converted back to a trial account. IBM Cloud trial accounts are available for faculty and students at accredited academic institutions. Trial accounts expire after 30 days. Your account is deactivated when the trial period ends.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts"},{"document_id":"ibmcld_12559-6637-8921","score":18.9797,"text":"\nIf you want to assign a different user as the account owner, enter their IBMid in the Owner field. The account owner has full access to manage the account.\n5. Select Marketing as the parent of this account.\n6. Click Create.\n\n\n\nAfter you create the account, the account owner can log in to the account to invite other users and manage their access.\n\nRepeat the steps to create more accounts. As an example, the Example Corp enterprise has the following child account and parent account group hierarchy.\n\n\n\nTable 1. Child account and parent account group hierarchy\n\n Child Parent \n\n Print Marketing \n Frontend Engineering \n Backend Engineering \n Direct Sales \n Online Sales \n Enablement Sales \n\n\n\n\n\n\n\n Step 5: Explore subscriptions \n\nYou can explore subscriptions in the enterprise from the enterprise dashboard. Any existing subscriptions from accounts that are imported into the enterprise are moved to the enterprise account and added to the enterprise [credit pool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprisecredit-pool).\n\n\n\n1. Go back to the Enterprise dashboard by clicking Dashboard. In the Billing section, you can view available credit, remaining credit, and subscription expiration dates.\n2. To view details about all subscriptions in the enterprise, click View subscriptions.\n\nIn the Platform subscription section, you can view the subscription start date, end date, starting credit and available credit. To add more credit, you can purchase additional subscriptions and apply the subscription code.\n\n\n\n\n\n\n\n Step 6: Invite users to manage your enterprise \n\nIn a large organization like Example Corp., there are likely other people who you want to give access to manage the enterprise so they can do their jobs. In this case, you want to give department leads of the Marketing, Development, and Sales account groups access to manage their accounts and resource usage, and you want the Example Corp. financial officer to have access to view the entire enterprise's billing and usage. To give other users access, you invite them to the enterprise account and assign them the appropriate access.\n\nFirst, invite the department leads and assign them access.\n\n\n\n1. Go to the Enterprise dashboard by clicking Manage > Enterprise in the IBM Cloud console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=ui"},{"document_id":"ibmcld_03786-1684-3421","score":18.858088,"text":"\nFrom the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date. Ensure that you add the code to the correct account because the subscription credits can't be removed after the code is applied. After you add the subscription code, you might see that the status of the subscription as IN_PROCESS. Contact IBM Cloud Sales to review the account.\n3. Enter the subscription code, and click Apply.\n\nIf you have separate codes for platform and support credit, apply the platform subscription code first, then apply the support subscription code.\n\n\n\nTo manually apply the subscription code to a new account, complete the following steps:\n\n\n\n1. Go [create an IBM Cloud account](https:\/\/cloud.ibm.com\/registration), and enter the required information.\n2. Click Register with a code instead of entering your credit card information.\n3. Click Create account.\n\n\n\nIf you don't know your seller, the codes are applied in the wrong order, or you experience issues with applying the codes, [contact IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\nFor information about other codes and credits that can be applied to different account types, see [Applying feature codes to a Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) or [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code"},{"document_id":"ibmcld_12544-1669-3632","score":18.847733,"text":"\nUsage access is managed separately and can be targeted to the enterprise, an account group, or an account.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/d4595e5202a9a27767cf034e81b038cdf772e0d5\/secure-enterprise\/includes\/billing-usage\/includes\/billing-usage\/images\/enterprise-billing-usage.svg)\n\nFigure 1.Enterprise billing and usage management\n\n\n\n\n\n Billing options \n\nEnterprises require subscription billing or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). In subscription billing, you purchase a subscription for an amount of credit to spend during the subscription term, and usage is deducted from the subscription credit at a discounted rate. The Enterprise Savings Plan billing model is similar to subscription billing. You commit to spend a certain amount on IBM Cloud and receive discounts across the platform. You are billed monthly based on your usage and you continue to receive a discount even after you reach your committed amount.\n\nThe account that you use to create the enterprise must be a [Subscription account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountssubscription-account) or an account with the [Enterprise Savings Plan billing model](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use). After the enterprise is created, you can add more accounts to the enterprise. If you add a Lite or trial account, the account is automatically upgraded to a Pay-As-You-Go account.\n\nSome Pay-As-You-Go accounts can't be directly imported into an enterprise, such as many Pay-As-You-Go accounts that are billed in United States dollars (USD). However, you can still import these accounts into your enterprise by converting them to Subscription accounts and then importing them. To convert an account, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\nEach enterprise supports only a single billing currency.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"},{"document_id":"ibmcld_08063-1403-3121","score":18.84171,"text":"\nTechnical support for Lite accounts with free support is provided by the [IBM Cloud docs](https:\/\/cloud.ibm.com\/docs) and [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud?tab=Newest).\n\nBy default, account users don't have access to create, update, search, or view cases. The account owner must provide users access by assigning an Identity and Access Management (IAM) access policy. For more information, see [Assigning user access for working with support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-accessaccess).\n\n\n\n Creating a support case \n\nComplete the following steps to create a support case:\n\n\n\n1. From the IBM Cloud console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9147bc2ffd9bafd03e4559b378e714fac17a4977\/icons\/help.svg) > Support center.\n2. From the Contact support section, click Create a case.\n3. Select the category for your issue.\n4. Select the topic and the associated subtopic that is most closely related to your issue, and click Next.\n5. Complete the required fields.\n\nTo maintain security, do not include any personal information, sensitive data, or device or service credentials in case responses. For example, don't include passwords, API keys, secrets, or credit card information.\n6. Optional:\n\n\n\n* Attach files and resources to provide more details about the issue you're experiencing.\n* If you'd like a user in you account to be updated about the case, add them by using the Contact watchlist. For more information about assigning users access to your account, see [Adding users to your case management access group](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-accessadd-user-access-group).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-case&interface=ui"},{"document_id":"ibmcld_08069-7-2230","score":18.771442,"text":"\nBasic, Advanced, and Premium Support plans \n\nYou can choose a Basic, Advanced, or Premium support plan to customize your IBM Cloud\u00ae support experience for your business needs. The level of support that you select determines the severity that you can assign to support cases and your level of access to the tools available in the Support Center.\n\nIf you have free support, you're provided technical support through [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud?tab=Newest). Also, with a Lite account and free support, you can open cases that are related to access management, accounts, and billing and usage. If you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative.\n\nInitial response Service Level Objectives (SLO) do not apply to any billing, invoice, or sales related inquiry or cases.\n\nThe following table shows the support types available for Pay-As-You-Go accounts, Subscription accounts, and the Enterprise Savings Plan billing model. For more information about accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\nTable 1. Support plans\n\n Basic Support Advanced Support Premium Support \n\n Description Basic business protection that is included with your IBM Cloud Pay-As-You-Go or Subscription account Prioritized case handling and support experience that is aligned with your business needs for your Pay-As-You-Go account, Subscription account, or Enterprise Savings Plan billing model Client engagement that is aligned with your business outcomes to accelerate time-to-value for your Pay-As-You-Go account, Subscription account, or Enterprise Savings Plan billing model \n Availability 24 x 7 access to the IBM Cloud technical support team through cases <br>Phone and chat are available only for Pay-As-You-Go and Subscription accounts 24 x 7 access to the IBM Cloud technical support team through cases, phone, and chat 24 x 7 access to the IBM Cloud technical support team through cases, phone, and chat \n [Case severity](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity) Not applicable Case severity ranking available Case severity ranking available","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans"},{"document_id":"ibmcld_11163-68646-70819","score":18.752922,"text":"\nFor more information, see [Support subscriptions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accountssupport-subscriptions).\n\nYou can also now view your support subscriptions in the IBM Cloud console so you can keep track of your available credit. For more information, see [Viewing your support costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-support).\n\n\n\n\n\n 12 September 2019 \n\nRedirecting SoftLayer to IBM Cloud\n: SoftLayer account owners who previously didn't have access to the IBM Cloud platform can now manage their infrastructure, services, and applications from one location: [cloud.ibm.com](https:\/\/cloud.ibm.com).\n\n\n\n\n\n\n\n July 2019 \n\n\n\n 25 July 2019 \n\nIBM Cloud enterprises for centrally managing multiple accounts\n: You can now centrally manage billing and usage for multiple accounts by creating an IBM Cloud enterprise. With an enterprise, you can create a multitiered hierarchy of accounts by organizing related accounts into account groups. Enterprises simplify management of multiple accounts with the following key features:\n\n\n\n* Consolidated billing means that you can manage billing, invoicing, and payment for all accounts from a single place, the enterprise account.\n* Subscription credit is aggregated into a credit pool and shared with all accounts in the enterprise. Not only is tracking your subscriptions easier, but you can get fewer, larger subscriptions for a better discount because the credit is shared.\n* Top-down usage reporting gives you a unified view of usage costs from all accounts, organized according to your enterprise hierarchy.\n\n\n\nIf you have multiple accounts, at least one of which is a Subscription account, you can create an enterprise. See [What is an enterprise?](https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-what-is-enterprise) and [Introducing IBM Cloud Enterprises](https:\/\/www.ibm.com\/cloud\/blog\/announcements\/introducing-ibm-cloud-enterprises) for more information.\n\nSubscriptions page for tracking subscription credit spending\n: If you have a Subscription account, you can now view all of your subscriptions and analyze your credit spending on the Subscriptions page.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatsnew"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-7-2136","score":10.292427,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-7-2136","score":10.292427,"text":"\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_16727-453100-455403","score":9.561079,"text":"\nConflicted documents harm performance. A highly concurrent update-in-place pattern also increases the likelihood that writes get rejected. In that situation, the _rev parameter isn\u2019t the expected one, which forces your application to retry and delay processing.\n\nThis conflicted-document scenario is significantly more likely to happen for updates that occur more often than once a second. Use immutable documents for updates that occur more than once every 10 seconds to be on the safe side.\n\n\n\n\n\nRather than using views as search indexes, you can use the search get me all person documents and make the search extract the data for you. For example, you can retrieve all 10,000 person documents to calculate the combined hours worked. However, it's better to use a view with a composite key to pre-calculate the hours worked by year, month, day, half-day, and hour by using the _sum built-in reduce. You save work in your application and allow the database to concentrate on serving many small requests. This method is preferable to reading huge amounts of data from disk to service a single large request.\n\n\n\n\n\nIt's straightforward. First, both maps and reduces are precomputed, so the result of a reduce function is a cheap operation. The operation cost is low even when compared to the significant amounts of IO required to stream hundreds or even thousands of documents from the on-disk storage.\n\nAt a deeper level, when a node receives a view request, it asks the nodes that hold the shard replicas of the view's database for the results of the view request from the documents in each shard. As it receives the answers, taking the first answer for each shard replica, the node that services the view request combines the results and streams the final result to the client. As more documents are involved, it takes longer for each replica to stream the results from disk and across the network. The node that services the request also has much more work to do in combining the results from each database shard.\n\nOverall, the goal is for a view request to require the minimum amount of data from each shard. This practice minimizes the time that the data is in transit and being combined to form the final result. Using the power of views to precompute aggregate data is one way to achieve this aim.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-453118-455421","score":9.561079,"text":"\nConflicted documents harm performance. A highly concurrent update-in-place pattern also increases the likelihood that writes get rejected. In that situation, the _rev parameter isn\u2019t the expected one, which forces your application to retry and delay processing.\n\nThis conflicted-document scenario is significantly more likely to happen for updates that occur more often than once a second. Use immutable documents for updates that occur more than once every 10 seconds to be on the safe side.\n\n\n\n\n\nRather than using views as search indexes, you can use the search get me all person documents and make the search extract the data for you. For example, you can retrieve all 10,000 person documents to calculate the combined hours worked. However, it's better to use a view with a composite key to pre-calculate the hours worked by year, month, day, half-day, and hour by using the _sum built-in reduce. You save work in your application and allow the database to concentrate on serving many small requests. This method is preferable to reading huge amounts of data from disk to service a single large request.\n\n\n\n\n\nIt's straightforward. First, both maps and reduces are precomputed, so the result of a reduce function is a cheap operation. The operation cost is low even when compared to the significant amounts of IO required to stream hundreds or even thousands of documents from the on-disk storage.\n\nAt a deeper level, when a node receives a view request, it asks the nodes that hold the shard replicas of the view's database for the results of the view request from the documents in each shard. As it receives the answers, taking the first answer for each shard replica, the node that services the view request combines the results and streams the final result to the client. As more documents are involved, it takes longer for each replica to stream the results from disk and across the network. The node that services the request also has much more work to do in combining the results from each database shard.\n\nOverall, the goal is for a view request to require the minimum amount of data from each shard. This practice minimizes the time that the data is in transit and being combined to form the final result. Using the power of views to precompute aggregate data is one way to achieve this aim.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_04866-1541-3629","score":9.5531025,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-1541-3629","score":9.5531025,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_02361-24500-26305","score":9.388896,"text":"\n[Information about Immutable Object Storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/activity-tracker?topic=activity-tracker-adoption"},{"document_id":"ibmcld_00469-2977-5094","score":9.367733,"text":"\nIt is more expensive in the end to mutate existing documents than to create new ones. IBM Cloudant always needs to keep the document tree structure around. This rule applies even if internal nodes in the tree are stripped of their payloads. If you find that you create long revision trees, your replication performance suffers. Moreover, if your update frequency is higher than, say, once or twice every few seconds, you\u2019re more likely to produce update conflicts.\n\nPrefer models that are immutable.\n\nWhen you read the following sections, Deleting documents doesn't delete them and Be careful with updates, they provoke an obvious question. That is, does the data set grow unbounded if my model is immutable? If you accept that deletes don\u2019t completely purge the deleted data and that updates are not updating in place in terms of data volume growth, not much difference exists. Managing data volume over time requires different techniques.\n\nThe only way to truly reclaim space is to delete databases, rather than documents. You can replicate only winning revisions to a new database and delete the old to get rid of lingering deletes and conflicts. Or perhaps you can build it into your model to regularly start new databases (say \u2018annual data\u2019) and archive off (or remove) outdated data, if your use case allows.\n\n\n\n\n\n Eventual consistency is a harsh taskmaster (also known as don\u2019t read your writes) \n\nEventual consistency is a great idea on paper, and a key contributor to IBM Cloudant\u2019s ability to scale out in practice. However, it\u2019s fair to say that the mindset required to develop against an eventually consistent data store does not feel natural to most people.\n\nYou often get stung when you write tests similar to the following ones:\n\n\n\n1. Create a database.\n2. Populate the database with some test data.\n3. Query the database for some subset of this test data.\n4. Verify that the data that you got back is the data that you expected to get back.\n\n\n\nNothing wrong with that test? That works on every other database that you ever used, correct?\n\nNot on IBM Cloudant.\n\nOr rather, it works 99 times out of 100.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Cloudant?topic=Cloudant-cloudant-in-practice"},{"document_id":"ibmcld_05032-6428-8442","score":9.32872,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05168-15740-17188","score":9.296308,"text":"\nfmt.Println(r)\nfmt.Println(e)\n\n}\n\nShow more\n\nThe typical response is exemplified here.\n\n{\nRules: [{\nFilter: {\n\n},\nID: \"id3\",\nStatus: \"Enabled\",\nTransitions: {\nDays: 5,\nStorageClass: \"GLACIER\"\n}]\n}]\n}\n\n\n\n\n\n Immutable Object Storage \n\nUsers can configure buckets with an Immutable Object Storage policy to prevent objects from being modified or deleted for a defined period of time. The retention period can be specified on a per-object basis, or objects can inherit a default retention period set on the bucket. It is also possible to set open-ended and permanent retention periods. Immutable Object Storage meets the rules set forth by the SEC governing record retention, and IBM Cloud administrators are unable to bypass these restrictions.\n\nNote: Immutable Object Storage does not support Aspera transfers via the SDK to upload objects or directories at this stage.\n\nfunc main() {\n\n\/\/ Create Client\nsess := session.Must(session.NewSession())\nclient := s3.New(sess, conf)\n\n\/\/ Create a bucket\ninput := &s3.CreateBucketInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\n}\nd, e := client.CreateBucket(input)\nfmt.Println(d) \/\/ should print an empty bracket\nfmt.Println(e) \/\/ should print <nil>\n\n\/\/ PUT BUCKET PROTECTION CONFIGURATION\npInput := &s3.PutBucketProtectionConfigurationInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\nProtectionConfiguration: &s3.ProtectionConfiguration{\nDefaultRetention: &s3.BucketProtectionDefaultRetention{\nDays: aws.Int64(100),\n},","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-using-go"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.5,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.6366824387,"ndcg_cut_10":0.7541985435}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-6428-8391","score":11.395278,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-6428-8442","score":11.243402,"text":"\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https:\/\/cloud.ibm.com\/docs\/images\/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_14708-3638-5837","score":8.028669,"text":"\nThe [Compliance assessment report (by Cohasset)](https:\/\/www.veeam.com\/wp-compliance-assessment-report-cohasset.html) describes the settings that must be configured to become compliant with the following regulations:\n\n\n\n* FINRA Rule 4511.\n* SEC Rule 17a-4(f).\n* CFTC Rule 1 .31 (c)-(d).\n\n\n\nThe previous assessment report considers the following details as best practice for a Linux hardened repository:\n\n\n\n* The Linux hardened repository can be independent or Scale-out backup repository. A repository that retains immutable backup files for compliance with SEC 17a-4(f) must be configured as a stand-alone backup repository as a Veeam Scale-Out backup Repository is not compliant with this rule.\n* It is recommended that the name and description attributes for the repository include the word \u201cimmutable\" when the Linux hardened repository feature is enabled.\n* To protect against the possibility of premature deletion of backup files that can result from accelerating the system time clock, Linux OS must be configured to synchronize with a secure time source. For example, with a network time protocol (NTP) clock.\n* Ensure separation of duties by assigning management of Linux hardened repositories to a team other than backup administrators.\n* Veeam recommends XFS for performance and space efficiency reasons (block cloning support). Due to the requirement for periodic full backups, means that due to fast cloning, synthetic full backups take no physical disk space, except for metadata.\n* Only backup job configurations with forward incremental with synthetic or active full are supported. Forward incremental with synthetic full is the default backup job setting.\n* For backup copy jobs, GFS must be enabled.\n* Encryption of backup files is available as follows:\n\n\n\n* When configured in a backup job, Veeam Backup and Replication can use 256-bit AES block cypher encryption.\n* For data in transit, a global network traffic rule can be configured to enable all traffic to be encrypted through 256-bit AES encryption. When enable and two backup infrastructure components need to communicate, a dynamic key is generated by the backup server and communicated to each node over a secure channel.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr"},{"document_id":"ibmcld_04939-64122-65726","score":6.580348,"text":"\nSystem.out.printf(\"New retention period on %s is %sn\", objectName, additionalSeconds);\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied\n\n\n\nIf there are no legal holds on the object, an empty LegalHoldSet is returned. If there is no retention period specified on the object, a 404 error is returned.\n\npublic static void listLegalHoldsOnObject(String bucketName, String objectName) {\nSystem.out.printf(\"List all legal holds on object %s in bucket %sn\", objectName, bucketName);\n\nListLegalHoldsResult result = cos.listLegalHolds(\nbucketName,\nobjectName\n);\n\nSystem.out.printf(\"Legal holds on bucket %s: n\", bucketName);\n\nList<LegalHold> holds = result.getLegalHolds();\nfor (LegalHold hold : holds) {\nSystem.out.printf(\"Legal Hold: %s\", hold);\n}\n}\n\n\n\n\n\n Create a hosted static website \n\nThis operation requires an import statement to be added:\n\nimport com.ibm.cloud.objectstorage.services.s3.model.model.BucketWebsiteConfiguration;\n\nThis operation provides the following upon configuration and requires a correctly configured client:\n\n\n\n* Bucket configuration for suffix (index document)\n* Bucket configuration for key (error document)\n\n\n\ncosClient.setBucketWebsiteConfiguration(\"<bucket_name>\", new BucketWebsiteConfiguration(\"index.html\", \"error.html\"));\n\n\n\n\n\n\n\n Next Steps \n\nFor more information, [see the Javadoc](https:\/\/ibm.github.io\/ibm-cos-sdk-java\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-java"},{"document_id":"ibmcld_05044-64102-65706","score":6.580348,"text":"\nSystem.out.printf(\"New retention period on %s is %sn\", objectName, additionalSeconds);\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied\n\n\n\nIf there are no legal holds on the object, an empty LegalHoldSet is returned. If there is no retention period specified on the object, a 404 error is returned.\n\npublic static void listLegalHoldsOnObject(String bucketName, String objectName) {\nSystem.out.printf(\"List all legal holds on object %s in bucket %sn\", objectName, bucketName);\n\nListLegalHoldsResult result = cos.listLegalHolds(\nbucketName,\nobjectName\n);\n\nSystem.out.printf(\"Legal holds on bucket %s: n\", bucketName);\n\nList<LegalHold> holds = result.getLegalHolds();\nfor (LegalHold hold : holds) {\nSystem.out.printf(\"Legal Hold: %s\", hold);\n}\n}\n\n\n\n\n\n Create a hosted static website \n\nThis operation requires an import statement to be added:\n\nimport com.ibm.cloud.objectstorage.services.s3.model.model.BucketWebsiteConfiguration;\n\nThis operation provides the following upon configuration and requires a correctly configured client:\n\n\n\n* Bucket configuration for suffix (index document)\n* Bucket configuration for key (error document)\n\n\n\ncosClient.setBucketWebsiteConfiguration(\"<bucket_name>\", new BucketWebsiteConfiguration(\"index.html\", \"error.html\"));\n\n\n\n\n\n\n\n Next Steps \n\nFor more information, [see the Javadoc](https:\/\/ibm.github.io\/ibm-cos-sdk-java\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-java"},{"document_id":"ibmcld_05070-27030-28536","score":6.0426803,"text":"\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\n\n\n\n\n List legal holds on a protected object \n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied\n\n\n\nIf there are no legal holds on the object, an empty LegalHoldSet is returned. If there is no retention period specified on the object, a 404 error is returned.\n\nfunction listLegalHoldsOnObject(bucketName, objectName) {\nconsole.log(List all legal holds on object ${objectName} in bucket ${bucketName});\nreturn cos.listLegalHolds({\nBucket: bucketName,\nKey: objectId\n}).promise()\n.then((data) => {\nconsole.log(Legal holds on bucket ${bucketName}: ${data});\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\n\n\n\n\n Create a hosted static website \n\nThis operation requires permissions, as only the bucket owner is typically permitted to configure a bucket to host a static website. The parameters determine the default suffix for visitors to the site as well as an optional error document.\n\nvar websiteParams = {\nBucket: \"bucketName\",\nWebsiteConfiguration: {\nErrorDocument: {\nKey: \"error.html\"\n},\nIndexDocument: {\nSuffix: \"index.html\"\n}\n}\n};\nfunction putBucketWebsiteConfiguration(websiteParams) {\nreturn cos.putBucketWebsite({websiteParams}).promise()\n.then((data) => {\nconsole.log(Website configured for ${bucketName});","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_04866-4961-6763","score":5.9329686,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-4961-6763","score":5.9329686,"text":"\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https:\/\/www.finra.org\/rules-guidance\/rulebooks\/finra-rules\/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https:\/\/www.ecfr.gov\/cgi-bin\/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05070-24369-25822","score":5.5992675,"text":"\nfunction addLegalHoldToObject(bucketName, objectName, legalHoldId) {\nconsole.log(Adding legal hold ${legalHoldId} to object ${objectName} in bucket ${bucketName});\nreturn cos.client.addLegalHold({\nBucket: bucketName,\nKey: objectId,\nRetentionLegalHoldId: legalHoldId\n}).promise()\n.then(() => {\nconsole.log(Legal hold ${legalHoldId} added to object ${objectName} in bucket ${bucketName}!);\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\nfunction deleteLegalHoldFromObject(bucketName, objectName, legalHoldId) {\nconsole.log(Deleting legal hold ${legalHoldId} from object ${objectName} in bucket ${bucketName});\nreturn cos.client.deleteLegalHold({\nBucket: bucketName,\nKey: objectId,\nRetentionLegalHoldId: legalHoldId\n}).promise()\n.then(() => {\nconsole.log(Legal hold ${legalHoldId} deleted from object ${objectName} in bucket ${bucketName}!);\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\nShow more\n\n\n\n\n\n Extend the retention period of a protected object \n\nThe retention period of an object can only be extended. It cannot be decreased from the currently configured value.\n\nThe retention expansion value is set in one of three ways:\n\n\n\n* additional time from the current value (Additional-Retention-Period or similar method)\n* new extension period in seconds (Extend-Retention-From-Current-Time or similar method)\n* new retention expiry date of the object (New-Retention-Expiration-Date or similar method)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_09275-28240-30517","score":5.577495,"text":"\nA preset is an alert template that you can attach to any number of views.\n\nTo reuse an alert configuration with different views and enforce notification channels across users that analyze data through that instance, configure alert presets.\n\nWhen you send a notification, you can include log data as part of the notification.\n\nCustomize the data that is included in a notification for situations where the receiver of the notification does not have access to the log data.\n\n\n\n\n\n Define the archive strategy \n\nYou might have different requirements that require archiving your data:\n\n\n\n* Backup requirements to keep data for a period of time\n* Data access requirements so that you can query the data after it is not available for search through the web UI\n* Disaster recovery requirements\n* Compliance requirements\n\n\n\nlogging as a service does not backup your data.\n\nThere are 2 types of data that you should consider archiving:\n\n\n\n* Log data\n\nBy default, archiving of log data is not enabled for any logging instance.\n\nWhen you enable archiving of your log data, notice that you are responsible for checking that your archived files are not corrupted, and for the maintenance of your archived files.\n* Web UI resource definitions such as parsing templates, exclusion rules, views, screens, and dashboards.\n\n\n\nYou will want to archive your logging resource definitions and your log data.\n\n\n\n Backup the resource configurations of your logging instance \n\nIn the logging web UI, you can define custom views, dashboards, parsing templates, screens, and exclusion rules that you can use to view and analyze data.\n\nTo reuse resource definitions that you define in your logging instance, you can export these resources from an IBM Log Analysis instance as a JSON file. Then, you can import the definitions into other logging instances. For example, you can reuse your logging resources across different environments for your stage, pre-production, and production logging instances. [Learn more](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-reuse_resource_definitions).\n\nBackup logging resource definitions into a version control system such as a git repository where you can control access to the archived files and manage versions.\n\n\n\n\n\n Archive log data to a COS bucket","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-adoption"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04866-1541-3629","score":16.354965,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05032-1541-3629","score":16.354965,"text":"\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https:\/\/www.ibm.com\/cloud\/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage\/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04939-57496-59284","score":15.813939,"text":"\nSystem.out.printf(\"Minimum Retention (Days): %sn\", config.getMinimumRetentionInDays());\nSystem.out.printf(\"Default Retention (Days): %sn\", config.getDefaultRetentionInDays());\nSystem.out.printf(\"Maximum Retention (Days): %sn\", config.getMaximumRetentionInDays());\n}\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-java"},{"document_id":"ibmcld_05044-57476-59264","score":15.813939,"text":"\nSystem.out.printf(\"Minimum Retention (Days): %sn\", config.getMinimumRetentionInDays());\nSystem.out.printf(\"Default Retention (Days): %sn\", config.getDefaultRetentionInDays());\nSystem.out.printf(\"Maximum Retention (Days): %sn\", config.getMaximumRetentionInDays());\n}\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-java"},{"document_id":"ibmcld_05032-3142-5463","score":15.810048,"text":"\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-3142-5463","score":15.810048,"text":"\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05088-35529-37138","score":15.412479,"text":"\nThe new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\ndef add_protection_configuration_to_bucket(bucket_name):\ntry:\nnew_protection_config = {\n\"Status\": \"Retention\",\n\"MinimumRetention\": {\"Days\": 10},\n\"DefaultRetention\": {\"Days\": 100},\n\"MaximumRetention\": {\"Days\": 1000}\n}\n\ncos.put_bucket_protection_configuration(Bucket=bucket_name, ProtectionConfiguration=new_protection_config)\n\nprint(\"Protection added to bucket {0}n\".format(bucket_name))\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to set bucket protection config: {0}\".format(e))\nShow more\n\n\n\n\n\n Check protection on a bucket \n\ndef get_protection_configuration_on_bucket(bucket_name):\ntry:\nresponse = cos.get_bucket_protection_configuration(Bucket=bucket_name)\nprotection_config = response.get(\"ProtectionConfiguration\")\n\nprint(\"Bucket protection config for {0}n\".format(bucket_name))\nprint(protection_config)\nprint(\"n\")\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to get bucket protection config: {0}\".format(e))\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"},{"document_id":"ibmcld_05075-5285-7227","score":15.042141,"text":"\n* You will need to pick a region where Object Lock is supported, refer to [Integrated Services](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-service-availability) for details.\n* A maximum default retention period of 100 years (or 36500 days) is supported.\n* When using the console, it is also possible to set a Retain Until Date in months, in addition to days or years.\n\n\n\nThe retention period for an object cannot be decreased. If you are using default retention for validation testing please use a lower duration (such as 1 day) as the default retention, increasing it to your desired setting as needed.\n\n\n\n Creating and setting up your new bucket for use with Object Lock \n\n\n\n1. Navigate to your desired Object Storage instance and use Create Bucket with Customize your bucket option\n2. Enter the required bucket configuration details as per your use case requirements\n3. Navigate to the Object Versioning section and set it to Enabled\n4. Look for Immutability, and under Object Lock click Add\n5. Set Object Lock to Enabled\n6. Optionally, set a default retention period.\n7. Click on Save\n8. Proceed with rest of the configuration settings and click Create bucket\n\n\n\n\n\n\n\n Enabling Object Lock on an existing bucket: \n\nA bucket can be set for Object Lock use as follows:\n\n\n\n1. Navigate to your bucket Configuration section\n2. Click on Object Versioning\n3. At the Object Versioning section click on Edit, set the configuration option to Enabled and Save\n4. Navigate to Object Lock section, click on Add\n5. Set Object Lock to Enabled\n6. Optionally, set a default retention period.\n7. Click on Save\n\n\n\n\n\n\n\n Adding a Retain Until Date or Legal Hold to an object \n\n\n\n1. Navigate to the bucket with the target object\n2. Toggle Display Versions\n3. Go to the details of the target version\n4. Add a retention period and\/or toggle on a legal hold.\n\n\n\n\n\n\n\n\n\n Using Object Lock for business continuity and disaster recovery","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-ol-overview"},{"document_id":"ibmcld_05032-7904-10153","score":15.027377,"text":"\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time. A Content-MD5 header is required to ensure data integrity, and is automatically sent when using an SDK.\n\n\n\n Add a retention policy on an existing bucket \n\nThis implementation of the PUT operation uses the protection query parameter to set the retention parameters for an existing bucket. This operation allows you to set or change the minimum, default, and maximum retention period. This operation also allows you to change the protection state of the bucket.\n\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object-specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nA Content-MD5 header is required. This operation does not make use of extra query parameters.\n\nFor more information about endpoints, see [Endpoints and storage locations](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage?topic=cloud-object-storage-endpointsendpoints)\n\nSyntax\n\nPUT https:\/\/{endpoint}\/{bucket-name}?protection= path style\nPUT https:\/\/{bucket-name}.{endpoint}?protection= virtual host style\n\nExample request","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-7925-10174","score":15.027377,"text":"\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time. A Content-MD5 header is required to ensure data integrity, and is automatically sent when using an SDK.\n\n\n\n Add a retention policy on an existing bucket \n\nThis implementation of the PUT operation uses the protection query parameter to set the retention parameters for an existing bucket. This operation allows you to set or change the minimum, default, and maximum retention period. This operation also allows you to change the protection state of the bucket.\n\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object-specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nA Content-MD5 header is required. This operation does not make use of extra query parameters.\n\nFor more information about endpoints, see [Endpoints and storage locations](https:\/\/cloud.ibm.com\/docs\/services\/cloud-object-storage?topic=cloud-object-storage-endpointsendpoints)\n\nSyntax\n\nPUT https:\/\/{endpoint}\/{bucket-name}?protection= path style\nPUT https:\/\/{bucket-name}.{endpoint}?protection= virtual host style\n\nExample request","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"2f013337236ea4635ad106813275dab7<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07098-3231-5441","score":8.840865,"text":"\n* Works well with questions with longer phrase or clause answers.\n\n\n\n* Example question: How do I flip a pancake?\n* Passage: The key to getting a world-class pancake is flipping it properly. The best way to flip a pancake is to stick a spatula under it, lift it at least 4 inches in the air, and quickly rotate the spatula 180 degrees.\n\n\n\n* Many how or why questions are only fully answered by much longer spans of text. The answer-finding feature does not return a whole document as the answer (and it doesn't summarize a document length answer).\n* Handles yes or no questions that are factual and have a concise answer in the text\n\n\n\n* Example question: Is there a library in Timbuktu\n* Passage: Timbuktu's main library, officially called the Ahmed Baba Institute of Higher Islamic Studies and Research, is a treasure house that contains more than 20,000 manuscripts that cover centuries of Mali's history.\n\n\n\n* Handles questions with very short answers, such as names and dates, especially when the type of answer that is required is explicit in the text.\n* Handles opinion questions, but only by finding a statement of that opinion; it does not assess the validity of the opinion.\n\n\n\n* Example question: Should I try blue eyeshadow?\n* Passage: We think blue eye shadow is trending this year.\n\n\n\n\n\n\n\n How the answer-finding feature works \n\nAfter a user submits a query, the query is analyzed by the Discovery service. Query analysis transforms the user's original query in ways that improve the chances of finding the best search results. For example, it lemmatizing words, removes stop words, and adds query expansions. The search is performed and the resulting documents and passages are returned.\n\nAnswer finding is applied to the returned passages. Up to 60 passages are sent to the answer-finding service. How these 60 passages are chosen differs based on the passages.per_document parameter value.\n\n\n\n* If passages.per_document is false, the top 60 passages from all of the documents that are returned by search are chosen based on their passage scores only.\n* If passages.per_document is true, the returned documents are ranked first, and then the top 60 passages from these top documents are chosen.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-parameters"},{"document_id":"ibmcld_05032-29611-31206","score":7.6383862,"text":"\nprint(\"New retention period on {0} is {1}n\".format(object_name, additional_seconds))\n\nfunction extendRetentionPeriodOnObject(bucketName, objectName, additionalSeconds) {\nconsole.log(Extend the retention period on ${objectName} in bucket ${bucketName} by ${additionalSeconds} seconds.);\nreturn cos.extendObjectRetention({\nBucket: bucketName,\nKey: objectName,\nAdditionalRetentionPeriod: additionalSeconds\n}).promise()\n.then((data) => {\nconsole.log(New retention period on ${objectName} is ${data.RetentionPeriod});\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\n\n\n\n\n List legal holds on an object \n\nThis implementation of the GET operation uses the legalHold query parameter to return the list of legal holds on an object and related retention state in an XML response body.\n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied\n\n\n\nIf there are no legal holds on the object, an empty LegalHoldSet is returned. If there is no retention period that is specified on the object, a 404 error is returned.\n\nSyntax\n\nGET https:\/\/{endpoint}\/{bucket-name}\/{object-name}?legalHold= path style\nGET https:\/\/{bucket-name}.{endpoint}\/{object-name}?legalHold= virtual host style\n\nExample request\n\nGET \/BucketName\/ObjectName?legalHold HTTP\/1.1\nHost: myBucket.mydsNet.corp.com\nDate: Fri, 8 Dec 2018 17:50:00 GMT\nAuthorization: {authorization-string}\nContent-Type: text\/plain\n\nExample response","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-29632-31227","score":7.6383862,"text":"\nprint(\"New retention period on {0} is {1}n\".format(object_name, additional_seconds))\n\nfunction extendRetentionPeriodOnObject(bucketName, objectName, additionalSeconds) {\nconsole.log(Extend the retention period on ${objectName} in bucket ${bucketName} by ${additionalSeconds} seconds.);\nreturn cos.extendObjectRetention({\nBucket: bucketName,\nKey: objectName,\nAdditionalRetentionPeriod: additionalSeconds\n}).promise()\n.then((data) => {\nconsole.log(New retention period on ${objectName} is ${data.RetentionPeriod});\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\n\n\n\n\n List legal holds on an object \n\nThis implementation of the GET operation uses the legalHold query parameter to return the list of legal holds on an object and related retention state in an XML response body.\n\nThis operation returns:\n\n\n\n* Object creation date\n* Object retention period in seconds\n* Calculated retention expiration date based on the period and creation date\n* List of legal holds\n* Legal hold identifier\n* Timestamp when legal hold was applied\n\n\n\nIf there are no legal holds on the object, an empty LegalHoldSet is returned. If there is no retention period that is specified on the object, a 404 error is returned.\n\nSyntax\n\nGET https:\/\/{endpoint}\/{bucket-name}\/{object-name}?legalHold= path style\nGET https:\/\/{bucket-name}.{endpoint}\/{object-name}?legalHold= virtual host style\n\nExample request\n\nGET \/BucketName\/ObjectName?legalHold HTTP\/1.1\nHost: myBucket.mydsNet.corp.com\nDate: Fri, 8 Dec 2018 17:50:00 GMT\nAuthorization: {authorization-string}\nContent-Type: text\/plain\n\nExample response","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_05088-35529-37138","score":7.6247883,"text":"\nThe new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\ndef add_protection_configuration_to_bucket(bucket_name):\ntry:\nnew_protection_config = {\n\"Status\": \"Retention\",\n\"MinimumRetention\": {\"Days\": 10},\n\"DefaultRetention\": {\"Days\": 100},\n\"MaximumRetention\": {\"Days\": 1000}\n}\n\ncos.put_bucket_protection_configuration(Bucket=bucket_name, ProtectionConfiguration=new_protection_config)\n\nprint(\"Protection added to bucket {0}n\".format(bucket_name))\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to set bucket protection config: {0}\".format(e))\nShow more\n\n\n\n\n\n Check protection on a bucket \n\ndef get_protection_configuration_on_bucket(bucket_name):\ntry:\nresponse = cos.get_bucket_protection_configuration(Bucket=bucket_name)\nprotection_config = response.get(\"ProtectionConfiguration\")\n\nprint(\"Bucket protection config for {0}n\".format(bucket_name))\nprint(protection_config)\nprint(\"n\")\nexcept ClientError as be:\nprint(\"CLIENT ERROR: {0}n\".format(be))\nexcept Exception as e:\nprint(\"Unable to get bucket protection config: {0}\".format(e))\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-python"},{"document_id":"ibmcld_04939-57496-59284","score":7.268153,"text":"\nSystem.out.printf(\"Minimum Retention (Days): %sn\", config.getMinimumRetentionInDays());\nSystem.out.printf(\"Default Retention (Days): %sn\", config.getDefaultRetentionInDays());\nSystem.out.printf(\"Maximum Retention (Days): %sn\", config.getMaximumRetentionInDays());\n}\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/libraries?topic=cloud-object-storage-java"},{"document_id":"ibmcld_05044-57476-59264","score":7.268153,"text":"\nSystem.out.printf(\"Minimum Retention (Days): %sn\", config.getMinimumRetentionInDays());\nSystem.out.printf(\"Default Retention (Days): %sn\", config.getDefaultRetentionInDays());\nSystem.out.printf(\"Maximum Retention (Days): %sn\", config.getMaximumRetentionInDays());\n}\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-java"},{"document_id":"ibmcld_05070-19089-20725","score":7.203923,"text":"\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are 0 days and 365243 days (1000 years) respectively.\n\nfunction addProtectionConfigurationToBucket(bucketName) {\nconsole.log(Adding protection to bucket ${bucketName});\nreturn cos.putBucketProtectionConfiguration({\nBucket: bucketName,\nProtectionConfiguration: {\n'Status': 'Retention',\n'MinimumRetention': {'Days': 10},\n'DefaultRetention': {'Days': 100},\n'MaximumRetention': {'Days': 1000}\n}\n}).promise()\n.then(() => {\nconsole.log(Protection added to bucket ${bucketName}!);\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\nShow more\n\n\n\n\n\n Check protection on a bucket \n\nfunction getProtectionConfigurationOnBucket(bucketName) {\nconsole.log(Retrieve the protection on bucket ${bucketName});\nreturn cos.getBucketProtectionConfiguration({\nBucket: bucketName\n}).promise()\n.then((data) => {\nconsole.log(Configuration on bucket ${bucketName}:);\nconsole.log(data);\n})","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_05070-20435-22267","score":7.16509,"text":"\nfunction getProtectionConfigurationOnBucket(bucketName) {\nconsole.log(Retrieve the protection on bucket ${bucketName});\nreturn cos.getBucketProtectionConfiguration({\nBucket: bucketName\n}).promise()\n.then((data) => {\nconsole.log(Configuration on bucket ${bucketName}:);\nconsole.log(data);\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\nfunction putObjectAddLegalHold(bucketName, objectName, legalHoldId) {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-node"},{"document_id":"ibmcld_05032-3142-5463","score":6.9716234,"text":"\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-immutable"},{"document_id":"ibmcld_04866-3142-5463","score":6.9716234,"text":"\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-immutable"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04105-1672-3877","score":12.878865,"text":"\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":11.188119,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-7-2225","score":7.853725,"text":"\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04146-2946-5057","score":7.156115,"text":"\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0\/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-fields-and-expressions"},{"document_id":"ibmcld_04170-7-2189","score":6.8310947,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04105-5067-6335","score":6.5683,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04111-35313-36062","score":6.479905,"text":"\nGet Bot Management settings. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT \/v1\/{crn}\/zones\/{domain_id}\/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET \/v1\/{crn}\/zones\/{domain_id}\/bot_analytics\/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-at_iam_CIS"},{"document_id":"ibmcld_03369-1415-3586","score":6.4686227,"text":"\nThese changes are the result of migrating the Watson Assistant platform to Java 17, where locale values are updated by using specifications in [CLDR 39](https:\/\/cldr.unicode.org\/index\/downloads\/cldr-39).\n\nTo avoid or minimize the impact of similar changes in the future, you can use [Actions display formats](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-actions-global-settingsactions-global-settings-display-formats).\n\n\n\n\n\n 18 May 2023 \n\nDifferences in contextual entity detection for dialog skills with few annotations\n: If you have 10 to 20 examples of contextual entities in your dialog skill, you might see differences in the entities detected due to updates made to address critical vulnerabilities. The impact of these differences is limited to only newly-trained models. Existing models are unaffected. You can mitigate these differences by annotating more examples. For more information, see [Annotation-based method](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entitiesentities-annotations-overview).\n\n\n\n\n\n 15 May 2023 \n\nChange to dialog skill context variables named request\n: If your dialog skill used a context variable that is named request, it was removed from the response payload of any \/message calls in the V1 or V2 API, or through the Watson Assistant user interface. After 15 May 2023, this behavior changes. Watson Assistant doesn't remove context variables that are named request from the response payload anymore.\n\n\n\n\n\n 3 May 2023 \n\nAlgorithm version Beta provides improved intent detection and action matching\n: The algorithm version Beta now provides improved intent detection and action matching. It includes a new foundation model that is trained using a transformer architecture to improve intent detection and action matching for English.\n\nImprovements include:\n\n\n\n* Improved robustness to variations in user inputs such as typos and different inflection forms\n* Less training data required to reach the same level of performance compared to previous algorithms\n\n\n\nFor more information, see [Algorithm version and training](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_16364-213826-215727","score":6.3152146,"text":"\nFor details, see [Defining entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities) and search for Enabling system entities.\n* You can now view a history of conversations with users on the Improve page. You can use this to understand your bot's behavior. For details, see [Improving your skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs).\n* You can now import entities from a comma-separated value (CSV) file, which helps with when you have a large number of entities. For details, see [Defining entities](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-entities) and search for Importing entities.\n\n\n\n\n\n\n\n 20 September 2016 \n\nNew version 2016-09-20\n: To take advantage of the changes in a new version, change the value of the version parameter to the new date. If you're not ready to update to this version, don't change your version date.\n\n\n\n* version 2016-09-20: dialog_stack changed from an array of strings to an array of JSON objects.\n\n\n\n\n\n\n\n 29 August 2016 \n\nUpdates\n: This release includes the following updates:\n\n\n\n* You can move dialog nodes from one branch to another, as siblings or peers. For details, see [Moving a dialog node](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-tasksdialog-tasks-move-node).\n* You can expand the JSON editor window.\n* You can view chat logs of your bot's conversations to help you understand it's behavior. You can filter by intents, entities, date, and time. For details, see [Improving your skill](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs).\n\n\n\n\n\n\n\n 11 July 2016 \n\nGeneral Availability\n: This General Availability release enables you to work with entities and dialogs to create a fully functioning bot.\n\n\n\n\n\n 18 May 2016 \n\nExperimental release\n: This Experimental release of the Watson Assistant introduces the user interface and enables you to work with workspaces, intents, and examples.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_13761-1826-3662","score":6.2444654,"text":"\nIn such cases, the differences might not be readily discernible from the default expressive tone. But there are instances where the style can audibly enhance the voices' inherent ability to detect and express emotion. The differences are often detectable only on certain words and phrases.\n\nTable 1 provides examples of each available style for the <express-as> element. To demonstrate the effect of the styles, the table provides two samples for each example. The first sample speaks the text with the default en-US_EmmaExpressive voice. The second sample speaks the same text with the same voice but with the indicated style. A request that uses the <express-as> element fails if the style is not one of the supported values or is omitted from the element.\n\n\n\nTable 1. Speaking styles\n\n Style Example input text Audio sample \n\n cheerful \"Oh, that's good news. I am very happy for you!\" Your browser does not support the audio tag. \n \"<express-as style='cheerful'>Oh, that's good news. I am very happy for you!<\/express-as>\" Your browser does not support the audio tag. \n empathetic \"Oh, I'm sorry to hear that. I know how difficult that can be.\" Your browser does not support the audio tag. \n \"<express-as style='empathetic'>Oh, I'm sorry to hear that. I know how difficult that can be.<\/express-as>\" Your browser does not support the audio tag. \n neutral \"A five-alarm fire early this morning claimed the lives of more than a dozen residents.\" Your browser does not support the audio tag. \n \"<express-as style='neutral'>A five-alarm fire early this morning claimed the lives of more than a dozen residents.<\/express-as>\" Your browser does not support the audio tag. \n uncertain \"That's strange. Hmm, I don't know if I've seen this before.\" Your browser does not support the audio tag. \n \"<express-as style='uncertain'>That's strange.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-synthesis-expressive"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04170-7-2189","score":12.951093,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04105-5067-6335","score":11.134773,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":10.899167,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04334-39121-41053","score":10.704739,"text":"\nValid values for group are all, domain, reliability, performance, security. This option is mutually exclusive with -f, --feature.\n\n-f, --feature\n: Feature of domain settings to check. This option is mutually exclusive with g, --group. Valid values are as follow:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination in the BoringSSL format. This command only lists ciphers specifically whitelisted by customers. If no ciphers are whitelisted, the list is empty and the default ciphers are used. See [TLS Options](\/docs\/cis? topic=cis-cis-tls-options#cipher-suites) for the list of default ciphers.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04113-1734-4014","score":10.3002205,"text":"\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:\n\n\n\n* Select Security Level to Essentially off\n* Select TLS to Off\n* Select Browser Integrity Check to Off\n\n\n\n* Select Provision Resource\n\n\n\n* Alternatively, you can turn off Web Application Firewall globally from the Security page.\n\n\n\n\n\n What does the Browser Integrity Check do? \n\nThe browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks visitors that do not have a user agent, or who add a non-standard user agent (this tactic is commonly used by abuse bots, crawlers, or APIs).\n\n\n\n\n\n\n\n Best practice 4: Configure your security settings as strictly as possible \n\nCIS provides some options for encrypting your traffic. As a reverse proxy the TLS connection is terminated at Cloudflare and a new TLS connection is opened to your origin servers. For your termination with CIS, you can upload a custom certificate from your account, you can use a wildcard certificate provisioned for you by CIS, or both.\n\n\n\n Upload a custom certificate \n\nYou can upload your public and private key when you create an Enterprise domain. If you upload your own certificate, you gain immediate compatibility with encrypted traffic, and you maintain control over your certificate (for example, an Extended Validation (EV) certificate). Remember that you'll be responsible for managing your certificate if you upload a custom certificate. For example, IBM CIS won't track the certificate expiration dates.\n\n\n\n\n\n Alternatively, use a certificate provisioned by CIS \n\nIBM CIS has partnered with several Certificate Authorities (CAs) to provide domain wildcard certificates for our customers, by default. Manual verification could be required for setting up these certificates, and your support team can help you perform these additional steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup"},{"document_id":"ibmcld_04334-43529-45385","score":10.185401,"text":"\nUpdate a feature for the domain.\n\nibmcloud cis domain-settings-update DNS_DOMAIN_ID (-f, --feature FEATURE) (-v, --value VALUE) [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required. -f, --feature value\n: Feature of domain settings to update. Required. Valid values:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination. These ciphers must be in the BoringSSL format.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.\n* image_size_optimization: Improve image load time by optimizing images hosted on your domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_04107-9120-10897","score":9.984123,"text":"\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection \n\nCIS does not meter or bill for traffic that is blocked as part of DDoS mitigation, firewall, or rate limiting. Only requests that are passed through the CIS network to the origin destination incur charges or usage.\n\nCIS also helps keep egress bandwidth charges from your origin under control by only passing along good requests that the origin needs to respond to. All CIS plans offer unlimited and unmetered mitigation of DDoS attacks. You are never charged for attack traffic. There\u2019s no penalty for spikes due to attack traffic, so there's no chargeback by the customer.\n\n\n\n\n\n\n\n Reliability features \n\nZoom\n\n![reliability graphic](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/images\/reliability-graphic.png)\n\nFigure 2. Reliability features\n\n\n\n Global load balancing features \n\nThe global load balancing service distributes your traffic across multiple servers with a combination of origin pools, health checks, and a load balancer. Global load balancing has the following features:\n\n\n\n* Proxy and non-proxy options for load balancing\n* Origin pools and health checks\n\n\n\n\n\n Global anycast network \n\nThe available health check regions are based on the [Cloudflare Global Anycast Network](https:\/\/www.cloudflare.com\/network\/).\n\n\n\n\n\n\n\n DNS features \n\nDNS within CIS has the following features:\n\n\n\n* DNS management - Manage your DNS records, control proxying, and enable DNS security.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_04149-7-1761","score":9.877999,"text":"\nGetting started with IBM Cloud Internet Services \n\nIBM Cloud\u00ae Internet Services (CIS), powered with Cloudflare, offers three main capabilities to enhance your workflow: [security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-security), [reliability](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cloud-internet-services-deployment-for-optimal-reliability), and [performance](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-cis-deployment-for-best-performance). You can navigate to features for each of these capabilities after you open the CIS UI.\n\nFor each capability, CIS helps you tune its features to suit your specific needs. These features are detailed in the [About IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis) section.\n\n\n\n Before you begin \n\nBefore you begin using CIS:\n\n\n\n* You'll need an [IBMid](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=urx-19776).\n* Then, you can order your services through the [IBM Cloud Internet Services console](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services).\n\n\n\nIt is recommended that you use the Chrome browser for CIS.\n\n\n\n\n\n Process overview \n\nYou can start using CIS for your internet traffic with just a few steps.\n\n\n\n1. Open the CIS application from your IBM Cloud dashboard.\n2. Add the domain that you want to manage.\n3. Set up your DNS records (optional).\n4. Configure your DNS information with the name servers provided.\n5. Continue getting started with CIS by following a tutorial, or by setting up other features.\n\n\n\n\n\n Step 1: Open the IBM CIS application \n\nOpen the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog). Then, select the Networking category in the navigation pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04175-0-1274","score":9.745699,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_04214-1728-3555","score":9.44024,"text":"\nMigration to Standard Next plans \n\nTo migrate from your current Standard plan to a Standard Next plan, take the following steps.\n\n\n\n1. Enter your existing CIS instance\n2. Navigate to the Plan page in left side panel\n3. Select Standard Next plan\n4. Check the box to acknowledge the terms and conditions\n5. Click Create and follow any prompts that might block this plan change\n\n\n\n\n\n\n\n\n\n Transitioning to Enterprise Tier plans \n\nStarting 31 August 2023, the current CIS Enterprise Package, Enterprise GLB, and Enterprise Security plans will no longer be available for new instances. Any instance that is created on or after this date will use the new Enterprise Tier plans.\n\nBy moving to a more metered model, the base cost of the Enterprise Tier plans are smaller than the original Enterprise plans. The following table shows what features are available in the Enterprise Tier plans.\n\n\n\nTable 2. Comparison of CIS Enterprise Tier plans\n\n Features Enterprise Essential Enterprise Advanced Enterprise Premier \n\n Included domains 1 2 2 \n Included DNS records 3500 3500 3500 \n Protected traffic included (DDoS, CDN, DNS, WAF, GLB) 5 TB 5 TB 5 TB \n Requests included (CDN, WAF, GLB) in millions 150 150 150 \n Custom uploaded certificates 25 25 25 \n GLB: Origins, pools, GLB included 20 20 20 \n Range (Layer 3\/4) No Yes Yes \n Advanced rate limiting No Yes Yes \n Advanced WAF No Yes Yes \n Bot management No No Yes \n\n\n\n\n\n Migration to Enterprise Tiers plans \n\nTo migrate from your current Enterprise Package, Enterprise GLB, and Enterprise Security plans, take the following steps.\n\n\n\n1. Enter your existing CIS instance\n2. Navigate to the Plan page in left side panel\n3. Select desired Enterprise Tier plan\n4. Check the box to acknowledge the terms and conditions\n5. Click Create and follow any prompts that might block this plan change","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-transition-plans"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04170-7-2189","score":12.830801,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04105-5067-6335","score":12.222054,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-3403-5572","score":11.586396,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04177-7-2309","score":11.149438,"text":"\nManaging your CIS deployment \n\nYou'll begin by using the Overview screen as your working base of operations. It shows all of the current parameters for your deployment.\n\nOnce you've set up your DNS and configured it, you are ready to go!\n\n\n\n Using the Overview screen \n\nUsing the Overview screen, you can see the status of all your selections. Each setting links to the section of the user interface where the setting is configured. To modify any selection, you can navigate by clicking the link for the setting. For example, to change the load balancer configuration or add a new load balancer, click the Load Balancer field.\n\nOn the Overview screen, you might see that your domain name configuration is in Pending status, or in Active status. Pending status indicates that your domain is not fully set up, yet. You have to update your DNS provider or registrar with the name servers that are provided as part of the setup process.\n\nEnterprise only: The Service Details section of the Overview also allows you to add additional domains to your instance of CIS, and to switch between multiple domains.\n\n\n\n\n\n Changing the Service mode \n\nIn the Service Mode section of the Overview page is a list menu to select one of two modes:\n\n\n\n* Defense Mode helps protect against existing or predicted DNS attacks. This mode prevents all traffic from reaching your origin servers through your domain.\n* Pause Service disables all security and performance benefits to your domain. DNS functions still resolve for your website, but traffic is sent directly to configured origins.\n\n\n\n\n\n Setting up Service mode \n\n\n\n1. Select the mode you want from the list menu.\n2. Click Activate mode.\n3. Confirm or cancel the selection in the confirmation pop-up.\n\n\n\nA notification appears on all pages to show that either Pause Service or Defense Mode is active. To return to normal operation, click Deactivate mode in the notification banner.\n\n\n\n\n\n\n\n Configuring and managing your DNS \n\nGo to the Reliability section, click the DNS tab and add a record. Type in the information about your DNS record and then click Add record to implement your changes.\n\nAfter creating your records, consider turning on the Proxy setting. Most of the features of CIS require that the internet traffic to your site flow through CIS infrastructure.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-cis-deployment"},{"document_id":"ibmcld_04170-1738-2974","score":10.879426,"text":"\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed. Your CSP should allow scripts that are served from your origin domain (script-src self).\n* If your CSP uses a nonce for script tags, CIS adds these nonces to the scripts it injects by parsing your CSP response header.\n* If your CSP does not use nonce for script tags and JavaScript Detection is enabled, you might see a console error such as\n\nRefused to execute inline script because it violates the following Content Security Policy directive: \"script-src 'self'\". Either the 'unsafe-inline' keyword, a hash ('sha256-b123b8a70+4jEj+d6gWI9U6IilUJIrlnRJbRR\/uQl2Jc='), or a nonce ('nonce-...') is required to enable inline execution.\n* It is not recommended to use unsafe-inline. Instead, it is recommend that you use CSP nonces in script tags which are parsed and supported in the CDN.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04179-7-1888","score":10.7208395,"text":"\nManaging CIS for optimal security \n\nThe IBM Cloud\u00ae Internet Services (CIS) security settings include safe defaults designed to avoid false positives and negative influence on your traffic. However, these safe default settings do not provide the best security posture for every customer. Take the following steps to be sure that your CIS account is configured in a safe and secure way.\n\nRecommendations and best practices:\n\n\n\n* Secure your origin IP addresses by proxying and increasing obfuscation\n* Configure your security level selectively\n* Activate your Web Application Firewall (WAF) safely\n\n\n\n\n\n Best practice 1: Secure your origin IP addresses \n\nWhen a subdomain is proxied using CIS, all traffic is protected because we actively respond with IP addresses specific to CIS (for example, all of your clients connect to CIS proxies first, and your origin IP addresses are obscured).\n\n\n\n Use CIS proxies for all DNS records for HTTP(S) traffic from your origin \n\nTo improve the security of your origin IP address, you should proxy all HTTP(S) traffic.\n\nSee the difference yourself - Query a non-proxied and a proxied record:\n\ndig nonproxied.theburritobot.com +short\n1.2.3.4 (The origin IP address)\n\n$ dig proxied.theburritobot.com +short\n104.16.22.6 , 104.16.23.6 (CIS IP addresses)\n\n\n\n\n\n Obscure non-proxied origin records with non-standard names \n\nAny records that cannot be proxied through CIS, and that still use your origin IP, such as FTP, can be secured by creating additional obfuscation. In particular, if you require a record for your origin that cannot be proxied by CIS, use a non-standard name. For example, instead of ftp.example.com use [random word or-random characters].example.com. This obfuscation makes dictionary scans of your DNS records less likely to expose your origin IP addresses.\n\n\n\n\n\n Use separate IP ranges for HTTP and non-HTTP traffic if possible","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-security"},{"document_id":"ibmcld_04149-7-1761","score":10.519628,"text":"\nGetting started with IBM Cloud Internet Services \n\nIBM Cloud\u00ae Internet Services (CIS), powered with Cloudflare, offers three main capabilities to enhance your workflow: [security](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-security), [reliability](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cloud-internet-services-deployment-for-optimal-reliability), and [performance](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-cis-deployment-for-best-performance). You can navigate to features for each of these capabilities after you open the CIS UI.\n\nFor each capability, CIS helps you tune its features to suit your specific needs. These features are detailed in the [About IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis) section.\n\n\n\n Before you begin \n\nBefore you begin using CIS:\n\n\n\n* You'll need an [IBMid](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=urx-19776).\n* Then, you can order your services through the [IBM Cloud Internet Services console](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services).\n\n\n\nIt is recommended that you use the Chrome browser for CIS.\n\n\n\n\n\n Process overview \n\nYou can start using CIS for your internet traffic with just a few steps.\n\n\n\n1. Open the CIS application from your IBM Cloud dashboard.\n2. Add the domain that you want to manage.\n3. Set up your DNS records (optional).\n4. Configure your DNS information with the name servers provided.\n5. Continue getting started with CIS by following a tutorial, or by setting up other features.\n\n\n\n\n\n Step 1: Open the IBM CIS application \n\nOpen the [IBM Cloud catalog](https:\/\/cloud.ibm.com\/catalog). Then, select the Networking category in the navigation pane.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-getting-started"},{"document_id":"ibmcld_04113-1734-4014","score":10.378403,"text":"\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:\n\n\n\n* Select Security Level to Essentially off\n* Select TLS to Off\n* Select Browser Integrity Check to Off\n\n\n\n* Select Provision Resource\n\n\n\n* Alternatively, you can turn off Web Application Firewall globally from the Security page.\n\n\n\n\n\n What does the Browser Integrity Check do? \n\nThe browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks visitors that do not have a user agent, or who add a non-standard user agent (this tactic is commonly used by abuse bots, crawlers, or APIs).\n\n\n\n\n\n\n\n Best practice 4: Configure your security settings as strictly as possible \n\nCIS provides some options for encrypting your traffic. As a reverse proxy the TLS connection is terminated at Cloudflare and a new TLS connection is opened to your origin servers. For your termination with CIS, you can upload a custom certificate from your account, you can use a wildcard certificate provisioned for you by CIS, or both.\n\n\n\n Upload a custom certificate \n\nYou can upload your public and private key when you create an Enterprise domain. If you upload your own certificate, you gain immediate compatibility with encrypted traffic, and you maintain control over your certificate (for example, an Extended Validation (EV) certificate). Remember that you'll be responsible for managing your certificate if you upload a custom certificate. For example, IBM CIS won't track the certificate expiration dates.\n\n\n\n\n\n Alternatively, use a certificate provisioned by CIS \n\nIBM CIS has partnered with several Certificate Authorities (CAs) to provide domain wildcard certificates for our customers, by default. Manual verification could be required for setting up these certificates, and your support team can help you perform these additional steps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-best-practices-for-cis-setup"},{"document_id":"ibmcld_04175-0-1274","score":10.32077,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_04107-10503-12404","score":10.047336,"text":"\n* Proxy and non-proxy options for load balancing\n* Origin pools and health checks\n\n\n\n\n\n Global anycast network \n\nThe available health check regions are based on the [Cloudflare Global Anycast Network](https:\/\/www.cloudflare.com\/network\/).\n\n\n\n\n\n\n\n DNS features \n\nDNS within CIS has the following features:\n\n\n\n* DNS management - Manage your DNS records, control proxying, and enable DNS security.\n* DNSSEC - DNS security cryptographically signs a zone to ensure that the DNS records provided to the user are the same as the DNS records published on the DNS server.\n\n\n\n\n\n\n\n gRPC protocol support \n\nThe gRPC protocol builds efficient APIs with smaller payloads, which reduces bandwidth requirements, decreases latency, and increases the implementation time. CIS supports gRPC protocol for any proxied gRPC endpoints. To enable or disable gRPC support, navigate to the Reliability section, select the Advanced tab, and toggle the gRPC switch.\n\nThe following requirements must be met before you use gRPC:\n\n\n\n* The gRPC endpoint must listen on port 443\n* The gRPC endpoint must support TLS and HTTP\/2\n* HTTP\/2 must be advertised over Application-Layer Protocol Negotiation (ALPN)\n* The content-type header of gRPC requests must use application\/grpc or application\/grpc+<message type>\n\n\n\n\n\n\n\n\n\n Performance features \n\nZoom\n\n![performance graphic](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/images\/performance-graphic.png)\n\nFigure 3. Performance features\n\n\n\n Caching \n\nControl how CIS manages your cached assets.\n\n\n\n\n\n Page rules \n\nFine-tune your cache behavior and create content optimization.\n\n\n\n\n\n Routing \n\nEliminate excess latency by analyzing and optimizing routing decisions across the global internet using real-time network connections.\n\n\n\n\n\n Advanced performance \n\nApply Brotli compression and restrict upload sizes in the advanced performance section.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6934264036,"ndcg_cut_5":0.6934264036,"ndcg_cut_10":0.6934264036}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04175-0-1274","score":16.625141,"text":"\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-machine-learning-models"},{"document_id":"ibmcld_04170-7-2189","score":10.672617,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04334-43529-45385","score":10.599379,"text":"\nUpdate a feature for the domain.\n\nibmcloud cis domain-settings-update DNS_DOMAIN_ID (-f, --feature FEATURE) (-v, --value VALUE) [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required. -f, --feature value\n: Feature of domain settings to update. Required. Valid values:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination. These ciphers must be in the BoringSSL format.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.\n* image_size_optimization: Improve image load time by optimizing images hosted on your domain.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_16256-4941-7340","score":10.448432,"text":"\nThis version is then labeled as Previous after you upgrade. In addition, each new release will support running models that were trained on the version prior to that so that upgrading won't impact your runtime. For example, if you upgrade from IBM Cloud Pak for Data 4.6 to 4.7, and were using Latest (01-Jun-2022) that version becomes listed as Previous (01 June 2022) and remains your selected version.\n\n\n\n Automatic retraining after upgrading \n\nAfter your Watson Assistant for IBM Cloud Pak for Data upgrade is complete, Watson Assistant performs automatic retraining for any assistant models that were trained using a version that is no longer supported. In this case, Watson Assistant automatically retrains your assistant to the Latest version. This automatic retraining is required to assure your ability to run your trained models in your next upgrade.\n\n\n\n\n\n Best practices \n\nIt's recommended to use the Latest version in your production deployment of Watson Assistant for IBM Cloud Pak for Data. This is the default for newly-created assistants. During an upgrade, your settings don't automatically switch existing assistants to use the latest version. If prior to your upgrade you had selected Latest, your settings continue to use that version, now labeled as Previous. After you upgrade, it's recommended you choose Latest and run basic regression tests.\n\nIBM performs robust testing on a variety of data sets to minimize impacts on existing assistants. But given the nature of machine learning models and the nuance and subtlety of natural languages processing, you may find some discrepancies from version to version. If you find a major issue through your tests, you have the ability to switch your settings and use Previous to return to the prior behavior. In this event, we recommend you contact IBM and provide details of your test so that that IBM can support you in the steps to resolve the problem.\n\nIt's also recommended that you try the Beta version in one of your test systems after you upgrade. This gives you early visibility to changes that are likely to be delivered in a future version, and will reduce the probability of negative impacts to your production systems. IBM values both positive and negative feedback from customers who use Beta. You will have the opportunity to shape how the algorithms function before the version is promoted to Latest in a future version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-algorithm-version"},{"document_id":"ibmcld_16495-3299-5420","score":10.288925,"text":"\nYou might need to make modifications while you train a model, based on the performance statistics. But, generally, you want the type system to be as close to final as possible before you begin large-scale annotation tasks. If you change the type system after human annotators began their work, they must revisit the documents that they annotated. They must assess the applicability of the type system changes.\n\n\n\n About this task \n\nThis process propagates the current type system, ground truth editor keyboard shortcuts, and color settings to all document sets in a task.\n\n\n\n\n\n Procedure \n\nTo modify the type system without losing the work that was done by human annotators:\n\n\n\n1. Change the type system. For example, you can add or remove entity types or relation types.\n2. Decide whether you want to propagate the changes to existing human annotation tasks.\n3. Open the Machine Learning Model > Annotations page and click the Annotation Tasks tab. Open each task that you want to update and click Apply Type System Updates.\n\nIf you removed entity types or relation types from the type system, all occurrences of those types are highlighted in gray in the documents. These invalid types are ignored by the machine learning model. They do not prevent you from submitting and approving document sets.\n4. Provide details to the human annotators about what changed in the type system.\n5. Ask human annotators to update their documents to reflect the changes in the type system. For example, if you added new entity types or relation types, they must review their documents and annotate them appropriately.\n\n> Note: If the task contains completed documents, human annotators cannot alter those documents to assess type system changes until they are back in an editable state. To become editable, ask human annotators to submit the document sets so that you can reject them.\n\n\n\nRelated concepts:\n\n[Type systems](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-typesystemwks_typesystem)\n\n\n\n\n\n\n\n Document set management \n\nUse the right sets of data to test and train the model at the right time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio?topic=watson-knowledge-studio-improve-ml"},{"document_id":"ibmcld_13429-122860-124889","score":10.213804,"text":"\nThe new models offer improved speech recognition. By default, the service automatically uses the updated models for all recognition requests. If you have custom language or custom acoustic models that are based on these models, you must upgrade your existing custom models to take advantage of the updates by using the following methods:\n\n\n\n* POST \/v1\/customizations\/{customization_id}\/upgrade_model\n* POST \/v1\/acoustic_customizations\/{customization_id}\/upgrade_model\n\n\n\nFor more information, see [Upgrading custom models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-custom-upgrade).\n\nKeyword spotting and word alternatives features now generally available\n: The keyword spotting and word alternatives features are now generally available (GA) rather than beta functionality for all languages. For more information, see\n\n\n\n* [Keyword spotting](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-spottingkeyword-spotting)\n* [Word alternatives](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-spottingword-alternatives)\n\n\n\nDefect fix: Improve documentation for customization interface\n: Defect fix: The following known issues that were associated with the customization interface have been resolved and are fixed in production. The following information is preserved for users who may have encountered the problems in the past.\n\n\n\n* If you add data to a custom language or custom acoustic model, you must retrain the model before using it for speech recognition. The problem shows up in the following scenario:\n\n\n\n1. The user creates a new custom model (language or acoustic) and trains the model.\n2. The user adds additional resources (words, corpora, or audio) to the custom model but does not retrain the model.\n3. The user cannot use the custom model for speech recognition. The service returns an error of the following form when used with a speech recognition request:\n\n{\n\"code_description\": \"Bad Request\",\n\"code\": 400,\n\"error\": \"Requested custom language model is not available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_16437-3299-5354","score":10.205077,"text":"\nYou might need to make modifications while you train a model, based on the performance statistics. But, generally, you want the type system to be as close to final as possible before you begin large-scale annotation tasks. If you change the type system after human annotators began their work, they must revisit the documents that they annotated. They must assess the applicability of the type system changes.\n\n\n\n About this task \n\nThis process propagates the current type system, ground truth editor keyboard shortcuts, and color settings to all document sets in a task.\n\n\n\n\n\n Procedure \n\nTo modify the type system without losing the work that was done by human annotators:\n\n\n\n1. Change the type system. For example, you can add or remove entity types or relation types.\n2. Decide whether you want to propagate the changes to existing human annotation tasks.\n3. Open the Machine Learning Model > Annotations page and click the Annotation Tasks tab. Open each task that you want to update and click Apply Type System Updates.\n\nIf you removed entity types or relation types from the type system, all occurrences of those types are highlighted in gray in the documents. These invalid types are ignored by the machine learning model. They do not prevent you from submitting and approving document sets.\n4. Provide details to the human annotators about what changed in the type system.\n5. Ask human annotators to update their documents to reflect the changes in the type system. For example, if you added new entity types or relation types, they must review their documents and annotate them appropriately.\n\n> Note: If the task contains completed documents, human annotators cannot alter those documents to assess type system changes until they are back in an editable state. To become editable, ask human annotators to submit the document sets so that you can reject them.\n\n\n\nRelated concepts:\n\n[Type systems](https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-typesystemwks_typesystem)\n\n\n\n\n\n\n\n Document set management","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-ml"},{"document_id":"ibmcld_03110-6742-7759","score":10.08476,"text":"\nBut given the nature of machine learning models and the nuance and subtlety of natural languages processing, you may find some discrepancies from version to version. If you find a major issue through your tests, you have the ability to switch your settings and use Previous to return to the prior behavior. In this event, we recommend you contact IBM and provide details of your test so that that IBM can support you in the steps to resolve the problem.\n\nIt's also recommended that you try the Beta version in one of your test systems after you upgrade. This gives you early visibility to changes that are likely to be delivered in a future version, and will reduce the probability of negative impacts to your production systems. IBM values both positive and negative feedback from customers who use Beta. You will have the opportunity to shape how the algorithms function before the version is promoted to Latest in a future version. If you choose Beta, your assistant always trains on the most current beta version.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-algorithm-version"},{"document_id":"ibmcld_04105-5067-6335","score":9.896111,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_13429-128669-130443","score":9.808763,"text":"\n: The Spanish narrowband model, es-ES_NarrowbandModel, was updated for improved speech recognition. By default, the service automatically uses the updated model for all recognition requests. If you have custom language or custom acoustic models that are based on this model, you must upgrade your custom models to take advantage of the updates by using the following methods:\n\n\n\n* POST \/v1\/customizations\/{customization_id}\/upgrade_model\n* POST \/v1\/acoustic_customizations\/{customization_id}\/upgrade_model\n\n\n\nFor more information, see [Upgrading custom models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-custom-upgrade).\n\nAs of this update, the following two versions of the Spanish narrowband model are available:\n\n\n\n* es_ES.8kHz.general.lm20180522235959.am20180522235959 (current)\n* es_ES.8kHz.general.lm20180308235959.am20180308235959 (previous)\n\n\n\nThe following version of the model is no longer available:\n\n\n\n* es_ES.8kHz.general.lm20171031235959.am20171031235959\n\n\n\nA recognition request that attempts to use a custom model that is based on the now unavailable base model uses the latest base model without any customization. The service returns the following warning message: Using non-customized default base model, because your custom {type} model has been built with a version of the base model that is no longer supported. To resume using a custom model that is based on the unavailable model, you must first upgrade the model by using the appropriate upgrade_model method described previously.\n\n\n\n\n\n 12 June 2018 \n\nNew features for applications hosted in Washington, DC, location\n: The following features are enabled for applications that are hosted in Washington, DC (us-east):\n\n\n\n* The service now supports a new API authentication process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04170-7-2189","score":13.373187,"text":"\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https:\/\/research.google\/pubs\/pub45581\/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with \/cdn-cgi\/challenge-platform\/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"},{"document_id":"ibmcld_04105-3403-5572","score":12.266212,"text":"\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04105-5067-6335","score":11.433373,"text":"\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-bot-mgmt"},{"document_id":"ibmcld_04334-40577-42576","score":11.121162,"text":"\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.\n* image_size_optimization: Improve image load time by optimizing images hosted on your domain.\n* ip_geolocation: Include the country code of the visitor location with all requests to your website.\n* ipv6: Enable IPv6 support and gateway.\n* max_upload: The amount of data visitors can upload to your website in a single request.\n* min_tls_version: Only allow HTTPS connections from visitors that support the selected TLS protocol version or newer.\n* minify: Reduce the file size of source code on your website.\n* mobile_redirect: Redirect visitors that are using mobile devices to a mobile-optimized website.\n* opportunistic_encryption: Opportunistic Encryption allows browsers to benefit from the improved performance of HTTP\/2 by letting them know that your site is available over an encrypted connection.\n* origin_error_page_pass_thru: When Origin Error Page is set to On, CIS will proxy the 502 and 504 error pages directly from the origin. (Enterprise plan only)\n* prefetch_preload: CIS will prefetch any URLs included in the prefetch HTTP header (Enterprise plan only).\n* pseudo_ipv4: Adds an IPv4 header to requests when a client is using IPv6, but the server only supports IPv4.\n* response_buffering: Enable or disable buffering of responses from the origin server (Enterprise plan only).\n* script_load_optimization: Improve the paint time for pages that include JavaScript.\n* security_header: Enforce web security policy for your website.\n* security_level: Choose the appropriate security profile for your website.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_03109-10370-12635","score":10.518855,"text":"\nWhen the web chat widget is being interacted with by a user, we track the features that are being used, and events such as how many times the widget is opened and how many users start conversations. This information does not include Assistant training data or the content of any chat interactions. The information being sent to Amplitude is not Content as defined in the Cloud Service Agreement (CSA); it is Account Usage Information as described in Section 9.d of the CSA and is handled accordingly as described in the [IBM Privacy Statement](https:\/\/www.ibm.com\/privacy). The purpose of this information gathering is limited to establishing statistics about use and effectiveness of the web chat and making general improvements.\n\n\n\n\n\n Private network endpoints \n\nYou can set up a private network for Watson Assistant instances that are part of a Plus or Enterprise service plan. Using a private network prevents data from being transferred over the public internet, and ensures greater data isolation.\n\n![Plus or higher plans only](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/417db917d18067d9dcc4cf2612564a9a87c3ddc8\/assistant\/images\/plus.png) This feature is available only to users of paid plans.\n\nPrivate network endpoints support routing services over the IBM Cloud private network instead of the public network. A private network endpoint provides a unique IP address that is accessible to you without a VPN connection.\n\nFor implementation details, see [Public and private network endpoints](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-public-private-endpoints).\n\n\n\n Important private network endpoint notes \n\n\n\n* The integrations that are provided with the product require endpoints that are available on the public internet. Therefore, any built-in integrations you add to your assistant will have public endpoints. If you only want to connect to a client application or messaging channel over the private network, then you must build your own custom client application or channel integration.\n* Before you can use a search integration or search skill, you must create a Discovery instance with a private network endpoint. The list of Discovery instances that are displayed for you to connect to includes only instances with private network endpoints.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-admin-securing"},{"document_id":"ibmcld_16729-186060-188072","score":10.414206,"text":"\nThis tutorial highlights how Cloud Internet Services (CIS), a uniform platform to configure and manage the Domain Name System (DNS), Global Load Balancing (GLB), Web Application Firewall (WAF), and protection against Distributed Denial of Service (DDoS) for internet applications, can be integrated with Kubernetes clusters to support this scenario and to deliver a secure and resilient solution across multiple locations.\n\nKubernetes service Container Registry\n\n+1\n\nCloud Internet Services (CIS)\n\n\n\n* 2 hours\n* 2023-05-10\n\n\n\n[Deploy isolated workloads across multiple locations and zones](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-multi-region)Deploy isolated workloads across multiple locations and zones\n\nThis tutorial walks you through steps for setting up highly available and isolated workloads by provisioning IBM Cloud\u00ae Virtual Private Clouds (VPCs). You will create virtual server instances (VSIs) in multiple zones within one region to ensure the high availability of the application. You will create additional VSIs in a second region and configure a global load balancer (GLB) to provide high availability between regions and reduce network latency for users in different geographies.\n\nVirtual Private Cloud (VPC) Cloud Internet Services (CIS)\n\n+1\n\nSecrets Manager\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Centralize communication through a VPC Transit Hub and Spoke architecture - Part one](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-transit1)Centralize communication through a VPC Transit Hub and Spoke architecture - Part one\n\nA Virtual Private Cloud (VPC) provides network isolation and security in the IBM Cloud. A VPC can be a building block that encapsulates a corporate division (marketing, development, accounting, ...) or a collection of microservices owned by a DevSecOps team. VPCs can be connected to an on-premises enterprise and each other. This may create the need to route traffic through centralized firewall-gateway appliances.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_04334-39121-41053","score":10.353616,"text":"\nValid values for group are all, domain, reliability, performance, security. This option is mutually exclusive with -f, --feature.\n\n-f, --feature\n: Feature of domain settings to check. This option is mutually exclusive with g, --group. Valid values are as follow:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination in the BoringSSL format. This command only lists ciphers specifically whitelisted by customers. If no ciphers are whitelisted, the list is empty and the default ciphers are used. See [TLS Options](\/docs\/cis? topic=cis-cis-tls-options#cipher-suites) for the list of default ciphers.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP\/2.\n* http3: Accelerate your website with HTTP\/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cis-cli"},{"document_id":"ibmcld_12529-7-2053","score":10.281639,"text":"\nCatalog management on IBM Cloud \n\nAs an account owner, you can control your users' access to the IBM Cloud catalog, which contains over 350 products available for public use. You can hide the IBM Cloud catalog from all users, or apply filters to scope the products that are available. Within your account, private catalogs provide more fine-tuned control over access to products in the IBM Cloud catalog.\n\nLet's say you're an account administrator for your team, and you require access to all products in the IBM Cloud catalog. A member of your team is tasked with a specific project, for example, building a voice-enabled chatbot by using Watson Assistant, Speech to Text, and Text to Speech. And, you want them to access only those products in the IBM Cloud catalog.\n\nTo achieve this, you create one catalog that includes all products in the IBM Cloud catalog. Then, you create another catalog that includes only the required products, and you give the team member viewer access to the catalog.\n\nFor information about managing settings for all catalogs in your account, go to [Managing catalog settings](https:\/\/cloud.ibm.com\/docs\/account?topic=account-filter-account&interface=ui).\n\nFor information about filtering the products that are available to users in your account, go to [Customizing the IBM Cloud catalog and private catalogs for users in your account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-restrict-by-user&interface=ui).\n\nWhen you're ready, head over to [Catalog management](https:\/\/cloud.ibm.com\/content-mgmt\/overview) in the IBM Cloud console to get started.\n\n\n\n Watch and learn \n\n\n\n* Video transcript\n\nManage settings for catalogs across your account. Go to Manage > Catalogs to access catalog management. Then, click Settings.\n\nTurn the IBM Cloud catalog off or on with one click. From the Settings page, you can control whether users in your account can access the IBM Cloud catalog or not. Toggle on the IBM Cloud catalog to make the catalog available for users in your account.\n\nAdd rules for fine-grained control.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-cm-video"},{"document_id":"ibmcld_12457-1784-3800","score":10.228458,"text":"\nIf you have a working ACME client or account for Let's Encrypt, you can use your existing private key. If you don't have an account yet, you can create one by using the [ACME account creation tool](https:\/\/github.com\/ibm-cloud-security\/acme-account-creation-tool).\n\nCertificate authorities can apply a charge when you are ordering or renewing a certificate. Additionally, various rate limits apply. Secrets Manager does not control costs or rate limits that are associated with ordering certificates. For more information about rate limits to keep in mind as you order Let's Encrypt certificates, check out the [Let's Encrypt documentation](https:\/\/letsencrypt.org\/docs\/rate-limits\/).\n\n\n\n\n\n\n\n Supported DNS providers \n\nA DNS provider is the service that is used to manage the domains that you own. You can connect the following DNS providers with your Secrets Manager service instance.\n\n\n\nTable 2. DNS provider options\n\n DNS provider Description \n\n [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) IBM Cloud\u00ae Internet Services (CIS), powered by Cloudflare, provides a fast, highly performant, reliable, and secure internet service for customers who are running their business on IBM Cloud. \n [IBM Cloud classic infrastructure](https:\/\/cloud.ibm.com\/catalog\/infrastructure\/domain_registration) [IBM Cloud\u00ae Domain Name Registration](https:\/\/cloud.ibm.com\/docs\/dns), available as part of IBM Cloud classic infrastructure (SoftLayer), offers a central location from which to view and manage domains. \n [Manual DNS providers](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-public-certificatesorder-public-cert-manual-ui) If your DNS provier is not IBM Cloud Internet Services or IBM Cloud Domain Name Registration, you can connect your Secrets Manager to your DNS provider manually. \n\n\n\n\n\n Granting service access to CIS \n\nIf you manage your domains in Cloud Internet Services (CIS), you must assign access to Secrets Manager so that it can validate the ownership.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-prepare-order-certificates&interface=ui"},{"document_id":"ibmcld_04170-1738-2974","score":10.180359,"text":"\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under \/cdn-cgi\/challenge-platform\/ is allowed. Your CSP should allow scripts that are served from your origin domain (script-src self).\n* If your CSP uses a nonce for script tags, CIS adds these nonces to the scripts it injects by parsing your CSP response header.\n* If your CSP does not use nonce for script tags and JavaScript Detection is enabled, you might see a console error such as\n\nRefused to execute inline script because it violates the following Content Security Policy directive: \"script-src 'self'\". Either the 'unsafe-inline' keyword, a hash ('sha256-b123b8a70+4jEj+d6gWI9U6IilUJIrlnRJbRR\/uQl2Jc='), or a nonce ('nonce-...') is required to enable inline execution.\n* It is not recommended to use unsafe-inline. Instead, it is recommend that you use CSP nonces in script tags which are parsed and supported in the CDN.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-javascript-detections"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05440-3062-4677","score":12.304452,"text":"\nUse secrets to store sensitive information You can store information, such as passwords and SSH keys in a secret. For more information, see [Working with secrets](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret). \n\n\n\n\n\n Supported TLS versions and cipher suites \n\nThe Code Engine API and application endpoints support transport layer security (TLS) 1.2 (or higher) and the following cipher suites.\n\n\n\n TLS cipher suites \n\n\n\n* ECDHE-ECDSA-AES128-GCM-SHA256\n* ECDHE-ECDSA-AES256-GCM-SHA384\n* ECDHE-RSA-AES128-GCM-SHA256\n* ECDHE-RSA-AES256-GCM-SHA384\n* ECDHE-ECDSA-CHACHA20-POLY1305\n* ECDHE-RSA-CHACHA20-POLY1305\n\n\n\n\n\n\n\n\n\n DDoS protection \n\nCode Engine provides out-of-the-box DDoS protection for your application. Code Engine's DDoS protection is provided by Cloud Internet Services (CIS) at no additional cost to you.\n\nDDoS protection covers System Interconnection (OSI) Layer 3 and Layer 4 (TCP\/IP) protocol attacks, but not Layer 7 (HTTP) attacks.\n\nTo address Layer 7 attacks, you can take the following steps so that your traffic runs through a secure route using your custom domain and is no longer available to the public internet through the Code Engine provided domain.\n\n\n\n1. Obtain your custom domain.\n2. In Code Engine, [create a custom domain mapping](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-domain-mappings) for your app.\n3. Set up an instance of [Cloud Internet Services (CIS)](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) to manage your custom domain.\n4. [Add the custom domain to the CIS instance](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-domain-support).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secure"},{"document_id":"ibmcld_13877-27044-28556","score":11.28864,"text":"\n4. Click Order a public certificate.\n5. Name secure-file-storage.example.com.\n6. Certificate authority: LetsEncrypt created earlier.\n7. Key algorithm: RSA2048.\n8. DNS provider: cis created earlier.\n9. Select domains .\n10. Open the cis example.com.\n11. Click secure-file-storage.example.com created as a DNS CNAME record created earlier.\n12. Click Done then Order.\n13. Click the three vertical dots menu for the active secret and choose Show snippet and note the secret's PUBLIC_CERT_ID can be extracted from the command line. Export the value in the shell. It will look something like this:\n\n\n\nexport PUBLIC_CERT_ID=01234567-abcd-abcd-abcd-01234567abcd\n5. Click Endpoints on the left. Make note of the Public URL in the Service API section. This is the Secrets Manager SECRETS_MANAGER_API_URL. Export it in the shell. Something like this:\n\nexport SECRETS_MANAGER_API_URL=https:\/\/01234567-0123-0123-0123-01234567abcd.us-south.secrets-manager.appdomain.cloud\n\n\n\nThis tutorial leverages the [External Secrets Operator](https:\/\/external-secrets.io\/) to access the Secrets Manager service instance and the secret created from your cluster. A service ID and API key are required to provide access:\n\n\n\n1. Create a service ID and set it as an environment variable.\n\nexport SERVICE_ID=ibmcloud iam service-id-create secure-file-storage-tutorial --description \"A service ID for e2e security tutorial.\" --output json | jq -r \".id\"; echo $SERVICE_ID\n2. Assign the service ID permissions to read secrets from Secrets Manager.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-cloud-e2e-security"},{"document_id":"ibmcld_12492-87895-89178","score":10.887204,"text":"\n\"cis_crn\": \"crn:v1:bluemix:public:internet-svcs:global:a\/a5ebf2570dcaedf18d7ed78e216c263a:0f4c764e-dc3d-44d1-bd60-a2f7cd91e0c0::\"\n},\n\"name\": \"my-cis-instance\",\n\"type\": \"cis\"\n},\n\"wrap_info\": null,\n\"warnings\": null,\n\"auth\": null\n}\n\n\n\n\n\n\n\n Delete a configuration \n\nRemoves a configuration for a secrets engine that serves as the backend for a specific type of secret. You can delete configurations for the following secret types: public_cert, private_cert\n\n\n\n Example requests \n\nDelete a public certificate authority configuration.\n\ncurl -X DELETE 'https:\/\/https:\/\/{instance_id}.{region}.secrets-manager.appdomain.cloud\/v1\/ibmcloud\/public_cert\/config\/certificate_authorities\/my-lets-encrypt' -H 'X-Vault-Token: {Vault-Token}'\n\nDelete the DNS provider configuration.\n\ncurl -X DELETE 'https:\/\/https:\/\/{instance_id}.{region}.secrets-manager.appdomain.cloud\/v1\/ibmcloud\/public_cert\/config\/dns_providers\/my-cis-instance' -H 'X-Vault-Token: {Vault-Token}'\n\nDelete a private certificate authority configuration.\n\ncurl -X DELETE 'https:\/\/https:\/\/{instance_id}.{region}.secrets-manager.appdomain.cloud\/v1\/ibmcloud\/private_cert\/config\/root_certificate_authorities\/my-root-ca' -H 'X-Vault-Token: {Vault-Token}'\n\n\n\n\n\n Example response \n\nA successful request returns an HTTP 204 No Content response.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-api"},{"document_id":"ibmcld_13877-25808-27295","score":10.695915,"text":"\nsecure-file-storage.example.com-account-info.json secure-file-storage.example.com-private-key.pem\nShow more\n\n\n\n2. Connect the Let's Encrypt ACME account to the Secrets Manager instance. See [Adding a certificate authority configuration in the UI](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-add-certificate-authority&interface=uiadd-certificate-authority-ui) for more details:\n\n\n\n1. Open the Secrets Managerservice instance, you can find it in the [Resource List](https:\/\/cloud.ibm.com\/resources).\n2. Open Secrets engines on the left and click Public certificates.\n3. Under Certificate authorities click Add.\n4. Name: LetsEncrypt and Certificate authority: Let's Encrypt.\n5. For the Private key under Select file click Add file and choose the secure-file-storage.example.com-private-key.pem or your existing .pem file from the chooser.\n6. Click Add.\n\n\n\n3. Connect the CIS as a DNS provider:\n\n\n\n1. Under DNS providers click Add.\n2. Name cis and choose Cloud Internet Services from the dropdown.\n3. Click Next.\n4. In the Authorization tab choose the CIS instance.\n5. Click Add.\n\n\n\n4. Add the TLS certificate secret to Secrets Manager:\n\n\n\n1. Click the Secrets tab on the left.\n2. Click Add.\n3. Click TLS certificates.\n4. Click Order a public certificate.\n5. Name secure-file-storage.example.com.\n6. Certificate authority: LetsEncrypt created earlier.\n7. Key algorithm: RSA2048.\n8. DNS provider: cis created earlier.\n9. Select domains .\n10. Open the cis example.com.\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/tutorials?topic=solution-tutorials-cloud-e2e-security"},{"document_id":"ibmcld_12457-1784-3800","score":10.563976,"text":"\nIf you have a working ACME client or account for Let's Encrypt, you can use your existing private key. If you don't have an account yet, you can create one by using the [ACME account creation tool](https:\/\/github.com\/ibm-cloud-security\/acme-account-creation-tool).\n\nCertificate authorities can apply a charge when you are ordering or renewing a certificate. Additionally, various rate limits apply. Secrets Manager does not control costs or rate limits that are associated with ordering certificates. For more information about rate limits to keep in mind as you order Let's Encrypt certificates, check out the [Let's Encrypt documentation](https:\/\/letsencrypt.org\/docs\/rate-limits\/).\n\n\n\n\n\n\n\n Supported DNS providers \n\nA DNS provider is the service that is used to manage the domains that you own. You can connect the following DNS providers with your Secrets Manager service instance.\n\n\n\nTable 2. DNS provider options\n\n DNS provider Description \n\n [IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/catalog\/services\/internet-services) IBM Cloud\u00ae Internet Services (CIS), powered by Cloudflare, provides a fast, highly performant, reliable, and secure internet service for customers who are running their business on IBM Cloud. \n [IBM Cloud classic infrastructure](https:\/\/cloud.ibm.com\/catalog\/infrastructure\/domain_registration) [IBM Cloud\u00ae Domain Name Registration](https:\/\/cloud.ibm.com\/docs\/dns), available as part of IBM Cloud classic infrastructure (SoftLayer), offers a central location from which to view and manage domains. \n [Manual DNS providers](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-public-certificatesorder-public-cert-manual-ui) If your DNS provier is not IBM Cloud Internet Services or IBM Cloud Domain Name Registration, you can connect your Secrets Manager to your DNS provider manually. \n\n\n\n\n\n Granting service access to CIS \n\nIf you manage your domains in Cloud Internet Services (CIS), you must assign access to Secrets Manager so that it can validate the ownership.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-prepare-order-certificates&interface=ui"},{"document_id":"ibmcld_16729-186060-188072","score":10.513301,"text":"\nThis tutorial highlights how Cloud Internet Services (CIS), a uniform platform to configure and manage the Domain Name System (DNS), Global Load Balancing (GLB), Web Application Firewall (WAF), and protection against Distributed Denial of Service (DDoS) for internet applications, can be integrated with Kubernetes clusters to support this scenario and to deliver a secure and resilient solution across multiple locations.\n\nKubernetes service Container Registry\n\n+1\n\nCloud Internet Services (CIS)\n\n\n\n* 2 hours\n* 2023-05-10\n\n\n\n[Deploy isolated workloads across multiple locations and zones](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-multi-region)Deploy isolated workloads across multiple locations and zones\n\nThis tutorial walks you through steps for setting up highly available and isolated workloads by provisioning IBM Cloud\u00ae Virtual Private Clouds (VPCs). You will create virtual server instances (VSIs) in multiple zones within one region to ensure the high availability of the application. You will create additional VSIs in a second region and configure a global load balancer (GLB) to provide high availability between regions and reduce network latency for users in different geographies.\n\nVirtual Private Cloud (VPC) Cloud Internet Services (CIS)\n\n+1\n\nSecrets Manager\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Centralize communication through a VPC Transit Hub and Spoke architecture - Part one](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-transit1)Centralize communication through a VPC Transit Hub and Spoke architecture - Part one\n\nA Virtual Private Cloud (VPC) provides network isolation and security in the IBM Cloud. A VPC can be a building block that encapsulates a corporate division (marketing, development, accounting, ...) or a collection of microservices owned by a DevSecOps team. VPCs can be connected to an on-premises enterprise and each other. This may create the need to route traffic through centralized firewall-gateway appliances.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_12462-12296-13940","score":10.482636,"text":"\nca = ibm_sm_public_certificate_configuration_ca_lets_encrypt.my_lets_encrypt_config.name\ndns = ibm_sm_public_certificate_configuration_dns_cis.my_cis_dns_config.name\nrotation {\nauto_rotate = true\nrotate_keys = false\n}\n}\n\n\n\n\n\n\n\n Ordering public certificates with your own DNS provider in the UI \n\nTo create a public certificate by using a manual DNS provider in the UI, complete the following steps.\n\n\n\n1. In the console, click the Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/icons\/icon_hamburger.svg)> Resource List.\n2. From the list of services, select your instance of Secrets Manager.\n3. In the Secrets table, click Add.\n4. Click the Order public certificate tile.\n5. Add a name and description to easily identify your certificate.\n6. Select the\n\nsecret groupthat you want to assign to the secret.\n\nDon't have a secret group? In the Secret group field, you can click Create to provide a name and a description for a new group. Your secret is added to the new group automatically. For more information about secret groups, check out [Organizing your secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secret-groups).\n7. Optional: Add labels to help you to search for similar secrets in your instance.\n8. Optional: Add metadata to your secret or to a specific version of your secret.\n\n\n\n1. Upload a file or enter the metadata and the version metadata in JSON format.\n\n\n\n9. Click Next.\n10. Select a certificate authority configuration.\n\nThe configuration that you select determines the certificate authority to use for signing and issuing the certificate.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-public-certificates&interface=ui"},{"document_id":"ibmcld_12492-86346-87418","score":10.46124,"text":"\n\"issuing_certificates_urls_encoded\": true,\n\"key_bits\": 2048,\n\"key_type\": \"rsa\",\n\"locality\": [],\n\"max_path_length\": -1,\n\"max_ttl\": 157788000,\n\"organization\": [],\n\"other_sans\": [],\n\"ou\": [],\n\"permitted_dns_domains\": [],\n\"postal_code\": [],\n\"private_key_format\": \"der\",\n\"province\": [],\n\"status\": \"configured\",\n\"street_address\": [],\n\"ttl\": 157788000\n},\n\"name\": \"my-configured-root-ca\",\n\"type\": \"root_certificate_authority\"\n},\n\"wrap_info\": null,\n\"warnings\": null,\n\"auth\": null\n}\n\n\n\n\n\n\n\n Update a configuration \n\nUpdates the configuration of a secrets engine that serves as the backend for a specific type of secret. You can update the configuration for the following secret types: iam_credentials, private_cert, public_cert\n\n\n\n Example requests \n\nUpdate a DNS provider configuration for the public_cert secrets engine.\n\ncurl -X PUT 'https:\/\/https:\/\/{instance_id}.{region}.secrets-manager.appdomain.cloud\/v1\/ibmcloud\/public_cert\/config\/dns_providers' -H 'X-Vault-Token: {Vault-Token}' -H 'Content-Type: application\/json' -d'{\n\"name\": \"my-cis-instance\",\n\"type\": \"cis\",\n\"config\": {","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-api"},{"document_id":"ibmcld_13234-18581-20551","score":10.335535,"text":"\nFor more information read through the [Proxying DNS records and global load balancers](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-dns-conceptsdns-concepts-proxying-dns-records) topic.\n\n\n\n\n\n Alternative 1: Proxy, traffic flows through CIS \n\nThis first alternative creates a wildcard certificate for example.com and then proxies it in the IBM Cloud Internet Services (CIS) allowing you to take advantage of industry leading security, protection and performance capabilities.\n\nCurrently ordering certificates is by using Let's Encrypt, you may follow the topic [Supported certificate authorities](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-prepare-order-certificatesconnect-certificate-authority) for updates. Using Let's Encrypt requires an ACME account. Follow the steps outlined in the [Connecting third-party certificate authorities](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-add-certificate-authority&interface=ui) topic to create or register your account. In addition, you are required to add a DNS provider following the steps in the [Connecting DNS providers](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-add-dns-provider&interface=uiadd-dns-provider-ui) topic. For this tutorial, you must add CIS as your DNS provider.\n\nInitially HTTPS is configured from the user to Secrets Manager only.\n\n\n\n1. Order a certificate in Secrets Manager\n\n\n\n* Open the Secrets Manager service and select Secrets on the left.\n* Click Add and then TLS certificates.\n* Click on the Order a public certificate tile.\n* Complete the form:\n\n\n\n* Name - type a name you can remember.\n* Description - enter a description of your choice.\n* Under Certificate authority select your configured Let's Encrypt certificate authority engine.\n* Under Key algorithm, pick your preferred algorithm,\n* Bundle certificates - leave off\n* Automatic certificate rotation - leave off\n* Under DNS provider select your configured DNS provider instance","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-multi-region"},{"document_id":"ibmcld_16729-287024-288758","score":10.290708,"text":"\nActivity Tracker hosted event search,Container Registry,Secrets Manager,App ID,Cloudant,Key Protect,Log Analysis,Cloud Internet Services (CIS)\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Resource sharing across accounts](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-resource-sharing)Resource sharing across accounts\n\nThis tutorial walks you through different options on how to share cloud-based resources across accounts.\n\nVirtual Private Cloud (VPC) Log Analysis\n\n+6\n\nActivity Tracker hosted event search,Secrets Manager,App ID,Key Protect,Hyper Protect Crypto Services,Object Storage\n\n\n\n* 1 hour\n* 2023-05-05\n\n\n\n[Serverless web app and eventing for data retrieval and analytics](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-serverless-github-traffic-analytics)Serverless web app and eventing for data retrieval and analytics\n\nIn this tutorial, you create an application to automatically collect GitHub traffic statistics for repositories and provide the foundation for traffic analytics. GitHub only provides access to the traffic data for the last 14 days. If you want to analyze statistics over a longer period of time, you need to download and store that data yourself. In this tutorial, you deploy a serverless app in a IBM Cloud Code Engine project. The app manages the metadata for GitHub repositories and provides access to the statistics for data analytics. The traffic data is collected from GitHub either on-demand in the app or when triggered by Code Engine events, e.g., daily. The app discussed in this tutorial implements a multi-tenant-ready solution with the initial set of features supporting a single-tenant mode.\n\nCode Engine Db2 on Cloud\n\n+1\n\nApp ID\n\n\n\n* 1 hour\n* 2023-06-16","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"20c2cbd18c16c12c9c2bbead6aef1a21<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1213887-1215935","score":10.362027,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1216520-1218568","score":10.362027,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_04183-0-2205","score":10.267128,"text":"\n\n\n\n\n\n\n  Securing your data in CIS \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Internet Services, it is important to know exactly what data is stored and encrypted and how to delete any stored personal data.\n\n\n\n  How your data is stored and encrypted in CIS \n\nCIS interacts with Cloudflare services using a channel that is fully encrypted end-to-end using Transport Layer Security (TLS) 1.2. CIS does not store any customer data. Configuration data about your specific CIS configuration is encrypted in transit and at rest. CIS configuration data is deleted on your request through the UI, CLI, or API.\n\n\n\n\n\n  Protecting your sensitive data in CIS \n\nAll data related to CIS configuration is not considered sensitive data. The configuration data is encrypted at rest. No customer-managed keys are managed by the CIS offering. Therefore, neither Key Protect nor Hyper Protect Crypto Services are used.\n\n\n\n  Working with customer-managed keys for CIS \n\nNo customer-managed keys are managed by the CIS offering.\n\n\n\n\n\n\n\n  Deleting your data in CIS \n\nThe CIS configuration data is deleted on request through the UI, CLI or API.\n\n\n\n  Deleting CIS instances \n\nThe CIS data retention policy describes how long your data is stored after you delete the service. The data retention policy is included in the CIS service description, which you can find in [IBM Cloud Terms](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-terms). When a CIS instance is deleted by the UI, CLI, or API, the instance data is retained for seven days from deletion.\n\nBefore deleting an instance, all the domains in the instance must be removed.\n\nDeleting the CIS instance removes all data.\n\n\n\n\n\n  Restoring deleted data for CIS \n\nCIS can currently restore the deleted instance. After you delete an instance of CIS, you can restore the deleted service instance within the data retention period of seven days. After the seven-day period expires, the service instance is permanently deleted.\n\nTo view which service instances are available for restoration, use the ibmcloud resource reclamations command. To restore a deleted service instance, use the ibmcloud resource reclamation-restore command.\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-mng-data"},{"document_id":"ibmcld_04186-16084-17604","score":10.252817,"text":"\nFor a secured connection with HTTPS, you can either obtain a certificate from [Let's Encrypt](https:\/\/letsencrypt.org\/) as described in the following [IBM Cloud\u00ae blog](https:\/\/www.ibm.com\/cloud\/blog\/secure-apps-on-ibm-cloud-with-wildcard-certificates) or through [IBM Cloud Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-public-certificates&interface=ui).\n\n\n\n\n\n Increase performance and protect from Denial of Service attacks \n\nA distributed denial of service ([DDoS](https:\/\/en.wikipedia.org\/wiki\/Denial-of-service_attack)) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. CIS is equipped to protect your domain from DDoS.\n\n\n\n1. In the CIS dashboard, select Reliability > Global Load Balancer.\n2. Locate the GLB you created in the Load Balancers table.\n3. Enable the Security and Performance features in the Proxy column:\n\nZoom\n\n![CIS Proxy Toggle ON](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cb1eb27836421578019401fa7556779109430b29\/cis\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-proxy.png)\n\nCIS Proxy Toggle ON\n\n\n\nYour GLB is now protected. An immediate benefit is that the origin IP addresses of your clusters will be hidden from the clients. If CIS detects a threat for an upcoming request, the user may see a screen like this one before being redirected to your application:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cis"},{"document_id":"ibmcld_04179-1360-3455","score":10.225203,"text":"\nAny records that cannot be proxied through CIS, and that still use your origin IP, such as FTP, can be secured by creating additional obfuscation. In particular, if you require a record for your origin that cannot be proxied by CIS, use a non-standard name. For example, instead of ftp.example.com use [random word or-random characters].example.com. This obfuscation makes dictionary scans of your DNS records less likely to expose your origin IP addresses.\n\n\n\n\n\n Use separate IP ranges for HTTP and non-HTTP traffic if possible \n\nSome customers use separate IP ranges for HTTP and non-HTTP traffic, thereby allowing them to proxy all records pointing to their HTTP IP range, and to obscure all non-HTTP traffic with a different IP subnet.\n\n\n\n\n\n\n\n Best practice 2: Configure your security level selectively \n\nYour Security Level establishes the sensitivity of our IP Reputation Database. To prevent negative interactions or false positives, configure your Security Level by domain to heighten security where necessary, and to decrease it where appropriate.\n\n\n\n Increase the security level for sensitive areas to 'High' \n\nYou can increase this setting from the Advanced Security page for your domain or by adding a Page Rule for administration pages or login pages, to reduce brute-force attempts:\n\n\n\n1. Create a Page Rule with the URL pattern of your API (for example, www.example.com\/wp-login).\n2. Identify the Security Level setting.\n3. Mark the setting as High.\n4. Select Provision Resource.\n\n\n\n\n\n\n\n Decrease the security level for non-sensitive paths or APIs to reduce false positives \n\nThis setting can be decreased for general pages and API traffic:\n\n\n\n1. Create a Page Rule with the URL pattern of your API (for example, www.example.com\/api\/).\n2. Identify the Security Level setting.\n3. Turn Security Level to Low or Essentially off.\n4. Select Provision Resource.\n\n\n\n\n\n\n\n What do security level settings mean? \n\nOur security level settings are aligned with threat scores that certain IP addresses acquire from malicious behavior on our network. A threat score above 10 is considered high.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-manage-your-ibm-cis-for-optimal-security"},{"document_id":"ibmcld_04107-1440-3475","score":10.150687,"text":"\nManage the certificates used to secure traffic to your site.\n\n\n\n\n\n Origin \n\nManage the TLS certificates that encrypt traffic between your origin server and your users.\n\n\n\n\n\n Rate limiting \n\nUse rate limiting rules to protect your site or API from malicious traffic by blocking client IP addresses that match a URL pattern or exceed a defined threshold.\n\n\n\n\n\n Traffic scrubbing \n\nCIS offers 192 Tbps of global network edge capacity and can mitigate DDoS attacks that have extremely high packet and HTTP request rates.\n\nWhen a DDoS attack occurs, CIS doesn't use scrubbing centers; the activity is analyzed on the edge, which helps to mitigate DDoS attacks closest to the source.\n\nTraffic that is identified as being \"dirty\" or part of an attack is not included in the billing. Customers are being billed for protected traffic, which consists of clean traffic that is forwarded to the origin and responses that are returned from the edge to the client.\n\n\n\n\n\n Web Application Firewall (WAF) \n\nWAF is implemented through two rule sets: [OWASP](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-settingsowasp-rule-set-for-waf) and [CIS](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-waf-settingscis-ruleset-for-waf).\n\n\n\n\n\n IP firewall \n\nIBM Cloud Internet Services offers several tools for controlling your traffic so that you protect your domains, URLs, and directories against volumes of traffic, certain groups of requesters, and particular requesting IPs.\n\n\n\n IP rules \n\nWith IP rules you can control access for specific IP addresses, IP ranges, specific countries, specific ASNs, and certain CIDR blocks. Available actions on incoming requests are:\n\n\n\n* Allowlist\n* Block\n* Challenge (Captcha)\n* JavaScript challenge (Defense mode)\n\n\n\nFor example, if you notice that a particular IP is causing malicious requests, you can block that user by IP address.\n\nIP rules apply to TCP, HTTP, and HTTPS [Range](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-range) apps, because IP rules are applied to Open System Interconnection (OSI) Layer 3 and Layer 4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-about-ibm-cloud-internet-services-cis"},{"document_id":"ibmcld_01391-16119-17644","score":10.131409,"text":"\nFor a secured connection with HTTPS, you can either obtain a certificate from [Let's Encrypt](https:\/\/letsencrypt.org\/) as described in the following [IBM Cloud\u00ae blog](https:\/\/www.ibm.com\/cloud\/blog\/secure-apps-on-ibm-cloud-with-wildcard-certificates) or through [IBM Cloud Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-public-certificates&interface=ui).\n\n\n\n\n\n Increase performance and protect from Denial of Service attacks \n\nA distributed denial of service ([DDoS](https:\/\/en.wikipedia.org\/wiki\/Denial-of-service_attack)) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. CIS is equipped to protect your domain from DDoS.\n\n\n\n1. In the CIS dashboard, select Reliability > Global Load Balancer.\n2. Locate the GLB you created in the Load Balancers table.\n3. Enable the Security and Performance features in the Proxy column:\n\nZoom\n\n![CIS Proxy Toggle ON](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cbb80bf851fb762a838129cba09d5674f8bfffda\/Registry\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/cis-proxy.png)\n\nCIS Proxy Toggle ON\n\n\n\nYour GLB is now protected. An immediate benefit is that the origin IP addresses of your clusters will be hidden from the clients. If CIS detects a threat for an upcoming request, the user may see a screen like this one before being redirected to your application:\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"},{"document_id":"ibmcld_16727-1209239-1211244","score":10.085779,"text":"\nFor more examples of personal data, see section 2.2 of the [NIST Special Publication 800-122](https:\/\/www.nist.gov\/publications\/guide-protecting-confidentiality-personally-identifiable-information-pii).\n* Can encryption keys that are created in one region be used in another region?\n\nYour encryption keys can be used to encrypt data stores located anywhere within IBM Cloud.\n* How do I control who has access to keys?\n\nKey Protect supports a centralized access control system, governed by IBM Cloud\u00ae Identity and Access Management, to help you manage users and access for your encryption keys and allow the principle of least privilege. If you are a security admin for your service, you can assign [IBM Cloud IAM roles that correspond to the specific Key Protect permissions](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-accessmanage-access-roles) you want to grant to members of your team.\n\nOne way this is possible is by grouping keys into \"key rings\", allowing an account owner to assign access to a particular group of keys to a particular group of users. For more information, check out [Grouping keys together using key rings](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys).\n* What are differences between the Reader and ReaderPlus roles?\n\nBoth the Reader and ReaderPlus roles help you assign read-only access to Key Protect resources.\n\n\n\n* As a Reader, you can browse a high-level view of keys and perform wrap and unwrap actions. Readers cannot access or modify key material.\n* As a ReaderPlus, you can browse a high-level view of keys, access key material for standard keys, and perform wrap and unwrap actions. The ReaderPlus role cannot modify key material.\n\n\n\n* How do I monitor API calls to Key Protect?\n\nYou can use the IBM Cloud Activity Tracker service to track how users and applications interact with your Key Protect instance. For example, when you create, import, delete, or read a key in Key Protect, an Activity Tracker event is generated.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1206606-1208611","score":10.085779,"text":"\nFor more examples of personal data, see section 2.2 of the [NIST Special Publication 800-122](https:\/\/www.nist.gov\/publications\/guide-protecting-confidentiality-personally-identifiable-information-pii).\n* Can encryption keys that are created in one region be used in another region?\n\nYour encryption keys can be used to encrypt data stores located anywhere within IBM Cloud.\n* How do I control who has access to keys?\n\nKey Protect supports a centralized access control system, governed by IBM Cloud\u00ae Identity and Access Management, to help you manage users and access for your encryption keys and allow the principle of least privilege. If you are a security admin for your service, you can assign [IBM Cloud IAM roles that correspond to the specific Key Protect permissions](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-manage-accessmanage-access-roles) you want to grant to members of your team.\n\nOne way this is possible is by grouping keys into \"key rings\", allowing an account owner to assign access to a particular group of keys to a particular group of users. For more information, check out [Grouping keys together using key rings](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-grouping-keys).\n* What are differences between the Reader and ReaderPlus roles?\n\nBoth the Reader and ReaderPlus roles help you assign read-only access to Key Protect resources.\n\n\n\n* As a Reader, you can browse a high-level view of keys and perform wrap and unwrap actions. Readers cannot access or modify key material.\n* As a ReaderPlus, you can browse a high-level view of keys, access key material for standard keys, and perform wrap and unwrap actions. The ReaderPlus role cannot modify key material.\n\n\n\n* How do I monitor API calls to Key Protect?\n\nYou can use the IBM Cloud Activity Tracker service to track how users and applications interact with your Key Protect instance. For example, when you create, import, delete, or read a key in Key Protect, an Activity Tracker event is generated.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_07882-1678-3175","score":9.942151,"text":"\n* Check whether Hyper Protect DBaaS for PostgreSQL is enabled with customer-managed encryption and Keep Your Own Key (KYOK)\n* Check whether Cloud Object Storage is enabled with customer-managed encryption and Keep Your Own Key (KYOK)\n* Check whether Virtual Servers for VPC data volumes are enabled with customer-managed encryption and Keep Your Own Key (KYOK)\n* Check whether data disks are encrypted with customer-managed keys\n\n\n\n\n\n\n\n NIST supplemental guidance \n\nThis control addresses the confidentiality and integrity of information at rest and covers user information and system information. Information at rest refers to the state of information when it is located on storage devices as specific components of information systems. System-related information requiring protection includes, for example, configurations or rule sets for firewalls, gateways, intrusion detection\/prevention systems, filtering routers, and authenticator content. Organizations may employ different mechanisms to achieve confidentiality and integrity protections, including the use of cryptographic mechanisms and file share scanning. Integrity protection can be achieved, for example, by implementing Write-Once-Read-Many (WORM) technologies. Organizations may also employ other security controls including, for example, secure off-line storage in lieu of online storage when adequate protection of information at rest cannot otherwise be achieved and\/or continuous monitoring to identify malicious code at rest.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-sc-28"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":16.30581,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":15.987445,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":13.297241,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":13.297241,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01415-6473-8616","score":13.224798,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_09410-1574-3779","score":13.047048,"text":"\n* IBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM.\n* The IBM Cloud Container Registry includes Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\n\n\nTo get details about the logging agent images, see [Getting information about logging agent images](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent_image).\n\n\n\n Resource Limits for agents deployed on Kubernetes \n\nThe agent is deployed as a Kubernetes DaemonSet, creating one pod for each node selected. The agent collects logs of all the pods in the node. The resource requirements of the agent are in direct relation to the number of pods for each node and the amount of logs produced for each pod.\n\nThe agent requires at least 128 MB and no more than 512 MB of memory. It requires at least twenty millicpu (20m).\n\nDifferent features can also increase resource utilization. When line exclusion, inclusion or redaction rules are specified, you can expect additional CPU consumption for each line and regex rule defined. When Kubernetes event logging is enabled (disabled by default), additional CPU usage will occur on the oldest agent pod.\n\nPlacing traffic shaping or CPU limits on the agent is not recommended to ensure data can be sent to the log ingestion service.\n\n\n\n\n\n Understanding image tags \n\nThe tag that is associated to a logging image indicates whether the logging agent is automatically updated.\n\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_01535-1902-3811","score":12.969507,"text":"\nFor more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages) or [configuration issue](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-1902-3785","score":12.940059,"text":"\nFor more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nThe following functions are available in version 3:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides recommendations to secure configuration files for a subset of application types.\n* Provides instructions about how to fix a reported [vulnerable package](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexpackages) or [configuration issue](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexapp_configurations) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_06063-53153-55320","score":12.903874,"text":"\nImage Vulnerability Scanner: By default, Vulnerability Advisor scans images that are stored in IBM Cloud Container Registry to find potential security vulnerabilities. For more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n4. IBM Cloud Security and Compliance Center: When you enable IBM Cloud Security and Compliance Center, you can view reports about suspicious incoming and outgoing network traffic. For more information, see [What is IBM Cloud Security and Compliance Center?](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n5. IBM Cloud\u00ae Secrets Manager: You can store your Ingress and Kubernetes secrets in IBM Cloud\u00ae Secrets Manager. When you integrate Secrets Manager into your cluster, you set a default Secrets Manager instance where all Ingress subdomain secrets are uploaded. For more information, see [Setting up Secrets Manager in your Kubernetes Service cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-secrets-mgr).\n\n\n\n\n\n\n\n Image and registry \n\nEvery deployment is based on an image that holds the instructions for how to spin up the container that runs your app. These instructions include the operating system inside the container and extra software that you want to install. To protect your app, you must protect the image and establish checks to ensure the image's integrity.\n\nShould I use a public or a private registry to store my images?\n: Public registries, such as Docker Hub, can be used to get started with Docker images and Kubernetes to create your first containerized app in a cluster. But when it comes to enterprise applications, avoid registries that you don't know or don't trust to protect your cluster from malicious images. Keep your images in a private registry, like the one provided in IBM Cloud Container Registry and make sure to control access to the registry and the image content that can be pushed.\n\nWhy is it important to check images against vulnerabilities?\n: Research shows that most malicious attacks leverage known software vulnerabilities and weak system configurations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_01535-4-2366","score":12.753336,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"}],"retriever_scores":{"recall_1":0.5,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":13.322069,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":13.048506,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":10.766723,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":10.766723,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_09410-1574-3779","score":10.676073,"text":"\n* IBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM.\n* The IBM Cloud Container Registry includes Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\n\n\nTo get details about the logging agent images, see [Getting information about logging agent images](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent_image).\n\n\n\n Resource Limits for agents deployed on Kubernetes \n\nThe agent is deployed as a Kubernetes DaemonSet, creating one pod for each node selected. The agent collects logs of all the pods in the node. The resource requirements of the agent are in direct relation to the number of pods for each node and the amount of logs produced for each pod.\n\nThe agent requires at least 128 MB and no more than 512 MB of memory. It requires at least twenty millicpu (20m).\n\nDifferent features can also increase resource utilization. When line exclusion, inclusion or redaction rules are specified, you can expect additional CPU consumption for each line and regex rule defined. When Kubernetes event logging is enabled (disabled by default), additional CPU usage will occur on the oldest agent pod.\n\nPlacing traffic shaping or CPU limits on the agent is not recommended to ensure data can be sent to the log ingestion service.\n\n\n\n\n\n Understanding image tags \n\nThe tag that is associated to a logging image indicates whether the logging agent is automatically updated.\n\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_01535-4-2366","score":10.476435,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-4-2366","score":10.476435,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01415-6473-8616","score":10.246789,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_01447-1492-3786","score":10.229417,"text":"\nVulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nReview the following table to find an overview of benefits of using Container Registry.\n\n\n\nTable 1. Container Registry benefits\n\n Benefit Description \n\n Highly available and scalable private registry. Set up your own image namespace in a multi-tenant, highly available, scalable, encrypted private registry that is hosted and managed by IBM.<br><br>Store your private Docker images and share them with users in your IBM Cloud account. \n Image security compliance with Vulnerability Advisor. Benefit from automatic scanning of images in your namespace.<br><br>Review recommendations that are specific to the operating system to fix potential vulnerabilities and protect your containers from being compromised. \n Quota limits for storage and pull traffic. Benefit from free storage and pull traffic to your private images until you reach your free quota.<br><br>Set custom quota limits for the amount of storage and pull traffic per month to avoid exceeding your preferred payment level. \n\n\n\n\n\n Service plans \n\nYou can choose between the free or standard Container Registry service plans to store your Docker images and make these images available to users in your IBM Cloud account.\n\nThe IBM Cloud Container Registry service plan determines the amount of storage and pull traffic that you can use for your private images. The service plan is associated with your IBM Cloud account, and limits for storage and image pull traffic apply to all namespaces that you set up in your account.\n\nService plans are scoped to the specific registry instance (one of the regional registries or the global registry) that you're currently working with. Plan settings must all be managed separately for your account in each registry instance. For more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\nThe following table shows available IBM Cloud Container Registry service plans and their characteristics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"},{"document_id":"ibmcld_00879-2782-4388","score":10.147159,"text":"\nvulnerabilityadvisor Vulnerability Advisor results from IBM Vulnerability Advisor on Cloud \n\n\n\nTest records must provide data in one of the following supported formats:\n\n\n\nTable 2. Supported formats\n\n Test Type Supported Formats \n\n Unit test Mocha, xUnit, Karma\/Mocha \n Functional verification test Mocha, xUnit, Karma\/Mocha \n Code coverage Cobertura, lcov, JaCoCo \n SonarQube Scan data that is provided by SonarQube scans \n Static AppScan Static App Scans that are provided by IBM Application Security on Cloud \n Dynamic AppScan Dynamic App Scans that are provided by IBM Application Security on Cloud \n Vulnerability Advisor Results Vulnerability Advisor results from IBM Vulnerability Advisor on Cloud \n\n\n\n\n\n\n\n Viewing test results \n\nWhen your pipeline runs, it publishes the test result data to DevOps Insights. You can view the test result data on the Quality Dashboard page.\n\n\n\n1. From the IBM Cloud console, click the menu icon ![hamburger icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/icon_hamburger.svg), and select Resource List.\n2. Select your toolchain.\n3. From your toolchain's Overview page, on the IBM Cloud tools card, click DevOps Insights.\n4. Click Quality Dashboard in the navigation to open the page.\n\n\n\nFor more information about the Quality Dashboard page, see [DevOps data aggregation](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-devops-data-aggregation).\n\n\n\n\n\n Next steps \n\n[Evaluate gates](https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-evaluate-gates-cli).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-publish-test-cli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.4,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.2338647045}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01329-14955-16723","score":11.072905,"text":"\nIf you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr image-digests [--format FORMAT | --quiet | -q | --json] [--restrict RESTRICTION] [--include-ibm] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository@digest\n\n--json\n: (Optional) Outputs the list in JSON format.\n\n--restrict RESTRICTION\n: (Optional) Limit the output to display only images in the specified namespace or repository.\n\n--include-ibm\n: (Optional) Includes IBM-provided public images in the output. By default only private images are listed. You can view IBM-provided images in the global registry only.\n\n--no-va\n: (Optional) Excludes the security status (Vulnerability Advisor) results from the output.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01471-5654-7396","score":10.979286,"text":"\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4 to run the ibmcloud cr va, ibmcloud cr image-list, or ibmcloud cr image-digests commands, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nFor more information about Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout). For more information about Vulnerability Advisor API 4, see [Vulnerability Advisor 4 for IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/apidocs\/container-registry\/va-v4).\n\nNew commands for setting and checking the Vulnerability Advisor version are available from Container Registry plug-in 1.0.0\n: From Container Registry plug-in 1.0.0, you can use new commands to check and set Vulnerability Advisor versions.\n\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4, you can set the version by running the [ibmcloud cr va-version-set](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version_set) command.\n\nFor more information about setting the version by using the ibmcloud cr va-version-set command, see [ibmcloud cr va-version-set](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version_set) and [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nTo find out which version of Vulnerability Advisor that you're running, see [ibmcloud cr va-version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcliic_cr_va_version).\n\n\n\n\n\n 3 August 2022","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"},{"document_id":"ibmcld_01533-8109-9900","score":10.96828,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-8161-9952","score":10.96828,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":10.771507,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":10.771507,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01329-59746-61590","score":10.755478,"text":"\nFor more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.\n\nFor information about supported Docker base images, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\nFor more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui).\n\n--extended, -e\n: (Optional) The command output shows additional information about fixes for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01535-4-2366","score":10.692587,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-4-2366","score":10.692587,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01533-10805-12534","score":10.597231,"text":"\nRed Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support. [Ubuntu CVE Tracker](https:\/\/launchpad.net\/ubuntu-cve-tracker). \n\n\n\n\n\n\n\n Configuration issues - version 3 only \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nConfiguration issues are potential security issues that are related to how an\n\nappis set up. Configuration issues are not supported in version 4.\n\nMany of the reported problems can be fixed by updating your\n\nDockerfile.\n\nImages are scanned only if they are using an operating system that is supported by Vulnerability Advisor. Vulnerability Advisor checks the configuration settings for the following types of apps:\n\n\n\n* MySQL\n* NGINX\n* Apache\n\n\n\n\n\n\n\n\n\n Setting the Vulnerability Advisor version \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nStarting from version 1.0.0 of the Container Registry plug-in, you can choose whether to fetch results from either version 3, v3 (the default), or version 4, v4, of Vulnerability Advisor for the following commands:\n\n\n\n* [ibmcloud cr va IMAGE](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_va), where IMAGE is the name of the image.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01329-14955-16723","score":12.246404,"text":"\nIf you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr image-digests [--format FORMAT | --quiet | -q | --json] [--restrict RESTRICTION] [--include-ibm] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository@digest\n\n--json\n: (Optional) Outputs the list in JSON format.\n\n--restrict RESTRICTION\n: (Optional) Limit the output to display only images in the specified namespace or repository.\n\n--include-ibm\n: (Optional) Includes IBM-provided public images in the output. By default only private images are listed. You can view IBM-provided images in the global registry only.\n\n--no-va\n: (Optional) Excludes the security status (Vulnerability Advisor) results from the output.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01533-8109-9900","score":12.050478,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-8161-9952","score":12.050478,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01329-59746-61590","score":11.9462185,"text":"\nFor more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.\n\nFor information about supported Docker base images, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\nFor more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui).\n\n--extended, -e\n: (Optional) The command output shows additional information about fixes for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01410-2747-3497","score":11.92184,"text":"\nVersion 1.0.0 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability Advisor v4 is now available, see [Vulnerability Advisor 4 is available from Container Registry plug-in 1.0.0](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes15sep2022_va_version_4).\n* Image and digest list output no longer includes security status by default. You can either add the --va argument to include security status for all the listed images, or you can use the ibmcloud cr va command to query security status for an individual image.\n\n\n\n\n\n\n\n Version 0.1.582 \n\nVersion 0.1.582 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_change_log"},{"document_id":"ibmcld_04340-57846-59619","score":11.862384,"text":"\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-containerregcli"},{"document_id":"ibmcld_07578-368912-370964","score":11.758438,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands \n\nOn Red Hat\u00ae OpenShift\u00ae and CentOS, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-368886-370938","score":11.758438,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands \n\nOn Red Hat\u00ae OpenShift\u00ae and CentOS, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01442-1679-3832","score":11.613865,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01415-7932-9985","score":11.547054,"text":"\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\n\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6934264036,"ndcg_cut_5":0.6934264036,"ndcg_cut_10":0.6934264036}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-8109-9900","score":13.733704,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-8161-9952","score":13.733704,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_07578-368912-370964","score":13.236538,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands \n\nOn Red Hat\u00ae OpenShift\u00ae and CentOS, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-368886-370938","score":13.236538,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands \n\nOn Red Hat\u00ae OpenShift\u00ae and CentOS, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\nrpm -qi <package_name>\n\nyum info <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\nrpm -qa\n\nyum list installed\n\n\n\n\n\n* Does Vulnerability Advisor have versions?\n\n Does Vulnerability Advisor have versions? \n\nVulnerability Advisor is available in two versions, version 3 and version 4.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01410-2747-3497","score":12.954887,"text":"\nVersion 1.0.0 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability Advisor v4 is now available, see [Vulnerability Advisor 4 is available from Container Registry plug-in 1.0.0](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes15sep2022_va_version_4).\n* Image and digest list output no longer includes security status by default. You can either add the --va argument to include security status for all the listed images, or you can use the ibmcloud cr va command to query security status for an individual image.\n\n\n\n\n\n\n\n Version 0.1.582 \n\nVersion 0.1.582 of the CLI was released on 15 September 2022.\n\nThis release has the following changes:\n\n\n\n* Vulnerability remediations.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_change_log"},{"document_id":"ibmcld_01329-14955-16723","score":12.896781,"text":"\nIf you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr image-digests [--format FORMAT | --quiet | -q | --json] [--restrict RESTRICTION] [--include-ibm] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository@digest\n\n--json\n: (Optional) Outputs the list in JSON format.\n\n--restrict RESTRICTION\n: (Optional) Limit the output to display only images in the specified namespace or repository.\n\n--include-ibm\n: (Optional) Includes IBM-provided public images in the output. By default only private images are listed. You can view IBM-provided images in the global registry only.\n\n--no-va\n: (Optional) Excludes the security status (Vulnerability Advisor) results from the output.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01442-1679-3832","score":12.867838,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_01441-1679-3819","score":12.76962,"text":"\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_04340-57846-59619","score":12.698681,"text":"\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-containerregcli"},{"document_id":"ibmcld_01329-58331-60199","score":12.61984,"text":"\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01533-4546-6910","score":17.545366,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-4585-6962","score":17.321299,"text":"\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-6329-8623","score":14.972721,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01535-6381-8675","score":14.972721,"text":"\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01535-4-2366","score":14.676453,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-4-2366","score":14.676453,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01415-6473-8616","score":14.590851,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_07578-367408-369576","score":14.546666,"text":"\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-367382-369550","score":14.546666,"text":"\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01533-8109-9900","score":14.348502,"text":"\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https:\/\/gitlab.alpinelinux.org\/) and [CVE](https:\/\/cve.mitre.org\/data\/downloads\/index.html). \n CentOS Version 7 [CentOS announce archives](https:\/\/lists.centos.org\/pipermail\/centos-announce\/) and [CentOS CR announce archives](https:\/\/lists.centos.org\/pipermail\/centos-cr-announce\/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https:\/\/lists.debian.org\/debian-security-announce\/) and [Debian LTS Security Information](https:\/\/www.debian.org\/lts\/security\/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https:\/\/github.com\/GoogleContainerTools\/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL\/UBI 7, RHEL\/UBI 8, and RHEL\/UBI 9 [Red Hat Security Data API](https:\/\/access.redhat.com\/labsinfo\/securitydataapi). \n Ubuntu All stable versions with vendor security support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01447-1492-3786","score":18.284086,"text":"\nVulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nReview the following table to find an overview of benefits of using Container Registry.\n\n\n\nTable 1. Container Registry benefits\n\n Benefit Description \n\n Highly available and scalable private registry. Set up your own image namespace in a multi-tenant, highly available, scalable, encrypted private registry that is hosted and managed by IBM.<br><br>Store your private Docker images and share them with users in your IBM Cloud account. \n Image security compliance with Vulnerability Advisor. Benefit from automatic scanning of images in your namespace.<br><br>Review recommendations that are specific to the operating system to fix potential vulnerabilities and protect your containers from being compromised. \n Quota limits for storage and pull traffic. Benefit from free storage and pull traffic to your private images until you reach your free quota.<br><br>Set custom quota limits for the amount of storage and pull traffic per month to avoid exceeding your preferred payment level. \n\n\n\n\n\n Service plans \n\nYou can choose between the free or standard Container Registry service plans to store your Docker images and make these images available to users in your IBM Cloud account.\n\nThe IBM Cloud Container Registry service plan determines the amount of storage and pull traffic that you can use for your private images. The service plan is associated with your IBM Cloud account, and limits for storage and image pull traffic apply to all namespaces that you set up in your account.\n\nService plans are scoped to the specific registry instance (one of the regional registries or the global registry) that you're currently working with. Plan settings must all be managed separately for your account in each registry instance. For more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\nThe following table shows available IBM Cloud Container Registry service plans and their characteristics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"},{"document_id":"ibmcld_01471-7-1919","score":18.232113,"text":"\nRelease notes for Container Registry \n\nLearn about the changes to IBM Cloud\u00ae Container Registry and Vulnerability Advisor. The changes are grouped by date.\n\n\n\n 19 June 2023 \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023\n: For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\n\n\n 19 May 2023 \n\nUpdate Vulnerability Advisor to version 4 by 19 June 2023\n: The Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\nFor more information, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4).\n\n\n\n\n\n 26 April 2023 \n\nUsing Portieris to block the deployment of images with issues is deprecated.\n: The use of Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n\n\n 11 November 2022 \n\nChange to virtual private endpoints\n: Virtual private endpoints are changing.\n\nOn 11 November 2022, virtual private endpoints (VPEs) for IBM Cloud Container Registry are being updated and the existing VPE version is being deprecated on 15 December 2022. If you use Container Registry VPE gateways, you must create new VPE gateways and remove your VPE gateways that were created before 11 November 2022 at the earliest opportunity so that you pick up these changes. VPE gateways that were created before 11 November 2022 are deprecated and will not work after 15 December 2022.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"},{"document_id":"ibmcld_01415-7932-9985","score":18.214996,"text":"\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\n\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run the following command:\n\napk info <package_name>\n* To list all installed packages and their versions, run the following command:\n\napk list\n\n\n\n\n\n\n\n Debian and Ubuntu package manager commands \n\nOn Debian and Ubuntu, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.\n\n\n\n* To list the metadata for a specific installed package, run either of the following commands:\n\napt show <package_name>\n\ndpkg-query -l <package_name>\n* To list all installed packages and their versions, run either of the following commands:\n\napt list\n\ndpkg-query -W\n\n\n\n\n\n\n\n Red Hat and CentOS package manager commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_01535-4-2366","score":18.2034,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui"},{"document_id":"ibmcld_01533-4-2366","score":18.2034,"text":"\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index"},{"document_id":"ibmcld_01415-6473-8616","score":18.070705,"text":"\nFor more information, see [Billing for storage and pull traffic](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_faq&interface=ui"},{"document_id":"ibmcld_09410-1574-3779","score":17.861664,"text":"\n* IBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM.\n* The IBM Cloud Container Registry includes Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\n\n\nTo get details about the logging agent images, see [Getting information about logging agent images](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent_image).\n\n\n\n Resource Limits for agents deployed on Kubernetes \n\nThe agent is deployed as a Kubernetes DaemonSet, creating one pod for each node selected. The agent collects logs of all the pods in the node. The resource requirements of the agent are in direct relation to the number of pods for each node and the amount of logs produced for each pod.\n\nThe agent requires at least 128 MB and no more than 512 MB of memory. It requires at least twenty millicpu (20m).\n\nDifferent features can also increase resource utilization. When line exclusion, inclusion or redaction rules are specified, you can expect additional CPU consumption for each line and regex rule defined. When Kubernetes event logging is enabled (disabled by default), additional CPU usage will occur on the oldest agent pod.\n\nPlacing traffic shaping or CPU limits on the agent is not recommended to ensure data can be sent to the log ingestion service.\n\n\n\n\n\n Understanding image tags \n\nThe tag that is associated to a logging image indicates whether the logging agent is automatically updated.\n\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"},{"document_id":"ibmcld_07578-367408-369576","score":17.821354,"text":"\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-367382-369550","score":17.821354,"text":"\nIf this issue persists, contact support for help;\nsee https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-help-and-support).\n* How often are the security notices updated?\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n* Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3?\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n* Which version of a package is installed in my image?\n\n Which version of a package is installed in my image? \n\nTo determine the version of a package that is installed in your image, use the relevant package manager command for your operating system.\n\n\n\n Alpine package manager commands \n\nOn Alpine, to determine the version of a package that is installed in your image, you can use the following commands, where <package_name> is the name of your package.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_01471-4315-5983","score":17.669273,"text":"\nTo include security status, you can either add the --va option to the command, or use the [ibmcloud cr va](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_va) command to query the security status for an individual image.\n\nFor more information, see [Container Registry CLI stops returning security status results in lists by default from version 1.0.0](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_lists).\n\nAll releases of Container Registry plug-in 0.1 are deprecated\n: All releases of version 0.1 of the Container Registry CLI plug-in are deprecated. You can continue to use releases of version 0.1, but version 1.0.0 is available for you to use. Version 0.1 will continue to be updated with any required updates until 15 September 2023. To update the version of your CLI plug-in, see [Updating the container-registry CLI plug-in](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespace&interface=uiregistry_cli_update).\n\nVulnerability Advisor 4 is available from Container Registry plug-in 1.0.0\n: From Container Registry plug-in 1.0.0, you can choose whether to use Vulnerability Advisor version 3 or version 4 to run your commands. Vulnerability Advisor 4 is available from version 1.0.0 of the Container Registry plug-in. Vulnerability Advisor 3 is the default.\n\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4 to run the ibmcloud cr va, ibmcloud cr image-list, or ibmcloud cr image-digests commands, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16729-71418-73421","score":20.08504,"text":"\nIBM Cloud\u00ae Container Registry provides a multi-tenant private image registry that you can use to store and share your container images with users in your IBM Cloud account.\n\nKubernetes service Container Registry\n\n\n\n* 45 minutes\n* 2023-06-02\n\n\n\n[Encrypting images for content confidentiality](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_encrypt)Encrypting images for content confidentiality\n\nYou can protect the confidentiality of your IBM Cloud\u00ae Container Registry images, and ensure that hosts that aren't trusted can't run the images.\n\nKey Protect Container Registry\n\n\n\n* 2 hours\n* 2023-01-25\n\n\n\n[Granting access to Container Registry resources tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iam_access)Granting access to Container Registry resources tutorial\n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nContainer Registry\n\n\n\n* 45 minutes\n* 2023-01-31\n\n\n\n[Container Registry and Vulnerability Advisor workflow tutorial](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflow)Container Registry and Vulnerability Advisor workflow tutorial\n\nUse this tutorial to find out about the basic functions of both IBM Cloud\u00ae Container Registry and Vulnerability Advisor.\n\nKubernetes service Container Registry\n\n\n\n* 2 hours\n* 2023-06-19\n\n\n\n[Onboarding a Certified Operator from a Red Hat registry](https:\/\/cloud.ibm.com\/docs\/account?topic=account-catalog-opbundle-tutorial)Onboarding a Certified Operator from a Red Hat registry\n\nThis tutorial walks you through how to onboard a sample Operator bundle from a Red Hat\u00ae registry to your account. By completing this tutorial, you learn how to create a private catalog in your account, import the Operator bundle, and validate that it can be installed on a Red Hat OpenShift on IBM Cloud cluster.\n\nContainer Registry Managing your account, resources, and access\n\n\n\n* 45 minutes\n* 2022-10-26","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_01329-59746-61590","score":20.032316,"text":"\nFor more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.\n\nFor information about supported Docker base images, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\nFor more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui).\n\n--extended, -e\n: (Optional) The command output shows additional information about fixes for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01329-14955-16723","score":19.355692,"text":"\nIf you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr image-digests [--format FORMAT | --quiet | -q | --json] [--restrict RESTRICTION] [--include-ibm] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository@digest\n\n--json\n: (Optional) Outputs the list in JSON format.\n\n--restrict RESTRICTION\n: (Optional) Limit the output to display only images in the specified namespace or repository.\n\n--include-ibm\n: (Optional) Includes IBM-provided public images in the output. By default only private images are listed. You can view IBM-provided images in the global registry only.\n\n--no-va\n: (Optional) Excludes the security status (Vulnerability Advisor) results from the output.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01488-7-2011","score":19.313513,"text":"\nContainer Registry and Vulnerability Advisor workflow tutorial \n\nUse this tutorial to find out about the basic functions of both IBM Cloud\u00ae Container Registry and Vulnerability Advisor.\n\nThese two services are pre-integrated and work together seamlessly in IBM Cloud, and their features provide a robust but straightforward workflow for users of containers. You can use these services to store your container images, ensure the security of your images and Kubernetes clusters, control the images that you can use to deploy to your clusters, and more.\n\nMuch of the information that is provided in this tutorial is available in greater detail in the \"How To\" sections of the documentation. This tutorial combines all those tasks into a workflow that helps you to use IBM Cloud Container Registry and Vulnerability Advisor. To learn more about each task, click the relevant link.\n\n\n\n Objectives \n\nThe tutorial has the following objectives.\n\n\n\n* Understand the core features of IBM Cloud Container Registry and Vulnerability Advisor.\n* Use the functions of these services to create a workflow.\n\n\n\n\n\n\n\n Services used \n\nThis tutorial uses the following IBM Cloud services:\n\n\n\n* [IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/registry\/repos)\n* [IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/kubernetes\/catalog\/about)\n\n\n\n\n\n\n\n Before you begin \n\nBefore you begin, complete the following tasks:\n\n\n\n* [Install Git](https:\/\/git-scm.com\/).\n* [Install IBM Cloud Developer Tools](https:\/\/github.com\/IBM-Cloud\/ibm-cloud-developer-tools), a script to install docker, kubectl, helm, ibmcloud CLI, and required plug-ins by following the instructions in the README.md file in the repository.\n* [Create a cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusters).\n* Ensure that you have the correct access permissions for adding and removing\n\nnamespaces, see [Access roles for configuring IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_configure).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflow"},{"document_id":"ibmcld_01471-23854-25589","score":19.305798,"text":"\n: If you want to manage your Vulnerability Advisor exemption policies for security issues, depending on the task that you want to complete, you might have to update your access role.\n\nFor more information, see [Access roles for configuring Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n 29 July 2020 \n\nYou can set permissions so that access to resources within a namespace can be configured at the resource group level\n: Namespaces are created in resource groups so that access to resources within a namespace can be configured at the resource group level. If a namespace isn't already in a resource group, you can assign the namespace to a resource group.\n\n\n\n* Namespaces created in version 0.1.485 of the Container Registry CLI or later, or in the IBM Cloud console on or after 29 July 2020, are created in a resource group that you specify so that you can configure access to resources within the namespace at the [resource group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rgs) level. However, you can still set permissions for the namespace at the account level or in the namespace itself. For more information, see [Set up a namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgs_registry_namespace_add) and [ibmcloud cr namespace-add](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_namespace_add).\n* Namespaces created in version 0.1.484 of the Container Registry CLI or earlier, or in the IBM Cloud console before 29 July 2020 aren't assigned to resource groups. You can assign an existing namespace to a resource group so that you can configure access to resources within a namespace at the resource group level.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"},{"document_id":"ibmcld_01329-20420-22158","score":19.259695,"text":"\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nIf the command to list images times out, see [Why is it timing out when I list images?](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-troubleshoot-image-timeout) for assistance.\n\nibmcloud cr image-list [--format FORMAT] [--quiet | -q ] [--restrict RESTRICTION] [--include-ibm] [--no-trunc] [--show-type] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository:tag\n\n--restrict RESTRICTION","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01447-1492-3786","score":19.206985,"text":"\nVulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nReview the following table to find an overview of benefits of using Container Registry.\n\n\n\nTable 1. Container Registry benefits\n\n Benefit Description \n\n Highly available and scalable private registry. Set up your own image namespace in a multi-tenant, highly available, scalable, encrypted private registry that is hosted and managed by IBM.<br><br>Store your private Docker images and share them with users in your IBM Cloud account. \n Image security compliance with Vulnerability Advisor. Benefit from automatic scanning of images in your namespace.<br><br>Review recommendations that are specific to the operating system to fix potential vulnerabilities and protect your containers from being compromised. \n Quota limits for storage and pull traffic. Benefit from free storage and pull traffic to your private images until you reach your free quota.<br><br>Set custom quota limits for the amount of storage and pull traffic per month to avoid exceeding your preferred payment level. \n\n\n\n\n\n Service plans \n\nYou can choose between the free or standard Container Registry service plans to store your Docker images and make these images available to users in your IBM Cloud account.\n\nThe IBM Cloud Container Registry service plan determines the amount of storage and pull traffic that you can use for your private images. The service plan is associated with your IBM Cloud account, and limits for storage and image pull traffic apply to all namespaces that you set up in your account.\n\nService plans are scoped to the specific registry instance (one of the regional registries or the global registry) that you're currently working with. Plan settings must all be managed separately for your account in each registry instance. For more information, see [Regions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overviewregistry_regions).\n\nThe following table shows available IBM Cloud Container Registry service plans and their characteristics.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_overview"},{"document_id":"ibmcld_01441-7-2257","score":19.205048,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4"},{"document_id":"ibmcld_01442-7-2257","score":19.205048,"text":"\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from \/va\/api\/v3 APIs to \/va\/api\/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui"},{"document_id":"ibmcld_09410-1574-3779","score":19.03027,"text":"\n* IBM Cloud Container Registry provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM.\n* The IBM Cloud Container Registry includes Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\n\n\nTo get details about the logging agent images, see [Getting information about logging agent images](https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent_image).\n\n\n\n Resource Limits for agents deployed on Kubernetes \n\nThe agent is deployed as a Kubernetes DaemonSet, creating one pod for each node selected. The agent collects logs of all the pods in the node. The resource requirements of the agent are in direct relation to the number of pods for each node and the amount of logs produced for each pod.\n\nThe agent requires at least 128 MB and no more than 512 MB of memory. It requires at least twenty millicpu (20m).\n\nDifferent features can also increase resource utilization. When line exclusion, inclusion or redaction rules are specified, you can expect additional CPU consumption for each line and regex rule defined. When Kubernetes event logging is enabled (disabled by default), additional CPU usage will occur on the oldest agent pod.\n\nPlacing traffic shaping or CPU limits on the agent is not recommended to ensure data can be sent to the log ingestion service.\n\n\n\n\n\n Understanding image tags \n\nThe tag that is associated to a logging image indicates whether the logging agent is automatically updated.\n\nA tag consists of multiple parts:\n\nX.Y.Z-<date>.[hash]\n\nWhere\n\n\n\n* X represents the major version of an image.\n* Y represents the minor version of an image.\n* Z represents an incremental ID that determines the latest patched minor version.\n* <date> represents the date that the image is built and available. The format is YYYYMMDD.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/log-analysis?topic=log-analysis-log_analysis_agent"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"c6c3b02ca32795af64c903dd76700517<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_01471-23854-25589","score":14.560377,"text":"\n: If you want to manage your Vulnerability Advisor exemption policies for security issues, depending on the task that you want to complete, you might have to update your access role.\n\nFor more information, see [Access roles for configuring Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n 29 July 2020 \n\nYou can set permissions so that access to resources within a namespace can be configured at the resource group level\n: Namespaces are created in resource groups so that access to resources within a namespace can be configured at the resource group level. If a namespace isn't already in a resource group, you can assign the namespace to a resource group.\n\n\n\n* Namespaces created in version 0.1.485 of the Container Registry CLI or later, or in the IBM Cloud console on or after 29 July 2020, are created in a resource group that you specify so that you can configure access to resources within the namespace at the [resource group](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rgs) level. However, you can still set permissions for the namespace at the account level or in the namespace itself. For more information, see [Set up a namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgs_registry_namespace_add) and [ibmcloud cr namespace-add](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregclibx_cr_namespace_add).\n* Namespaces created in version 0.1.484 of the Container Registry CLI or earlier, or in the IBM Cloud console before 29 July 2020 aren't assigned to resource groups. You can assign an existing namespace to a resource group so that you can configure access to resources within a namespace at the resource group level.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_release_notes"},{"document_id":"ibmcld_04340-56606-58228","score":14.505784,"text":"\nibmcloud cr trash-list [--restrict NAMESPACE] [--json]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--restrict NAMESPACE\n: (Optional) Limit the output to display only images in the specified namespace.\n\n--json\n: (Optional) Outputs JSON that contains the details of the contents of the trash.\n\n\n\n\n\n Example \n\nDisplay the images that are in the trash in the birds namespace.\n\nibmcloud cr trash-list --restrict birds\n\n\n\n\n\n\n\n ibmcloud cr va-version \n\nFind out which version of Vulnerability Advisor you're using.\n\nibmcloud cr va-version\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n\n\n ibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-containerregcli"},{"document_id":"ibmcld_01488-1691-3475","score":13.997649,"text":"\n* [Create a cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusters).\n* Ensure that you have the correct access permissions for adding and removing\n\nnamespaces, see [Access roles for configuring IBM Cloud Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_configure).\n* Ensure that you are using Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\n\n\n\n\n\n\n Step 1: From code to a running container \n\nUsing [IBM Cloud Container Registry](https:\/\/www.ibm.com\/cloud\/container-registry) to store your container images is the easiest way to get an application up and running with IBM Cloud Kubernetes Service. The following steps show you how to build a container image, store it in IBM Cloud Container Registry, and create a Kubernetes deployment that uses that image.\n\n\n\n Create a namespace \n\nCreate a\n\nnamespaceto store your container images in IBM Cloud Container Registry. Namespaces are created in aresource group. For more information, see [Planning namespaces](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_setup_cli_namespaceregistry_setup_cli_namespace_plan).\n\n\n\n1. To log in to IBM Cloud and target the us-south region, run the following command.\n\nibmcloud login -r us-south [--sso]\n\nIf you have a federated ID, use ibmcloud login -r us-south --sso to log in. Enter your username and use the provided URL in your CLI output to retrieve your one-time passcode. If you have a federated ID, the login fails without the --sso and succeeds with the --sso option.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflow"},{"document_id":"ibmcld_01327-9280-11431","score":13.610925,"text":"\ncontainer-registry.exemption.create Create a Vulnerability Advisor exemption. \n container-registry.exemption.delete Delete a Vulnerability Advisor exemption. \n\n\n\n\n\n\n\n\n\n Analyzing Activity Tracker events \n\nThe following fields are populated as described, depending on how you populate the request:\n\n\n\n* target.name shows the image name and, if you request an image name with a tag, a tag. If you request an image name by digest, the digest is shown instead of the tag because the digest might have many tags.\n* target.id shows the image name by digest to represent a searchable unique ID for the image, unless the request is for an image with a tag and the request fails before the digest is discovered. To see all the events for this digest across all tags, you can search by target.id.\n* target.resourceGroupId shows the resource group ID that is associated with a namespace and its resources. For more information, see [Set up a namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgs_registry_namespace_add).\n\nEarlier namespaces that aren't migrated to IAM don't have a resource group, therefore this field is not available.\n\n\n\n\n\n Request data for vulnerability events \n\nGet the data for vulnerability events in Container Registry.\n\n\n\n Request data for the account vulnerability report \n\nGet the vulnerability assessment (container-registry.account-vulnerability-report.list) for the list of registry images that belong to a specific account.\n\nThe following table lists the fields that are available through the requestData field in events with the action container-registry.account-vulnerability-report.list.\n\n\n\nTable 18. Custom event fields for Container Registry account vulnerability reports list\n\n Custom Event Fields Type Description \n\n requestData.RequestParameters.repository String The name of the repository that you want to see image vulnerability assessments for. For example, us.icr.io\/namespace\/image. \n requestData.RequestParameters.includeIBM String When set to true, the returned list contains IBM public images and the account images. If not set, or set to false, the list contains only the account images.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-at_events"},{"document_id":"ibmcld_01329-59746-61590","score":13.593634,"text":"\nFor more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr vulnerability-assessment [--extended | -e] [--vulnerabilities | -v] [--configuration-issues | -c] [--output FORMAT | -o FORMAT] IMAGE [IMAGE...]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\nIMAGE\n: The name of the image for which you want to get a report. The report states whether the image has any known package vulnerabilities. You can request reports for multiple images at the same time by listing each image in the command with a space between each name.\n\nTo find the names of your images, run ibmcloud cr image-list. Combine the content of the Repository column (repository) and Tag column (tag) separated by a colon (:) to create the image name in the format repository:tag. If a tag is not specified in the image name, the report assesses the image that is tagged latest.\n\nFor information about supported Docker base images, see [Vulnerable packages](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uipackages).\n\nFor more information, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=ui).\n\n--extended, -e\n: (Optional) The command output shows additional information about fixes for vulnerable packages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01329-14955-16723","score":13.458952,"text":"\nIf you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr image-digests [--format FORMAT | --quiet | -q | --json] [--restrict RESTRICTION] [--include-ibm] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository@digest\n\n--json\n: (Optional) Outputs the list in JSON format.\n\n--restrict RESTRICTION\n: (Optional) Limit the output to display only images in the specified namespace or repository.\n\n--include-ibm\n: (Optional) Includes IBM-provided public images in the output. By default only private images are listed. You can view IBM-provided images in the global registry only.\n\n--no-va\n: (Optional) Excludes the security status (Vulnerability Advisor) results from the output.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-containerregcli"},{"document_id":"ibmcld_01488-11005-12525","score":13.452586,"text":"\nView the security.yaml file in the [GitHub repository](https:\/\/github.com\/IBM\/registry-va-workflow), and read about customizing [policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-security_enforce_portierispolicies_portieris) to understand this file's contents. In short, this policy requires all images in your namespace to have no issues reported by Vulnerability Advisor.\n3. Update the following line in the security.yaml file by replacing <my_namespace> with your namespace:\n\n- name: us.icr.io\/<my_namespace>\/\n4. Apply the custom policies:\n\nkubectl apply -f security.yaml\n5. To update hello-world.yaml so that it references your vulnerable image, change the tag from 1 to 2 as shown here:\n\nimage: us.icr.io\/<my_namespace>\/hello-world:2\n6. Try to patch the existing deployment by running the following command:\n\nkubectl apply -f hello-world.yaml\n\nYou see the following error message:\n\nDeny \"us.icr.io\/<my_namespace>\/hello-world:2\", the Vulnerability Advisor image scan assessment\nfound issues with the container image that are not exempted. Refer to your image vulnerability\nreport for more details by using the ibmcloud cr va command.\n\nThe Vulnerability Advisor verdict is subject to any [exemption policies](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_managing_policy) that you create. If you want to use an image that Vulnerability Advisor considers vulnerable, you can exempt one, or more vulnerabilities so that Vulnerability Advisor doesn't consider them in its verdict.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_tutorial_workflow"},{"document_id":"ibmcld_08191-5423-7289","score":13.417236,"text":"\n* namespace: Is the [namespace created](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-getting-startedgs_registry_namespace_add) in the IBM Cloud Container Registry, see also step 4 of this procedure.\n* name: Is the unique name for the repository (one repository can have multiple images that differ by the tag).\n* tag: Is the unique tag for the image.\n\n\n\n\n\n3. After you create your image, check for vulnerable components. Most containers are built by using a collection of open source components that can suffer from known vulnerabilities. It is your responsibility to use scanning tools to identify if any of the components you include in the build are vulnerable. Scan the components before you distribute the image, for example, with [Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=va-va_index).\n4. Push the image to the container registry you choose. You can use Docker Hub (with Docker Content Trust enabled), or ICR. To push the image to ICR, you must first sign the image using Red Hat signing. For more information, see [Sign your image by using Red Hat simple signing](https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-byoisign_image_redhat).\n5. Follow the [backup instructions](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_trustedcontenttrustedcontent_backupkeys) to back up your keys after you push the image.\n\n\n\n\n\n\n\n Sign your image by using Red Hat simple signing \n\nYou must provide the \"Fingerprint\" and the \"Path to the public key\" that you used when you signed the image by using Red Hat signing when you run the hpvs registration-create command, and are prompted for the \"Fingerprint\", and the \"Path to the file containing the image public key\".\n\nComplete the following steps to sign the images:\n\n\n\n1. Create a batch file and add the following content to it:\n\nKey-Type: RSA\nKey-Length: 4096","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hp-virtual-servers?topic=hp-virtual-servers-byoi"},{"document_id":"ibmcld_04340-14470-16309","score":13.277615,"text":"\nYou can also refer to the image name by using a combination of the content of the Repository column (repository) and one of the tags in the Tags column (tag) separated by a colon (:) to create the image name in the format repository:tag.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index&interface=uiabout).\n\nibmcloud cr image-digests [--format FORMAT | --quiet | -q | --json] [--restrict RESTRICTION] [--include-ibm] [--no-va] [--va]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for using Container Registry](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-iamaccess_roles_using).\n\n\n\n\n\n Command options \n\n--format FORMAT\n: (Optional) Format the output elements by using a Go template. For more information, see [Formatting and filtering the Container Registry CLI output](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_cli_list).\n\n--quiet, -q\n: (Optional) Each image is listed in the format: repository@digest\n\n--json\n: (Optional) Outputs the list in JSON format.\n\n--restrict RESTRICTION\n: (Optional) Limit the output to display only images in the specified namespace or repository.\n\n--include-ibm\n: (Optional) Includes IBM-provided public images in the output. By default only private images are listed. You can view IBM-provided images in the global registry only.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-containerregcli"},{"document_id":"ibmcld_10261-16096-18060","score":13.266354,"text":"\nOr, you might push a Docker image that you work with to your namespace so that other users can access the image. To get started, see [Adding images to your namespace](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_images_).\n\n\n\n\n\n Managing security of images in IBM Cloud Container Registry with Vulnerability Advisor \n\nVulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's IBM Cloud Container Registry namespace.\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-va_index).\n\n\n\n\n\n Setting up trusted content for container images \n\nYou can build containers from trusted images that are signed and stored in IBM Cloud Container Registry, and prevent deployments from unsigned or vulnerable images.\n\n\n\n1. [Sign images for trusted content](https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-registry_trustedcontentregistry_trustedcontent). After you set up trust for your images, you can manage trusted content and signers that can push images to your registry.\n2. To enforce a policy so that only signed images can be used to build containers in your cluster, [install the open source Portieris project](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-imagesportieris-image-sec).\n3. Cluster users can deploy apps that are built from trusted images.\n\n\n\n1. [Deploy to the default Kubernetes namespace](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-imagesnamespace).\n2. [Deploy to a different Kubernetes namespace, or from a different IBM Cloud region or account](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-registryother).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-images"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05597-10227-11923","score":18.79614,"text":"\nIf the cluster master runs two or more versions behind the oldest supported version, you can no longer apply updates and must delete the cluster and create a new one.\n5. Archived: The version is unsupported with no upgrade path. IBM provides no support. IBM reserves the right to shut down the control planes for such clusters.\n\n\n\nIf you wait until your cluster is two or more minor versions behind the oldest supported version, you can't update the cluster. Instead, [create a new cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clustersclusters), [deploy your apps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-appapp) to the new cluster, and [delete](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-remove) the unsupported cluster. To avoid this issue, update deprecated clusters to a supported version that is one or two behind the current version, such as 1.21 or 1.22 and then update to the latest version, 1.23. If the worker nodes run a version two or more behind the master, you might see your pods fail by entering a state such as MatchNodeSelector, CrashLoopBackOff, or ContainerCreating until you update the worker nodes to the same version as the master. After you update from a deprecated to a supported version, your cluster can resume normal operations and continue receiving support. You can find out whether your cluster is unsupported by reviewing the State field in the output of the ibmcloud ks cluster ls command or in the [IBM Cloud Kubernetes Service console](https:\/\/cloud.ibm.com\/kubernetes\/clusters).\n\n\n\n\n\n Preparing to update \n\nUpdating a cluster to a new version from the previous version is likely to have an impact on deployed apps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog"},{"document_id":"ibmcld_05728-10229-11925","score":18.79614,"text":"\nIf the cluster master runs two or more versions behind the oldest supported version, you can no longer apply updates and must delete the cluster and create a new one.\n5. Archived: The version is unsupported with no upgrade path. IBM provides no support. IBM reserves the right to shut down the control planes for such clusters.\n\n\n\nIf you wait until your cluster is two or more minor versions behind the oldest supported version, you can't update the cluster. Instead, [create a new cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clustersclusters), [deploy your apps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-appapp) to the new cluster, and [delete](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-remove) the unsupported cluster. To avoid this issue, update deprecated clusters to a supported version that is one or two behind the current version, such as 1.21 or 1.22 and then update to the latest version, 1.23. If the worker nodes run a version two or more behind the master, you might see your pods fail by entering a state such as MatchNodeSelector, CrashLoopBackOff, or ContainerCreating until you update the worker nodes to the same version as the master. After you update from a deprecated to a supported version, your cluster can resume normal operations and continue receiving support. You can find out whether your cluster is unsupported by reviewing the State field in the output of the ibmcloud ks cluster ls command or in the [IBM Cloud Kubernetes Service console](https:\/\/cloud.ibm.com\/kubernetes\/clusters).\n\n\n\n\n\n Preparing to update \n\nUpdating a cluster to a new version from the previous version is likely to have an impact on deployed apps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions"},{"document_id":"ibmcld_05754-3185-5238","score":17.969326,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud ks versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug_master"},{"document_id":"ibmcld_10189-3187-5240","score":17.93824,"text":"\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud oc versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-debug_master"},{"document_id":"ibmcld_10642-1365-3347","score":17.874113,"text":"\nThen, [update the worker nodes](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master. The update automation also skips clusters that are in an unhealthy state or have operations currently in progress. Occasionally, IBM might disable automatic updates for a specific master fix pack, such as a patch that is only needed if a master is updated from one minor version to another. In any of these cases, you can [check the versions change log](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift_versions) for any potential impact and choose to safely use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update"},{"document_id":"ibmcld_06209-7-1817","score":17.468725,"text":"\nUpdating clusters, worker nodes, and cluster components \n\nYou can install updates to keep your Kubernetes clusters up-to-date in IBM Cloud\u00ae Kubernetes Service.\n\n\n\n Updating the Kubernetes master \n\nPeriodically, the Kubernetes project releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). Updates can affect the Kubernetes API server version or other components in your Kubernetes master. IBM updates the patch version, but you must update the master major and minor versions.\n\n\n\n About updating the master \n\nHow do I know when to update the master?\n: You are notified in the IBM Cloud console and CLI when updates are available, and can also check the [supported versions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) page.\n\nHow many versions behind the latest can the master be?\n: IBM generally supports three versions of Kubernetes at a time. You can update the Kubernetes API server only to the next version ahead of its current version (n+1). Additionally, your worker nodes can be up to two versions behind the master version (n-2).\n\nFor example, if your current Kubernetes API server version is 1.18 (n) and you want to update to 1.20, you must first update to 1.19 (n+1) and then to 1.20 (n+2). Next, you can update the worker nodes up to two version ahead, such as 1.18 to 1.20 (n+2).\n\nIf your cluster runs an unsupported Kubernetes version, follow the [version archive instructions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsk8s_version_archive). To avoid getting in an unsupported state and operational impact, keep your cluster up-to-date.\n\nCan my worker nodes run a later version than the master?\n: Your worker nodes can't run a later major.minor Kubernetes version than the master.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_06209-1393-3390","score":17.357748,"text":"\nIf your cluster runs an unsupported Kubernetes version, follow the [version archive instructions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsk8s_version_archive). To avoid getting in an unsupported state and operational impact, keep your cluster up-to-date.\n\nCan my worker nodes run a later version than the master?\n: Your worker nodes can't run a later major.minor Kubernetes version than the master. Additionally, your worker nodes can be only up to two versions behind the master version (n-2). First, [update your master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate_master) to the latest Kubernetes version. Then, [update the worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master. The update automation also skips clusters that are in an unhealthy state or have operations currently in progress. Occasionally, IBM might disable automatic updates for a specific master fix pack, such as a patch that is only needed if a master is updated from one minor version to another. In any of these cases, you can [check the versions change log](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-changelog) for any potential impact and choose to safely use the ibmcloud ks cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update"},{"document_id":"ibmcld_10394-1469-2994","score":17.29532,"text":"\nIf you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.\n\n\n\n\n\n\n\n Step 2: Determine which worker nodes you want to update \n\nMajor\n\nMinor\n\n\n\n1. List your worker nodes by using the oc get nodes command and determining which worker nodes you want to update.\n\noc get nodes\n\nExample output\n\nNAME STATUS ROLES AGE VERSION\n10.241.0.4 Ready master,worker 106s v1.21.6+4b61f94\n10.241.128.4 Ready master,worker 22d v1.21.6+bb8d50a\n10.241.64.4 Ready master,worker 22d v1.21.6+bb8d50a\n\n\n\n\n\n\n\n Step 3: Scale down OpenShift Data Foundation \n\nMajor\n\nMinor\n\n\n\n1. For each worker node that you found in the previous step, find the rook-ceph-mon and rook-ceph-osd deployments.\n\noc get pods -n openshift-storage -o wide | grep -i <node_name>\n2. Scale down the deployments that you found in the previous step.\n\noc scale deployment rook-ceph-mon-c --replicas=0 -n openshift-storage\noc scale deployment rook-ceph-osd-2 --replicas=0 -n openshift-storage\noc scale deployment --selector=app=rook-ceph-crashcollector,node_name=NODE-NAME --replicas=0 -n openshift-storage\n\n\n\n\n\n\n\n Step 4: Cordon and drain the worker node \n\nMajor\n\nMinor\n\n\n\n1. Cordon the node. Cordoning the node prevents any pods from being scheduled on this node.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"},{"document_id":"ibmcld_10246-15672-17685","score":17.23565,"text":"\nDuring the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud oc cluster master update[command](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud oc versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n\n\n Disabling remote health reporting \n\nOpenShift Container Platform collects anonymized health reports about your cluster through a [telemetry component that is enabled by default](https:\/\/docs.openshift.com\/container-platform\/4.11\/support\/remote_health_monitoring\/about-remote-health-monitoring.html) in your Red Hat OpenShift on IBM Cloud cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-health-monitor"},{"document_id":"ibmcld_10394-7-1848","score":17.12319,"text":"\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-update-classic"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.765360637,"ndcg_cut_10":0.765360637}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05618-7-2074","score":18.35731,"text":"\nKubernetes version 1.27 CIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.27. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmarkcis-benchmark-use).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive Not Scored 1 Pass IBM \n 1.1.10 Ensure that the Container Network Interface file ownership is set to root:root Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-127"},{"document_id":"ibmcld_05617-7-2046","score":18.115204,"text":"\nVersion 1.26 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.26. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive Not Scored 1 Pass IBM \n 1.1.10 Ensure that the Container Network Interface file ownership is set to root:root Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-126"},{"document_id":"ibmcld_05615-7-1945","score":17.880741,"text":"\nVersion 1.24 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.24. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124"},{"document_id":"ibmcld_05614-7-1955","score":17.863598,"text":"\nVersion 1.23 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.23. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123"},{"document_id":"ibmcld_05616-7-1945","score":17.853788,"text":"\nVersion 1.25 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.25. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125"},{"document_id":"ibmcld_05613-7-1955","score":17.850279,"text":"\nVersion 1.22 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.22. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-122"},{"document_id":"ibmcld_05611-7-1955","score":17.849783,"text":"\nVersion 1.20 CIS Kubernetes benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.20. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-120"},{"document_id":"ibmcld_05608-4885-6487","score":17.569498,"text":"\nTo review the results of the CIS Kubernetes benchmark for Section 4: Worker node security configuration, you can run the test yourself. Because you own the worker nodes and are partially [responsible](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks) for their compliance, you might make configuration changes that you want to validate on your own.\n\nBefore you begin: [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\n1. Create a namespace for the resources to run the benchmark.\n\nkubectl create ns ibm-kube-bench-test\n2. Create a ConfigMap with the config and node configuration files from the [kube-samples](https:\/\/github.com\/IBM-Cloud\/kube-samples\/tree\/master\/cis-kube-benchmark\/cis-1.5\/ibm) GitHub repository.\n\n\n\n1. Download the the config and node configuration files into a local directory called ibm. You can also clone the repository and navigate into the ibm directory.\n\n\n\n* [config file](https:\/\/raw.githubusercontent.com\/IBM-Cloud\/kube-samples\/master\/cis-kube-benchmark\/cis-1.5\/ibm\/config.yaml)\n* [node file](https:\/\/raw.githubusercontent.com\/IBM-Cloud\/kube-samples\/master\/cis-kube-benchmark\/cis-1.5\/ibm\/node.yaml)\n\n\n\n2. Create the ConfigMap by using the --from-file option to specify the ibm directory where your downloaded the configuration files.\n\nkubectl create cm kube-bench-node -n ibm-kube-bench-test --from-file ibm\n\n\n\n3. Create a job to run the benchmark test based on the configurations that you previously created.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"},{"document_id":"ibmcld_05612-7-1934","score":17.389845,"text":"\nVersion 1.21 CIS Kubernetes benchmark \n\nKubernetes version 1.21 becomes unsupported on 14 September 2022. Update your cluster to at least [version 1.22](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions_122) as soon as possible.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.21. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-121"},{"document_id":"ibmcld_05610-7-1993","score":17.344095,"text":"\nVersion 1.19 CIS Kubernetes benchmark \n\nKubernetes version 1.19 is unsupported.\n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations. This document contains the results of the version 1.5 CIS Kubernetes benchmark for clusters that run Kubernetes version 1.19. For more information or help understanding the benchmark, see [Using the benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n 1 Master node security configuration \n\nReview the Master node security configuration results of the version 1.5 CIS Kubernetes benchmark.\n\n\n\n 1.1 Master node configuration files \n\n\n\nSection 1.1 Master node benchmark results\n\n Section Recommendation Scored\/Not Scored Level Result Responsibility \n\n 1.1.1 Ensure that the API server pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.2 Ensure that the API server pod specification file ownership is set to root:root Scored 1 Pass IBM \n 1.1.3 Ensure that the controller manager pod specification file permissions are set to 644 or more restrictive Scored 1 Pass IBM \n 1.1.4 Ensure that the controller manager pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.5 Ensure that the scheduler pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.6 Ensure that the scheduler pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.7 Ensure that the etcd pod specification file permissions are set to 644 or more restrictive. Scored 1 Pass IBM \n 1.1.8 Ensure that the etcd pod specification file ownership is set to root:root. Scored 1 Pass IBM \n 1.1.9 Ensure that the Container Network Interface file permissions are set to 644 or more restrictive. Not Scored 1 Pass IBM","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-119"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-373434-375500","score":20.87065,"text":"\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-373408-375474","score":20.87065,"text":"\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05726-3592-5935","score":20.453714,"text":"\n* DEVELOPMENT ENVIRONMENT: Kubernetes clusters for Dev, Test, and Production systems increase collaboration and data sharing among the retailer and its business partners\n\n\n\nFor the retailer to work with global business partners, the inventory APIs required changes to fit each region\u2019s language and market preferences. IBM Cloud Kubernetes Service offers coverage in multiple regions, including North America, Europe, Asia, and Australia, so that the APIs reflected the needs of each country and ensured low latency for API calls.\n\nAnother requirement is that inventory data must be shareable with the business partners and customers of the company. With the inventory APIs, Developers can surface information in apps, such as mobile inventory apps or web e-commerce solutions. The Developers are also busy with building and maintaining the primary e-commerce site. In short, they need to focus on coding instead of managing the infrastructure.\n\nThus, they chose IBM Cloud Kubernetes Service because IBM simplifies infrastructure management.\n\n\n\n* Managing Kubernetes master, IaaS, and operational components, such as Ingress and storage\n* Monitoring health and recovery for worker nodes\n* Providing global compute, so Developers own hardware infrastructure in regions where they need workloads and data to reside\n\n\n\nMoreover logging and monitoring for the API microservices, especially how they pull personalized data out of back-end systems, easily integrates with IBM Cloud Kubernetes Service. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot live systems.\n\nIBM\u00ae Event Streams for IBM Cloud\u00ae acts as the just-in-time events platform to bring in the rapidly changing information from the business partners\u2019 inventory systems to IBM Cloud\u00ae Object Storage.\n\nCompute, storage, and event management that run in public cloud with access to retail inventories across the globe, as needed\n\nTechnical solution:\n\n\n\n* IBM Cloud Kubernetes Service\n* IBM\u00ae Event Streams for IBM Cloud\u00ae\n* IBM Cloud\u00ae Object Storage\n* IBM Cloud\u00ae Continuous Delivery\n* IBM Cloud Logging and Monitoring\n* App ID\n\n\n\n\n\n Step 1: Containerize apps by using microservices \n\n\n\n* Structure apps into a set of cooperative microservices that run within IBM Cloud Kubernetes Service based on functional areas of the app and its dependencies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_uc_retail"},{"document_id":"ibmcld_05777-1455-3483","score":20.276958,"text":"\nYour worker nodes are controlled by a highly available Kubernetes master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov).\n\n\n\n\n\n Why should I use IBM Cloud Kubernetes Service? \n\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n\n\n\n\n\n Can I get a free cluster? \n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_05707-7-2073","score":20.189526,"text":"\nBenefits and service offerings \n\n[IBM Cloud\u00ae Kubernetes Service](https:\/\/www.ibm.com\/cloud\/kubernetes-service) delivers powerful tools by combining Docker containers, the Kubernetes technology, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts. For more information about certification, see [Compliance on the IBM Cloud](https:\/\/www.ibm.com\/cloud\/compliance).\n\n\n\n Benefits of using the service \n\nClusters are deployed on compute hosts that provide native Kubernetes and IBM-specific capabilities.\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud. For more information, see Comparison between [Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovopenshift_kubernetes) and community Kubernetes clusters.\n\nSingle-tenant Kubernetes clusters with compute, network, and storage infrastructure isolation\n: Create your own customized infrastructure that meets the requirements of your organization.\n: Choose between [IBM Cloud Classic or VPC infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers).\n: Provision a dedicated and secured Kubernetes master, worker nodes, virtual networks, and storage by using the resources provided by IBM Cloud infrastructure.\n: Fully managed Kubernetes master that is continuously monitored and updated by IBM to keep your cluster available.\n: Option to provision worker nodes as bare metal servers for compute-intensive workloads such as data, GPU, and AI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov"},{"document_id":"ibmcld_05707-4888-6797","score":20.08092,"text":"\nIBM Cloud Kubernetes Service on IBM Cloud Public delivers powerful tools by combining Docker containers, the Kubernetes technology, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts For more information, see [IBM Cloud Kubernetes Service technology](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch).\n: You can also create your cluster in a Virtual Private Cloud (VPC), which gives you the security of a private cloud environment with isolated networking features along with the dynamic scalability of the public cloud. For more information, see [Overview of Classic and VPC infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers).\n\nIBM Cloud Private, on-premises\n: IBM Cloud Private is an application platform that can be installed locally on your own machines. You might choose to use Kubernetes in IBM Cloud Private when you need to develop and manage on-premises, containerized apps in your own controlled environment behind a firewall. For more information, see the [IBM Cloud Private product documentation](https:\/\/www.ibm.com\/docs\/en\/cloud-private\/3.2.x).\n\n\n\n\n\n Comparison of free and standard clusters \n\nReview the following table for a comparison of free and standard clusters.\n\nThe free cluster option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nFree clusters are automatically deleted after 30 days.\n\nIf you have a free cluster and want to upgrade to a standard cluster, you can [create a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusters).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov"},{"document_id":"ibmcld_06057-15394-17048","score":20.016752,"text":"\nFor example, to prepare your cluster for HA\/DR scenarios, follow the guidance in [High availability for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha). Note that persistent storage of data such as application logs and cluster metrics are not set up by default.<br><br><br> \n\n\n\n\n\n\n\n Applications and data \n\nYou are completely responsible for the applications, workloads, and data that you deploy to IBM Cloud. However, IBM provides various tools to help you set up, manage, secure, integrate and optimize your apps as described in the following table.\n\n\n\nTable 7. Applications and data\n\n Resource How IBM helps What you can do \n\n Applications <br><br> * Provision clusters with Kubernetes components installed so that you can access the Kubernetes API to deploy and manage your containerized apps.<br> * Provide a number of managed add-ons to extend your app's capabilities, such as [Istio](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-istio) or the Diagnostics and Debug Tool. Maintenance is simplified for you because IBM provides the installation and updates for the managed add-ons.<br> * Provide cluster integration with select third-party partnership technologies, such as Log Analysis, Monitoring, and Portworx.<br> * Provide automation to enable service binding to other IBM Cloud services.<br> * Create clusters with image pull secrets so that your deployments in the default Kubernetes namespace can pull images from IBM Cloud Container Registry.<br> * Provide access to Kubernetes APIs that you can use to set up Operators to add community, third-party, and your own services to your cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks"},{"document_id":"ibmcld_06128-7-1993","score":19.88443,"text":"\nMoving your environment to IBM Cloud Kubernetes Service \n\nWith IBM Cloud\u00ae Kubernetes Service, you can quickly and securely deploy container workloads for your apps in production. Learn more so that when you plan your cluster strategy, you optimize your setup to make the most of [Kubernetes](https:\/\/kubernetes.io\/) automated deploying, scaling, and orchestration management capabilities.\n\n\n\n Moving your workloads to the IBM Cloud \n\nYou have lots of reasons to move your workloads to IBM Cloud: reducing total cost of ownership, increasing high availability for your apps in a secure and compliant environment, scaling up and down in respond to your user demand, and many more. IBM Cloud Kubernetes Service combines container technology with open source tools, such as Kubernetes so that you can build a cloud-native app that can migrate across different cloud environments, avoiding vendor lock-in.\n\nBut how do you get to the cloud? What are your options along the way? And how do you manage your workloads after you get there?\n\nUse this page to learn some strategies for your Kubernetes deployments on IBM Cloud Kubernetes Service. And engage with our team on [Slack](https:\/\/ibm-cloud-success.slack.com).\n\nNot on slack yet? [!Request an invite](https:\/\/cloud.ibm.com\/kubernetes\/slack)\n\n\n\n What can I move to the IBM Cloud? \n\nWith IBM Cloud, you have flexibility to create Kubernetes clusters in [off-premises, on-premises, or hybrid cloud environments](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovdifferentiation). The following table provides some examples of what types of workloads that users typically move to the various types of clouds. You might also choose a hybrid approach where you have clusters that run in both environments.\n\n\n\nIBM Cloud implementations support your workloads\n\n Workload Kubernetes Service off-prem on-prem \n\n DevOps enablement tools Yes \n Developing and testing apps Yes \n Apps have major shifts in demand and need to scale rapidly Yes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategy"},{"document_id":"ibmcld_05707-6437-8139","score":19.86224,"text":"\nIf you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nFree clusters are automatically deleted after 30 days.\n\nIf you have a free cluster and want to upgrade to a standard cluster, you can [create a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-clusters). Then, [copy your deployment configuration files](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appcopy_apps_cluster) from your free cluster into the standard cluster.\n\n\n\nCharacteristics of free and standard clusters\n\n Characteristics Free clusters Standard clusters \n\n [In-cluster networking](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork) Yes Yes \n [Public network app access by a NodePort service to a non-stable IP address](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-nodeport) Yes Yes \n [User access management](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access-overviewaccess_policies) Yes Yes \n [IBM Cloud service access from the cluster and apps](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-bindingbind-services) Yes Yes \n [Disk space on worker node for non-persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-storage-plan) Yes Yes \n [Provision Red Hat OpenShift clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-getting-started) Yes \n [Create clusters in a Virtual Private Cloud (VPC)](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-vpc_ks_tutorial) Yes \n [Ability to create cluster in every IBM Cloud Kubernetes Service region](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-regions-and-zones) Yes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov"},{"document_id":"ibmcld_07578-378095-380247","score":19.837128,"text":"\nFor more information, see [Updating cluster add-ons](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateaddons).\n\nPeriodically, Kubernetes releases [major, minor, or patch updates](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsupdate_types). These updates can affect the Kubernetes API server version or other components in your Kubernetes master. IBM automatically updates the patch version, but you must update the master major and minor versions. For more information, see [Updating the master](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updatemaster).\n\nWorker nodes in standard clusters are provisioned in to your IBM Cloud infrastructure account. The worker nodes are dedicated to your account and you are responsible to request timely updates to the worker nodes to ensure that the worker node OS and IBM Cloud Kubernetes Service components apply the latest security updates and patches. Security updates and patches are made available by IBM Site Reliability Engineers (SREs) who continuously monitor the Linux image that is installed on your worker nodes to detect vulnerabilities and security compliance issues. For more information, see [Updating worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateworker_node).\n* Are the master and worker nodes highly available?\n\nThe IBM Cloud Kubernetes Service architecture and infrastructure is designed to ensure reliability, low processing latency, and a maximum uptime of the service. By default, every cluster in IBM Cloud Kubernetes Service is set up with multiple Kubernetes master instances to ensure availability and accessibility of your cluster resources, even if one or more instances of your Kubernetes master are unavailable.\n\nYou can make your cluster even more highly available and protect your app from a downtime by spreading your workloads across multiple worker nodes in multiple zones of a region. This setup is called a [multizone cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-ha_clustersmz-clusters) and ensures that your app is accessible, even if a worker node or an entire zone is not available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-373434-375500","score":20.54056,"text":"\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-373408-375474","score":20.54056,"text":"\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05608-3099-5358","score":20.285555,"text":"\n* Shared: You and IBM share responsibility for configuring the setting that the benchmark recommends.\n\n\n\n\n\n\n\n\n\n What parts of the benchmark am I responsible for? \n\nBecause IBM Cloud Kubernetes Service is a managed offering, IBM already configures many security settings for you. For example, IBM manages and automatically applies updates to your cluster master. For your worker nodes, IBM provides security and version updates, but you must apply the updates. You are also responsible for your workload applications and data. For more information, see [Your responsibilities while using IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks).\n\n\n\n\n\n What if some part of the service fails to comply with a recommendation? \n\nFirst, check the explanation of the failure for any remediation steps.\n\nThen, determine whether the failure is acceptable according to your security requirements. For example, some recommendations might be more in-depth configuration requirements than your particular processes or standards require. Also, some recommendations are not scored, and don't impact the overall benchmark score.\n\nNext, decide whether the component falls within your responsibility. If so, you might need to change how you configure that component. For example, you might configure pod security policies for all your app deployments. For components that are not directly within your responsibility, assess whether you can use another IBM Cloud service to meet the recommendation.\n\n\n\n\n\n What else can I do to increase the security and compliance of my cluster? \n\nSee [Security for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security).\n\n\n\n\n\n\n\n Running the worker node CIS Kubernetes benchmark \n\nTo review the results of the CIS Kubernetes benchmark for Section 4: Worker node security configuration, you can run the test yourself. Because you own the worker nodes and are partially [responsible](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks) for their compliance, you might make configuration changes that you want to validate on your own.\n\nBefore you begin: [Log in to your account. If applicable, target the appropriate resource group.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"},{"document_id":"ibmcld_05608-1309-3624","score":20.16747,"text":"\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM. IBM might not configure default settings in a way that meets every recommendation, but documents whether the recommendation is met to help you in your review. For example, you might use the benchmark in an audit to confirm that basic security measures are in place, and to identify areas where you might enhance your security.\n\n\n\n What does the benchmark cover? \n\nThe benchmark covers recommendations for master components, etcd, control plane configurations, worker nodes, and policies such as for users, network, and pod security.\n\n\n\n\n\n What do the benchmark recommendations mean? \n\nThe benchmark recommendations have scoring, levels, result status, and responsibilities as follows.\n\n\n\n* Scoring\n\n\n\n* Scored: The overall benchmark score increases or decreases depending on whether the recommendation is met.\n* Not scored: The overall benchmark score is not impacted, whether the recommendation is met.\n\n\n\n* Levels\n\n\n\n* Level 1: Practical security measures that can be configured without inhibiting the service.\n* Level 2: More in-depth security measures that might reduce the performance or functionality of a service.\n\n\n\n* Result\n\n\n\n* Pass: The service complies with the benchmark recommendation.\n* Fail: The service does not comply with the benchmark recommendation by default. Refer to the remediation section for an explanation and possible actions that you can take to comply with the benchmark recommendation.\n\n\n\n* Responsibility\n\n\n\n* IBM: IBM is responsible for configuring the setting that the benchmark recommends.\n* Shared: You and IBM share responsibility for configuring the setting that the benchmark recommends.\n\n\n\n\n\n\n\n\n\n What parts of the benchmark am I responsible for? \n\nBecause IBM Cloud Kubernetes Service is a managed offering, IBM already configures many security settings for you. For example, IBM manages and automatically applies updates to your cluster master. For your worker nodes, IBM provides security and version updates, but you must apply the updates. You are also responsible for your workload applications and data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"},{"document_id":"ibmcld_05608-7-1899","score":19.773392,"text":"\nCIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https:\/\/www.cisecurity.org\/benchmark\/kubernetes\/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations.\n\nWhen a new [Kubernetes version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versions) is released, IBM engineers compare the default configuration of a cluster that runs that Kubernetes version against the benchmark and publishes the results in this documentation. You can review how specific versions of your IBM Cloud\u00ae Kubernetes Service clusters meet the CIS Kubernetes Benchmark.\n\n\n\n Available benchmark versions \n\nUse the list to find CIS Kubernetes Benchmark results for available versions.\n\n\n\n* [Version 1.27](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-127)\n* [Version 1.26](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-126)\n* [Version 1.25](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-125)\n* [Version 1.24](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-124)\n* [Version 1.23](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark-123)\n\n\n\n\n\n\n\n Using the benchmark \n\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM. IBM might not configure default settings in a way that meets every recommendation, but documents whether the recommendation is met to help you in your review. For example, you might use the benchmark in an audit to confirm that basic security measures are in place, and to identify areas where you might enhance your security.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark"},{"document_id":"ibmcld_06063-7-2179","score":19.5601,"text":"\nSecurity for IBM Cloud Kubernetes Service \n\nYou can use built-in security features in IBM Cloud\u00ae Kubernetes Service for risk analysis and security protection. These features help you to protect your cluster infrastructure and network communication, isolate your compute resources, and ensure security compliance across your infrastructure components and container deployments.\n\nFor an analysis of security guidelines by product version, see [CIS Kubernetes Benchmark](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cis-benchmark).\n\n\n\n Overview of security threats for your cluster \n\nTo protect your cluster from being compromised, you must understand potential security threats for your cluster and what you can do to reduce the exposure to vulnerabilities.\n\nExternal attacks\n: Attackers that gain access to your cluster, deployed resources, apps, or personal information.\n\nVulnerable deployments\n: Known vulnerabilities are exploited to gain access to the cloud environment and run malicious software.\n\nCompromised or lost data\n: Incorrect storage of sensitive data and missing encryption.\n\nInsiders and third party vendors\n: Missing network isolation and segmentation can lead to the misuse of legitimate permissions.\n\nCloud security and the protection of your systems, infrastructure, and data against attacks became very important over the last couple of years as companies continue to move their workloads into the public cloud. A cluster consists of several components that each can put your environment at risk for malicious attacks. To protect your cluster against these security threats, you must make sure that you apply the latest IBM Cloud Kubernetes Service and Kubernetes security features and updates in all cluster components.\n\nThese components include:\n\n\n\n* [Kubernetes API server and etcd data store](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityapiserver)\n* [Worker nodes](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securityworkernodes)\n* [Network](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitynetwork)\n* [Persistent storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitystorage)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_05777-1455-3483","score":19.47877,"text":"\nYour worker nodes are controlled by a highly available Kubernetes master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov).\n\n\n\n\n\n Why should I use IBM Cloud Kubernetes Service? \n\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n\n\n\n\n\n Can I get a free cluster? \n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_05707-7-2073","score":19.447199,"text":"\nBenefits and service offerings \n\n[IBM Cloud\u00ae Kubernetes Service](https:\/\/www.ibm.com\/cloud\/kubernetes-service) delivers powerful tools by combining Docker containers, the Kubernetes technology, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts. For more information about certification, see [Compliance on the IBM Cloud](https:\/\/www.ibm.com\/cloud\/compliance).\n\n\n\n Benefits of using the service \n\nClusters are deployed on compute hosts that provide native Kubernetes and IBM-specific capabilities.\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud. For more information, see Comparison between [Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovopenshift_kubernetes) and community Kubernetes clusters.\n\nSingle-tenant Kubernetes clusters with compute, network, and storage infrastructure isolation\n: Create your own customized infrastructure that meets the requirements of your organization.\n: Choose between [IBM Cloud Classic or VPC infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers).\n: Provision a dedicated and secured Kubernetes master, worker nodes, virtual networks, and storage by using the resources provided by IBM Cloud infrastructure.\n: Fully managed Kubernetes master that is continuously monitored and updated by IBM to keep your cluster available.\n: Option to provision worker nodes as bare metal servers for compute-intensive workloads such as data, GPU, and AI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov"},{"document_id":"ibmcld_12725-0-1775","score":19.41723,"text":"\n\n\n\n\n\n\n  Change log: IBM Cloud Kubernetes Service Benchmark \n\nIn this change log, you can learn about the latest changes, improvements, and updates for the IBM Cloud Kubernetes Service profile. The change log lists changes that were made, ordered by the version number.\n\nTo work with this profile, you must connect an instance of [Workload Protection](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance=setup-workload-protection).\n\n\n\n  Profile versioning \n\nWhen specifications or controls are edited, removed from, or added to a profile in a way that is not compatible with the current version, a new version is released. To take advantage of the changes in a new version, update your attachments to use the newest profile version.\n\nThis profile is consistently updated and is not an exhaustive list of all the controls that might be required for every organization. Be sure to validate the available controls to determine where you might need to supplement your workloads with other security measures.\n\n\n\n  Active versions \n\nThe following table shows the service behavior changes for each version date. Switching to a later version date activates all changes that are introduced in earlier versions.\n\n\n\nTable. Active versions of the IBM Cloud Kubernetes Service Benchmark\n\n Version number   Release date \n\n Version 1.0.0    2023-07-12   \n\n\n\n\n\n\n\n\n\n  Version 1.0.0 \n\nNow available\n:   Released today, 12 July 2023, the IBM Cloud Kubernetes Service Benchmark is a collection of controls designed to validate the configuration of your Kubernetes Service clusters. This profile introduces the concept of wp-rule assessments. These are assessments that are defined by the Workload Protection service and imported into Security and Compliance Center.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-iks-profile"},{"document_id":"ibmcld_04810-7-1962","score":19.10101,"text":"\nDeployment Journey Overview \n\nIBM Cloud Kubernetes Service(IKS) is a managed offering to create your own Kubernetes cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\nWelcome to the Deployment Journey for Cloud Native on IBM Cloud! Use the sidebar on the left to navigate between the journey points.\n\n\n\n Journey Map \n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/b7b9235ce6abd45b66931867c388cf107d38e15b\/cloud-native-journey\/kubernetes-on-vpc\/images\/overview\/journey-map.png)\n\n\n\n\n\n Assumptions \n\nThis deployment guide will be assuming the following points. Please note that while your circumstance may not be exactly identical, you will still benefit from the overall journey steps and concepts covered in this guide.\n\n\n\n* You are already familar with the concepts introduced in the \"Tour IBM Cloud\" videos available on the [Getting Started with IBM Cloud](https:\/\/cloud.ibm.com\/cloud\/get-started) page.\n* Access groups will need to be defined so only certain users have the ability to create and manage the VPC network settings (i.e. CIDR ranges, Subnet ACLs rules, etc.).\n* When you create your cluster, you must choose a VPC networking setup so that certain cluster components can communicate with each other and with networks or services outside of the cluster.\n\n\n\n* Worker-to-worker communication: All worker nodes must be able to communicate with each other on the private network through VPC subnets.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-native-journey?topic=cloud-native-journey-cloud-native-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05998-7-2051","score":12.977597,"text":"\nUnderstanding IBM Cloud Kubernetes Service \n\nLearn more about [IBM Cloud\u00ae Kubernetes Service](https:\/\/www.ibm.com\/cloud\/kubernetes-service), its capabilities, and the options that are available to you to customize the cluster to your needs.\n\nReview frequently asked questions and key technologies that IBM Cloud Kubernetes Service uses.\n\n\n\n What is IBM Cloud Kubernetes Service and how does it work? \n\nIBM Cloud Kubernetes Service is a managed offering to create your own Kubernetes cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\n\n\n\n\n What is Kubernetes? \n\nKubernetes is an open source platform for managing containerized workloads and services across multiple hosts, and offers management tools for deploying, automating, monitoring, and scaling containerized apps with minimal to no manual intervention.\n\nZoom\n\n![Kubernetes certification badge](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/certified-kubernetes-color.svg)\n\nFigure 1. This badge indicates Kubernetes certification for IBM Cloud Container Service.\n\nThe open source project, Kubernetes, combines running a containerized infrastructure with production workloads, open source contributions, and Docker container management tools. The Kubernetes infrastructure provides an isolated and secure app platform for managing containers that is portable, extensible, and self-healing in case of a failover. For more information, see [What is Kubernetes?](https:\/\/www.ibm.com\/topics\/kubernetes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overview"},{"document_id":"ibmcld_16729-77369-79294","score":12.967516,"text":"\nThis tutorial walks you through the process setting up a continuous integration and delivery pipeline for containerized applications running on the Kubernetes Service. You will learn how to set up source control, then build, test and deploy the code to different deployment stages. Next, you will add integrations to other services like Slack notifications.\n\nKubernetes service Container Registry\n\n+1\n\nContinuous Delivery\n\n\n\n* 1 hour\n* 2023-05-08\n\n\n\n[Accelerate a dynamic website using Dynamic Content Acceleration](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-dynamic-content-cdn)Accelerate a dynamic website using Dynamic Content Acceleration\n\nWeb applications are composed of static content like text, images, cascading style sheets, and JavaScript files. The tutorial Accelerate delivery of static files using a CDN shows how to host and serve static assets (images, videos, and documents) of a website from IBM Cloud Object Storage with IBM\u00ae Content Delivery Network (CDN).\n\nContent Delivery Network (CDN) Kubernetes service\n\n+2\n\nContainer Registry,Domain Name Registration\n\n\n\n* 2 hours\n* 2023-06-14\n\n\n\n[Resilient and secure multi-region Kubernetes clusters with IBM Cloud Internet Services](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-multi-region-k8s-cis)Resilient and secure multi-region Kubernetes clusters with IBM Cloud Internet Services\n\nThis tutorial highlights how Cloud Internet Services (CIS), a uniform platform to configure and manage the Domain Name System (DNS), Global Load Balancing (GLB), Web Application Firewall (WAF), and protection against Distributed Denial of Service (DDoS) for internet applications, can be integrated with Kubernetes clusters to support this scenario and to deliver a secure and resilient solution across multiple locations.\n\nKubernetes service Container Registry\n\n+1\n\nCloud Internet Services (CIS)\n\n\n\n* 2 hours\n* 2023-05-10","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_16729-186060-188072","score":12.908387,"text":"\nThis tutorial highlights how Cloud Internet Services (CIS), a uniform platform to configure and manage the Domain Name System (DNS), Global Load Balancing (GLB), Web Application Firewall (WAF), and protection against Distributed Denial of Service (DDoS) for internet applications, can be integrated with Kubernetes clusters to support this scenario and to deliver a secure and resilient solution across multiple locations.\n\nKubernetes service Container Registry\n\n+1\n\nCloud Internet Services (CIS)\n\n\n\n* 2 hours\n* 2023-05-10\n\n\n\n[Deploy isolated workloads across multiple locations and zones](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-multi-region)Deploy isolated workloads across multiple locations and zones\n\nThis tutorial walks you through steps for setting up highly available and isolated workloads by provisioning IBM Cloud\u00ae Virtual Private Clouds (VPCs). You will create virtual server instances (VSIs) in multiple zones within one region to ensure the high availability of the application. You will create additional VSIs in a second region and configure a global load balancer (GLB) to provide high availability between regions and reduce network latency for users in different geographies.\n\nVirtual Private Cloud (VPC) Cloud Internet Services (CIS)\n\n+1\n\nSecrets Manager\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Centralize communication through a VPC Transit Hub and Spoke architecture - Part one](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-vpc-transit1)Centralize communication through a VPC Transit Hub and Spoke architecture - Part one\n\nA Virtual Private Cloud (VPC) provides network isolation and security in the IBM Cloud. A VPC can be a building block that encapsulates a corporate division (marketing, development, accounting, ...) or a collection of microservices owned by a DevSecOps team. VPCs can be connected to an on-premises enterprise and each other. This may create the need to route traffic through centralized firewall-gateway appliances.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_10287-7-1804","score":12.901235,"text":"\nUnderstanding Kubernetes storage basics \n\nBefore you get started with provisioning storage, it is important to understand the Kubernetes concepts for storage, dynamic provisioning, static provisioning, as well as the storage classes that are available to you.\n\n\n\n Persistent volumes and persistent volume claims \n\nBefore you get started with provisioning storage, it is important to understand the Kubernetes concepts of a persistent volume and a persistent volume claim and how they work together in a cluster.\n\nThe following image shows the storage components in a cluster.\n\nZoom\n\n![Storage components in a cluster.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/bce0f0917a9eea684d1b4b704ac6343a1f65f446\/openshift\/images\/cs_storage_pvc_pv.svg)\n\nFigure 1. Storage components in a cluster\n\nCluster\n: By default, every cluster is set up with a plug-in to [provision file storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-file_storageadd_file). You can choose to install other add-ons, such as the one for [block storage](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-block_storage). To use storage in a cluster, you must create a persistent volume claim, a persistent volume and a physical storage instance. When you delete the cluster, you have the option to delete related storage instances.\n\nApp\n: To read from and write to your storage instance, you must mount the persistent volume claim (PVC) to your app. Different storage types have different read-write rules. For example, you can mount multiple pods to the same PVC for file storage. Block storage comes with a RWO (ReadWriteOnce) access mode so that you can mount the storage to one pod only.\n\nPersistent volume claim (PVC)\n: A PVC is the request to provision persistent storage with a specific type and configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kube_concepts"},{"document_id":"ibmcld_05884-7-1809","score":12.883782,"text":"\nUnderstanding Kubernetes storage basics \n\nBefore you get started with provisioning storage, it is important to understand the Kubernetes concepts for storage, dynamic provisioning, static provisioning, as well as the storage classes that are available to you.\n\n\n\n Persistent volumes and persistent volume claims \n\nBefore you get started with provisioning storage, it is important to understand the Kubernetes concepts of a persistent volume and a persistent volume claim and how they work together in a cluster.\n\nThe following image shows the storage components in a cluster.\n\nZoom\n\n![Storage components in a cluster.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/cs_storage_pvc_pv.svg)\n\nFigure 1. Storage components in a cluster\n\nCluster\n: By default, every cluster is set up with a plug-in to [provision file storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-file_storageadd_file). You can choose to install other add-ons, such as the one for [block storage](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-block_storage). To use storage in a cluster, you must create a persistent volume claim, a persistent volume and a physical storage instance. When you delete the cluster, you have the option to delete related storage instances.\n\nApp\n: To read from and write to your storage instance, you must mount the persistent volume claim (PVC) to your app. Different storage types have different read-write rules. For example, you can mount multiple pods to the same PVC for file storage. Block storage comes with a RWO (ReadWriteOnce) access mode so that you can mount the storage to one pod only.\n\nPersistent volume claim (PVC)\n: A PVC is the request to provision persistent storage with a specific type and configuration.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kube_concepts"},{"document_id":"ibmcld_03824-7-1809","score":12.781413,"text":"\nKubernetes \n\nThe IBM Blockchain Platform allows you to provision blockchain components into your Kubernetes cluster. Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n\nKubernetes provides a container-centric management environment. It orchestrates computing, networking, and storage infrastructure on behalf of user workloads. This provides much of the simplicity of Platform as a Service (PaaS) with the flexibility of Infrastructure as a Service (IaaS), and enables portability across infrastructure providers.\n\nThe following diagram explains the architecture of Kubernetes. For more explanation about nodes, containers, and pod, see the [Key Kubernetes objects](https:\/\/cloud.ibm.com\/docs\/blockchain\/reference?topic=blockchain-k8s-overviewk8s-overview-key-obj) section below.\n\nZoom\n\n![Kubernetes architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/k8s-archi-diagram.svg)\n\nFigure 1. Kubernetes architecture diagram\n\n\n\n Key Kubernetes objects \n\n\n\n* Cluster\n\nA set of machines, called nodes, that run containerized applications managed by Kubernetes. A cluster has several worker nodes and at least one master node.\n* Node\n\nA node is a worker machine in Kubernetes. A node may be a VM or physical machine, depending on the cluster. Each node contains the services necessary to run pods and is managed by the master components. The services on a node include the container runtime, kubelet and kube-proxy. For more information, see the [Kubernetes Node section](https:\/\/kubernetes.io\/docs\/concepts\/architecture\/nodes\/) in the Kubernetes documentation.\n* Container\n\nA lightweight and portable executable image that contains software and all of its dependencies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain\/reference?topic=blockchain-k8s-overview"},{"document_id":"ibmcld_04145-12361-13925","score":12.770653,"text":"\nThe hostname in a Kubernetes ingress must consist of lower case alphanumeric characters, - or ., and must start and end with an alphanumeric character. Using _ in the load balancer name, though permitted, can cause an ingress error in Kubernetes clusters. We recommend that you not use - in the load balancer name to avoid issues with Kubernetes clusters.\n\n\n\n\n\n I got a 502 error attempting to save an Edge Functions Action, what do I do? \n\nContact [IBM support](https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-gettinghelp) and provide the script that you were attempting to save.\n\n\n\n\n\n How do I find my service instance ID? \n\nTo find your service instance ID, copy the CRN on the overview page. For example:\n\ncrn:v1:test:public:internet-svcs:global:a\/2c38d9a9913332006a27665dab3d26e8:836f33a5-d3e1-4bc6-876a-982a8668b1bb::\n\nThe last part of the CRN is your service instance: 836f33a5-d3e1-4bc6-876a-982a8668b1bb.\n\nAlternatively, you can click the row containing the CIS instance on the resource list main page and copy the GUID for the service instance ID.\n\n\n\n\n\n Does CIS compress resources? \n\nYes, CIS applies \"gzip\" and \"brotli\" compression to some types of content. CIS also compresses items based on the browser's UserAgent to speed up page loading time.\n\nIf you're already using gzip CIS honors your gzip settings as long as you're passing the details in a header from your web server for the files.\n\nCIS only supports the content type \"gzip\" towards your origin server and can also only deliver content either gzip-compressed, brotli-compressed, or not compressed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-faq"},{"document_id":"ibmcld_04186-2976-4733","score":12.767364,"text":"\n* own a custom domain so you can configure the DNS for this domain to point to IBM Cloud Internet Services name servers.\n* and [understand the basics of Kubernetes](https:\/\/kubernetes.io\/docs\/tutorials\/kubernetes-basics\/).\n\n\n\n\n\n\n\n Step 1: Deploy an application to one location \n\nThis tutorial deploys a Kubernetes application to clusters in multiple locations. You will start with one location, Dallas, and then repeat these steps for London.\n\n\n\n Create a Kubernetes cluster \n\nA minimal cluster with one (1) zone, one (1) worker node and the smallest available size (Flavor) is sufficient for this tutorial.\n\nWhen creating the Kubernetes cluster below:\n\n\n\n1. Set Cluster name to my-us-cluster.\n2. Locate in North America and Dallas\n\n\n\nOpen the [Kubernetes clusters](https:\/\/cloud.ibm.com\/kubernetes\/clusters) and click Create cluster. See the documentation referenced below for more details based on the cluster type. Summary:\n\n\n\n* Click Standard tier cluster\n* For Kubernetes on VPC infrastructure see reference documentation [Creating VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2&interface=ui).\n\n\n\n* Click Create VPC:\n\n\n\n* Enter a name for the VPC.\n* Chose the same resource group as the cluster.\n* Click Create.\n\n\n\n* Attach a Public Gateway to each of the subnets that you create:\n\n\n\n* Navigate to the [Virtual private clouds](https:\/\/cloud.ibm.com\/vpc-ext\/network\/vpcs).\n* Click the previously created VPC used for the cluster.\n* Scroll down to subnets section and click a subnet.\n* In the Public Gateway section, click Detached to change the state to Attached.\n* Click the browser back button to return to the VPC details page.\n* Repeat the previous three steps to attach a public gateway to each subnet.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-multi-region-k8s-cis"},{"document_id":"ibmcld_01391-2981-4738","score":12.767364,"text":"\n* own a custom domain so you can configure the DNS for this domain to point to IBM Cloud Internet Services name servers.\n* and [understand the basics of Kubernetes](https:\/\/kubernetes.io\/docs\/tutorials\/kubernetes-basics\/).\n\n\n\n\n\n\n\n Step 1: Deploy an application to one location \n\nThis tutorial deploys a Kubernetes application to clusters in multiple locations. You will start with one location, Dallas, and then repeat these steps for London.\n\n\n\n Create a Kubernetes cluster \n\nA minimal cluster with one (1) zone, one (1) worker node and the smallest available size (Flavor) is sufficient for this tutorial.\n\nWhen creating the Kubernetes cluster below:\n\n\n\n1. Set Cluster name to my-us-cluster.\n2. Locate in North America and Dallas\n\n\n\nOpen the [Kubernetes clusters](https:\/\/cloud.ibm.com\/kubernetes\/clusters) and click Create cluster. See the documentation referenced below for more details based on the cluster type. Summary:\n\n\n\n* Click Standard tier cluster\n* For Kubernetes on VPC infrastructure see reference documentation [Creating VPC clusters](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-create-vpc-gen2&interface=ui).\n\n\n\n* Click Create VPC:\n\n\n\n* Enter a name for the VPC.\n* Chose the same resource group as the cluster.\n* Click Create.\n\n\n\n* Attach a Public Gateway to each of the subnets that you create:\n\n\n\n* Navigate to the [Virtual private clouds](https:\/\/cloud.ibm.com\/vpc-ext\/network\/vpcs).\n* Click the previously created VPC used for the cluster.\n* Scroll down to subnets section and click a subnet.\n* In the Public Gateway section, click Detached to change the state to Attached.\n* Click the browser back button to return to the VPC details page.\n* Repeat the previous three steps to attach a public gateway to each subnet.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"},{"document_id":"ibmcld_05998-3108-5122","score":12.739109,"text":"\nKubernetes resources include services, deployments, and pods. For more information, see [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch).\n\nNamespace\n: Kubernetes namespaces are a way to divide your cluster resources into separate areas that you can deploy apps and restrict access to, such as if you want to share the cluster with multiple teams. For example, system resources that are configured for you are kept in separate namespaces like kube-system or ibm-system. If you don't designate a namespace when you create a Kubernetes resource, the resource is automatically created in the default namespace. For more information, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/concepts\/overview\/working-with-objects\/namespaces\/).\n\nService\n: A service is a Kubernetes resource that groups a set of pods and provides network connectivity to these pods without exposing the actual private IP address of each pod. You can use a service to make your app available within your cluster or to the public internet. For more information, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/concepts\/services-networking\/service\/).\n\nDeployment\n: A deployment is a Kubernetes resource where you might specify information about other resources or capabilities that are required to run your app, such as services, persistent storage, or annotations. You document a deployment in a configuration YAML file, and then apply it to the cluster. The Kubernetes master configures the resources and deploys containers into pods on the worker nodes with available capacity.\n: Define update strategies for your app, including the number of pods that you want to add during a rolling update and the number of pods that can be unavailable at a time. When you perform a rolling update, the deployment checks whether the update is working and stops the rollout when failures are detected.\n: A deployment is just one type of workload controller that you can use to manage pods.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-overview"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05666-7-2151","score":20.645445,"text":"\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like IBM Cloud\u00ae Kubernetes Service, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith IBM Cloud Kubernetes Service clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-costs"},{"document_id":"ibmcld_07578-373434-375500","score":20.232353,"text":"\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-373408-375474","score":20.232353,"text":"\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n* Can I get a free cluster?\n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days. Free clusters are ideal for testing out Kubernetes deployments and getting familiar with the IBM Cloud Kubernetes Service API, CLI, and console tools. After you are done testing your free cluster, you can [copy your configuration files and redeploy them to a standard cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_appcopy_apps_cluster).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_05707-7-2073","score":19.684082,"text":"\nBenefits and service offerings \n\n[IBM Cloud\u00ae Kubernetes Service](https:\/\/www.ibm.com\/cloud\/kubernetes-service) delivers powerful tools by combining Docker containers, the Kubernetes technology, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts. For more information about certification, see [Compliance on the IBM Cloud](https:\/\/www.ibm.com\/cloud\/compliance).\n\n\n\n Benefits of using the service \n\nClusters are deployed on compute hosts that provide native Kubernetes and IBM-specific capabilities.\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud. For more information, see Comparison between [Red Hat OpenShift](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovopenshift_kubernetes) and community Kubernetes clusters.\n\nSingle-tenant Kubernetes clusters with compute, network, and storage infrastructure isolation\n: Create your own customized infrastructure that meets the requirements of your organization.\n: Choose between [IBM Cloud Classic or VPC infrastructure providers](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-infrastructure_providers).\n: Provision a dedicated and secured Kubernetes master, worker nodes, virtual networks, and storage by using the resources provided by IBM Cloud infrastructure.\n: Fully managed Kubernetes master that is continuously monitored and updated by IBM to keep your cluster available.\n: Option to provision worker nodes as bare metal servers for compute-intensive workloads such as data, GPU, and AI.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov"},{"document_id":"ibmcld_06128-7-1993","score":19.662981,"text":"\nMoving your environment to IBM Cloud Kubernetes Service \n\nWith IBM Cloud\u00ae Kubernetes Service, you can quickly and securely deploy container workloads for your apps in production. Learn more so that when you plan your cluster strategy, you optimize your setup to make the most of [Kubernetes](https:\/\/kubernetes.io\/) automated deploying, scaling, and orchestration management capabilities.\n\n\n\n Moving your workloads to the IBM Cloud \n\nYou have lots of reasons to move your workloads to IBM Cloud: reducing total cost of ownership, increasing high availability for your apps in a secure and compliant environment, scaling up and down in respond to your user demand, and many more. IBM Cloud Kubernetes Service combines container technology with open source tools, such as Kubernetes so that you can build a cloud-native app that can migrate across different cloud environments, avoiding vendor lock-in.\n\nBut how do you get to the cloud? What are your options along the way? And how do you manage your workloads after you get there?\n\nUse this page to learn some strategies for your Kubernetes deployments on IBM Cloud Kubernetes Service. And engage with our team on [Slack](https:\/\/ibm-cloud-success.slack.com).\n\nNot on slack yet? [!Request an invite](https:\/\/cloud.ibm.com\/kubernetes\/slack)\n\n\n\n What can I move to the IBM Cloud? \n\nWith IBM Cloud, you have flexibility to create Kubernetes clusters in [off-premises, on-premises, or hybrid cloud environments](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovdifferentiation). The following table provides some examples of what types of workloads that users typically move to the various types of clouds. You might also choose a hybrid approach where you have clusters that run in both environments.\n\n\n\nIBM Cloud implementations support your workloads\n\n Workload Kubernetes Service off-prem on-prem \n\n DevOps enablement tools Yes \n Developing and testing apps Yes \n Apps have major shifts in demand and need to scale rapidly Yes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-strategy"},{"document_id":"ibmcld_05777-1455-3483","score":19.643784,"text":"\nYour worker nodes are controlled by a highly available Kubernetes master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ov).\n\n\n\n\n\n Why should I use IBM Cloud Kubernetes Service? \n\nIBM Cloud Kubernetes Service is a managed Kubernetes offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, IBM Cloud Kubernetes Service provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_ovbenefits).\n\n\n\n\n\n Can I get a free cluster? \n\nThe free tier option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https:\/\/www.ibm.com\/account\/reg\/us-en\/signup?formid=MAIL-wcp).\n\nYou can have 1 free cluster at a time in IBM Cloud Kubernetes Service, and each free cluster expires in 30 days.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-faqs"},{"document_id":"ibmcld_04085-7-1799","score":19.63118,"text":"\nKubernetes \n\nThe IBM Blockchain Platform allows you to provision blockchain components into your Kubernetes cluster. Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n\nKubernetes provides a container-centric management environment. It orchestrates computing, networking, and storage infrastructure on behalf of user workloads. This provides much of the simplicity of Platform as a Service (PaaS) with the flexibility of Infrastructure as a Service (IaaS), and enables portability across infrastructure providers.\n\nThe following diagram explains the architecture of Kubernetes. For more explanation about nodes, containers, and pod, see the [Key Kubernetes objects](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-k8s-overviewk8s-overview-key-obj) section below.\n\nZoom\n\n![Kubernetes architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/k8s-archi-diagram.svg)\n\nFigure 1. Kubernetes architecture diagram\n\n\n\n Key Kubernetes objects \n\n\n\n* Cluster\n\nA set of machines, called nodes, that run containerized applications managed by Kubernetes. A cluster has several worker nodes and at least one master node.\n* Node\n\nA node is a worker machine in Kubernetes. A node may be a VM or physical machine, depending on the cluster. Each node contains the services necessary to run pods and is managed by the master components. The services on a node include the container runtime, kubelet and kube-proxy. For more information, see the [Kubernetes Node section](https:\/\/kubernetes.io\/docs\/concepts\/architecture\/nodes\/) in the Kubernetes documentation.\n* Container\n\nA lightweight and portable executable image that contains software and all of its dependencies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-k8s-overview"},{"document_id":"ibmcld_03824-7-1809","score":19.558445,"text":"\nKubernetes \n\nThe IBM Blockchain Platform allows you to provision blockchain components into your Kubernetes cluster. Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n\nKubernetes provides a container-centric management environment. It orchestrates computing, networking, and storage infrastructure on behalf of user workloads. This provides much of the simplicity of Platform as a Service (PaaS) with the flexibility of Infrastructure as a Service (IaaS), and enables portability across infrastructure providers.\n\nThe following diagram explains the architecture of Kubernetes. For more explanation about nodes, containers, and pod, see the [Key Kubernetes objects](https:\/\/cloud.ibm.com\/docs\/blockchain\/reference?topic=blockchain-k8s-overviewk8s-overview-key-obj) section below.\n\nZoom\n\n![Kubernetes architecture diagram](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/c5288bed34c3820e3a5251d820ee91adcd2591a3\/blockchain\/images\/k8s-archi-diagram.svg)\n\nFigure 1. Kubernetes architecture diagram\n\n\n\n Key Kubernetes objects \n\n\n\n* Cluster\n\nA set of machines, called nodes, that run containerized applications managed by Kubernetes. A cluster has several worker nodes and at least one master node.\n* Node\n\nA node is a worker machine in Kubernetes. A node may be a VM or physical machine, depending on the cluster. Each node contains the services necessary to run pods and is managed by the master components. The services on a node include the container runtime, kubelet and kube-proxy. For more information, see the [Kubernetes Node section](https:\/\/kubernetes.io\/docs\/concepts\/architecture\/nodes\/) in the Kubernetes documentation.\n* Container\n\nA lightweight and portable executable image that contains software and all of its dependencies.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain\/reference?topic=blockchain-k8s-overview"},{"document_id":"ibmcld_13139-7-2067","score":19.337626,"text":"\nResilient and secure multi-region Kubernetes clusters with IBM Cloud Internet Services \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nUsers are less likely to experience downtime when an application is designed with resiliency in mind. When implementing a solution with Kubernetes Service, you benefit from built-in capabilities, like load balancing and isolation, increased resiliency against potential failures with hosts, networks, or apps. By creating multiple clusters and if an outage occurs with one cluster, users can still access an app that is also deployed in another cluster. With multiple clusters in different locations, users can also access the closest cluster and reduce network latency. For additional resiliency, you have the option to also select the multi-zone clusters, meaning your nodes are deployed across multiple zones within a location.\n\nThis tutorial highlights how Cloud Internet Services (CIS), a uniform platform to configure and manage the Domain Name System (DNS), Global Load Balancing (GLB), Web Application Firewall (WAF), and protection against Distributed Denial of Service (DDoS) for internet applications, can be integrated with Kubernetes clusters to support this scenario and to deliver a secure and resilient solution across multiple locations.\n\n\n\n Objectives \n\n\n\n* Deploy an application on multiple Kubernetes clusters in different locations.\n* Distribute traffic across multiple clusters with a Global Load Balancer.\n* Route users to the closest cluster.\n* Protect your application from security threats.\n* Increase application performance with caching.\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f84e2238288b7f0355715a4c355609ce7ac48fb0\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/Architecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The developer builds a Docker image for the application.\n2. The image is pushed to a Container Registry.\n3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-multi-region-k8s-cis"},{"document_id":"ibmcld_01391-7-2065","score":19.323809,"text":"\nResilient and secure multi-region Kubernetes clusters with IBM Cloud Internet Services \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nUsers are less likely to experience downtime when an application is designed with resiliency in mind. When implementing a solution with Kubernetes Service, you benefit from built-in capabilities, like load balancing and isolation, increased resiliency against potential failures with hosts, networks, or apps. By creating multiple clusters and if an outage occurs with one cluster, users can still access an app that is also deployed in another cluster. With multiple clusters in different locations, users can also access the closest cluster and reduce network latency. For additional resiliency, you have the option to also select the multi-zone clusters, meaning your nodes are deployed across multiple zones within a location.\n\nThis tutorial highlights how Cloud Internet Services (CIS), a uniform platform to configure and manage the Domain Name System (DNS), Global Load Balancing (GLB), Web Application Firewall (WAF), and protection against Distributed Denial of Service (DDoS) for internet applications, can be integrated with Kubernetes clusters to support this scenario and to deliver a secure and resilient solution across multiple locations.\n\n\n\n Objectives \n\n\n\n* Deploy an application on multiple Kubernetes clusters in different locations.\n* Distribute traffic across multiple clusters with a Global Load Balancer.\n* Route users to the closest cluster.\n* Protect your application from security threats.\n* Increase application performance with caching.\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cbb80bf851fb762a838129cba09d5674f8bfffda\/Registry\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/Architecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The developer builds a Docker image for the application.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.6666666667,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":0.0,"ndcg_cut_3":0.530721274,"ndcg_cut_5":0.530721274,"ndcg_cut_10":0.530721274}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_10505-11399-13334","score":16.391907,"text":"\nCompliance to industry standards varies depending on the infrastructure provider of the cluster, such as classic or VPC.<br> * Monitor, isolate, and recover the cluster master.<br> * Provide highly available replicas of the Kubernetes master API server, etcd, scheduler, and controller manager components to protect against a master outage.<br> * Monitor and report the health of the master and worker nodes in the various interfaces.<br> * Automatically apply master security patch updates, and provide worker node security patch updates.<br> * Enable certain security settings, such as encrypted disks on worker nodes.<br> * Disable certain insecure actions for worker nodes, such as not permitting users to SSH into the host.<br> * Encrypt communication between the master and worker nodes with TLS.<br> * Provide CIS-compliant Linux images for worker node operating systems.<br> * Continuously monitor master and worker node images to detect vulnerability and security compliance issues.<br> * Provision worker nodes with two local SSD, AES 256-bit encrypted data partitions.<br> * Provide options for cluster network connectivity, such as public and private cloud service endpoints.<br> * Provide options for compute isolation, such as dedicated virtual machines or bare metal.<br> * Integrate Kubernetes role-based access control (RBAC) with IBM Cloud Identity and Access Management (IAM).<br><br><br> <br><br> * Set up and maintain security and regulation compliance for your apps and data. For example, choose how to set up your [cluster network](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_clusters), [protect sensitive information](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryption) such as with IBM Key Protect encryption, and configure further [security settings](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity) to meet your workload's security and compliance needs.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-satellite-responsibilities"},{"document_id":"ibmcld_05999-7882-10247","score":16.133867,"text":"\n* The master is publicly accessible to authorized cluster users only through the public cloud service endpoint. Your cluster users can securely access your Kubernetes master over the internet to run kubectl commands, for example.\n\n\n\n\n\n\n\n Public and private cloud service endpoints \n\nTo make your master publicly or privately accessible to cluster users, you can enable the public and private cloud service endpoints. VRF is required in your IBM Cloud account, and you must enable your account to use service endpoints. To enable VRF and service endpoints, run ibmcloud account update --service-endpoint-enable true.\n\n\n\n* If worker nodes are connected to public and private VLANs, communication between worker nodes and master is established over both the private network through the private cloud service endpoint and the public network through the public cloud service endpoint. By routing half of the worker-to-master traffic over the public endpoint and half over the private endpoint, your master-to-worker communication is protected from potential outages of the public or private network. If worker nodes are connected to private VLANs only, communication between worker nodes and master is established over the private network through the private cloud service endpoint only.\n* The master is publicly accessible to authorized cluster users through the public cloud service endpoint. The master is privately accessible through the private cloud service endpoint if authorized cluster users are in your IBM Cloud private network or are connected to the private network through a VPN connection or IBM Cloud Direct Link. Note that you must [expose the master endpoint through a private load balancer](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_clusteraccess_private_se) so that users can access the master through a VPN or IBM Cloud Direct Link connection.\n* You can optionally secure access to your private cloud service endpoint by creating a subnet allowlist. Only authorized requests to your cluster master that originate from subnets in the allowlist are permitted through the cluster's private cloud service endpoint. For more information, see [Creating an allowlist for the private cloud service endpoint](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_clusterprivate-se-allowlist).\n\n\n\n\n\n\n\n Private service endpoint only","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_basics"},{"document_id":"ibmcld_06057-11447-12770","score":15.9924555,"text":"\nCompliance to industry standards varies depending on the infrastructure provider of the cluster, such as classic or VPC.<br> * Monitor, isolate, and recover the cluster master.<br> * Provide highly available replicas of the Kubernetes master API server, etcd, scheduler, and controller manager components to protect against a master outage.<br> * Provide options for cluster network connectivity, such as public and private cloud service endpoints.<br> * Provide options for compute isolation, such as dedicated virtual machines or bare metal.<br> * Integrate Kubernetes role-based access control (RBAC) with IBM Cloud Identity and Access Management (IAM).<br><br><br> <br><br> * Set up and maintain security and regulation compliance for your apps and data. For example, choose how to set up your [cluster network](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-plan_clusters), [protect sensitive information](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-encryption) such as with IBM Key Protect encryption, and configure further [security settings](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitysecurity) to meet your workload's security and compliance needs. If applicable, configure your [firewall](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-firewallfirewall).<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-responsibilities_iks"},{"document_id":"ibmcld_10488-11431-12746","score":15.898526,"text":"\nCompliance to industry standards varies depending on the infrastructure provider of the cluster, such as classic or VPC.<br> * Monitor, isolate, and recover the cluster master.<br> * Provide highly available replicas of the Kubernetes master API server, etcd, scheduler, and controller manager components to protect against a master outage.<br> * Provide options for cluster network connectivity, such as public and private cloud service endpoints.<br> * Provide options for compute isolation, such as dedicated virtual machines or bare metal.<br> * Integrate Kubernetes role-based access control (RBAC) with IBM Cloud Identity and Access Management (IAM).<br><br><br> <br><br> * Set up and maintain security and regulation compliance for your apps and data. For example, choose how to set up your [cluster network](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_clusters), [protect sensitive information](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-encryption) such as with IBM Key Protect encryption, and configure further [security settings](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-securitysecurity) to meet your workload's security and compliance needs. If applicable, configure your [firewall](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-firewallfirewall).<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-responsibilities_iks"},{"document_id":"ibmcld_06063-3142-5113","score":15.8886795,"text":"\nBy default, Kubernetes requires every request to go through several stages before access to the API server is granted.\n\nAuthentication\n: Validates the identity of a registered user or service account.\n\nAuthorization\n: Limits the permissions of authenticated users and service accounts to ensure that they can access and operate only the cluster components that you want them to.\n\nAdmission control\n: Validates or mutates requests before they are processed by the Kubernetes API server. Many Kubernetes features require admission controllers to properly function.\n\n\n\n\n\n What does IBM Cloud Kubernetes Service do to secure my API server and etcd data store? \n\nThe following image shows the default cluster security settings that address authentication, authorization, admission control, and secure connectivity between the Kubernetes master and worker nodes.\n\nZoom\n\n![Describes the security stages when you access the Kubernetes API server.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7\/containers\/images\/cs_security_apiserver_access.png)\n\nFigure 1. Security stages when accessing the Kubernetes API server\n\nReview the following security features for Kubernetes API server and etcd.\n\nFully managed and dedicated Kubernetes master\n: Every cluster in IBM Cloud Kubernetes Service is controlled by a dedicated Kubernetes master that is managed by IBM in an IBM-owned IBM Cloud account. The Kubernetes master is set up with the following dedicated components that are not shared with other IBM customers.\n\n\n\n* etcd data store: Stores all Kubernetes resources of a cluster, such as Services, Deployments, and Pods. Kubernetes ConfigMaps and Secrets are app data that is stored as key value pairs so that they can be used by an app that runs in a pod. Data in etcd is stored on the local disk of the Kubernetes master and is backed up to IBM Cloud Object Storage. Data is encrypted during transit to IBM Cloud Object Storage and at rest.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_06063-7869-9744","score":15.830969,"text":"\nThese certificates are never shared across clusters or across Kubernetes master components.\n\nNeed to revoke existing certificates and create new certificates for your cluster? Check out [Rotating CA certificates in your cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-securitycert-rotate).\n\nConnectivity to worker nodes\n: Although Kubernetes secures the communication between the master and worker nodes by using the https protocol, no authentication is provided on the worker node by default. To secure this communication, IBM Cloud Kubernetes Service automatically sets up an Konnectivity connection between the Kubernetes master and the worker node when the cluster is created.\n\nFine-grained access control\n: As the account administrator you can [grant access to other users for IBM Cloud Kubernetes Service](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-usersusers) by using IBM Cloud Identity and Access Management (IAM). IBM Cloud IAM provides secure authentication with the IBM Cloud platform, IBM Cloud Kubernetes Service, and all the resources in your account. Setting up proper user roles and permissions is key to limiting who can access your resources and to limiting the damage that a user can do when legitimate permissions are misused. You can select from the following pre-defined user roles that determine the set of actions that the user can perform:\n\n\n\n* Platform access roles: Determine the cluster and worker node management-related actions that a user can perform in IBM Cloud Kubernetes Service.\n* Service access roles: Determine the [Kubernetes RBAC role](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/rbac\/) that is assigned to the user and the actions that a user can run against the Kubernetes API server. With RBAC roles, users can create Kubernetes resources, such as app deployments, namespaces, or configmaps.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-security"},{"document_id":"ibmcld_05527-39945-41302","score":15.775596,"text":"\nCluster health image Master v1.1.5 v1.1.8 Additional status information is included when an add-on health state is critical. Improved performance when handling cluster status updates. \n Cluster master operations Master N\/A N\/A Cluster master operations such as refresh or update are now canceled if a broken [Kubernetes admission webhook](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/extensible-admission-controllers\/) is detected. \n etcd Master v3.3.20 v3.3.22 See the [etcd release notes](https:\/\/github.com\/etcd-io\/etcd\/releases\/v3.3.22). \n GPU device plug-in and installer Master 8b02302 31d4bb6 Updated image for [CVE-2020-3810](https:\/\/cve.mitre.org\/cgi-bin\/cvename.cgi?name=CVE-2020-3810). \n IBM Cloud File Storage for Classic plug-in Master 373 375 Fixed a bug that might cause error handling to create additional persistent volumes. \n IBM Cloud Provider Master v1.16.10-243 v1.16.11-267 Updated to support the Kubernetes 1.16.11 release. Updated the version 2.0 private network load balancers (NLBs) to manage Calico global network policies. Updated calicoctl version to 3.9.6. \n Kubernetes Both v1.16.10 v1.16.11 See the [Kubernetes release notes](https:\/\/github.com\/kubernetes\/kubernetes\/releases\/tag\/v1.16.11). The master update resolves CVE-2020-8558 (see the [IBM security bulletin](https:\/\/www.ibm.com\/support\/pages\/node\/6249905)).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-116_changelog"},{"document_id":"ibmcld_10510-12295-14132","score":15.719616,"text":"\nWhen you create a cluster, Red Hat OpenShift on IBM Cloud automatically installs the default [Kubernetes admission controllers](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/admission-controllers\/) in a particular order in the Red Hat OpenShift master, which can't be changed by the user. Review the order of default admission controllers by cluster version in the [kube-apiserver component reference information](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-service-settingskube-apiserver).\n\nYou can [install your own admission controllers in the cluster](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/extensible-admission-controllers\/admission-webhooks) or choose an optional admission controller, such as [Portieris](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-imagesportieris-image-sec). With Portieris, you can block container deployments from unsigned images.\n\nIf you manually installed admission controllers and you don't want to use them anymore, make sure to remove them entirely. If admission controllers are not entirely removed, they might block all actions that you want to perform on the cluster.\n\n\n\n\n\n What else can I do to secure my API server? \n\nYou can restrict connections to the master nodes by enabling the private cloud service endpoint, and creating a subnet allowlist. This combination provides the greatest degree of isolation.. Note that your options for service endpoints vary based on your cluster's Red Hat OpenShift version and infrastructure provider. For more information about service endpoints, see worker-to-master and user-to-master communication in [classic clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_basicsworkeruser-master) and [VPC clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-plan_vpc_basicsvpc-workeruser-master).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-security"},{"document_id":"ibmcld_01391-7-2065","score":15.714379,"text":"\nResilient and secure multi-region Kubernetes clusters with IBM Cloud Internet Services \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nUsers are less likely to experience downtime when an application is designed with resiliency in mind. When implementing a solution with Kubernetes Service, you benefit from built-in capabilities, like load balancing and isolation, increased resiliency against potential failures with hosts, networks, or apps. By creating multiple clusters and if an outage occurs with one cluster, users can still access an app that is also deployed in another cluster. With multiple clusters in different locations, users can also access the closest cluster and reduce network latency. For additional resiliency, you have the option to also select the multi-zone clusters, meaning your nodes are deployed across multiple zones within a location.\n\nThis tutorial highlights how Cloud Internet Services (CIS), a uniform platform to configure and manage the Domain Name System (DNS), Global Load Balancing (GLB), Web Application Firewall (WAF), and protection against Distributed Denial of Service (DDoS) for internet applications, can be integrated with Kubernetes clusters to support this scenario and to deliver a secure and resilient solution across multiple locations.\n\n\n\n Objectives \n\n\n\n* Deploy an application on multiple Kubernetes clusters in different locations.\n* Distribute traffic across multiple clusters with a Global Load Balancer.\n* Route users to the closest cluster.\n* Protect your application from security threats.\n* Increase application performance with caching.\n\n\n\nZoom\n\n![Architecture](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/cbb80bf851fb762a838129cba09d5674f8bfffda\/Registry\/includes\/solution-tutorials\/includes\/solution-tutorials\/images\/solution32-multi-region-k8s-cis\/Architecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The developer builds a Docker image for the application.\n2.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/Registry?topic=Registry-multi-region-k8s-cis"},{"document_id":"ibmcld_05638-5445-7278","score":15.6856785,"text":"\nThe Kubernetes API server that runs in your Kubernetes master is being updated to a new Kubernetes API version. During the update, you can still access and change the cluster. However, you cannot initiate concurrent master operations, such as enabling API server auditing. Worker nodes, apps, and resources that the user deployed aren't modified and continue to run. Wait for the update to complete to review the health of your cluster.\n\n\n\n\n\n Unsupported \n\nReview the following description of the Unsupported cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nThe [Kubernetes version](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionscs_versions) that the cluster runs is no longer supported. Your cluster's health is no longer actively monitored or reported. Additionally, you can't add or reload worker nodes. To continue receiving important security updates and support, you must update your cluster. Review the [version update preparation actions](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsprep-up), then [update your cluster](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate) to a supported Kubernetes version.\n\n\n\n\n\n Warning \n\nReview the following description of the Warning cluster state. To view the state of your cluster, run ibmcloud ks cluster get --cluster <cluster_name_or_ID>.\n\nAt least one worker node in the cluster is not available, but other worker nodes are available and can take over the workload. Try to [reload](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-kubernetes-service-clics_worker_reload) the unavailable worker nodes. - Your cluster has zero worker nodes, such as if you created a cluster without any worker nodes or manually removed all the worker nodes from the cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cluster-states-reference"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"4c86c8740c3d49e06b7aca9d308119fa<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_05818-4001-4896","score":19.292078,"text":"\nFor the Problem type, search for or select Kubernetes Service.\n6. For the Case details, provide a descriptive title and include the details that you previously gathered. From the Resources, you can also select the cluster that the issue is related to.\n\n\n\n\n\n\n\n Requesting access to allowlisted features \n\n\n\n1. [Create a ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form).\n2. On the Category tab, select Account\n3. On the Topic tab, select the Other subtopic and click Next.\n4. On the Details tab, in the Subject field, enter Allowlist request for <FEATURE> for account <ACCOUNTID> and include the feature name and your account ID.\n5. In the Description field, include details about the feature that you want access to.\n6. Click Next and review your selections ticket.\n7. Click Submit case.\n8. After support processes the ticket, you will receive a notification that your account is updated.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help"},{"document_id":"ibmcld_05846-13861-15174","score":16.675425,"text":"\nUsers with a service access role to IBM Cloud Kubernetes Service in IAM are given [corresponding user roles in RBAC](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-iam-service-access-rolesrbac_ref). The RBAC user details include a unique issuer ID, subject identifier claim, and Kubernetes username. These details vary with the Kubernetes version of the cluster. When you update a cluster from a previous version, the details are automatically updated. RBAC usernames are prefixed by IAM. For more information about how OpenID authentication works, see the [Kubernetes documentation](https:\/\/kubernetes.io\/docs\/reference\/access-authn-authz\/authentication\/).\n\nYou might use this information if you build automation tooling within the cluster that relies on the user details to authenticate with the Kubernetes API server.\n\n\n\nIBM Cloud IAM issuer details for RBAC users\n\n Version Issuer Claim Casing* \n\n 1.18 or later https:\/\/iam.cloud.ibm.com\/identity realmed_sub_<account_ID> lowercase \n 1.17 https:\/\/iam.cloud.ibm.com\/identity sub_<account_ID> lowercase \n 1.10 - 1.16 https:\/\/iam.bluemix.net\/identity sub_<account_ID> lowercase \n 1.9 or earlier https:\/\/iam.ng.bluemix.net\/kubernetes sub camel case \n\n\n\n: An example of lowercase is user.name@company.com. An example of camel case is User.Name@company.com.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-iam-service-access-roles"},{"document_id":"ibmcld_04077-10869-12689","score":16.608536,"text":"\nFor instructions on how to update Kubernetes, see [Updating clusters, worker nodes, and cluster components](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-updateupdate). For the list of IBM Cloud Kubernetes Service supported versions and expiration dates see the [release history](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_versionsrelease-history).\n\nYou must wait for the update to complete before you can [resume the IBM Blockchain Platform deployment](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iks-icibp-v2-deploy-iks-steps).\n\n\n\n\n\n How to assign Kubernetes access roles \n\nThe user who links the blockchain service instance to the Kubernetes cluster must have the Administrator and Manager roles in Kubernetes. To configure this access you must complete the following steps:\n\n1. In the IBM Cloud dashboard, click the Manage drop-down list, then Access (IAM).\n2. In the left navigation menu, click Users and click the ID of user who will link the service instance to the Kubernetes cluster.\n3. Click Access Policies, then Assign access.\n4. Click the tile Assign access to resources.\n5. In the Services drop-down list, select Kubernetes Service.\n6. Check the Administrator and Manager roles for this user.\n7. Click Assign.\n\nFor more information about Kubernetes access control, see [how to pick the right access policy and role for your users](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-userschecking-perms).\n\n\n\n\n\n Post-install instructions \n\nAfter you deploy your console, you can click the Launch the IBM Blockchain Platform button to open the console in your browser. You can add the console URL as a bookmark to your browser.\n\n\n\n Returning to your console from IBM Cloud \n\nIf you don't have the console URL, you can find it from your IBM Cloud dashboard.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iks-ic"},{"document_id":"ibmcld_15469-0-2119","score":16.324963,"text":"\n\n\n\n\n\n\n  Getting help and support \n\nDepending on the level of help you need, use the following information to sign up for Slack communication or open an IBM support case.\n\n\n\n  Slack channel \n\nWe actively monitor our Slack channel for questions about VPC infrastructure services. Join a community of customers and IBM employees where you can ask questions or discuss IBM Cloud VPC releases.\n\nTo sign up, complete the following steps.\n\n\n\n1.  Request to [join the public Slack channel](https:\/\/cloud.ibm.com\/kubernetes\/slack).\n2.  Next, [sign in to Slack](https:\/\/ibm-cloud-success.slack.com).\n3.  Finally, join our virtual-private-cloud channel.\n\n\n\n\n\n\n\n  Support cases \n\nFor more information about opening an IBM support cases, or about support levels and case severities, see [Contacting support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\nIf you need to open a support case, collect as much information as possible to help Support analyze and diagnose your problem.\n\nFor UI issues:\n\n\n\n*  Provide error codes and reference IDs.\n*  Save the full URL of the console when the problem occurred, for example: https:\/\/cloud.ibm.com\/vpc-ext\/provision\/vs\n*  Include steps to reproduce the issue, along with your inputs and expected outputs.\n*  Note the approximate time that the error occurred.\n*  Provide the code version and error details:\n\n\n\n1.  Right-click the console page and select the Inspect or Inspect Element option.\n2.  Click the Console tab and copy the version information at the beginning of the output (Project, Version, Build Time, and so on).\n3.  Scroll to the end of the output and copy any errors or stack traces.\n\n\n\n*  Provide the network response:\n\n\n\n1.  While you inspect the page, click the Network tab.\n2.  Refresh the page and reproduce the problem.\n3.  Filter all requests by the word \"graph\".\n4.  Starting at the end of the list, click each request and view the Preview tab. If the request has an \"errors\" node, expand that node to show the full error.\n5.  Click the Response tab and include the full response string and the URL that generated the response.\n\n\n\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-getting-help&interface=cli"},{"document_id":"ibmcld_03994-5802-7727","score":16.274559,"text":"\n* Kubernetes service integration. Leverage services such as IBM Log Analysis for logging and Prometheus and IBM Cloud Monitoring for monitoring. Leverage the built-in IBM Cloud services, such as IBM Cloud Kubernetes Service and OpenShift dashboards, IBM Log Analysis, and IBM Cloud Identity and Access Management (IAM).\n* Upgrade the Fabric version of your nodes. Nodes running Fabric version 1.4.x can be [upgraded to 2.x.](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-govern-componentsibp-console-govern-components-upgrade)\n\n\n\nAfter which, the capabilities of your channels can also be increased to v2.0, allowing full access to the latest Fabric features like the smart contract lifecycle.\n\nGROW --- Scalability and flexibility\n\n\n\n* Choose your compute. You have the flexibility to decide the amount of CPU, memory, and storage you want to provision in your Kubernetes cluster. For more information, see [Allocating resources](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-allocate-resources).\n* Scale up and down the resources in your Kubernetes cluster, paying for only what you need. For more information, see [Pricing](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-saas-pricing).\n* Disaster recovery and multi-region high availability (HA). This option duplicates your Kubernetes deployment across zones and regions, enabling high availability (HA) of your components and disaster recovery (DR).\n* Connect to other Fabric networks: Join IBM Blockchain Platform peers to any network running Hyperledger Fabric components. Similarly, you can invite Fabric peers to join channels hosted on an ordering service deployed on the IBM Blockchain Platform. Note that you will need to use Hyperledger Fabric APIs or the CLI.\n\n\n\nThis offering is intended for experienced Fabric users who want to build and manage their own networks.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-overview"},{"document_id":"ibmcld_13167-13903-15855","score":16.087286,"text":"\nLeave the field for Service account as is to go with the default.\n* Finish by clicking Continue.\n\n\n\n5. Next, click on Access policy. In the list of services, select All Identity and Access enabled services and click Next. Go with All resources, click Next again, then select Viewer, and again click on Next. In the section Roles and actions, select Reader for Service access and Viewer for Platform access. When done, click Next and finally Add.\n6. Review the Summary on the right side, then Create the trusted profile with the shown trust relationship and the listed access privileges. Leave the browser tab open for later.\n\n\n\n[Utilizing an access group to assign access is best practices](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account_setuplimit-policies). For the sake of simplicity, we opted for assigning read-only access through a direct access policy. The recommendation is to create an access group with assigned privileges, then make the trusted profile a member of it.\n\n\n\n\n\n Step 4: Deploy the app \n\nWith the Kubernetes cluster and the trusted profile in place, it is time to deploy a simple test app. The source code for the app and the configuration is in the [GitHub repository trusted-profile-enterprise-security](https:\/\/github.com\/IBM-Cloud\/trusted-profile-enterprise-security) You don't need it for the deployment, but might be interested in how it works nonetheless.\n\n\n\n1. In the browser tab cluster overview, check that the cluster has been fully deployed. You might want to refresh the browser and check that all checkmarks are green. If this is the case, click on Kubernetes dashboard and a new browser tab opens (Kubernetes dashboard).\n2. In the top left, find the namespace selector and switch to All namespaces.\n3. On the upper right, click on + to create a new resource. Paste the following content into the text form Create from input.\n\napiVersion: v1\nkind: Namespace\nmetadata:\nname: tptest\nlabels:\nname: tptest\n---","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-trusted-profile-for-enterprise-security"},{"document_id":"ibmcld_05818-2659-4377","score":15.962124,"text":"\n* See [Getting help](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar) for more details about using the forums.\n\n\n\n\n\n\n\n\n\n Contacting support \n\nBefore you open a support case, gather relevant information about your cluster environment.\n\n\n\n1. Get your cluster details.\n\nibmcloud ks cluster get -c <cluster_name_or_ID>\n2. If your issue involves worker nodes, get the worker node details.\n\n\n\n1. List all worker nodes in the cluster, and note the ID of any worker nodes with an unhealthy State or Status.\n\nibmcloud ks worker ls -c <cluster_name_or_ID>\n2. Get the details of the unhealthy worker node.\n\nibmcloud ks worker get -w <worker_ID> -c <cluster_name_or_ID>\n\n\n\n3. For issues with resources within your cluster such as pods or services, log in to the cluster and use the Kubernetes API to get more information about them.\n\nYou can also use the [IBM Cloud Kubernetes Service Diagnostics and Debug Tool](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-debug-tool) to gather and export pertinent information to share with IBM Support.\n4. Contact IBM Support by [opening a case](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form). To learn about opening an IBM support case, or about support levels and case severities, see [Contacting support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n5. For the Problem type, search for or select Kubernetes Service.\n6. For the Case details, provide a descriptive title and include the details that you previously gathered. From the Resources, you can also select the cluster that the issue is related to.\n\n\n\n\n\n\n\n Requesting access to allowlisted features \n\n\n\n1. [Create a ticket](https:\/\/cloud.ibm.com\/unifiedsupport\/cases\/form).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-get-help"},{"document_id":"ibmcld_05846-1433-3438","score":15.959949,"text":"\nReview the available platform and service roles and the actions mapped to each to help you assign access. If you're using the CLI or API to assign access, use containers-kubernetes for the service name.\n\nPlatform roles\n\nService roles\n\nActions\n\n\n\nTable 25. Platform roles - Kubernetes Service\nUse the tab buttons to change the context of the table. This table has row and column headers. The row headers provide the platform role name and the column headers identify the specific information available about each role.\n\n Role Description \n\n Administrator As an administrator, you can perform all platform actions based on the resource this role is being assigned, including assigning access policies to other users. \n Editor As an editor, you can perform all platform actions except for managing the account and assigning access policies. \n Operator As an operator, you can perform platform actions required to configure and operate service instances, such as viewing a service's dashboard. \n Viewer As a viewer, you can view service instances, but you can't modify them. \n\n\n\n\n\n\n\n Kubernetes service access roles and corresponding RBAC roles \n\nThe following table shows the Kubernetes resource permissions that are granted by each service access role and its corresponding RBAC role.\n\n\n\nTable 1. Kubernetes resource permissions by service and corresponding RBAC roles\n\n Service access role Corresponding RBAC role, binding, and scope Kubernetes resource permissions \n\n Reader role When scoped to one namespace: view cluster role applied by the ibm-view role binding in that namespace.<br><br><br><br> * When scoped to all namespaces: view cluster role applied by the ibm-view role binding in each namespace of the cluster. You can also view the cluster in the IBM Cloud console and CLI.<br><br><br> <br><br> * Read access to resources in a namespace<br> * No read access to roles and role bindings or to Kubernetes secrets<br> * Access the Kubernetes dashboard to view resources in a namespace.<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-iam-service-access-roles"},{"document_id":"ibmcld_04066-6776-8657","score":15.793288,"text":"\nIf you do not have an account:\n\n\n\n1. Click the Sign up button.\n2. After you create a free trial account, upgrade it to a Pay-As-You-Go type by going to Manage > Billing and Usage > Billing in the IBM Cloud console, and clicking Add Credit Card.\n3. Ensure that the user has both Administrator and Manager roles for the Kubernetes cluster that they will link to their blockchain service instance. See these steps on [how to assign Kubernetes access roles](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iks-icibp-v2-deploy-iks-k8x-access-roles) for more information.\n\n\n\n\n\nWhen you plan to use the service instance in the context of a broader organization-wide solution, it is recommended that the participating organizations use a functional email address to create their network. In this case, access to the network does not depend on any single individual's availability.\n\n\n\n* If you plan to use an existing Kubernetes cluster on IBM Cloud, ensure the version of Kubernetes it is running is between v1.24 - v1.26. For more information about how to determine what version of Kubernetes your cluster is running and how to upgrade the version, see [Updating the Kubernetes version of your cluster](https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iks-icibp-v2-deploy-iks-updating-kubernetes).\n* If you plan to use a Hardware Security Module (HSM) to generate and store the private key for your peer and ordering nodes, you can configure the HSM before you deploy the platform. Along with deploying the HSM device itself, in order for the blockchain components to access the HSM partition, you also need to publish an HSM client image to a container registry. If you decide to publish an HSM client image to a container registry, you can enable HSM support for the platform by providing the image URL when you link the service to your cluster.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-v2-deploy-iks"},{"document_id":"ibmcld_11163-31247-33195","score":15.765124,"text":"\nTo help you quickly find the product that you're looking for, you can now filter the products to view services only, software only, or professional services only. For more information, see [IBM Cloud catalog](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatis-platformcatalog).\n\n\n\n\n\n\n\n July 2021 \n\n\n\n 27 July 2021 \n\nAssigning access to federated users and compute resources by using trusted profiles\n: You can use trusted profiles to automatically grant federated users in your account access to resources with conditions based on SAML attributes from your corporate directory. You can also use trusted profiles to manage the authorization of applications that are running in compute resources, such as IBM Cloud Kubernetes Service, to access other IBM Cloud services without the need for service IDs or API keys. For more information, see [Creating trusted profiles](https:\/\/cloud.ibm.com\/docs\/account?topic=account-create-trusted-profilefederated-users-steps).\n\n\n\n\n\n 15 July 2021 \n\nScoping support cases to what matters to you\n: When you create a case in the IBM Cloud Support Center, you now have options to narrow the subject of your case to a specific topic that's most closely related to the issue you're experiencing. As a result, you can ensure that your support case gets routed to the appropriate support engineer and resolved as efficiently as possible. For more information, see [Creating support cases](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-open-casecreating-support-case).\n\n\n\n\n\n 14 July 2021 \n\nDelivering notifications by using Slack webhooks\n: In addition to generic webhooks, you can now add Slack webhooks to your distribution list and receive account-wide IBM Cloud notifications through them. To create a webhook, you need to set up an app in Slack and a unique URL. With this new webhook integration, you can easily receive the notifications in a selected Slack channel in which you installed your app.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatsnew"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04353-90549-92065","score":9.21585,"text":"\nThis query parameter cannot be used in conjunction with the deactivation_date, expiration_date, deactivation_date_min, and deactivation_date_max query parameters. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--created-at (string)\n: Optional. Return only managed keys whose creation time matches the parameter. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--created-at-min (string)\n: Optional. Return only managed keys whose creation time is at or after the parameter value. This query parameter cannot be used in conjunction with the created_at query parameter. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--created-at-max (string)\n: Optional. Return only managed keys whose creation time is at or before the parameter value. This query parameter cannot be used in conjunction with the created_at query parameter. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--updated-at (string)\n: Optional. Return only managed keys whose update time matches the parameter. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--updated-at-min (string)\n: Optional. Return only managed keys whose update time is after the parameter value. This query parameter cannot be used in conjunction with the updated_at query parameter. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--updated-at-max (string)\n: Optional. Return only managed keys whose update time is before the parameter value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-hpcs-cli-plugin"},{"document_id":"ibmcld_08425-90779-92295","score":9.21585,"text":"\nThis query parameter cannot be used in conjunction with the deactivation_date, expiration_date, deactivation_date_min, and deactivation_date_max query parameters. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--created-at (string)\n: Optional. Return only managed keys whose creation time matches the parameter. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--created-at-min (string)\n: Optional. Return only managed keys whose creation time is at or after the parameter value. This query parameter cannot be used in conjunction with the created_at query parameter. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--created-at-max (string)\n: Optional. Return only managed keys whose creation time is at or before the parameter value. This query parameter cannot be used in conjunction with the created_at query parameter. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--updated-at (string)\n: Optional. Return only managed keys whose update time matches the parameter. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--updated-at-min (string)\n: Optional. Return only managed keys whose update time is after the parameter value. This query parameter cannot be used in conjunction with the updated_at query parameter. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--updated-at-max (string)\n: Optional. Return only managed keys whose update time is before the parameter value.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-cli-plugin-hpcs-cli-plugin"},{"document_id":"ibmcld_13446-19419-21379","score":9.178909,"text":"\nIf you set the redaction parameter to true, the service automatically forces the smart_formatting parameter to be true, and it disables the keywords, keywords_threshold, max_alternatives, and (for the WebSocket interface) interim_results parameters. For more information, see [Numeric redaction](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-formattingnumeric-redaction).\n\n\n\nTable 22. The redaction parameter\n\n Availability and usage Description \n\n Previous-generation models Beta for US English, Japanese, and Korean. \n Next-generation models Beta for US English, Japanese, and Korean. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n smart_formatting \n\nAn optional boolean that indicates whether the service converts dates, times, numbers, currency, and similar values into more conventional representations in the final transcript. For US English, the feature also converts certain keyword phrases into punctuation symbols. By default (false), smart formatting is not performed. For more information, see [Smart formatting](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-formattingsmart-formatting).\n\n\n\nTable 23. The smart_formatting parameter\n\n Availability and usage Description \n\n Previous-generation models Beta for US English, Japanese, and Spanish (all dialects). \n Next-generation models Beta for US English, Japanese, and Spanish (all dialects). It also also available for the en-WW_Medical_Telephony model when US English audio is recognized. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n speaker_labels \n\nAn optional boolean that indicates whether the service identifies which individuals spoke which words in a multi-participant exchange.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"},{"document_id":"ibmcld_07191-1691-3739","score":8.966597,"text":"\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance. The reason is because the filter parameter runs first and caches results, and then the query parameter ranks them. For an example of using filters and queries together, see [Building combined queries](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-conceptsbuilding-combined-queries). Filters can also be used in aggregations.\n\nWhen you write a query that includes both a filter, and an aggregation, query, or natural_language_query parameter; the filter parameters run first, after which any aggregation, query, or natural_language_query parameters run in parallel.\n\nWith a simple query, especially on a small data set, filter and query often return the exact same (or similar) results. If a filter and query call return similar results, and getting a response in order of relevance does not matter, it is better to use filter because filter calls are faster and are cached. Caching means that the next time you make that call, you get a much quicker response, particularly in a big data set.\n\n\n\n\n\n\n\n aggregation \n\nAggregation queries return a count of documents matching a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see the [Aggregations table](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-aggregations). These aggregations are written using the [Discovery Query Language](https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-operators).\n\n\n\n\n\n natural_language_query","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery?topic=discovery-query-parameters"},{"document_id":"ibmcld_07095-2569-4026","score":8.820381,"text":"\nUsing the parameters together improves performance because the filter parameter is applied first. It filters the documents and caches the results. The query parameter then ranks the cached results.\n\n\n\n Filter example: Get a document by its ID \n\nQuery body:\n\n{\n\"filter\": \"document_id::b6d8c6e3-1097-421b-9e39-75717d2554aa\"\n}\n\nIf the document exists, the query returns 1 matching result. If it doesn't, the query returns no matching results.\n\n\n\n\n\n Filter example: Find a document ID by its file name \n\nIf you don't know the document_id of a document, but you know the original filename of the document, you can use the filter and return parameters together to discover the document_id.\n\nQuery body:\n\n{\n\"filter\": \"extracted_metadata.filename::100674.txt\",\n\"return\": [ \"document_id\", \"extracted_metadata\" ]\n}\n\nResponse:\n\n{\n\"matching_results\": 1,\n\"results\": [\n{\n\"document_id\": \"b6d8c6e3-1097-421b-9e39-75717d2554aa\",\n\"extracted_metadata\": {\n\"sha1\": \"AD447F7592A17CDCBF0A589C4E6EC2087AF7H35F\",\n\"filename\": \"100674.txt\",\n\"file_type\": \"text\"\n}\n}\n]\n}\n\n\n\n\n\n Filter example: Find documents that mention an entity value \n\nThe query looks for documents that mention the entity Gilroy and finds 4 matching documents.\n\nQuery body:\n\n{\n\"filter\": \"enriched_text.entities.text::Gilroy\"\n}\n\nResponse:\n\n{\n\"matching_results\": 4\n}\n\n\n\n\n\n\n\n Filtering nested values \n\nYou can nest one filter inside another to ensure that the documents that are returned match more than one condition.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/discovery-data?topic=discovery-data-query-dql-overview"},{"document_id":"ibmcld_09701-13735-14292","score":8.671466,"text":"\nThe value of this parameter must be a multiple of 60000000 microseconds.\n\n\n\n\n\n version (integer) \n\nVersion of an alert.\n\nThe version changes every time you update an alert.\n\nThe version is used for optimistic locking.\n\n\n\n\n\n\n\n Query parameters \n\n\n\n alertId (integer) \n\nID of an alert.\n\n\n\n\n\n from (long) \n\nDefines the start timestamp, in microseconds, that is used when you request information about alerts that are defined.\n\n\n\n\n\n to (long) \n\nDefines the end timestamp, in microseconds, that is used when you request information about alerts that are defined.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/monitoring?topic=monitoring-alert_api"},{"document_id":"ibmcld_13446-24100-26099","score":8.463771,"text":"\nAsynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n timestamps \n\nAn optional boolean that indicates whether the service produces timestamps for the words of the transcript. By default (false), timestamps are not returned. For more information, see [Word timestamps](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-metadataword-timestamps).\n\n\n\nTable 27. The timestamps parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n Transfer-Encoding \n\nAn optional value of chunked that causes the audio to be streamed to the service. By default, audio is sent all at once as a one-shot delivery. For more information, see [Audio transmission](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtransmission).\n\n\n\nTable 28. The Transfer-Encoding parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Not applicable; always streamed \n Synchronous HTTP Request header of POST \/v1\/recognize method \n Asynchronous HTTP Request header of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n word_alternatives_threshold \n\nAn optional double between 0.0 and 1.0 that specifies the threshold at which the service reports acoustically similar alternatives for words of the input audio. By default, word alternatives are not returned. For more information, see [Word alternatives](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-spottingword-alternatives).\n\n\n\nTable 29. The word_alternatives_threshold parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"},{"document_id":"ibmcld_15845-18362-19949","score":8.424836,"text":"\ninvalid_generation_parameter \n\nMessage: The generation query parameter is invalid.\n\nFor versions on and after 5\/31\/2019, the 'generation' query parameter must be set to 1 to allow VPC API requests for use with generation 1 compute resources and set to 2 to allow VPC API requests for use with generation 2 compute resources.\n\nHow to set the generation parameter\n\nIn the CLI: ibmcloud is target --gen 1\n\nIn the API:\n\ncurl -X GET \"$rias_endpoint\/v1\/regions?version=$version&generation=1\"\n-H \"Authorization: $iam_token\"\n\n\n\n\n\n invalid_id_format \n\nMessage: Bad ID format. Ensure format is correct.\n\nMake sure that the ID you provided does not contain any malformed data.\n\nYou may get this error message if you provide a malformed start query when making a pagination request. For example, GET \/v1\/network_acls?start=23fbba08-ceb3-4cbe-a951-84ff20a06069?version=$version&generation=1 contains two ?s. Fix the query and try again.\n\n\n\n\n\n invalid_route \n\nMessage: The requested route does not exist.\n\nThe requested route on the API URL you provided does not exist. Verify that the URL you specified to call the API endpoint is correct.\n\n\n\n\n\n invalid_request_field \n\nMessage: A field provided in the request is not valid.\n\nFor example, to update the network ACL used by a subnet use the PATCH \/v1\/subnets\/{subnet_id}?version=$version&generation=1 -d '{ \"network_acl\":{ \"id\": \u201c{network_acl_id}\u201d } }\u2019 API.\n\nThe following request would be invalid because \u201cnetworkacl\u201d is not a valid field, PATCH \/v1\/subnets\/{subnet_id}?version=$version&generation=1 -d '{ \"networkacl\":{ \"id\": \u201c{network_acl_id}\u201d } }\u2019","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-rias-error-messages"},{"document_id":"ibmcld_13446-4441-6470","score":8.388255,"text":"\nTable 5. The base_model_version parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Query parameter of \/v1\/recognize connection request \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n character_insertion_bias \n\nAn optional float between -1.0 and 1.0 that indicates whether the service is biased to recognize shorter (negative values) or longer (positive values) strings of characters when developing transcription hypotheses. By default, the service uses a default bias of 0.0. The value that you specify represents a change from a model's default. For more information, see [Character insertion bias](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-parsinginsertion-bias).\n\n\n\nTable 6. The character_insertion_bias parameter\n\n Availability and usage Description \n\n Previous-generation models Not available. \n Next-generation models Beta for all models. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST \/v1\/recognize method \n Asynchronous HTTP Query parameter of POST \/v1\/recognitions method \n\n\n\n\n\n\n\n Content-Type \n\nAn optional audio format (MIME type) that specifies the format of the audio data that you pass to the service. The service can automatically detect the format of most audio, so the parameter is optional for most formats. It is required for the audio\/alaw, audio\/basic, audio\/l16, and audio\/mulaw formats. For more information, see [Specifying an audio format](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-audio-formatsaudio-formats-specifying).\n\n\n\nTable 7. The Content-Type parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket content-type parameter of JSON start message","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary"},{"document_id":"ibmcld_08425-27411-28852","score":8.38006,"text":"\nThe value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--created-at (string)\n: Optional. Return only managed keys whose creation time matches the parameter. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--created-at-min (string)\n: Optional. Return only managed keys whose creation time is at or after the parameter value. This query parameter cannot be used in conjunction with the created_at query parameter. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--created-at-max (string)\n: Optional. Return only managed keys whose creation time is at or before the parameter value. This query parameter cannot be used in conjunction with the created_at query parameter. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--updated-at (string)\n: Optional. Return only managed keys whose update time matches the parameter. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--updated-at-min (string)\n: Optional. Return only managed keys whose update time is after the parameter value. This query parameter cannot be used in conjunction with the updated_at query parameter. The value must match regular expression \/[0-9]{4}-[0-9]{2}-[0-9]{2}\/.\n\n--updated-at-max (string)\n: Optional. Return only managed keys whose update time is before the parameter value. This query parameter cannot be used in conjunction with the updated_at query parameter.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/hs-crypto?topic=hs-crypto-cli-plugin-hpcs-cli-plugin"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2021073465,"ndcg_cut_10":0.2021073465}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16321-14177-15957","score":14.466716,"text":"\nThe WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use. For more information about voice model options, see [Supported languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices).\n\nThe model you specify must be one that is supported by the Text to Speech service instance that is configured for use with the integration.\n\n\n\n\n\n\n\n Transferring a call to a live agent \n\nWhen you configure the phone integration, you can optionally set up backup call center support, which makes it possible for the assistant to transfer a call to a human.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03285-13886-15581","score":13.693851,"text":"\nOnly changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_13429-163247-165127","score":13.455547,"text":"\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https:\/\/github.com\/watson-developer-cloud\/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_16321-5729-7915","score":12.909102,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03285-5746-7932","score":12.909102,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_13361-1589-2935","score":12.781026,"text":"\n* For the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), you first specify the customization ID with the language_customization_id parameter of the \/v1\/recognize method. You use this method to establish a WebSocket connection with the service.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token\n+ '&language_customization_id={customization_id}';\nvar websocket = new WebSocket(wsURI);\n\nYou then specify the name of the grammar with the grammar_name parameter in the JSON start message for the active connection. Passing this value with the start message allows you to change the grammar dynamically for each request that you send over the connection.\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/l16;rate=22050',\ngrammar_name: '{grammar_name}'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n* For the [synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http), pass both parameters with the POST \/v1\/recognize method.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio\/flac\" --data-binary @audio-file.flac \"{url}\/v1\/recognize?language_customization_id={customization_id}&grammar_name={grammar_name}\"\n\nIBM Cloud Pak for Data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse"},{"document_id":"ibmcld_13455-13739-15986","score":12.684002,"text":"\n* By sending a JSON text message with the action parameter set to the value stop:\n\n{action: 'stop'}\n* By sending an empty binary message, one in which the specified blob is empty:\n\nwebsocket.send(blob)\n\n\n\nIf the client fails to signal that the transmission is complete, the connection can time out without the service sending final results. To receive final results between multiple recognition requests, the client must signal the end of transmission for the previous request before it sends a subsequent request. After it returns the final results for the first request, the service returns another {\"state\":\"listening\"} message to the client. This message indicates that the service is ready to receive another request.\n\n\n\n\n\n Send additional requests and modify request parameters \n\nWhile the WebSocket connection remains active, the client can continue to use the connection to send further recognition requests with new audio. By default, the service continues to use the parameters that were sent with the previous start message for all subsequent requests that are sent over the same connection.\n\nTo change the parameters for subsequent requests, the client can send another start message with the new parameters after it receives the final recognition results and a new {\"state\":\"listening\"} message from the service. The client can change any parameters except for those parameters that are specified when the connection is opened (model, language_customization_id, and so on).\n\nThe following example sends a start message with new parameters for subsequent recognition requests that are sent over the connection. The message specifies the same content-type as the previous example, but it directs the service to return confidence measures and timestamps for the words of the transcription.\n\nvar message = {\naction: 'start',\ncontent-type: 'audio\/l16;rate=22050',\nword_confidence: true,\ntimestamps: true\n};\nwebsocket.send(JSON.stringify(message));\n\n\n\n\n\n Keep a connection alive \n\nThe service terminates the session and closes the connection if an inactivity or session timeout occurs:\n\n\n\n* An inactivity timeout occurs if audio is being sent by the client but the service detects no speech. The inactivity timeout is 30 seconds by default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_03285-12413-14528","score":12.579765,"text":"\n\"parameter name\": \"parameter value\",\n\"parameter name\": \"parameter value\"\n}\n}\n}\n]\n}\n}\nShow more\n\n\n\nEach command type along with its related parameters are described in the following sections.\n\n\n\n command_info.type : configure \n\nDynamically reconfigures the Text to Speech service by applying a set of configuration parameters, which can be based on the dialog or action flow. For example, you might want to choose a particular voice at a specific point in the conversation.\n\n\n\n parameter description required default \n\n synthesize The Text to Speech service configuration to use when synthesizing audio. The parameters defined by this object are used when connecting to the Text to Speech service for speech synthesis requests. For more information about these parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speechsynthesize-audio-websockets-). yes Current Text to Speech configuration \n update_strategy Specifies the update strategy to use when setting the speech configuration. Possible values include:<br><br><br><br> * replace: Replaces the configuration for the rest of the session. Any root-level fields in the new configuration completely overwrite the previous configuration.<br> * replace_once: Replaces the configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_13790-1284-2889","score":12.513273,"text":"\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nYou call the \/v1\/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13724-70042-71880","score":12.478481,"text":"\nFor more information, see [Using audio formats](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-audio-formats).\n\nHTTP and WebSocket interfaces can now return warnings\n: The HTTP and WebSocket \/v1\/synthesize methods can return a warnings response that includes messages about invalid query parameters or JSON fields that are included with a request. The format of the warnings changed. The following example shows the previous format:\n\n\"warnings\": \"Unknown arguments: [u'{invalid_arg_1}', u'{invalid_arg_2}'].\"\n\nThe same warning now has the following format:\n\n\"warnings\": \"Unknown arguments: {invalid_arg_1}, {invalid_arg_2}.\"\n\n\n\n\n\n 10 March 2016 \n\nSynthesis methods can now return warnings\n: The GET and POST \/v1\/synthesize methods can now return a Warnings response header that includes a list of warning messages about invalid query parameters or JSON fields that are included with the request. Each element of the list includes a string that describes the nature of the warning followed by an array of invalid argument strings; for example, Unknown arguments: [u'{invalid_arg_1}', u'{invalid_arg_2}']. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated and replaced by the Watson Swift SDK. The new SDK is available from the [swift-sdk repository](https:\/\/github.com\/watson-developer-cloud\/swift-sdk) in the watson-developer-cloud namespace on GitHub.\n\n\n\n\n\n 22 February 2016 \n\nNew expressive SSML feature\n: The service was updated with a new expressive SSML feature. The service extends SSML with an <express-as> element that you can use to indicate expressiveness in one of three speaking styles: GoodNews, Apology, or Uncertainty.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.3065735964,"ndcg_cut_5":0.3065735964,"ndcg_cut_10":0.3065735964}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16321-14177-15957","score":13.057706,"text":"\nThe WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use. For more information about voice model options, see [Supported languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices).\n\nThe model you specify must be one that is supported by the Text to Speech service instance that is configured for use with the integration.\n\n\n\n\n\n\n\n Transferring a call to a live agent \n\nWhen you configure the phone integration, you can optionally set up backup call center support, which makes it possible for the assistant to transfer a call to a human.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03285-13886-15581","score":12.668232,"text":"\nOnly changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_13790-1284-2889","score":12.494317,"text":"\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nYou call the \/v1\/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13361-1589-2935","score":12.255982,"text":"\n* For the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), you first specify the customization ID with the language_customization_id parameter of the \/v1\/recognize method. You use this method to establish a WebSocket connection with the service.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token\n+ '&language_customization_id={customization_id}';\nvar websocket = new WebSocket(wsURI);\n\nYou then specify the name of the grammar with the grammar_name parameter in the JSON start message for the active connection. Passing this value with the start message allows you to change the grammar dynamically for each request that you send over the connection.\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/l16;rate=22050',\ngrammar_name: '{grammar_name}'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n* For the [synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http), pass both parameters with the POST \/v1\/recognize method.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio\/flac\" --data-binary @audio-file.flac \"{url}\/v1\/recognize?language_customization_id={customization_id}&grammar_name={grammar_name}\"\n\nIBM Cloud Pak for Data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse"},{"document_id":"ibmcld_13432-6305-8426","score":12.083823,"text":"\nThe WebSocket protocol is lightweight. It requires only a single connection to perform live-speech recognition.\n* Enables audio to be streamed directly from browsers (HTML5 WebSocket clients) to the service.\n* Returns results as soon as they are available when you use a next-generation model or request interim results.\n\n\n\n\n\n\n\n\n\n Using speech recognition parameters \n\nThe service's speech recognition interfaces share largely common parameters for transcribing speech to text. The parameters let you tailor aspects of your request, such as whether the data is streamed or sent all at once, and the information that the service includes in its response.\n\nThe following sections introduce the speech recognition parameters and their functionality. Some parameters are available only for some speech recognition interfaces or for some languages and models. For information about all parameters and their interface and language support, see the [Parameter summary](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-summary).\n\n\n\n Audio transmission and timeouts \n\n\n\n* [Audio transmission](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtransmission) describes how you can pass audio as a continuous stream of data chunks or as a one-shot delivery that passes all of the data at one time. With the WebSocket interface, audio data is always streamed to the service over the connection. With the HTTP interfaces, you can stream the audio or send it all at once.\n* [Timeouts](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtimeouts) are used by the service to ensure an active flow of data during audio streaming. When you initiate a streaming session, the service enforces inactivity and session timeouts from which your application must recover gracefully. If a timeout lapses during a streaming session, the service closes the connection.\n\n\n\n\n\n\n\n Interim results and low latency \n\n\n\n* [Interim results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-interiminterim-results) are intermediate hypotheses that the service returns as transcription progresses.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-features"},{"document_id":"ibmcld_13429-163247-165127","score":11.967494,"text":"\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https:\/\/github.com\/watson-developer-cloud\/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13297-4312-5935","score":11.901144,"text":"\nTo use the WebSocket interface, you first use the \/v1\/recognize method to establish a connection with the service. You specify parameters such as the language model and any custom models that are to be used for requests that are sent over the connection. You then register event listeners to handle responses from the service. To make a request, you send a JSON text message that includes the audio format and any additional parameters. You pass the audio as a binary message (blob), and then send a text message to signal the end of the audio.\n\nThe following example provides JavaScript code that establishes a connection and sends the text and binary messages for a recognition request. The basic example does not include the code to define all of the necessary event handlers for the connection.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token;\nvar websocket = new WebSocket(wsURI);\n\nwebsocket.onopen = function(evt) { onOpen(evt) };\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/flac'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\nwebsocket.send(JSON.stringify({action: 'stop'}));\n}\nShow more\n\n\n\n\n\n Using the synchronous HTTP interface \n\n[The synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http) provides the simplest way to make a recognition request. You use the POST \/v1\/recognize method to make a request to the service. You pass the audio and all parameters with the single request. The following curl example shows a basic HTTP recognition request:\n\nIBM Cloud","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-basic-request"},{"document_id":"ibmcld_16321-5729-7915","score":11.900639,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03285-5746-7932","score":11.900639,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_13455-13739-15986","score":11.834979,"text":"\n* By sending a JSON text message with the action parameter set to the value stop:\n\n{action: 'stop'}\n* By sending an empty binary message, one in which the specified blob is empty:\n\nwebsocket.send(blob)\n\n\n\nIf the client fails to signal that the transmission is complete, the connection can time out without the service sending final results. To receive final results between multiple recognition requests, the client must signal the end of transmission for the previous request before it sends a subsequent request. After it returns the final results for the first request, the service returns another {\"state\":\"listening\"} message to the client. This message indicates that the service is ready to receive another request.\n\n\n\n\n\n Send additional requests and modify request parameters \n\nWhile the WebSocket connection remains active, the client can continue to use the connection to send further recognition requests with new audio. By default, the service continues to use the parameters that were sent with the previous start message for all subsequent requests that are sent over the same connection.\n\nTo change the parameters for subsequent requests, the client can send another start message with the new parameters after it receives the final recognition results and a new {\"state\":\"listening\"} message from the service. The client can change any parameters except for those parameters that are specified when the connection is opened (model, language_customization_id, and so on).\n\nThe following example sends a start message with new parameters for subsequent recognition requests that are sent over the connection. The message specifies the same content-type as the previous example, but it directs the service to return confidence measures and timestamps for the words of the transcription.\n\nvar message = {\naction: 'start',\ncontent-type: 'audio\/l16;rate=22050',\nword_confidence: true,\ntimestamps: true\n};\nwebsocket.send(JSON.stringify(message));\n\n\n\n\n\n Keep a connection alive \n\nThe service terminates the session and closes the connection if an inactivity or session timeout occurs:\n\n\n\n* An inactivity timeout occurs if audio is being sent by the client but the service detects no speech. The inactivity timeout is 30 seconds by default.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.25,"recall_10":0.5,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1681275363,"ndcg_cut_10":0.2982542196}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13361-1589-2935","score":14.920932,"text":"\n* For the [WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets), you first specify the customization ID with the language_customization_id parameter of the \/v1\/recognize method. You use this method to establish a WebSocket connection with the service.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}\/v1\/recognize'\n+ '?access_token=' + access_token\n+ '&language_customization_id={customization_id}';\nvar websocket = new WebSocket(wsURI);\n\nYou then specify the name of the grammar with the grammar_name parameter in the JSON start message for the active connection. Passing this value with the start message allows you to change the grammar dynamically for each request that you send over the connection.\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio\/l16;rate=22050',\ngrammar_name: '{grammar_name}'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n* For the [synchronous HTTP interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-http), pass both parameters with the POST \/v1\/recognize method.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio\/flac\" --data-binary @audio-file.flac \"{url}\/v1\/recognize?language_customization_id={customization_id}&grammar_name={grammar_name}\"\n\nIBM Cloud Pak for Data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse"},{"document_id":"ibmcld_13645-7-1414","score":13.998892,"text":"\nUsing a custom model for speech synthesis \n\nOnce you create a custom model and populate it with custom entries, you use it by passing its customization ID (GUID) with the customization_id query parameter of the HTTP GET or POST \/v1\/synthesize method or the WebSocket \/v1\/synthesize method. When you include a customization ID, you must call a synthesize method with credentials for the instance of the service that owns the specified custom model.\n\n\n\n Examples of using a custom model \n\nThe first two examples generate a custom pronunciation for IEEE that is based on entries from the indicated custom model. The custom pronunciation is used instead of the default pronunciation from the service's regular pronunciation rules.\n\n\n\n* The HTTP GET \/v1\/synthesize method:\n\nIBM Cloud\n\ncurl -X GET -u \"apikey:{apikey}\" --header \"Accept: audio\/flac\" --output ieee.flac \"{url}\/v1\/synthesize?text=IEEE&customization_id={customization_id}\"\n\nIBM Cloud Pak for Data\n\ncurl -X GET --header \"Authorization: Bearer {token}\" --header \"Accept: audio\/flac\" --output ieee.flac \"{url}\/v1\/synthesize?text=IEEE&customization_id={customization_id}\"\n* The HTTP POST \/v1\/synthesize method:\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application\/json\" --header \"Accept: audio\/flac\" --data \"{\"text\":\"IEEE\"}\" --output ieee.flac \"{url}\/v1\/synthesize?customization_id={customization_id}\"\n\nIBM Cloud Pak for Data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-custom-using"},{"document_id":"ibmcld_13712-4613-6343","score":13.875344,"text":"\nA customer ID that you specify is associated with the instance of the service whose credentials are used with the request; only credentials for that instance of the service can delete data associated with the ID.\n\nUse the X-Watson-Metadata header with the following methods:\n\n\n\n* With HTTP requests:\n\n\n\n* POST \/v1\/synthesize\n* GET \/v1\/synthesize\n\n\n\nThe customer ID is associated with data that is sent with the request.\n* With WebSocket requests:\n\n\n\n* \/v1\/synthesize\n\n\n\nYou specify the customer ID with the x-watson-metadata query parameter to associate the ID with data that is sent with the request. You must URL-encode the argument to the query parameter, for example, customer_id%3dmy_customer_ID.\n* With requests to add custom words to custom models:\n\n\n\n* POST \/v1\/customizations\/{customization_id}\n* POST \/v1\/customizations\/{customization_id}\/words\n* PUT \/v1\/customizations\/{customization_id}\/words\/{word}\n\n\n\nThe customer ID is associated with the custom words that are added or updated by the request.\n\n\n\n\n\n\n\n Deleting data \n\nTo delete all data that is associated with a customer ID, use the DELETE \/v1\/user_data method. You pass the string customer_id={id} as a query parameter with the request. The following example deletes all data for the customer ID my_customer_ID:\n\nIBM Cloud\n\ncurl -X DELETE -u \"apikey:{apikey}\" \"{url}\/v1\/user_data?customer_id=my_customer_ID\"\n\nIBM Cloud Pak for Data\n\ncurl -X DELETE --header \"Authorization: Bearer {token}\" \"{url}\/v1\/user_data?customer_id=my_customer_ID\"\n\nThe \/v1\/user_data method deletes all data that is associated with the specified customer ID, regardless of the method by which the information was added. The method has no effect if no data is associated with the customer ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-information-security"},{"document_id":"ibmcld_16321-5729-7915","score":13.268238,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03285-5746-7932","score":13.268238,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_13429-109689-111379","score":13.127701,"text":"\n* DELETE \/v1\/customizations\/{customization_id}\/grammars\/{grammar_name} removes an existing grammar from a custom model.\n\n\n\nYou can use a grammar for speech recognition with the WebSocket and HTTP interfaces. Use the language_customization_id and grammar_name parameters to identify the custom model and the grammar that you want to use. Currently, you can use only a single grammar with a speech recognition request.\n\nFor more information about grammars, see the following documentation:\n\n\n\n* [Using grammars with custom language models](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammars)\n* [Understanding grammars](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUnderstand)\n* [Adding a grammar to a custom language model](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarAdd)\n* [Using a grammar for speech recognition](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarUse)\n* [Managing grammars](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-manageGrammars)\n* [Example grammars](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-grammarExamples)\n\n\n\nFor information about all methods of the interface, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nNew numeric redaction feature for US English, Japanese, and Korean now available\n: A new numeric redaction feature is now available to mask numbers that have three or more consecutive digits. Redaction is intended to remove sensitive personal information, such as credit card numbers, from transcripts. You enable the feature by setting the redaction parameter to true on a recognition request.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13790-2496-4190","score":12.843968,"text":"\n{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service. You must use the access token before it expires.\n\n\n\nIBM Cloud\n\nPass an Identity and Access Management (IAM) access token to authenticate with the service. You pass an IAM access token instead of passing an API key with the call. For more information, see [Authenticating to IBM Cloud](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iamgs-credential-cloud).\nIBM Cloud Pak for Data\n\nPass an access token as you would with the Authorization header of an HTTP request. For more information, see [Authenticating to IBM Cloud Pak for Data](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-iamgs-credential-cpd).\n\n\n\nvoice (optional string)\n: Specifies the voice in which the text is to be spoken in the audio. Use the \/v1\/voices method to get the current list of supported voices. Omit the parameter to use the default voice. For more information, see [Languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices) and [Using the default voice](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voices-usespecify-voice-default).\n\ncustomization_id (optional string)\n: Specifies the globally unique identifier (GUID) for a custom model that is to be used for the synthesis. A specified custom model must match the language of the voice that is used for the synthesis.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13724-68545-70490","score":12.753061,"text":"\nFor more information, see [Understanding customization](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-customIntro).\n\nVoices updated for improved speech synthesis\n: The service features improved expressiveness and naturalness for the most frequently used voices. The improvements are based on Recursive Neural Network (RNN)-based prosody prediction from input text. They are made available as a new service engine and voice-model updates for the following languages:\n\n\n\n* en-US_AllisonVoice\n* en-US_LisaVoice\n* en-US_MichaelVoice\n* es-ES_EnriqueVoice\n* fr-FR_ReneeVoice\n\n\n\nNew customization ID parameter for word pronunciation\n: The GET \/v1\/pronunciation method now accepts an optional customization_id query parameter. The parameter obtains a word translation from a specified custom model. If the custom model does not contain the word, the method returns the word's default pronunciation. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\nWhen using the GET \/v1\/pronunciation method without a customization ID and for a language other than US English, you can request a word's pronunciation only in IBM SPR notation. For a language other than US English, you must specify spr with the method's format option.\n\nNew support for audio\/basic audio format\n: The list of supported audio formats now includes audio\/basic, which provides single-channel audio that is encoded using 8-bit u-law (or mu-law) data that is sampled at 8 kHz. For more information, see [Using audio formats](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-audio-formats).\n\nHTTP and WebSocket interfaces can now return warnings\n: The HTTP and WebSocket \/v1\/synthesize methods can return a warnings response that includes messages about invalid query parameters or JSON fields that are included with a request. The format of the warnings changed. The following example shows the previous format:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-release-notes"},{"document_id":"ibmcld_13365-3377-5348","score":12.714566,"text":"\nExperimental and beta features should not be used when implementing a solution that requires the labeling and deletion of data.\n\n\n\n Specifying a customer ID \n\nTo associate a customer ID with data, include the X-Watson-Metadata header with the request that passes the information. You pass the string customer_id={id} as the argument of the header.\n\nA customer ID can include any characters except for the ; (semicolon) and = (equals sign). Specify a random or generic string for the customer ID; do not specify a personally identifiable string, such as an email address or Twitter ID. You can specify different customer IDs with different requests. A customer ID that you specify is associated with the instance of the service whose credentials are used with the request; only credentials for that instance of the service can delete data associated with the ID.\n\n\n\n Supported methods \n\nYou can use the X-Watson-Metadata header with the following methods:\n\n\n\n* With WebSocket requests:\n\n\n\n* \/v1\/recognize\n\n\n\nYou specify the customer ID with the x-watson-metadata query parameter of the request to open the connection. You must URL-encode the argument to the query parameter, for example, customer_id%3dmy_customer_ID. The customer ID is associated with all data that is passed with recognition requests sent over the connection.\n* With synchronous HTTP requests:\n\n\n\n* POST \/v1\/recognize\n\n\n\nThe customer ID is associated with the data that is sent with the individual request.\n* With asynchronous HTTP requests:\n\n\n\n* POST \/v1\/register_callback\n* POST \/v1\/recognitions\n\n\n\nThe customer ID is associated with the allowlisted callback URL or with the data that is sent with the individual recognition request.\n* With requests to add corpora, custom words, or grammars to custom language models:\n\n\n\n* POST \/v1\/customizations\/{customization_id}\/corpora\/{corpus_name}\n* POST \/v1\/customizations\/{customization_id}\/words\n* PUT \/v1\/customizations\/{customization_id}\/words\/{word_name}","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-information-security"},{"document_id":"ibmcld_13779-3555-3945","score":12.584025,"text":"\nvar access_token = '{access_token}';\nvar wsURI = '{ws_url}\/v1\/synthesize'\n+ '?access_token=' + access_token\n+ '&customization_id={customization_id}'\n+ '&voice=en-US_AllisonV3Voice';\nvar websocket = new WebSocket(wsURI);\n\nfunction onOpen(evt) {\nvar message = {\ntext: '<ibm:prompt id=\"goodbye\"\/>',\naccept: 'audio\/ogg;codecs=opus'\n};\nwebsocket.send(JSON.stringify(message));\n}\n\n. . .\nShow more","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-tbe-use"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16321-14177-15957","score":14.334193,"text":"\nThe WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use. For more information about voice model options, see [Supported languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices).\n\nThe model you specify must be one that is supported by the Text to Speech service instance that is configured for use with the integration.\n\n\n\n\n\n\n\n Transferring a call to a live agent \n\nWhen you configure the phone integration, you can optionally set up backup call center support, which makes it possible for the assistant to transfer a call to a human.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_16321-5729-7915","score":12.966751,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03285-5746-7932","score":12.966751,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_07578-506456-508701","score":12.299151,"text":"\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-506398-508643","score":12.299151,"text":"\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_13790-1284-2889","score":12.259148,"text":"\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nYou call the \/v1\/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13455-1311-2796","score":12.118865,"text":"\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6. [Keep a connection alive](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-keep)\n7. [Close a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-close)\n\n\n\nWhen the client sends data to the service, it must pass all JSON messages as text messages and all audio data as binary messages.\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nThe Speech to Text service uses the WebSocket Secure (WSS) protocol to make the \/v1\/recognize method available at the following endpoint:\n\nwss:\/\/api.{location}.speech-to-text.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/recognize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of your service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_03285-13886-15581","score":12.015468,"text":"\nOnly changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16384-7-2422","score":11.874675,"text":"\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-web-chat-overview"},{"document_id":"ibmcld_03369-40495-42527","score":11.701632,"text":"\nThis integration, which is now generally available, creates a connection between your assistant and WhatsApp by using Twilio as a provider. For more information, see [Integrating with WhatsApp](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-whatsapp).\n\nWeb chat home screen now generally available\n: Ease your customers into the conversation by adding a home screen to your web chat window. The home screen greets your customers and shows conversation starter messages that customers can click to easily start chatting with the assistant. For more information about the home screen feature, see [Configuring the home screen](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-home-screen). The home screen feature is now enabled by default for all new web chat deployments. Also, you can now access context variables from the home screen. Note that initial context must be set using a conversation_start node. For more information, see [Starting the conversation](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-startdialog-start-welcome).\n\nConnect to human agent response type allows more text\n: In a dialog skill, the response type Connect to human agent now allows 320 characters in the Response when agents are online and Response when no agents are online fields. The previous limit was 100 characters.\n\nLegacy system entities deprecated\n: In January 2020, a new version of the system entities was introduced. As of April 2021, only the new version of the system entities is supported for all languages. The option to switch to using the legacy version is no longer available.\n\n\n\n\n\n 6 April 2021 \n\nService API endpoint change\n: As explained in [December 2019](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notesassistant-dec122019), as part of work done to fully support IAM authentication, the endpoint you use to access your Watson Assistant service programmatically is changing. The old endpoint URLs are deprecated and will be retired on 26 May 2021.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_16321-5729-7915","score":15.861491,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03285-5746-7932","score":15.861491,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16321-14177-15957","score":14.878791,"text":"\nThe WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use. For more information about voice model options, see [Supported languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices).\n\nThe model you specify must be one that is supported by the Text to Speech service instance that is configured for use with the integration.\n\n\n\n\n\n\n\n Transferring a call to a live agent \n\nWhen you configure the phone integration, you can optionally set up backup call center support, which makes it possible for the assistant to transfer a call to a human.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_07578-506456-508701","score":14.081562,"text":"\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-506398-508643","score":14.081562,"text":"\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https:\/\/cloud.ibm.com\/billing\/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https:\/\/cloud.ibm.com\/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03369-22311-24192","score":14.011131,"text":"\nFor more information, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel).\n\n\n\n\n\n 3 December 2021 \n\nConfigure webhook timeout\n: From the Pre-message webhook and Post-message webhook configuration pages, you can configure the webhook timeout length from a minimum of 1 second to a maximum of 30 seconds. For more information, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-overview).\n\n\n\n\n\n 27 November 2021 \n\nNew API version\n: The current API version is now 2021-11-27. This version introduces the following changes:\n\n\n\n* The output.text object is no longer returned in message responses. All responses, including text responses, are returned only in the output.generic array.\n\n\n\n\n\n\n\n 9 November 2021 \n\nNew phone response types\n: New response types are available for controlling the configuration and behavior of the phone integration. These response types replace most of the older vgw actions, which are now deprecated. (The vgw actions will continue to work, so existing skills do not need to be changed.) For more information, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions).\n\nRich response types\n: Your assistant can now send responses that include elements such as audio, video, or embedded iframe content. For more information, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n 4 November 2021 \n\nActions enhancement: Add variables to links\n: In an actions skill, when including a link in an assistant response, you can now access and use variables. In the URL field for a link, type a dollar sign ($) character to see a list of variables to choose from.\n\n\n\n\n\n 14 October 2021 \n\nvgwHangUp message no longer sent","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_13790-1284-2889","score":13.936131,"text":"\n* For more information about obtaining word timings, see [Generating word timings](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nYou call the \/v1\/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.{location}.text-to-speech.watson.cloud.ibm.com\/instances\/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}\/v1\/synthesize.\n\nA WebSocket client calls the \/v1\/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-usingWebSocket"},{"document_id":"ibmcld_13455-1311-2796","score":13.266455,"text":"\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6. [Keep a connection alive](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-keep)\n7. [Close a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-close)\n\n\n\nWhen the client sends data to the service, it must pass all JSON messages as text messages and all audio data as binary messages.\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https:\/\/tools.ietf.org\/html\/rfc6455).\n\n\n\n Open a connection \n\nThe Speech to Text service uses the WebSocket Secure (WSS) protocol to make the \/v1\/recognize method available at the following endpoint:\n\nwss:\/\/api.{location}.speech-to-text.watson.cloud.ibm.com\/instances\/{instance_id}\/v1\/recognize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of your service instance.\n\nThe examples in the documentation abbreviate wss:\/\/api.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_13455-7-1568","score":13.2569895,"text":"\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the \/v1\/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-websockets"},{"document_id":"ibmcld_03285-13886-15581","score":13.253959,"text":"\nOnly changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13432-4611-6782","score":16.1461,"text":"\n* For information about the results of a speech recognition request, see [Understanding speech recognition results](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-basic-response).\n\n\n\n\n\n Data limits \n\nThe interfaces accept the following maximum amounts of audio data with a single request:\n\n\n\n* The WebSocket interface accepts a maximum of 100 MB of audio.\n* The synchronous HTTP interface accepts a maximum of 100 MB of audio.\n* The asynchronous HTTP interface accepts a maximum of 1 GB of audio.\n\n\n\nFor more information about using compression to maximize the amount of data that you can send to the service, see [Data limits and compression](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-audio-formatsaudio-formats-limits).\n\n\n\n\n\n Advantages of the WebSocket interface \n\nThe WebSocket interface has a number of advantages over the HTTP interface. The WebSocket interface\n\n\n\n* Provides a single-socket, full-duplex communication channel. The interface lets the client send multiple requests to the service and receive results over a single connection in an asynchronous fashion.\n* Provides a much simpler and more powerful programming experience. The service sends event-driven responses to the client's messages, eliminating the need for the client to poll the server.\n* Allows you to establish and use a single authenticated connection indefinitely. The HTTP interfaces require you to authenticate each call to the service.\n* Reduces latency. Recognition results arrive faster because the service sends them directly to the client. The HTTP interface requires four distinct requests and connections to achieve the same results.\n* Reduces network utilization. The WebSocket protocol is lightweight. It requires only a single connection to perform live-speech recognition.\n* Enables audio to be streamed directly from browsers (HTML5 WebSocket clients) to the service.\n* Returns results as soon as they are available when you use a next-generation model or request interim results.\n\n\n\n\n\n\n\n\n\n Using speech recognition parameters \n\nThe service's speech recognition interfaces share largely common parameters for transcribing speech to text.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-service-features"},{"document_id":"ibmcld_16321-14177-15957","score":16.091663,"text":"\nThe WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use. For more information about voice model options, see [Supported languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices).\n\nThe model you specify must be one that is supported by the Text to Speech service instance that is configured for use with the integration.\n\n\n\n\n\n\n\n Transferring a call to a live agent \n\nWhen you configure the phone integration, you can optionally set up backup call center support, which makes it possible for the assistant to transfer a call to a human.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_16321-5729-7915","score":16.024912,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03285-5746-7932","score":16.024912,"text":"\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_03369-22311-24192","score":14.863875,"text":"\nFor more information, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel).\n\n\n\n\n\n 3 December 2021 \n\nConfigure webhook timeout\n: From the Pre-message webhook and Post-message webhook configuration pages, you can configure the webhook timeout length from a minimum of 1 second to a maximum of 30 seconds. For more information, see [Webhook overview](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-webhook-overview).\n\n\n\n\n\n 27 November 2021 \n\nNew API version\n: The current API version is now 2021-11-27. This version introduces the following changes:\n\n\n\n* The output.text object is no longer returned in message responses. All responses, including text responses, are returned only in the output.generic array.\n\n\n\n\n\n\n\n 9 November 2021 \n\nNew phone response types\n: New response types are available for controlling the configuration and behavior of the phone integration. These response types replace most of the older vgw actions, which are now deprecated. (The vgw actions will continue to work, so existing skills do not need to be changed.) For more information, see [Handling phone interactions](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions).\n\nRich response types\n: Your assistant can now send responses that include elements such as audio, video, or embedded iframe content. For more information, see [Rich responses](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n 4 November 2021 \n\nActions enhancement: Add variables to links\n: In an actions skill, when including a link in an assistant response, you can now access and use variables. In the URL field for a link, type a dollar sign ($) character to see a list of variables to choose from.\n\n\n\n\n\n 14 October 2021 \n\nvgwHangUp message no longer sent","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-release-notes"},{"document_id":"ibmcld_03285-13886-15581","score":14.744328,"text":"\nOnly changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-dialog-voice-actions"},{"document_id":"ibmcld_16294-8240-10414","score":14.591379,"text":"\nOnce the phone number has been enabled for SMS, you will see a webhook icon beside the number.\n\nPaste the value that you copied from the Webhook URI field into it.\n15. Click Save.\n16. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n\n\n\n\n\n\n\n\n\n SMS Advanced configuration options \n\nThe Advanced options tab is available after you set up the SMS integration. Click the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your actions for messaging \n\nFor the best customer experience, design your actions with the capabilities of the SMS integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* The SMS integration does not support chat transfers that are initiated with the connect_to_agent response type.\n* Image, Audio, Video response types allow sending a message containing media. A title and description are sent along with the attachment. Note that depending on the carrier and device of the end user these messages may not be successfully received. For a list of the supported content types for Twilio, see [Twilio: Accepted Content Types for Media](https:\/\/www.twilio.com\/docs\/sms\/accepted-mime-types).\n\nFor more information on these response types, see [Response types reference](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\nIf you want to use the same action for an assistant that you deploy to many different platforms, add custom responses per integration type. You can add a conditioned response that tells the assistant to show the response only when the SMS integration is being used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-sms"},{"document_id":"ibmcld_13369-5768-7486","score":14.40404,"text":"\n* With the HTTP interfaces, the service waits for all of the audio to arrive before sending a response. It then sends a single stream of bytes in response. The response can include multiple transcription elements with multiple final results, and it can be sent incrementally. But it is a single stream of data.\n* With the WebSocket interface, the service sends final results as they become available. It can send multiple independent responses in the form of different streams of bytes. The connection is bidirectional and full duplex, and requests and responses can continue to flow back and forth over a single connection for as long as it remains active.\n\n\n\n\n\n Low-latency restrictions \n\nThe low-latency feature has the following usage restrictions:\n\n\n\n* Low latency is available only for some next-generation models. For next-generation models that do not support low-latency, if you include the low_latency parameter with a request, the service fails with status code 400:\n\n{\n\"code\": 400,\n\"code_description\": \"Bad Request\",\n\"error\": \"low_latency is not a supported feature for model {model_id}\"\n}\n* Low latency is not available for previous-generation models. For previous-generation models, if you include the low_latency parameter with a request, the service generates a warning:\n\n\"warnings\": [\n\"Unknown arguments: low_latency.\"\n]\n\n\n\n\n\n\n\n Low-latency example \n\nThe following synchronous HTTP example requests low latency with the en-US_Telephony model. The example sets the low_latency query parameter to true.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio\/wav\" --data-binary @{path}audio-file.wav \"{url}\/v1\/recognize?model=en-US_Telephony&low_latency=true\"\n\nIBM Cloud Pak for Data","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-interim"},{"document_id":"ibmcld_13429-163247-165127","score":14.27449,"text":"\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https:\/\/cloud.ibm.com\/apidocs\/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https:\/\/github.com\/watson-developer-cloud\/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"},{"document_id":"ibmcld_13429-175517-177105","score":14.190567,"text":"\n: The Content-Type header of the recognize methods now supports audio\/wav for Waveform Audio File (WAV) files, in addition to audio\/flac and audio\/l16. For more information, see [audio\/wav format](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-audio-formatsaudio-formats-wav).\n\nLimits on maximum amount of audio for speech recognition\n: The service now has a limit of 100 MB of data per session in streaming mode. You specify streaming mode by specifying the value chunked with the header Transfer-Encoding. One-shot delivery of an audio file still imposes a size limit of 4 MB on the data that is sent. For more information, see [Audio transmission](https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-inputtransmission).\n\nNew header to opt out of contributing to service improvements\n: The GET \/v1\/sessions\/{session_id}\/observe_result, POST \/v1\/sessions\/{session_id}\/recognize, and POST \/v1\/recognize methods now include the header parameter X-WDC-PL-OPT-OUT to control whether the service uses the audio and transcription data from a request to improve future results. The WebSocket interface includes an equivalent query parameter. Specify a value of 1 to prevent the service from using the audio and transcription results. The parameter applies only to the current request. The new header replaces the X-logging header from the beta API. See [Controlling request logging for Watson services](https:\/\/cloud.ibm.com\/docs\/watson?topic=watson-gs-logging-overview).\n\nChanges to HTTP error codes\n: The service can now respond with the following HTTP error codes:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/speech-to-text?topic=speech-to-text-release-notes"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"b4614daadceeecb400f7baf0aa48dcb8<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03312-7276-9469","score":17.399288,"text":"\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call. Using only the default transfer target to handle call failures is acceptable for low call volume scenarios but can result in large numbers of calls being directed to a customer contact center when bigger call volumes are handled by Watson Assistant. To enable this 500 error response capability for a specific Watson Assistant instance, you need to make a request to IBM.\n\nYou should plan for both full and partial service outages. A good first step is to plan for a manual failover between regions before enabling automation. This requires a complete replica of Watson Assistant in both regions, including all custom speech model training. When automation is enabled it is best to start with a strategy for detecting and failing over to the passive backup region when a complete regional outage is detected. After this is in place, a strategy can be implemented to deal with partial outages, which should cover the vast majority of failure conditions that can occur with a phone integration deployment.\n\n\n\n\n\n\n\n Web chat \n\n\n\n Monitoring \n\nWeb chat provides an onError listening feature that allows the host page to detect specific types of outage errors, in particular INITIAL_CONFIG, OPEN_CONFIG, and MESSAGE_COMMUNICATION errors.\n\nYou can find the documentation for this feature here:\n\n[https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration#onerror-detail](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationonerror-detail)\n\n\n\n\n\n Failover \n\nHandling a failover for web chat is simple assuming you have set up an additional web chat integration in another region. When the failover needs to be manually triggered, make the following changes:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-failover"},{"document_id":"ibmcld_16250-7169-9454","score":16.225471,"text":"\nUsing only the default transfer target to handle call failures is acceptable for low call volume scenarios but can result in large numbers of calls being directed to a customer contact center when bigger call volumes are handled by Watson Assistant. To enable this 500 error response capability for a specific Watson Assistant instance, you need to make a request to IBM.\n\nYou should plan for both full and partial service outages. A good first step is to plan for a manual failover between regions before enabling automation. This requires a complete replica of Watson Assistant in both regions, including all custom speech model training. When automation is enabled it is best to start with a strategy for detecting and failing over to the passive backup region when a complete regional outage is detected. After this is in place, a strategy can be implemented to deal with partial outages, which should cover the vast majority of failure conditions that can occur with a phone integration deployment.\n\n\n\n\n\n\n\n Web chat \n\n\n\n Monitoring \n\nWeb chat provides an onError listening feature that allows the host page to detect specific types of outage errors, in particular INITIAL_CONFIG, OPEN_CONFIG, and MESSAGE_COMMUNICATION errors.\n\nYou can find the documentation for this feature here:\n\n[https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configuration#onerror-detail](https:\/\/web-chat.global.assistant.watson.cloud.ibm.com\/docs.html?to=api-configurationonerror-detail)\n\n\n\n\n\n Failover \n\nHandling a failover for web chat is simple assuming you have set up an additional web chat integration in another region. When the failover needs to be manually triggered, make the following changes:\n\n\n\n* The embed script that contains your integration ID, region, service instance ID, and subscription ID (if applicable) needs be changed or updated to use the IDs for the new integration and region.\n* If you are using Salesforce or ZenDesk integrations for connecting to human agents, update the configuration within those systems to make sure they can communicate with the correct integration. Follow the instructions on the Live agent tab in the web chat configuration for setting up those systems. This is only needed for obtaining the conversation history for the agent.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-admin-failover"},{"document_id":"ibmcld_16321-14177-15957","score":15.487295,"text":"\nThe WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https:\/\/cloud.ibm.com\/apidocs\/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use. For more information about voice model options, see [Supported languages and voices](https:\/\/cloud.ibm.com\/docs\/text-to-speech?topic=text-to-speech-voiceslanguageVoices).\n\nThe model you specify must be one that is supported by the Text to Speech service instance that is configured for use with the integration.\n\n\n\n\n\n\n\n Transferring a call to a live agent \n\nWhen you configure the phone integration, you can optionally set up backup call center support, which makes it possible for the assistant to transfer a call to a human.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_16288-7-2218","score":14.893183,"text":"\nPhone integration configuration \n\nIBM Cloud\n\nAfter you have set up the phone integration for your assistant, you can modify the phone integration settings to customize the call behavior.\n\n\n\n Handling call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, go to the Advanced tab in the phone integration settings, and make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup call center support](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-transfer-service).\n* Call failure message: Add the message you want the assistant to say to a caller before it transfers the call to a human agent.\n\n\n\nIf, after you transfer the call to a human, the connection to a live agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message you want the assistant to say to a caller if transfer to a live agent fails. The message can be up to 150 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after the failure message. This option is enabled by default. If this option is disabled, when a call transfer fails, your assistant can disconnect or process a different action.\n\nIf you choose to leave a call connected despite a transfer failure, Watson Assistant will initiate a new turn to determine the next step. It's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16321-20604-22275","score":14.220276,"text":"\n\"message\": \"Sorry, I could not find an agent.\"\n},\n\"message_to_human_agent\": \"The caller needs help resetting their password\"\n}\n]\n}\nShow more\n\n\n\n\n\n Transferring upon failure \n\nTo configure transfer on failures, go to the Advanced tab in the phone integration settings. The following selections can be configured:\n\n\n\n* Transfer failure message\n* Disconnect call on transfer failure\n\n\n\nFor more information, see [Handling call and transfer failures](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-failure).\n\n\n\n\n\n Passing Watson Assistant Metadata in SIP Signaling \n\nTo support loading the conversational history between the caller and Watson Assistant, the phone integration specifies a value for the User-to-User header as a key that can be used with the web chat integration. If User-to-User is specified in the transfer_headers list, the session history key is sent in the X-Watson-Assistant-Session-History-Key header.\n\nThe value of the SIP header is limited to 1024 bytes.\n\nHow this data is presented in the SIP REFER message also depends on the value of transfer_headers_send_method(as defined in [Generic Service Desk SIP Parameters](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actionsgeneric-service-desk-sip-parameters)).\n\nThe following example shows the data included as headers:\n\nREFER sip:b@atlanta.example.com SIP\/2.0\nVia: SIP\/2.0\/UDP agenta.atlanta.example.com;branch=z9hG4bK2293940223\nTo: <sip:b@atlanta.example.com>\nFrom: <sip:a@atlanta.example.com>;tag=193402342\nCall-ID: 898234234@agenta.atlanta.example.com\nCSeq: 23 REFER\nMax-Forwards: 7\nRefer-To: sip:user@domain.com","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_03312-5487-7760","score":14.009659,"text":"\nIf a failover is automated and a regional backup is enabled, it is always best to try a different zone first and only redirect traffic to the passive backup region if a preconfigured number of failures occur within a short period of time. This prevents an unnecessary failover between regions if only a short outage occurs.\n\nNote that Watson Assistant provides a round-robin fully qualified domain name (FQDN) that includes the IPs for each zone in the region. Many SIP trunking providers automatically retry each IP in the FQDN when failures occur. To support disaster recovery, the service provider may need to configure two separate SIP trunks, one for each region, and only when all the zones in a single region fail should the call be switched to the backup region. It's important to set the SIP INVITE failure timeouts at the SIP trunking provider low enough to avoid long call setup latencies when a failover is occurring.\n\n\n\n\n\n Partial service outage \n\nThe second type of failure is a partial service outage within the region. This is much harder to detect and manage because of the large number of variations in service failures that can occur within a region. In some cases, these may be small issues that affect the performance characteristics of the call but not cause the call to fail.\n\nFor issues like this that ultimately cause a call to fail, there are two ways Watson Assistant can handle the call. The first is to accept the call and then transfer it to a configured default SIP URI. This can be configured in the Watson Assistant phone integration settings and is also used if there is a mid-call failure. The default transfer target SIP URI is defined in the SIP target when a call fails field located on the Advanced tab of the phone integration configuration panel.\n\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-failover"},{"document_id":"ibmcld_16321-19290-20983","score":13.866095,"text":"\n\"uri\": \"sip:12345556789\\@myhost.com\"\n\n\n\n Transferring after hangup \n\nBy default, the phone integration transfers calls by using a SIP REFER request. Depending on the IVR service provider, you might need to configure call transfer to use a SIP BYE request instead. Use the transfer_method attribute to specify how to transfer the call, using either refer or hangup. When transfer_method is set to hangup instead of refer, the behavior of the transfer action changes. Instead of sending a SIP REFER request, the phone integration plays back any associated text and then hangs up the call by sending a SIP BYE request.\n\nAfter the hangup, the phone integration passes the transfer destination that is specified in the url attribute to the call anchor in the BYE message. The header field that contains the transfer target is determined by the transfer_target_header attribute. If the transfer_target_header attribute isn't specified, the phone integration uses Transfer-Target.\n\n{\n\"generic\": [\n{\n\"response_type\": \"connect_to_agent\",\n\"transfer_info\": {\n\"target\": {\n\"service_desk\": {\n\"sip\": {\n\"uri\": \"sip:user\\@domain.com\",\n\"transfer_method\": \"hangup\",\n\"transfer_target_header\": \"Transfer-Target\"\n}\n}\n}\n},\n\"agent_available\": {\n\"message\": \"Please hold on while I connect you with a live agent.\"\n},\n\"agent_unavailable\": {\n\"message\": \"Sorry, I could not find an agent.\"\n},\n\"message_to_human_agent\": \"The caller needs help resetting their password\"\n}\n]\n}\nShow more\n\n\n\n\n\n Transferring upon failure \n\nTo configure transfer on failures, go to the Advanced tab in the phone integration settings. The following selections can be configured:\n\n\n\n* Transfer failure message\n* Disconnect call on transfer failure","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-phone-actions"},{"document_id":"ibmcld_16288-1733-3996","score":13.659372,"text":"\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16288-10521-12298","score":13.36986,"text":"\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Add a number and then Buy a Number.\n* If you already have a number, you can click Add a number and then Add an Existing Number.\n\n\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target. For more information, see the [Twilio documentation](https:\/\/support.twilio.com\/hc\/en-us\/articles\/223136107-How-does-Twilio-s-Free-Trial-work-).\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https:\/\/www.five9.com\/products\/capabilities\/contact-center-software)\n* [Genesys](https:\/\/www.genesys.com\/en-sg\/definitions\/what-is-a-trunk)\n* [Vonage](https:\/\/www.vonage.com\/communications-apis\/sip-trunking\/)\n* [Voximplant](https:\/\/voximplant.com\/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-phone-config"},{"document_id":"ibmcld_16294-8240-10414","score":13.220119,"text":"\nOnce the phone number has been enabled for SMS, you will see a webhook icon beside the number.\n\nPaste the value that you copied from the Webhook URI field into it.\n15. Click Save.\n16. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n\n\n\n\n\n\n\n\n\n SMS Advanced configuration options \n\nThe Advanced options tab is available after you set up the SMS integration. Click the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your actions for messaging \n\nFor the best customer experience, design your actions with the capabilities of the SMS integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* The SMS integration does not support chat transfers that are initiated with the connect_to_agent response type.\n* Image, Audio, Video response types allow sending a message containing media. A title and description are sent along with the attachment. Note that depending on the carrier and device of the end user these messages may not be successfully received. For a list of the supported content types for Twilio, see [Twilio: Accepted Content Types for Media](https:\/\/www.twilio.com\/docs\/sms\/accepted-mime-types).\n\nFor more information on these response types, see [Response types reference](https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\nIf you want to use the same action for an assistant that you deploy to many different platforms, add custom responses per integration type. You can add a conditioned response that tells the assistant to show the response only when the SMS integration is being used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-deploy-sms"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.2640681226,"ndcg_cut_10":0.4486438194}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13895-7118-8344","score":9.51188,"text":"\n6.7R14S2 \n\nReleased October 10, 2017.\n\n\n\n Issues Resolved \n\n\n\nIssues resolved in 6.7R14S2\n\n Issue Number Priority Summary \n\n VSE-9837 Minor \u201cshow system commit different\u201d showing permission denied after upgrade from 6.7R11S9 to 6.7R13S3 \n\n\n\n\n\n\n\n Security Vulnerabilities Resolved \n\n\n\nSecurity vulnerabilties resolved in 6.7R14S2\n\n Issue Number CVSS score Advisory Summary \n\n VSE-9845 9.8 DLA-1124-1 CVE-2017-14491, CVE-2017-14492, CVE-2017-14494: Debian DLA-1124-1: dnsmasq security update \n\n\n\n\n\n\n\n\n\n 6.7R14S1 \n\nReleased September 22, 2017.\n\n\n\n Issues Resolved \n\n\n\nIssues resolved in 6.7R14S1\n\n Issue Number Priority Summary \n\n VSE-9831 Major MTU setting reverts back to default after reboot on a VIF interface \n\n\n\n\n\n\n\n Security Vulnerabilities Resolved \n\n\n\nSecurity vulnerabilties resolved in 6.7R14S1\n\n Issue Number CVSS score Advisory Summary \n\n VSE-9841 9.8 DLA-1060-1 CVE-2017-0663, CVE-2017-7376: Debian DLA-1060-1: libxml2 security update \n VSE-9840 6.5 DLA-1062-1 CVE-2017-1000100: Debian DLA-1062-1: curl security update \n VSE-9839 7.5 DLA-1059-1 CVE-2017-11185: Debian DLA-1059-1: strongswan security update \n VSE-9835 7.5 DSA-3900-1 CVE-2017-7522, CVE-2017-7521, CVE-2017-7520, CVE-2017-7508 OpenVPN security update","title":"","source":"https:\/\/cloud.ibm.com\/docs\/virtual-router-appliance?topic=virtual-router-appliance-at-t-vyatta-5400-vrouter-security-vulnerability-fixes"},{"document_id":"ibmcld_12143-11142-12571","score":9.420616,"text":"\nVersions 0.13 through 0.15 require a stepwise upgrade, 0.13 to 0.14, 0.14 to 0.15, 0.15 to 1.0.\n\nThe process is the same for each version step. It is mandatory that a Terraform Apply is run after each version change. This updates the Terraform state file with schema changes related to that version and that version only. After successfully upgrading a single version, the next version update can be performed.\n\n\n\n1. Read the Terraform [upgrade guide](https:\/\/developer.hashicorp.com\/terraform\/language\/v1.1.x\/upgrade-guides) for the release and implement any required config changes.\n2. Follow the process outlined in [Upgrading the Terraform template version 1.x and above](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-migrating-terraform-versionterraform-version-upgrade1x-process) to upgrade a single version to the target version.\n3. Verify in the Workspace settings page the TF version is now set to the desired version.\n4. Run a Generate Plan operation against the workspace. Validate that the command runs successfully without error and no unexpected messages are logged. The Plan should result in no proposed changes to the resources.\n5. Run a Apply Plan operation against the workspace. This step is mandatory to perform a Terraform state file update. Validate that the command runs successfully without error and no unexpected messages are logged.\n6. You have now successfully upgraded a single version step.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-migrating-terraform-version"},{"document_id":"ibmcld_00861-233607-234578","score":9.241615,"text":"\nTo view the contents of version 2.11, from the running image, type default_versions.sh. This image includes the following tools:\n\n node --version\nv12.20.1\n\n npm --version\n6.14.11\n\n jq --version\njq-1.6\n\n yq --version\nyq version 2.4.1\n\n yq3 --version\nyq version 3.4.1\n\n kubectl version --client\nClient Version: version.Info{Major:\"1\", Minor:\"17+\", GitVersion:\"v1.17.16-rc.0\", GitCommit:\"737e2c461a2999fa242d39e77b9252d0eee7167e\", GitTreeState:\"clean\", BuildDate:\"2020-12-09T11:14:02Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux\/amd64\"}\n\n buildctl --version\nbuildctl github.com\/moby\/buildkit v0.8.0 73fe4736135645a342abc7b587bba0994cccf0f9\n\n helm version --client\nClient: &version.Version{SemVer:\"v2.17.0\", GitCommit:\"a690bad98af45b015bd3da1a41f6218b1a451dbe\", GitTreeState:\"clean\"}\n\n helm3 version --client\nversion.BuildInfo{Version:\"v3.4.2\", GitCommit:\"23dd3af5e19a02d4f4baa5b2f242645a1a3af629\", GitTreeState:\"clean\", GoVersion:\"go1.14.13\"}\n\n ibmcloud -version","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_00861-261247-262292","score":9.236227,"text":"\nTo view the contents of version 2.1, from the running image, type default_versions.sh. This image includes the following tools:\n\n node --version\nv10.16.0\n\n npm --version\n6.9.0\n\n jq --version\njq-1.6\n\n yq --version\nyq version 2.4.0\n\n kubectl version --client\nClient Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.3\", GitCommit:\"5e53fd6bc17c0dec8434817e69b04a25d8ae0ff0\", GitTreeState:\"clean\", BuildDate:\"2019-06-06T01:44:30Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux\/amd64\"}\n\n helm version --client\nClient: &version.Version{SemVer:\"v2.14.1\", GitCommit:\"5270352a09c7e8b6e8c9593002a73535276507c0\", GitTreeState:\"clean\"}\n\n ibmcloud -version\nibmcloud version 0.16.2+d1a5f92-2019-06-06T18:32:54+00:00\n\n ibmcloud plugin list\nListing installed plug-ins...\n\nPlugin Name Version Status\ncloud-functions\/wsk\/functions\/fn 1.0.32\ncontainer-registry 0.1.391\ncontainer-service\/kubernetes-service 0.3.47\ndoi 0.1.2\n\n java -version\nopenjdk version \"1.8.0_212\"\nOpenJDK Runtime Environment (build 1.8.0_212-8u212-b03-0ubuntu1.16.04.1-b03)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_00861-237281-238251","score":9.187798,"text":"\nTo view the contents of version 2.10, from the running image, type default_versions.sh. This image includes the following tools:\n\n node --version\nv12.20.0\n\n npm --version\n6.14.9\n\n jq --version\njq-1.6\n\n yq --version\nyq version 2.4.1\n\n yq3 --version\nyq version 3.4.1\n\n kubectl version --client\nClient Version: version.Info{Major:\"1\", Minor:\"17+\", GitVersion:\"v1.17.16-rc.0\", GitCommit:\"737e2c461a2999fa242d39e77b9252d0eee7167e\", GitTreeState:\"clean\", BuildDate:\"2020-12-09T11:14:02Z\", GoVersion:\"go1.13.15\", Compiler:\"gc\", Platform:\"linux\/amd64\"}\n\n buildctl --version\nbuildctl github.com\/moby\/buildkit v0.8.0 73fe4736135645a342abc7b587bba0994cccf0f9\n\n helm version --client\nClient: &version.Version{SemVer:\"v2.17.0\", GitCommit:\"a690bad98af45b015bd3da1a41f6218b1a451dbe\", GitTreeState:\"clean\"}\n\n helm3 version --client\nversion.BuildInfo{Version:\"v3.4.2\", GitCommit:\"23dd3af5e19a02d4f4baa5b2f242645a1a3af629\", GitTreeState:\"clean\", GoVersion:\"go1.14.13\"}\n\n ibmcloud -version","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_16173-12945-14297","score":9.162592,"text":"\nIBM has since transitioned to a new architecture for its gateways that leverages SR-IOV on the host. This caused the vSRX configuration\u2019s interface mapping to change in many cases. Differences in the interface configuration are also influenced by whether the vSRX is:\n\n\n\n* 10G or 1G\n* Standalone or High Availability\n* Public and Private, or Private Only\n* The vSRX Version\n\n\n\n* All 15.1 based vSRX\u2019s use the legacy architecture\n* Some 18.4 based vSRX\u2019s also use the legacy architecture\n\n\n\n\n\nBoth the legacy and current architecture is detailed in the following sections.\n\n\n\n vSRX High Availability interfaces (current architecture) \n\n\n\nTable 2: vSRX High Availability interfaces (current architecture)\n\n Interface 10G Pub+Priv 10G Priv Only 1G Pub+Priv 1G Priv Only \n\n ge-0\/0\/0 fab0 fab0 fab0 fab0 \n ge-0\/0\/1 reth0 reth0 reth0 reth0 \n ge-0\/0\/2 reth0 reth0 reth0 reth0 \n ge-0\/0\/3 reth1 reth2 reth1 reth2 \n ge-0\/0\/4 reth1 reth2 reth1 reth2 \n ge-0\/0\/5 reth2 fab0 reth2 fab0 \n ge-0\/0\/6 reth2 Does Not Exist reth2 Does Not Exist \n ge-0\/0\/7 reth3 Does Not Exist reth3 Does Not Exist \n ge-0\/0\/8 reth3 Does Not Exist reth3 Does Not Exist \n ge-0\/0\/9 fab0 Does Not Exist fab0 Does Not Exist \n ge-7\/0\/0 fab1 fab1 fab1 fab1 \n ge-7\/0\/1 reth0 reth0 reth0 reth0 \n ge-7\/0\/2 reth0 reth0 reth0 reth0 \n ge-7\/0\/3 reth1 reth2 reth1 reth2 \n ge-7\/0\/4 reth1 reth2 reth1 reth2","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vsrx?topic=vsrx-understanding-the-vsrx-default-configuration"},{"document_id":"ibmcld_12897-5384-7049","score":9.088825,"text":"\n\"_conflicts\":[\"2-61ae00e029d4f5edd2981841243ded13\"]\n}\n\nThe version with the changed price was chosen arbitrarily as the latest version of the document. The conflict with another version is noted by providing the ID of that other version in the _conflicts array. In most cases, this array has only one element, but many conflicting revisions might exist.\n\n\n\n\n\n Merge the changes \n\nTo compare the revisions to see what changed, your application gets all of the versions from the database.\n\nSee the following example commands to retrieve all versions of a document from the database:\n\nhttps:\/\/$ACCOUNT.cloudant.com\/products\/$_ID\nhttps:\/\/$ACCOUNT.cloudant.com\/products\/$_ID?rev=2-61ae00e029d4f5edd2981841243ded13\nhttps:\/\/$ACCOUNT.cloudant.com\/products\/$_ID?rev=1-7438df87b632b312c53a08361a7c3299\n\nSince the conflicting changes are for different fields of the document, it is easy to merge them.\n\nFor more complex conflicts, other resolution strategies might be required:\n\n\n\n* Time based - use the first or last edit.\n* User intervention - report conflicts to users and let them decide on the best resolution.\n* Sophisticated algorithms - for example, 3-way merges of text fields.\n\n\n\nFor a practical example of how to implement a merge of changes, see this project with [sample code](https:\/\/github.com\/glynnbird\/deconflict).\n\n\n\n\n\n Upload the new revision \n\nThe next step is to create a document that resolves the conflicts, and update the database with it.\n\nSee the following example document that merges changes from the two conflicting revisions:\n\n{\n\"_id\": \"74b2be56045bed0c8c9d24b939000dbe\",\n\"_rev\": \"3-daaecd7213301a1ad5493186d6916755\",\n\"name\": \"Samsung Galaxy S4\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvcc"},{"document_id":"ibmcld_00861-263463-264537","score":9.075992,"text":"\nTo view the contents of version 2.0, from the running image, type default_versions.sh. This image includes the following tools:\n\n node --version\nv10.15.3\n\n npm --version\n6.4.1\n\n jq --version\njq-1.6\n\n yq --version\nyq version 2.2.1\n\n kubectl version\nClient Version: version.Info{Major:\"1\", Minor:\"12\", GitVersion:\"v1.12.2\", GitCommit:\"17c77c7898218073f14c8d573582e8d2313dc740\", GitTreeState:\"clean\", BuildDate:\"2018-10-24T06:54:59Z\", GoVersion:\"go1.10.4\", Compiler:\"gc\", Platform:\"linux\/amd64\"}\nThe connection to the server localhost:8080 was refused - did you specify the right host or port?\n\n helm version --client\nClient: &version.Version{SemVer:\"v2.12.3\", GitCommit:\"eecf22f77df5f65c823aacd2dbd30ae6c65f186e\", GitTreeState:\"clean\"}\n\n ibmcloud -version\nibmcloud version 0.14.0+3303164-2019-02-06T06:09:00+00:00\n\n ibmcloud plugin list\nListing installed plug-ins...\n\nPlugin Name Version Status\ncloud-functions\/wsk\/functions\/fn 1.0.30\ncontainer-registry 0.1.380\ncontainer-service\/kubernetes-service 0.2.99 Update Available\ndoi 0.1.0\n\n java -version\nopenjdk version \"1.8.0_191\"","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"},{"document_id":"ibmcld_06876-1099-1940","score":9.058636,"text":"\n0cc6ddd7dafffdc5a955a640e678633c2710b174 refs\/tags\/5\n0cc6ddd7dafffdc5a955a640e678633c2710b174 refs\/tags\/6\n83f7a87ee59185eaeac554bd3abeebfd2c1b4ad8 refs\/tags\/8\n0019d75d466bbdaba02ea979f3e094784a10b558 refs\/tags\/9\n1914a125e76aa97c497f4bd2c2f455b58cf079b8 refs\/tags\/10\nd9dd5d8553889ef24dff0678a3fcbae8aed3259b refs\/tags\/11\n1914a125e76aa97c497f4bd2c2f455b58cf079b8 refs\/tags\/prod_latest\n\n\n\n1. Select the inventory state to revert to refs\/tags\/8. The following command lists all the versions or commits between the current state (refs\/tags\/prod_latest) and the last known good state (refs\/tags\/8).\n\n\n\n \/c\/usr\/devsecops\/compliance-inventory (master)\n$ git rev-list --no-merges HEAD...83f7a87ee59185eaeac554bd3abeebfd2c1b4ad8\n67cc8babdff3e09c1f0e632f897798c1b5424f38\n6fab5ce3d60590cd858206424ecfd7d3a8c9ceb4\n22a575d48008299116ea426bdac45417d9df6238","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-rollback-deployment"},{"document_id":"ibmcld_00861-259033-260078","score":9.027411,"text":"\nTo view the contents of version 2.2, from the running image, type default_versions.sh. This image includes the following tools:\n\n node --version\nv10.16.0\n\n npm --version\n6.9.0\n\n jq --version\njq-1.6\n\n yq --version\nyq version 2.4.0\n\n kubectl version --client\nClient Version: version.Info{Major:\"1\", Minor:\"14\", GitVersion:\"v1.14.3\", GitCommit:\"5e53fd6bc17c0dec8434817e69b04a25d8ae0ff0\", GitTreeState:\"clean\", BuildDate:\"2019-06-06T01:44:30Z\", GoVersion:\"go1.12.5\", Compiler:\"gc\", Platform:\"linux\/amd64\"}\n\n helm version --client\nClient: &version.Version{SemVer:\"v2.14.1\", GitCommit:\"5270352a09c7e8b6e8c9593002a73535276507c0\", GitTreeState:\"clean\"}\n\n ibmcloud -version\nibmcloud version 0.16.3+68cb57c-2019-06-20T08:59:16+00:00\n\n ibmcloud plugin list\nListing installed plug-ins...\n\nPlugin Name Version Status\ncloud-functions\/wsk\/functions\/fn 1.0.32\ncontainer-registry 0.1.395\ncontainer-service\/kubernetes-service 0.3.58\ndoi 0.1.3\n\n java -version\nopenjdk version \"1.8.0_212\"\nOpenJDK Runtime Environment (build 1.8.0_212-8u212-b03-0ubuntu1.16.04.1-b03)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-pipeline_versioned_base_images"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12897-5384-7049","score":11.243244,"text":"\n\"_conflicts\":[\"2-61ae00e029d4f5edd2981841243ded13\"]\n}\n\nThe version with the changed price was chosen arbitrarily as the latest version of the document. The conflict with another version is noted by providing the ID of that other version in the _conflicts array. In most cases, this array has only one element, but many conflicting revisions might exist.\n\n\n\n\n\n Merge the changes \n\nTo compare the revisions to see what changed, your application gets all of the versions from the database.\n\nSee the following example commands to retrieve all versions of a document from the database:\n\nhttps:\/\/$ACCOUNT.cloudant.com\/products\/$_ID\nhttps:\/\/$ACCOUNT.cloudant.com\/products\/$_ID?rev=2-61ae00e029d4f5edd2981841243ded13\nhttps:\/\/$ACCOUNT.cloudant.com\/products\/$_ID?rev=1-7438df87b632b312c53a08361a7c3299\n\nSince the conflicting changes are for different fields of the document, it is easy to merge them.\n\nFor more complex conflicts, other resolution strategies might be required:\n\n\n\n* Time based - use the first or last edit.\n* User intervention - report conflicts to users and let them decide on the best resolution.\n* Sophisticated algorithms - for example, 3-way merges of text fields.\n\n\n\nFor a practical example of how to implement a merge of changes, see this project with [sample code](https:\/\/github.com\/glynnbird\/deconflict).\n\n\n\n\n\n Upload the new revision \n\nThe next step is to create a document that resolves the conflicts, and update the database with it.\n\nSee the following example document that merges changes from the two conflicting revisions:\n\n{\n\"_id\": \"74b2be56045bed0c8c9d24b939000dbe\",\n\"_rev\": \"3-daaecd7213301a1ad5493186d6916755\",\n\"name\": \"Samsung Galaxy S4\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvcc"},{"document_id":"ibmcld_04335-212022-213814","score":10.909384,"text":"\n--quiet, -q\n: Specify this option to reduce the output of the command. This value is optional. The default value is false.\n\n\n\n\n\n Example \n\nThe following command updates a Git access secret that is called github to use a new host.\n\nibmcloud ce repo update -n github --host NEW_HOST\n\n\n\n\n\n Example output \n\nGetting Git access secret 'github'...\nUpdating Git access secret 'github'...\nOK\n\n\n\n\n\n\n\n\n\n Revision commands \n\nAn application, or app, runs your code to serve HTTP requests. In addition to traditional HTTP requests, IBM Cloud\u00ae Code Engine also supports applications that use WebSockets as their communications protocol. An app contains one or more revisions. A revision represents an immutable version of the configuration properties of the app. Each update of an app configuration property creates a new revision of the app.\n\nUse revision commands to manage application revisions.\n\nYou must be within the context of a [project](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-clicli-project) before you use revision commands.\n\nFor more information about working with revisions for apps, see [Deploying applications](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-application-workloads).\n\nYou can use either revision or rev in your revision commands. To see CLI help for the revision commands, run ibmcloud ce revision -h.\n\n\n\n ibmcloud ce revision delete \n\nDelete an application revision.\n\nibmcloud ce revision delete --name REVISION_NAME [--force] [--ignore-not-found] [--quiet]\n\n\n\n Command Options \n\n--name, -n\n: The name of the application revision. This value is required.\n\n--force, -f\n: Force deletion without confirmation. This value is optional. The default value is false.\n\n--ignore-not-found, --inf\n: If not found, do not fail. This value is optional. The default value is false.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cli"},{"document_id":"ibmcld_05337-25650-27624","score":10.495917,"text":"\n1.5.0 10 May 2021 <br><br> * Added the revision delete, revision get, and revision list commands for managing application revisions.<br> * Added the --show-all-revisions option to the application get command to display all revisions for the specified app.<br> * Added revision Tag information to the application get command.<br> * Changed application revision name generation. For example, an app revision that is created before CLI 1.5.0 is of the format myapp-abc12-1. An app revision that is created starting from CLI 1.5.0 is of the format myapp-00001.<br> * Updated the yaml output for the secret get and secret list commands to show Code Engine generic secrets as type Opaque.<br><br><br> \n 1.4.0 29 April 2021 <br><br> * Added the registry update and repo update commands.<br> * Added the --decode option on the registry get, repo get, and secret get commands to show data as decoded.<br> * Updated the build list and build get command output to replace kaniko with dockerfile.<br> * Updated the output of get and list commands so that if the --output yaml or --output json option is used with these commands, then the command output no longer displays managedFields information.<br><br><br> \n 1.3.0 21 April 2021 <br><br> * Added --wait, --no-wait, and --wait-timeout options to the project delete command.<br> * Added support for CloudEvent extensions on subscription COS and subscription ping commands. This support adds the --extensions option to the subscription COS create, subscription COS update, subscription ping create, and subscription ping update commands. Also adds the --extensions-rm option to the subscription COS update and subscription ping update commands to remove CloudEvent extensions.<br> * Updated the project status on the output for the project get and the project list commands. The status of provisioning is changed to creating, and the status of pending reclamation is changed to soft deleted.<br> * Fixed various minor bugs.<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cli_versions"},{"document_id":"ibmcld_05278-253270-254957","score":10.446339,"text":"\nThe default value is false.\n\n\n\n\n\n Example \n\nibmcloud ce revision logs -n myapp-00001\n\n\n\n\n\n Example output \n\nCode Engine retains only the latest inactive revision of your application in addition to your active app revision. Older revisions are not retained.\n\nGetting logs for all instances of application revision 'newapp-mytest-00002'...\nGetting application revision 'newapp-mytest-00002'...\nOK\n\nnewapp-mytest-00002-deployment-7c87cfbf66-xnwkp\/user-container:\n2021-07-15 20:40:56 Listening on port 8080\n\n\n\n\n\n\n\n\n\n Secret commands \n\nA secret provides a method to include sensitive configuration information, such as passwords or SSH keys, to your deployment. By referencing values from your secret, you can decouple sensitive information from your deployment to keep your app or job portable. Anyone who is authorized to your project can also view your secrets; be sure that you know that the secret information can be shared with those users. Secrets contain information in key-value pairs.\n\nYou must be within the context of a [project](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-project) before you use secret commands.\n\nFor more information about working with secrets, see [Working with secrets](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret).\n\nTo see CLI help for the secret commands, run ibmcloud ce secret -h.\n\nBeginning with CLI version 1.42.0, defining and working with secrets in the CLI is unified under the secret command group. Use the --format option to specify the category of secret, such as basic_auth, generic, ssh, tls, or registry. The default value for the --format option is generic.\n\n\n\n ibmcloud ce secret create \n\nCreate a secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cli"},{"document_id":"ibmcld_12580-1668-3050","score":10.433714,"text":"\nEdit the configuration to update it to the new version.\n\nIf the new version is a major version update, for example, going from version 1.0.0 to 2.0.0, review the readme file for the deployable architecture to learn about any special handling that might be required before you deploy the new version.\n\nIt's a best practice to deploy new versions in your testing environment first to check for issues. Then, deploy to your production environment. You might also want to deploy the new version to a single region first to check for issues before you deploy to all regions.\n\nTo update your configuration, complete the following steps:\n\n\n\n1. From the projects list, select a project.\n2. Go to the Configurations tab, and select a deployable architecture configuration.\n3. Click Edit.\n4. In the Select inputs section, use the Version menu to select the new version of the deployable architecture.\n5. Click Save.\n6. Validate and approve your changes before you deploy.\n\n\n\n\n\n\n\n Changes not deployed \n\nAfter your save and validate your changes, you are notified that the changes are not deployed. Your changes must be approved before you deploy your configuration. You can also go to the Activity tab for more details on this update.\n\n\n\n\n\n Validation successful \n\nThe validation of your changes is complete. Issues didn't occur during the validation process, and you can deploy your changes.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-needs-attention-projects"},{"document_id":"ibmcld_05278-243417-245234","score":10.320507,"text":"\nUse jsonpath to specify the path to an element of the JSON output. This value is optional.\n\n--quiet, -q\n: Specify this option to reduce the output of the command. This value is optional. The default value is false.\n\n\n\n\n\n Example \n\nThe following command updates a Git access secret that is called github to use a new host.\n\nibmcloud ce repo update -n github --host NEW_HOST\n\n\n\n\n\n Example output \n\nGetting Git access secret 'github'...\nUpdating Git access secret 'github'...\nOK\n\n\n\n\n\n\n\n\n\n Revision commands \n\nAn application, or app, runs your code to serve HTTP requests. In addition to traditional HTTP requests, IBM Cloud\u00ae Code Engine also supports applications that use WebSockets as their communications protocol. An app contains one or more revisions. A revision represents an immutable version of the configuration properties of the app. Each update of an app configuration property creates a new revision of the app.\n\nUse revision commands to manage application revisions.\n\nYou must be within the context of a [project](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-project) before you use revision commands.\n\nFor more information about working with revisions for apps, see [Deploying applications](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-application-workloads).\n\nYou can use either revision or rev in your revision commands. To see CLI help for the revision commands, run ibmcloud ce revision -h.\n\n\n\n ibmcloud ce revision delete \n\nDelete an application revision.\n\nibmcloud ce revision delete --name REVISION_NAME [--force] [--ignore-not-found] [--quiet]\n\n\n\n Command Options \n\n--name, -n\n: The name of the application revision. This value is required.\n\n--force, -f\n: Force deletion without confirmation. This value is optional. The default value is false.\n\n--ignore-not-found, --inf","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cli"},{"document_id":"ibmcld_16034-15398-17327","score":10.301547,"text":"\nUpdated commands \n\n\n\n* Update vpn-server-update command to support VPN server upgrade and downgrade.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Linux_S390x build support added.\n\n\n\n\n\n\n\n\n\n v2.0.0 \n\nVersion 2.0.0 was released on 2021-11-18.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance commands with \"by name\" support. Instance commands include instance-initialization-values, instance-console, instance-create, instance-create-from-template, instance-delete, instance-disk, instance-disk-update, instance-disks, instance-network-interface, instance-network-interface-create, instance-network-interface-delete, instance-network-interface-floating-ip, instance-network-interface-floating-ip-add, instance-network-interface-floating-ip-remove, instance-network-interface-floating-ips, instance-network-interface-update, instance-network-interfaces, instance-reboot, instance-stop, instance-update, instance-volume-attachments, instance-volume-attachment, instance-volume-attachment-add, instance-volume-attachment-detach, instance-volume-attachment-update, instance-template, instance-template-create, instance-template-create-override-source-template, instance-template-update, instance-group, instance-group-create, instance-group-update, instance-group-delete, instance-group-load-balancer-delete, instance-group-managers, instance-group-manager-create, instance-group-manager-update, instance-group-manager-delete, instance-group-manager-actions, instance-group-manager-action-create, instance-group-manager-action-update, instance-group-manager-action-delete, instance-group-manager-policies, instance-group-manager-policy, instance-group-manager-policy-create, instance-group-manager-policy-update, instance-group-membership, instance-group-membership-delete, instance-group-membership-update, instance-group-memberships, instance-group-memberships-delete commands with \"by name\" support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-9550-11527","score":10.261725,"text":"\n* Updated instance-update command to support placement target patch.\n* Updated vpn-server-update command to support client DNS reset option.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v4.0.3 \n\nVersion 4.0.3 was released on 2022-04-25.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated instance-create command to support more data volumes in interactive mode.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Fixed bare-metal-server-create command's interactive mode error log for allowed-vlans.\n* Fixed bare-metal-server-console command to display the correct bare metal server VNC console URL.\n\n\n\n\n\n\n\n\n\n v4.0.2 \n\nVersion 4.0.2 was released on 2022-04-08.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Fixed the reserved IP not displaying issue when the instance list instances command is run.\n\n\n\n\n\n\n\n\n\n v4.0.1 \n\nVersion 4.0.1 was released on 2022-04-06.\n\n\n\n New commands \n\n\n\n* Added instance-network-interface-reserved-ips and instance-network-interface-reserved-ip commands to list\/get reserved IPs that are associated with a network interface.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated instance-create, instance-network-interface-create, instance-create-from-template, instance-template-create, instance-template-create-override-source-template, bare-metal-server-create, bare-metal-server-network-interface-create, subnet-reserved-ip-create commands to support reserved IP.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* Removed security group network interface commands security-group-network-interface, security-group-network-interface-add, security-group-network-interface-remove and security-group-network-interfaces.\n\n\n\n\n\n\n\n Note \n\n\n\n* Support for primary_ipv4_address property in primary-network-interface and network-interface options for the instance-create, instance-create-from-template, instance-template-create and instance-template-create-override-source-template commands were removed.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-4138-5877","score":10.199095,"text":"\n* Updated instance-create, instance-create-from-template, instance-update, instance-template-create and instance-template-create-override-source-template commands to support instance metadata service.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.5.0 \n\nVersion 6.5.0 was released on 2023-02-07.\n\n\n\n New commands \n\n\n\n* Added snapshot-clone, snapshot-clone-create, snapshot-clone-delete and snapshot-clonescommands to support snapshot fast restore.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated snapshot-create, backup-policy-create, backup-policy-plan-create and backup-policy-plan-update commands to support snapshot and backup fast restore.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.4.0 \n\nVersion 6.4.0 was released on 2023-01-31.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated bare-metal-server-create, bare-metal-server-update and bare-metal-server commands to support secure boot mode and TPM.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.3.0 \n\nVersion 6.3.0 was released on 2023-01-13.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated ike-policy-create, ike-policy-update, ipsec-policy-create and ipsec-policy-update commands to remove the weak ciphers.\n* Updated vpn-server-create, vpn-server-update, load-balancer-listener-create and load-balancer-listener-update commands to remove the certificate manager support.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.2.0 \n\nVersion 6.2.0 was released on 2022-12-14.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Updated volume-create command to support creation of volume from snapshot.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v6.1.0 \n\nVersion 6.1.0 was released on 2022-11-21.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_08851-1541-3076","score":10.194797,"text":"\nuse the new syntax features from Terraform on IBM Cloud v0.12, and identify\nany constructs that may need to be adjusted for correct operation with\nTerraform on IBM Cloud v0.13.\n\nWe recommend to use this command in a clean version control work tree, so that\nyou can easily see the proposed changes as a diff against the latest commit.\nIf you have uncommited changes already present, we recommend aborting this\ncommand and dealing with them before running this command again.\n\nWould you like to upgrade the module in the current directory?\nOnly 'yes' is accepted to confirm.\n\nEnter a value: yes\n\n-----------------------------------------------------------------------------\n\nUpgrade complete!\n\nThe configuration files were upgraded successfully. Use your version control\nsystem to review the proposed changes, make any necessary adjustments, and\nthen commit.\n4. Verify versions.tf file is generated as shown in the example.\n\nExample versions.tf\n\nterraform {\nrequired_providers {\nibm = {\n TF-UPGRADE-TODO\n\n No source detected for this provider. You must add a source address\n in the following format:\n\n source = \"your-registry.example.com\/organization\/ibm\"\n\n For more information, see the provider source documentation:\n\n https:\/\/www.terraform.io\/docs\/configuration\/providers.htmlprovider-source\n}\n}\nrequired_version = \">= 0.13\"\n}\nShow more\n5. Edit the versions.tf configuration file. Comment out source = \"your-registry.example.com\/organization\/ibm\" parameter and provide source value as source = \"IBM-Cloud\/ibm\" as shown in the example.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-migration-versioncontrol"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_04335-212022-213814","score":13.35399,"text":"\n--quiet, -q\n: Specify this option to reduce the output of the command. This value is optional. The default value is false.\n\n\n\n\n\n Example \n\nThe following command updates a Git access secret that is called github to use a new host.\n\nibmcloud ce repo update -n github --host NEW_HOST\n\n\n\n\n\n Example output \n\nGetting Git access secret 'github'...\nUpdating Git access secret 'github'...\nOK\n\n\n\n\n\n\n\n\n\n Revision commands \n\nAn application, or app, runs your code to serve HTTP requests. In addition to traditional HTTP requests, IBM Cloud\u00ae Code Engine also supports applications that use WebSockets as their communications protocol. An app contains one or more revisions. A revision represents an immutable version of the configuration properties of the app. Each update of an app configuration property creates a new revision of the app.\n\nUse revision commands to manage application revisions.\n\nYou must be within the context of a [project](https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-clicli-project) before you use revision commands.\n\nFor more information about working with revisions for apps, see [Deploying applications](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-application-workloads).\n\nYou can use either revision or rev in your revision commands. To see CLI help for the revision commands, run ibmcloud ce revision -h.\n\n\n\n ibmcloud ce revision delete \n\nDelete an application revision.\n\nibmcloud ce revision delete --name REVISION_NAME [--force] [--ignore-not-found] [--quiet]\n\n\n\n Command Options \n\n--name, -n\n: The name of the application revision. This value is required.\n\n--force, -f\n: Force deletion without confirmation. This value is optional. The default value is false.\n\n--ignore-not-found, --inf\n: If not found, do not fail. This value is optional. The default value is false.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cli?topic=cli-cli"},{"document_id":"ibmcld_12897-5384-7049","score":13.286588,"text":"\n\"_conflicts\":[\"2-61ae00e029d4f5edd2981841243ded13\"]\n}\n\nThe version with the changed price was chosen arbitrarily as the latest version of the document. The conflict with another version is noted by providing the ID of that other version in the _conflicts array. In most cases, this array has only one element, but many conflicting revisions might exist.\n\n\n\n\n\n Merge the changes \n\nTo compare the revisions to see what changed, your application gets all of the versions from the database.\n\nSee the following example commands to retrieve all versions of a document from the database:\n\nhttps:\/\/$ACCOUNT.cloudant.com\/products\/$_ID\nhttps:\/\/$ACCOUNT.cloudant.com\/products\/$_ID?rev=2-61ae00e029d4f5edd2981841243ded13\nhttps:\/\/$ACCOUNT.cloudant.com\/products\/$_ID?rev=1-7438df87b632b312c53a08361a7c3299\n\nSince the conflicting changes are for different fields of the document, it is easy to merge them.\n\nFor more complex conflicts, other resolution strategies might be required:\n\n\n\n* Time based - use the first or last edit.\n* User intervention - report conflicts to users and let them decide on the best resolution.\n* Sophisticated algorithms - for example, 3-way merges of text fields.\n\n\n\nFor a practical example of how to implement a merge of changes, see this project with [sample code](https:\/\/github.com\/glynnbird\/deconflict).\n\n\n\n\n\n Upload the new revision \n\nThe next step is to create a document that resolves the conflicts, and update the database with it.\n\nSee the following example document that merges changes from the two conflicting revisions:\n\n{\n\"_id\": \"74b2be56045bed0c8c9d24b939000dbe\",\n\"_rev\": \"3-daaecd7213301a1ad5493186d6916755\",\n\"name\": \"Samsung Galaxy S4\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/Cloudant?topic=Cloudant-document-versioning-and-mvcc"},{"document_id":"ibmcld_16034-12689-13797","score":13.038874,"text":"\nVersion 3.4.0 was released on 2022-02-24.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance-create, instance-update, instance-template-create, instance-template-create-override-source-template and instance-create-from-template commands to support metadata service.\n* Update instance-create and instance-create-from-template commands to support trusted profile.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v3.3.0 \n\nVersion 3.3.0 was released on 2022-02-17.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance-create, instance-update, instance-template-create, instance-template-create-override-source-template and instance-create-from-template, commands to add support for vm-host-failure-policy.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v3.2.0 \n\nVersion 3.2.0 was released on 2022-02-11.\n\n\n\n New commands \n\n\n\n* N\/A.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance-create, instance-update and volume-update commands to support resize boot volume.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v3.1.0 \n\nVersion 3.1.0 was released on 2022-01-28.\n\n\n\n New commands","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_16034-15398-17327","score":13.02347,"text":"\nUpdated commands \n\n\n\n* Update vpn-server-update command to support VPN server upgrade and downgrade.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Note \n\n\n\n* Linux_S390x build support added.\n\n\n\n\n\n\n\n\n\n v2.0.0 \n\nVersion 2.0.0 was released on 2021-11-18.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance commands with \"by name\" support. Instance commands include instance-initialization-values, instance-console, instance-create, instance-create-from-template, instance-delete, instance-disk, instance-disk-update, instance-disks, instance-network-interface, instance-network-interface-create, instance-network-interface-delete, instance-network-interface-floating-ip, instance-network-interface-floating-ip-add, instance-network-interface-floating-ip-remove, instance-network-interface-floating-ips, instance-network-interface-update, instance-network-interfaces, instance-reboot, instance-stop, instance-update, instance-volume-attachments, instance-volume-attachment, instance-volume-attachment-add, instance-volume-attachment-detach, instance-volume-attachment-update, instance-template, instance-template-create, instance-template-create-override-source-template, instance-template-update, instance-group, instance-group-create, instance-group-update, instance-group-delete, instance-group-load-balancer-delete, instance-group-managers, instance-group-manager-create, instance-group-manager-update, instance-group-manager-delete, instance-group-manager-actions, instance-group-manager-action-create, instance-group-manager-action-update, instance-group-manager-action-delete, instance-group-manager-policies, instance-group-manager-policy, instance-group-manager-policy-create, instance-group-manager-policy-update, instance-group-membership, instance-group-membership-delete, instance-group-membership-update, instance-group-memberships, instance-group-memberships-delete commands with \"by name\" support.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_10140-25366-27043","score":13.014574,"text":"\nVersion 1.0.0 of the CLI was released on 26 March 2020.\n\n\n\n* Introduces permanent behavior and syntax changes that are not compatible with earlier versions. For a summary of the changes in version 1.0, see [Using version 1.0 of the plug-in](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelogchangelog_beta).\n\n\n\n\n\n\n\n Deprecated versions \n\nAll versions of the CLI plug-in that are earlier than version 1.0 are no longer supported. You can review the archive of the change logs. To update to the latest version, see [Updating to version 1.0 of the plug-in](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelogchangelog_beta).\n\n\n\n Updating to version 1.0 of the plug-in \n\nVersion 1.0 of the CLI plug-in was released on 16 March 2020. This version contains permanent syntax and behavior changes that are not compatible with earlier versions.\n\nTo maintain all CLI functionality, update and test any automation before you update to 1.0 by checking out the [ibmcloud oc script update command](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-kubernetes-service-cliscript_update) and setting your IKS_BETA_VERSION environment variable to 1.0. After you update your scripts, update your CLI to version 1.0 of the plug-in.\n\nCheck out the following syntax and behavior changes between each version of the CLI plug-in:\n\n\n\nLatest versions of the redesigned Red Hat OpenShift on IBM Cloud plug-in\n\n Functionality 0.2 0.3 0.4 1.0 \n\n Supported? Deprecated Deprecated Deprecated Default \n ibmcloud oc help output structure<br><br><br><br> * Legacy: Alphabetical list of commands<br> * Latest: Categories of commands<br><br><br> Legacy Legacy Latest Latest","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-cs_cli_changelog"},{"document_id":"ibmcld_16034-17328-19156","score":12.910887,"text":"\nInstance commands can now use an ID or name for the command option values.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v1.7.0 \n\nVersion 1.7.0 was released on 2021-10-07.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update load-balancer, vpc-routing-table-route-create, snapshots, vpn-gateway and vpn-server commands with \"by name\" support. These commands can now use an ID or name for the command option values.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v1.6.0 \n\nVersion 1.6.0 was released on 2021-09-15.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update load-balancer-create\/load-balancer-listener-create\/load-balancer-update\/load-balancer-listener-update commands to support the load-balancer vnf support.\n* Update subnet, public gateway, image, floating IP, key, placement-group, flow-log, security group, virtual private endpoint gateway, dedicated host and volume commands with \"by name\" support. These commands can now use an ID or name for the command option values.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v1.5.0 \n\nVersion 1.5.0 was released on 2021-08-27.\n\n\n\n New commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update instance-create\/instance-update\/instance-template-create commands to support the instance attached block storage bandwidth setting.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A\n\n\n\n\n\n\n\n\n\n v1.4.0 \n\nVersion 1.4.0 was released on 2021-08-26.\n\n\n\n New commands \n\n\n\n* Add client-to-site VPN server commands (Beta).\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Update vpc\/address-prefix\/routing-table\/route commands with \"by name\" support. These commands can now use an ID or name for the command option values.\n* Update network ACL and network ACL rule commands with \"by name\" support. These commands can now use an ID or name for the command option values.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N\/A","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-vpc-cli-rn"},{"document_id":"ibmcld_05684-34652-36491","score":12.871067,"text":"\n* Removes the deprecated region get, region set, and region ls commands from help output.\n* Updates command structure to the new spaced format in help output.\n* Adds a warning to the output of legacy cluster config behavior. For more information, see the [version 1.0 plug-in documentation](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_cli_changelogchangelog_beta).\n* Fixes a bug so that worker reload and messages commands now fail if the command errors.\n* Updates the help text in various languages.\n\n\n\n\n\n\n\n Version 0.4.23 \n\nVersion 0.4.23 of the CLI was released on 16 September 2019.\n\n\n\n* Decreases startup time for the plug-in.\n* Fixes a Go version issue for macOS users.\n* Improves debug tracing.\n* In ibmcloud ks logging filter commands, the syntax of the --logging-config option changes from accepting multiple values in a comma-separated list to requiring repeated options.\n* Minor bug and security fixes.\n* Updates message, warning, and help text.\n\n\n\n\n\n\n\n Version 0.4.3 \n\nVersion 0.4.3 of the CLI was released on 4 September 2019.\n\n\n\n* Adds deprecation warnings for legacy commands to error messages that are sent to stderr.\n\n\n\n\n\n\n\n Version 0.4.1 \n\nVersion 0.4.1 of the CLI was released on 3 April 2019.\n\n\n\n* Sets the IBM Cloud Kubernetes Service plug-in to the redesigned format by default. This redesigned version includes changes such as categorical lists instead of an alphabetical list of commands in the output of ibmcloud ks help, spaced-structured commands instead of hyphenated-structure commands, repeated options instead of multiple values in comma-separated lists, and more. For a full list of the changes between version 0.3 and 0.4, see the comparison table in [Using the beta IBM Cloud Kubernetes Service plug-in](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_cli_changelogchangelog_beta).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-cs_cli_changelog"},{"document_id":"ibmcld_05278-253270-254957","score":12.832126,"text":"\nThe default value is false.\n\n\n\n\n\n Example \n\nibmcloud ce revision logs -n myapp-00001\n\n\n\n\n\n Example output \n\nCode Engine retains only the latest inactive revision of your application in addition to your active app revision. Older revisions are not retained.\n\nGetting logs for all instances of application revision 'newapp-mytest-00002'...\nGetting application revision 'newapp-mytest-00002'...\nOK\n\nnewapp-mytest-00002-deployment-7c87cfbf66-xnwkp\/user-container:\n2021-07-15 20:40:56 Listening on port 8080\n\n\n\n\n\n\n\n\n\n Secret commands \n\nA secret provides a method to include sensitive configuration information, such as passwords or SSH keys, to your deployment. By referencing values from your secret, you can decouple sensitive information from your deployment to keep your app or job portable. Anyone who is authorized to your project can also view your secrets; be sure that you know that the secret information can be shared with those users. Secrets contain information in key-value pairs.\n\nYou must be within the context of a [project](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-clicli-project) before you use secret commands.\n\nFor more information about working with secrets, see [Working with secrets](https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-secret).\n\nTo see CLI help for the secret commands, run ibmcloud ce secret -h.\n\nBeginning with CLI version 1.42.0, defining and working with secrets in the CLI is unified under the secret command group. Use the --format option to specify the category of secret, such as basic_auth, generic, ssh, tls, or registry. The default value for the --format option is generic.\n\n\n\n ibmcloud ce secret create \n\nCreate a secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/codeengine?topic=codeengine-cli"},{"document_id":"ibmcld_10645-8307-10100","score":12.689335,"text":"\nThis process continues until the rollout is complete and all 10 replicas run the new version.\n\nIf you want to perform a blue-green instantaneous switch style update, set the maxSurge to 100%. The deployment creates all the new required replicas, then scales down the old version replicas to 0.\n3. [Roll out](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/deployment\/updating-a-deployment) a change. For example, you might want to change the image that you used in your initial deployment.\n\n\n\n1. Get the deployment name.\n\noc get deployments\n2. Get the pod name.\n\noc get pods\n3. Get the name of the container that runs in the pod.\n\noc describe pod <pod_name>\n4. Set the new image for the deployment to use.\n\noc set image deployment\/<deployment_name><container_name>=<image_name>\n\n\n\nWhen you run the commands, the change is immediately applied and logged in the roll-out history.\n4. Check the status of your deployment.\n\noc rollout status deployments\/<deployment_name>\n\nIf you notice something in the status that you want time to follow up on, you can pause and resume your rollout with the following commands.\n\noc rollout pause deployment <deployment_name>\n\noc rollout resume deployment <deployment_name>\n5. Roll back a change.\n\n\n\n1. View the roll-out history for the deployment and identify the revision number of your last deployment.\n\noc rollout history deployment\/<deployment_name>\n\nTip: To see the details for a specific revision, include the revision number.\n\noc rollout history deployment\/<deployment_name> --revision=<number>\n2. Roll back to the previous version, or specify a revision. To roll back to the previous version, use the following command.\n\noc rollout undo deployment\/<depoyment_name> --to-revision=<number>\n\n\n\n\n\n\n\n\n\n Setting up continuous integration and delivery","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-update_app"},{"document_id":"ibmcld_06225-8563-10311","score":12.615344,"text":"\nIf you want to perform a blue-green instantaneous switch style update, set the maxSurge to 100%. The deployment creates all the new required replicas, then scales down the old version replicas to 0.\n3. [Roll out](https:\/\/kubernetes.io\/docs\/concepts\/workloads\/controllers\/deployment\/updating-a-deployment) a change. For example, you might want to change the image that you used in your initial deployment.\n\n\n\n1. Get the deployment name.\n\nkubectl get deployments\n2. Get the pod name.\n\nkubectl get pods\n3. Get the name of the container that runs in the pod.\n\nkubectl describe pod <pod_name>\n4. Set the new image for the deployment to use.\n\nkubectl set image deployment\/<deployment_name><container_name>=<image_name>\n\n\n\nWhen you run the commands, the change is immediately applied and logged in the roll-out history.\n4. Check the status of your deployment.\n\nkubectl rollout status deployments\/<deployment_name>\n\nIf you notice something in the status that you want time to follow up on, you can pause and resume your rollout with the following commands.\n\nkubectl rollout pause deployment <deployment_name>\n\nkubectl rollout resume deployment <deployment_name>\n5. Roll back a change.\n\n\n\n1. View the roll-out history for the deployment and identify the revision number of your last deployment.\n\nkubectl rollout history deployment\/<deployment_name>\n\nTip: To see the details for a specific revision, include the revision number.\n\nkubectl rollout history deployment\/<deployment_name> --revision=<number>\n2. Roll back to the previous version, or specify a revision. To roll back to the previous version, use the following command.\n\nkubectl rollout undo deployment\/<depoyment_name> --to-revision=<number>\n\n\n\n\n\n\n\n\n\n Setting up continuous integration and delivery","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-update_app"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"927077bd895f0c292618f4a34789bef3<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_15507-1716-3433","score":16.92073,"text":"\nFailed Image creation failed. \n Deleting The image is being deleted. \n Deprecated You can use the image to create an instance. Using the deprecated status can discourage use of the image before the status changes to obsolete. \n Obsolete You can't use the image to a create an instance. If you try to use an obsolete image to create an instance, you receive a message that the image can't be used to create an instance. This status allows a reversible disabiling of an image before you delete the image. \n\n\n\n\n\n\n\n Scheduling an image from volume lifecycle status by using the UI \n\nYou can schedule either a single image lifecycle status change or schedule the status changes for the entire lifecycle of the image.\n\nUse the following steps to schedule a single status change:\n\nYou can schedule a single status change for an image.\n\n\n\n1. In [IBM Cloud console](https:\/\/cloud.ibm.com\/login), go to Menu icon ![Menu icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/icons\/icon_hamburger.svg) > VPC Infrastructure > Compute > Images.\n2. On the Custom images tab, click the Actions icon ![More Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/f02b9c9adcbb7328d95a45e105cec371d50f15eb\/icons\/action-menu-icon.svg) for a specific image and select from the available options.\n3. Select Schedule lifecycle.\n4. In Image status, select the status change for the image.\n5. In Deprecation details, select whether to change status Immediately or to Schedule future date.\n6. If you selected Schedule future date, you need to fill out the following:\n\n\n\n* Select either By calendar date or By number of days.\n\n\n\n* If you selected By calendar date, enter the date and time information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-29196-30599","score":16.762024,"text":"\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-29235-30638","score":16.762024,"text":"\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint\/v1\/images\/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15507-8094-9618","score":16.454208,"text":"\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15646-25256-26940","score":16.368898,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15646-27823-29559","score":16.324745,"text":"\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-imagesschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images"},{"document_id":"ibmcld_15647-27849-29558","score":16.172474,"text":"\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint\/v1\/images\/$image_id\/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15647-25269-26966","score":16.170004,"text":"\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=uischedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-custom-images&interface=ui"},{"document_id":"ibmcld_15507-5434-7003","score":16.161856,"text":"\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-image-from-volume-vpc-manage"},{"document_id":"ibmcld_15544-7685-9445","score":15.521455,"text":"\nUsing the deprecated status can discourage use of the image before the status changes to obsolete.<br> * obsolete: The image is not available to use to provision an instance.<br> * Schedule complete lifecycle: You can schedule both the deprecated and obsolete status changes at the same time.<br><br><br><br>You can move back and forth between the three statuses. Only the statuses you can change to are displayed. You can schedule status changes by using calendar date and time or number of days. The obsolescence date must always be after the deprecation date. \n\n\n\n\n\n\n\n Importing a custom image by using the CLI \n\nMake sure that your compatible custom image is available in IBM Cloud Object Storage. For more information, see [Creating a Linux custom image](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-linux-custom-image), [Creating a Windows custom image](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-create-windows-custom-image), [Bring your own license](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-byol-vpc-about) and [Uploading data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage?topic=cloud-object-storage-upload) to IBM Cloud Object Storage.\n\nWhen you have an image available in IBM Cloud Object Storage, you can import it to IBM Cloud VPC infrastructure by using the command-line interface (CLI).\n\nTo import a custom image by using the CLI, use the ibmcloud is image-create command. Specify the name of the custom image to be created by using the IMAGE_NAME variable. You must also specify the source; for example, specify the --file option with the image file location. Specify the --os-name option with the name of the operating system for the image.\n\nibmcloud is image-create IMAGE_NAME [--file IMAGE_FILE_LOCATION] [--os-name OPERATING_SYSTEM_NAME]","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-importing-custom-images-vpc&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.1428571429,"recall_10":0.2857142857,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.1312050775,"ndcg_cut_10":0.1930505095}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":11.109455,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12493-7948-9647","score":8.735242,"text":"\nUse the following commands to add a static secret, such as a user credential or an arbitrary secret, to your Secrets Manager instance. Allowable values for SECRET_TYPE are: arbitrary,imported_cert, [kv](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-manage-kv-cli), private_cert, public_cert, and username_password.\n\nCreate a secret in the default secret group.\n\nvault write [-format=FORMAT] ibmcloud\/SECRET_TYPE\/secrets name=NAME [description=\"DESCRIPTION\"] [username=USERNAME] [password=USERNAME] [payload=DATA] [expiration_date=EXPIRATION] [certificate=CERTIFICATE_DATA] [private_key=PRIVATE_KEY_DATA] [intermediate=INTERMEDIATE_CERTIFICATE_DATA] [ca=CA_CONFIGURATION_NAME] [dns=DNS_CONFIGURATION_NAME] [key_algorithm=KEY_ALGORITHM] [labels=LABEL,LABEL]\n\nCreate a secret in a specified secret group.\n\nvault write [-format=FORMAT] ibmcloud\/SECRET_TYPE\/secrets\/groups\/SECRET_GROUP_ID name=NAME [description=\"DESCRIPTION\"] [username=USERNAME] [password=USERNAME] [payload=DATA] [expiration_date=EXPIRATION] [certificate=CERTIFICATE_DATA] [private_key=PRIVATE_KEY_DATA] [intermediate=INTERMEDIATE_CERTIFICATE_DATA] [ca=CA_CONFIGURATION_NAME] [dns=DNS_CONFIGURATION_NAME] [key_algorithm=KEY_ALGORITHM] [labels=LABEL,LABEL]\n\n\n\n Prerequisites \n\nYou need the [Writer service role](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam) to create secrets.\n\n\n\n\n\n Command options \n\nname\n: The human-readable alias that you want to assign to the secret. Required.\n\ndescription\n: An extended description to assign to the secret.\n\nexpiration_date\n: The expiration date that you want to assign to the secret. Supported for the arbitrary and username_password secret types.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-cli"},{"document_id":"ibmcld_00373-7-2065","score":8.5290785,"text":"\nAccelerate a dynamic website using Dynamic Content Acceleration \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nWeb applications are composed of static content like text, images, cascading style sheets, and JavaScript files. The tutorial [Accelerate delivery of static files using a CDN](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-static-files-cdn) shows how to host and serve static assets (images, videos, and documents) of a website from IBM Cloud Object Storage with [IBM\u00ae Content Delivery Network (CDN)](https:\/\/cloud.ibm.com\/catalog\/infrastructure\/cdn-powered-by-akamai).\n\nApplications also contain personalized and dynamically changing contents that can\u2019t be cached at CDN. A common example of non-cacheable dynamic content is adding an item to a cart in an e-commerce website that might be generated from JavaScript on the base page. Before Dynamic Content Acceleration is available, a CDN will pass every request for a non-cacheable object through to the owner\u2019s origin server, and pass the result back to the user.\n\nTo stop these dynamic contents from being a performance bottleneck, you can utilize the new Dynamic Content Acceleration (DCA) capability of [IBM\u00ae Content Delivery Network (CDN)](https:\/\/cloud.ibm.com\/catalog\/infrastructure\/cdn-powered-by-akamai) to optimize the performance of dynamic contents:\n\n\n\n* the DCA capability of CDN will choose the optimal routes for requests\n* proactively pre-fetch contents from origin servers so that users can access these contents rapidly from the edge\n* extend the duration of TCP connections for multiple requests\n* automatically compress images for lower latency.\n\n\n\n\n\n Objectives \n\n\n\n* Deploy a sample dynamic web application to a Kubernetes Service cluster.\n* Make static content globally available with IBM\u00ae Content Delivery Network.\n* Enable the Dynamic Content Acceleration (DCA) capability for performance optimization of non-static content.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-dynamic-content-cdn"},{"document_id":"ibmcld_13131-7-2065","score":8.5290785,"text":"\nAccelerate a dynamic website using Dynamic Content Acceleration \n\nThis tutorial may incur costs. Use the [Cost Estimator](https:\/\/cloud.ibm.com\/estimator\/review) to generate a cost estimate based on your projected usage.\n\nWeb applications are composed of static content like text, images, cascading style sheets, and JavaScript files. The tutorial [Accelerate delivery of static files using a CDN](https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-static-files-cdn) shows how to host and serve static assets (images, videos, and documents) of a website from IBM Cloud Object Storage with [IBM\u00ae Content Delivery Network (CDN)](https:\/\/cloud.ibm.com\/catalog\/infrastructure\/cdn-powered-by-akamai).\n\nApplications also contain personalized and dynamically changing contents that can\u2019t be cached at CDN. A common example of non-cacheable dynamic content is adding an item to a cart in an e-commerce website that might be generated from JavaScript on the base page. Before Dynamic Content Acceleration is available, a CDN will pass every request for a non-cacheable object through to the owner\u2019s origin server, and pass the result back to the user.\n\nTo stop these dynamic contents from being a performance bottleneck, you can utilize the new Dynamic Content Acceleration (DCA) capability of [IBM\u00ae Content Delivery Network (CDN)](https:\/\/cloud.ibm.com\/catalog\/infrastructure\/cdn-powered-by-akamai) to optimize the performance of dynamic contents:\n\n\n\n* the DCA capability of CDN will choose the optimal routes for requests\n* proactively pre-fetch contents from origin servers so that users can access these contents rapidly from the edge\n* extend the duration of TCP connections for multiple requests\n* automatically compress images for lower latency.\n\n\n\n\n\n Objectives \n\n\n\n* Deploy a sample dynamic web application to a Kubernetes Service cluster.\n* Make static content globally available with IBM\u00ae Content Delivery Network.\n* Enable the Dynamic Content Acceleration (DCA) capability for performance optimization of non-static content.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/solution-tutorials?topic=solution-tutorials-dynamic-content-cdn"},{"document_id":"ibmcld_06843-4238-6198","score":8.229386,"text":"\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-cc-pipeline"},{"document_id":"ibmcld_12717-7818-8740","score":8.13687,"text":"\nCheck whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether Secrets Manager arbitrary secrets are rotated at least every # days IA-5(g) Rule was added \n Check whether Secrets Manager user credentials are rotated at least every # days IA-5(g) Rule was added","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-fs-change-log"},{"document_id":"ibmcld_06881-2811-4554","score":8.087627,"text":"\nIt runs the static scans and dynamic scans on the Application Source Code, detect secrets in Git repos, Bill Of Materials (BOM) check, CIS check, and Vulnerability Advisor scan. After scanning and running checks on artifacts and source repositories, the pipeline creates a new incident issue or updates the existing incident issues in the incident repository. Finally, using these issues and the results, the pipeline collects evidence and summarizes the evidence, so the Security and Compliance Center Center can update the compliance status of the found artifacts.\n\nThe CC pipeline uses the [async sub pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-async-stagesasync-stages-setup-triggers) that runs in parallel to the main pipeline run to optimize pipeline run time and improve pipeline resiliency.\n\nThis tutorial uses a staging environment as an example to configure and showcase the continuous compliance (CC) toolchain.\n\nThe CC toolchain implements the following best practices:\n\n\n\n* Runs a static code scanner at pre-defined intervals on the application repositories that are provided to detect secrets in the application source code and vulnerable packages that are used as application dependencies.\n* Scan the container image for security vulnerabilities.\n* Any incident issue that is found during the scan or updated is marked with a due date.\n* Generate a summary.json file and store in IBM Cloud Object Storage at the end of every run that summarizes the details of the scan.\n\n\n\nLet's get started with the creation and exploration of the CC toolchain.\n\n\n\n\n\n Step 1: Start the CC toolchain setup \n\nStart the CC toolchain configuration by using one of the following options:\n\n\n\n* Click Create toolchain.\n\n[!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-cc-toolchain"},{"document_id":"ibmcld_16729-294066-295916","score":8.050635,"text":"\nA script and tool will assist you to simulate the transmission of web server log messages from a static file to Event Streams.\n\nObject Storage Event Streams\n\n+3\n\nAnalytics Engine,Data Engine,Key Protect\n\n\n\n* 3 hours\n* 2023-05-05\n\n\n\n[Getting started with Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-getting-started)Getting started with Secrets Manager\n\nThis tutorial focuses on storing and managing a username and password in IBM Cloud\u00ae Secrets Manager. With Secrets Manager, you can create, lease, and centrally manage secrets that are used in IBM Cloud services or your custom-built applications. Secrets are stored in a dedicated Secrets Manager instance, built on open source HashiCorp Vault.\n\nSecrets Manager\n\n\n\n* 10 minutes\n* 2023-03-01\n\n\n\n[Access a storage bucket by using a dynamic secret](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket)Access a storage bucket by using a dynamic secret\n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nSecrets Manager Object Storage\n\n\n\n* 1 hour\n* 2023-05-30\n\n\n\n[Secure secrets for apps that run in your Kubernetes cluster](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-kubernetes-secrets)Secure secrets for apps that run in your Kubernetes cluster\n\nThis tutorial is for the Classic flavor of Kubernetes Service clusters. External Secrets is also available as an OpenShift operator.\n\nSecrets Manager\n\n\n\n* 45 minutes\n* 2023-06-15\n\n\n\n[Part 2: Create a GitHub issue when your certificates are about to expire](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-tutorial-expiring-secrets-part-2)Part 2: Create a GitHub issue when your certificates are about to expire","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=tutorials"},{"document_id":"ibmcld_06804-2648-4507","score":8.017041,"text":"\nThe static-scan task runs a scan on the specified repos.\n* If you don't have your own SonarQube instance, the pipeline creates a SonarQube instance during the pipeline run. You can access this instance after the static-scan stage successfully runs.\n* Add your own static scan code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n Adding SonarQube scan to your pipelines \n\nFor more information about integrating SonarQube with the continuous integration pipeline, see [Configuring SonarQube](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-sonarqube).\n\n\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 5. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities. For example, the BOM captures the list of base images that are used in the build, the list of packages from the base images, and the list of app packages that are installed over the base image. The BOM acts as a ground truth for the analytic results and can potentially be used to enforce policy gates. Uses the Code Risk Analyzer tool. \n Repository compliance checking Checks that branch protection settings are correct. For example, the master\/main branch should always restrict the force push.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-ci-pipeline"},{"document_id":"ibmcld_00323-1120-2502","score":7.7845864,"text":"\n(https:\/\/cloud.ibm.com\/docs\/CDN?topic=solution-tutorials-static-files-cdn)[Accelerate a dynamic website Learn how to use Dynamic Content Acceleration (DCA) to optimize the performance of non-static content.](https:\/\/cloud.ibm.com\/docs\/CDN?topic=solution-tutorials-dynamic-content-cdn)\n\n Video library \n\n[![carousel thumbnail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/CDN\/\/images\/thumbnail1.png)<br><br>What is a Content Delivery Network?](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-content-delivery-network-video)[![carousel thumbnail](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/CDN\/\/images\/thumbnail3.png)<br><br>Setting up a web app with security group, load balancer, and CDN](https:\/\/cloud.ibm.com\/docs\/CDN?topic=CDN-set-up-web-app-video)\n\n Learn more \n\n[IBM Developer<br><br>Visit IBM Developer for technical articles, code patterns, tutorials, and more.<br><br>![112-Developer-tools.svg](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/112-Developer-tools.svg)](https:\/\/developer.ibm.com\/depmodels\/cloud\/)[Architecture Center<br><br>Discover the architecture references available for this product.<br><br>![190-Application-Platform.svg](https:\/\/cloud.ibm.com\/media\/docs\/images\/homepage\/190-Application-Platform.svg)](https:\/\/www.ibm.com\/cloud\/architecture\/architectures\/hybrid-messaging\/overview\/)[IBM Training<br><br>Build your skills with IBM Cloud training.<br><br>!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/CDN\/CDN-configure-cdn-with-ibm-cloud-object-storage"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":0.5,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.6131471928,"ndcg_cut_10":0.8065735964}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1213887-1215935","score":13.64311,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1216520-1218568","score":13.64311,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_12498-8087-10171","score":11.494811,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_06843-4238-6198","score":11.398374,"text":"\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-cc-pipeline"},{"document_id":"ibmcld_12717-7818-8740","score":11.32374,"text":"\nCheck whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether Secrets Manager arbitrary secrets are rotated at least every # days IA-5(g) Rule was added \n Check whether Secrets Manager user credentials are rotated at least every # days IA-5(g) Rule was added","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-fs-change-log"},{"document_id":"ibmcld_12439-7-1984","score":10.967035,"text":"\nComparison between Secrets Manager and related IBM Cloud services \n\nWith IBM Cloud, you can choose from various secrets management and data protection offerings that help you to protect your sensitive data and centralize your secrets. If you need to integrate general-purpose secrets to authenticate your apps, you can use Secrets Manager to create\n\ndynamic secretsand manage their lifecycle. But for other application secrets, such as encryption keys, your business might require a higher level of control that relies on highly secure, customer-controlled cryptographic hardware.\n\nFor example, consider the following scenarios and how they map to secrets management offerings and data protection offerings in IBM Cloud.\n\nZoom\n\n![The image describes three use cases for secrets management and how they map to available services in IBM Cloud. The content is explained fully in the surrounding text.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/991f60ddbe3ab0a9aa69481a07a0a73b359fa329\/secrets-manager\/images\/secrets-mgmt-options.svg)\n\nFigure 1. Secrets management use cases\n\n\n\n Which data protection service is best for me? \n\nThe following table lists the different offerings that you can use with IBM Cloud to protect your application secrets.\n\n\n\nTable 1. Secrets management and data protection scenarios\n\n Scenario What to use \n\n As a DevOps team contributor, you need to create, lease, and manage API keys, credentials, database configurations, and other secrets for your services and applications. With [Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager), you can manage secrets of various types in a dedicated instance. \n You need to generate, renew, and manage SSL\/TLS certificates for your deployments. You can also manage your SSL\/TLS certificates and private keys in dedicated instance of [Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager). \n You need to create and manage encryption keys that are backed by FIPS 140-2 Level 3 validated hardware.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manage-secrets-ibm-cloud"},{"document_id":"ibmcld_07844-5372-7725","score":10.93665,"text":"\nRA-5 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nSecurity categorization of information systems guides the frequency and comprehensiveness of vulnerability scans. Organizations determine the required vulnerability scanning for all information system components, ensuring that potential sources of vulnerabilities such as networked printers, scanners, and copiers are not overlooked. Vulnerability analyses for custom software applications may require additional approaches such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches. Organizations can employ these analysis approaches in a variety of tools (e.g., web-based application scanners, static analysis tools, binary analyzers) and in source code reviews. Vulnerability scanning includes, for example: (i) scanning for patch levels; (ii) scanning for functions, ports, protocols, and services that should not be accessible to users or devices; and (iii) scanning for improperly configured or incorrectly operating information flow control mechanisms. Organizations consider using tools that express vulnerabilities in the Common Vulnerabilities and Exposures (CVE) naming convention and that use the Open Vulnerability Assessment Language (OVAL) to determine\/test for the presence of vulnerabilities. Suggested sources for vulnerability information include the Common Weakness Enumeration (CWE) listing and the National Vulnerability Database (NVD). In addition, security control assessments such as red team exercises provide other sources of potential vulnerabilities for which to scan.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"},{"document_id":"ibmcld_09175-7-1618","score":10.921781,"text":"\nData security and compliance \n\nIBM\u00ae Key Protect for IBM Cloud\u00ae has data security strategies in place to meet your compliance needs and ensure that your data remains secure and protected in the cloud.\n\n\n\n Secrets management \n\nSecrets required for deployment are managed with automation using a HashiCorp Vault and are not stored in charts, GitHub, or deployment scripts.\n\n\n\n\n\n Security readiness \n\nKey Protect ensures security readiness by adhering to IBM best practices for systems, networking, and secure engineering.\n\nTo learn more about security controls across IBM Cloud, see [How do I know that my data is safe?](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-securitysecurity).\n\n\n\n Data encryption \n\nKey Protect uses [IBM Cloud hardware security modules (HSMs)](https:\/\/ibm.com\/cloud\/hardware-security-module) to generate provider-managed key material and perform [envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) operations. HSMs are tamper-resistant hardware devices that store and use cryptographic key material without exposing keys outside of a cryptographic boundary.\n\nAccess to Key Protect takes place over HTTPS and uses Transport Layer Security (TLS) to encrypt data in transit.\n\nNote that only the following TLS 1.2 and TLS 1.3 ciphers are supported:\n\n\n\n* TLS 1.2:\n\n\n\n* ECDHE-ECDSA-AES128-GCM-SHA256\n* ECDHE-ECDSA-AES256-GCM-SHA384\n* ECDHE-RSA-AES128-GCM-SHA256\n* ECDHE-RSA-AES256-GCM-SHA384\n* ECDHE-ECDSA-AES128-SHA256\n* ECDHE-ECDSA-AES256-SHA384\n* ECDHE-RSA-AES128-SHA256\n* ECDHE-RSA-AES256-SHA384\n\n\n\n* TLS 1.3:\n\n\n\n* TLS_AES_256_GCM_SHA384","title":"","source":"https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-security-and-compliance"},{"document_id":"ibmcld_06881-2811-4554","score":10.458341,"text":"\nIt runs the static scans and dynamic scans on the Application Source Code, detect secrets in Git repos, Bill Of Materials (BOM) check, CIS check, and Vulnerability Advisor scan. After scanning and running checks on artifacts and source repositories, the pipeline creates a new incident issue or updates the existing incident issues in the incident repository. Finally, using these issues and the results, the pipeline collects evidence and summarizes the evidence, so the Security and Compliance Center Center can update the compliance status of the found artifacts.\n\nThe CC pipeline uses the [async sub pipeline](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-devsecops-async-stagesasync-stages-setup-triggers) that runs in parallel to the main pipeline run to optimize pipeline run time and improve pipeline resiliency.\n\nThis tutorial uses a staging environment as an example to configure and showcase the continuous compliance (CC) toolchain.\n\nThe CC toolchain implements the following best practices:\n\n\n\n* Runs a static code scanner at pre-defined intervals on the application repositories that are provided to detect secrets in the application source code and vulnerable packages that are used as application dependencies.\n* Scan the container image for security vulnerabilities.\n* Any incident issue that is found during the scan or updated is marked with a due date.\n* Generate a summary.json file and store in IBM Cloud Object Storage at the end of every run that summarizes the details of the scan.\n\n\n\nLet's get started with the creation and exploration of the CC toolchain.\n\n\n\n\n\n Step 1: Start the CC toolchain setup \n\nStart the CC toolchain configuration by using one of the following options:\n\n\n\n* Click Create toolchain.\n\n[!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-tutorial-cc-toolchain"},{"document_id":"ibmcld_06804-2648-4507","score":10.446317,"text":"\nThe static-scan task runs a scan on the specified repos.\n* If you don't have your own SonarQube instance, the pipeline creates a SonarQube instance during the pipeline run. You can access this instance after the static-scan stage successfully runs.\n* Add your own static scan code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n Adding SonarQube scan to your pipelines \n\nFor more information about integrating SonarQube with the continuous integration pipeline, see [Configuring SonarQube](https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-sonarqube).\n\n\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 5. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https:\/\/github.com\/IBM\/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities. For example, the BOM captures the list of base images that are used in the build, the list of packages from the base images, and the list of app packages that are installed over the base image. The BOM acts as a ground truth for the analytic results and can potentially be used to enforce policy gates. Uses the Code Risk Analyzer tool. \n Repository compliance checking Checks that branch protection settings are correct. For example, the master\/main branch should always restrict the force push.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/devsecops?topic=devsecops-cd-devsecops-ci-pipeline"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.4306765581,"ndcg_cut_10":0.4306765581}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":16.634432,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12415-7-1973","score":14.54551,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_12498-9696-11699","score":14.49053,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12493-27359-28981","score":14.489145,"text":"\nPrerequisites \n\nYou need the [Writer service role](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam) to rotate secrets.\n\n\n\n\n\n Command options \n\npayload\n: The new data to store for an arbitrary secret. Only text-based payloads are supported. If you need to store a binary file, be sure to base64 encode it before you save it to Secrets Manager. For more information, see [Examples](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-clivault-cli-create-static-secret-examples).\n\npassword\n: The new password to assign to a username_password secret.\n\ncertificate\n: The new certificate data to store for an imported_cert secret. Supported file type is .pem.\n\nprivate_key\n: The new private key data to store for an imported_cert secret. Supported file type is .pem.\n\nintermediate\n: The new intermediate certificate data to store for an imported_cert secret. Supported file type is .pem.\n\n-format\n: Prints the output in the format that you specify. Valid formats are table, json, and yaml. The default is table. You can also set the output format by using the VAULT_FORMAT environment variable.\n\n-force\n: Replaces the password that is stored for a username_password secret with a randomly generated, 32-character password that contains uppercase letters, lowercase letters, digits, and symbols.\n\n\n\n\n\n Examples \n\nManually rotate the secret data that is stored for an arbitrary secret.\n\nvault write -format=json ibmcloud\/arbitrary\/secrets\/fe874c2b-e8fd-bbb6-9f19-e91bbe744735\/rotate payload=\"Updated secret data.\"\n\nManually rotate the password that is stored for a username_password secret.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-cli"},{"document_id":"ibmcld_16727-1218119-1220168","score":14.316874,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1215486-1217535","score":14.316874,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_12467-1716-3849","score":14.140993,"text":"\n* When you try to modify or delete a secret while it is locked, Secrets Manager denies the request with an HTTP 412 Precondition Failed response. You see an error message similar to the following example:\n\nThe requested action can't be completed because the secret version is locked.\n\nIf you're working with\n\ndynamic secrets, such as IAM credentials, locking your secrets also means that by default, those secrets can't be read or accessed. For more information, see [Why can't I read a locked IAM credentials secret?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-locked-iam-credentials)\n* If a locked secret reaches its expiration date, it stays in the Active state and its data remains accessible to your applications. Secrets Manager moves the secret to the Destroyed state and permanently deletes the expired secret data only after all locks on the secret are removed.\n\nSSL\/TLS certificates still reach their defined expiration dates and move into a Destroyed state even if they are locked. For more information, see [Why did my locked certificate move to the Destroyed state?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-locked-certificates)\n* If you try to rotate a secret while its current version is locked and the previous version is unlocked (or if an automatic rotation is scheduled), the request to rotate the secret is allowed. The current secret version becomes the new previous version, retaining its existing locks. A new current version is created without any locks.\n* If you try to rotate a secret while its previous version is locked (or if an automatic rotation is scheduled), your request to rotate the secret is denied. Rotation is allowed only after all locks on the previous secret version are removed.\n\n\n\n\n\n Creating locks in the UI \n\nYou can create up to 1000 locks on a secret by using the Secrets Manager UI. Each lock can be used to represent a single application or service that uses your secret.\n\nA secret is considered locked after you attach one or more locks to it. A lock can be applied only on a secret version that contains active payload, or secret data.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secret-locks"},{"document_id":"ibmcld_12428-14731-16279","score":14.048223,"text":"\nIf reuse_api_key is false for IAM credentials, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. For example, the following command creates an IAM credential by using the service_id field.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\nYou can find the ID value of a service ID in the IAM section of the console. Go to Manage > Access (IAM) > Service IDs > name. Click Details to view the ID.\n\ncurl -X POST\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H \"Content-Type: application\/json\" -d '{\n\"name\": \"example-iam-credentials-secret\",\n\"description\": \"Description of my IAM Credentials secret\",\n\"service_id\":\"iam-ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0\",\n\"secret_type\": \"iam_credentials\",\n\"secret_group_id\": \"bfc0a4a9-3d58-4fda-945b-76756af516aa\",\n\"labels\": [\n\"dev\",\n\"us-south\"\n],\n\"ttl\": \"30m\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"},{"document_id":"ibmcld_12422-14705-16253","score":14.048223,"text":"\nIf reuse_api_key is false for IAM credentials, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. For example, the following command creates an IAM credential by using the service_id field.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\nYou can find the ID value of a service ID in the IAM section of the console. Go to Manage > Access (IAM) > Service IDs > name. Click Details to view the ID.\n\ncurl -X POST\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H \"Content-Type: application\/json\" -d '{\n\"name\": \"example-iam-credentials-secret\",\n\"description\": \"Description of my IAM Credentials secret\",\n\"service_id\":\"iam-ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0\",\n\"secret_type\": \"iam_credentials\",\n\"secret_group_id\": \"bfc0a4a9-3d58-4fda-945b-76756af516aa\",\n\"labels\": [\n\"dev\",\n\"us-south\"\n],\n\"ttl\": \"30m\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials"},{"document_id":"ibmcld_12462-22671-23294","score":13.837419,"text":"\n\"alt_name1\", \"alt_name2\"\n],\n\"algorithm\": \"sha256WithRSAEncryption\",\n\"key_algorithm\": \"rsaEncryption 2048 bit\",\n\"rotation\": {\n\"enabled\": false,\n\"rotate_keys\":false\n},\n\"custom_metadata\" : {\n\"anyKey\" : \"anyValue\"\n},\n\"version_custom_metadata\" : {\n\"anyKey\" : \"anyValue\"\n},\n\"expiration_date\" : \"2030-01-01T00:00:00Z\",\n}\n]\n\nThe command outputs the ID value of the secret, along with other metadata. For more information about the command options, see [ibmcloud secrets-manager secret-create](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-cli-plugin-secrets-manager-clisecrets-manager-cli-secret-create-command).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-public-certificates&interface=ui"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.25,"recall_5":0.25,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.39038005,"ndcg_cut_10":0.5205067333}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-8087-10171","score":13.500681,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12498-9696-11699","score":12.72707,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12428-4-1817","score":12.662012,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Creating IAM credentials \n\nYou can use IBM Cloud\u00ae Secrets Manager to dynamically generate IAM credentials for accessing an IBM Cloud resource that requires IAM authentication.\n\nIAM credentials are\n\ndynamic secretsthat you can use to access an IBM Cloud resource. A set of IAM credentials consists of a service ID and an API key that is generated each time that the protected resource is read or accessed. You can define a time-to-live (TTL) or a lease duration for your IAM credential at its creation so that you shorten the amount of time that the secret exists.\n\nTo learn more about the types of secrets that you can manage in Secrets Manager, see [What is a secret?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret)\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To create or add secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\nIAM credentials require an extra configuration step before you can start to create or manage them in the service. For more information, see [Configuring the IAM credentials engine](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-configure-iam-engine).\n\nAn account administrator (or any entity with the required level of access) can externally alter IAM Credentials that are created and managed by Secrets Manager. If such a service ID or API key is deleted outside of Secrets Manager, the service might behave unexpectedly. For example, you might be unable to create, or rotate credentials.\n\n\n\n\n\n Creating IAM credentials in the UI \n\nTo create IAM credentials by using the Secrets Manager UI, complete the following steps.\n\n\n\n1. In the console, click the Menu icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"},{"document_id":"ibmcld_12422-4-1817","score":12.662012,"text":"\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Creating IAM credentials \n\nYou can use IBM Cloud\u00ae Secrets Manager to dynamically generate IAM credentials for accessing an IBM Cloud resource that requires IAM authentication.\n\nIAM credentials are\n\ndynamic secretsthat you can use to access an IBM Cloud resource. A set of IAM credentials consists of a service ID and an API key that is generated each time that the protected resource is read or accessed. You can define a time-to-live (TTL) or a lease duration for your IAM credential at its creation so that you shorten the amount of time that the secret exists.\n\nTo learn more about the types of secrets that you can manage in Secrets Manager, see [What is a secret?](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret)\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To create or add secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\nIAM credentials require an extra configuration step before you can start to create or manage them in the service. For more information, see [Configuring the IAM credentials engine](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-configure-iam-engine).\n\nAn account administrator (or any entity with the required level of access) can externally alter IAM Credentials that are created and managed by Secrets Manager. If such a service ID or API key is deleted outside of Secrets Manager, the service might behave unexpectedly. For example, you might be unable to create, or rotate credentials.\n\n\n\n\n\n Creating IAM credentials in the UI \n\nTo create IAM credentials by using the Secrets Manager UI, complete the following steps.\n\n\n\n1. In the console, click the Menu icon !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials"},{"document_id":"ibmcld_00894-7096-9156","score":12.282139,"text":"\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox. Also, specify a lease duration with a minimum of 12 hours when you use public worker agents to run your pipeline. If you use private worker agents, make sure that you set a minimum lease duration to the forced cancellation duration for a pipeline. It is recommended that you confirm these settings with your account administrator. By setting the reuse option and an appropriate lease duration, you can make sure that the dynamically managed IAM credentials service ID API key persists during your pipeline runs.\n\nZoom\n\n![IAM credentials lease duration and reuse API key](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/secret-leaseduration.png)\n\nFigure 3. IAM credentials lease duration and reuse API key\n\nBy running the Rotate action on IAM credentials from the Secrets Manager dashboard, you can maintain the compliance posture requirements for API Key rotations that are used by your Continuous Delivery pipelines. Secrets Manager works with IAM to generate a new API Key for an IAM credentials secret and manages the versioning of the secret.\n\nThe IAM credentials secret type also helps to provide continuity of service during and after secret rotation:\n\n\n\n* New Continuous Delivery pipeline workloads use the newly rotated API Key until its lease duration expires.\n* Existing Continuous Delivery pipeline workloads that are running with the API Key that was issued before rotation can continue to run with the previous version until the lease duration of the previous version expires.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"},{"document_id":"ibmcld_12960-7096-9156","score":12.282139,"text":"\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox. Also, specify a lease duration with a minimum of 12 hours when you use public worker agents to run your pipeline. If you use private worker agents, make sure that you set a minimum lease duration to the forced cancellation duration for a pipeline. It is recommended that you confirm these settings with your account administrator. By setting the reuse option and an appropriate lease duration, you can make sure that the dynamically managed IAM credentials service ID API key persists during your pipeline runs.\n\nZoom\n\n![IAM credentials lease duration and reuse API key](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/secret-leaseduration.png)\n\nFigure 3. IAM credentials lease duration and reuse API key\n\nBy running the Rotate action on IAM credentials from the Secrets Manager dashboard, you can maintain the compliance posture requirements for API Key rotations that are used by your Continuous Delivery pipelines. Secrets Manager works with IAM to generate a new API Key for an IAM credentials secret and manages the versioning of the secret.\n\nThe IAM credentials secret type also helps to provide continuity of service during and after secret rotation:\n\n\n\n* New Continuous Delivery pipeline workloads use the newly rotated API Key until its lease duration expires.\n* Existing Continuous Delivery pipeline workloads that are running with the API Key that was issued before rotation can continue to run with the previous version until the lease duration of the previous version expires.\n\n\n\nZoom\n\n!","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"},{"document_id":"ibmcld_16727-1218119-1220168","score":12.179647,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1215486-1217535","score":12.179647,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_12415-7-1973","score":12.052552,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_12447-1578-3681","score":11.728712,"text":"\nIf the IAM credentials secret was created by using an existing service ID in the account, only the API key is regenerated as part of a manual rotation. In contrast, if the secret was created by selecting an access group, both the service ID and API key values are regenerated when they're manually rotated.<br><br>The Reuse IAM credentials until lease expires (reuse_api_key) option for an IAM credentials secret impacts whether it can be rotated manually. If this field is false or set to Off in the UI, manual rotation isn't supported. The API key that is dynamically generated for the secret on each read is already a single-use, ephemeral value. \n [Imported certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatesimport-certificates) Certificates that were initially imported to a service instance are immediately replaced with the data that you reimport on rotation. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) Key-value secrets are immediately replaced with the data that you provide on rotation. \n [Private certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatescreate-certificates) Private certificates are immediately replaced with a certificate that is signed by its parent or issuing certificate authority. \n [Public certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatesorder-certificates) Public certificates move to the Active, Rotation pending status to indicate that a request to rotate a certificate is being processed. Secrets Manager sends the request to the configured certificate authority (CA), for example Let's Encrypt, to validate the ownership of your domains. If the validation completes successfully, a new certificate is issued. \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) Passwords that are associated with user credentials secrets are immediately replaced with the data that you provide on rotation. \n\n\n\n\n\n\n\n\n\n Creating new secret versions in the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.25,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.1231511944}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12498-9696-11699","score":17.515718,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12415-7-1973","score":17.183437,"text":"\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https:\/\/cloud.ibm.com\/docs\/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-faqs"},{"document_id":"ibmcld_12498-8087-10171","score":17.173784,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12428-14731-16279","score":16.847668,"text":"\nIf reuse_api_key is false for IAM credentials, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. For example, the following command creates an IAM credential by using the service_id field.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\nYou can find the ID value of a service ID in the IAM section of the console. Go to Manage > Access (IAM) > Service IDs > name. Click Details to view the ID.\n\ncurl -X POST\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H \"Content-Type: application\/json\" -d '{\n\"name\": \"example-iam-credentials-secret\",\n\"description\": \"Description of my IAM Credentials secret\",\n\"service_id\":\"iam-ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0\",\n\"secret_type\": \"iam_credentials\",\n\"secret_group_id\": \"bfc0a4a9-3d58-4fda-945b-76756af516aa\",\n\"labels\": [\n\"dev\",\n\"us-south\"\n],\n\"ttl\": \"30m\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"},{"document_id":"ibmcld_12422-14705-16253","score":16.847668,"text":"\nIf reuse_api_key is false for IAM credentials, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. For example, the following command creates an IAM credential by using the service_id field.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\nYou can find the ID value of a service ID in the IAM section of the console. Go to Manage > Access (IAM) > Service IDs > name. Click Details to view the ID.\n\ncurl -X POST\n-H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H \"Content-Type: application\/json\" -d '{\n\"name\": \"example-iam-credentials-secret\",\n\"description\": \"Description of my IAM Credentials secret\",\n\"service_id\":\"iam-ServiceId-c0c7cfa4-b24e-4917-ad74-278f2fee5ba0\",\n\"secret_type\": \"iam_credentials\",\n\"secret_group_id\": \"bfc0a4a9-3d58-4fda-945b-76756af516aa\",\n\"labels\": [\n\"dev\",\n\"us-south\"\n],\n\"ttl\": \"30m\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials"},{"document_id":"ibmcld_16727-1218119-1220168","score":16.655226,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1215486-1217535","score":16.655226,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_12422-4077-6158","score":16.10726,"text":"\nIf you'd like to continue to use those credentials through the end of the lease of your secret, you can set Reuse IAM credentials until lease expires to On. When you enable this option, your secret retains its current service ID, and API key values and reuses them on each read while the secret remains valid. After the secret reaches the end of its lease, the credentials are revoked automatically.\n\nIf the reuse IAM credentials option is set to Off, manual rotation for the secret isn't supported. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n\n\n Using an existing service ID in your account \n\nYou might already have a service ID in your account that you want to use to dynamically generate an API key. In this scenario, you can choose to create an IAM credentials secret by bringing your own service ID. Or, if you prefer to generate both a service ID and an API key, you can assign access by choosing an access group.\n\nIn the Assign access step of the Create IAM credentials wizard, choose a scope of access for your credentials.\n\n\n\n1. To use an existing service ID, select an ID from the list.\n\nChoose this option when you need Secrets Manager to generate and manage only an API key for your IAM credentials secret, and not the service ID itself. The API key inherits the access policy of the service ID that you select from your account. Only the service IDs that you have access to are displayed.\n2. To generate both a new service ID and API key for the secret, select an access group.\n\nBy selecting an access group from your IBM Cloud account, you determine the scope of access to assign to the service ID and the API key. The API key is dynamically generated and associated with your new IAM credential. This step ensures that your IAM credentials are scoped with the preferred level of permissions in your IBM Cloud account. You can assign up to 10 access groups.\n\n\n\nIf you used an existing service ID, the API key that was generated by Secrets Manager is automatically locked.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials"},{"document_id":"ibmcld_12447-1578-3681","score":15.920575,"text":"\nIf the IAM credentials secret was created by using an existing service ID in the account, only the API key is regenerated as part of a manual rotation. In contrast, if the secret was created by selecting an access group, both the service ID and API key values are regenerated when they're manually rotated.<br><br>The Reuse IAM credentials until lease expires (reuse_api_key) option for an IAM credentials secret impacts whether it can be rotated manually. If this field is false or set to Off in the UI, manual rotation isn't supported. The API key that is dynamically generated for the secret on each read is already a single-use, ephemeral value. \n [Imported certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatesimport-certificates) Certificates that were initially imported to a service instance are immediately replaced with the data that you reimport on rotation. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) Key-value secrets are immediately replaced with the data that you provide on rotation. \n [Private certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatescreate-certificates) Private certificates are immediately replaced with a certificate that is signed by its parent or issuing certificate authority. \n [Public certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatesorder-certificates) Public certificates move to the Active, Rotation pending status to indicate that a request to rotate a certificate is being processed. Secrets Manager sends the request to the configured certificate authority (CA), for example Let's Encrypt, to validate the ownership of your domains. If the validation completes successfully, a new certificate is issued. \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) Passwords that are associated with user credentials secrets are immediately replaced with the data that you provide on rotation. \n\n\n\n\n\n\n\n\n\n Creating new secret versions in the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"},{"document_id":"ibmcld_12447-22464-24202","score":15.871481,"text":"\nA successful response returns the ID value for the secret, along with other metadata. For more information about the required and optional request parameters, check out the [API docs](https:\/\/cloud.ibm.com\/apidocs\/secrets-manager\/secrets-manager-v2update-secret).\n\n\n\n\n\n Rotating user credentials \n\nYou can rotate secrets by calling the Secrets Manager API.\n\nThe following example request creates a new version of your secret. When you call the API, replace the ID variables and IAM token with the values that are specific to your Secrets Manager instance.\n\nYou can store metadata that are relevant to the needs of your organization with the custom_metadata and version_custom_metadata request parameters. Values of the version_custom_metadata are returned only for the versions of a secret. The custom metadata of your secret is stored as all other metadata, for up to 50 versions, and you must not include confidential data.\n\ncurl -X POST -H \"Authorization: Bearer {iam_token}\" -H \"Accept: application\/json\" -H \"Content-Type: application\/json\" -d '{\n\"custom_metadata\": {\n\"metadata_custom_key\": \"metadata_custom_value\"\n},\n\"password\": \"new-password\",\n\"version_custom_metadata\": {\n\"custom_version_key\": \"custom_version_value\"\n}\n}' \n\"https:\/\/{instance_ID}.{region}.secrets-manager.appdomain.cloud\/api\/v2\/secrets\/{id}\/versions\"\n\nTo have the service generate and assign a random password to your credential, you can pass an empty string on the password field. For example, { \"password\": \"\"}. Secrets Manager replaces the existing value with a randomly generated 32-character password that contains uppercase letters, lowercase letters, digits, and symbols.\n\nA successful response returns the ID value for the secret, along with other metadata.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_12717-7818-8740","score":17.161844,"text":"\nCheck whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts CM-3(2)(0), CM-4(0), CM-4(1)(0), CM-7(1)(a), CM-7(b), RA-5(1)(0), RA-5(2)(0), RA-5(3)(0), RA-5(a), RA-5(b), RA-5(c), RA-5(d), SA-10(e), SA-15(a), SA-3(a), SA-3(d), SA-8(0), SI-10(0), SI-2(2)(0), SI-2(a), SI-2(b), SI-2(c), and SI-2(d) Rule was added \n Check whether Secrets Manager arbitrary secrets are rotated at least every # days IA-5(g) Rule was added \n Check whether Secrets Manager user credentials are rotated at least every # days IA-5(g) Rule was added","title":"","source":"https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-fs-change-log"},{"document_id":"ibmcld_12498-9696-11699","score":16.374662,"text":"\n[IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL\/TLS certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation) !","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_12447-1578-3681","score":16.018345,"text":"\nIf the IAM credentials secret was created by using an existing service ID in the account, only the API key is regenerated as part of a manual rotation. In contrast, if the secret was created by selecting an access group, both the service ID and API key values are regenerated when they're manually rotated.<br><br>The Reuse IAM credentials until lease expires (reuse_api_key) option for an IAM credentials secret impacts whether it can be rotated manually. If this field is false or set to Off in the UI, manual rotation isn't supported. The API key that is dynamically generated for the secret on each read is already a single-use, ephemeral value. \n [Imported certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatesimport-certificates) Certificates that were initially imported to a service instance are immediately replaced with the data that you reimport on rotation. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) Key-value secrets are immediately replaced with the data that you provide on rotation. \n [Private certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatescreate-certificates) Private certificates are immediately replaced with a certificate that is signed by its parent or issuing certificate authority. \n [Public certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatesorder-certificates) Public certificates move to the Active, Rotation pending status to indicate that a request to rotate a certificate is being processed. Secrets Manager sends the request to the configured certificate authority (CA), for example Let's Encrypt, to validate the ownership of your domains. If the validation completes successfully, a new certificate is issued. \n [User credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) Passwords that are associated with user credentials secrets are immediately replaced with the data that you provide on rotation. \n\n\n\n\n\n\n\n\n\n Creating new secret versions in the UI","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"},{"document_id":"ibmcld_16727-1218119-1220168","score":15.818802,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1215486-1217535","score":15.818802,"text":"\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_12384-4-1975","score":15.66629,"text":"\n* UI\n* CLI\n* API\n\n\n\n\n\n\n\n Automatically rotating secrets \n\nYou can schedule automatic rotation for secrets by using IBM Cloud\u00ae Secrets Manager.\n\nWhen you rotate a secret in your service instance, you create a new version of its value. By scheduling automatic rotation of your secrets at regular intervals, you can reduce the likelihood of compromise and ensure that your credentials never expire.\n\nAutomatic rotation is available only for secrets that are generated by Secrets Manager. If the secret was imported initially, you must provide new secret data to rotate it. For more information, see [Manually rotating secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-manual-rotation).\n\n\n\n Before you begin \n\nBefore you get started, be sure that you have the required level of access. To rotate secrets, you need the [Writer service role or higher](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam).\n\n\n\n Supported secret types \n\nAutomatic rotation is supported for [private certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatescreate-certificates), [public certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatesorder-certificates), [user credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-user-credentials) and [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials). Depending on the type of secret, automatic rotation takes place immediately on the date and time that you set, or it might need to complete a few extra steps before a new version of the secret can be created.\n\n\n\nTable 1. Describes how Secrets Manager evaluates manual rotation by secret type\n\n Type Rotation description \n\n [Private certificates](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-certificatescreate-certificates) The existing certificate value is replaced with new certificate content.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-automatic-rotation"},{"document_id":"ibmcld_00062-7-2216","score":15.560978,"text":"\nSecurity model \n\nIBM Analytics Engine serverless instances provide a security architecture that is designed to enable administrators and developers to create secure Spark clusters.\n\nThe following sections describe how the security model of IBM Analytics Engine serverlesss instances manages the access to and control of the secure instances.\n\n\n\n Controlling access to IBM Analytics Engine activities \n\nAccess to IBM Analytics Engine serverless instances is controlled by IAM authentication and authorization. IAM is the Identity and Access Management service of IBM Cloud\u00ae. User authentication and access control happens through IAM when you log in with your IBMId. See how to [retrieve the IAM token](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-iam-token-serverless).\n\nAs an administrator or creator of the service instance, you can grant or deny access to other users with whom you may want to share the service instance. All activities on the service instance life cycle management, like modifying the instance configuration, submitting and tracking Spark applications or customizing the instance with custom library sets are controlled through IAM authentication and authorization. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless) to understand which operations are supported and what is the level of access required for each of those operations.\n\n\n\n\n\n Encrypting at Rest \n\nIBM Cloud Object Storage is the recommended data store to store the data required for executing Spark jobs on the cluster. IBM Cloud Object Storage comes with default built-in encryption. See [Encrypting your data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-encryptionencryption).\n\nIn addition, or as an alternative to using IBM Cloud Object Storage storage encryption in analytic scenarios for large-scale data, you can use Parquet modular encryption, especially when fine-grained access control is important. See [Working with Parquet modular encryption](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-parquet-encryption-serverless).\n\n\n\n\n\n Encrypting endpoints","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-security-model-serverless"},{"document_id":"ibmcld_12492-53535-54571","score":15.167736,"text":"\n}'\n\nRotate a username_password secret in the default secret group.\n\ncurl -X POST \"https:\/\/{instance_id}.{region}.secrets-manager.appdomain.cloud\/v1\/ibmcloud\/username_password\/secrets\/{secret_id}\/rotate\" -H 'Accept: application\/json' -H 'X-Vault-Token: {Vault-Token}' -d '{\n\"password\": \"new-password\"\n}'\n\nRotate an imported_cert secret in the default secret group.\n\ncurl -X POST \"https:\/\/{instance_id}.{region}.secrets-manager.appdomain.cloud\/v1\/ibmcloud\/imported_cert\/secrets\/{secret_id}\/rotate\" -H 'Accept: application\/json' -H 'X-Vault-Token: {Vault-Token}' -d '{\n\"certificate\": \"new-certificate\",\n\"private_key\": \"new-private-key\",\n\"intermediate\": \"new-intermediate-certificate\"\n}'\n\n\n\n\n\n Example responses \n\nA request to rotate a kv secret in the default secret group returns the following response:\n\n{\n\"request_id\": \"e00000b-0000-0ad1-beb0-00000d0000\",\n\"lease_id\": \"\",\n\"renewable\": false,\n\"lease_duration\": 0,\n\"data\": {\n\"created_by\": \"iam-ServiceId-9ca2000007-f0000d-400000e-8b02-ed6b000000\",\n\"creation_date\": \"2022-01-25T19:22:04Z\",","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-vault-api"},{"document_id":"ibmcld_12498-8087-10171","score":14.877619,"text":"\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secret"},{"document_id":"ibmcld_00053-11982-13956","score":14.808625,"text":"\nMost KMS systems support key rotation by replacing the contents of the stored master keys and keeping the MEK ID intact (but updating the key version). After a user or administrator has performed the master key rotation inside the KMS instance using the KMS-specific API, the Parquet key rotation mechanism can be triggered (for example, by the same administrator) by calling:\n\npublic static void KeyToolkit.rotateMasterKeys(String folderPath, Configuration hadoopConfig)\n\nWhen key rotation is performed, every KEK in all key material files in folderPath is unwrapped with the old MEK version to enable decrypting the DEK. A new KEK is generated for each master key ID, and wrapped with the new MEK version. Creating a new KEK, instead of re-using the old one, doesn't only mean that security is improved but also that the performance of subsequent data read operations is increased. This is because a single key rotation process, run by the administrator, operates across multiple files created by different processes, meaning many different KEKs for the same MEK ID. The key rotation process replaces the old KEKs with a single new KEK, which allows the readers to run a single unwrap interaction with KMS for each master key.\n\nFor examples of how to use key rotation:\n\n\n\n* For key management by application, see [Key rotation in key management by application](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-key-management-application-serverlesskey-rotation-key-mgt-application).\n* For key management by Key Protect, see [Key rotation key management by Key Protect](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-key-management-key-protect-serverlesskey-rotation-key-mgt-keyprotect).\n\n\n\n\n\n\n\n Learn more \n\nCheck out the following sample notebook to learn how to use Parquet Encryption:\n\n\n\n* [Parquet Encryption by Key Management Application](https:\/\/dataplatform.cloud.ibm.com\/exchange\/public\/entry\/view\/013c690997e27f3a8d91332653054441)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-parquet-encryption-serverless"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_07578-1213887-1215935","score":16.961847,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1216520-1218568","score":16.961847,"text":"\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_00062-7-2216","score":15.084669,"text":"\nSecurity model \n\nIBM Analytics Engine serverless instances provide a security architecture that is designed to enable administrators and developers to create secure Spark clusters.\n\nThe following sections describe how the security model of IBM Analytics Engine serverlesss instances manages the access to and control of the secure instances.\n\n\n\n Controlling access to IBM Analytics Engine activities \n\nAccess to IBM Analytics Engine serverless instances is controlled by IAM authentication and authorization. IAM is the Identity and Access Management service of IBM Cloud\u00ae. User authentication and access control happens through IAM when you log in with your IBMId. See how to [retrieve the IAM token](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-iam-token-serverless).\n\nAs an administrator or creator of the service instance, you can grant or deny access to other users with whom you may want to share the service instance. All activities on the service instance life cycle management, like modifying the instance configuration, submitting and tracking Spark applications or customizing the instance with custom library sets are controlled through IAM authentication and authorization. See [Granting permissions to users](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless) to understand which operations are supported and what is the level of access required for each of those operations.\n\n\n\n\n\n Encrypting at Rest \n\nIBM Cloud Object Storage is the recommended data store to store the data required for executing Spark jobs on the cluster. IBM Cloud Object Storage comes with default built-in encryption. See [Encrypting your data](https:\/\/cloud.ibm.com\/docs\/cloud-object-storage\/basics?topic=cloud-object-storage-encryptionencryption).\n\nIn addition, or as an alternative to using IBM Cloud Object Storage storage encryption in analytic scenarios for large-scale data, you can use Parquet modular encryption, especially when fine-grained access control is important. See [Working with Parquet modular encryption](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-parquet-encryption-serverless).\n\n\n\n\n\n Encrypting endpoints","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-security-model-serverless"},{"document_id":"ibmcld_10906-35292-37042","score":14.028034,"text":"\n<br>If you have configured a Secrets Manager instance as described in [Encrypt and protect your data](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklistsecuring), you can use that instance to dynamically generate a service ID and an API key each time a protected resource is read or accessed. For more information, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui). \n <br><br> * Create API keys<br><br><br> An API key is a unique code passed into an API to identify the calling application or user. You can use platform IBM Cloud API keys that are associated with user identities, and you can create other API keys for service IDs. For more information, see [Understanding API keys](https:\/\/cloud.ibm.com\/docs\/account?topic=account-manapikey). <br>If you have configured a Secrets Manager instance as described in [Encrypt and protect your data](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklistsecuring), you can use that instance to dynamically generate a service ID and an API key each time a protected resource is read or accessed. For more information, see [Creating IAM credentials](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui). \n <br><br> * Learn about IAM policies<br><br><br> A policy consists of a subject, target, and a role. A policy grants a subject one or multiple roles to a set of resources so that specific actions can be taken. The role defines the level of access that is granted. For more information, see [What are IAM policies and who can assign them?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-iamusermanpol) \n\n\n\n\n\n\n\n Get support and other resources","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklist"},{"document_id":"ibmcld_12945-6747-8260","score":13.3657,"text":"\nFor example, if you click New to mint a new API key, you can select the Save this key in a secrets store for reuse checkbox to save the API key in a Key Protect instance to use it again later. If you do not already have a Key Protect instance, a new instance is created for you.\n\n\n\n\n\n Authorizing your toolchain to access secrets \n\nReferences to secrets that are stored in Key Protect are dynamically resolved when the toolchain runs. To access the required secrets, you must authorize your toolchain to access the Key Protect instance. If you create a toolchain that has a valid Key Protect tool integration, or add this tool integration to an existing toolchain, a request is automatically made to create the necessary authorization.\n\nTo view your authorizations in IBM Cloud, complete the following steps:\n\n\n\n1. From the IBM Cloud console, click Manage > Access (IAM).\n2. Click Authorizations.\n\n\n\nYou can also access your authorizations on the [Manage authorizations](https:\/\/cloud.ibm.com\/iam\/authorizations) page.\n\nZoom\n\n![Toolchain Authorizations for Key Protect](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/562806c0b18119f4d21cb66f5ae6d051634b4a16\/ContinuousDelivery\/images\/s2s-auths.png)\n\nFigure 3. Toolchain authorizations for Key Protect\n\nYou can create the authorization manually, if required. To successfully resolve the secret references, your toolchain instance must have both Viewer and ReaderPlus access to the correct Key Protect service instance.\n\n\n\n\n\n Configuring Key Protect by using the API","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-keyprotect"},{"document_id":"ibmcld_05581-20196-21776","score":13.360102,"text":"\nYou can enable encryption by creating a Kubernetes secret that uses your personal API key as long as you have the Reader service access role for your Key Protect instance as well as the Viewer platform access role and the Writer service access role for your cluster.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-access_cluster)\n\n\n\n1. Make sure that you are assigned the Editor platform access role and the Writer service access role for Key Protect so that you can create your own root key that you use to encrypt your Block Storage for Classic instance. You can review your IAM access roles in the [IAM console](https:\/\/cloud.ibm.com\/iam). For more information about IAM roles, see [IAM access](https:\/\/cloud.ibm.com\/docs\/account?topic=account-userroles).\n2. If you don't have a Key Protect instance, [provision one](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-provision).\n3. [Create a root key](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-create-root-keys). By default, the root key is created without an expiration date.\n4. Create an IAM service ID. Replace <service_ID_name> with the name that you want to assign to your service ID. This service ID is used to access your Key Protect instance from your Block Storage for Classic volume.\n\nibmcloud iam service-id-create <service_ID_name>\n\nExample output\n\nOK\nService ID test-id is created successfully\n\nID ServiceId-a1a11111-bb11-1111-a11b-1111111a11ba\nName test-id\nDescription","title":"","source":"https:\/\/cloud.ibm.com\/docs\/containers?topic=containers-block_storage"},{"document_id":"ibmcld_10393-14004-14767","score":13.056195,"text":"\n2. In the Instance ID field, enter your Hyper Protect Crypto Services instance ID. For example: d11a1a43-aa0a-40a3-aaa9-5aaa63147aaa.\n3. In the Secret name field, enter the name of the secret that you created by using your Hyper Protect Crypto Services credentials. For example: ibm-hpcs-secret.\n4. In the Base URL field, enter the public endpoint of your Hyper Protect Crypto Services instance. For example: https:\/\/api.eu-gb.hs-crypto.cloud.ibm.com:8389.\n5. In the Token URL field, enter https:\/\/iam.cloud.ibm.com\/identity\/token.\n\n\n\n\n\n\n\n\n\n Step 16: Verify OpenShift Data Foundation is running \n\n\n\n1. List the pods in the openshift-storage namespace and verify they are running.\n\noc get pods -n openshift-storage\n2. List the available storage classes.\n\noc get sc","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-openshift-storage-odf-private"},{"document_id":"ibmcld_12945-5261-7283","score":13.016536,"text":"\nBy using references to secrets that are managed by secret providers such as Key Protect, your secret values are centralized and stored securely in a single location. This approach resolves secrets sprawl and proliferation, and means that you can update secrets without updating your toolchain. When you use secret references, the actual secret value is resolved when the toolchain runs by dynamically retrieving it from Key Protect. This approach is useful when you must rotate the value of your toolchain secrets periodically.\n\n\n\n\n\n Adding a Key Protect tool integration to your toolchain template \n\nYou can add a Key Protect tool integration to your toolchain template by adding a service definition to the toolchain.yml file in your template repo. This file is the design blueprint for your toolchain and includes all of the tool integrations that are available when you create a toolchain instance based on that template. To customize an existing toolchain template to include a Key Protect tool integration, insert a YAML definition.\n\nkp-tool:\nservice_id: keyprotect\nparameters:\nname: kp-compliance-secrets\nregion: us-south\nresource-group: default\ninstance-name: ffs-secrets\n\nFor more information about customizing toolchain templates, see [Create a template for a custom toolchain](https:\/\/www.ibm.com\/cloud\/architecture\/tutorials\/create-a-template-for-a-custom-toolchain).\n\nIn certain scenarios, you can add a Key Protect tool integration dynamically while creating a toolchain. For example, if you click New to mint a new API key, you can select the Save this key in a secrets store for reuse checkbox to save the API key in a Key Protect instance to use it again later. If you do not already have a Key Protect instance, a new instance is created for you.\n\n\n\n\n\n Authorizing your toolchain to access secrets \n\nReferences to secrets that are stored in Key Protect are dynamically resolved when the toolchain runs. To access the required secrets, you must authorize your toolchain to access the Key Protect instance.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/services\/ContinuousDelivery?topic=ContinuousDelivery-keyprotect"},{"document_id":"ibmcld_00055-4234-5526","score":12.911808,"text":"\nSee [Architecture and concepts in serverless instances](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts) for a description of the provisioning parameters in the payload.\n\nNote that both Spark 3.1 and Spark 3.3 are supported. If you don't specify a default Spark runtime version when you create a service instance, Spark 3.1 is taken by default.\n\n{\n\"default_runtime\": {\n\"spark_version\": \"3.1\"\n},\n\"instance_home\": {\n\"region\": \"us-south\",\n\"endpoint\": \"https:\/\/s3.direct.us-south.cloud-object-storage.appdomain.cloud\",\n\"hmac_access_key\": \"<your-hmac-access-key\",\n\"hmac_secret_key\": \"<your-hmac-secret-key\"\n},\n\"default_config\": {\n\"key1\": \"value1\",\n\"key2\": \"value2\"\n}\n}\n\nThe IBM Cloud\u00ae response to the create instance command:\n\nCreating service instance MyServiceInstance in resource group Default of account <your account name> as <your user name>...\nOK\nService instance MyServiceInstance was created.\n\nName: MyServiceInstance\nID: crn:v1:staging:public:ibmanalyticsengine:us-south:a\/d628eae2cc7e4373bb0c9d2229f2ece5:1e32e-afd9-483a-b1-724ba5cf4::\nGUID: 1e32e-afd9-483a-b1-724ba5cf4\nLocation: us-south\nState: provisioning\nType: service_instance\nSub Type:\nService Endpoints: public\nAllow Cleanup: false\nLocked: false\nCreated at: 2021-11-29T07:20:40Z","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless"},{"document_id":"ibmcld_00046-3301-4886","score":12.8561535,"text":"\nSet the class implementing EncryptionPropertiesFactory:\n\nsc.hadoopConfiguration.set(\"parquet.crypto.factory.class\",\"com.ibm.parquet.key.management.IBMKeyToolsFactory\")\n2. Provide the IAM access token for the relevant keys:\n\nsc.hadoopConfiguration.set(\"parquet.encryption.key.access.token\" , \"<token string>\")\n3. Call the regular parquet read commands, such as:\n\nval dataFrame = spark.read.parquet(\"<path to encrypted files>\")\n\n\n\n\n\n\n\n Key rotation \n\nIf key rotation is required, the administrator has to rotate master keys in Key Protect using the procedure described in [Manually rotating keys](https:\/\/cloud.ibm.com\/docs\/key-protect?topic=key-protect-rotate-keys). Then the administrator can trigger Parquet key rotation by calling:\n\npublic static void KeyToolkit.rotateMasterKeys(String folderPath, Configuration hadoopConfig)\n\nTo enable Parquet key rotation, the following Hadoop configuration properties must be set:\n\n\n\n* The parameters \"parquet.encryption.key.access.token\", \"parquet.encryption.kms.instance.url\", \"parquet.encryption.kms.instance.id\"\n* The parameter \"parquet.encryption.key.material.store.internally\" must be set to \"false\"\n* The parameter \"parquet.encryption.kms.client.class\" must be set to \"com.ibm.parquet.key.management.KeyProtectClient\"\n* * The parameter \"parquet.crypto.factory.class\" must be set to \"com.ibm.parquet.key.management.IBMKeyToolsFactory\"\n\nFor example:\n\nsc.hadoopConfiguration.set(\"parquet.encryption.key.access.token\" , \"<token string>\")\nsc.hadoopConfiguration.set(\"parquet.encryption.kms.instance.url\" , \"https:\/\/<region>.kms.cloud.ibm.com\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-key-management-key-protect-serverless"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"5815bb4a99e2a0d8a986348da4c49083<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_13481-6212-7871","score":19.479002,"text":"\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management. For user, specify the CRN and for password a valid API key with access to your Data Engine. Find the endpoint to use in the following table.\n\n\n\nTable 1. Region endpoints\n\n Region Endpoint \n\n us-south thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083 \n eu-de thrift:\/\/catalog.eu-de.dataengine.cloud.ibm.com:9083 \n\n\n\n\n\n\n\n Convenience libraries to configure Spark \n\nWhile the Data Engine catalog is compatible with the Hive metastore and can be used as any other external Hive metastore server, an SDK is provided to minimize the steps that are needed to configure Apache Spark. The SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/dataengine-spark-integration-1.4.51.jar)","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_13481-7-1988","score":18.426172,"text":"\nConnecting Apache Spark with Data Engine \n\nIBM Cloud\u00ae Data Engine catalog provides an interface that is compatible with Apache Hive metastore. This unified metadata repository enables any Big Data engine, such as Apache Spark, to use Data Engine as metastore. The same definition for tables and views can be created once and used from any connected engine. Each instance of Data Engine exports its catalog as a database called default.\n\n\n\n Catalog usage within Data Engine \n\nThe Catalog can be used in Data Engine in read and write mode. Seamless access is configured without any configuration steps needed.\n\n\n\n\n\n Connecting Apache Spark with Data Engine \n\nWhen you use the Hive metastore compatible interface, access is limited to read only operations. Thus, existing tables and views can be used, but not modified.\n\nDepending from where you want to connect to your catalog, the steps may vary.\n\n\n\n Usage within Watson Studio Notebooks \n\nWatson Studio has the compatible Hive metastore client already included. It also includes a convenience library to configure the connection to the Hive metastore. Set the required variables (CRN and apikey) and call the helper function to connect to the Hive metastore:\n\n change the CRN and the APIkey according to your instance\ncrn='yourDataengineCRN'\napikey='yourAPIkey'\n\nfrom dataengine import SparkSessionWithDataengine\n\n call the helper function to create a session builder equipped with the correct config\nsession_builder = SparkSessionWithDataengine.enableDataengine(crn, apikey, \"public\")\nspark = session_builder.appName(\"Spark DataEngine integration test\").getOrCreate()\n\nDisplay your tables and run an SQL statement:\n\nspark.sql('show tables').show(truncate=False)\n\n replace yourTable with a valid table. Do not use the sample tables as you do not have access to the data!\nspark.sql('select * from yourTable').show()\n\n\n\n\n\n Usage with IBM Analytics Engine \n\nThe Hive metastore client is also already included in IBM\u00ae Analytics Engine.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_00032-0-1390","score":18.074774,"text":"\n\n\n\n\n\n\n  Working with Spark SQL and an external metastore \n\nSpark SQL uses Hive metastore to manage the metadata of a user's applications tables, columns, partition information.\n\nBy default, the database that powers this metastore is an embedded Derby instance that comes with the Spark cluster. You could choose to externalize this metastore database to an external data store, like to an IBM Cloud Databases for PostgreSQL or an IBM Cloud Data Engine (previously SQL Query) instance.\n\nPlacing your metadata outside of the Spark cluster will enable you to reference the tables in different applications across your IBM Analytics Engine instances. This, in combination with storing your data in IBM Cloud Object Storage, helps persisting data and metadata and allows you to work with this data seamlessly across different Spark workloads.\n\n\n\n  Enabling and testing an external metastore with IBM Analytics Engine \n\nTo enable and test an external metastore with IBM Analytics Engine, you need to perform the following steps:\n\n\n\n1.  Create a metastore to store the metadata. You can choose to provision either an IBM Cloud Databases for PostgreSQL or an IBM Cloud Data Engine (previously SQL Query) instance.\n2.  Configure IBM Analytics Engine to work with the database instance.\n3.  Create a table in one Spark application and then access this table from another Spark application.\n\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-external-metastore"},{"document_id":"ibmcld_13481-5443-6857","score":17.745758,"text":"\n.config(\"spark.hive.metastore.uris\", \"thrift:\/\/catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\") \n.config(\"spark.hive.metastore.client.plain.username\", '<YourDataengineCRN>') \n.config(\"spark.hive.metastore.client.plain.password\", '<YourAPIkey>') \n.config(\"spark.hive.execution.engine\", \"spark\") \n.config(\"spark.hive.stats.autogather\", \"false\") \n.config(\"spark.sql.warehouse.dir\", \"file:\/\/\/tmp\") \n only spark is allowed as the default catalog\n.config(\"metastore.catalog.default\", \"spark\") \n.enableHiveSupport() \n.getOrCreate()\nShow more\n\n\n\n\n\n Apache Hive metastore version 3.1.2 compatible client \n\nDownload the [Hive-compatible client](https:\/\/us.sql-query.cloud.ibm.com\/download\/catalog\/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in \/tmp\/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_16641-2355-3755","score":17.740274,"text":"\nspark.sql.catalog.lakehouse.uri = <hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683)\nspark.hive.metastore.client.auth.mode = PLAIN\nspark.hive.metastore.client.plain.username = <hms-user-from-watsonx.data> (for example, ibmlhapikey)\nspark.hive.metastore.client.plain.password = <hms-password-from-watsonx.data>\nspark.hive.metastore.use.SSL = true\nspark.hive.metastore.truststore.type = JKS\nspark.hive.metastore.truststore.path = file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\nspark.hive.metastore.truststore.password = changeit\nShow more\n\n\n\nParameter value:\n\n\n\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data.\n* Hms-user-from-watsonx.Data: The watsonx.data username.\n* Hms-password-from-watsonx.Data: The watsonx.data password.\n\n\n\n\n\n\n\n Configuring Analytics Engine instance by using Analytics Engine API \n\nTo configure your IBM Analytics Engine instance from the Analytics Engine API, complete the following steps:\n\n\n\n1. Generate an IAM token to connect to the IBM Analytics Engine API. For more information about how to generate an IAM token, see [IAM token](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli).\n2. Run the following API command to invoke the Analytics Engine API by using the generated IAM token.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_00042-2867-4770","score":17.545635,"text":"\nSee [Use the Spark history server](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-spark-history-serverless).\n\n\n\n\n\n September 2022 \n\n\n\n 21 September 2022 \n\nSupport for Spark 3.3\n: You can now provision IBM\u00ae Analytics Engine severless plan instances with the default Spark runtime set to Spark 3.3, which enables you to run Spark applications on Spark 3.3.\n\n\n\n\n\n 09 September 2022 \n\nYou can now use Hive metastore to manage the metadata related to your applications tables, columns, and partition information when working with Spark SQL.\n: You could choose to externalize this metastore database to an external data store, like to an IBM Cloud Data Engine (previously SQL Query) or an IBM Cloud Databases for PostgreSQL instance. For details, see [Working with Spark SQL and an external metastore](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-external-metastore).\n\n\n\n\n\n\n\n July 2022 \n\n\n\n 12 July 2022 \n\nYou can now provision IBM\u00ae Analytics Engine serverless instances in a new region.\n: In addition to the IBM Cloud\u00ae us-south (Dallas) region, you can now also provision serverless instances in the eu-de (Frankurt) region.\n\n\n\n\n\n 08 July 2022 \n\nNew API for platform logging\n: Start using the log_forwarding_config API to forward platform logs from an IBM Analytics Engine instance to IBM Log Analysis. Although you can still use the logging API, it is deprecated and will be removed in the near future. For details on how to use the log_forwarding_config API, see [Configuring and viewing logs](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n\n\n\n\n\n\n\n 13 May 2022 \n\nSupport for Python 3.9\n: You can now run Spark applications using Python 3.9. on your IBM Analytics Engine serverless instances.\n\n\n\n\n\n 04 April 2022 \n\nLimitation on how long Spark applications can run\n: Spark applications can run for a maximum period of 3 days (72 hours).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-iae-serverless-relnotes"},{"document_id":"ibmcld_00029-8568-9861","score":17.500324,"text":"\n\"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3\n\"spark.hive.metastore.truststore.path\":\"\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n for spark 3.1, spark 3.2\n\"spark.hive.metastore.truststore.path\":\"file:\/\/\/opt\/ibm\/jdk\/jre\/lib\/security\/cacerts\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.jars\":\"\/opt\/ibm\/connectors\/data-engine\/hms-client\/\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.version\":\"3.0\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.warehouse.dir\":\"file:\/\/\/tmp\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hadoop.metastore.catalog.default\":\"spark\"\n},\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"application\": \"cos:\/\/mybucket.ALIAS NAME\/select_query_data_engine.py\"\n\u00a0\u00a0\u00a0 }\n}\nShow more\n\nParameter values:\n\n\n\n* ALIAS NAME: specify the data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-overviewendpoints).\n* THRIFT URL: specify the region-specific thrift URL. For example, thrift:\/\/catalog.us.dataengine.cloud.ibm.com:9083.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"},{"document_id":"ibmcld_13481-3545-4909","score":17.456987,"text":"\ncurl -X POST https:\/\/api.us-south.ae.cloud.ibm.com\/v3\/analytics_engines\/<GUID of Analytic Engine>\/spark_applications --header \"Authorization: Bearer $TOKEN\" -H \"content-type: application\/json\" -d @listTablesExample.json\n\n\n\n\n\n Apache Spark Data Engine integration \n\nFor self-hosted Apache Spark installations use the following instructions.\n\n\n\n1. Ensure that [Stocator](https:\/\/github.com\/CODAIT\/stocator) is installed according to the instructions provided.\n2. Download the Hive-compatible client with the provided [instructions](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastorehive_compatible_client).\n3. Either download the [provided convenience libraries](https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastoreconvenience_libraries) or, in case you don't want to use them, set the following settings in SparkContext yourself:\n\nspark = SparkSession.builder.appName('Python-App') \n.config(\"spark.sql.pyspark.jvmStacktrace.enabled\", True) \n.config(\"spark.hive.metastore.truststore.path\", \"file:\/\/\/opt\/ibm\/jdk\/jre\/lib\/security\/cacerts\") \n to access IBM Cloud Object Storage ensure that stocator is available\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\") \n.config(\"fs.stocator.scheme.list\", \"cos\") \n.config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\") \n.config(\"fs.stocator.cos.scheme\", \"cos\")","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sql-query?topic=sql-query-hive_metastore"},{"document_id":"ibmcld_16641-4554-5850","score":17.177557,"text":"\n\"spark.sql.catalog.lakehouse.type\": \"hive\",\n\"spark.sql.catalog.lakehouse.uri\": \"<hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683) \",\n\"spark.hive.metastore.client.auth.mode\": \"PLAIN\",\n\"spark.hive.metastore.client.plain.username\": \"<hms-user-from-watsonx.data> (for example, ibmlhapikey)\",\n\"spark.hive.metastore.client.plain.password\": \"<hms-password-from-watsonx.data>\",\n\"spark.hive.metastore.use.SSL\": \"true\",\n\"spark.hive.metastore.truststore.type\": \"JKS\",\n\"spark.hive.metastore.truststore.path\": \"file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n\"spark.hive.metastore.truststore.password\": \"changeit\"\n}\nShow more\n* BASE_URL: The Analytics Engine URL for the region where you provisioned the instance. For example, api.region.ae.ibmcloud.com.\n* INSTANCE_ID: The Analytics Engine instance ID. For more information about how to retrieve an instance ID, see [Obtaining the service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli).\n* hms-thrift-endpoint-from-watsonx.data: Specify the credentials for watsonx.data.\n* hms-user-from-watsonx.data: The watsonx.data username.\n* hms-password-from-watsonx.data: The watsonx.data password.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"},{"document_id":"ibmcld_16641-6629-7897","score":16.943752,"text":"\n\"spark.sql.catalog.lakehouse.type\": \"hive\",\n\"spark.sql.catalog.lakehouse.uri\": \"<hms-thrift-endpoint-from-watsonx.data> for example (thrift:\/\/81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683) \",\n\"spark.hive.metastore.client.auth.mode\": \"PLAIN\",\n\"spark.hive.metastore.client.plain.username\": \"<hms-user-from-watsonx.data> (for example, ibmlhapikey)\",\n\"spark.hive.metastore.client.plain.password\": \"<hms-password-from-watsonx.data>\",\n\"spark.hive.metastore.use.SSL\": \"true\",\n\"spark.hive.metastore.truststore.type\": \"JKS\",\n\"spark.hive.metastore.truststore.path\": \"file:\/\/\/opt\/ibm\/jdk\/lib\/security\/cacerts\",\n\"spark.hive.metastore.truststore.password\": \"changeit\"\n}\nShow more\n* INSTANCE_ID: The Analytics Engine instance ID. For more information about how to retrieve an instance ID, see [Obtaining the service endpoints](https:\/\/cloud.ibm.com\/docs\/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli)\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data. For more information on getting the HMS credentials, see [Getting (Hive metastore) HMS Credentials](https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-hms).\n* Hms-user-from-watsonx.Data: The watsonx.data username.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watsonxdata?topic=watsonxdata-lh-config-ae"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.3333333333,"recall_5":0.6666666667,"recall_10":0.6666666667,"ndcg_cut_1":1.0,"ndcg_cut_3":0.469278726,"ndcg_cut_5":0.6713860725,"ndcg_cut_10":0.6713860725}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>1","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_02597-4595-6892","score":13.077546,"text":"\nThrough the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.\n\nAs well as controlling which APIs a customer can use, different Plans can be used to implement rate limits. A rate limit can be implemented as a default rate across an entire Plan, or for specific operations of an API within that Plan, exempting them from the Plan rate limit. Different Plans can have differing rate limits, both between operations and for the overall limit. Applying rate limits to Plans makes it easy to offer different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute while a \"Full Plan\" might permit up to 1000 calls per minute.\n\nFinally, different Plans can be used to assign a billing cost. A Plan can be set as a free Plan, or as a Plan with billing. Plans with billing can be used with rate limits to set different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute for a cost of $5 per month, while a \"Full Plan\" might permit up to 1000 calls per minute for a cost of $20 per month.\n\nNote: Applying a rate limit at the Plan level, creates a default rate limit that applies to each operation within the Plan. If you need to set specific rate limits for specific operations, you must set them within the operations themselves and this setting overrides the setting at the Plan level.\n\nIBM API Connect also supports the implementation of multiple versions of Products. You can choose version numbers and use them to aid the development of your Products and Plans.\n\nNote: The version for a Product is distinct from the version of any APIs that are contained in the associated Plans. Plans cannot themselves have their own version, they use the version of their parent Product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_02597-3131-5174","score":11.390014,"text":"\nPlans can share APIs, but whether subscription approval is required depends upon the Plan itself. Additionally, you can enforce rate limits through Plans or through operations within a Plan's APIs that override the Plan's rate limit.\n\nPlans can also specify billing costs for customers who use your Products. For example, you can define three different Plans for a single Product. Each Plan can have a different subscription cost and a different rate limit that targets different customers.\n\n\n\n\n\n Products \n\nPlans and APIs are grouped in Products. Through Products, you can manage the availability and visibility of APIs and Plans. Use the API Designer to create, edit, and stage your Product. Use the API Manager to manage the lifecycle of your Product.\n\nThe following diagram demonstrates how Products, Plans, and APIs relate to one another. Note how Plans belong to only one Product, can possess different APIs to other Plans within the same Product, and can share APIs with Plans from any Product. Figure to show the hierarchy of Products, Plans, and APIs. ![Figure to show the hierarchy of Products, Plans, and APIs.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/78bb71851d95d7580503eb9ba10cf3ae31490ade\/apiconnect\/images\/plan_product_hierarchy.png)\n\nYou can create Plans only within Products, and these Products are then published in a Catalog. A lifecycle manager can then control the availability and visibility of APIs and Plans through the API Manager. Through the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-about_apic_overview"},{"document_id":"ibmcld_02612-4813-6728","score":11.065349,"text":"\nIf you select Custom, use the Type to add field to search for the developer organizations or communities that you want to be able to subscribe to the Plans in the Product.\n9. In the APIs section, specify the APIs that you want to include in the Product.\n\n\n\n1. Click the Add API icon.\n2. Select the APIs that you want to include, then click Apply. The selected APIs are listed.\n\n\n\n10. To make an API available to application developers, you must include it in a Plan. To add one or more Plans to the Product, click the Add Plan icon.\n\n\n\n1. Expand the new Plan that has been created. If you have already added APIs to your Product, these are automatically included.\n2. Rename your Plan in the Title and Name fields, and optionally add a description. Note: A Default Plan is automatically created for you, and you can include your API in this Plan if you do not want to create your own. However, if you decide not to use the Default Plan you must delete it, as a Product cannot be staged if it includes any Plans that do not include APIs.\n\n\n\n11. Verify that the APIs you require are included in the Plan.\n\n\n\n1. Expand the Plan to which you want to add an API.\n2. Under APIs included, ensure that the check boxes of the APIs you require are selected. If there are APIs already selected, and you do not want them included in the Plan you are editing, clear their check boxes.\n\n\n\n12. Optional: Add the billing information for your Plan. To add billing information, you must establish an account with a credit card processing service so your customers can pay with a credit card. Monthly billing Plans are billed on the same date of each month.\n13. Optional: If you want to tailor which operations from an API are included in the Plan, hover the cursor over the API that contains the operation. Click the Show operations icon, and then select or clear the check boxes for the operations you want to include or exclude.\n14.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/apiconnect?topic=apiconnect-managing_products"},{"document_id":"ibmcld_04118-531-2235","score":10.931683,"text":"\nThe following table compares each offering to help you choose the one that's right for you. Enterprise Tier plans are available with different pricing models.\n\n\n\nTable 1. CIS plan comparison\n\n Standard Next Enterprise Essentials Enterprise Advanced Enterprise Premier Enterprise Usage \n\n Domain 1 1 2 2 Up to 1000, but recommend no more than 20 \n DNS 250 records 3500 records 3500 records 3500 records 3500 records \n Global load balancers <br><br> * 3 pools<br> * 3 origin servers<br> * 5 Health checks<br> * 60s health checks<br> * Geo Routing<br> * Health checks from single region<br> * 60s minimum TTL for non-proxied global load balancers<br><br><br> <br><br> * 20 pools <br> (additional pools available for charge)<br> * 20 origin servers<br> * 100 health checks<br> * 5s health checks<br> * Smart Routing<br> * Health checks from multiple regions<br> * 10s minimum TTL for non-proxied global load balancers<br><br><br> <br><br> * 20 pools <br> (additional pools available for charge)<br> * 20 origin servers<br> * 100 health checks<br> * 5s health checks<br> * Smart Routing<br> * Health checks from multiple regions<br> * 10s minimum TTL for non-proxied global load balancers<br><br><br> <br><br> * 20 pools <br> (additional pools available for charge)<br> * 20 origin servers<br> * 100 health checks<br> * 5s health checks<br> * Smart Routing<br> * Health checks from multiple regions<br> * 10s minimum TTL for non-proxied global load balancers<br><br><br> <br><br> * Up to 100 pools<br> * 100 origin servers<br> * Up to 100 health checks<br> * 5s health checks<br> * Smart Routing<br> * Health checks from multiple regions<br> * 10s minimum TTL for non-proxied global load balancers<br><br><br>","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-plan-comparison"},{"document_id":"ibmcld_08069-7-2230","score":10.260192,"text":"\nBasic, Advanced, and Premium Support plans \n\nYou can choose a Basic, Advanced, or Premium support plan to customize your IBM Cloud\u00ae support experience for your business needs. The level of support that you select determines the severity that you can assign to support cases and your level of access to the tools available in the Support Center.\n\nIf you have free support, you're provided technical support through [Stack Overflow](https:\/\/stackoverflow.com\/questions\/tagged\/ibm-cloud?tab=Newest). Also, with a Lite account and free support, you can open cases that are related to access management, accounts, and billing and usage. If you want to upgrade your support plan, contact a [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule) representative.\n\nInitial response Service Level Objectives (SLO) do not apply to any billing, invoice, or sales related inquiry or cases.\n\nThe following table shows the support types available for Pay-As-You-Go accounts, Subscription accounts, and the Enterprise Savings Plan billing model. For more information about accounts, see [Account types](https:\/\/cloud.ibm.com\/docs\/account?topic=account-accounts).\n\n\n\nTable 1. Support plans\n\n Basic Support Advanced Support Premium Support \n\n Description Basic business protection that is included with your IBM Cloud Pay-As-You-Go or Subscription account Prioritized case handling and support experience that is aligned with your business needs for your Pay-As-You-Go account, Subscription account, or Enterprise Savings Plan billing model Client engagement that is aligned with your business outcomes to accelerate time-to-value for your Pay-As-You-Go account, Subscription account, or Enterprise Savings Plan billing model \n Availability 24 x 7 access to the IBM Cloud technical support team through cases <br>Phone and chat are available only for Pay-As-You-Go and Subscription accounts 24 x 7 access to the IBM Cloud technical support team through cases, phone, and chat 24 x 7 access to the IBM Cloud technical support team through cases, phone, and chat \n [Case severity](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-case-severity) Not applicable Case severity ranking available Case severity ranking available","title":"","source":"https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-support-plans"},{"document_id":"ibmcld_04118-7-945","score":10.203383,"text":"\nPlan comparison \n\nIBM Cloud\u00ae Internet Services offers several plans to choose from: no-cost Trial, Standard Next, and Enterprise Tier variations.\n\nThe no-cost Trial plan is the same as the Standard Next plan, except that it expires after 30 days. Only one trial is available per account. After the Trial plan has expired, it is automatically subject to reclamation.\n\nThe numbers in these tables are quotas or resource limits for the associated feature. Features are pay-as-you-go, except for Trial and Standard Next plans.\n\nThe following table compares each offering to help you choose the one that's right for you. Enterprise Tier plans are available with different pricing models.\n\n\n\nTable 1. CIS plan comparison\n\n Standard Next Enterprise Essentials Enterprise Advanced Enterprise Premier Enterprise Usage \n\n Domain 1 1 2 2 Up to 1000, but recommend no more than 20 \n DNS 250 records 3500 records 3500 records 3500 records 3500 records","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cis?topic=cis-cis-plan-comparison"},{"document_id":"ibmcld_10906-20682-22396","score":10.157332,"text":"\nLearn more about [Enterprise Savings Plan](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-committed-use) and [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions). \n <br><br> * View invoices and build your own reports<br><br><br> To manage and view your invoices, visit the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud console. See [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices). You can also build your own reports by using the API and SDK that are available.<br><br><br><br> * [Usage Reports API\/SDK](https:\/\/cloud.ibm.com\/apidocs\/metering-reporting)<br> * [Enterprise Billing Units API\/SDK](https:\/\/cloud.ibm.com\/apidocs\/enterprise-apis\/billing-unit).<br> * [Enterprise Usage Reports API\/SDK](https:\/\/cloud.ibm.com\/apidocs\/enterprise-apis\/resource-usage-reports).<br><br><br> \n\n\n\n\n\n\n\n Connect your network to IBM Cloud \n\nAs the need for global reach and 24\/7 operations of web applications increases, the need to host services in multiple cloud data centers increases too. Data centers across multiple locations provide resilience in the case of a geographic failure and bring workloads closer to globally distributed users, which reduces latency and increases perceived performance. The IBM Cloud network enables users to link workloads hosted in secure private networks across data centers and locations. Use the following checklist to review the available options and to connect your existing on-premises environments to IBM Cloud.\n\n\n\nTable 5. Getting started tasks for connecting your network to IBM Cloud\n\n Task Description","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-get-started-checklist"},{"document_id":"ibmcld_16364-161519-163610","score":10.007231,"text":"\nIf you choose to use this plan, design any custom applications that you build to properly identify the users who generate \/message API calls. See [User-based plans](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-services-informationservices-information-user-based-plans) for more information.\n\nExisting Premium plan service instances are not impacted by this change; they continue to use API-based billing methods. Only existing Premium plan users will see the API-based plan listed as the Premium (API) plan option.\n\nSee Watson Assistant [service plan options](https:\/\/www.ibm.com\/cloud\/watson-assistant\/pricing\/) for more information about all available service plans.\n\n\n\n\n\n 20 November 2018 \n\n**Recommendations are discontinued\n: The Recomendations section on the Improve tab was removed. Recommendations was a beta feature available to Premium plan users only. It recommended actions that users could take to improve their training data. Instead of consolidating recommendations in one place, recommendations are now being made available from the parts of the tool where you make actual training data changes. For example, while adding entity synonyms, you can now opt to see a list of synonymous terms that are recommended by Watson. If you are looking for other ways to analyze your user conversation logs in more detail, consider using Jupyter notebooks. See [Advanced tasks](https:\/\/cloud.ibm.com\/docs\/assistant?topic=assistant-logs-resources) for more details.\n\n\n\n\n\n 9 November 2018 \n\nMajor user interface revision\n: The Watson Assistant service has a new look and added features.\n\nThis version of the tool was evaluated by beta program participants over the past several months.\n\n\n\n* Skills: What you think of as a workspace is now called a skill. A dialog skill is a container for the natural language processing training data and artifacts that enable your assistant to understand user questions, and respond to them.\n\n\n\nWhere are my workspaces? Any workspaces that you created previously are now listed in your service instance as skills. Click the Skills tab to see them.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"},{"document_id":"ibmcld_02660-1509-3609","score":10.006573,"text":"\nCurrently, Dallas (us-south), Washington DC (us-east), London (eu-gb), and Sydney (au-syd) regions are supported.\n4. Select a pricing plan - Based on your business requirements, select a pricing plan: Lite, Standard, and Enterprise.\n\n\n\n* Lite - Includes all App Configuration capabilities for evaluation only. Not to be used for production. Lite plan services are deleted after 30 days of inactivity.\n* Standard - The standard plan includes feature flags and property management capabilities. You can use simple and uniform REST APIs to configure, enable, segment, and monitor features to mobile devices and web applications.\n* Enterprise - The enterprise plan includes targeting segment in addition to the property management and feature flags that are found in the Standard plan. The enterprise plan now supports by using private endpoints.\n\n\n\nFor more information about App Configuration usage and billing, see [Usage and billing](https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-faqs-usage).\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a resource group - The resource group selection helps how you want resources to be organized in your account. The resource group that you select cannot be changed after the service instance is created.\n7. Optionally, define Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key:value pairs to help group-related tags, such as costctr:124.\n8. Optionally, define Access management tags that are needed to apply flexible access policies on specific resources. For example, access:dev, proj:version-1.\n9. If you selected the Enterprise plan, then specify the Service endpoints. The following options are available:\n\n\n\n* Public network - The public network service endpoints are accessible from anywhere on the internet.\n* Both Public & Private network - use of both public and private service endpoint network access.\n\n\n\n10. Accept the licensing agreements and terms by clicking the checkbox.\n11.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/app-configuration?topic=app-configuration-ac-create-an-instance"},{"document_id":"ibmcld_04709-1717-3966","score":9.935253,"text":"\nPricing Hourly and monthly billing, plus suspend billing features Hourly, suspend billing, and sustained usage discount \n Virtual server families Public, dedicated, transient, reserved Public, dedicated \n Profiles All profiles, including the GPU profiles Balanced, compute, memory profiles with higher RAM and vCPU options \n Supported images Full set of pre-stock images, plus custom images Limited set of pre-stock images, plus the ability to import a custom image \n Platform integration IAM and resource group integration for a unified experience \n\n\n\nSuspend billing supports only hourly, SAN instances that are provisioned with a public profile from one of the Balanced, Compute, Memory, or Variable compute families.\n\n\n\n\n\n Network differentiators \n\nSee the following table for the networking differences between classic and VPC.\n\n\n\nTable 2. Network comparison\nThis table has row and column headers. The row headers identify possible features. The column headers identify the differentiators between classic infrastructure and VPC infrastructure. To understand the differences between environments, navigate to the row and find the details for the feature that you're interested in.\n\n Category Classic infrastructure VPC infrastructure \n\n Location construct Data centers and PODs <br>(Might require VLAN spanning to connect two different pods or data centers, and purchasing gateways to control and route traffic) Regional model that abstracts infrastructure so you don't need to worry about pod locations. \n Network functions and services Physical and virtual appliances from multiple vendors Cloud-native network functions (VPNs, LBaaS) <br>(VPC isolation, dedicated resources carved out of public cloud, with more options for VPNs, LBaaS, multiple vNIC instances, and larger subnet sizes) \n IP addresses IPv6 addresses supported IPv4 addresses only \n Gateway routing Use a virtual or physical network appliance (Virtual Router Appliance, Vyatta, Juniper vSRX, Fortinet FSA) Traffic routing is handled by public gateway and floating IP services \n Network address translation (NAT) Use a virtual or physical network appliance (Virtual Router Appliance, Vyatta, Juniper vSRX, Fortinet FSA) Supported by the Bring-your-own-IP (BYOIP) functionality","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-infrastructure?topic=cloud-infrastructure-compare-infrastructure"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>2","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03735-7-1918","score":13.283043,"text":"\nEstimating your costs \n\nYou can use the cost estimator to estimate the cost of IBM Cloud\u00ae products by customizing plans that fit your business needs. Your account type doesn't affect your estimates. Explore the catalog to find available products to add to an estimate.\n\nEstimates can now be saved to an account. Make sure you're in the account that you want to save the estimate to. If you have existing estimates, they must be converted to a saved estimate that is attached to an account.\n\n\n\n Creating a new estimate \n\n\n\n1. In the IBM Cloud console, go to Cost estimator icon![Cost estimator icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/calculator.svg). From here, you are directed to Estimating your costs page.\n2. Click Create new estimate.\n3. Enter a name and description for the estimate.\n4. Click Create\n5. From here, you are directed to the estimate details page. Click Go to catalog to add products to the estimate.\n6. Select the product that you are interested in.\n\nDepending on the product, an interim informational page might be displayed. For example, if you select Bare Metal Servers, an informational page that describes various features is displayed. Click Continue.\n7. Select your pricing plan and enter other configuration details if needed. Then, click Add to estimate.\n\nSome products might require that you log in to add them to an estimate.\n8. Enter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_01623-6277-8255","score":12.897402,"text":"\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https:\/\/cloud.ibm.com\/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-started"},{"document_id":"ibmcld_10116-17431-19145","score":12.407731,"text":"\nSee [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as tiered pricing for increased hourly usage. For more information, see [Understanding costs for your clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costscosts-for-clusters).\n\n\n\n\n\n Managing costs \n\nThe following steps present a general process to manage costs for your Red Hat OpenShift on IBM Cloud clusters.\n\n\n\n1. Decide on a cloud platform strategy to manage your resources.\n\n\n\n* See [Best practices for billing and usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-best-practices).\n* Organize your billing with [resource groups](https:\/\/cloud.ibm.com\/docs\/account?topic=account-rgs).\n* [Add tags to your clusters](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-add_workerscluster_tags) according to your organizational strategy.\n\n\n\n2. Plan the type of cluster that you need.\n\n\n\n* [Size your cluster to support your workloads](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategysizing), including the network bandwidth that your workloads need.\n* [Decide the cluster environment that you want](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-strategykube_env).\n* [Consider the availability that you want for your cluster](https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-ha_clusters). For example, a basic high availability setup is one multizone cluster with two worker nodes in each of three zones, for a minimum total of 6 worker nodes.\n\n\n\n3. Check out other IBM Cloud services, add-ons, operators, and other third-party software that you might use that can increase your cost.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/openshift?topic=openshift-costs"},{"document_id":"ibmcld_03735-1425-3233","score":12.303775,"text":"\nEnter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1. Click Save and select the estimate that you'd like to add the product to, and then add the calculated cost to your estimate by clicking Save.\n2. When you're done adding products to your estimate, review the product details, and click View estimate.\n\n\n\n\n\n\n\n Updating an existing estimate \n\nYou can always update the name and description of an estimate as your needs change. To edit an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to edit.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Edit.\n3. Enter the updated name and description.\n4. Click Save\n\n\n\n\n\n\n\n Saving and sharing your estimate \n\nWhen you create an estimate, you can save each estimate's unique link to share or revisit directly through your browser. To share an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to share.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Share.\n3. Click Copy link and share the link with users in your account.\n\n\n\n\n\n\n\n Creating quotes for classic infrastructure services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_07578-278658-280528","score":12.218608,"text":"\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?\n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n\n\n\nSlurm on IBM Cloud\n\n\n\n* What Slurm version is used in cluster nodes deployed with this offering?\n\nCluster nodes that are deployed with this offering include Slurm 19.05.5-1 Advanced Edition.\n* What locations are available for deploying VPC resources?\n\nAvailable regions and zones for deploying VPC resources, and a mapping of those to city locations and data centers can be found in [Locations for resource deployment](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locations).\n* What permissions do I need in order to create a cluster using the offering?\n\nInstructions for setting the appropriate permissions for IBM Cloud services that are used by the offering to create a cluster can be found in [Granting user permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources), [Managing user access for Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access), and [Assigning access to Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-assign-access).\n* How do I SSH among nodes?\n\nAll of the nodes in the HPC cluster have the same public key that you register at your cluster creation.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-278632-280502","score":12.218608,"text":"\nWhen you create a resource such as a location or cluster, you can review a cost estimate in the Summary pane of the console. For other types of estimates, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as the costs for your underlying infrastructure.\n* Can I view and control my current usage?\n\nSee [View your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusageviewingusage) and [Set spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending) for general IBM Cloud account guidance.\n\n\n\nSlurm on IBM Cloud\n\n\n\n* What Slurm version is used in cluster nodes deployed with this offering?\n\nCluster nodes that are deployed with this offering include Slurm 19.05.5-1 Advanced Edition.\n* What locations are available for deploying VPC resources?\n\nAvailable regions and zones for deploying VPC resources, and a mapping of those to city locations and data centers can be found in [Locations for resource deployment](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-locations).\n* What permissions do I need in order to create a cluster using the offering?\n\nInstructions for setting the appropriate permissions for IBM Cloud services that are used by the offering to create a cluster can be found in [Granting user permissions for VPC resources](https:\/\/cloud.ibm.com\/docs\/vpc?topic=vpc-managing-user-permissions-for-vpc-resources), [Managing user access for Schematics](https:\/\/cloud.ibm.com\/docs\/schematics?topic=schematics-access), and [Assigning access to Secrets Manager](https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-assign-access).\n* How do I SSH among nodes?\n\nAll of the nodes in the HPC cluster have the same public key that you register at your cluster creation.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-806120-808288","score":11.97686,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-805993-808161","score":11.97686,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_11149-17131-19651","score":11.345722,"text":"\nStorage Products that support data to be created, read, updated, and deleted \n\n\n\nYou can also scope your view of the catalog by using the Provider filter to browse by individual providers and the Industry filter to view products catered for certain industries.\n\n\n\n\n\n\n\n Pricing and billing \n\nYou can view the pricing details for each service when you're browsing the catalog. If you choose a service plan with a paid plan, you can estimate your costs by using the cost estimator tool. For more information, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nIBM Cloud billing provides multiple services that ensure the IBM Cloud platform can securely manage pricing, accounts, usage, and more.\n\n\n\n Account management \n\nAccount management maintains the billing relationship with the customer. Each account is a billing entity that represents a customer. This service controls account lifecycle, subscription, user relationship, and organization.\n\n\n\n\n\n Usage metering \n\nWith usage metering, service providers can submit metrics that are collected for resource instances that are created by IBM Cloud users. Third-party service providers that deliver an integrated billing service are required to submit usage for all active service instances every hour.\n\n\n\n\n\n Usage reports \n\nUsage reports return the summary for the account for the specified month. Account billing managers are authorized to access the reports.\n\n\n\n\n\n\n\n Managing security and compliance \n\nThe IBM Cloud\u00ae Security and Compliance Center offers a single location where you can validate that your resources are meeting continuous security and compliance.\n\nYou can create profiles and config rules to ensure that specific areas of your business adhere to your defined requirements or industry regulations. From the Security and Compliance Center dashboard, you can download detailed reports that you can use to provide evidence to stakeholders or external auditors. The Security and Compliance Center also offers security insights that you can use to detect potential threats when observing your account activity. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n\n\n Creating resources \n\nThe resource controller is the next-generation IBM Cloud platform provisioning layer that manages the lifecycle of IBM Cloud resources in your account. Resources are created globally in an account scope.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatis-platform"},{"document_id":"ibmcld_11163-81224-83154","score":11.210694,"text":"\n: To help you decide and analyze what services you'd like to purchase, you can use the cost estimator. Now, you can go through the console and select each service you'd like to have, and add all of the costs in an easy to use tool. You can even enter projected data usages, lookups per second, writes per second, and queries per second to get a more accurate estimation of your monthly expenditures. You can use the cost estimator with each catalog service you select, or you can click the Cost Estimator icon ![Cost Estimator icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/adcecdbe4e86955f88aac7f3c1e7ec3ff44992ef\/overview\/icons\/calculator.svg) in the console menu to get a summary of your estimated costs. For more information, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\n\n\n\n\n 01 November 2018 \n\nUpdated global location names\n: As IBM Cloud continues to expand our global availability footprint, we\u2019re updating our location naming structure to better support an understandable, consistent hierarchy of geographies, regions, and data centers around the world. If you\u2019re familiar with our current global regions, you\u2019ll recognize names like US South and Sydney. We\u2019re aligning these location names to the names of the city in which the data centers physically exist.\n\nFor now, the programmatic IDs are not changing, so there\u2019s no impact from an API perspective. The following table shows the old and new location names. For more information and a comprehensive list of data centers and regions, see [Service availability](https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-services_region).\n\n\n\nTable 1. New location names\n\n Previous Location Display Name New Location Display Name Code \n\n US South Dallas us-south \n US East Washington DC us-east \n United Kingdom London eu-gb \n Germany Frankfurt eu-de \n Sydney Sydney au-syd \n AP North Tokyo jp-tok \n\n\n\n\n\n\n\n\n\n October 2018","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatsnew"}],"retriever_scores":{"recall_1":0.5,"recall_3":0.5,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.6131471928,"ndcg_cut_5":0.8772153153,"ndcg_cut_10":0.8772153153}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>3","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03798-0-2240","score":13.234056,"text":"\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http:\/\/ibm.com\/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https:\/\/cloud.ibm.com\/billing\/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https:\/\/cloud.ibm.com\/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-understand-invoices"},{"document_id":"ibmcld_03776-3313-5682","score":13.201839,"text":"\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03797-4528-6268","score":12.896283,"text":"\n[A view of the invoices page in the IBM Cloud console. This view displays new and one-time charges that reflect what you're charged.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/example-invoice-console.png)\n\nFigure 3. New and one-time charges in the console for the month of March.\n\nThe remaining infrastructure charges of $322,806.71 USD from the recurring invoice in the console and the new and one-time charges should add up to the total IaaS final invoice charge of $324,245.93 USD.\n\n\n\n\n\n Granular view of the line item charges \n\nNow that we confirmed that the final invoice totals match the recurring and new and one time charges in the console, let\u2019s find out what the charges on the final invoice represent.\n\nOn the Excel version of your recurring invoice that you downloaded in step 2, click the Detailed Billing tab. The Detailed Billing tab provides a breakdown of all of your infrastructure and platform charges. They represent three major types of usage:\n\n\n\n* In Advance (for example, the month of March) infrastructure monthly usage charges. These are recurring charges that you incur until you cancel the service. The charge is the same every month.\n\n\n\nZoom\n\n![An example of an advanced infrastructure monthly usage charges on the detailed invoice tab from the downloaded Excel invoice.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/advance-billing.png)\n\nFigure 4. In advance infrastructure monthly usage charges.\n\n\n\n* In Arrears (for example, the month of February) infrastructure hourly charges. These are usage-based charges from the previous month. Note the 672 hrs * .066 format of the charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"},{"document_id":"ibmcld_03797-3428-4809","score":12.495338,"text":"\n[Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/download.svg) to download the invoice directly to your device.\n5. Open the downloaded file, and click Summary tab.\n\n\n\nIn this example, the Platform Services charge matches the total on the PaaS final invoice from Figure 1: $5,566.81 USD. The remaining charges, which total $322,806.71 USD ($328,373.52 - $5566.81 = $322,806.71) represent the remaining infrastructure, nonplatform charges from this recurring invoice.\n\nZoom\n\n![An image of recurring console invoice](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/Recurring-invoice.png)\n\nFigure 2.IaaS recurring charges.\n\n\n\n\n\n Identify the new and one-time charges \n\nNext, you need to identify and find the sum of the new and one time charges. Your new and one-time charges are on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices) in the console. There are three new charges on the invoices page during this time period: A charge of $500.52, $767.10, and $171.60.\n\nZoom\n\n![A view of the invoices page in the IBM Cloud console. This view displays new and one-time charges that reflect what you're charged.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/example-invoice-console.png)\n\nFigure 3.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"},{"document_id":"ibmcld_03797-7-1811","score":11.914678,"text":"\nReconciling usage for nonsubscription multi-year account invoices \n\nAs an IBM Cloud\u00ae customer with a nonsubscription multi-year account, understanding the different invoices that are available to you can help you understand your monthly cost breakdown.\n\nFinal invoice\n: The finalized compilation of charges a user receives at the end of the month.\n: Includes new and one-time charges from the 20th of the prior month to the 19th of the current month. For the examples referenced in this document, the new and one-time charges are from 20 February to 20 March.\n: Includes the recurring charges from the recurring invoice in the IBM Cloud console.\n\nRecurring invoice\n: The recurring invoice is a system generated reference invoice that's located in the IBM Cloud console. The recurring invoice provides a line item breakdown of each recurring charge. This doesn't include every charge that appears on the final monthly invoice and is not the final invoice that you are charged for.\n\nIn this tutorial, you'll see a few invoice examples:\n\n\n\n* [Figure 1](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-reconcile-invoiceIaaS-PaaS): The Infrastructure as a Service (IaaS) and Platform as a Service (PaaS) invoice for March. This invoice is sent to the email associated with the account.\n* [Figure 2](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-reconcile-invoicerecurring-console-invoice): The March recurring invoice. You can find your recurring invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices).\n* [Figure 3](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-reconcile-invoicenew-charges): A view of the invoice tab in the console with the new and one-time charges from 20 February to 19 March.\n\n\n\n\n\n Step 1: Review the totals on the final invoice","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"},{"document_id":"ibmcld_03797-5893-7322","score":11.851579,"text":"\n(https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/advance-billing.png)\n\nFigure 4. In advance infrastructure monthly usage charges.\n\n\n\n* In Arrears (for example, the month of February) infrastructure hourly charges. These are usage-based charges from the previous month. Note the 672 hrs * .066 format of the charges. In arrears, infrastructure hourly charges are always in this format.\n\n\n\nZoom\n\n![An example of an arrears infrastructure hourly charge on the detailed invoice tab from the downloaded Excel invoice.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/arrears-hourly.png)\n\nFigure 5.In Arrears infrastructure hourly charges.\n\n\n\n* In arrears (for example, the month of January) platform service charges. These are usage-based charges from two months prior. They are labeled Platform service in column B and reference the month in which the usage was consumed.\n\n\n\nZoom\n\n![In arrears platform service charges.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/arrears-platform-service-charges.png)\n\nFigure 6. In arrears platform service charges for the month of January.\n\n\n\n\n\n Next steps \n\nTo continue your learning about your billing and usage, see [Managing payments](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage),","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"},{"document_id":"ibmcld_03729-7-2197","score":11.834941,"text":"\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03771-1594-3365","score":11.680212,"text":"\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices):\n\n\n\n* Invoiced: You received the latest invoice from IBM Cloud.\n* Paid: Your payment for the charges on your latest invoice was received.\n* Unpaid: The charges on your latest invoice have not been paid.\n* Pending: Your payment for your latest charges has not been applied due to a payment processing error. In this case, you can contact IBM Cloud Support for more details about the error.\n\n\n\nTurning a resource \"off\" doesn't cancel the resource in your account. You will receive invoices for resources in your account until you cancel them. For more information, see [Cancelling your billing items](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cancel-billing-items).\n\n\n\n\n\n Viewing and downloading your invoice \n\nView and download your invoice from the IBM console by clicking the Download icon ![Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/download.svg)> PDF invoice next to each invoice. For some accounts, invoices are available through the [Invoices@IBM](http:\/\/ibm.com\/invoices) website. See the [Viewing and downloading invoices for all other accounts](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_03800-3318-5483","score":11.678011,"text":"\nClick View plans to view all the instances of a specific type of resource.\n3. To view a detailed summary of estimated charges for each instance of a specific resource type, click View details. You can also view the detailed monthly usage metrics for the selected instance.\n\n\n\nIf you have a Pay-As-You-Go account that isn't billed in US dollars or a Subscription account, the usage for all services is finalized by the 20th of the following month. If you have a Pay-As-You-Go account that is billed in US dollars, the usage for all services is finalized by the 3rd of the following month.\n\nThe account is billed for the total usage that is incurred across all groups and organizations at the end of each billing cycle. Each billing cycle lasts one month.\n\nYou can filter the usage summary by group and select the time frame for usage. The charges that are shown represent the amount that is billed to the account for that particular month.\n\nIf you select a specific organization from the Filter by group list, you can see the total usage for that organization, including any usage as part of a free tier. The free tier usage is shown as free at the account level, but not at the organizational level. When you view the organizational usage, you see the real usage for that organization, which includes both free and charged usage. All organizational usage is rolled up to the account usage after the free tier is removed.\n\nThe account owner of a billable account can set spending notifications against the total cost of the account, for runtime, services, and for individual services, excluding third-party services. For more information, see [Setting spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending).\n\n\n\n\n\n\n\n Viewing your usage by using the API \n\nYou can programmatically view your usage by calling the [IBM Cloud Usage Reports API](https:\/\/cloud.ibm.com\/apidocs\/metering-reportingget-account-usage). You can base the query in your API call on an account, org, resource group, or resource instance.\n\nThe following examples show queries that you can use to view account level usage:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage"},{"document_id":"ibmcld_11408-13151-14243","score":11.440172,"text":"\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change. To calculate your pricing, use the [IBM cost estimator](https:\/\/cloud.ibm.com\/estimator) in IBM Cloud console.\n\n\n\n\n\n End of billing \n\nThe monthly billing cycle ends when you delete the LPAR. If you scale your infrastructure up and down in response to workload requirements, your billing follows the timing of the LPAR provision change. If you stop the LPAR, the billing process is not stopped. You must delete the LPAR to stop the billing cycle.\n\nYou are still charged if the VM is in a suspended state. When your VM is inactive, you can use Dynamic Logical Partitioning (DLPAR) to resize it to a minimal state. You can drastically decrease the price per hour by reducing the VM's core count and memory.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/power-iaas?topic=power-iaas-pricing-virtual-server"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.156426242}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>4","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03729-4932-7001","score":17.717505,"text":"\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges\n: You select a plan and pay on a flat rate basis. For example, the Bare Metal Servers are charged at a flat-rate.\n\nMetered charges\n: You pay based on your runtime and service consumption. For example, with the Push service, any usage over the free monthly allowance is charged.\n\nReserved charges\n: As the account owner of a Pay As You Go account or a Subscription account, you can reserve a service instance, with a long-term commitment, for a discounted price. For example, you can reserve the standard large Db2 on Cloud offering for 12 months.\n: Some IBM Cloud services offer reserved plans. You can request a reserved plan from the IBM Cloud catalog by clicking the tile of the service. Then, select the service plan that best meets your needs. If a reserved plan is available, click Request, and follow the prompts to send your request. You receive an email that contains the price information of the reserved plan. An IBM Cloud sales representative also contacts you soon to complete the purchase.\n\nTiered charges\n: Similar to metered charges, you pay based on your runtime and service consumption. However, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03776-5228-7163","score":17.316395,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03729-1672-3956","score":17.163887,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_03776-3313-5682","score":12.520214,"text":"\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03729-7-2197","score":12.372324,"text":"\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_04607-2714-3624","score":11.023827,"text":"\nA plan that offers a vGPU support for VSI reservation and charge based on the maximum number of virutal server (also known as Concurrent User) provisioned at any moment of the given month.\n\nThe total capacity offered is:\n\n\n\n* A vGPU VSI configuration: 4 vCPU, 16GB RAM, vGPU: 1GB GPU memory, 100GB Disk\n\n\n\nPricing (billed monthly)\n\n\n\n* Tier 1: $150\/concurrent VSI for the first 1-49 virutal servers\n* Tier 2: $142.50\/concurrent VSI for 50-99 virutal servers\n* Tier 3: $135.00\/concurrent VSI for 100-199 virutal servers\n* Tier 4: $127.50\/concurrent VSI for 200-499 virutal servers\n* Tier 5: $120\/concurrent VSI for 500-999 virutal servers\n* Tier 6: $117\/concurrent VSI for 1000-1,499 virutal servers\n* Tier 7: $112.50\/concurrent VSI for 1500-2,999 virutal servers\n* Tier 8: $105.00\/concurrent VSI for additional virutal servers passing 3,000\n\n\n\nAdditional Persistent Storage\n\n\n\n* $2 per 10 GB per user per month","title":"","source":"https:\/\/cloud.ibm.com\/docs\/cloud-for-education?topic=cloud-for-education-pricing"},{"document_id":"ibmcld_03729-6519-8345","score":11.014761,"text":"\nHowever, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items \n\n Tier 1: 1 - 1000 $1 USD \n Tier 2: 1001 - 2000 $0.90 USD \n Tier 3: 2001 - 3000 $0.75 USD \n Tier 4: 3001 - 4000 $0.60 USD \n Tier 5: > 4000 $0.40 USD \n\n\n\nThe following table illustrates how much you pay with a plan that is based on a simple tier pricing model:\n\n\n\nTable 3. Charge calculation by using the simple tier pricing model\n\n Quantity of Items Charge Calculation Total Price \n\n 500 500 \u00d7 1 = 500 $500 USD \n 1500 1500 \u00d7 0.90 = 1350 $1350 USD \n 2500 2500 \u00d7 0.75 = 1875 $1875 USD \n ... ... ... \n 5200 5200 \u00d7 0.40 = 2080 $2080 USD \n\n\n\n\n\n\n\n Graduated tier \n\nIn the graduated tier model, the unit price per tier decreases as your level of usage increases. The total price is the cumulative charges for each level of usage, consisting of your quantity multiplied by the unit price at that tier, for example:\n\n\n\nTable 4. Graduated tier pricing table\n\n Quantity of Items Unit Price for Items in the Tier \n\n Tier 1: 1 - 1000 $1 USD \n Tier 2: 1001 - 2000 $0.90 USD \n Tier 3: 2001 - 3000 $0.75 USD \n Tier 4: 3001 - 4000 $0.60 USD \n Tier 5: > 4000 $0.40 USD \n\n\n\nThe following table illustrates how much you pay with a plan that is based on a graduated tier pricing model:\n\n\n\nTable 5. Charge calculation by using the graduated tier pricing model\n\n Quantity of Items Charge Calculation Total Price \n\n 500 500 \u00d7 1 (unit price for Tier 1) = 500 $500 USD","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_14546-7-1993","score":11.003273,"text":"\nVMware Shared pricing \n\nIBM Cloud\u00ae for VMware Solutions Shared offers two pricing plans for creating VMware\u00ae virtual data centers. Virtual data centers incur charges for the following virtual data center resource usages:\n\n\n\n* Storage allocations with tiered pricing based on storage performance\n* Virtual CPU (vCPU) usage\n* Virtual memory usage\n* Egress on public networking\n* Commercial operating system licenses used\n* Third-party VMware services\n\n\n\n\n\nTable 1. Pricing plans\n\n Plans Description \n\n VMware Shared On-demand <br><br> * The vCPU and RAM virtual data center are allocated based on the demand. Resources are not preallocated. If you have a large regional demand, delays in availability can occur.<br> <br> <br> <br> <br> * The limits that are established for the amount of vCPU and RAM are maximums.<br> * vCPU and RAM resource limits can be increased and decreased later as required.<br> * The price is calculated hourly and it is based on the resource usage in the virtual data center.<br> * The amount of storage that can be allocated and used in the virtual data center is unlimited. Charges are hourly based on GB of allocated storage.<br> * The amount of inbound and outbound public networking is unlimited. Public outbound bandwidth is charged per GB.<br> <br> <br> <br> <br><br><br> \n VMware Shared Reserved <br><br> * The vCPU and RAM virtual data center reservations are pre-allocated and their availability is guaranteed.<br> <br> <br> <br> <br> * vCPU and RAM resources can be increased and decreased later as required.<br> * The amount of storage that can be allocated and used in the virtual data center is unlimited. Charges are hourly based on GB of allocated storage.<br> * The amount of inbound and outbound public networking is unlimited. Public outbound bandwidth is charged per GB.<br> <br> <br> <br> <br><br><br> \n\n\n\n\n\n Price breakdown \n\n\n\n Usage \n\nMetering is for the full potential size of the resource for the time period that the resource is used.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_14546-1313-3289","score":10.924916,"text":"\nVMware Shared Reserved <br><br> * The vCPU and RAM virtual data center reservations are pre-allocated and their availability is guaranteed.<br> <br> <br> <br> <br> * vCPU and RAM resources can be increased and decreased later as required.<br> * The amount of storage that can be allocated and used in the virtual data center is unlimited. Charges are hourly based on GB of allocated storage.<br> * The amount of inbound and outbound public networking is unlimited. Public outbound bandwidth is charged per GB.<br> <br> <br> <br> <br><br><br> \n\n\n\n\n\n Price breakdown \n\n\n\n Usage \n\nMetering is for the full potential size of the resource for the time period that the resource is used.\n\nFor example, a single-zone on-demand virtual data center is created with a resource limit of 100 vCPU and 800 GB RAM. The data center has no VMs running on it, so you do not receive a charge for the vCPU and RAM. If an 8 vCPU with 8 GB virtual machine (VM) is started, metering is calculated for the size of that VM. If the VM uses fewer resources than the ones assigned to it, metering is applicable to the full size of the VM.\n\n\n\n\n\n Allocation \n\nMetering is applicable to the full potential size of the resource for the life of the resource.\n\nFor example, a single zone reserved virtual data center is created with a resource allocation of 100 vCPU and 800 GB RAM and no VMs are created or running on it. Metering is applicable to 100 vCPU and 800 GB RAM.\n\n\n\n\n\n Monthly peak metric usage \n\nThe maximum value of the metric used over a full month.\n\nFor example, a single zone reserved virtual data center is created with 100 vCPU and 800 GB RAM. Later in the month, the data center is reduced to 50 vCPU and 400 GB RAM. The monthly peak usage is 100 vCPU and 800 GB RAM.\n\n\n\n\n\n Hourly peak metric usage \n\nThe maximum value of the metric used over an hour. For example, if 100 vCPU is used for a minute of the hour with 0 vCPU used for the other 59 mins, the hourly peak metric usage is 100 vCPU.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/vmwaresolutions?topic=vmwaresolutions-shared_pricing"},{"document_id":"ibmcld_12837-8834-10242","score":10.749674,"text":"\nBlock tier (up to) The total amount that is charged is established by an up to quantity that doesn't vary within the block If Q is <=Q1, T=T1<br><br>If Q1 < Q <=Q2, T=T2<br><br>If Q2 < Q <=Q3, T=T3 Q1=1000, T1=$0<br><br>Q2=2500, T2=2500<br><br>Q3=10000, T3=$4500<br><br>T=$4500 \n\n\n\nBlock tier pricing is not currently supported. If your product migrated from the resource management console, and you used block tier pricing, it is still honored. However, you can't add any new block tier pricing plans at this time.\n\n\n\n\n\n Metrics for metering models \n\nIf you created your service with Partner Center, you can choose from the following metrics and default metering models:\n\n\n\nTable 9. Partner Center metering model metrics\n\n Type Metric \n\n dailyproration_max Active User \n standard-add API call \n dailyproration_max Authorized User \n standard_add Gigabyte hour \n standard_add Gigabyte month \n monthlyproration Instance \n standard_add Terabyte hour \n standard_add Terabyte month \n dailyproration_max User \n standard_add Virtual Server \n standard_add Virtual Server Hour \n standard_add Virtual Processor Core \n\n\n\nThird-party providers that migrated from the resource management console to Partner Center can manage their metering models with Partner Center. Any information that you added or edited for pricing plans and metering models by using the resource management console can be updated in Partner Center.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-metering-integration"}],"retriever_scores":{"recall_1":0.3333333333,"recall_3":0.6666666667,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":0.703918089,"ndcg_cut_5":0.8854598816,"ndcg_cut_10":0.8854598816}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>5","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03776-5228-7163","score":15.835148,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_11149-17131-19651","score":15.296961,"text":"\nStorage Products that support data to be created, read, updated, and deleted \n\n\n\nYou can also scope your view of the catalog by using the Provider filter to browse by individual providers and the Industry filter to view products catered for certain industries.\n\n\n\n\n\n\n\n Pricing and billing \n\nYou can view the pricing details for each service when you're browsing the catalog. If you choose a service plan with a paid plan, you can estimate your costs by using the cost estimator tool. For more information, see [Estimating your costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost).\n\nIBM Cloud billing provides multiple services that ensure the IBM Cloud platform can securely manage pricing, accounts, usage, and more.\n\n\n\n Account management \n\nAccount management maintains the billing relationship with the customer. Each account is a billing entity that represents a customer. This service controls account lifecycle, subscription, user relationship, and organization.\n\n\n\n\n\n Usage metering \n\nWith usage metering, service providers can submit metrics that are collected for resource instances that are created by IBM Cloud users. Third-party service providers that deliver an integrated billing service are required to submit usage for all active service instances every hour.\n\n\n\n\n\n Usage reports \n\nUsage reports return the summary for the account for the specified month. Account billing managers are authorized to access the reports.\n\n\n\n\n\n\n\n Managing security and compliance \n\nThe IBM Cloud\u00ae Security and Compliance Center offers a single location where you can validate that your resources are meeting continuous security and compliance.\n\nYou can create profiles and config rules to ensure that specific areas of your business adhere to your defined requirements or industry regulations. From the Security and Compliance Center dashboard, you can download detailed reports that you can use to provide evidence to stakeholders or external auditors. The Security and Compliance Center also offers security insights that you can use to detect potential threats when observing your account activity. For more information, see [Getting started with Security and Compliance Center](https:\/\/cloud.ibm.com\/docs\/security-compliance?topic=security-compliance-getting-started).\n\n\n\n\n\n Creating resources \n\nThe resource controller is the next-generation IBM Cloud platform provisioning layer that manages the lifecycle of IBM Cloud resources in your account. Resources are created globally in an account scope.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/overview?topic=overview-whatis-platform"},{"document_id":"ibmcld_03735-1425-3233","score":15.011299,"text":"\nEnter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1. Click Save and select the estimate that you'd like to add the product to, and then add the calculated cost to your estimate by clicking Save.\n2. When you're done adding products to your estimate, review the product details, and click View estimate.\n\n\n\n\n\n\n\n Updating an existing estimate \n\nYou can always update the name and description of an estimate as your needs change. To edit an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to edit.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Edit.\n3. Enter the updated name and description.\n4. Click Save\n\n\n\n\n\n\n\n Saving and sharing your estimate \n\nWhen you create an estimate, you can save each estimate's unique link to share or revisit directly through your browser. To share an estimate, complete the following steps:\n\n\n\n1. From the View Estimate page, identify the estimate that you want to share.\n2. Click the Actions icon ![Actions icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/action-menu-icon.svg) > Share.\n3. Click Copy link and share the link with users in your account.\n\n\n\n\n\n\n\n Creating quotes for classic infrastructure services","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost"},{"document_id":"ibmcld_12407-4383-5026","score":14.422407,"text":"\nTo update your service plan after you create an instance, see [Updating your service plan](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-changing).\n\n\n\n\n\n Upgrading a Secrets Manager instance to the Standard plan \n\nWhen your Trial instance expires, you lose access to your secrets, and integrations. To preserve your data, and prevent any disruptions in your workflow, you must upgrade to the Standard plan before your Trial plan expires. Follow the steps to [update your pricing plan](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-changing&interface=ui). You can use the UI, API, and CLI to complete this process.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secrets-manager?topic=secrets-manager-create-instance&interface=ui"},{"document_id":"ibmcld_07578-806120-808288","score":14.416858,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-805993-808161","score":14.416858,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03800-5111-6803","score":14.377305,"text":"\nYou can programmatically view your usage by calling the [IBM Cloud Usage Reports API](https:\/\/cloud.ibm.com\/apidocs\/metering-reportingget-account-usage). You can base the query in your API call on an account, org, resource group, or resource instance.\n\nThe following examples show queries that you can use to view account level usage:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X GET -H \"Authorization: {iam_token}\" -H \"Accept: application\/json\" \"{base_url}\/v4\/accounts\/{account_id}\/usage\/{billingmonth}\"\n\nServiceCall<AccountUsage> getAccountUsage(GetAccountUsageOptions getAccountUsageOptions)\n\nget_account_usage(self,\naccount_id: str,\nbillingmonth: str,\n,\nnames: bool = None,\naccept_language: str = None,\nkwargs\n) -> DetailedResponse\n\n(usageReports UsageReportsV4) GetAccountUsage(getAccountUsageOptions GetAccountUsageOptions) (result AccountUsage, response core.DetailedResponse, err error)\n\ngetAccountUsage(params)\n\n\n\n\n\n Exporting your usage details to a .csv file \n\nYou can export a summary of your account's usage, or information about your services and instances, to a CSV file. By exporting your CSV file, you can easily find usage and cost information estimates for each resource for chargebacks to your customers or to understand more about your costs. Because the report includes usage data for the entire account, you need Administrator access on the Billing service to export usage details.\n\nThis is not an estimate of your final bill. Instance costs don\u2019t reflect your final bill because other charges or discounts might be applied to your account.\n\n\n\n1. In the console, go to Manage > Billing and usage, and select Usage.\n2. Click Export CSV and select one of the options:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage"},{"document_id":"ibmcld_12815-6899-9236","score":14.319374,"text":"\nNow that you\u2019ve defined your pricing model, review how customers would understand and experience it. After your metering updates are approved, validate that your metered plans are correctly configured by enabling and submitting a usage test. This usage test includes creating your metering JSON, calling the Usage Metering API, and submitting metering evidence. [Click Add metrics for the pricing plan you added. Click Test estimation and metering to submit your metering evidence for review.]\n\nThe next step is to add features that uniquely identify your product\u2019s attributes and differentiate this pricing plan from others. [Click Add feature to add more information about your pricing plan.]\n\nCheck your progress in the Onboarding checklist to make sure you\u2019ve completed all the required tasks. At this point, you\u2019re ready to submit your product for publishing approval. Submitting your request automatically notifies our onboarding team. The team will review the product details you provided to approve it for publishing, or they might request additional updates. [Click the name of your service in the breadcrumb menu, and click Checklist to open the Onboarding checklist. Click Request approval to request publishing approval for your product.]\n\nYou'll get an email with details about any changes that you might need to make.\n\nAfter your product is approved, return to Partner Center and publish it to the IBM Cloud catalog. Congratulations, your service is now ready and available to all users in the IBM Cloud catalog! [Click Publish to publish your service after you receive approval to do so.]\n\n\n\n\n\n\n\n Before you begin \n\nTo onboard your services to the IBM Cloud platform, you must be an approved IBM Cloud build partner. You can expand your network by receiving access to IBM\u2019s global ecosystem, receive insights to better engage customers, grow your business, and increase revenue. For more information on being an IBM Cloud build partner, see the [IBM Build Partner](https:\/\/www.ibm.com\/partnerworld\/public\/build) page.\n\nBesides being an IBM Cloud build partner, service onboarding is limited to providers who meet the following prerequisites due to current processing times:\n\n\n\n* Providers who leverage one or more services in the IBM Cloud catalog.\n* Providers who intend on selling their product in the IBM Cloud catalog.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-get-started"},{"document_id":"ibmcld_03800-3318-5483","score":14.305471,"text":"\nClick View plans to view all the instances of a specific type of resource.\n3. To view a detailed summary of estimated charges for each instance of a specific resource type, click View details. You can also view the detailed monthly usage metrics for the selected instance.\n\n\n\nIf you have a Pay-As-You-Go account that isn't billed in US dollars or a Subscription account, the usage for all services is finalized by the 20th of the following month. If you have a Pay-As-You-Go account that is billed in US dollars, the usage for all services is finalized by the 3rd of the following month.\n\nThe account is billed for the total usage that is incurred across all groups and organizations at the end of each billing cycle. Each billing cycle lasts one month.\n\nYou can filter the usage summary by group and select the time frame for usage. The charges that are shown represent the amount that is billed to the account for that particular month.\n\nIf you select a specific organization from the Filter by group list, you can see the total usage for that organization, including any usage as part of a free tier. The free tier usage is shown as free at the account level, but not at the organizational level. When you view the organizational usage, you see the real usage for that organization, which includes both free and charged usage. All organizational usage is rolled up to the account usage after the free tier is removed.\n\nThe account owner of a billable account can set spending notifications against the total cost of the account, for runtime, services, and for individual services, excluding third-party services. For more information, see [Setting spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending).\n\n\n\n\n\n\n\n Viewing your usage by using the API \n\nYou can programmatically view your usage by calling the [IBM Cloud Usage Reports API](https:\/\/cloud.ibm.com\/apidocs\/metering-reportingget-account-usage). You can base the query in your API call on an account, org, resource group, or resource instance.\n\nThe following examples show queries that you can use to view account level usage:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage"},{"document_id":"ibmcld_12837-7-2080","score":14.286487,"text":"\nMetering integration \n\nIBM Cloud\u00ae supports multiple models for aggregating product usage, and with Partner Center, you can measure various metrics for services with usage-based pricing plans. You can measure metrics on the created instances, and submit those measures to the metering service. The submitted usage is aggregated into different buckets (instance, resource group, and account) based on the model that you choose. The aggregation and rating models for all metrics in a plan are contained in the metering and rating definition documents for the plan.\n\nThe following list describes the expectations for tracking and submitting usage:\n\n\n\n* Third-party providers don't need to submit usage for free plans or monthly subscription plans.\n* For metered plans, all providers must submit usage hourly, and usage for Lite plans must submitted every 15 minutes to 1 hour.\n* You're responsible for automating the usage submission, including automation that retries failure responses. To automate the usage submission, you can create cron jobs, or other similar job schedulers. IBM Cloud doesn't provide a retry function for failed submissions. For more information, see the status codes and actions table in [Submitting usage records](https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-submitusageusage-records).\n\n\n\nZoom\n\n![A diagram that shows third-party providers how the IBM Cloud Usage Metering service works when they create a cron job, or other similar job scheduler to automate usage submission.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/ff5860bfede49db3197c4bbba7f7123769bdc068\/sell\/images\/Usage_metering_role.svg)\n\nFigure 1. Understanding the function of the IBM Cloud Usage Metering service for automating the submission of usage data.\n\n\n\n* You must submit usage records for the current month by the second day of the following month.\n* IBM Cloud is configured for a monthly billing cycle and time is represented in Coordinated Universal Time (UTC).\n* You must test usage submission and validate your results to describe how the monthly billing cycle is calculated.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-metering-integration"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>6","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03729-7-2197","score":16.07405,"text":"\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_07578-806120-808288","score":15.379462,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-805993-808161","score":15.379462,"text":"\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16727-807613-809619","score":15.284464,"text":"\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n* In terms of cost, what do I pay for?\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n* Can I change billing options after my direct link is provisioned?\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-807740-809746","score":15.284464,"text":"\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n* In terms of cost, what do I pay for?\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n* Can I change billing options after my direct link is provisioned?\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03776-3313-5682","score":15.102665,"text":"\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_07289-1587-3853","score":15.058157,"text":"\nFor example, log in to the [IBM Cloud Direct Link console](https:\/\/cloud.ibm.com\/interconnectivity\/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n\n\n\n\n What is planned for Direct Link on Classic Exchange? \n\nThe marketplace has evolved since Direct Link Exchange was established. With data center operators now blurring the lines as network service providers, IBM will be combining the Exchange offering with Connect on the new \"next generation\" platform to reflect both this change and simplify the Direct Link portfolio. Direct Link Exchange will service only the Direct Link classic infrastructure.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/dl?topic=dl-faqs"},{"document_id":"ibmcld_03729-4932-7001","score":14.759848,"text":"\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges\n: You select a plan and pay on a flat rate basis. For example, the Bare Metal Servers are charged at a flat-rate.\n\nMetered charges\n: You pay based on your runtime and service consumption. For example, with the Push service, any usage over the free monthly allowance is charged.\n\nReserved charges\n: As the account owner of a Pay As You Go account or a Subscription account, you can reserve a service instance, with a long-term commitment, for a discounted price. For example, you can reserve the standard large Db2 on Cloud offering for 12 months.\n: Some IBM Cloud services offer reserved plans. You can request a reserved plan from the IBM Cloud catalog by clicking the tile of the service. Then, select the service plan that best meets your needs. If a reserved plan is available, click Request, and follow the prompts to send your request. You receive an email that contains the price information of the reserved plan. An IBM Cloud sales representative also contacts you soon to complete the purchase.\n\nTiered charges\n: Similar to metered charges, you pay based on your runtime and service consumption. However, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"},{"document_id":"ibmcld_12837-8247-9383","score":14.611545,"text":"\nIf Q is <=Q1, T=P1 * Q<br><br>If Q1 < Q <=Q2, T=P2 * Q<br><br>If Q2 < Q <=Q3, T=P3 * Q Q1=1000, P1=$1<br><br>Q2=2500, P2=$0.9<br><br>Q3=10000, P3=$0.75<br><br>T=$0.75 * 5000=$3750 \n Graduated tier (step tier) The price per unit varies as the quantity-consumed moves into different predefined tiers. The total charge involves cumulating the charges from the previous tiers T1=P1 * Q (0 < Q<br><br>If Q1 < Q <=Q2, T=T2<br><br>If Q2 < Q <=Q3, T=T3 Q1=1000, P1=$1, T1=1 * 1000<br><br>Q2=1500, P2=$0.9, T2=0.9 * 1500<br><br>Q3=10000, P3=$0.75, T3=0.75 * 2500<br><br>T=1000 +1350+1875=$4225 \n Block tier (up to) The total amount that is charged is established by an up to quantity that doesn't vary within the block If Q is <=Q1, T=T1<br><br>If Q1 < Q <=Q2, T=T2<br><br>If Q2 < Q <=Q3, T=T3 Q1=1000, T1=$0<br><br>Q2=2500, T2=2500<br><br>Q3=10000, T3=$4500<br><br>T=$4500 \n\n\n\nBlock tier pricing is not currently supported. If your product migrated from the resource management console, and you used block tier pricing, it is still honored. However, you can't add any new block tier pricing plans at this time.\n\n\n\n\n\n Metrics for metering models","title":"","source":"https:\/\/cloud.ibm.com\/docs\/sell?topic=sell-service-metering-integration"},{"document_id":"ibmcld_03729-1672-3956","score":14.062949,"text":"\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-charges"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>7","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03776-5228-7163","score":12.984733,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03776-6753-8705","score":12.72025,"text":"\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\nFor more information about how to manage your payments, see [Managing your payment method](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusageprereqs-payments).\n\n\n\n\n\n Tracking your usage \n\nTo view usage data for resources, you must be assigned the correct access. Access can be assigned at the account level or to individual resource groups and Cloud Foundry orgs.\n\n\n\n* To view usage for all resources in the account, you need an access policy with the Administrator role on the Billing account management service.\n* To view usage only for specific IBM Cloud Identity and Access Management (IAM) resources, you need the Viewer role or higher on the resource group.\n* To view usage for only specific Cloud Foundry services, the Billing manager role must be applied at the org level. Billing managers can see the details for only the organizations in which they are assigned the Billing manager role.\n\n\n\nYou can limit the access to view the usage for a specific resource group by assigning the viewer role or higher on all Identity and Access enabled services within that resource group.\n\n\n\n\n\n Managing your invoices \n\nIf you have a Pay-As-You-Go account that's billed in US dollars, you can view your invoice in the IBM Cloud console by going to Manage > Billing and usage, > and clicking Invoices.\n\nIf you own one of the following accounts, you can view your invoice on the [IBM Invoices](http:\/\/ibm.com\/invoices) website, which is linked from the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices) in the console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03765-7-1896","score":12.49669,"text":"\nManaging payments \n\nDepending on your account type, you can easily manage your payment methods by using the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud\u00ae console or by going to [IBM\u00ae Billing](https:\/\/myibm.ibm.com\/billing\/).\n\nA valid credit card is required for all Pay-As-You-Go and Subscription accounts. Every month, the credit card is charged with the usage amount that is accumulated during that month. When updates to your payment details are approved, they are applied to your account within 24 hours. The contact that is specified in the billing address section receives an email confirming that the updates are applied.\n\nYou can contact IBM Cloud Support to get help with payment-related issues. From the console menu bar, click the Help icon ![Help icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/help.svg) > Support center, and then click Create a case to get in touch.\n\n\n\n Before you begin \n\nTo manage payments, you need to be assigned the operator role or higher on the billing account management service. See [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services) for more information.\n\n\n\n\n\n Managing payment methods for new US-based Pay-As-You-Go accounts with credit card billing \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, can you add multiple cards to the account, replace your default card with a saved one, or edit the details of a card. You manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nComplete the following steps to add a new payment method to the account:\n\n\n\n1. Click Add payment method.\n2. Enter the card details, and click Save. Updates to your card details are reflected immediately.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_03765-5710-7263","score":12.001259,"text":"\nClick Manual Payment and complete the fields in the one-time payment section. One-time payments are reviewed and processed each day. The account balance is updated after the payment is accepted. If a late fee is assessed and you have submitted a one-time payment, contact the [IBM Cloud Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n\n\n Managing your payment method outside of the console \n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/) and log in with your IBMid and password. You are also required to enter the temporary passcode that's emailed to you.\n\nTo add a payment method, complete the following steps:\n\n\n\n1. Go to [ibm.com](http:\/\/www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your payment information, and click Register. A temporary passcode is emailed to you after the registration process is complete.\n\n\n\nAfter you register a payment method, when you click Manage payment method, you can view the Manage my wallet page to update or delete your payment methods by clicking the Edit icon ![Edit icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/edit-tagging.svg).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusage"},{"document_id":"ibmcld_07578-1045891-1047755","score":11.431464,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1045762-1047626","score":11.431464,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03704-4411-6289","score":11.29824,"text":"\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https:\/\/cloud.ibm.com\/unifiedsupport\/cases) page in the IBM Cloud console to view the status of your request.\n\n\n\n\n\n Can I delete my credit card? \n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_03704-5798-7955","score":11.209998,"text":"\nFor more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.\n\nAn account that is invoiced in a currency other than US Dollars can't be converted to US Dollar invoicing.\n\n\n\n\n\n What is Business Continuity Insurance? \n\nBusiness Continuity Insurance is insurance that protects you from illegitimate charges against your servers. You can request this insurance through [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) to avoid overage charges if a documented network attack occurs against a covered server. IBM Cloud credits back any overages incurred on the affected server.\n\nTo receive the credits for illegitimate charges against your servers, contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and open a support case.\n\n\n\n\n\n What is the Service: Support and Services charge on my invoice? \n\nIf you create a VMWare cluster on your IBM Cloud account, you are charged for VMWare Level 2 Support for each cluster instance. This charge is in addition to any IBM Cloud Support charges for Premium or Advanced Support.\n\n\n\n\n\n What's the difference between promo codes and feature codes? \n\nPromo codes are for Pay-As-You-Go and Subscription accounts and give you limited-time credits toward your account and IBM Cloud products. The codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1047268-1049406","score":11.209689,"text":"\nFor more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.\n\nAn account that is invoiced in a currency other than US Dollars can't be converted to US Dollar invoicing.\n* What is Business Continuity Insurance?\n\nBusiness Continuity Insurance is insurance that protects you from illegitimate charges against your servers. You can request this insurance through [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) to avoid overage charges if a documented network attack occurs against a covered server. IBM Cloud credits back any overages incurred on the affected server.\n\nTo receive the credits for illegitimate charges against your servers, contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and open a support case.\n* What is the Service: Support and Services charge on my invoice?\n\nIf you create a VMWare cluster on your IBM Cloud account, you are charged for VMWare Level 2 Support for each cluster instance. This charge is in addition to any IBM Cloud Support charges for Premium or Advanced Support.\n* What's the difference between promo codes and feature codes?\n\nPromo codes are for Pay-As-You-Go and Subscription accounts and give you limited-time credits toward your account and IBM Cloud products. The codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1047139-1049277","score":11.209689,"text":"\nFor more information, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) for more information.\n\nAn account that is invoiced in a currency other than US Dollars can't be converted to US Dollar invoicing.\n* What is Business Continuity Insurance?\n\nBusiness Continuity Insurance is insurance that protects you from illegitimate charges against your servers. You can request this insurance through [IBM Cloud Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) to avoid overage charges if a documented network attack occurs against a covered server. IBM Cloud credits back any overages incurred on the affected server.\n\nTo receive the credits for illegitimate charges against your servers, contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and open a support case.\n* What is the Service: Support and Services charge on my invoice?\n\nIf you create a VMWare cluster on your IBM Cloud account, you are charged for VMWare Level 2 Support for each cluster instance. This charge is in addition to any IBM Cloud Support charges for Premium or Advanced Support.\n* What's the difference between promo codes and feature codes?\n\nPromo codes are for Pay-As-You-Go and Subscription accounts and give you limited-time credits toward your account and IBM Cloud products. The codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.3333333333,"recall_5":0.3333333333,"recall_10":0.3333333333,"ndcg_cut_1":0.0,"ndcg_cut_3":0.234639363,"ndcg_cut_5":0.234639363,"ndcg_cut_10":0.234639363}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>8","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03771-1594-3365","score":16.686527,"text":"\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices):\n\n\n\n* Invoiced: You received the latest invoice from IBM Cloud.\n* Paid: Your payment for the charges on your latest invoice was received.\n* Unpaid: The charges on your latest invoice have not been paid.\n* Pending: Your payment for your latest charges has not been applied due to a payment processing error. In this case, you can contact IBM Cloud Support for more details about the error.\n\n\n\nTurning a resource \"off\" doesn't cancel the resource in your account. You will receive invoices for resources in your account until you cancel them. For more information, see [Cancelling your billing items](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cancel-billing-items).\n\n\n\n\n\n Viewing and downloading your invoice \n\nView and download your invoice from the IBM console by clicking the Download icon ![Download icon](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/icons\/download.svg)> PDF invoice next to each invoice. For some accounts, invoices are available through the [Invoices@IBM](http:\/\/ibm.com\/invoices) website. See the [Viewing and downloading invoices for all other accounts](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_03771-7-2029","score":15.390113,"text":"\nViewing your invoices \n\nTo manage and view your invoices, visit the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console. If your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices.\n\nIn these situations, visit the [Invoices@IBM](http:\/\/ibm.com\/invoices) website to see your invoices.\n\n\n\n Before you begin \n\nTo view your invoices, you need to be assigned the operator role or higher on the billing account management service. For more information, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n\n\n\n\n\n Viewing invoices for new US-based Pay-As-You-Go accounts with credit card billing \n\nNew IBM Cloud Pay-As-You-Go accounts for US customers with credit card billing can now view all classic infrastructure and platform services on one invoice. In the IBM Cloud console, go to Manage > Billing and usage, and select Invoices.\n\nThe new invoice hierarchy highlights the most important details. By showcasing when the usage is measured, you can view each invoice\u2019s billing period in a clarified and comprehensive manner. The adjustments section on your invoice provides details about credits and adjustments from previous billing periods that might be included on an invoice from a different month.\n\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices):","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices"},{"document_id":"ibmcld_03800-5111-6803","score":14.843282,"text":"\nYou can programmatically view your usage by calling the [IBM Cloud Usage Reports API](https:\/\/cloud.ibm.com\/apidocs\/metering-reportingget-account-usage). You can base the query in your API call on an account, org, resource group, or resource instance.\n\nThe following examples show queries that you can use to view account level usage:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X GET -H \"Authorization: {iam_token}\" -H \"Accept: application\/json\" \"{base_url}\/v4\/accounts\/{account_id}\/usage\/{billingmonth}\"\n\nServiceCall<AccountUsage> getAccountUsage(GetAccountUsageOptions getAccountUsageOptions)\n\nget_account_usage(self,\naccount_id: str,\nbillingmonth: str,\n,\nnames: bool = None,\naccept_language: str = None,\nkwargs\n) -> DetailedResponse\n\n(usageReports UsageReportsV4) GetAccountUsage(getAccountUsageOptions GetAccountUsageOptions) (result AccountUsage, response core.DetailedResponse, err error)\n\ngetAccountUsage(params)\n\n\n\n\n\n Exporting your usage details to a .csv file \n\nYou can export a summary of your account's usage, or information about your services and instances, to a CSV file. By exporting your CSV file, you can easily find usage and cost information estimates for each resource for chargebacks to your customers or to understand more about your costs. Because the report includes usage data for the entire account, you need Administrator access on the Billing service to export usage details.\n\nThis is not an estimate of your final bill. Instance costs don\u2019t reflect your final bill because other charges or discounts might be applied to your account.\n\n\n\n1. In the console, go to Manage > Billing and usage, and select Usage.\n2. Click Export CSV and select one of the options:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage"},{"document_id":"ibmcld_03800-3318-5483","score":14.19712,"text":"\nClick View plans to view all the instances of a specific type of resource.\n3. To view a detailed summary of estimated charges for each instance of a specific resource type, click View details. You can also view the detailed monthly usage metrics for the selected instance.\n\n\n\nIf you have a Pay-As-You-Go account that isn't billed in US dollars or a Subscription account, the usage for all services is finalized by the 20th of the following month. If you have a Pay-As-You-Go account that is billed in US dollars, the usage for all services is finalized by the 3rd of the following month.\n\nThe account is billed for the total usage that is incurred across all groups and organizations at the end of each billing cycle. Each billing cycle lasts one month.\n\nYou can filter the usage summary by group and select the time frame for usage. The charges that are shown represent the amount that is billed to the account for that particular month.\n\nIf you select a specific organization from the Filter by group list, you can see the total usage for that organization, including any usage as part of a free tier. The free tier usage is shown as free at the account level, but not at the organizational level. When you view the organizational usage, you see the real usage for that organization, which includes both free and charged usage. All organizational usage is rolled up to the account usage after the free tier is removed.\n\nThe account owner of a billable account can set spending notifications against the total cost of the account, for runtime, services, and for individual services, excluding third-party services. For more information, see [Setting spending notifications](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-spending).\n\n\n\n\n\n\n\n Viewing your usage by using the API \n\nYou can programmatically view your usage by calling the [IBM Cloud Usage Reports API](https:\/\/cloud.ibm.com\/apidocs\/metering-reportingget-account-usage). You can base the query in your API call on an account, org, resource group, or resource instance.\n\nThe following examples show queries that you can use to view account level usage:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage"},{"document_id":"ibmcld_03798-0-2240","score":14.13236,"text":"\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http:\/\/ibm.com\/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https:\/\/cloud.ibm.com\/billing\/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https:\/\/cloud.ibm.com\/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-understand-invoices"},{"document_id":"ibmcld_12544-10042-12276","score":14.0843935,"text":"\nYou can view usage from the Usage page in the console, from the CLI, or from the Enterprise Usage Reports API. For more information, see [Viewing usage in an enterprise](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Invoicing and payments \n\nUsage in the enterprise is invoiced through the enterprise account. As with all billable accounts, usage is invoiced monthly, and the invoice is due on the billing date for your account. During each billing cycle, a single invoice with the usage costs from all accounts is made available in the enterprise account. The invoice contains costs for all platform and infrastructure usage as a single-line item in your invoice. If all of the credit in the credit pool is used, the invoice contains a line item for any overage charges.\n\nBecause all usage is invoiced through the enterprise account, child accounts within the enterprise don't receive separate invoices.\n\nYou can analyze usage costs for each account or account group on the Usage page in the enterprise account. For details, see [Viewing usage in an enterprise](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Access management for enterprise billing and usage \n\nAs with other enterprise management roles, access to enterprise billing and usage is managed through the enterprise account. Users must be invited to the enterprise account and assigned an access policy with a role on the relevant service.\n\nIn an enterprise, billing access and usage access are assigned separately.\n\n\n\n* Billing access is provided by assigning enterprise users a role on the Billing account management service. For example, you can assign the Viewer role to an enterprise user so that they can view the amount of available subscription credit in the credit pool. If you would like an enterprise user to be able to add new subscriptions or manage payment methods, you can assign the Editor or Administrator role to them.\n* Usage access is provided by assigning enterprise users the Usage Reports Viewer, Editor, or Administrator role on the Enterprise account management service. You can assign this access for the entire enterprise or for specific account groups and accounts.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/secure-enterprise?topic=secure-enterprise-enterprise"},{"document_id":"ibmcld_03797-4528-6268","score":14.02288,"text":"\n[A view of the invoices page in the IBM Cloud console. This view displays new and one-time charges that reflect what you're charged.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/example-invoice-console.png)\n\nFigure 3. New and one-time charges in the console for the month of March.\n\nThe remaining infrastructure charges of $322,806.71 USD from the recurring invoice in the console and the new and one-time charges should add up to the total IaaS final invoice charge of $324,245.93 USD.\n\n\n\n\n\n Granular view of the line item charges \n\nNow that we confirmed that the final invoice totals match the recurring and new and one time charges in the console, let\u2019s find out what the charges on the final invoice represent.\n\nOn the Excel version of your recurring invoice that you downloaded in step 2, click the Detailed Billing tab. The Detailed Billing tab provides a breakdown of all of your infrastructure and platform charges. They represent three major types of usage:\n\n\n\n* In Advance (for example, the month of March) infrastructure monthly usage charges. These are recurring charges that you incur until you cancel the service. The charge is the same every month.\n\n\n\nZoom\n\n![An example of an advanced infrastructure monthly usage charges on the detailed invoice tab from the downloaded Excel invoice.](https:\/\/cloud.ibm.com\/docs-content\/v1\/content\/9713d864488177dc6b273b53b7f2383a81f10bc1\/billing-usage\/images\/advance-billing.png)\n\nFigure 4. In advance infrastructure monthly usage charges.\n\n\n\n* In Arrears (for example, the month of February) infrastructure hourly charges. These are usage-based charges from the previous month. Note the 672 hrs * .066 format of the charges.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-tutorial-reconcile-invoice"},{"document_id":"ibmcld_16727-1068047-1069909","score":13.795067,"text":"\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1062822-1064465","score":13.606086,"text":"\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https:\/\/www.ibm.com\/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-managing-invoices) for more information.\n* Why does my usage not match my invoice?\n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-viewingusage). If it still doesn't match, get in touch with us by calling 1-866-325-0045 and choosing the third option, or by opening a [support case](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n* Why can't I manage my invoices?\n\nYou might not have the correct permissions. Ask your account owner to add you to the View account summary access group. For more information, see [Managing migrated SoftLayer account permissions](https:\/\/cloud.ibm.com\/docs\/account?topic=account-migrated_permissions).\n* How can I download my invoice?\n\nTo download your invoice, go to Manage > Billing and usage, and select Invoices. Then, click the Download icon ![Download icon](https:\/\/cloud.ibm.com\/icons\/download.svg) and choose an invoice format.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03776-6753-8705","score":13.4284,"text":"\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).\n\nFor more information about how to manage your payments, see [Managing your payment method](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusageprereqs-payments).\n\n\n\n\n\n Tracking your usage \n\nTo view usage data for resources, you must be assigned the correct access. Access can be assigned at the account level or to individual resource groups and Cloud Foundry orgs.\n\n\n\n* To view usage for all resources in the account, you need an access policy with the Administrator role on the Billing account management service.\n* To view usage only for specific IBM Cloud Identity and Access Management (IAM) resources, you need the Viewer role or higher on the resource group.\n* To view usage for only specific Cloud Foundry services, the Billing manager role must be applied at the org level. Billing managers can see the details for only the organizations in which they are assigned the Billing manager role.\n\n\n\nYou can limit the access to view the usage for a specific resource group by assigning the viewer role or higher on all Identity and Access enabled services within that resource group.\n\n\n\n\n\n Managing your invoices \n\nIf you have a Pay-As-You-Go account that's billed in US dollars, you can view your invoice in the IBM Cloud console by going to Manage > Billing and usage, > and clicking Invoices.\n\nIf you own one of the following accounts, you can view your invoice on the [IBM Invoices](http:\/\/ibm.com\/invoices) website, which is linked from the [Invoices page](https:\/\/cloud.ibm.com\/billing\/invoices) in the console.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.5,"recall_5":0.5,"recall_10":0.5,"ndcg_cut_1":1.0,"ndcg_cut_3":0.765360637,"ndcg_cut_5":0.6366824387,"ndcg_cut_10":0.6366824387}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>9","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03787-5002-7004","score":16.703182,"text":"\nA subscription is inactive if its term expires or all of its credit is spent.\n\n\n\nYou can use the spending and usage information on the Subscriptions page to evaluate whether your subscriptions suit your usage needs. For example, if you consistently have overages, you might increase your monthly spending commitment to save money on that usage. To buy new subscriptions or change future subscription amounts, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n\n\n\n\n\n Support subscriptions \n\nTo view support subscription usage, in the console, go to Manage > Billing and usage, and select Support costs. You can view the remaining credit in your active support subscriptions and any upcoming subscriptions that aren't yet valid. For more information, see [Viewing your support costs](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-support).\n\n\n\n\n\n\n\n Subscription credit \n\nAfter you buy a subscription for platform or support credit, you add the credit to your account by applying a subscription code. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nFor more information, see [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Expiring subscriptions \n\nYou are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After the subscription expires, your account is converted to a Pay-As-You Go account, which means you pay only for billable services that you use with no contracts or commitments. The discounts that are associated with the subscription account won't apply to the Pay-As-You-Go account. The IBM Sales team is happy to help extend your subscription before you reach its expiration date. If you extend your subscription within 30 days from the expiration date, you won't get charged at the Pay-As-You-Go account rate. After 30 days, you are invoiced as a Pay-As-You-Go account.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions"},{"document_id":"ibmcld_03776-5228-7163","score":16.665958,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03704-10459-12479","score":16.146402,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n How do I apply a feature code? \n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Why did my account get billed for additional services charges? \n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_03786-7-2105","score":16.04203,"text":"\nApplying subscription codes \n\nAfter you buy a subscription for platform or support credit, you must add the credit to your account by applying a subscription code to an existing account or a new account when you register. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nIf you set up your first subscription through the [Subscriptions page](https:\/\/cloud.ibm.com\/billing\/subscriptions), the credit for this subscription is automatically added to your account - no code required.\n\nAfter IBM Cloud Sales places the order, an email with the subscription code for each subscription and support line item is sent to the appropriate contact.\n\nOnly the account owner, enterprise account owner, or a user with the Editor or Administrator role on the Billing account management service can apply the subscription code. If you don't have access to apply subscription codes, the account owner or administrator can provide access. For more information, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services). Applying the subscription code through the IBM Cloud\u00ae console is essential to ensure that your account is migrated appropriately.\n\n\n\n1. Open the email with the subscription code.\n\nIf you bought a subscription and didn't receive your subscription code, [contact us](https:\/\/www.ibm.com\/cloud?contactmodule) or email Sales at [CloudDigitalSales@us.ibm.com](mailto:CloudDigitalSales@us.ibm.com) to request for it to be sent again.\n2. Click Add subscription to add it to an existing account.\n3. Sign in to the console with your IBMid and password.\n4. From the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code"},{"document_id":"ibmcld_03786-1684-3421","score":15.610658,"text":"\nFrom the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date. Ensure that you add the code to the correct account because the subscription credits can't be removed after the code is applied. After you add the subscription code, you might see that the status of the subscription as IN_PROCESS. Contact IBM Cloud Sales to review the account.\n3. Enter the subscription code, and click Apply.\n\nIf you have separate codes for platform and support credit, apply the platform subscription code first, then apply the support subscription code.\n\n\n\nTo manually apply the subscription code to a new account, complete the following steps:\n\n\n\n1. Go [create an IBM Cloud account](https:\/\/cloud.ibm.com\/registration), and enter the required information.\n2. Click Register with a code instead of entering your credit card information.\n3. Click Create account.\n\n\n\nIf you don't know your seller, the codes are applied in the wrong order, or you experience issues with applying the codes, [contact IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\nFor information about other codes and credits that can be applied to different account types, see [Applying feature codes to a Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) or [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code"},{"document_id":"ibmcld_07578-1051890-1053900","score":15.588659,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1051761-1053771","score":15.588659,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03704-8977-10890","score":15.457138,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n\n\n\n\n\n Why did I get invoiced when I have remaining promotion credits? \n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_16727-1068047-1069909","score":15.45163,"text":"\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https:\/\/www.ibm.com\/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https:\/\/cloud.ibm.com\/account\/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration). For more information, see [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https:\/\/www.ibm.com\/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_16727-1050284-1052192","score":15.42503,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"}],"retriever_scores":{"recall_1":0.0,"recall_3":0.0,"recall_5":0.0,"recall_10":0.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.0,"ndcg_cut_5":0.0,"ndcg_cut_10":0.0}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>10","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03732-0-1673","score":15.177732,"text":"\n\n\n\n\n\n\n  Applying feature codes \n\nYou can apply feature codes to take advantage of extra IBM Cloud\u00ae resources or capabilities. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.\n\nAre you looking for details about adding subscription credit to your account? See [Managing subscriptions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscriptions) for more information.\n\nYou must have the Editor role or higher for all account management services to apply a feature code. The extra resources or capabilities that are provided vary depending on the particular code but include one or more of the following items in general:\n\n\n\n*  Increase the memory quota to a number of GB that is specified by the code\n*  Add one organization with a memory quota that is specified by the code\n*  Add an unlimited number of organizations\n*  Upload an extra number of SSL certificates, as specified by the code\n*  Use premium service plans\n*  Convert a Lite account to a trial account, which provides access to more services but only within a limited trial period\n\n\n\nComplete the following steps to apply a feature code to your existing account:\n\nIf you don't have an account yet, you can add your feature code when you [register](https:\/\/cloud.ibm.com\/registration) for a new account by clicking Register with a code instead of entering your credit card information.\n\n\n\n1.  In the IBM Cloud console, go to Manage > Account, and select Account settings.\n2.  Click Apply code.\n3.  Enter the feature code, which is typically a random alphanumeric value such as a1b2c3def456.\n4.  Click Apply.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-codes"},{"document_id":"ibmcld_03709-0-1479","score":14.126424,"text":"\n\n\n\n\n\n\n  Why can't I apply a feature code? \n\nTo successfully apply a feature code, make sure the code is valid and that you have the correct account type.\n\n  What\u2019s happening \n\nWhen you try to apply a feature code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error for any of the following reasons:\n\n\n\n*  Your account doesn't meet the requirements for the feature code.\n*  You don't have the required access in the account.\n*  The code expired.\n\n\n\n  How to fix it \n\nUse the following steps to successfully apply a feature code:\n\n\n\n*  Verify that you have the correct account type. For example, some feature codes for educational promotions are only for Lite accounts. To view your account type, in the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes).\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n*  If you are unable to apply a feature code that you received from an educational provider, contact that educational provider for further assistance.\n\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cannot-apply-feature-code"},{"document_id":"ibmcld_03704-10459-12479","score":14.021013,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n How do I apply a feature code? \n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Why did my account get billed for additional services charges? \n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_03786-1684-3421","score":13.687092,"text":"\nFrom the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date. Ensure that you add the code to the correct account because the subscription credits can't be removed after the code is applied. After you add the subscription code, you might see that the status of the subscription as IN_PROCESS. Contact IBM Cloud Sales to review the account.\n3. Enter the subscription code, and click Apply.\n\nIf you have separate codes for platform and support credit, apply the platform subscription code first, then apply the support subscription code.\n\n\n\nTo manually apply the subscription code to a new account, complete the following steps:\n\n\n\n1. Go [create an IBM Cloud account](https:\/\/cloud.ibm.com\/registration), and enter the required information.\n2. Click Register with a code instead of entering your credit card information.\n3. Click Create account.\n\n\n\nIf you don't know your seller, the codes are applied in the wrong order, or you experience issues with applying the codes, [contact IBM Cloud Support](https:\/\/cloud.ibm.com\/docs\/get-support?topic=get-support-using-avatar).\n\nFor information about other codes and credits that can be applied to different account types, see [Applying feature codes to a Lite account](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) or [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code"},{"document_id":"ibmcld_07578-1051890-1053900","score":13.617913,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1051761-1053771","score":13.617913,"text":"\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https:\/\/cloud.ibm.com\/account\/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https:\/\/cloud.ibm.com\/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https:\/\/cloud.ibm.com\/docs\/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03704-8977-10890","score":13.230691,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n\n\n\n\n\n Why did I get invoiced when I have remaining promotion credits? \n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_16727-1050284-1052192","score":13.157325,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_07578-1050413-1052321","score":13.157325,"text":"\nTo apply your promo code, go to the [Promotions](https:\/\/cloud.ibm.com\/billing\/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https:\/\/cloud.ibm.com\/docs\/account?topic=account-codes) and [Applying subscription codes](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_03711-0-822","score":12.893575,"text":"\n\n\n\n\n\n\n  Why can\u2019t I create a service after I apply a feature code? \n\nYou can recover from issues with creating service after a feature code is applied by following a few easy steps.\n\n  What\u2019s happening \n\nWhen you try to create an instance of a service from the catalog, you're prompted to upgrade with a message such as Upgrade your account to create instances of the offering.\n\n  Why it\u2019s happening \n\nYour account wasn't enabled to create resources of that type after you applied the feature code. The resources or capabilities that are provided vary for each feature code.\n\n  How to fix it \n\nContact the person who gave you the feature code to verify the capabilities that it can enable for your account. For example, contact your educational provider for feature codes that they gave you for use with coursework.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cant-create-service-feature-code"}],"retriever_scores":{"recall_1":0.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":0.0,"ndcg_cut_3":0.6309297536,"ndcg_cut_5":0.6309297536,"ndcg_cut_10":0.6309297536}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>11","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03713-7-2194","score":12.953992,"text":"\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-1710-3705","score":12.929291,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7896-8949","score":12.178513,"text":"\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments). Credit card transactions are automatically retried within 24 hours after you update the information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_16727-1072450-1074392","score":11.603314,"text":"\nFor more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?\n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.\n\nAfter you open the case, an email notification is sent to you. Follow the instructions for further communication.\n\n\n\nIf you can't log in to an IBM Cloud account, [create an account request](https:\/\/watson.service-now.com\/x_ibmwc_open_case_app.do!\/create).\n* Why is a VAT ID required when I create an account?\n\nA tax identification number, such as a VAT ID, GST number, or TIN, is required to create a new personal use account with an address in specific countries or regions. For information about these requirements or where personal use accounts are not permitted, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts). A tax identification number is also required for company accounts depending on your location. Some countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03776-5228-7163","score":11.41872,"text":"\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https:\/\/myibm.ibm.com\/billing\/).","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-overview"},{"document_id":"ibmcld_03782-0-720","score":11.095571,"text":"\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-section-error"},{"document_id":"ibmcld_03704-3030-4892","score":10.587587,"text":"\nIn the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-ts-ccibm)\n\n\n\n\n\n How do I change my payment method? \n\nFor a Pay-As-You-Go account, you must have an active credit card on file. Our Subscription and IBM Cloud Enterprise Savings Plan account types might enable you to use other payment options. Contact an [IBM Cloud Sales](https:\/\/cloud.ibm.com\/catalog?contactmodule) representative to inquire about payment options.\n\n\n\n\n\n Why didn't my credit card process? \n\nProtecting your identity is a priority for us, so we take credit card verification seriously.\n\nIf your credit card did not process successfully, contact us by calling 1-866-325-0045 and selecting the third option. For information about specific error messages, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n\nYou might manage your payment method on a separate billing platform, [IBM Billing](https:\/\/myibm.ibm.com\/billing\/). For more information about that process, see [Managing your payment method outside of the console](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-billusagefaqs"},{"document_id":"ibmcld_07578-1069800-1071727","score":10.414597,"text":"\nThis credit card hold is reversed within 24 to 72 hours. In many cases, a credit card isn't accepted because your credit card issuer didn't authorize it. For more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?\n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.\n\nAfter you open the case, an email notification is sent to you. Follow the instructions for further communication.\n\n\n\nIf you can't log in to an IBM Cloud account, [create an account request](https:\/\/watson.service-now.com\/x_ibmwc_open_case_app.do!\/create).\n* Why is a VAT ID required when I create an account?\n\nA tax identification number, such as a VAT ID, GST number, or TIN, is required to create a new personal use account with an address in specific countries or regions. For information about these requirements or where personal use accounts are not permitted, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts). A tax identification number is also required for company accounts depending on your location. Some countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_02273-0-665","score":10.333285,"text":"\n\n\n\n\n\n\n  Why can't I submit the form to add my credit card information? \n\nYou can't submit your credit card information to upgrade your Lite account to a billable account.\n\n  What\u2019s happening \n\nThe Upgrade account button is disabled.\n\n  Why it\u2019s happening \n\nThis problem happens when your information isn't entered correctly.\n\n  How to fix it \n\nComplete the following steps:\n\n\n\n1.  Complete all of the required fields to add your credit card and billing information in the IBM Cloud console.\n\nEnsure that you specified a business account and not a personal account type, if you are providing a VAT ID or tax identification number.\n2.  Click Upgrade account.\n\n\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-ts_addcc"},{"document_id":"ibmcld_02301-1556-3330","score":10.317815,"text":"\nFor any billable services that you use beyond any free allowances, you receive a monthly invoice.\n\nIf you're upgrading to reactivate a deactivated account, your account might take a few days to be fully available. If your account continues to be in a pending state, see [Why can't I upgrade my account?](https:\/\/cloud.ibm.com\/docs\/account?topic=account-ts_upgrade_cc) for help.\n\nIf you can't upgrade your account because of an issue with your credit card, see [Troubleshooting credit card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages) for more information.\n\n\n\n\n\n Promotional credit for upgrading your account \n\nAfter you sign up for a new Pay-As-You-Go account or upgrade your free account, you'll receive a promotional credit to use on any IBM product. To view the list of eligible products, go to the IBM Cloud console and select Catalog > Provider > IBM.\n\nThe credit might take a few hours to appear in your account. Any unused upgrade credit expires after the 30 day period ends. You are invoiced for any usage that exceeds the promotional credit. To view the promotional credit, go to the [Promotions and credits](https:\/\/cloud.ibm.com\/billing\/promotions) page or the [Invoices](https:\/\/cloud.ibm.com\/billing\/invoices) page in the console.\n\nThe following table lists the current upgrade promotional amounts for different currencies:\n\n\n\nTable 1. Promo price for different currencies\n\n Country Currency Converted Promo Amount \n\n United States USD 200.00 \n Australia AUD 279.94 \n Brazil BRL 862.84 \n Canada CAD 260.96 \n Switzerland CHF 190.85 \n China CNY 1,836.38 \n Denmark DKK 1,258.68 \n Euro EUR 168.67 \n UK GBP 151.96 \n Indonesia IDR 3,128,000.00 \n India INR 14,390.14 \n Japan JPY 22,400.62 \n South Korea KRW 232,999.57","title":"","source":"https:\/\/cloud.ibm.com\/docs\/account?topic=account-upgrading-account"}],"retriever_scores":{"recall_1":0.25,"recall_3":0.75,"recall_5":0.75,"recall_10":0.75,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":0.8318724637,"ndcg_cut_10":0.8318724637}}
{"task_id":"adf9b1f61c73d715809bc7b37ac02724<::>12","Collection":"mt-rag-ibmcloud-elser-512-100-20240502","contexts":[{"document_id":"ibmcld_03713-3269-5168","score":24.003523,"text":"\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7-2194","score":22.17758,"text":"\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-1710-3705","score":20.750357,"text":"\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-4689-6647","score":18.499279,"text":"\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https:\/\/cloud.ibm.com\/billing\/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-6236-8279","score":15.30024,"text":"\nFor more information, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_03713-7896-8949","score":13.864969,"text":"\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https:\/\/cloud.ibm.com\/billing\/payments). Credit card transactions are automatically retried within 24 hours after you update the information.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages"},{"document_id":"ibmcld_07578-1069800-1071727","score":12.908604,"text":"\nThis credit card hold is reversed within 24 to 72 hours. In many cases, a credit card isn't accepted because your credit card issuer didn't authorize it. For more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?\n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.\n\nAfter you open the case, an email notification is sent to you. Follow the instructions for further communication.\n\n\n\nIf you can't log in to an IBM Cloud account, [create an account request](https:\/\/watson.service-now.com\/x_ibmwc_open_case_app.do!\/create).\n* Why is a VAT ID required when I create an account?\n\nA tax identification number, such as a VAT ID, GST number, or TIN, is required to create a new personal use account with an address in specific countries or regions. For information about these requirements or where personal use accounts are not permitted, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts). A tax identification number is also required for company accounts depending on your location. Some countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/faqs"},{"document_id":"ibmcld_16727-1072450-1074392","score":11.451779,"text":"\nFor more information about issues with credit card authorization, see [Credit Card error messages](https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?\n\nIf you are able to log in to an IBM Cloud account, go to the [Support Center](https:\/\/cloud.ibm.com\/unifiedsupport\/supportcenter) and choose one of the following options.\n\n\n\n* If you have advanced or premium support, click Chat with IBM to talk to an IBM Cloud support representative.\n* Create a support case by clicking Create a case from the Need more help? section.\n\nAfter you open the case, an email notification is sent to you. Follow the instructions for further communication.\n\n\n\nIf you can't log in to an IBM Cloud account, [create an account request](https:\/\/watson.service-now.com\/x_ibmwc_open_case_app.do!\/create).\n* Why is a VAT ID required when I create an account?\n\nA tax identification number, such as a VAT ID, GST number, or TIN, is required to create a new personal use account with an address in specific countries or regions. For information about these requirements or where personal use accounts are not permitted, see [Personal use availability](https:\/\/cloud.ibm.com\/docs\/account?topic=account-account-getting-startedsignup-personalaccts). A tax identification number is also required for company accounts depending on your location. Some countries where the local government requires it, taxes are charged directly instead.\n* How do I update my credit card?\n\nIf you have a Pay-As-You-Go account type that is billed in US Dollars, complete the following steps:\n\n\n\n1. Go to the [Payments](https:\/\/cloud.ibm.com\/billing\/payments) page.\n2. Click Update card, enter the new credit card information, and click Save.\n\n\n\nTo switch to a different payment method, select Pay with Other and then click Submit change request. A support case to change your payment method is created for you.","title":"","source":"https:\/\/cloud.ibm.com\/docs?tab=faqs"},{"document_id":"ibmcld_03935-33555-35918","score":10.8628025,"text":"\nBecause the peers will be unable to progress beyond this configuration block, it will not be possible to reverse this configuration block and submit another one to \"fix\" the problem. A channel in this state is unrepairable.\n\n\n\n\n\n\n\n\n\n Tuning your ordering service \n\nPerformance of a blockchain platform can be affected by many variables such as transaction size, block size, network size, as well as limits of the hardware. The orderer node includes a set of tuning parameters that together can be used to control orderer throughput and performance. You can use these parameters to customize how your orderer processes transactions depending on whether you have many small frequent transactions, or fewer but large transactions that arrive less frequently. Essentially, you have the control to decide when the blocks are cut based on your transaction size, quantity, and arrival rate.\n\nThe following parameters are available in the console by clicking the orderer node in the Nodes tab and then clicking its Settings icon. Click the Advanced button to open the Advanced channel configuration for the orderer.\n\n\n\n Block cutting parameters \n\nThe following three parameters work together to control when a block is cut, based on a combination of setting the maximum number of transactions in a block as well as the block size itself.\n\n\n\n* Absolute max bytes Set this value to the largest block size in bytes that can be cut by the orderer. No transaction may be larger than the value of Absolute max bytes. Usually, this setting can safely be two to ten times larger than your Preferred max bytes. Note: The maximum size permitted is 99MB.\n* Max message count Set this value to the maximum number of transactions that can be included in a single block.\n* Preferred max bytes Set this value to the ideal block size in bytes, but it must be less than Absolute max bytes. A minimum transaction size, one that contains no endorsements, is around 1KB. If you add 1KB per required endorsement, a typical transaction size is approximately 3-4KB. Therefore, it is recommended to set the value of Preferred max bytes to be around Max message count * expected averaged tx size. At run time, whenever possible, blocks will not exceed this size. If a transaction arrives that causes the block to exceed this size, the block is cut and a new block is created for that transaction.","title":"","source":"https:\/\/cloud.ibm.com\/docs\/blockchain?topic=blockchain-ibp-console-govern"},{"document_id":"ibmcld_03782-0-720","score":10.857383,"text":"\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n","title":"","source":"https:\/\/cloud.ibm.com\/docs\/billing-usage?topic=billing-usage-section-error"}],"retriever_scores":{"recall_1":1.0,"recall_3":1.0,"recall_5":1.0,"recall_10":1.0,"ndcg_cut_1":1.0,"ndcg_cut_3":1.0,"ndcg_cut_5":1.0,"ndcg_cut_10":1.0}}
