{"task_id": "1be66272113492407e814eaf21a761d4<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03363-4-2165", "score": 41.462915024088886, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_03036-4322-6185", "score": 39.27236273337922, "text": "\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_03363-1671-3630", "score": 39.093262481646036, "text": "\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_03036-2789-4951", "score": 38.19633275098379, "text": "\nIf you have [selected a data source](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_09795-7-2120", "score": 33.66610933406264, "text": "\nPricing \n\nThis topic includes information about pricing for the IBM Cloud Monitoring. You can also review the sample scenarios to learn more about the costs of a Monitoring instance.\n\nIBM Cloud Monitoring pricing is based on hourly consumption. You are billed monthly based on the number of connected agents and the agent deployment mode, the number of custom metric time series, extra number of containers per agent and additional API calls above 1M. There are two agent modes: agent for orchestrated environments, and agent for non-orchestrated environments.\n\nAll other IBM Cloud Monitoring functionality, including dashboards, panels, and alerts, are included in the base service price and pricing does not vary.\n\nThe costs that are provided in this topic are guidelines and do not represent actual costs. They represent a starting point for estimates of costs that would be incurred in environments with a similar configuration. Actual costs can vary by geography. The prices that are used are based on actual prices as of April 1, 2023 and it is possible they can change.\n\n\n\n Before you begin \n\nRead this section to understand concepts and costs that are associated with the Monitoring service.\n\n\n\n* [Service plans](https://cloud.ibm.com/docs/monitoring?topic=monitoring-service_plans).\n* [Time-series](https://cloud.ibm.com/docs/monitoring?topic=monitoring-about-timeseries).\n* [Sources of custom metrics](https://cloud.ibm.com/docs/monitoring?topic=monitoring-about-collect-metrics).\n* [Collecting metrics by infrastructure](https://cloud.ibm.com/docs/monitoring?topic=monitoring-collect-metrics-by-host).\n\n\n\n\n\n\n\n Consumption charges \n\nIn your monthly usage charges, consumption is measured hourly and your bill breaks down into the following concepts:\n\n\n\nTable 2. Billing usage metrics\n\n Metric Description \n\n NODE_HOURS Tracks the number of agents that are running in an agent for orchestrated environments.<br><br>This does not include the agents tracked by LITE_NODE_HOURS<br><br>For example, if you have 1 agent connected continuously, that agent will be billed 720 NODE_HOURS at the end of the month.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-pricing_plans"}, {"document_id": "ibmcld_09814-3364-5804", "score": 31.88558316873457, "text": "\nDocument changes in the [Agent release notes](https://docs.sysdig.com/en/sysdig-agent-release-notes.html) Update the agent to keep it up to date as new versions are made available. \n Update default dashboards Update the default dashboards as requirements change. Update custom dashboards and track changes by using your own change management process. \n Update pre-defined alert definitions Update the default alert definitions as requirements change. Update custom alert definitions and track changes by using your own change management process. \n Track versions of custom dashboards, alerts, notifications, and teams Use your own change management process to control versions of monitoring resources such as dashboards, alert definitions, teams, and notifications. \n\n\n\n\n\n\n\n Identity and access management \n\nIBM is responsible for the security and compliance of IBM Cloud Monitoring. You are responsible for defining the IBM Cloud Identity and Access Management (IAM) policies to control which users within your account have access to the monitoring data.\n\n\n\nTable 3. Responsibilities for identity and access management\n\n Task IBM Responsibilities Your Responsibilities \n\n Manage platform permissions Allow administrators to control access to manage resources in the IBM Cloud. Grant, revoke, and manage access to service instances by using IAM. \n Manage service permissions Allow administrators to control access to work with the IBM Cloud Monitoring. Grant, revoke, and manage access to monitoring features by using IAM. \n Control monitoring data access Allow administrators to control access to metrics data and metadata through Sysdig teams. Grant, revoke, and manage access to monitoring data by using IAM. \n\n\n\n[Learn more about controlling access through IAM](https://cloud.ibm.com/docs/monitoring?topic=monitoring-iam).\n\n\n\n\n\n Security and regulation compliance \n\nIBM is responsible for the security and compliance of IBM Cloud Monitoring. You are responsible for ensuring that metrics, that contain regulated data, are not provided to the IBM Cloud Monitoring service.\n\n\n\nTable 4. Responsibilities for security and regulation compliance\n\n Task IBM Responsibilities Your Responsibilities \n\n Meet security and compliance objectives Maintain controls that are commensurate to supported industry compliance standards, such as SOC. Ensure that regulated data is not provided to the IBM Cloud Monitoring service. \n\n\n\n\n\n\n\n Disaster recovery", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-shared-responsibilities"}, {"document_id": "ibmcld_14503-4971-7126", "score": 31.23545948781657, "text": "\nThe client can also configure their compute VMs to uses these forwarders, if required.\n* VMware Update Manager (VUM) provides updating of vSphere hosts and VM hardware and tools. VUM uses the Proxy to gain access to the internet repositories.\n\n\n\nVMware Aria Operations collects data from objects in the environment. Each piece of data that is collected is called a metric observation or value. VMware Aria Operations uses the vCenter adapter to collect raw metrics from vCenter. In addition to the metrics it collects, VMware Aria Operations calculates capacity metrics, badge metrics, and metrics to monitor the health of your system. Alert definitions are a combination of symptoms and recommendations that identify problem areas and generate alerts on which you act for those areas.\n\n\n\n\n\n Monitored components \n\n\n\n Monitoring of vCenter \n\nThe monitoring of vCenter is accomplished with VMware Aria Operations and the VMware SDDC Health Management Pack. VMware Aria Operations for Logs collects the log data from vCenter and the Content Pack for vSphere adds specific understanding to the logs and in turn sends alerts to VMware Aria Operations.\n\nThe VMware SDDC Health Management Pack monitors the SDDC Management stack and provides badges for health and alerts related to configuration and compliance of SDDC product components that include vCenter.\n\n\n\n\n\n Monitoring of vSphere hosts \n\nMonitoring of the vSphere hosts is accomplished with VMware Aria Operations through vCenter and the collection of logs through VMware Aria Operations for Logs.\n\n\n\n\n\n Monitoring of vSAN \n\nTo monitor vSAN, VMware Aria Operations, and VMware Aria Operations for Logs are used. In vCenter, you can use an extra set of vSAN Health Checks. Installation of the Management Pack for vSAN provides more dashboards to aid with the monitoring of vSAN.\n\nVMware Aria Operations generates an alert if a problem occurs in the SDDC product components in the storage area network that the VMware vSAN adapter is monitoring. An alert that is related to configuration compliance and health is passed through VMware SDDC Health Solution management pack from VMware vSAN Management Pack.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-opsmgmt-arch"}, {"document_id": "ibmcld_09814-1491-3814", "score": 30.580806055994458, "text": "\nMaintain IBM Cloud high availability SLA Operate the Continuous Delivery service in accordance with the IBM Cloud Public [Service Level Agreements (SLAs)](https://cloud.ibm.com/docs/overview/terms-of-use?topic=overview-slas). \n Provide high availability capabilities Provide capabilities, such as IBM-owned infrastructure in multizone regions (MZR), to meet local access and low latency requirements for each supported region. Use the list of [available regions](https://cloud.ibm.com/docs/monitoring?topic=monitoring-endpoints) to plan for and create new instances of the service. \n Monitor monitoring agents Provide images and instructions for how to install monitoring agents in environments that you want to monitor, such as Kubernetes, Linux, and Red Hat OpenShift. Install and configure monitoring agents. <br>Monitor that the agents are running in your environment, for example, by using monitoring alerts. \n Deliver platform metrics Deliver platform metrics for Monitoring-enabled services to the monitoring instance that collects platform metrics and is located in the region where the platform metrics are generated. Configure 1 monitoring instance per region to collect platform metrics in that region. \n\n\n\n\n\n\n\n Change management \n\nYou and IBM share responsibilities for keeping IBM Cloud Monitoring service components at the latest version. You are responsible for change management of your monitoring agents, dashboards, and alert definitions.\n\n\n\nTable 2. Responsibilities for change management\n\n Task IBM Responsibilities Your Responsibilities \n\n Update the IBM Cloud Monitoring service Provide regular updates to the service with new features, fixes for defects, and security fixes. \n Update the monitoring agent image that is hosted in IBM Cloud Provide regular updates to the monitoring agent image with new features, fixes to defects, and security fixes. Document changes in the [Agent release notes](https://docs.sysdig.com/en/sysdig-agent-release-notes.html) Update the agent to keep it up to date as new versions are made available. \n Update default dashboards Update the default dashboards as requirements change. Update custom dashboards and track changes by using your own change management process. \n Update pre-defined alert definitions Update the default alert definitions as requirements change.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-shared-responsibilities"}, {"document_id": "ibmcld_09148-1749-3696", "score": 30.362294916357286, "text": "\n* Other IBM Cloud users with administrator or editor permissions can manage the Monitoring service in the IBM Cloud. These users must also have platform permissions to create resources within the context of the resource group where they plan to provision the instance.\n\n\n\n\n\n\n\n Connecting Monitoring with Key Protect \n\nYour dashboard will show metrics for all Key Protect instances with an enabled metrics policy.\n\n\n\n Configure a Monitoring instance for metrics \n\nTo enable platform metrics in a region, complete the following steps:\n\n\n\n1. [Provision an instance of Monitoring](https://cloud.ibm.com/docs/monitoring?topic=monitoring-provision) in the region of the Key Protect instance that contains an [enabled metrics policy](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-monitor-metrics).\n2. Go to the [monitoring dashboard](https://cloud.ibm.com/observe/monitoring).\n3. Click on \"Configure platform metrics.\"\n4. Select the region where the Key Protect instance was created.\n5. Select the Key Protect instance in which you would like to receive metrics.\n6. Click \"Configure.\"\n7. Your Key Protect instance is now set for platform metrics.\n\n\n\n\n\n\n\n\n\n Key Protect Metrics Details \n\nYou can use the metrics in your monitoring instance dashboard to measure the types of requests being made in your service instance as well as the latency of the requests.\n\n\n\n API Hits \n\nThe type and amount of API requests being made to your Key Protect instance. For example, you can track how many API requests have been made by an authorized user be setting an [alert](https://cloud.ibm.com/docs/key-protect?topic=key-protect-operational-metricsset-monitor-alerts) that triggers when your monitoring instance notices a frequent amount of 401 status codes being returned from your Key Protect instance.\n\n\n\nTable 1. Describes the API Hits metrics.\n\n Metadata Description \n\n Metric Name ibm_kms_api_request_gauge \n Metric Type Gauge \n Value Type none", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-operational-metrics"}, {"document_id": "ibmcld_08592-3134-5110", "score": 29.560054766419334, "text": "\n6. Click Configure.\n7. Your Hyper Protect Crypto Services instance is now set for platform metrics.\n\n\n\n\n\n\n\n\n\n Hyper Protect Crypto Services Metrics Details \n\nYou can use the metrics in your Monitoring dashboard to measure the types of requests that are made to your service instance as well as the latency of the requests.\n\n\n\n API Hits \n\nThe type and number of API requests that are made to your Hyper Protect Crypto Services instance. For example, you can track how many API requests that are made by an authorized user by setting an [alert](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-operational-metricsset-monitor-alerts). The alert triggers when your Monitoring instance notices a frequent number of 401 status codes that are returned from your Hyper Protect Crypto Services instance.\n\n\n\nTable 1. Describes the API Hits metrics.\n\n Metadata Description \n\n Metric Name ibm_hpcs_api_request_gauge \n Metric Type Gauge \n Value Type none \n Segment By [Attributes for Segmentation](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-operational-metricsattributes-for-segmentation) \n\n\n\n\n\n\n\n\n\n Latency \n\nThe number of time it takes Hyper Protect Crypto Services to receive an API request and respond to it.\n\nThe latency is calculated by getting the average of all requests of the same type that occur within 60 seconds.\n\n\n\nTable 2. Describes the Latency metrics.\n\n Metadata Description \n\n Metric Name ibm_hpcs_api_latency_gauge \n Metric Type Gauge \n Value Type Milliseconds \n Segment By [Attributes for Segmentation](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-operational-metricsattributes-for-segmentation) \n\n\n\n\n\n\n\n Attributes for Segmentation \n\nYou can filter your metrics by using the following attributes.\n\n\n\nTable 3. Describes the attributes use for segmenting metrics.\n\n Attribute Name Description \n\n ibm_resource_type Supported resource type is instance. \n ibm_hpcs_response_code Response code for the Hyper Protect Crypto Services service API request.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-operational-metrics"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02361-22962-24900", "score": 17.42060473762779, "text": "\nIn the UI, you can define custom views, dashboards, parsing templates, screens, and exclusion rules that you can use to view and analyze data.\n\nTo reuse resource definitions that you define in your auditing instance, you can export these resources from an IBM Cloud Activity Tracker instance as a JSON file. Then, you can import the definitions into other auditing instances. For example, you can reuse your resources across different environments for your stage, pre-production, and production instances. [Learn more](https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-reuse_resource_definitions).\n\nBackup resource definitions into a version control system such as a git repository where you can control access to the archived files and manage versions.\n\n\n\n\n\n Archive log data to a COS bucket \n\nEnable archiving of your data from an auditing instance to an IBM Cloud Object Storage (COS) bucket.\n\nAfter you provision an auditing instance, you can configure archiving to an IBM Cloud Object Storage (COS) bucket. You can create different types of buckets based on your requirements.\n\nWhen you plan the bucket for an auditing instance, consider the following information:\n\n\n\nTable 5. COS bucket requirements\n\n Requirement Question to answer Information \n\n Type of workload [1] How often do you need to access the data? [Information about storage classes](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-classesclasses-about) \n Retention policy [2] Do you need to protect data from being deleted? [Information about Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time?", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-adoption"}, {"document_id": "ibmcld_09275-30068-31881", "score": 16.983190657713358, "text": "\nFor example, you can reuse your logging resources across different environments for your stage, pre-production, and production logging instances. [Learn more](https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-reuse_resource_definitions).\n\nBackup logging resource definitions into a version control system such as a git repository where you can control access to the archived files and manage versions.\n\n\n\n\n\n Archive log data to a COS bucket \n\nEnable archiving of your data from a logging instance to an IBM Cloud Object Storage (COS) bucket.\n\nAfter you provision a logging instance, you can configure archiving to an IBM Cloud Object Storage (COS) bucket. You can create different types of buckets based on your requirements.\n\nWhen you plan the bucket for a logging instance, consider the following information:\n\n\n\nTable 5. COS bucket requirements\n\n Requirement Question to answer Information \n\n Type of workload [1] How often do you need to access the data? [Information about storage classes](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-classesclasses-about) \n Retention policy [2] Do you need to protect data from being deleted? [Information about Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest?", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-adoption"}, {"document_id": "ibmcld_04866-6428-8391", "score": 12.996077084528936, "text": "\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https://cloud.ibm.com/docs/cloud-object-storage/images/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-6428-8442", "score": 12.904342533761898, "text": "\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https://cloud.ibm.com/docs/images/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05138-7979-9034", "score": 12.406675309537667, "text": "\nAfter your bucket is created with Activity Tracker and Monitoring, it may take a few minutes for the rules to take effect.\n\nYou are now ready to store data in a secure content store with encryption, monitoring, and audit observability!\n\n\n\n\n\n Get started by uploading data \n\n\n\n* See [uploading data](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-upload) for more information.\n\n\n\n\n\n\n\n Add capabilities \n\nAdd capabilities to protect objects from ransomware and accidental deletion such as [versioning](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-versioning) and [immutable retention polices](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-ol-overview) for supporting immutable storage, and immutable backup and archive data.\n\n\n\n\n\n Library of Object Storage tutorials \n\nCheck out the IBM Cloud Tutorials library for more tutorials when deploying solutions with [Cloud Object Storage](https://cloud.ibm.com/docs?tab=tutorials&page=1&pageSize=20&tags=cloud-object-storage).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-secure-content-store"}, {"document_id": "ibmcld_02361-24500-26305", "score": 12.406093338646158, "text": "\n[Information about Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-adoption"}, {"document_id": "ibmcld_05168-15740-17188", "score": 12.384087989820376, "text": "\nfmt.Println(r)\nfmt.Println(e)\n\n}\n\nShow more\n\nThe typical response is exemplified here.\n\n{\nRules: [{\nFilter: {\n\n},\nID: \"id3\",\nStatus: \"Enabled\",\nTransitions: {\nDays: 5,\nStorageClass: \"GLACIER\"\n}]\n}]\n}\n\n\n\n\n\n Immutable Object Storage \n\nUsers can configure buckets with an Immutable Object Storage policy to prevent objects from being modified or deleted for a defined period of time. The retention period can be specified on a per-object basis, or objects can inherit a default retention period set on the bucket. It is also possible to set open-ended and permanent retention periods. Immutable Object Storage meets the rules set forth by the SEC governing record retention, and IBM Cloud administrators are unable to bypass these restrictions.\n\nNote: Immutable Object Storage does not support Aspera transfers via the SDK to upload objects or directories at this stage.\n\nfunc main() {\n\n// Create Client\nsess := session.Must(session.NewSession())\nclient := s3.New(sess, conf)\n\n// Create a bucket\ninput := &s3.CreateBucketInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\n}\nd, e := client.CreateBucket(input)\nfmt.Println(d) // should print an empty bracket\nfmt.Println(e) // should print <nil>\n\n// PUT BUCKET PROTECTION CONFIGURATION\npInput := &s3.PutBucketProtectionConfigurationInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\nProtectionConfiguration: &s3.ProtectionConfiguration{\nDefaultRetention: &s3.BucketProtectionDefaultRetention{\nDays: aws.Int64(100),\n},", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-using-go"}, {"document_id": "ibmcld_06808-1384-2991", "score": 11.94740438257612, "text": "\n[Learn more](https://cloud.ibm.com/docs/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidencecd-devsecops-cos-bucket-resiliency).\n\n\n\n\n\n Naming your bucket \n\nCloud Object Storage object names consist of the following components:\n\n{NAMESPACE} / {PIPELINE_RUN_ID} / {TYPE} / {FILE_NAME} _ {HASH}\n\n\n\n Examples: \n\nci/48decaa9-9042-498f-b58d-3577e0ac0158/evidences/build-vulnerability-advisor.json_362c06afa88b3f304878f0d0979e834f\n\nci/48decaa9-9042-498f-b58d-3577e0ac0158/artifacts/app-image-va-report.json_b3f30487f0d0979e834f362c06afaaa8\n\nThe name component {NAMESPACE} / {PIPELINE_RUN_ID} / {TYPE} is useful as a prefix when you're looking for collected data from a certain pipeline run.\n\n\n\n\n\n Retention policy \n\nYou can set Cloud Object Storage buckets to enforce a retention policy or period for uploaded objects, otherwise known as [Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable). Immutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a Write-One-Read-Many (WORM), non-erasable, and non-rewritable manner. You cannot change or delete objects in protected buckets within the retention period, or delete protected buckets with objects themselves until the retention period is over. The policy is enforced until the end of a retention period and the removal of any legal holds.\n\nIt is recommended that teams set a retention policy for the buckets that are used as their evidence locker that stores every object for a minimum of 365 days.\n\n\n\n\n\n\n\n Audit event log", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidence"}, {"document_id": "ibmcld_05010-7-1832", "score": 11.94662415837054, "text": "\nFAQ - General \n\nFrequently asked questions can produce helpful answers and insight into best practices for working with IBM Cloud\u00ae Object Storage.\n\n\n\n How can I find out the total size of my bucket by using the API? \n\nYou can use the [Resource Configuration API](https://cloud.ibm.com/apidocs/cos/cos-configurationreturns-metadata-for-the-specified-bucket) to get the bytes used for a given bucket.\n\n\n\n\n\n How can I view my buckets? \n\nYou can view and navigate your buckets using the console, CLI or the API.\n\nFor example, the CLI command ibmcloud cos buckets will list all buckets associated with the targeted service instance.\n\n\n\n\n\n Can I migrate data from AWS S3 into IBM Cloud Object Storage? \n\nYes, you can use your existing tools to read and write data into IBM Cloud Object Storage. You need to configure HMAC credentials allow your tools to authenticate. Not all S3-compatible tools are currently unsupported. For details, see [Using HMAC credentials](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-uhc-hmac-credentials-main).\n\n\n\n\n\n Can I use AWS S3 SDKs with IBM Cloud Object Storage? \n\nYes, IBM COS SDKs are based on the official AWS S3 API SDKs, but are modified to use IBM Cloud features, such as IAM, Key Protect, Immutable Object Storage, and others. When using these SDKs, use HMAC authorization and an explicit endpoint. For details, see [About IBM COS SDKs](https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-sdk-about).\n\n\n\n\n\n Is there a 100-bucket limit to an account? What happens if I need more? \n\nYes, 100 is the current bucket limit. Generally, prefixes are a better way to group objects in a bucket, unless the data needs to be in a different region or storage class. For example, to group patient records, you would use one prefix per patient.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-faq"}, {"document_id": "ibmcld_04866-4961-6763", "score": 11.79347975552575, "text": "\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https://www.ecfr.gov/cgi-bin/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https://www.finra.org/rules-guidance/rulebooks/finra-rules/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01468-7-2067", "score": 24.68102002505224, "text": "\nManaging quota limits for storage and pull traffic \n\nYou can limit the amount of storage and pull traffic that can be used in your IBM Cloud account by setting and managing custom quota limits in IBM Cloud\u00ae Container Registry.\n\n\n\n Setting quota limits for storing and pulling images \n\nYou can limit the amount of storage and pull traffic to your private images by setting your own quota limits.\n\nWhen you upgrade to the IBM Cloud Container Registry standard plan, you benefit from unlimited amount of storage and pull traffic to your private images. To avoid exceeding your preferred payment level, you can set individual quotas for the amount of storage and pull traffic. Quota limits are applied to all\n\nnamespacesthat you set up in IBM Cloud Container Registry. If you're using the free service plan, you can also set custom quotas within your free amount of storage and pull traffic.\n\nTo set a quota, complete the following steps.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Review your current quota limits for storage and pull traffic.\n\nibmcloud cr quota\n\nYour output looks similar to the following example.\n\nGetting quotas and usage for the current month, for account '<account_owner> Account'...\n\nQUOTA LIMIT USED\nPull traffic 5.1 GB 0 B\nStorage 512 MB 511 MB\n\nOK\n3. Change the quota limit for storage and pull traffic. To change the pull traffic usage, specify the traffic option, and replace <traffic_quota> with the value in megabytes that you want to set for the pull traffic quota. If you want to change the amount of storage in your account, specify the storage option, and replace <storage_quota> with the value in megabytes that you want to set.\n\nIf you are on the free plan, you cannot set your quota to an amount that exceeds the free tier. The free tier allowance for storage is 512 MB and traffic is 5120 MB.\n\nibmcloud cr quota-set --traffic <traffic_quota> --storage <storage_quota>\n\nExample to set your quota limit for storage to 600 megabytes, and the pull traffic to 7000 megabytes:\n\nibmcloud cr quota-set --storage 600 --traffic 7000", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_quota"}, {"document_id": "ibmcld_01468-1672-3502", "score": 22.19919668292274, "text": "\nIf you are on the free plan, you cannot set your quota to an amount that exceeds the free tier. The free tier allowance for storage is 512 MB and traffic is 5120 MB.\n\nibmcloud cr quota-set --traffic <traffic_quota> --storage <storage_quota>\n\nExample to set your quota limit for storage to 600 megabytes, and the pull traffic to 7000 megabytes:\n\nibmcloud cr quota-set --storage 600 --traffic 7000\n\n\n\n\n\n\n\n Reviewing quota limits and usage \n\nYou can review your quota limits and check your current storage and pull traffic usage for your account.\n\n\n\n1. Log in to IBM Cloud.\n\nibmcloud login\n2. Review your current quota limits for storage and pull traffic.\n\nibmcloud cr quota\n\nYour output looks similar to the following example.\n\nGetting quotas and usage for the current month, for account '<account_owner> Account'...\n\nQUOTA LIMIT USED\nPull traffic 5.1 GB 0 B\nStorage 512 MB 511 MB\n\nOK\n\n\n\n\n\n\n\n Staying within quota limits \n\nIf you exceed the quota limits that are set for your IBM Cloud account, you can free up storage and change your service plan or quota limits so that you can continue pushing and pulling images to and from your namespace.\n\nFrom 1 February 2022, both [tagged](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_tag) and [untagged](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images are charged for.\n\nTo free up image storage in your IBM Cloud account, complete the following steps.\n\nDepending on the size of the image, it might take a while for the image to be removed and for the storage to be available.\n\n\n\n1. Find the names of the images that you want to remove.\n\n\n\n* To list only tagged images, run the [ibmcloud cr image-list](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregclibx_cr_image_list) command.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_quota"}, {"document_id": "ibmcld_04340-46955-48852", "score": 19.475821915445838, "text": "\n: (Optional) Check whether the use of public connections is prevented for image pushes or pulls in your account.\n\n\n\n\n\n Example \n\nPrevent image pulls or pushes over public network connections for your account.\n\nibmcloud cr private-only --enable\n\n\n\n\n\n\n\n ibmcloud cr quota \n\nDisplays your current quotas for traffic and storage, and usage information against those quotas for the registry region that you're targeting.\n\nibmcloud cr quota\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for configuring Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n\n\n ibmcloud cr quota-set \n\nModify the specified quota for the registry region that you're targeting.\n\nibmcloud cr quota-set [--traffic TRAFFIC] [--storage STORAGE]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for configuring Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n Command options \n\n--traffic TRAFFIC\n: (Optional) Changes your traffic quota to the specified value in megabytes. The operation fails if you are not authorized to set traffic, or if you set a value that exceeds your current pricing plan.\n\n--storage STORAGE\n: (Optional) Changes your storage quota to the specified value in megabytes. The operation fails if you are not authorized to set storage quotas, or if you set a value that exceeds your current pricing plan.\n\n\n\n\n\n Example \n\nSet your quota limit for pull traffic to 7000 megabytes and storage to 600 megabytes.\n\nibmcloud cr quota-set --traffic 7000 --storage 600\n\n\n\n\n\n\n\n ibmcloud cr region \n\nDisplays the targeted region and the registry.\n\nibmcloud cr region\n\nFor more information, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n\n\n\n Prerequisites \n\nNone\n\n\n\n\n\n\n\n ibmcloud cr region-set", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-containerregcli"}, {"document_id": "ibmcld_01329-48362-50241", "score": 18.547668686292923, "text": "\nibmcloud cr quota-set [--traffic TRAFFIC] [--storage STORAGE]\n\n\n\n Prerequisites \n\nTo find out about the required permissions, see [Access roles for configuring Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iamaccess_roles_configure).\n\n\n\n\n\n Command options \n\n--traffic TRAFFIC\n: (Optional) Changes your traffic quota to the specified value in megabytes. The operation fails if you are not authorized to set traffic, or if you set a value that exceeds your current pricing plan.\n\n--storage STORAGE\n: (Optional) Changes your storage quota to the specified value in megabytes. The operation fails if you are not authorized to set storage quotas, or if you set a value that exceeds your current pricing plan.\n\n\n\n\n\n Example \n\nSet your quota limit for pull traffic to 7000 megabytes and storage to 600 megabytes.\n\nibmcloud cr quota-set --traffic 7000 --storage 600\n\n\n\n\n\n\n\n ibmcloud cr region \n\nDisplays the targeted region and the registry.\n\nibmcloud cr region\n\nFor more information, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n\n\n\n Prerequisites \n\nNone\n\n\n\n\n\n\n\n ibmcloud cr region-set \n\nSet a target region for the IBM Cloud Container Registry commands. To list the available regions, run the command with no options.\n\nibmcloud cr region-set [REGION]\n\n\n\n Prerequisites \n\nNone\n\n\n\n\n\n Command options \n\nREGION\n: (Optional) The name of your target region, for example, us-south. For more information, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n\n\n\n\n\n Example \n\nTarget the US South region.\n\nibmcloud cr region-set us-south\n\n\n\n\n\n\n\n ibmcloud cr retention-policy-list \n\nList the image retention policies for your account. Image retention policies retain the specified number of images for each repository within a namespace in IBM Cloud Container Registry.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_00348-11019-12529", "score": 18.52610088484854, "text": "\n\"Total number of megabytes transferred between the Edge to the end user in the region - Australasia\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - EMEA\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - India\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Japan\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - North America\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Rest Of APAC\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - South America\"\n],\n\"totals\": [\n15, // Total Hits from start time to end time.\n4.9301e-5, // Total Bandwidth from start time to end time.\n0, // Hits by type 0XX\n0, // Hits by type 200\n0, // Hits by type 206\n0, // Hits by type 2XX\n0, // Hits by type 302\n0, // Hits by type 304\n0, // Hits by type 3XX\n0, // Hits by type 404\n13, // Hits by type 4XX\n2, // Hits by type 5XX\n0, // Hits by type Other\n0, // Bandwidth by region Australasia\n3.6554e-5, // Bandwidth by region EMEA\n0, // Bandwidth by region India\n0, // Bandwidth by region Japan\n1.1524e-5, // Bandwidth by region North America\n1.223e-6, // Bandwidth by region Rest Of APAC\n0 // Bandwidth by region South America\n],\n\"percentage\": [ // The percentage of the bandwidth by regions\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\nnull,\n0, // Australasia", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-code-examples-using-the-cdn-api"}, {"document_id": "ibmcld_00348-10050-11511", "score": 18.486024584392197, "text": "\n\"type\": \"INTEGRATED\",\n\"names\": [\n\"TotalHits\",\n\"TotalBandwidth\",\n\"0XX\",\n\"200\",\n\"206\",\n\"2XX\",\n\"302\",\n\"304\",\n\"3XX\",\n\"404\",\n\"4XX\",\n\"5XX\",\n\"Other\",\n\"Australasia\",\n\"EMEA\",\n\"India\",\n\"Japan\",\n\"North America\",\n\"Rest Of APAC\",\n\"South America\"\n],\n\"descriptions\": [\n\"All hits to the Edge servers from the end-users.\",\n\"Total number of megabytes transferred between the Edge to the end user.\",\n\"Number of hits that returned response code - 0XX\",\n\"Number of hits that returned response code - 200\",\n\"Number of hits that returned response code - 206\",\n\"Number of hits that returned response code - 2XX\",\n\"Number of hits that returned response code - 302\",\n\"Number of hits that returned response code - 304\",\n\"Number of hits that returned response code - 3XX\",\n\"Number of hits that returned response code - 404\",\n\"Number of hits that returned response code - 4XX\",\n\"Number of hits that returned response code - 5XX\",\n\"Number of hits that returned response code not within 2XX to 5XX\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Australasia\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - EMEA\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - India\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - Japan\",\n\"Total number of megabytes transferred between the Edge to the end user in the region - North America\",", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-code-examples-using-the-cdn-api"}, {"document_id": "ibmcld_04360-2697-3466", "score": 16.77665266533915, "text": "\nibmcloud billing enterprise-usage [--account-group ACCOUNT_GROUP_NAME | --account-group-id ACCOUNT_GROUP_ID | --account ACCOUNT_NAME | --account-id ACCOUNT_ID] [--month MONTH] [--children] [--output FORMAT] [-q, --quiet]\n\n\n\n Command options \n\n--account ACCOUNT_NAME (optional)\n: Name of target account.\n\n--account-id ACCOUNT_ID (optional)\n: ID of target account.\n\n--account-group ACCOUNT_GROUP_NAME (optional)\n: Name of target account group.\n\n--account-group-id ACCOUNT_GROUP_ID (optional)\n: ID of target account group.\n\n--children (optional)\n: Show children usage reports.\n\n--month MONTH (optional)\n: Target month. Default to current month.\n\n--output FORMAT (optional)\n: Specify output format. Only JSON is supported.\n\n-q, --quiet (optional)\n: Suppress verbose output.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_billing"}, {"document_id": "ibmcld_11421-1359-2601", "score": 16.47771703280899, "text": "\nVOLUME GROUP: rootvg VG IDENTIFIER: 00f6db0a00004c000000016b94f02\nVG STATE: active PP SIZE: 32 megabyte(s)\nVG PERMISSION: read/write TOTAL PPs: 639 (20448 megabytes)\nMAX LVs: 256 FREE PPs: 477 (15264 megabytes)\nLVs: 12 USED PPs: 162 (5184 megabytes)\nOPEN LVs: 11 QUORUM: 2 (Enabled)\nTOTAL PVs: 1 VG DESCRIPTIORS: 2\nSTALE PVs: 0 STALE PPs: 0\nACTIVE PVs: 1 AUTO ON: yes\nMAX PPs per VG: 32512\nMAX PPs per PV: 1016 MAX PVs: 32\nLTG size(Dynamic): 512 kilobyte(s) AUTO SYNC: no\nHOT SPARE: no BB POLICY: relocatable\nPV RESTRICTION: none INFINITE RETRY: no\nDISK BLOCK SIZE: 512 CRITICAL VG: no\nFS SYNC OPTION: no CRITICAL PVs: no\n\nShow more\n\nRunning the df -g command displays information about the total space and available space on a file system. In this instance, the rootvg volume group has enough space for creating a new file system, expanding an existing one, and storing the mksysb source image.\n\nThe storage information is shown as follow:\n\n df -g\nFilesystem GB blocks Free %Used Iused %Iused Mounted on\n/dev/hd4 0.09 0.06 41% 2619 17% /\n/dev/hd2 2.16 0.26 89% 36565 37% /usr\n/dev/hd9var 0.19 0.16 17% 953 3% /var\n/dev/hd3 0.22 0.22 1% 33 1% /tmp\n/dev/hd1 0.03 0.03 2% 7 1% /home\n/dev/hd11admin 0.12 0.12 1% 5 1% /admin\n/proc - - - - - /proc", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-restoring-aix-mksysb-image"}, {"document_id": "ibmcld_04360-1365-3035", "score": 16.285154662175835, "text": "\nibmcloud billing resource-group-usage \n\nShow monthly usage for a resource group (account admin or resource group admin only):\n\nibmcloud billing resource-group-usage GROUP_NAME [-d YYYY-MM] [--output FORMAT] [-q, --quiet]\n\n\n\n Command options \n\nGROUP_NAME (required)\n: Name of the resource group.\n\n-d MONTH_DATE (optional)\n: Display data for the month and date that is specified by using the YYYY-MM format. If not specified, usage of the current month is shown.\n\n--output FORMAT (optional)\n: Specify output format. Only JSON is supported.\n\n-q, --quiet (optional)\n: Suppress verbose output.\n\n\n\n\n\n\n\n ibmcloud billing resource-instances-usage \n\nShow monthly resource instances usage under the current account:\n\nibmcloud billing resource-instances-usage [-o ORG] [-g RESOURCE_GROUP] [-d YYYY-MM] [--output FORMAT] [-q, --quiet]\n\n\n\n Command options \n\n-o ORG_NAME (optional)\n: Filter instances by organization.\n\n-g GROUP_NAME\n: Filter instance by resource group.\n\n-d MONTH_DATE (optional)\n: Display data for month and date that is specified by using the YYYY-MM format. If not specified, usage of the current month is shown.\n\n--output FORMAT (optional)\n: Specify output format. Accepted inputs are JSON and CSV.\n\n-q, --quiet (optional)\n: Suppress verbose output.\n\n\n\n\n\n\n\n ibmcloud billing enterprise-usage \n\nShow enterprise usage reports:\n\nibmcloud billing enterprise-usage [--account-group ACCOUNT_GROUP_NAME | --account-group-id ACCOUNT_GROUP_ID | --account ACCOUNT_NAME | --account-id ACCOUNT_ID] [--month MONTH] [--children] [--output FORMAT] [-q, --quiet]\n\n\n\n Command options \n\n--account ACCOUNT_NAME (optional)\n: Name of target account.\n\n--account-id ACCOUNT_ID (optional)", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_billing"}, {"document_id": "ibmcld_06110-19432-20896", "score": 16.257256515520957, "text": "\nParameters: ibm.io/chunk-size-mb=16,ibm.io/curl-debug=false,ibm.io/debug-level=warn,ibm.io/iam-endpoint=https://iam.bluemix.net,ibm.io/kernel-cache=true,ibm.io/multireq-max=20,ibm.io/object-store-endpoint=https://s3-api.dal-us-geo.objectstorage.service.networklayer.com,ibm.io/object-store-storage-class=us-standard,ibm.io/parallel-count=2,ibm.io/s3fs-fuse-retry-count=5,ibm.io/stat-cache-size=100000,ibm.io/tls-cipher-suite=AESGCM\nAllowVolumeExpansion: <unset>\nMountOptions: <none>\nReclaimPolicy: Delete\nVolumeBindingMode: Immediate\nEvents: <none>\n\nibm.io/chunk-size-mb\n: The size of a data chunk that is read from or written to IBM Cloud Object Storage in megabytes. Storage classes with perf in their name are set up with 52 megabytes. Storage classes without perf in their name use 16 megabyte chunks. For example, if you want to read a file that is 1GB, the plug-in reads this file in multiple 16 or 52-megabyte chunks.\n\nibm.io/curl-debug\n: Enable the logging of requests that are sent to the IBM Cloud Object Storage service instance. If enabled, logs are sent to syslog and you can [forward the logs to an external logging server](https://cloud.ibm.com/docs/containers?topic=containers-healthlogging). By default, all storage classes are set to false to disable this logging feature.\n\nibm.io/debug-level\n: The logging level that is set by the IBM Cloud Object Storage plug-in. All storage classes are set up with the WARN logging level.\n\nibm.io/iam-endpoint", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-storage_cos_install"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13162-7-1878", "score": 21.81662288668367, "text": "\nBuild a data lake using object storage \n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n\n\n Objectives \n\n\n\n* Use Object Storage to store raw data files\n* Query data directly from Object Storage using Data Engine (previously SQL Query)\n* Refine and analyze data in IBM Watson\u00ae Studio\n\n\n\nZoom\n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution29/Smart-Data-Lake-Architecture.png)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. Raw data is stored on Object Storage.\n2. Data is reduced, enhanced or refined with Data Engine.\n3. Data analysis occurs in Watson Studio.\n4. Non-technical users access data through application(s).\n5. Refined data is pulled from Object Storage.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI.\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools you can use the [Cloud Shell](https://cloud.ibm.com/shell) from the IBM Cloud console.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake"}, {"document_id": "ibmcld_16729-11586-13439", "score": 21.096899980034618, "text": "\n* 15 minutes\n* 2023-01-31\n\n\n\n[Build a data lake using object storage](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\nBlockchain[Setting up multiregion High Availability (HA) deployments for the ordering service](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-hadr-mr-os)Setting up multiregion High Availability (HA) deployments for the ordering service\n\nIn this tutorial, you learn how to set up a Raft ordering service with five ordering nodes that span multiple regions for maximum high availability.\n\nIBM Blockchain Platform\n\n\n\n* 2023-02-17\n\n\n\n[Using certificates from an external Certificate Authority](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-tutorial-extca)Using certificates from an external Certificate Authority\n\nIn this tutorial, you learn how to use certificates that were generated by an external Certificate Authority (CA) with your IBM\u00ae Blockchain Platform network. After you gather the required certificates for a peer or ordering node, you build a Membership Service Provider (MSP) definition that is used by your blockchain components.\n\nIBM Blockchain Platform\n\n\n\n* 30 minutes\n* 2023-02-17", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_16728-5097-7108", "score": 20.567938352084557, "text": "\n[solution icon](https://cloud.ibm.com/media/docs/images/homepage/magic-wand.svg) [Best practices for organizing users, teams, applications](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applications)Best practices for organizing users, teams, applications Solution tutorial\n\nThis tutorial gives an overview of the concepts available in IBM Cloud for identity and access management and how they can be implemented to support the multiple development stages of an application.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Bring Your Own IP Address](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-byoip)Bring Your Own IP Address Solution tutorial\n\nThis tutorial presents a brief overview of BYOIP implementation patterns that can be used with IBM Cloud and a decision tree for identifying the appropriate pattern when realizing the secure enclosure as described in the Isolate workloads with a secure private network tutorial. Setup may require additional input from your onsite network team, IBM Cloud technical support or IBM Services.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Build a data lake using object storage](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage Solution tutorial\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs?tab=solutions"}, {"document_id": "ibmcld_16728-6533-8457", "score": 20.450615197958594, "text": "\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Build a database-driven Slackbot](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson)Build a database-driven Slackbot Solution tutorial\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Build, deploy, test and monitor a predictive machine learning model](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model)Build, deploy, test and monitor a predictive machine learning model Solution tutorial\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs?tab=solutions"}, {"document_id": "ibmcld_16729-326786-328759", "score": 20.090407044266602, "text": "\nVirtual Private Cloud (VPC) Log Analysis\n\n+6\n\nActivity Tracker hosted event search,Secrets Manager,App ID,Key Protect,Hyper Protect Crypto Services,Object Storage\n\n\n\n* 1 hour\n* 2023-05-05\n\n\n\n[Serverless web application and API with Code Engine](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-serverless-webapp)Serverless web application and API with Code Engine\n\nIn this tutorial, you will create a serverless web application using a bucket in Object Storage and implementing the application backend using IBM Cloud Code Engine and IBM Cloudant as JSON document database.\n\nCode Engine Cloudant\n\n+1\n\nObject Storage\n\n\n\n* 1 hour\n* 2023-06-16\n\n\n\n[Build a data lake using object storage](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake)Build a data lake using object storage\n\nDefinitions of the term data lake vary, but in the context of this tutorial, a data lake is an approach to storing data in its native format for organizational use. To that end, you will create a data lake for your organization using Object Storage. By combining Object Storage and Data Engine, data analysts can query data where it lies using Structured Query Language (SQL). You'll also leverage the Data Engine (previously SQL Query) service in a Jupyter Notebook to conduct a simple analysis. When you're done, allow non-technical users to discover their own insights.\n\nObject Storage Data Engine\n\n\n\n* 1 hour\n* 2023-06-14\n\n\n\n[Accelerate delivery of static files using a CDN](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-static-files-cdn)Accelerate delivery of static files using a CDN\n\nThis tutorial walks you through how to host and serve website assets (images, videos, documents) and user generated content in a IBM Cloud Object Storage, and how to use a IBM\u00ae Content Delivery Network (CDN) for fast and secure delivery to users around the world.\n\nContent Delivery Network (CDN) Object Storage\n\n\n\n* 2 hours", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_16657-0-905", "score": 19.980186680539305, "text": "\n\n\n\n\n\n\n  Release notes for watsonx.data \n\nUse these release notes to learn about the latest updates to IBM\u00ae watsonx.data that are grouped by date.\n\n\n\n  7 July 2023 \n\nwatsonx.data is a new open architecture that combines the elements of the data warehouse and data lake models. The best-in-class features and optimizations available on the watsonx.data make it an optimal choice for next generation data analytics and automation. In the first release (watsonx.data 1.0.0), the following features are supported:\n\n\n\n*  Creating, scaling, pausing, resuming, and deleting the Presto query engine\n*  Associating and dissociating a catalog with an engine\n*  Exploring catalog objects\n*  Adding and deleting a database-catalog pair\n*  Updating database credentials\n*  Adding and deleting bucket-catalog pair\n*  Exploring bucket objects\n*  Loading data\n*  Exploring data\n*  Querying data\n*  Query history\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-release"}, {"document_id": "ibmcld_13497-1510-3518", "score": 19.530439909428388, "text": "\nExisting instances still work but will be fully deprecated on 31 October.\n\n\n\n\n\n May 2022 \n\nRebranding\n: IBM Cloud SQL Query was rebranded to IBM Cloud Data Engine.\n\nHive\n: Data Engine provides an external [Hive metastore (HMS) service](https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore).\n\n\n\n\n\n November 2021 \n\nAdd columns to Catalog tables\n: You can add columns to existing Catalog tables with the newly supported ALTER TABLE ... ADD COLUMNS statement.\n\n\n\n\n\n July 2021 \n\nStream landing tutorial\n: A detailed [getting started tutorial](https://www.ibm.com/cloud/blog/stream-landing-from-event-streams-kafka-service-to-ibm-cloud-data-lake-on-object-storage) for stream landing with Data Engine is now available.\n\nNew region for stream landing\n: The stream landing capability is now also available in Frankfurt, in addition to Dallas.\n\n\n\n\n\n June 2021 \n\nStream landing support\n: Data Engine now supports stream landing that enables you to stream your data in real time from a topic to a bucket of your choice. This capability enables efficient analytics on the new objects created.\n\nConnect to data lakes with Cloud Pak for Data\n: IBM Cloud Pak\u00ae for Data now comes with an integrated connector to Data Engine that allows to connect to cloud data lakes and import data assets into projects and catalogs in Cloud Pak for Data. For more information, see [Connecting to a Cloud Data Lake with IBM Cloud Pak for Data](https://www.ibm.com/cloud/blog/connecting-to-a-cloud-data-lake-with-ibm-cloud-pak-for-data).\n\n\n\n\n\n December 2020 \n\nSupported regions\n: Data Engine is available in Chennai, India. When you provision new instances, you can select whether it is being provisioned in Dallas, Frankfurt, or Chennai.\n\nIBM Cloud Object Storage\n: IBM Cloud Object Storage web console discovers SQL-queryable objects and folders and directly starts the Data Engine web console with a prefilled SQL statement for seamless interactive data exploration.\n\n\n\n\n\n November 2020 \n\nModify location of Hive partitions", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-query-relnotes"}, {"document_id": "ibmcld_09978-4314-6065", "score": 19.339956529009864, "text": "\n* Automatic pause and resume is enabled in the web console.\n\n\n\n\n\n\n\n Components \n\n\n\n* Netezza Performance Server 11.2.2.5\n* Web console 4.0.11\n\n\n\n\n\n\n\n Known issues \n\nIf a common table expression or derived table query contains column names or column aliases, which begin with an underscore, Netezza Performance Server deletes these columns in the query result set.\nIf there are no columns to display, Netezza Performance Server returns the following error.\n\nERROR: No columns are selected due to column alias begin with underscore\n\nExample:\n\ncreate table t1 ( c1 int , c2 int);\nCREATE TABLE\nwith tab1 as ( select c1 as _c1 , c2 as _c2 from t1 ) select tab1.* from tab1; ERROR: No columns are selected due to column alias begin with underscore\nselect tab1.* from ( select c1 as _c1 , c2 as _c2 from t1 ) as tab1; ERROR: No columns are selected due to column alias begin with underscore\n\n\n\n\n\n\n\n July 2022 \n\nAs of July 28, 2022, you can access data from data lakes and move data between applications with Kafka.\n\n\n\n New features \n\n\n\n* Use the technology preview of the Netezza Performance Server external tables to access and query parquet files that are stored outside of your database in data lakes (on AWS S3). For more information, see [Querying data from data lakes](https://cloud.ibm.com/docs/netezza?topic=netezza-overview_singularity).\n* Use Netezza Performance Server as a data source or data sink. For more information, see [Using Netezza Performance Server as a data source](https://cloud.ibm.com/docs/netezza?topic=netezza-netezzakafkadatasourcekafka) and [Using Netezza Performance Server as a data sink](https://cloud.ibm.com/docs/netezza?topic=netezza-netezzakafkadatasinkkafka).\n\n\n\n\n\n\n\n Known issues \n\ndatasource is a reserved keyword now.", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-my-service-relnotes"}, {"document_id": "ibmcld_09984-0-1283", "score": 19.042390998615748, "text": "\n\n\n\n\n\n\n  Overview \n\nData lakes are an essential tool for storing structured and unstructured data on the cloud. With IBM\u00ae Netezza\u00ae Performance Server for IBM Cloud Pak\u00ae for Data as a Service, you can use external tables to access parquet files that are stored outside of your database in data lakes (on AWS S3). Also, you can analyze this data by using the robust and massively parallel Netezza Performance Server execution engine.\n\nExternal data sources use connection strings to specify how you can access an external system. Each connection string describes where your data is placed and how to authenticate to your data source. Each external data source has a definition (schema), but the actual data exists external to the Netezza Performance Server database.\n\nYou cannot backup (nzbackup) and restore (nzrestore) external data source objects.\n\nUse cases for external data source include:\n\n\n\n*  [Running queries against parquet data that is stored in a data lake](https://cloud.ibm.com/docs/netezza?topic=netezza-querying_singularity).\n*  [Ingesting data into Netezza Performance Server](https://cloud.ibm.com/docs/netezza?topic=netezza-ingest_singularity).\n*  [Querying both local and remote data](https://cloud.ibm.com/docs/netezza?topic=netezza-merging_singularity).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-overview_singularity"}, {"document_id": "ibmcld_13162-2830-4436", "score": 18.834085044040876, "text": "\nCreate an instance of [Object Storage](https://cloud.ibm.com/catalog/services/cloud-object-storage). If you already have Object Storage instance with a lite plan, use standard instead of lite.\n\nibmcloud resource service-instance-create data-lake-cos cloud-object-storage lite global\n4. Create an instance of [Data Engine](https://cloud.ibm.com/catalog/services/sql-query). Replace us-south by your region, if needed. If you already have Data Engine instance with a lite plan, use standard instead of lite.\n\nibmcloud resource service-instance-create data-lake-sql sql-query lite us-south\n5. Create an instance of [Watson Studio](https://cloud.ibm.com/catalog/services/watson-studio).\n\nibmcloud resource service-instance-create data-lake-studio data-science-experience free-v1 us-south\n6. Create an API key for service access. Copy the output to a secure, permanent location for later use.\n\nibmcloud iam api-key-create data-lake-cos-key --output json\n\n\n\n\n\n\n\n Step 2: Uploading data \n\nIn this section, you will upload data to an Object Storage bucket. You can do this using regular http upload or by utilising the built-in Cloud High-Speed Transfer Service. Cloud High-Speed Transfer Service protects data as it is uploaded to the bucket and [can greatly reduce transfer time](https://www.ibm.com/cloud/blog/announcements/ibm-cloud-object-storage-simplifies-accelerates-data-to-the-cloud).\n\n\n\n1. Download the [City of Los Angeles / Traffic Collision Data from 2010](https://data.lacity.org/api/views/d5tf-ez2w/rows.csv?accessType=DOWNLOAD) CSV file. The file is 81MB and may take a few minutes to download.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-smart-data-lake"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01441-1679-3819", "score": 24.06808445597745, "text": "\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4"}, {"document_id": "ibmcld_01442-1679-3832", "score": 24.039757512481557, "text": "\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}, {"document_id": "ibmcld_01441-7-2257", "score": 21.6803567144131, "text": "\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4"}, {"document_id": "ibmcld_01442-7-2257", "score": 21.6803567144131, "text": "\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}, {"document_id": "ibmcld_01329-58331-60199", "score": 21.095022140923895, "text": "\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_01533-4-2366", "score": 20.76130734634401, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4-2366", "score": 20.76130734634401, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01471-5654-7396", "score": 20.251818213047365, "text": "\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4 to run the ibmcloud cr va, ibmcloud cr image-list, or ibmcloud cr image-digests commands, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nFor more information about Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout). For more information about Vulnerability Advisor API 4, see [Vulnerability Advisor 4 for IBM Cloud Container Registry](https://cloud.ibm.com/apidocs/container-registry/va-v4).\n\nNew commands for setting and checking the Vulnerability Advisor version are available from Container Registry plug-in 1.0.0\n: From Container Registry plug-in 1.0.0, you can use new commands to check and set Vulnerability Advisor versions.\n\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4, you can set the version by running the [ibmcloud cr va-version-set](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_va_version_set) command.\n\nFor more information about setting the version by using the ibmcloud cr va-version-set command, see [ibmcloud cr va-version-set](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_va_version_set) and [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nTo find out which version of Vulnerability Advisor that you're running, see [ibmcloud cr va-version](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_va_version).\n\n\n\n\n\n 3 August 2022", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_release_notes"}, {"document_id": "ibmcld_01533-10805-12534", "score": 20.222130037500808, "text": "\nRed Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support. [Ubuntu CVE Tracker](https://launchpad.net/ubuntu-cve-tracker). \n\n\n\n\n\n\n\n Configuration issues - version 3 only \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nConfiguration issues are potential security issues that are related to how an\n\nappis set up. Configuration issues are not supported in version 4.\n\nMany of the reported problems can be fixed by updating your\n\nDockerfile.\n\nImages are scanned only if they are using an operating system that is supported by Vulnerability Advisor. Vulnerability Advisor checks the configuration settings for the following types of apps:\n\n\n\n* MySQL\n* NGINX\n* Apache\n\n\n\n\n\n\n\n\n\n Setting the Vulnerability Advisor version \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nStarting from version 1.0.0 of the Container Registry plug-in, you can choose whether to fetch results from either version 3, v3 (the default), or version 4, v4, of Vulnerability Advisor for the following commands:\n\n\n\n* [ibmcloud cr va IMAGE](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregclibx_cr_va), where IMAGE is the name of the image.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-10857-12586", "score": 20.222130037500808, "text": "\nRed Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support. [Ubuntu CVE Tracker](https://launchpad.net/ubuntu-cve-tracker). \n\n\n\n\n\n\n\n Configuration issues - version 3 only \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nConfiguration issues are potential security issues that are related to how an\n\nappis set up. Configuration issues are not supported in version 4.\n\nMany of the reported problems can be fixed by updating your\n\nDockerfile.\n\nImages are scanned only if they are using an operating system that is supported by Vulnerability Advisor. Vulnerability Advisor checks the configuration settings for the following types of apps:\n\n\n\n* MySQL\n* NGINX\n* Apache\n\n\n\n\n\n\n\n\n\n Setting the Vulnerability Advisor version \n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nStarting from version 1.0.0 of the Container Registry plug-in, you can choose whether to fetch results from either version 3, v3 (the default), or version 4, v4, of Vulnerability Advisor for the following commands:\n\n\n\n* [ibmcloud cr va IMAGE](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregclibx_cr_va), where IMAGE is the name of the image.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10534-1033-2260", "score": 37.116878278239156, "text": "\n[Understanding Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewoverview)\n\n\n\n* [What is Red Hat OpenShift on IBM Cloud and how does it work?](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewwhat-is-overview)\n* [What is Kubernetes?](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewwhat-is-kube-overview)\n* [What are containers?](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewwhat-are-containers-overview)\n* [What is Red Hat OpenShift?](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewwhat-is-openshift-overview)\n* [What compute host infrastructure does the service offer?](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewwhat-compute-infra-is-offered)\n* [Related resources](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewkubernetes-resources)\n\n\n\n[Benefits and service offerings](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_07578-394005-396150", "score": 36.446512905836855, "text": "\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-393979-396124", "score": 36.446512905836855, "text": "\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_10154-7-1896", "score": 36.14547948816795, "text": "\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https://www.ibm.com/products/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}, {"document_id": "ibmcld_10214-7-1980", "score": 35.39607031482295, "text": "\nFAQs \n\nReview frequently asked questions (FAQs) for using Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\n\n\n How does Red Hat OpenShift on IBM Cloud work? \n\nWith Red Hat OpenShift on IBM Cloud, you can create your own Red Hat OpenShift cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov).\n\n\n\n\n\n Why should I use Red Hat OpenShift on IBM Cloud? \n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-faqs"}, {"document_id": "ibmcld_10214-1438-3413", "score": 32.69342452167289, "text": "\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits).\n\n\n\n\n\n What container platforms are available for my cluster? \n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform. If you want to use multiple container platforms, create a separate cluster for each.\n\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https://kubernetes.io/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-faqs"}, {"document_id": "ibmcld_05707-7-2073", "score": 31.654486059426716, "text": "\nBenefits and service offerings \n\n[IBM Cloud\u00ae Kubernetes Service](https://www.ibm.com/cloud/kubernetes-service) delivers powerful tools by combining Docker containers, the Kubernetes technology, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts. For more information about certification, see [Compliance on the IBM Cloud](https://www.ibm.com/cloud/compliance).\n\n\n\n Benefits of using the service \n\nClusters are deployed on compute hosts that provide native Kubernetes and IBM-specific capabilities.\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud. For more information, see Comparison between [Red Hat OpenShift](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovopenshift_kubernetes) and community Kubernetes clusters.\n\nSingle-tenant Kubernetes clusters with compute, network, and storage infrastructure isolation\n: Create your own customized infrastructure that meets the requirements of your organization.\n: Choose between [IBM Cloud Classic or VPC infrastructure providers](https://cloud.ibm.com/docs/containers?topic=containers-infrastructure_providers).\n: Provision a dedicated and secured Kubernetes master, worker nodes, virtual networks, and storage by using the resources provided by IBM Cloud infrastructure.\n: Fully managed Kubernetes master that is continuously monitored and updated by IBM to keep your cluster available.\n: Option to provision worker nodes as bare metal servers for compute-intensive workloads such as data, GPU, and AI.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_ov"}, {"document_id": "ibmcld_10534-1903-3343", "score": 31.202153527006192, "text": "\n[Benefits and service offerings](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes)\n* [Comparison between clusters that run in IBM Cloud and standard OCP](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovcompare_ocp)\n\n\n\n[Supported infrastructure providers](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersinfrastructure_providers)\n\n\n\n* [Virtual Private Cloud (VPC)](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersvpc-gen2-infra-overview)\n* [Satellite](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providerssatellite-infra-overview)\n* [Classic](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersclassic-infra-overview)\n* [Troubleshooting and support](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersinfra-troubleshoot)\n\n\n\n[Your responsibilities with using Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-responsibilities_iksresponsibilities_iks)\n\n\n\n* [Overview of shared responsibilities](https://cloud.ibm.com/docs/openshift?topic=openshift-responsibilities_iksoverview-by-resource)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_10170-12206-14575", "score": 30.073914292846872, "text": "\nDevelopers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.\n\nRed Hat OpenShift on IBM Cloud provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services as needed. Using industry-standard containers technology apps can be quickly developed and shared across multiple Development, Test, and Production environments. This setup provides the immediate benefit of scalability. Using Kubernetes rich set of deployment and runtime objects, the HR team can monitor and manage upgrades to apps reliably. They can also replicate and scale the apps, by using defined rules and the automated Kubernetes orchestrator.\n\n\n\n Step 1: Containers, microservices, and the Garage Method \n\n\n\n* Apps are built in a set of cooperative microservices that run in Red Hat OpenShift on IBM Cloud. The architecture represents the functional areas of the app with the most quality problems.\n* Deploy apps to container in Red Hat OpenShift on IBM Cloud, continuously scanned with IBM Vulnerability Advisor.\n* Provide standardized DevOps dashboards through Kubernetes.\n* Adopt the essential agile and iterative development practices within the IBM Garage Method to enable frequent releases of new functions, patches, and fixes without downtime.\n\n\n\n\n\n\n\n Step 2: Connections to existing benefits back-end \n\n\n\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure tunnel to on-premises systems that host the benefits systems.\n* Combination of on-premises data and Red Hat OpenShift on IBM Cloud lets them access sensitive data while they adhere to regulations.\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_transport"}, {"document_id": "ibmcld_07578-267680-269608", "score": 29.84251601992821, "text": "\nRunning, adding, or changing custom programs are not supported on IBM Cloud Qiskit Runtime. If you used this function previously, you can instead use code that calls primitives. To get performance benefits comparable to uploaded programs, you can use use sessions, which are a service aware context manager that minimizes artificial queuing latency inside an iterative workload.\n\n\n\nRed Hat OpenShift for HPC\n\n\n\n* What locations are available for deploying VPC resources?\n\nAvailable regions and zones for deploying VPC resources, and a mapping of those to city locations and data centers can be found in [Locations for resource deployment](https://cloud.ibm.com/docs/overview?topic=overview-locations).\n* What permissions do I need in order to create a cluster using the offering?\n\nInstructions for setting the appropriate permissions for IBM Cloud services that are used by the offering to create a cluster can be found in [User access permissions](https://cloud.ibm.com/docs/openshift?topic=openshift-access_referencecluster_create_permissions).\n* How many worker nodes can I deploy in my Red Hat OpenShift cluster through this offering?\n\nBefore you deploy a cluster, it is important to ensure that the cluster-related resource quota settings in your IBM Cloud account are appropriate for the size of the cluster that you would like to create. For more information, see [Service and quota limitations](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_limitationstech_limits).\n\nThe maximum number of worker nodes that are supported for the worker_nodes_per_zone deployment value is 1,000 (see [Deployment values](https://cloud.ibm.com/docs/hpc-openshift?topic=hpc-openshift-deployment-values)). However, the default quota, as noted in [Service and quota limitations](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_limitationstech_limits), is 500 worker nodes across all of the clusters in a region.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10852-44214-45420", "score": 50.16052840390068, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10852-43319-44485", "score": 49.749690854488705, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10817-1342-3184", "score": 47.57054974876005, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-7-1743", "score": 46.85895505293594, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10817-7-1802", "score": 44.43492744833081, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-1426-3052", "score": 42.18572625858598, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_07551-15747-17355", "score": 35.139418679473266, "text": "\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https://github.com/IBM/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n/Register iOS devices/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_07551-14062-16080", "score": 34.70890909734643, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_12332-1034-2510", "score": 32.50877187375829, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}, {"document_id": "ibmcld_02772-4213-5899", "score": 30.22727868517648, "text": "\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10817-1342-3184", "score": 36.11900662144988, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04168-12490-13969", "score": 27.469138590640902, "text": "\nHTTP/3 encrypts internet transport by default using a protocol from Google called QUIC. Enable HTTP/3 via the Cloudflare Network app. Use the following methods to experiment with HTTP/3.\n\n\n\n Using Google Chrome as your HTTP/3 client \n\nTo use Chrome to connect to your website over HTTP/3, first download and install the [latest Canary build](https://www.google.com/chrome/canary/). Then, enable HTTP/3 support in Chrome Canary using the --enable-quic and --quic-version=h3-23[command-line arguments](https://www.chromium.org/developers/how-tos/run-chromium-with-flags).\n\nAfter Chrome starts, type your domain in the address bar. Check the protocol version using the Network tab in Chrome\u2019s Developer Tools. If http2+quic/99 doesn\u2019t appear in the Protocol column when connecting to your domain, try reloading the page.\n\n\n\n\n\n Using cURL \n\nThe cURL command-line tool supports HTTP/3. [Download the latest version](https://github.com/curl/curl) and follow [the instructions to enable HTTP/3 support](https://github.com/curl/curl/blob/master/docs/HTTP3.mdquiche-version).\n\nFor macOS, use Homebrew to install cURL with HTTP/3 support:\n\nbrew install --HEAD -s https://raw.githubusercontent.com/cloudflare/homebrew-cloudflare/master/curl.rb\n\nThen, perform an HTTP/3 cURL with the --http3 command-line flag:\n\n./curl -I https://blog.cloudflare.com/ --http3\n\nConfirm HTTP/3 appears in the response and that there were no error messages.\n\n\n\n\n\nContribute in GitHub\n\nOpen doc issue\n\nEdit topic", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-http-concepts"}, {"document_id": "ibmcld_04518-7-1743", "score": 24.843359082086643, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_04518-1426-3052", "score": 24.252864882206875, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10835-65759-67135", "score": 23.179294127839487, "text": "\nBefore you begin, you must have Docker installed locally.\n\nYou won\u00b4t need Java installed locally as everything is supplied by the Java runtime.\n\nTo create a Java action by using Docker, complete the following steps.\n\n\n\n1. Create Hello.java file\n\nimport com.google.gson.JsonObject;\n\npublic class Hello {\npublic static JsonObject main(JsonObject args) {\nString name = \"stranger\";\nif (args.has(\"name\"))\nname = args.getAsJsonPrimitive(\"name\").getAsString();\nJsonObject response = new JsonObject();\nresponse.addProperty(\"greeting\", \"Hello, \" + name + \"!\");\nreturn response;\n}\n}\n2. Navigate to the folder that contains the Hello.java file and run the Docker Java runtime container.\n\ndocker run --rm -it --entrypoint \"/bin/bash\" -v $PWD:/tmp openwhisk/java8action:nightly\n\nUse the nightly tag for the latest runtime version or a specific tag.\n3. Set up the container.\n\n\n\n1. Navigate to the /tmp folder that contains your action code mounted from the host system.\n\ncd /tmp\n2. Install curl to download the dependencies.\n\napt update && apt install curl -y\n3. Download the gson dependency.\n\ncurl -L -o gson-2.9.0.jar https://repo1.maven.org/maven2/com/google/code/gson/gson/2.8.5/gson-2.9.0.jar\n4. Export the path and add gson to it.\n\nexport CLASSPATH=$CLASSPATH:$PWD/gson-2.9.0.jar\nexport CLASSPATH=$CLASSPATH:/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home/bin\n\n\n\n4.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-prep"}, {"document_id": "ibmcld_07546-4182-5472", "score": 22.714898262902828, "text": "\n[Project setting](https://cloud.ibm.com/docs-content/v1/content/4c9a07fe500838e5e55e71e73131ef20b44a6c66/event-notifications/images/en-migration-firebase-setting.png)\n\nFigure 5. Project setting\n4. Find an app with package name com.ibm.mobilefirstplatform.clientsdk.android.push and click Remove this app.\n5. Click Add app > Choose Android\n6. Enter com.ibm.cloud.eventnotifications.destination.android as the package name and click Register App.\n\nZoom\n\n![Register app](https://cloud.ibm.com/docs-content/v1/content/4c9a07fe500838e5e55e71e73131ef20b44a6c66/event-notifications/images/en-migration-firebase-addapp.png)\n\nFigure 6. Register app\n7. Download google-services.json. You use this file later when you modify the app.\n\n\n\n\n\n\n\n Edit the Android app \n\n\n\n1. Add the Firebase google-services.json in the app module.\n2. Change the Module\u2019s build.gradlefileto include the new SDKs.\n\n\n\n// Replace the below section\n\ndependencies {\n........\nimplementation 'com.google.firebase:firebase-messaging:20.0.0'\nImplementation 'com.ibm.mobilefirstplatform.clientsdk.android:core:3.+'\n.......\n}\n\n// with this\n\ndependencies {\n........\nimplementation platform('com.google.firebase:firebase-bom:29.0.0')\nimplementation 'com.google.firebase:firebase-messaging'\nimplementation 'com.ibm.cloud:sdk-core:9.15.0'", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-migrate-apps"}, {"document_id": "ibmcld_08428-1522-3121", "score": 22.477815868260404, "text": "\n[Set up access policy](https://docs.microsoft.com/en-us/azure/key-vault/general/assign-access-policy-portal) for the Key Vault, granting access to that service principal.\n\n\n\nUnified Key Orchestrator requires the following access to be able to manage keys in Azure Key Vault:\n\n\n\n* create\n* import\n* update\n* list\n* delete\n* get\n* recover\n* purge\n* backup\n* restore\n\n\n\nFor more information, check out [Assign a Key Vault access policy](https://docs.microsoft.com/en-us/azure/key-vault/general/assign-access-policy?tabs=azure-portal).\n\n\n\n\n\n Setting up required user access in AWS keystore \n\nUnified Key Orchestrator requires the following access to be able to manage keys in AWS KMS:\n\n\n\n* ListKeys\n* CreateKey\n* GetParametersForImport\n* ImportKeyMaterial\n* DeleteAlias\n* CreateAlias\n* TagResource\n* UntagResource\n* DescribeKey\n* DeleteImportedKeyMaterial\n* ListResourceTags\n* ListAliases\n* ScheduleKeyDeletion\n\n\n\nFor more information, check out [AWS KMS permissions](https://docs.aws.amazon.com/kms/latest/developerguide/kms-api-permissions-reference.html).\n\n\n\n\n\n Setting up required user access in Google Cloud KMS \n\nTo set up user access to Google Cloud KMS, complete the following steps:\n\n\n\n1. [Create a service account](https://cloud.google.com/iam/docs/creating-managing-service-accountscreating) in your Google Cloud project.\n2. [Create a service account key](https://cloud.google.com/iam/docs/creating-managing-service-account-keyscreating) to establish the identity of the service account. Select JSON for the key type. The private JSON key file will be downloaded directly on your workstation.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-connect-external-keystores"}, {"document_id": "ibmcld_10092-9206-10957", "score": 22.060680365342154, "text": "\nYou can upgrade your existing cluster autoscaler release to the latest version of the Helm chart. To check your current release version, run helm list -n <namespace> | grep cluster-autoscaler. Compare your version to the latest available release by reviewing the Chart Version in the [IBM Cloud Helm Catalog](https://cloud.ibm.com/kubernetes/helm/iks-charts/ibm-iks-cluster-autoscaler).\n\n\n\n Prerequisites \n\nBefore you begin to upgrade your cluster autoscaler release, complete the following steps.\n\nThis topic applies only to the cluster autoscaler Helm chart.\n\n\n\n1. [Access your Red Hat OpenShift cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-access_cluster).\n2. To review the change log of chart versions, [download the source code tar file](https://cloud.ibm.com/kubernetes/helm/iks-charts/ibm-iks-cluster-autoscaler) and open the RELEASENOTES.MD file.\n\n\n\n\n\n\n\n Upgrading the cluster autoscaler release version \n\nThis topic applies only to the cluster autoscaler Helm chart.\n\nTo upgrade your cluster autoscaler release, you can update the Helm chart repo and re-create the cluster autoscaler pods. Use the same version of Helm that you used to install the initial Helm chart and release.\n\nBefore you begin, see the [Prerequisites](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-helmca_helm_up_prereqs).\n\n\n\n1. Update the Helm repo to retrieve the latest version of all Helm charts in this repo.\n\nhelm repo update\n2. Optional: Download the latest Helm chart to your local machine. Then, extract the package and review the release.md file to find the latest release information.\n\nhelm pull iks-charts/ibm-iks-cluster-autoscaler\n3. Find the name of the cluster autoscaler release that you installed in your cluster.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-helm"}, {"document_id": "ibmcld_04356-7-1579", "score": 21.792279767315357, "text": "\nFAQs for the IBM Cloud CLI \n\nFAQs for the IBM Cloud\u00ae Command Line Interface include questions about CLI versioning, updates, and working with apps. To find all FAQs for IBM Cloud, see the [FAQ library](https://cloud.ibm.com/docs/faqs).\n\n\n\n Do I have to use the latest version of the IBM Cloud CLI? \n\nYes, you must use the latest version. You can check which version you are using by running the following command:\n\nibmcloud -v\n\n\n\n\n\n How do I update the CLI? \n\nRun the following command to update to the latest version of the CLI:\n\nibmcloud update\n\n\n\n\n\n How can I be notified about new CLI releases? \n\nWhen you run an IBM Cloud CLI command, you're notified if a new version is available. You can also subscribe to the [IBM Cloud CLI releases repository](https://github.com/IBM-Cloud/ibm-cloud-cli-release/releases/) to stay up to date on the latest releases.\n\n\n\n\n\n How do I install the IBM Cloud CLI along with developer plug-ins and tools? \n\nTo install the latest IBM Cloud CLI and recommended plug-ins and tools for developing applications for IBM Cloud, follow the steps in [Getting started with the IBM Cloud CLI](https://cloud.ibm.com/docs/cli?topic=cli-getting-started) and [Extending IBM Cloud CLI with plug-ins](https://cloud.ibm.com/docs/cli?topic=cli-plug-ins).\n\nTo install only the stand-alone IBM Cloud CLI without any plug-ins or tools, see [Installing the stand-alone IBM Cloud CLI](https://cloud.ibm.com/docs/cli?topic=cli-install-ibmcloud-cli).\n\n\n\n\n\n How do I download a plug-in? \n\nUse the ibmcloud plugin download PLUGIN_NAME command to download a plug-in.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-ibm-cli-faq"}, {"document_id": "ibmcld_07551-14062-16080", "score": 21.76047920563084, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16471-91132-93270", "score": 23.25165539141363, "text": "\n* [group by<group by list>]\n\nGroups the tuples that are produced from the same document by common values of a specified field. This clause is optional.\n* [order by<order by list>]\n\nOrders the output tuples that are produced by the select statement from each document. The order is based on the values of the order-by list, a comma-delimited list of expressions. This clause is optional.\n* [limit <maximum number of output tuples for each document>]\n\nLimits the number of output tuples for each document to the specified maximum. This clause is optional.\n\n\n\n\n\n\n\n Usage Notes \n\nThe semantics of the select statement are as follows:\n\n\n\n* Determine the input data (in tuples) by taking the Cartesian product of relations in the from list.\n* For each input tuple that is generated, filter it by applying the predicates in the (optional) where clause.\n* If the optional group by clause is present, group tuples that are produced from the same document by the values that are specified in the group-by list and compute the result of the aggregate functions within the select list.\n* Consolidate any overlapping tuples, according to the policy defined in the (optional) consolidation clause. If the optional order by clause is present, order these tuples by the values of the order-by list.\n* Compute all expressions within the select list on each tuple, and rename the columns as specified by the as clauses.\n* If the optional limit clause is present, limit the number of output tuples to the specified number of tuples for each document.\n\n\n\n\n\n\n\n Examples \n\nAn example of how to use the select statement is to extract phone numbers that match a pattern. Assume that the PhoneNumbers view that extracts phone numbers of the pattern XXX-XXX-XXXX for United States is already defined. This select statement evaluates the regular expression for the pattern 444-888-XXXX across the input text. The view has the output columns documentText and phoneNumber. In addition, the output is limited to the first occurrence of this phone number pattern that is identified per document.\n\ncreate view PhoneNumbersPattern1 as\nselect D.documentText, D.phoneNumber", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotation-query-language-reference"}, {"document_id": "ibmcld_03165-4477-6547", "score": 22.975922564680314, "text": "\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https://community.ibm.com/community/user/watsonapps/viewdocument/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-sms"}, {"document_id": "ibmcld_16287-7751-9832", "score": 22.530890562674397, "text": "\nHowever, provisioning the new number might take several minutes.\n\n\n\n\n\n Adding more phone numbers \n\nIf you are using existing phone numbers you configured via a SIP trunk provider, you can add multiple numbers to the same phone integration.\n\nIf you generated a free phone number, you cannot add more numbers.\n\nTo add more phone numbers:\n\n\n\n1. In the phone integration settings, go to the Phone number tab.\n2. Use one of the following methods:\n\n\n\n* To add phone numbers one by one, click Add phone number in the table, and enter the phone number along with an optional description. Click the Add button to save the number.\n* To import a set of phone numbers that are stored in a comma-separated values (CSV) file, click the Upload a CSV file icon (![Add phone number][images/phone-integ-import-number.png]), and then find the CSV file that contains the list of phone numbers.\n\nThe phone numbers you upload will replace any existing numbers in the table.\n\n\n\n\n\n\n\n\n\n Setting up live agent escalation \n\nIf you want your assistant to be able to transfer a conversation to a live agent, you can connect your phone integration to a contact center. For more information, see instructions for the supported platform:\n\n\n\n* [Genesys](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-genesys)\n* [Twilio Flex](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-flex)\n\n\n\n\n\n\n\n Phone integration limits \n\nAny speech service charges incurred by the phone integration are included as Voice add-on charges in your Watson Assistant service plan usage. The Voice add-on use is charged separately and in addition to your service plan charges.\n\nPlan usage is measured based on the number of monthly active users, where a user is identified by the caller's unique phone number. An MD5 hash is applied to the phone number and the 128-bit hash value is used for billing purposes.\n\nThe number of concurrent calls that your assistant can participate in at one time depends on your plan type.\n\n\n\nPlan details\n\n Plan Concurrent calls \n\n Enterprise 1,000", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone"}, {"document_id": "ibmcld_16321-26521-28332", "score": 21.961771916282046, "text": "\nIf you want customers to be able to send information by typing it on their phone keypad instead of speaking, you can add support for phone keypad entry. The best way to implement this type of support is to enable dual-tone multifrequency (DTMF) signaling. DTMF is a protocol used to transmit tones that are generated when a user presses keys on a push-button phone. The tones have a specific frequency and duration that can be interpreted by the phone network.\n\nTo start listening for tones as the user presses phone keys, use the dtmf response type in an action step. This response type can be added using the JSON editor.\n\n{\n\"generic\": [\n{\n\"response_type\": \"dtmf\",\n\"command_info\": {\n\"type\": \"<command type>\",\n\"parameters\": {\n\"parameter name\": \"parameter value\",\n\"parameter name\": \"parameter value\"\n}\n},\n\"channels\":\n{\n\"channel\": \"voice_telephony\"\n}\n]\n}\n]\n}\nShow more\n\nThe command_info property specifies a DTMF command for the phone integration. The supported commands and their related parameters are as follows.\n\n\n\n command_info.type : collect \n\nInstructs the phone integration to collect dual-tone multi-frequency signaling (DTMF) input from a user. This command supports the following parameters:\n\n\n\n parameter name description required default \n\n termination_key The DTMF termination key, which signals the end of DTMF input (for example, ). no n/a \n count The number of DTMF digits to collect. This must be a positive integer no larger than 100. Required if termintation_key, or minimum_count and maximum_count, are not defined n/a \n minimum_count The minimum number of DTMF digits to collect. This property is used along with maximum_count to define a range for the number of digits to collect. This value must be a positive integer with a minimum value of 1 and a maximum value less than maximum_count.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_16294-8240-10414", "score": 21.184955460785783, "text": "\nOnce the phone number has been enabled for SMS, you will see a webhook icon beside the number.\n\nPaste the value that you copied from the Webhook URI field into it.\n15. Click Save.\n16. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n\n\n\n\n\n\n\n\n\n SMS Advanced configuration options \n\nThe Advanced options tab is available after you set up the SMS integration. Click the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your actions for messaging \n\nFor the best customer experience, design your actions with the capabilities of the SMS integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* The SMS integration does not support chat transfers that are initiated with the connect_to_agent response type.\n* Image, Audio, Video response types allow sending a message containing media. A title and description are sent along with the attachment. Note that depending on the carrier and device of the end user these messages may not be successfully received. For a list of the supported content types for Twilio, see [Twilio: Accepted Content Types for Media](https://www.twilio.com/docs/sms/accepted-mime-types).\n\nFor more information on these response types, see [Response types reference](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\nIf you want to use the same action for an assistant that you deploy to many different platforms, add custom responses per integration type. You can add a conditioned response that tells the assistant to show the response only when the SMS integration is being used.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-sms"}, {"document_id": "ibmcld_16294-4288-5934", "score": 20.990733676189144, "text": "\nScroll to the Messaging section, and then find the Webhook field that defines what to do when A message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n14. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n15. Click Save.\n16. From the Develop tab in the sidebar, click Messaging > Settings > Geo permissions. If Messaging is not present, go to the Search Bar at the top and search for 'Messaging', then select SMS Geographic Permissions.\n17. From the Messaging Geographic Permissions page, select the country codes of the phone numbers that can text your Twilio number. By default, no country codes are allowed to text your Twilio number.\n18. Return to the SMS with Twilio integration setup page. Click Finish.\n\n\n\n\n\n\n\n\n\n Integrating with SMS with IntelePeer \n\n\n\n Before you begin \n\nIf you don't have a text messaging phone number, set up an SMS with IntelePeer account and get a phone number.\n\n\n\n1. Go to the [IntelePeer website](https://www.intelepeer.com/).\n2. Create an account or start a free trial.\n\nWhen you get an IntelePeer phone number, it supports voice and SMS. If the number is not automatically enabled for SMS, you will need to enable it manually. Your new phone number is listed as an active number. Refer to the [Atmosphere Messaging Quick Start Guide](https://docs.intelepeer.com/atmosphere/Content/Atmosphere-SMS-Messaging/Atmosphere-SMS-Messaging-Quick-Start-Guide.htm)\n\n\n\n\n\n\n\n Set up the integration \n\nTo set up the integration, complete the following steps:\n\n\n\n1. Go to the Integrations page by clicking the integrations icon (!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-sms"}, {"document_id": "ibmcld_16287-2974-4988", "score": 20.65470275633422, "text": "\nChoose whether to generate a free phone number for your assistant, integrate with your contact center, or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To integrate with a [contact center](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone), click Integrate with your contact center.\n* To use an existing phone number you have already configured with a [SIP trunk provider](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-sip-providers), click Use an existing phone number with an external provider.\n\n\n\nClick Next.\n5. If you are integrating with a contact center, follow the instructions to configure the contact center. Skip this step if you are generating a free phone number.\n\n\n\n1. On the Select contact center page, select the tile of the connect center you would like to use.\n2. On the Connect to contact center page, enter the required information. There is a Test Connection button on the page to validate the connection. Click Next.\n\n\n\n6. If you are using an existing phone number, follow the instructions to configure the SIP trunk. Skip this step if you are generating a free phone number.\n\n\n\n1. On the Bring your own SIP trunk page, copy the SIP URI and assign it to your SIP trunk. Click Next.\n\n\n\n7. On the Phone number page (only for Integrate with your contact center and Use an existing phone number with an external provider), specify the phone number of the SIP trunk. Specify the number by using the international phone number format: +1 958 555 0123. Do not surround the area code with parentheses.\n\nCurrently, only one primary phone number can be added during initial setup of the phone integration. You can add more phone numbers in the phone integration settings later.\n\nClick Next.\n8.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone"}, {"document_id": "ibmcld_03158-6114-8033", "score": 20.560622301819652, "text": "\nThe list of voices is automatically filtered to use the same language as your assistant. To see all voices, toggle the Filter voices based on assistant language switch to Off.\n\nFor more information about voice options, and to listen to audio samples, see [Languages and voices](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voices) in the Text to Speech documentation.\n\nClick Next.\n\n\n\nAny speech service charges that are incurred by the phone integration are billed with the Watson Assistant service plan as voice add-on charges. After the instances are created, you can access them directly from the IBM Cloud dashboard. Any use of the speech instances that occurs outside of your assistant are charged separately as speech service usage costs.\n\nThe phone integration setup is now complete. On the Phone page, you can click the tabs to view or edit the phone integration.\n\nIf you chose to generate a free telephone number, your new number is displayed on the Phone number tab immediately. However, provisioning the new number so it is ready to use might take several minutes.\n\n\n\n\n\n Adding more phone numbers \n\nIf you are using existing phone numbers you configured using a SIP trunk provider, you can add multiple numbers to the same phone integration.\n\nIf you generated a free phone number, you cannot add more numbers.\n\nTo add more phone numbers:\n\n\n\n1. In the phone integration settings, go to the Phone number tab.\n2. Use one of the following methods to add phone numbers:\n\n\n\n* To add phone numbers one by one, type each number in the table, along with an optional description. Click the checkmark icon ![checkmark icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/phone-checkmark-save.png) to save each number.\n* To import a set of phone numbers that are stored in a comma-separated values (CSV) file, click the Upload a CSV file icon (!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone"}, {"document_id": "ibmcld_03158-2940-4987", "score": 20.463576320552963, "text": "\nIn the Integrations section on the main page for your assistant, click Add integration.\n2. On the Add integration page, click Phone.\n3. Click Create.\n4. Choose whether you want to generate a free phone number for your assistant or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To use an existing phone number you have already configured with a [SIP trunk provider](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-sip-providers), click Use an existing phone number with an external provider.\n\n\n\nClick Next.\n5. If you are using an existing phone number, follow the instructions to configure the SIP trunk. (If you are generating a free phone number, skip this step).\n\n\n\n1. On the Bring your own SIP trunk page, copy the SIP URI and assign it to your SIP trunk. Click Next.\n2. On the Phone number page, specify the phone number of the SIP trunk. Specify the number by using the international phone number format: +1 958 555 0123. Do not surround the area code with parentheses.\n\n\n\nCurrently, only one primary phone number can be added during initial setup of the phone integration. You can add more phone numbers in the phone integration settings later.\n\nClick Next.\n6. On the Speech to Text page, select the instance of the Speech to Text service you want to use for the phone integration.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus instance.\n\n\n\n7. In the Choose your Speech to Text language model field, select the language model you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone"}, {"document_id": "ibmcld_16321-39281-39781", "score": 20.3912879982585, "text": "\nThe following example shows how to access the user phone number (i.e. the phone number that the call was received from):\n\n\"context\": {\n\"variables\": [\n{\n\"value\": {\n\"expression\": \"${system_integrations.voice_telephony.private.user_phone_number}.replace('+','')\"\n},\n\"skill_variable\": \"user_phone_number\"\n}\n]\n}\n\nFor more information about the phone integration context variables, see [Phone integration context variables](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-context).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12498-8087-10171", "score": 18.54713041786807, "text": "\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_06843-4238-6198", "score": 16.881097636036802, "text": "\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https://cloud.ibm.com/docs/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https://github.com/IBM/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-devsecops-cc-pipeline"}, {"document_id": "ibmcld_12498-9696-11699", "score": 15.877552278540731, "text": "\n[IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL/TLS certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-automatic-rotation) !", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_06836-7569-8653", "score": 15.138036927618348, "text": "\nup from the environment-properties configmap\n\n Eg. if there's a prop: my-config entry in the environment properties,\n then my-config is going to be used for $prop\nconfigmap: $prop\n\n the mechanism described works for secrets as well!\nsecret: $my-secrets\n\n the script is executed inside the checked out app repo\nscript: \n!/bin/sh\n...\n\n test runs after setup, but before building the docker image\ntest:\nimage: ibmcom/pipeline-base-image:2.7\nscript: \n!/bin/sh\n...\n\n static-scan runs after test, but before building the docker image\nstatic-scan:\nimage: ibmcom/pipeline-base-image:2.12\nscript: \n!/bin/sh\n...\n\n deploy runs after building the docker image\ndeploy:\nimage: ibmcom/pipeline-base-image:2.7\n\n the script has access to the built docker image, which is available at /config/image\nscript: \n!/bin/sh\n\ncat /config/image\n\n dynamic-scan runs after deploy, but before the acceptance test run\ndynamic-scan:\nimage: ibmcom/pipeline-base-image:2.12\nscript: \n!/bin/sh\n...\n\n acceptance-test runs after deploy\nacceptance-test:\nimage: ibmcom/pipeline-base-image:2.7\nscript: \n!/bin/sh\n...\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-custom-scripts"}, {"document_id": "ibmcld_16729-294066-295916", "score": 14.296959992864, "text": "\nA script and tool will assist you to simulate the transmission of web server log messages from a static file to Event Streams.\n\nObject Storage Event Streams\n\n+3\n\nAnalytics Engine,Data Engine,Key Protect\n\n\n\n* 3 hours\n* 2023-05-05\n\n\n\n[Getting started with Secrets Manager](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-getting-started)Getting started with Secrets Manager\n\nThis tutorial focuses on storing and managing a username and password in IBM Cloud\u00ae Secrets Manager. With Secrets Manager, you can create, lease, and centrally manage secrets that are used in IBM Cloud services or your custom-built applications. Secrets are stored in a dedicated Secrets Manager instance, built on open source HashiCorp Vault.\n\nSecrets Manager\n\n\n\n* 10 minutes\n* 2023-03-01\n\n\n\n[Access a storage bucket by using a dynamic secret](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-tutorial-access-storage-bucket)Access a storage bucket by using a dynamic secret\n\nIn this tutorial, you learn how to use IBM Cloud\u00ae Secrets Manager to create and lease an IAM credential that can be used to access a bucket in Cloud Object Storage.\n\nSecrets Manager Object Storage\n\n\n\n* 1 hour\n* 2023-05-30\n\n\n\n[Secure secrets for apps that run in your Kubernetes cluster](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-tutorial-kubernetes-secrets)Secure secrets for apps that run in your Kubernetes cluster\n\nThis tutorial is for the Classic flavor of Kubernetes Service clusters. External Secrets is also available as an OpenShift operator.\n\nSecrets Manager\n\n\n\n* 45 minutes\n* 2023-06-15\n\n\n\n[Part 2: Create a GitHub issue when your certificates are about to expire](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-tutorial-expiring-secrets-part-2)Part 2: Create a GitHub issue when your certificates are about to expire", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_07844-4589-6711", "score": 13.840754899220162, "text": "\nRA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n RA-5 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nSecurity categorization of information systems guides the frequency and comprehensiveness of vulnerability scans. Organizations determine the required vulnerability scanning for all information system components, ensuring that potential sources of vulnerabilities such as networked printers, scanners, and copiers are not overlooked. Vulnerability analyses for custom software applications may require additional approaches such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"}, {"document_id": "ibmcld_12415-7-1973", "score": 13.61588787892262, "text": "\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https://cloud.ibm.com/docs/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-faqs"}, {"document_id": "ibmcld_07844-3757-5369", "score": 13.397065652550161, "text": "\nRA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"}, {"document_id": "ibmcld_07844-2925-4586", "score": 13.30672072310853, "text": "\nRA-5 (a) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"}, {"document_id": "ibmcld_07578-1213887-1215935", "score": 13.263996988244115, "text": "\nAfter you delete your Key Protect instance, Key Protect uses[envelope encryption](https://cloud.ibm.com/docs/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.\n\nAfter the network access policy is set to private-only the UI cannot be used for any Key Protect actions.\n\nKeys in a private-only instance will not be shown in the UI and any Key Protect actions in the UI will return an unauthorized error (HTTP status code 401).\n\n\n\nSecrets Manager\n\n\n\n* What is a secret?\n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n* What is a secret group?\n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04105-1672-3877", "score": 22.78012368445551, "text": "\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-3403-5572", "score": 22.439874944564654, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-7-2225", "score": 22.3383281176868, "text": "\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_03164-1607-3518", "score": 20.476204911340133, "text": "\nFor more information about it, read the [Slack blog post](https://medium.com/slack-developer-blog/more-precision-less-restrictions-a3550006f9c3) about it.\n8. Assign bot token scopes to your Slack app. At a minimum, apply the following scopes:\n\n\n\n* app_mentions:read\n* chat:write\n* im:history\n* im:read\n* im:write\n\n\n\n9. Click Install App to Workspace, and then allow the installation when prompted.\n\nIf you are editing scopes for an existing application, reinstall it.\n10. From the Slack settings App Home page, enable the Always Show My Bot As Online setting.\n11. Go to the OAuth and Permissions page in Slack, copy the Bot User OAuth Access Token.\n12. From the Watson Assistant Slack integration configuration page, paste the token that you copied in the previous step into both the OAuth access token and Bot user OAuth access token fields.\n13. On the Slack app settings page, go to the Basic Information page, and then find the App Credentials section. Copy the app credential verification token.\n14. From the Watson Assistant Slack integration configuration page, paste the verification token that you copied in the previous step into the Verification token field.\n15. Click Generate request URL, and then copy the generated request URL.\n16. Return to the Slack app settings page. Open the Event Subscriptions page, and then turn on Enable Events. Paste the request URL that you copied in the previous step into the field.\n17. On the Event Subscriptions page in Slack, find the Subscribe to Bot Events section. Click Add Bot User Event, and then select the event types you want to subscribe to. You must select at least one of the following types:\n\n\n\n* message.im: Listens for message events that are posted in a direct message channel.\n* app_mention: Listens for only message events that mention your app or bot.\n\nChoose the app_mention entry in normal font, not the app_mention entry that is in bold font.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-slack"}, {"document_id": "ibmcld_04111-35313-36062", "score": 20.22126061362581, "text": "\nGet Bot Management settings. GET /v1/{crn}/zones/{domain_id}/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT /v1/{crn}/zones/{domain_id}/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET /v1/{crn}/zones/{domain_id}/bot_analytics/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET /v1/{crn}/zones/{domain_id}/bot_analytics/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET /v1/{crn}/zones/{domain_id}/bot_analytics/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-at_iam_CIS"}, {"document_id": "ibmcld_04105-5067-6335", "score": 19.48318777453023, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04170-7-2189", "score": 19.446863120262865, "text": "\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https://research.google/pubs/pub45581/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with /cdn-cgi/challenge-platform/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_04111-34153-35639", "score": 18.52922048800587, "text": "\nGET /v1/{crn}/zones/{domain_id}/setting/origin_error_page_pass_thru internet-svcs.zones.update internet-svcs.origin-error-page-pass-thru-setting.update \n Get brotli compression settings. GET /v1/{crn}/zones/{domain_id}/setting/brotli internet-svcs.performance.read internet-svcs.brotli-setting.read \n Update brotli compression settings. PUT /v1/{crn}/zones/{domain_id}/setting/brotli internet-svcs.performance.update internet-svcs.brotli-setting.update \n Get Email obfuscation settings. GET /v1/{crn}/zones/{domain_id}/setting/email_obfuscation internet-svcs.security.read internet-svcs.email-obfuscation-setting.read \n Update Email obfuscation settings. PUT /v1/{crn}/zones/{domain_id}/setting/email_obfuscation internet-svcs.security.update internet-svcs.email-obfuscation-setting.update \n Get ciphers settings. GET /v1/{crn}/zones/{domain_id}/setting/ciphers internet-svcs.security.read internet-svcs.ciphers-setting.read \n Update ciphers settings. PUT /v1/{crn}/zones/{domain_id}/setting/ciphers internet-svcs.security.update internet-svcs.ciphers-setting.update \n\n\n\n\n\n\n\n Bot Management \n\n\n\nTable 22. Bot Management\n\n Action Method IAM ACTION AT ACTION \n\n Get Bot Management settings. GET /v1/{crn}/zones/{domain_id}/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT /v1/{crn}/zones/{domain_id}/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-at_iam_CIS"}, {"document_id": "ibmcld_03403-26509-28185", "score": 18.20542356979553, "text": "\n[Close](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/close.png) to close the edit view.\n\n\n\nNow, when you test, you can provide a set of number or a mix of numbers and text as input, and the dialog reminds you of the correct order number format. You have successfully tested your dialog, found a weakness in it, and corrected it.\n\nAnother way you can address this type of scenario is to add a node with slots. See the [Adding a node with slots to a dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial-slots) tutorial to learn more about using slots.\n\n\n\n\n\n\n\n Step 5: Add the personal touch \n\nIf the user shows interest in the bot itself, you want the virtual assistant to recognize that curiosity and engage with the user in a more personal way. You might remember the General_About_You intent, which is provided with the General content catalog, that we considered using earlier, before you added your own custom about_restaurant intent. It is built to recognize just such questions from the user. Add a node that conditions on this intent. In your response, you can ask for the user's name and save it to a $username variable that you can use elsewhere in the dialog, if available.\n\n\n\n Add a node that handles questions about the bot \n\nAdd a dialog node that can recognize the user's interest in the bot, and respond.\n\n\n\n1. Click the Dialog tab.\n2. Find the Welcome node in the dialog tree.\n3. Click the More![More options](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png) icon on the Welcome node, and then select Add node below.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial"}, {"document_id": "ibmcld_03114-11593-13085", "score": 18.18195363683843, "text": "\n\"body\": \"IBM Watson Assistant is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\",\n\"url\": \"https://cloud.ibm.com/docs/assistant?topic=assistant-index\",\n\"id\": \"6682eca3c5b3778ccb730b799a8063f3\",\n\"result_metadata\": {\n\"confidence\": 0.08401551980328191,\n\"score\": 0.73975396\n},\n\"highlight\": {\n\"Shortdesc\":\n\"IBM <em>Watson</em> <em>Assistant</em> is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\"\n],\n\"url\":\n\"https://cloud.ibm.com/docs/<em>assistant</em>?topic=<em>assistant</em>-index\"\n],\n\"body\":\n\"IBM <em>Watson</em> <em>Assistant</em> is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\"\n]\n}\n}\n]\n}\n]\n},\n\"user_id\": \"58e1b04e-f4bb-469a-9e4c-dffe1d4ebf23\"\n}\nShow more\n\nFor each search result, the title, body, and url properties include content returned from the Discovery query. The search skill configuration determines which fields in the Discovery collection are mapped to these fields in the response. Your application can use these fields to display the results to the user (for example, you might use the body text to show an abstract or description of the matching document, and the url value to create a link the user can click to open the document).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-responses"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_11408-11687-13539", "score": 12.050848264600193, "text": "\nData volumes of 235 GB\n\nBoot volumes of 200 GB\n\nDeployed VMs of 160 GB\n\n\n\nTable 10. Account billable for storage use case\n\n Name Size State/Description \n\n data-volume-1 20 GB Available \n data-volume-2 25 GB In-use (attached to vm-1) \n data-volume-3 100 GB In-use (attached to vm-1) \n data-volume-4 30 GB Available \n data-volume-5 60 GB In-use (attached to vm-2) \n\n\n\nTotal billable storage = 595 GB\n\n\n\n* Data volumes: 235 GB\n* Image volumes: 200 GB\n* Deployed VMs: 160 GB\n\n\n\n\n\n\n\n\n\n Pricing for VPN connection \n\nWhen you use a VPN connection, you are billed monthly.\n\nIBM charges with the base price hourly per connection. The base price varies per geography. So if you use one vpn connection that is active for a month, the monthly bill would be $base price X 24 hours X 30 days.\n\n\n\n\n\n Pricing for Power Edge Router \n\nAs a Power Systems Virtual Server user, you are charged based on the Transit Gateway connections that you use:\n\n\n\n* New Transit Gateway that you create in a PER workspace.\n* Existing Transit Gateways that add Power Systems Virtual Server workspace to their existing connection.\n\n\n\nHere are some more PER charges based on the following Transit Gateway specifics:\n\n\n\n* Routing option\n* Number of connections\n\n\n\nThe following table shows the charges based on the routing option that you select:\n\n\n\nTable 13. TGW charges based on routing\n\n Routing type Charges \n\n Local routing data transfer No charges \n Global routing data transfer $0.009405 GB \n\n\n\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change.", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-pricing-virtual-server"}, {"document_id": "ibmcld_06206-0-1702", "score": 11.619074029007106, "text": "\n\n\n\n\n\n\n  Why am I still seeing charges for block storage devices after deleting my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n  What\u2019s happening \n\nYou have already deleted your cluster but your account is still charged for the storage volumes associated with the cluster.\n\n  Why it\u2019s happening \n\nWhen you delete your cluster, you have the option to delete the storage volumes used by the cluster. If you select no, the storage volumes remain in your account, and continue incurring charges until they are deleted.\n\n  How to fix it \n\nDelete the storage volumes from your account.\n\n\n\n1.  Find the cluster ID of the deleted cluster. This ID will be used to remove associated block storage volumes. If you don't have the cluster ID of the deleted cluster, run ibmcloud ks cluster ls and a make a note of the cluster IDs whose block storage volumes you want to keep.\n\nibmcloud ks cluster ls\n2.  Find the remaining volumes that are associated with the deleted cluster.\n\nClassic clusters:\n\nibmcloud ks storage volume ls --provider classic | awk '{print $1 \" \" $8}'\n\nExample output for Classic Block Storage volumes. Note the volume ID and the cluster ID.\n\n102413596 blntvemw0j6snjt04jr0\n\nVPC clusters:\n\nibmcloud ks storage volume ls --provider vpc-gen2 | awk '{print $1 \" \" $8}'\n3.  Remove the volumes.\n\nClassic clusters:\n\nibmcloud sl block volume-cancel VOLUME_ID\n\nVPC clusters:\n\nibmcloud is vold VOLUME_NAME_OR_ID\n4.  Optional: Verify there are no more volumes associated with the deleted cluster.\n\nClassic clusters:\n\nibmcloud ks storage volume ls --provider classic | awk '{print $1 \" \" $8}'\n\nVPC clusters:\n\nibmcloud ks storage volume ls --provider vpc-gen2 | awk '{print $1 \" \" $8}'\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts_storage_clean_volume"}, {"document_id": "ibmcld_10640-0-1702", "score": 11.619074029007106, "text": "\n\n\n\n\n\n\n  Why am I still seeing charges for block storage devices after deleting my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n  What\u2019s happening \n\nYou have already deleted your cluster but your account is still charged for the storage volumes associated with the cluster.\n\n  Why it\u2019s happening \n\nWhen you delete your cluster, you have the option to delete the storage volumes used by the cluster. If you select no, the storage volumes remain in your account, and continue incurring charges until they are deleted.\n\n  How to fix it \n\nDelete the storage volumes from your account.\n\n\n\n1.  Find the cluster ID of the deleted cluster. This ID will be used to remove associated block storage volumes. If you don't have the cluster ID of the deleted cluster, run ibmcloud oc cluster ls and a make a note of the cluster IDs whose block storage volumes you want to keep.\n\nibmcloud oc cluster ls\n2.  Find the remaining volumes that are associated with the deleted cluster.\n\nClassic clusters:\n\nibmcloud oc storage volume ls --provider classic | awk '{print $1 \" \" $8}'\n\nExample output for Classic Block Storage volumes. Note the volume ID and the cluster ID.\n\n102413596 blntvemw0j6snjt04jr0\n\nVPC clusters:\n\nibmcloud oc storage volume ls --provider vpc-gen2 | awk '{print $1 \" \" $8}'\n3.  Remove the volumes.\n\nClassic clusters:\n\nibmcloud sl block volume-cancel VOLUME_ID\n\nVPC clusters:\n\nibmcloud is vold VOLUME_NAME_OR_ID\n4.  Optional: Verify there are no more volumes associated with the deleted cluster.\n\nClassic clusters:\n\nibmcloud oc storage volume ls --provider classic | awk '{print $1 \" \" $8}'\n\nVPC clusters:\n\nibmcloud oc storage volume ls --provider vpc-gen2 | awk '{print $1 \" \" $8}'\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts_storage_clean_volume"}, {"document_id": "ibmcld_07532-5547-6568", "score": 11.436085504196454, "text": "\nSee the Event Notifications catalog page for current pricing.\n\n\n\n* As of 31 July, you create a pre-production destination and does not register any devices or send messages, the charges for July will be $15.\n* As of 1 August, you register 500 devices and 5001 messages sent. The charges for August will be $30 (This is due to the message threshold exceeds the permitted limit.)\n* As of 5 August, you change from pre-production destination to production destination. Then, the charges for August will be $30 plus pro-rata charges of consumption price, which will be equal to\n\nAmount charged = $30 + $ (50/31) x (remaining number of days in the month) = $30 + [(50/31) x 26] = $71.86.\n* If you create a pre-production destination on 1 August and do not register any devices and do not sent any message, but on 5th August change from pre-production destination to a production destination, then the charges will be:\n\nAmount charged = $15 + $ (50/31) x (remaining number of days in the month) = $15 + [(50/31) x 26] = $56.86.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-destinations-push"}, {"document_id": "ibmcld_05014-1097-2458", "score": 11.339545161191177, "text": "\nClass A: PUT, COPY, POST and LIST (per 1,000) $0.01 $0.01 $0.01 $0.01 $0.01 $0.01 $0.01 $0.01 \n Class B: GET and all others (per 10,000) $0.01 $0.01 $0.01 $0.01 $0.01 $0.01 $0.01 $0.01 \n Delete requests No charge No charge No charge No charge No charge No charge No charge No charge \n Data retrieval (per GB) $0.029 $0.029 $0.029 $0.029 $0.029 $0.029 $0.029 $0.029 \n\n\n\nRegional\n\nCross Region\n\nSingle Data Center\n\n\n\nTable 4. Flex charge model for combined (storage capacity and data retrieval) is calculated using the lowest value of (A) storage capacity charge + data retrieval charge, or (B) capacity x Flex cap charge.\n\n Flex cap US South US East EU United Kingdom EU Germany AP Australia AP Japan S\u00e3o Paulo, Brazil Toronto, Canada \n\n Total GB stored and retrieved $0.029 $0.029 $0.0296 $0.0299 $0.0308 $0.0302 $0.0308 $0.0293 \n\n\n\nRegional\n\nCross Region\n\nSingle Data Center\n\n\n\nTable 5. Aspera High-Speed Transfer outbound bandwidth (GB/month)\n\n Aspera HST egress US South US East EU United Kingdom EU Germany AP Australia AP Japan S\u00e3o Paulo, Brazil Toronto, Canada \n\n 0 - 50 TB $0.08 $0.08 $0.08 $0.08 $0.08 $0.08 $0.08 $0.08 \n Next 100 TB $0.06 $0.06 $0.06 $0.06 $0.06 $0.06 $0.06 $0.06 \n Next 350 TB $0.04 $0.04 $0.04 $0.04 $0.05 $0.04 $0.04 $0.04 \n Greater than 500 TB Contact us Contact us Contact us Contact us Contact us Contact us Contact us Contact us", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-flex-pricing"}, {"document_id": "ibmcld_09915-2815-3708", "score": 11.051530014507287, "text": "\nThe first 250,000 NLU items are charged at $0.003 per item\nAdditional NLU items until the 5,000,000th NLU item are charged at $0.001 per item\nEstimated price = (250,000 NLU items \u00d7 $0.003) + (50,000 NLU items \u00d7 $0.001)\nEstimated price = $750 + $50\n\n\n\nTotal cost = $800\n\n\n\n\n\n How do I calculate the Standard Plan price for 15,000 NLU items? \n\n\n\n* Since the first 250,000 NLU items are priced at $0.003/item - your 15,000 NLU items are charged at $0.003 per item (Tier 1). Your estimated price would be $45.\n\n\n\n\n\n\n\n How do I calculate the Standard Plan price for 6,000,000 NLU items? \n\n\n\n* Since you have more than 5,000,000 NLU items, your first 250,000 NLU items are charged at $0.003 per item (Tier 1), your next 4,750,000 NLU items are charged at $0.001 per item (Tier 2), and your remaining 1,000,000 NLU items are charged at $0.0002 per item (Tier 3). Your estimated price would be $5,700.", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-pricing"}, {"document_id": "ibmcld_05014-7-1379", "score": 10.667500120365288, "text": "\nFlex storage class pricing \n\nRegional\n\nCross Region\n\nSingle Data Center\n\n\n\nTable 1. Storage Capacity (GB/month)\n\n Storage used US South US East EU United Kingdom EU Germany AP Australia AP Japan S\u00e3o Paulo, Brazil Toronto, Canada \n\n 0 - 499.99 TB $0.009 $0.009 $0.0096 $0.0099 $0.0108 $0.0102 $0.0108 $0.0093 \n 500+ TB $0.009 $0.009 $0.0096 $0.0099 $0.0108 $0.0102 $0.0108 $0.0093 \n\n\n\nRegional\n\nCross Region\n\nSingle Data Center\n\n\n\nTable 2. Public outbound bandwidth (GB/month)\n\n Bandwidth used US South US East EU United Kingdom EU Germany AP Australia AP Japan S\u00e3o Paulo, Brazil Toronto, Canada \n\n 0 - 50 TB $0.09 $0.09 $0.09 $0.09 $0.14 $0.14 $0.18 $0.09 \n Next 100 TB $0.07 $0.07 $0.07 $0.07 $0.11 $0.11 $0.14 $0.07 \n Next 350 TB $0.05 $0.05 $0.05 $0.05 $0.08 $0.08 $0.10 $0.05 \n Greater than 500 TB Contact us Contact us Contact us Contact us Contact us Contact us Contact us Contact us \n\n\n\nRegional\n\nCross Region\n\nSingle Data Center\n\n\n\nTable 3. Operational Requests\n\n Request type US South US East EU United Kingdom EU Germany AP Australia AP Japan S\u00e3o Paulo, Brazil Toronto, Canada \n\n Class A: PUT, COPY, POST and LIST (per 1,000) $0.01 $0.01 $0.01 $0.01 $0.01 $0.01 $0.01 $0.01 \n Class B: GET and all others (per 10,000) $0.01 $0.01 $0.01 $0.01 $0.01 $0.01 $0.01 $0.01 \n Delete requests No charge No charge No charge No charge No charge No charge No charge No charge", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-flex-pricing"}, {"document_id": "ibmcld_05581-89951-91370", "score": 10.628040851011766, "text": "\nList the PVCs in your cluster and note the NAME of the PVC, the STORAGECLASS, and the name of the PV that is bound to the PVC and shown as VOLUME.\n\nkubectl get pvc\n\nExample output\n\nNAME STATUS VOLUME CAPACITY ACCESSMODES STORAGECLASS AGE\nclaim1-block-bronze Bound pvc-06886b77-102b-11e8-968a-f6612bb731fb 20Gi RWO ibmc-block-bronze 78d\nclaim-file-bronze Bound pvc-457a2b96-fafc-11e7-8ff9-b6c8f770356c 4Gi RWX ibmc-file-bronze-retain 105d\nclaim-file-silve Bound pvc-1efef0ba-0c48-11e8-968a-f6612bb731fb 24Gi RWX ibmc-file-silver 83d\n2. Review the ReclaimPolicy and billingType for the storage class.\n\nkubectl describe storageclass <storageclass_name>\n\nIf the reclaim policy says Delete, your PV and the physical storage are removed when you remove the PVC. Note that VPC Block Storage is not removed automatically, even if you used a Delete storage class to provision the storage. If the reclaim policy says Retain, or if you provisioned your storage without a storage class, then your PV and physical storage are not removed when you remove the PVC. You must remove the PVC, PV, and the physical storage separately.\n\nIf your storage is charged monthly, you still get charged for the entire month, even if you remove the storage before the end of the billing cycle.\n3. Remove any pods that mount the PVC. List the pods that mount the PVC. If no pod is returned in your CLI output, you don't have a pod that uses the PVC.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-block_storage"}, {"document_id": "ibmcld_03107-6652-8734", "score": 10.546217469749434, "text": "\n* For Slack integrations, the user_id property is a concatenation of the team ID, such as T09LVDR7Y, and the member ID of the user, such has W4F8K9JNF. For example: T09LVDR7YW4F8K9JNF.\n* For web chat, you can set the value of the user_id property.\n\n\n\nBilling is managed per monthly active user per service instance. If a single user interacts with assistants that are hosted by different service instances that belong to the same plan, each interaction is treated as a separate use. You are billed for the user's interaction with each service instance separately.\n\n\n\n\n\n Test activity charges \n\nTest messages that you send from the Preview button are charged. For the preview, a random user_id is generated and stored in a cookie. The multiple interactions that a single tester has with the assistant embedded in the preview are recognized as coming from a single user and are charged accordingly. If you are doing your own test, running a scripted regression test for example, use a single user_id for all of the calls within your regression test. Other uses are flagged as abuse.\n\n\n\n\n\n Handling anonymous users \n\nIf your custom application or assistant interacts with users who are anonymous, you can generate a randomized universally unique ID to represent each anonymous user. For more information about UUIDs, see [RFC 4122](https://tools.ietf.org/html/rfc4122.html).\n\n\n\n* For web chat, if you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user. And you are charged only once when the same anonymous user interacts with your assistant multiple times in a single month.\n\n\n\nIf an anonymous user logs in and later is identified as being the same person who submitted a request with a known ID, you are charged twice. Each message with a unique user ID is charged as an independent active user.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-plan"}, {"document_id": "ibmcld_11439-1329-3377", "score": 10.530431037810315, "text": "\nThere are several use cases for the snapshot feature. For example, an administrator plans to upgrade the middleware on his system but would like to be able to revert to its original state before proceeding with an upgrade. If the middleware fails, the administrator can restore the source disk to its previous state. To accomplish this, the administrator would perform the following steps:\n\n\n\n1. Initiate the snapshot API with the source disks where the middleware information resides.\n2. Upgrade the middleware.\n3. If the upgrade fails, restore the source disks by using the snapshot that is created in the previous step.\n4. If the upgrade succeeds, delete the snapshot that is created in the first step.\n\n\n\nYou can initiate multiple snapshot operations. However, these concurrent snapshot operations occur on a different set of disks.\n\n\n\n Metering and pricing of snapshot \n\nEach snapshot that you create is monitored every hour and charged depending on the disk space that is requested for the snapshot. The space that is utilized by a snapshot is charged at 30% of the base rate. For example, if you have M disks on a VM that add up to 600 GB of space, and those M disks are used as source disks for snapshots, the following charges are applicable:\n\n\n\n* If you create one snapshot, you are charged for the disk space that is used by the base 600 GB of M disks plus 30% of 600 GB of disk space. That is, 600 GB (space of M disks) + 180 GB (30% of 600 GB) = 780 GB of disk space.\n* If you create one more snapshot by using same disks, you will be charged for disk space that is used by M disks (600 GB) + (30% of 600 GB) + (30% of 600 GB) = 960 GB of disk space.\n* The pricing that is charged for the snapshot is based on the storage tier that contains the source volumes: Tier 1 or Tier 3.\n\n\n\n\n\n\n\n Best practices \n\n\n\n* Before you take a snapshot, ensure that all of the data is flushed to the disk. If you take a snapshot on a running virtual machine (VM) and did not flush the file system, you might lose some content that is residing in memory.", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-volume-snapshot-clone"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04866-1541-3629", "score": 37.6170969586289, "text": "\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https://cloud.ibm.com/docs/services/cloud-object-storage/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-1541-3629", "score": 37.6170969586289, "text": "\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https://cloud.ibm.com/docs/services/cloud-object-storage/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_01169-0-1263", "score": 32.25659847622237, "text": "\n\n\n\n\n\n\n  Using the administration Kafka Java client API \n\nIf you use a Kafka client version 0.11 or later, or Kafka Streams version 0.10.2.0 or later, you can use APIs to create and delete topics. We put some restrictions on the settings that are allowed when you create topics. See the following settings that you can modify.\n\ncleanup.policy\n:   Set to delete (default), compact or delete,compact.\n\nretention.ms\n:   The default retention period is 24 hours. The minimum is 1 hour and the maximum is 30 days. Specify this value as multiples of hours.\n\nIn the Enterprise plan, you can set retention to any value.\n\nretention.bytes\n:   The maximum size a partition (which consists of log segments) can grow to before we discard old log segments to free up space.\n\nEnterprise plan only. Set to any value larger than 10 MB.\n\nsegment.bytes\n:   The segment file size for the log.\n\nEnterprise plan only. Set to any value larger than 100 kB.\n\nsegment.index.bytes\n:   The size of the index that maps offsets to file positions.\n\nEnterprise plan only. Set to any value between 100 kB and 1 GB.\n\nsegment.ms\n:   The period after which Kafka forces the log to roll even if the segment file isn't full.\n\nEnterprise plan only. Set to any value between 5 minutes and 30 days.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-kafka_java_api"}, {"document_id": "ibmcld_04939-55110-56793", "score": 29.361968328438856, "text": "\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\npublic static void addProtectionConfigurationToBucket(String bucketName) {\nSystem.out.printf(\"Adding protection to bucket: %sn\", bucketName);\n\nBucketProtectionConfiguration newConfig = new BucketProtectionConfiguration()\n.withStatus(BucketProtectionStatus.Retention)\n.withMinimumRetentionInDays(10)\n.withDefaultRetentionInDays(100)\n.withMaximumRetentionInDays(1000);\n\ncos.setBucketProtection(bucketName, newConfig);\n\nSystem.out.printf(\"Protection added to bucket %sn\", bucketName);\n}\n\npublic static void addProtectionConfigurationToBucketWithRequest(String bucketName) {\nSystem.out.printf(\"Adding protection to bucket: %sn\", bucketName);\n\nBucketProtectionConfiguration newConfig = new BucketProtectionConfiguration()\n.withStatus(BucketProtectionStatus.Retention)\n.withMinimumRetentionInDays(10)\n.withDefaultRetentionInDays(100)\n.withMaximumRetentionInDays(1000);", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/libraries?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_05044-55090-56773", "score": 29.361968328438856, "text": "\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\npublic static void addProtectionConfigurationToBucket(String bucketName) {\nSystem.out.printf(\"Adding protection to bucket: %sn\", bucketName);\n\nBucketProtectionConfiguration newConfig = new BucketProtectionConfiguration()\n.withStatus(BucketProtectionStatus.Retention)\n.withMinimumRetentionInDays(10)\n.withDefaultRetentionInDays(100)\n.withMaximumRetentionInDays(1000);\n\ncos.setBucketProtection(bucketName, newConfig);\n\nSystem.out.printf(\"Protection added to bucket %sn\", bucketName);\n}\n\npublic static void addProtectionConfigurationToBucketWithRequest(String bucketName) {\nSystem.out.printf(\"Adding protection to bucket: %sn\", bucketName);\n\nBucketProtectionConfiguration newConfig = new BucketProtectionConfiguration()\n.withStatus(BucketProtectionStatus.Retention)\n.withMinimumRetentionInDays(10)\n.withDefaultRetentionInDays(100)\n.withMaximumRetentionInDays(1000);", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_04866-7925-10174", "score": 29.100203111661926, "text": "\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time. A Content-MD5 header is required to ensure data integrity, and is automatically sent when using an SDK.\n\n\n\n Add a retention policy on an existing bucket \n\nThis implementation of the PUT operation uses the protection query parameter to set the retention parameters for an existing bucket. This operation allows you to set or change the minimum, default, and maximum retention period. This operation also allows you to change the protection state of the bucket.\n\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object-specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nA Content-MD5 header is required. This operation does not make use of extra query parameters.\n\nFor more information about endpoints, see [Endpoints and storage locations](https://cloud.ibm.com/docs/services/cloud-object-storage?topic=cloud-object-storage-endpointsendpoints)\n\nSyntax\n\nPUT https://{endpoint}/{bucket-name}?protection= path style\nPUT https://{bucket-name}.{endpoint}?protection= virtual host style\n\nExample request", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-7904-10153", "score": 29.100203111661926, "text": "\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time. A Content-MD5 header is required to ensure data integrity, and is automatically sent when using an SDK.\n\n\n\n Add a retention policy on an existing bucket \n\nThis implementation of the PUT operation uses the protection query parameter to set the retention parameters for an existing bucket. This operation allows you to set or change the minimum, default, and maximum retention period. This operation also allows you to change the protection state of the bucket.\n\nObjects written to a protected bucket cannot be deleted until the protection period has expired and all legal holds on the object are removed. The bucket's default retention value is given to an object unless an object-specific value is provided when the object is created. Objects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nA Content-MD5 header is required. This operation does not make use of extra query parameters.\n\nFor more information about endpoints, see [Endpoints and storage locations](https://cloud.ibm.com/docs/services/cloud-object-storage?topic=cloud-object-storage-endpointsendpoints)\n\nSyntax\n\nPUT https://{endpoint}/{bucket-name}?protection= path style\nPUT https://{bucket-name}.{endpoint}?protection= virtual host style\n\nExample request", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04939-57496-59284", "score": 28.364443415819082, "text": "\nSystem.out.printf(\"Minimum Retention (Days): %sn\", config.getMinimumRetentionInDays());\nSystem.out.printf(\"Default Retention (Days): %sn\", config.getDefaultRetentionInDays());\nSystem.out.printf(\"Maximum Retention (Days): %sn\", config.getMaximumRetentionInDays());\n}\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/libraries?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_05044-57476-59264", "score": 28.364443415819082, "text": "\nSystem.out.printf(\"Minimum Retention (Days): %sn\", config.getMinimumRetentionInDays());\nSystem.out.printf(\"Default Retention (Days): %sn\", config.getDefaultRetentionInDays());\nSystem.out.printf(\"Maximum Retention (Days): %sn\", config.getMaximumRetentionInDays());\n}\n}\n\n\n\n\n\n Upload a protected object \n\nObjects in protected buckets that are no longer under retention (retention period has expired and the object does not have any legal holds), when overwritten, will again come under retention. The new retention period can be provided as part of the object overwrite request or the default retention time of the bucket will be given to the object.\n\n\n\n Value Type Description \n\n Retention-Period Non-negative integer (seconds) Retention period to store on the object in seconds. The object can be neither overwritten nor deleted until the amount of time specified in the retention period has elapsed. If this field and Retention-Expiration-Date are specified a 400 error is returned. If neither is specified the bucket's DefaultRetention period will be used. Zero (0) is a legal value assuming the bucket's minimum retention period is also 0. \n Retention-expiration-date Date (ISO 8601 Format) Date on which it will be legal to delete or modify the object. You can only specify this or the Retention-Period header. If both are specified a 400 error will be returned. If neither is specified the bucket's DefaultRetention period will be used. \n Retention-legal-hold-id string A single legal hold to apply to the object. A legal hold is a Y character long string. The object cannot be overwritten or deleted until all legal holds associated with the object are removed. \n\n\n\npublic static void putObjectAddLegalHold(String bucketName, String objectName, String fileText, String legalHoldId) {", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-java"}, {"document_id": "ibmcld_01150-7-1811", "score": 27.79530862437813, "text": "\nFAQs \n\nAnswers to common questions about the IBM\u00ae Event Streams service.\n\n\n\n How do I use Kafka APIs to create and delete topics? \n\nIf you're using a Kafka client at 0.11 or later, or Kafka Streams at 0.10.2.0 or later, you can use APIs to create and delete topics. We've put some restrictions on the settings allowed when you create topics. Currently, you can modify the following settings only:\n\ncleanup.policy\n: Set to delete (default), compact or delete,compact\n\nretention.ms\n: The default retention period is 24 hours. The minimum is 1 hour and the maximum is 30 days. Specify this value as multiples of hours.\n\nNote: In the Enterprise plan, you can set this to any value.\n\nretention.bytes\n: The maximum size a partition (which consists of log segments) can grow to before we discard old log segments to free up space.\n\nNote: Enterprise: Set to any value between 100 KiB and 2 TiB. Standard: Set to any value between 100 KiB and 1 GiB.\n\nsegment.bytes\n: The segment file size for the log.\n\nNote: Enterprise: Set to any value between 100 KiB and 2 TiB. Standard: Set to any value between 100 KiB and 512 MiB.\n\nsegment.index.bytes\n: The size of the index that maps offsets to file positions.\n\nNote: Enterprise: Set to any value between 100 KiB and 1 TiB. Standard: Set to any value between 100 KiB and 100 MiB.\n\nsegment.ms\n: The period of time after which Kafka will force the log to roll even if the segment file isn't full.\n\nNote: Set to any value between 5 minutes and 30 days.\n\nSee the following example of default value settings.\n\nDetails for topic testit\nTopic name Internal? Partition count Replication factor\ntestit false 1 3\n\nPartition details for topic testit\nPartition ID Leader Replicas In-sync\n0 1 [1 5 0] [1 5 0]\n\nConfiguration parameters for topic testit\nName Value\ncleanup.policy delete", "title": "", "source": "https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-faqs"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01327-4660-7015", "score": 22.066517637732193, "text": "\nActions that generate events for namespaces \n\n\n\nTable 9. Actions that generate events for namespaces\n\n Action Description Data Event \n\n container-registry.namespace.create Create a namespace in Container Registry.<br><br>Assign a Container Registry namespace to a resource group. \n container-registry.namespace.delete Delete a namespace from Container Registry. \n container-registry.namespace.list List the Container Registry namespaces in your IBM account. \n\n\n\n\n\n\n\n Actions that generate events for plans \n\n\n\nTable 10. Actions that generate events for plans\n\n Action Description Data Event \n\n container-registry.plan.get Display information about the current pricing plan. \n container-registry.plan.set Upgrade to the standard plan. \n\n\n\n\n\n\n\n Actions that generate events for quotas \n\n\n\nTable 11. Actions that generate events for quotas\n\n Action Description Data Event \n\n container-registry.quota.get Display the current quotas for traffic and storage, and the usage information against those quotas. \n container-registry.quota.set Modify the quotas. Quota settings must be managed separately for your account in each registry instance. You can set quota limits for storage in your free or standard plan. \n\n\n\n\n\n\n\n Actions that generate events for retention policies \n\n\n\nTable 12. Actions that generate events for retention policies\n\n Action Description Data Event \n\n container-registry.retention.analyze List the images that are deleted if you apply a specific retention policy. \n container-registry.retention.list List the image retention policies for your account. \n container-registry.retention.set Set a policy to retain images in a namespace in Container Registry by applying specified criteria. \n\n\n\n\n\n\n\n Actions that generate events for settings \n\n\n\nTable 13. Actions that generate events for settings\n\n Action Description Data Event \n\n container-registry.settings.get Get registry service settings for the targeted account, such as whether platform metrics are enabled. \n container-registry.settings.set Update registry service settings for the targeted account, such as enabling platform metrics. \n\n\n\n\n\n\n\n Actions that generate events for signing images \n\n\n\nTable 14. Actions that generate events for signing images\n\n Action Description Data Event \n\n container-registry.signature.delete Delete a signature from an image in Container Registry. True", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-at_events"}, {"document_id": "ibmcld_01409-1655-3233", "score": 21.896553381943672, "text": "\nList images. GET /api/v1/images container-registry.image.list container-registry.image.list \n Delete more than one image. POST /api/v1/images/bulkdelete container-registry.image.delete container-registry.image.bulkdelete \n List images by digest. POST /api/v1/images/digests container-registry.image.list container-registry.image.list \n Create tag. POST /api/v1/images/tags container-registry.image.pull<br><br>container-registry.image.push container-registry.image.tag \n Delete image. DELETE /api/v1/images/{image} container-registry.image.delete container-registry.image.delete \n Inspect an image. GET /api/v1/images/{image}/json container-registry.image.inspect container-registry.image.inspect \n Get image manifest. GET /api/v1/images/{image}/manifest container-registry.image.inspect container-registry.manifest.inspect \n\n\n\n\n\n\n\n Message API methods \n\n\n\nTable 3. Messages\n\n Action Method IAM ACTION AT ACTION \n\n Return any published system messages. GET /api/v1/messages \n\n\n\n\n\n\n\n Namespace API methods \n\n\n\nTable 4. Namespaces\n\n Action Method IAM ACTION AT ACTION \n\n List namespaces. GET /api/v1/namespaces container-registry.namespace.list container-registry.namespace.list \n Detailed namespace list. GET /api/v1/namespaces/details container-registry.namespace.list container-registry.namespace.list \n Create namespace. PUT /api/v1/namespaces/{namespace} container-registry.namespace.create container-registry.namespace.create \n Assign namespace. PATCH /api/v1/namespaces/{namespace} container-registry.namespace.create container-registry.namespace.update \n Delete namespace.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_at_iam"}, {"document_id": "ibmcld_01409-4151-6017", "score": 21.701351733628876, "text": "\nGET /api/v1/retentions container-registry.retention.list container-registry.retention.list \n Set the retention policy for the specified namespace. POST /api/v1/retentions container-registry.retention.set container-registry.retention.set \n Analyze a retention policy, and get a list of what would be deleted by it. POST /api/v1/retentions/analyze container-registry.retention.analyze container-registry.retention.analyze \n Get the retention policy for the specified namespace. GET /api/v1/retentions/{namespace} container-registry.retention.get container-registry.retention.get \n\n\n\n\n\n\n\n Settings API methods \n\n\n\nTable 8. Settings\n\n Action Method IAM ACTION AT ACTION \n\n Get registry service settings for the targeted account, such as whether platform metrics are enabled. GET /api/v1/settings container-registry.settings.get container-registry.settings.get \n Update registry service settings for the targeted account, such as enabling platform metrics. PATCH /api/v1/settings container-registry.settings.set container-registry.settings.set \n\n\n\n\n\n\n\n Tag API methods \n\n\n\nTable 9. Tags\n\n Action Method IAM ACTION AT ACTION \n\n Delete tag. DELETE /api/v1/tags/{image} container-registry.image.delete container-registry.image.untag \n\n\n\n\n\n\n\n Trash API methods \n\n\n\nTable 10. Trash\n\n Action Method IAM ACTION AT ACTION \n\n List images in the trash. GET /api/v1/trash container-registry.image.delete container-registry.trash.list \n Restore a digest and all associated tags. POST /api/v1/trash/{digest}/restoretags container-registry.image.push container-registry.trash.restore \n Restore deleted image. POST /api/v1/trash/{image}/restore container-registry.image.push container-registry.trash.restore \n\n\n\n\n\n\n\n\n\n Vulnerability Advisor API methods \n\n\n\n Report API methods \n\n\n\nTable 11. Report\n\n Action Method IAM ACTION AT ACTION \n\n Get the vulnerability assessment for all images.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_at_iam"}, {"document_id": "ibmcld_01409-2859-4626", "score": 21.374818150162252, "text": "\nGET /api/v1/namespaces/details container-registry.namespace.list container-registry.namespace.list \n Create namespace. PUT /api/v1/namespaces/{namespace} container-registry.namespace.create container-registry.namespace.create \n Assign namespace. PATCH /api/v1/namespaces/{namespace} container-registry.namespace.create container-registry.namespace.update \n Delete namespace. DELETE /api/v1/namespaces/{namespace} container-registry.namespace.delete container-registry.namespace.delete \n\n\n\n\n\n\n\n Plan API methods \n\n\n\nTable 5. Plans\n\n Action Method IAM ACTION AT ACTION \n\n Get plans for the targeted account. GET /api/v1/plans container-registry.plan.get container-registry.plan.get \n Update plans for the targeted account. PATCH /api/v1/plans container-registry.plan.set container-registry.plan.set \n\n\n\n\n\n\n\n Quota API methods \n\n\n\nTable 6. Quotas\n\n Action Method IAM ACTION AT ACTION \n\n Get quotas for the targeted account. GET /api/v1/quotas container-registry.quota.get container-registry.quota.get \n Update quotas for the targeted account. PATCH /api/v1/quotas container-registry.quota.set container-registry.quota.set \n\n\n\n\n\n\n\n Retention API methods \n\n\n\nTable 7. Retentions\n\n Action Method IAM ACTION AT ACTION \n\n List retention policies for all namespaces in the targeted IBM Cloud account. GET /api/v1/retentions container-registry.retention.list container-registry.retention.list \n Set the retention policy for the specified namespace. POST /api/v1/retentions container-registry.retention.set container-registry.retention.set \n Analyze a retention policy, and get a list of what would be deleted by it. POST /api/v1/retentions/analyze container-registry.retention.analyze container-registry.retention.analyze \n Get the retention policy for the specified namespace.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_at_iam"}, {"document_id": "ibmcld_05596-5434-6943", "score": 19.78863289123661, "text": "\nThe image is created in your private registry. You can run the ibmcloud cr images command to verify that the image was created.\n\nREPOSITORY NAMESPACE TAG DIGEST CREATED SIZE VULNERABILITY STATUS\nus.icr.io/namespace/cf-py namespace latest cb03170b2cb2 3 minutes ago 271 MB OK\n\n\n\n\n\n\n\n Step 3: Deploy a container from your image \n\nDeploy your app as a container in a Kubernetes cluster.\n\n\n\n1. Create a configuration YAML file that is named cf-py.yaml and update <registry_namespace> with the name of your private image registry. This configuration file defines a container deployment from the image that you created in the previous lesson and a service to expose the app to the public.\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\nlabels:\napp: cf-py\nname: cf-py\nnamespace: default\nspec:\nselector:\nmatchLabels:\napp: cf-py\nreplicas: 1\ntemplate:\nmetadata:\nlabels:\napp: cf-py\nspec:\ncontainers:\n- image: us.icr.io/<registry_namespace>/cf-py:latest\nname: cf-py\n\n---\napiVersion: v1\nkind: Service\nmetadata:\nname: cf-py-nodeport\nlabels:\napp: cf-py\nspec:\nselector:\napp: cf-py\ntype: NodePort\nports:\n- port: 5000\nnodePort: 30872\nShow more\n\n\n\nTable 2. Understanding the YAML file components\n\n Parameter Description \n\n image In us.icr.io/<registry_namespace>/cf-py:latest, replace <registry_namespace> with the namespace of your private image registry. If you are unsure what your namespace is, run the ibmcloud cr namespaces command to find it. \n nodePort Expose your app by creating a Kubernetes service of type NodePort.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cf_tutorial"}, {"document_id": "ibmcld_05596-4175-5823", "score": 19.724865460233787, "text": "\nSet the app directory\nas the working directory\nWORKDIR /cf-py/\nCOPY . .\n\nInstall any requirements that are defined\nRUN pip install --no-cache-dir -r requirements.txt\n\nUpdate the openssl package\nRUN apt-get update && apt-get install -y \nopenssl\n\nStart the app.\nCMD [\"python\", \"welcome.py\"]\nShow more\n3. Save your changes in the nano editor by pressing ctrl + o. Confirm your changes by pressing enter. Exit the nano editor by pressing ctrl + x.\n4. Build a Docker image that includes your app code and push it to your private registry.\n\ndocker build -t <region>.icr.io/namespace/cf-py .\n\n\n\nTable 1. Understanding this command's components\n\n Option Description \n\n build The build command. \n -t registry.<region>.icr.io/namespace/cf-py Your private registry path, which includes your unique namespace and the name of the image. For this example, the same name is used for the image as the app directory, but you can choose any name for the image in your private registry. If you are unsure what your namespace is, run the ibmcloud cr namespaces command to find it. \n . The location of the Dockerfile. If you are running the build command from the directory that includes the Dockerfile, enter a period (.). Otherwise, use the relative path to the Dockerfile. \n\n\n\nThe image is created in your private registry. You can run the ibmcloud cr images command to verify that the image was created.\n\nREPOSITORY NAMESPACE TAG DIGEST CREATED SIZE VULNERABILITY STATUS\nus.icr.io/namespace/cf-py namespace latest cb03170b2cb2 3 minutes ago 271 MB OK\n\n\n\n\n\n\n\n Step 3: Deploy a container from your image \n\nDeploy your app as a container in a Kubernetes cluster.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cf_tutorial"}, {"document_id": "ibmcld_01377-13470-15034", "score": 19.212504003588776, "text": "\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam"}, {"document_id": "ibmcld_01387-13496-15060", "score": 19.212504003588776, "text": "\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam&interface=ui"}, {"document_id": "ibmcld_01377-8075-10005", "score": 18.776660797448617, "text": "\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam"}, {"document_id": "ibmcld_01387-8101-10031", "score": 18.776660797448617, "text": "\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam&interface=ui"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_14434-1551-3515", "score": 14.46285715027049, "text": "\nMulticluster support Maximum number depends on VMware\u00ae sizing guidelines Supported. Automated configuration not included. \n Client-managed updating and patching of VMware stack Client-managed updates - Native VMware tools (VMware Update Manager\u2122)<br><br>[3] Client-managed updates - Native VMware tools (VMware Update Manager) \n Backup and restore Manually, by using Veeam\u00ae Backup and restore solution not included \n Software-defined networking<br><br>[4] NSX DC SP Base, Professional, Advanced, or Enterprise Plus NSX DC SP Base, Professional, Advanced, or Enterprise Plus. Automated configuration not included. \n NSX license upgrade options<br><br>[5] Upgrade available from NSX Advanced to Enterprise. None \n vSAN license editions vSAN Advanced or Enterprise vSAN Advanced or Enterprise \n Add-on services Supported<br><br>[6] Not supported by the automation of this solution. You can bring and install your own software. \n\n\n\n\n\n\n\n vCenter Server vs VMware Regulated Workloads \n\nReview the following table to understand the differences in feature support for vCenter Server instances and VMware Regulated Workloads.\n\n\n\nTable 2. Supported features for vCenter Server instances and VMware Regulated Workloads\n\n Feature vCenter Server offering Regulated Workloads offering \n\n vCenter Server version 7.0 Update 3k 7.0 Update 3k \n vSphere version 7.0 Update 3k 7.0 Update 3k \n NSX edition NSX DC SP Base, Professional, Advanced, or Enterprise Plus NSX DC SP Advanced or Enterprise Plus \n NSX networking solution <br><br>[7] NSX-T\u2122 NSX-T \n NFS Optional Not allowed \n vSAN Optional Required \n Consolidated cluster Optional Optional \n Separate management cluster Supported Supported \n Minimum number of ESXi servers For vSAN, 4 servers. <br>For NFS, 3 servers. 6 servers - 4 for the consolidated cluster and 2 for the gateway cluster. \n Gateway cluster Optional Required. Juniper vSRX, FortiGate Virtual Appliance, Bring your own gateway, or FortiGate Security Appliance.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-inst_comp_chart"}, {"document_id": "ibmcld_07578-1129740-1131838", "score": 13.604659605055783, "text": "\nA resource restoration can fail if you try to restore a resource in a deleted resource group or the resource restoration request isn't submitted in time. Most requests must be submitted within 7 days.\n* How do I retrieve details on a resource that is scheduled for reclamation?\n\nAfter the instance is deleted from the console, you can view it in your account by using the CLI in the SCHEDULED state. The SCHEDULED state indicates that this instance is scheduled for reclamation. For more information, see [Working with resources and resource groups](https://cloud.ibm.com/docs/account?topic=cli-ibmcloud_commands_resourcecommand-options-37).\n* Can you restore a resource that is in a deleted resource group?\n\nYou can restore a resource from a deleted resource group. [Create a support case](https://cloud.ibm.com/unifiedsupport/cases/add) in the IBM Cloud Support Center and specify in the description of the case that you want to restore the resource that's in a deleted resource group.\n\n\n\nRunning secure enterprise workloads\n\n\n\n* How do I set up an enterprise account?\n\nTo set up an enterprise, you must be the account owner or an administrator on the Billing account management service. You use the IBM Cloud console to create an enterprise account, enter the name of your company, provide your company's domain, create your enterprise structure, and more. For more information, see [Setting up an enterprise](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-tutorial).\n* When I create an enterprise, does my IBM Cloud account become the enterprise account?\n\nNo, your IBM Cloud account does not become the enterprise account. Your account is added to the enterprise hierarchy. For more information, see [Enterprise hierarchy](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterpriseenterprise-hierarchy).\n* Can I use my IBM Cloud account to create multiple enterprise accounts?\n\nNo, your IBM Cloud account can be a part of only one enterprise account. When you create an enterprise, your account is added to the enterprise hierarchy.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1132221-1134319", "score": 13.604659605055783, "text": "\nA resource restoration can fail if you try to restore a resource in a deleted resource group or the resource restoration request isn't submitted in time. Most requests must be submitted within 7 days.\n* How do I retrieve details on a resource that is scheduled for reclamation?\n\nAfter the instance is deleted from the console, you can view it in your account by using the CLI in the SCHEDULED state. The SCHEDULED state indicates that this instance is scheduled for reclamation. For more information, see [Working with resources and resource groups](https://cloud.ibm.com/docs/account?topic=cli-ibmcloud_commands_resourcecommand-options-37).\n* Can you restore a resource that is in a deleted resource group?\n\nYou can restore a resource from a deleted resource group. [Create a support case](https://cloud.ibm.com/unifiedsupport/cases/add) in the IBM Cloud Support Center and specify in the description of the case that you want to restore the resource that's in a deleted resource group.\n\n\n\nRunning secure enterprise workloads\n\n\n\n* How do I set up an enterprise account?\n\nTo set up an enterprise, you must be the account owner or an administrator on the Billing account management service. You use the IBM Cloud console to create an enterprise account, enter the name of your company, provide your company's domain, create your enterprise structure, and more. For more information, see [Setting up an enterprise](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-tutorial).\n* When I create an enterprise, does my IBM Cloud account become the enterprise account?\n\nNo, your IBM Cloud account does not become the enterprise account. Your account is added to the enterprise hierarchy. For more information, see [Enterprise hierarchy](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterpriseenterprise-hierarchy).\n* Can I use my IBM Cloud account to create multiple enterprise accounts?\n\nNo, your IBM Cloud account can be a part of only one enterprise account. When you create an enterprise, your account is added to the enterprise hierarchy.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_11163-1442-3558", "score": 13.403703208946682, "text": "\nFor more information, see [Configuring the architecture](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-config-projecthow-to-config).\n\nSupport for deployable architectures onboarded from private or public GitHub repositories\n: You can now deploy architectures that are onboarded to the catalog from either a private or public GitHub repository. Previously, only deployable architectures onboarded from a public GitHub repository were supported.\n\n\n\n\n\n 17 April 2023 \n\nCheck out deployable architectures in the catalog\n: IBM Cloud provides deployable architectures in the catalog, which are products that provide automation for the deployment of common architectural patterns that combine one or more cloud resources and are designed for scalability and modularity. Go to the catalog, and [filter by Deployable architectures](https://cloud.ibm.com/catalogreference_architecture) to review the growing catalog of options. For more information, see [Identifying the right infrastructure architecture](https://cloud.ibm.com/docs/overview?topic=overview-secure-enterprisedefine-architecture).\n\nIBM Cloud projects for automated IaC deployments\n: You can now configure, deploy, and monitor deployments by using DevOps best practices with projects. By using projects, you can manage Infrastructure as Code (IaC) at scale and across accounts to ensure that the configuration is always valid, secure, and compliant. [Learn more about IaC deployments with projects](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-understanding-projects).\n\nOnboard customized deployable architectures for your enterprise users\n: You can customize IBM Cloud deployable architectures to meet your enterprise\u2019s needs, and then leverage private catalogs to make only approved and compliant architectures available for your enterprise developers to deploy. For more information, see [Customizing an IBM Cloud deployable architecture](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-customize-from-catalog).\n\n\n\n\n\n 12 April 2023 \n\nSpecify language support for community-supported products", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-whatsnew"}, {"document_id": "ibmcld_12623-6811-8811", "score": 13.25009606693515, "text": "\n* A single invoice for all usage within the enterprise, so understanding costs is easier\n* A single place to manage payment methods, so you can update once for all accounts\n\n\n\nLearn more in [Centrally manage billing and usage with enterprises](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-enterprise).\n\n\n\n\n\n Enterprise support \n\nThe level of support that is assigned to an IBM Cloud enterprise defaults to the highest support plan within the enterprise. All child accounts within the enterprise also default to the highest support plan. For more information about the support experience, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-planssupport_level_enterprise).\n\n\n\n\n\n Resource management \n\nResources and services within an enterprise function the same as in stand-alone accounts. Each account in an enterprise can contain resources in resource groups. Account groups can't contain resources. For more information, see [Managing resources](https://cloud.ibm.com/docs/account?topic=account-manage_resource).\n\nZoom\n\n![A diagram that shows that resources are contained in accounts in the enterprise.](https://cloud.ibm.com/docs-content/v1/content/d4595e5202a9a27767cf034e81b038cdf772e0d5/secure-enterprise/images/enterprise-resources.svg)\n\nFigure 3. Resources in an enterprise\n\nAs with all accounts, resources are tied to the resource group and account in which they're created, so they can't be moved between accounts in the enterprise. However, the enterprise's flexible account structure means you can move resources within the enterprise by moving the accounts that contain them.\n\n\n\n\n\n Top-down usage reporting \n\nFrom the enterprise account, you can view resource usage from all accounts in the enterprise. Starting at the enterprise level, you see estimated usage costs that are broken down by account and account groups. You can navigate down within the enterprise structure to see the costs within each level.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterprise&interface=ui"}, {"document_id": "ibmcld_14664-8842-10671", "score": 13.227044152468842, "text": "\nThe 10 IOPS/GB performance level is limited to a maximum capacity of 4 TB per file share.\n* Individual configuration of file shares\n\n(NSX-V only) If you choose the NFS option, one 2 TB and four IOPS/GB file share for management components are ordered.\n\n\n\n\n\n\n\n vSAN storage \n\nThe vSAN option offers customized configurations, with various options for disk type, size, and quantity:\n\n\n\n* Disk quantity - 2, 4, 6, 8, or 10\n* Storage disk - 960 GB SSD, 1.9 TB SSD, 3.8 TB SSD, or 7.68 TB SSD (SSD SED disks are supported for Skylake servers.)\n\nIn addition, two cache disks of 960 GB are also ordered per host.\n\n3.8 TB SSD (solid-state disk) drives are supported when they are made generally available in a data center.\n* High Performance with Intel Optane - this option provides two extra capacity disk bays for a total of 10 capacity disks. It's available only for vSphere 6 instances.\n\n\n\n\n\n\n\n\n\n Licenses (IBM-provided or BYOL) and fees \n\n\n\n* VMware vSphere Enterprise Plus 7.0 (NSX-T only)\n* VMware vCenter Server 7.0\n* VMware NSX Service Providers Edition (Base, Advanced, or Enterprise) 6.4\n* (For vSAN clusters) VMware vSAN Advanced or Enterprise 7.0\n* Support and Services fee (one license per node)\n\n\n\n\n\n\n\n\n\n Technical specifications for vCenter Server expansion nodes \n\nEach vCenter Server expansion node deploys and incurs charges for the following components in your IBM Cloud account.\n\n\n\n Hardware for expansion nodes \n\nOne bare metal server with the configuration presented in [Technical specifications for vCenter Server instances](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_vcenterserveroverviewvc_vcenterserveroverview-specs).\n\n\n\n\n\n Licenses and fees for expansion nodes \n\n\n\n* One vSphere Enterprise Plus 7.0 (NSX-T only)\n* One NSX Service Providers Edition (Base, Advanced, or Enterprise) 6.4", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_vcenterserveroverview"}, {"document_id": "ibmcld_12578-1629-3315", "score": 13.106342235546093, "text": "\nGo to the [IBM Cloud catalog](https://cloud.ibm.com/catalogreference_architecture), and select a deployable architecture.\n2. Click Review deployment options > Customize locally > Start customizing to download a customization bundle that includes a prebuilt catalog manifest file.\n3. Use the following documentation to review and customize the JSON file:\n\n\n\n* [Catalog manifest template](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-manifestmanifest-template)\n* [Catalog manifest values](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-manifestmanifest-values)\n\n\n\n\n\nYou must store your catalog manifest at the root of your repository and name the file ibm_catalog.json.\n\n\n\n\n\n Catalog manifest template \n\nYou can use the following template to modify an existing catalog manifest. All values are optional, and you can determine which values you want to include and which values are not needed. For more information about each value, see [Catalog manifest values](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-manifestmanifest-values).\n\nYou can also see the template in a swagger format. For more information, see [Catalog Management API](https://cm.globalcatalog.cloud.ibm.com/api) and find the Catalog Manifest schema.\n\n{\n\"products\": [\n{\n\"label\": \"DISPLAY NAME\",\n\"name\": \"VERSION PROGRAMMATIC NAME\",\n\"version\": \"VERSION NUMBER\",\n\"product_kind\": \"PRODUCT KIND\",\n\"tags\": \"TAG\"],\n\"keywords\": \"keyword\"],\n\"short_description\": \"SHORT DESCRIPTION\",\n\"long_description\": \"LONG DESCRIPTION\",\n\"provider_name\": \"PROVIDER NAME\",\n\"offering_docs_url\": \"DOCS URL\",\n\"offering_icon_url\": \"ICON URL\",\n\"support_details\": \"SUPPORT DETAILS\",", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-manifest"}, {"document_id": "ibmcld_12552-5548-7750", "score": 13.051176948129593, "text": "\nFor more information, see [Enterprise hierarchy](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterprise&interface=uienterprise-hierarchy)\n\n\n\n\n\n Can I create common resources for all of my child accounts? \n\nAlthough you can create resources at the enterprise account level, this method is not a best practice. You can follow best practice by using resource groups and access groups to create and share resources.\n\nFor more information, see [Working with resources in an enterprise](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-best-practiceschild-resources-enterprise), [Resource management](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-what-is-enterpriseenterprise-resources), and [Best practices for assigning access](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-access-enterprises).\n\n\n\n\n\n How do I know how many child accounts are in the enterprise as an enterprise account owner? \n\nTo see all accounts within your enterprise, go to your Enterprise dashboard in the console and click Accounts.\n\n\n\n\n\n Do I automatically have access to child accounts and their resources as an enterprise administrator? \n\nNo, you do not automatically have access to child accounts and their resources. You need to be invited to individual child accounts and assigned access policies to manage resources. For more information, see [User management for enterprises](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-access-management).\n\n\n\n\n\n Can I add users to child accounts as an enterprise administrator? \n\nNo, you can't add users to child accounts.\n\nYou need to be invited to the child account and assigned the editor or administrator role for the User management service to add users to a child account.\n\n\n\n\n\n Do all accounts within an enterprise require the same level of support? \n\nYes, all accounts within an IBM Cloud enterprise are assigned the same level of support. The level of support that is assigned to an enterprise defaults to the highest support plan within the enterprise. All child accounts within the enterprise also default to the highest support plan.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-faqs"}, {"document_id": "ibmcld_12563-0-1448", "score": 12.913731412075078, "text": "\n\n\n\n\n\n\n  Getting help and support \n\nIf you experience an issue or have questions, you can use the following resources before you open a support case.\n\n\n\n*  Review the [FAQs about projects](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-project-faqs) and [FAQs about enterprises](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-faqs) in the product documentation.\n*  Review the troubleshooting documentation for [enterprises](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-troubleshoot-view-enterprise) and [projects](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-troubleshoot-project-access) to troubleshoot and resolve common issues.\n*  Check the status of the IBM Cloud platform and resources by going to the [Status page](https://cloud.ibm.com/status).\n*  Review [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud) to see whether other users experienced the same problem. When you ask a question, tag the question with projects or enterprise, so that it's seen by the IBM Cloud development teams.\n\n\n\nIf you still can't resolve the problem, you can open a support case. For more information, see [Creating support cases](https://cloud.ibm.com/docs/get-support?topic=get-support-open-case). And, if you're looking to provide feedback, see [Submitting feedback](https://cloud.ibm.com/docs/overview?topic=overview-feedback).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-get-help"}, {"document_id": "ibmcld_05496-0-1004", "score": 12.853505299916673, "text": "\n\n\n\n\n\n\n  Why does my service binding to a Db2 Enterprise instance fail? \n\n  What\u2019s happening \n\nYou cannot create a Code Engine service binding with a Db2 Enterprise service instance when you use the CLI or API. You receive a failed error message.\n\n  Why it\u2019s happening \n\nDb2 Enterprise does not support the IBM writer role that is used by default for Code Engine service bindings.\n\n  How to fix it \n\nTry one of these solutions.\n\n\n\n1.  If you are using the CLI to create the service binding with the Db2 Enterprise service instance to your Code Engine app or job, use the --role Manager option when you run the [ibmcloud ce application bind](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-application-bind) command or the [ibmcloud ce job bind](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-job-bind) command.\n2.  Use the console to create the service binding with the Db2 Enterprise service instance to your Code Engine app or job, and specify the role of Manager.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-ts-sb-db2createfails"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_14738-7598-10031", "score": 22.954562838676097, "text": "\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Encryption Provide secure SSL connections to administration portals and replication endpoints. Workload can be deployed by using AES 256-bit encrypted data stores with unique key per customer instance. Backups are encrypted uniquely per customer. Choose encrypted data stores when you are deploying workloads into the environment where appropriate. Use encrypted networking for workload to workload and workload to IBM Cloud Service connections. Use the IBM Cloud private network where appropriate. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Backup of management configuration data Conduct backups of the management component configurations. These backups include single-tenant vCenter Server, VMware NSX-T, VMware Cloud Director\u2122, and service configurations. Offsite immutable backup copies are enabled in an independent backup account and they run daily. \n Backup of workloads Enable backup services for customer workload. Choose and implement a backup provider for critical workloads. For more information, see [Understanding business continuity and disaster recovery](https://cloud.ibm.com/docs/vmware-service?topic=vmware-service-bc-dr). \n Recovery of configuration Conduct recovery in the original data center after the infrastructure is available. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, provide customer restore services after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vmaas-understand-responsib"}, {"document_id": "ibmcld_14598-9419-11893", "score": 22.755189218551997, "text": "\nResponsibilities for security and regulation compliance for VMware Solutions offerings (other than VMware Shared)\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Encryption Provide integration with Key Protect and Hyper Protect Crypto Services through KMIP service as an option for implementing data at-rest encryption. Configure and manage encryption for both data at rest and in transit, as needed. \n\n\n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as:\n\n\n\n* Providing dependencies on disaster recovery sites\n* Provision disaster recovery environments\n* Data and configuration backup\n* Replicating data and configuration to the disaster recovery environment\n* Fail over on disaster events\n\n\n\n\n\n Disaster recovery for VMware Shared \n\nThe following table describes the responsibilities that are related to disaster recovery for VMware Shared.\n\n\n\nTable 8. Responsibilities for disaster recovery for VMware Shared\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Backup of configuration data Backups are conducted of the shared management components to include customer environment configurations. Offsite backup copies are enabled and they run daily. \n Backup of workload Backup services are enabled for customer workload. Configure individual backup jobs to include critical systems. Offsite copies can be enabled per request. \n Recovery of configuration Recovery will be conducted in the original data center after the infrastructure is available. If long-term outage occurs, offsite recovery is conducted. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, customer restore services will be provided after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover. Restore systems from the configured backup jobs. \n\n\n\n\n\n\n\n Disaster recovery for VMware Solutions offerings (other than VMware Shared)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-understand-responsib"}, {"document_id": "ibmcld_01092-7-2034", "score": 21.893452510473722, "text": "\nDisaster recovery \n\nDisaster recovery (DR) backups for IBM\u00ae Db2\u00ae Warehouse on Cloud are enabled by default and supplement daily snapshot backups. DR backups are used exclusively for system recovery purposes by IBM service operators if there is a disaster or system loss.\n\nIf a disaster event occurs at the data center where your Db2 Warehouse on Cloud instance is deployed, IBM service operators will work with you to stand up a new data warehouse in a different data center, by using the most recent disaster recovery backup. There is no additional charge for these backups.\n\nThe RPO (Recovery Point Objective) and RTO (Recovery Time Objective) for DR backups for each cloud provider are described in the following sections. On IBM Cloud, DR backups are geo-replicated by default. You can open a support ticket to not have your DR backups replicated to certain regions to comply with your data retention policies. On AWS, DR backups are stored in another Availability Zone in the same region and can also be geo-replicated at an additional cost.\n\nFor more information about DR and replication on Db2 Warehouse on Cloud, see [Replication](https://www.ibm.com/support/knowledgecenter/SS6NHC/com.ibm.swg.im.dashdb.idrca.doc/overview/ovu-db2woc.html).\n\n\n\n IBM Cloud \n\nWhen deployed on IBM Cloud, a full backup of the database is taken once a week for disaster recovery. This DR backup is encrypted and stored in IBM Cloud Object Storage (COS).\n\nIBM COS replicates each DR backup across multiple IBM Cloud regions to ensure availability if a single zone fails.\n\nDR backups of the last 2 weeks are retained by default. The RPO for DR backups on IBM Cloud is 1 week. The RTO if a disaster occurs is dependent upon the size of the database \u2013 1.5 hours per terabyte of data.\n\n\n\n\n\n Amazon Web Services \n\nWhen deployed on Amazon Web Services, a full backup of the database is taken once a day for disaster recovery. This DR backup is encrypted and stored in Amazon Web Services S3.\n\nDR backups of the last 7 days are retained by default.", "title": "", "source": "https://cloud.ibm.com/docs/Db2whc?topic=Db2whc-dr"}, {"document_id": "ibmcld_15843-7468-9604", "score": 21.59025971898206, "text": "\nAudit records IBM provides audit records of the VPC resource lifecycle through IBM Cloud Activity Tracker. The Customer uses IBM Cloud Activity Tracker tooling to monitor audit records. \n Security groups and ACLs IBM provides the ability to restrict access to virtual server instances by using security groups and networks ACLs. The Customer uses security groups and network ACLs to secure their virtual server instances, such as restricting what IP addresses can SSH into the instance. \n Public Network Access IBM provides options to use a public gateway or floating IP addresses. The Customer chooses how to connect their workload to the public internet, if applicable, either through a public gateway or floating IP. \n Access restriction IBM provides security measures for customers to restrict access to resources and resource groups. The Customer restricts user access to the appropriate resources and resource groups. \n Activity tracker IBM provides logging and monitoring tools. The Customer integrates IBM Cloud Activity Tracker and IBM Cloud Monitoring data into their auditing and monitoring processes. \n Encryption IBM Cloud VPN for VPC supports encrypted traffic by using IKE/IPsec policies. The Customer ensures that their connection is encrypted end-to-end, if required. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 6. Responsibilities for disaster recovery\n\n Task IBM Responsibilities Your Responsibilities \n\n Load balancer and VPN disaster recovery IBM Cloud Load Balancer and VPN for VPC have off-site storage and replication of configuration data in an out-of-region disaster recovery node with daily backups. This data is fully managed by IBM Cloud and no customer input is required to ensure service recovery, although there can be up to a 24-hour loss of configuration data. The Customer sets up their backup and recovery strategies for workload data.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-responsibilities-vpc"}, {"document_id": "ibmcld_08669-4740-6634", "score": 20.82223731669092, "text": "\nYou are responsible for the security and compliance of your application data.\n\n\n\nTable 4. Responsibilities for security and regulation compliance\n\n Task IBM responsibilities Your responsibilities \n\n Applications Maintain controls that are commensurate to [various industry compliance standards](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-security-and-compliancecompliance-ready). Set up and maintain security and regulation compliance for your apps and data. For example, you can enable extra security settings to meet your compliance needs by choosing how and when to [import](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-importing-keysplan-ahead), [wrap](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-wrap-keys), [rotate](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-importing-keysplan-ahead), [rewrap](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-rewrap-keys), and [delete](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys) keys. \n Encryption IBM is responsible for the encryption of keys. Keep your root of trust, the master key parts, on either your workstation or smart cards. \n Master key backups IBM never touches your master key. Backup your master key in a regular basis to your smart card or workstation. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-shared-responsibilities"}, {"document_id": "ibmcld_07285-5829-8487", "score": 20.44881255165058, "text": "\nIdentity and access IBM provides the function to restrict access to resources through the IBM Cloud console and REST APIs. The Customer is responsible for managing access to resources through IBM Cloud Identity and Access Management (IAM). \n\n\n\n\n\n\n\n Security and regulation compliance \n\nSecurity and regulation compliance includes tasks, such as security controls implementation and compliance certification.\n\n\n\nTable 5. Responsibilities for security and regulation compliance\n\n Task IBM Responsibilities Your Responsibilities \n\n Encryption IBM does not provide encryption capabilities. The Customer is responsible for encryption of data on disk, in motion, and in backups. The Customer is also responsible for choosing and managing appropriate additional security features. If the Customer uses Key Protect (Bring Your Own Key), or another form of encryption, the Customer is responsible for managing the service authorization and keys. \n Security IBM is responsible for ensuring the security of data on disk and data in motion within its infrastructure. The Customer is responsible for restricting user access to the appropriate resources and resource groups. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks, such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 6. Responsibilities for disaster recovery\n\n Task IBM Responsibilities Your Responsibilities \n\n Diversity IBM provides diverse network options for consumption. The Customer must ensure diversity of Direct Link is deployed. \n Redundancy IBM provides diverse network options for consumption. Direct Link is not a redundant service. The Customer is responsible for establishing redundancy, as needed, via BGP schema. The Customer must also understand that Direct Link is not a redundant service. While IBM Cloud supplies Diverse Router (XCR) options, failover must be built into the BGP scheme a customer deploys between multiple Direct Links. \n Host service in multiple regions IBM is responsible for hosting this service in multiple regions. The Customer is responsible for designing and deploying their workload in a way that achieves the wanted availability and Disaster Recovery capabilities by using provided tools. For example, deploy in different zones of a region, use at least two load balancers that are located in different zones, and either use DNS records to point to the load balancers, or ensure that your application can handle a list of IP addresses that it can connect to.", "title": "", "source": "https://cloud.ibm.com/docs/dl?topic=dl-dl-responsibilities"}, {"document_id": "ibmcld_01092-1621-2411", "score": 20.011178576072098, "text": "\nThe RPO for DR backups on IBM Cloud is 1 week. The RTO if a disaster occurs is dependent upon the size of the database \u2013 1.5 hours per terabyte of data.\n\n\n\n\n\n Amazon Web Services \n\nWhen deployed on Amazon Web Services, a full backup of the database is taken once a day for disaster recovery. This DR backup is encrypted and stored in Amazon Web Services S3.\n\nDR backups of the last 7 days are retained by default. The RPO for DR backups on Amazon Web Services is 24 hours. The RTO if a disaster occurs is 4 hours.\n\n\n\n\n\n Brazil: Supplementary Rule 14 (applies to systems provisioned for the Brazilian federal government) \n\nAt this time, the disaster recovery (DR) option for Db2 Warehouse on Cloud offerings is not available in Brazil for the federal government due to Supplementary Rule 14.", "title": "", "source": "https://cloud.ibm.com/docs/Db2whc?topic=Db2whc-dr"}, {"document_id": "ibmcld_14774-27023-28718", "score": 19.89583380771134, "text": "\nIf a local restore is needed, the VMware datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the protected region HPCS instance through the KMIP for VMware service.\n5. Veeam network encryption is used for file and backup copy jobs to the recovery region.\n6. VM backup files are encrypted on disk in the recovery region Veeam Repository with Veeam encryption.\n7. If a restore is needed in the recovery region, the Veeam datastore encryption storage policy is used to reencrypt the VM by using an encryption key from the recovery region HPCS instance through the KMIP for VMware service.\n\n\n\nFor more information about Veeam encryption, see [Encryption standards](https://helpcenter.veeam.com/docs/backup/vsphere/encryption_standards.html?ver=100).\n\nIn the IBM Cloud for VMware\u00ae Regulated Workloads dual region design for SaaS Consumer key management, then the same encryption keys are required in the recovery region as used in the protected region. Currently, HPCS does not support the same encryption keys in two regions. If a failure of the first HPCS instance occurs, keys can be restored to another HPCS instance in another region.\n\nFor more information, see:\n\n\n\n* [HPCS cross-region disaster recovery](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-ha-drcross-region-disaster-recovery)\n* [Restoring your data from another region](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-restore-data)\n\n\n\n\n\n\n\n Related links \n\n\n\n* [Caveonix integration](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vrw-caveonix)\n* [Veeam on IBM Cloud overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeamvm_overview)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vrw-dualregion-design"}, {"document_id": "ibmcld_00471-1736-4209", "score": 19.69259822593923, "text": "\nSee [IBM Cloudant backup and recovery](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recovery) documentation for recommended tooling. \n\n\n\n\n\n\n\n Change management \n\nChange management includes tasks such as deployment, configuration, upgrades, patching, configuration changes, and deletion.\n\n\n\nTable 2. Responsibilities for change management\nThe first column describes the task that the customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n Scaling IBM scales infrastructure to meet capacity selected by the customer. Customer chooses the provisioned throughput capacity for their IBM Cloudant instances. \n Upgrades IBM handles all upgrades and patches of the IBM Cloudant service for the customer. \n\n\n\n\n\n\n\n Security and regulation compliance \n\nSecurity and regulation compliance includes tasks such as security controls implementation and compliance certification.\n\n\n\nTable 3. Responsibilities for security and regulation compliance\nThe first column describes the task that the customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM Responsibilities Your Responsibilities \n\n At-rest encryption By default, IBM encrypts all disks by using IBM Cloudant-managed encryption keys. If the customer wants bring-your-own-key (BYOK) encryption, then the customer is required to use Key Protect to store the customer-managed encryption key. The customer must select an appropriate key management service instance, and select a disk encryption key option during provisioning of an IBM Cloudant Dedicated Hardware plan instance. \n Make data unreadable to IBM Cloudant Operators None, IBM does not render data unreadable to IBM Cloudant Operators. If you intend to store sensitive information in an IBM Cloudant database, you must use client-side encryption to render data unreadable to IBM Cloudant operators. For example, for PCI DSS compliance, you must encrypt the Primary Account Number (PAN) before sending a document that contains it to the database. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes the following tasks:\n\n\n\n* Provide dependencies on disaster recovery sites.\n* Provision disaster recovery environments.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-cloudant-responsibilities"}, {"document_id": "ibmcld_08669-6042-7847", "score": 19.641940148294044, "text": "\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities \n\n Instance backups Continuously perform in-region and cross-region backups of key resources and perform continuous testing of backups. Back up your master key; validate the backups and restore data when needed. \n Disaster recovery When an in-region disaster occurs, automatically recover and restart service components. When a regional disaster that affects all available zones occurs, ensure that all data except the master key is replicated to another region. IBM will also make additional crypto units available in a different region and manage routing requests to the new crypto units. When a regional disaster that affects all available zones occurs, load your master key to the new crypto units that IBM provisions in a different region for restoring data. You can also enable and initialize failover crypto units before a disaster occurs, which reduces the downtime. \n Availability Provide high availability capabilities, such as IBM-owned infrastructure in multizone regions, to meet local access and low latency requirements for each supported region. Use the list of [available regions](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-regions) to plan for and create new instances of the service.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-shared-responsibilities"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02597-4595-6892", "score": 22.721558828307735, "text": "\nThrough the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.\n\nAs well as controlling which APIs a customer can use, different Plans can be used to implement rate limits. A rate limit can be implemented as a default rate across an entire Plan, or for specific operations of an API within that Plan, exempting them from the Plan rate limit. Different Plans can have differing rate limits, both between operations and for the overall limit. Applying rate limits to Plans makes it easy to offer different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute while a \"Full Plan\" might permit up to 1000 calls per minute.\n\nFinally, different Plans can be used to assign a billing cost. A Plan can be set as a free Plan, or as a Plan with billing. Plans with billing can be used with rate limits to set different levels of service to customers. For example, a \"Demo Plan\" might enforce a rate limit of 10 calls per minute for a cost of $5 per month, while a \"Full Plan\" might permit up to 1000 calls per minute for a cost of $20 per month.\n\nNote: Applying a rate limit at the Plan level, creates a default rate limit that applies to each operation within the Plan. If you need to set specific rate limits for specific operations, you must set them within the operations themselves and this setting overrides the setting at the Plan level.\n\nIBM API Connect also supports the implementation of multiple versions of Products. You can choose version numbers and use them to aid the development of your Products and Plans.\n\nNote: The version for a Product is distinct from the version of any APIs that are contained in the associated Plans. Plans cannot themselves have their own version, they use the version of their parent Product.", "title": "", "source": "https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-about_apic_overview"}, {"document_id": "ibmcld_03166-23681-24372", "score": 21.83550691814946, "text": "\nFor Lite plans, usage is measured by the number of /message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU \n Plus Unlimited MAU \n Trial 5,000 MAU \n Lite 10,000 API (approximately 1,000 MAU) \n\n\n\nFor more information about how the web chat widget tracks MAUs, see [Billing](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basicsweb-chat-basics-billing).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}, {"document_id": "ibmcld_03798-0-2240", "score": 21.46742489073965, "text": "\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https://cloud.ibm.com/billing/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http://ibm.com/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https://cloud.ibm.com/billing/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https://cloud.ibm.com/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-understand-invoices"}, {"document_id": "ibmcld_03107-4-1607", "score": 21.267143288121254, "text": "\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Managing your plan](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-plan). To see all documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Managing your plan \n\nThis topic provides:\n\n\n\n* A [plan information](https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-planadmin-managing-plan-information) reference\n* Steps on [upgrading your plan](https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-planadmin-managing-plan-upgrade)\n\n\n\n\n\n Plan information \n\nBilling for the use of Watson Assistant is managed through your IBM Cloud\u00ae account.\n\nThe metrics that are used for billing purposes differ based on your plan type. You can be billed based on the number of API calls made to a service instance or on the number of active users who interact with the instance.\n\nFor answers to common questions about subscriptions, see [How you're charged](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges).\n\nExplore the Watson Assistant [service plan options](https://www.ibm.com/cloud/watson-assistant/pricing/).\n\n\n\n Paid plan features \n\nThe following features are available only to users of a Plus or Enterprise plan. ![Plus or higher plans only](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/plus.png)\n\n\n\n* [Phone integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-plan"}, {"document_id": "ibmcld_16252-7-1601", "score": 20.96968200098148, "text": "\nManaging your plan \n\nThis topic provides:\n\n\n\n* A [plan information](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-information) reference\n* Steps on [upgrading your plan](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-upgrade)\n\n\n\n\n\n Plan information \n\nBilling for the use of Watson Assistant is managed through your IBM Cloud\u00ae account.\n\nThe metrics that are used for billing purposes differ based on your plan type. You can be billed based on the number of API calls made to a service instance or on the number of active users who interact with the instance.\n\nFor answers to common questions about subscriptions, see [How you're charged](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges).\n\nExplore the Watson Assistant [service plan options](https://www.ibm.com/cloud/watson-assistant/pricing/).\n\n\n\n Paid plan features \n\nThe following features are available only to users of a Plus or Enterprise plan. ![Plus or higher plans only](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/plus.png)\n\n\n\n* [Phone integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone)\n* [Private endpoints](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-securingsecurity-private-endpoints)\n* [Search](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-add)\n* [v2 Logs API](https://cloud.ibm.com/apidocs/assistant/assistant-v2listlogs)", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-plan"}, {"document_id": "ibmcld_16365-15662-16934", "score": 20.140360710959428, "text": "\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs. For information about how to avoid this problem, see [Managing user identity information](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nFor information about how to customize the handling of user identity information for billing purposes, see [Managing user identity information](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nThe usage is measured differently depending on the plan type. For Lite plans, usage is measured by the number of /message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU \n Plus Unlimited MAU \n Trial 5,000 MAU \n Lite 10,000 API (approximately 1,000 MAU)", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_03704-1531-3564", "score": 19.959513208014428, "text": "\nWhat's the difference between a Pay-As-You-Go and Subscription account? \n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accounts).\n\n\n\n\n\n What happens if my Lite plan instance reaches the monthly quota? \n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n\n\n\n\n\n Can I use PayPal as a payment method? \n\nAs of March 31, 2023, PayPal is no longer accepted.\n\n\n\n\n\n Can I update my credit card? \n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?]", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_07578-1042894-1044946", "score": 19.69297517356913, "text": "\nContact an [IBM Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1042765-1044817", "score": 19.69297517356913, "text": "\nContact an [IBM Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_02597-3131-5174", "score": 19.40945237547738, "text": "\nPlans can share APIs, but whether subscription approval is required depends upon the Plan itself. Additionally, you can enforce rate limits through Plans or through operations within a Plan's APIs that override the Plan's rate limit.\n\nPlans can also specify billing costs for customers who use your Products. For example, you can define three different Plans for a single Product. Each Plan can have a different subscription cost and a different rate limit that targets different customers.\n\n\n\n\n\n Products \n\nPlans and APIs are grouped in Products. Through Products, you can manage the availability and visibility of APIs and Plans. Use the API Designer to create, edit, and stage your Product. Use the API Manager to manage the lifecycle of your Product.\n\nThe following diagram demonstrates how Products, Plans, and APIs relate to one another. Note how Plans belong to only one Product, can possess different APIs to other Plans within the same Product, and can share APIs with Plans from any Product. Figure to show the hierarchy of Products, Plans, and APIs. ![Figure to show the hierarchy of Products, Plans, and APIs.](https://cloud.ibm.com/docs-content/v1/content/78bb71851d95d7580503eb9ba10cf3ae31490ade/apiconnect/images/plan_product_hierarchy.png)\n\nYou can create Plans only within Products, and these Products are then published in a Catalog. A lifecycle manager can then control the availability and visibility of APIs and Plans through the API Manager. Through the Developer Portal, the customer is then able to subscribe to one of the Plans that is available to them, as determined in the API Manager. If it is a Plan with billing, the customer must provide credit card information when subscribing. The user can subscribe to one Plan from a specific Product. Multiple Plans within a single Product are useful in that they can fulfill similar purposes but with differing levels of performance and cost. For example, you might have a \"Demo Plan\", which makes a single API available, and a \"Full Plan\", which makes several available.", "title": "", "source": "https://cloud.ibm.com/docs/apiconnect?topic=apiconnect-about_apic_overview"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03354-4-1897", "score": 20.235959351507567, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Improve your skill \n\nThe Analytics page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nTo open a list of individual messages between customers and the assistant that uses this dialog skill, select User conversations in the navigation bar.\n\nWhen you open the User conversations page, the default view lists inputs that were submitted to the assistant for the last day, with the newest results first. The top intent (#intent) and any recognized entity (@entity) values used in a message, and the message text are available. For intents that are not recognized, the value shown is Irrelevant. If an entity is not recognized, or has not been provided, the value shown is No entities found.\n\n![Logs default page](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/logs_page1.png)\n\nThe User conversations page displays the total number of messages between customers and your assistant. A message is a single utterance that a user sends to the assistant. A conversation typically consists of multiple messages. Therefore, the number of results on the User conversations page is different from the number of conversations that are shown on the Overview page.\n\n\n\n Log limits \n\nThe length of time for which messages are retained depends on your Watson Assistant service plan:\n\nService plan | Chat message retention\n------------------------------------ | ------------------------------------\nEnterprise with Data Isolation | Last 90 days\nEnterprise | Last 30 days\nPremium (legacy) | Last 90 days\nPlus | Last 30 days", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs"}, {"document_id": "ibmcld_01178-22864-25119", "score": 19.400690771838015, "text": "\nSegment By Service instance, Service instance name \n\n\n\n\n\n\n\n Number of under in-sync replica partitions \n\nThe number of partitions with fewer than two in-sync replicas.\n\n\n\nTable 18. Number of under in-sync replica partitions metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_kafka_under_minisr_partitions \n Metric Type gauge \n Value Type none \n Segment By Service instance \n\n\n\nIdeally this value should be zero. A nonzero value might highlight a temporary issue with the cluster.\n\n\n\n\n\n Produce message conversion time \n\nIndicates that the accumulated time spent performing message conversion from clients that are producing by using older protocol versions.\n\n\n\nTable 19. Produce message conversion time metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_instance_produce_conversions_time_quantile \n Metric Type gauge \n Value Type second \n Segment By Service instance, Quantile, Service instance name \n\n\n\nIdeally zero. A consistent growth in this indicates that some clients are down-level and should be upgraded. Ensure that all clients are at the latest levels.\n\n\n\n\n\n Rebalancing consumer groups \n\nThe number of rebalancing consumer groups in an Event Streams instance.\n\n\n\nTable 20. Rebalancing consumer groups metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_instance_rebalancing_consumergroups \n Metric Type gauge \n Value Type none \n Segment By Service instance, Service instance name \n\n\n\nWhile it is expected that this figure is occasionally >0 (as broker restarts happen frequently,) sustained high levels suggest that consumers might be restarting frequently and leaving or rejoining the consumer groups. Check you client logs.\n\n\n\n\n\n Reserved disk space percentage \n\nThe percentage of reserved disk space that is required for all allocated partitions if fully used.\n\n\n\nTable 21. Reserved disk space percentage metric metadata\n\n Metadata Description \n\n Metric Name ibm_eventstreams_instance_reserved_disk_space_percent \n Metric Type gauge \n Value Type percent \n Segment By Service instance, Service instance name \n\n\n\nShows the percentage of disk space that would be used if your topics were filled to the extent of their configured retention size.\n\n\n\n\n\n Schema greatest version percentage", "title": "", "source": "https://cloud.ibm.com/docs/EventStreams?topic=EventStreams-metrics"}, {"document_id": "ibmcld_09994-4281-6432", "score": 18.975848548572024, "text": "\nBETWEEN <TIMESTAMP EXPRESSION 1> AND <TIMESTAMP EXPRESSION 2> Includes all the rows that were valid at any time between TIMESTAMP EXPRESSION 1 and TIMESTAMP EXPRESSION 2 (inclusive), whose insert timestamp is less than or equal to TIMESTAMP EXPRESSION 2 and whose delete timestamp is NULL or is greater than TIMESTAMP EXPRESSION 1. If TIMESTAMP EXPRESSION 1 or TIMESTAMP EXPRESSION 2 is less than the table\u2019s retention start timestamp, an error is returned. If TIMESTAMP EXPRESSION 1 is greater than TIMESTAMP EXPRESSION 2, the query produces no rows. \n\n\n\n\n\n\n\n\n\n Timestamps in time travel queries \n\n\n\n Retention time interval and retention time period \n\nA table\u2019s retention time interval defines the number of days past their delete timestamps that historical (deleted) rows are available for time travel queries. At any given time, the retention time period ends at the current timestamp (date and time) and extends back the given number of days. This is a sliding time window that advances as the current system time advances.\n\n\n\n\n\n Retention lower bound \n\nFor the most part, a table\u2019s retention lower bound is the date and time when the table was defined to be a temporal table. This could have been when you ran the CREATE TABLE command, or the last time you altered the table\u2019s DATA_VERSION_RETENTION_TIME from zero to non-zero.\n\n\n\n\n\n Retention start timestamp \n\nAt the time of defining a table to be temporal (when the retention lower bound is defined), there are no historical rows available over the retention time period. To capture the notion of how far back historical rows are actually available (visible to time travel queries), a table\u2019s retention start timestamp is defined. The retention start timestamp is the larger of the following values:\n\n\n\n* The beginning of the retention time period (the current date/time minus the retention interval).\n* The retention lower bound.\n\n\n\nA table\u2019s retention start timestamp comes into play in the following operations:\n\n\n\n* Time travel queries (SELECT and sub-SELECT)\n\nIf you attempt to run queries for historical rows that were deleted before the retention start timestamp, an error is returned.", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-runningqueries_tt"}, {"document_id": "ibmcld_09956-7-2100", "score": 18.957858636674736, "text": "\nManaging the default retention time interval for the system and viewing retention time intervals \n\nBefore you set retention time interval for all tables in a schema or database, consider the cost of storage for temporal tables, which could be significant. See [Managing time travel space usage](https://cloud.ibm.com/docs/docs/netezza?topic=netezza-managing_tt).\n\n\n\n Setting the retention time interval for the system \n\nTo set the default DATA_VERSION_RETENTION_TIME to a specific value for the system, run the SET SYSTEM DEFAULT command.\n\nBefore you set DATA_VERSION_RETENTION_TIME for all tables in a schema or database, consider the cost of storage for temporal tables, which could be significant. See [Managing time travel space usage](https://cloud.ibm.com/docs/netezza?topic=netezza-managing_tt).\n\nSET SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME TO <NUMBER OF DAYS>\n\nExample:\n\nSET SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME TO 30\n\nThe value of the property at the system level determines the default value inherited by a subsequent CREATE DATABASE statement that does not explicitly specify this property.\n\nTo set DATA_VERSION_RETENTION_TIME for a specific object, you can run the ALTER or CREATE command.\n\n\n\n\n\n Viewing the retention time interval with the command-line \n\n\n\n Viewing the default retention time interval for the system with the command-line \n\nTo view DATA_VERSION_RETENTION_TIME for the system, run the SHOW SYSTEM DEFAULT command.\n\nSHOW SYSTEM DEFAULT DATA_VERSION_RETENTION_TIME\n\nIf you did not set the retention time previously, the default is 0.\n\n\n\n\n\n Viewing the retention time interval for tables, schemas, and databases with the command-line \n\nTo view DATA_VERSION_RETENTION_TIME for a specific object, run one of these commands. The commands display DATA_VERSION_RETENTION_TIME only if it is a nonzero value.\n\nd <table_name>\n\nSHOW SCHEMA <schema_name>\n\nl+ <all databases, with detail>\n\nRetention time interval and retention lower bound for an object are available in the dataverretntime and dataverretnlowerbound columns of the following system views:\n\n\n\n* _v_table", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-dataretentioninterval_tt"}, {"document_id": "ibmcld_15164-5536-7411", "score": 18.8752934536179, "text": "\n* For a Daily plan, enter the starting time (UTC) in hours and minutes, Coordinated Universal Time. For example, 12 noon is 12:00. Local time conversion is automatically provided on the screen, for example, 12 PM Central Daylight Time.\n\n\n\n* Weekly\n\n\n\n* For a Weekly plan, select the days of the week that you want backups to run. For example, you can select Monday, Wednesday, and Friday. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Monthly\n\n\n\n* For a Monthly plan, select the day of the month that you want backups to run. For example, \"1\" schedules a backup every first of the month. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Specify by using cron expression\n\n\n\n* Under Cron expression (UTC), enter the backup creation frequency in cron-spec format: minute, hour, day, month, and weekday. For example, to create a backup every day at 5:30 PM, you need to enter 30 17 * * .\n\n\n\n\n\nThe Backup destination shows the Block Storage for VPC volume's region. The Backup resource group is the resource group that is associated with the volume.\n3. Specify a Retention type for the backups. You can specify either how long to keep them by number of days or the total number to retain.\n\n\n\n* For Age, specify the number of days that you want to retain the backups. A default value for the maximum number of days to keep a backup is not provided.\n* For Count, provide the number of backups that you want to keep.\n\n\n\nTo keep costs down, set a retention period or snapshots count adequate to your needs. For example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=ui"}, {"document_id": "ibmcld_15161-5539-7414", "score": 18.8752934536179, "text": "\n* For a Daily plan, enter the starting time (UTC) in hours and minutes, Coordinated Universal Time. For example, 12 noon is 12:00. Local time conversion is automatically provided on the screen, for example, 12 PM Central Daylight Time.\n\n\n\n* Weekly\n\n\n\n* For a Weekly plan, select the days of the week that you want backups to run. For example, you can select Monday, Wednesday, and Friday. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Monthly\n\n\n\n* For a Monthly plan, select the day of the month that you want backups to run. For example, \"1\" schedules a backup every first of the month. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Specify by using cron expression\n\n\n\n* Under Cron expression (UTC), enter the backup creation frequency in cron-spec format: minute, hour, day, month, and weekday. For example, to create a backup every day at 5:30 PM, you need to enter 30 17 * * .\n\n\n\n\n\nThe Backup destination shows the Block Storage for VPC volume's region. The Backup resource group is the resource group that is associated with the volume.\n3. Specify a Retention type for the backups. You can specify either how long to keep them by number of days or the total number to retain.\n\n\n\n* For Age, specify the number of days that you want to retain the backups. A default value for the maximum number of days to keep a backup is not provided.\n* For Count, provide the number of backups that you want to keep.\n\n\n\nTo keep costs down, set a retention period or snapshots count adequate to your needs. For example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=api"}, {"document_id": "ibmcld_15162-5539-7414", "score": 18.8752934536179, "text": "\n* For a Daily plan, enter the starting time (UTC) in hours and minutes, Coordinated Universal Time. For example, 12 noon is 12:00. Local time conversion is automatically provided on the screen, for example, 12 PM Central Daylight Time.\n\n\n\n* Weekly\n\n\n\n* For a Weekly plan, select the days of the week that you want backups to run. For example, you can select Monday, Wednesday, and Friday. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Monthly\n\n\n\n* For a Monthly plan, select the day of the month that you want backups to run. For example, \"1\" schedules a backup every first of the month. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Specify by using cron expression\n\n\n\n* Under Cron expression (UTC), enter the backup creation frequency in cron-spec format: minute, hour, day, month, and weekday. For example, to create a backup every day at 5:30 PM, you need to enter 30 17 * * .\n\n\n\n\n\nThe Backup destination shows the Block Storage for VPC volume's region. The Backup resource group is the resource group that is associated with the volume.\n3. Specify a Retention type for the backups. You can specify either how long to keep them by number of days or the total number to retain.\n\n\n\n* For Age, specify the number of days that you want to retain the backups. A default value for the maximum number of days to keep a backup is not provided.\n* For Count, provide the number of backups that you want to keep.\n\n\n\nTo keep costs down, set a retention period or snapshots count adequate to your needs. For example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=cli"}, {"document_id": "ibmcld_15163-5557-7432", "score": 18.8752934536179, "text": "\n* For a Daily plan, enter the starting time (UTC) in hours and minutes, Coordinated Universal Time. For example, 12 noon is 12:00. Local time conversion is automatically provided on the screen, for example, 12 PM Central Daylight Time.\n\n\n\n* Weekly\n\n\n\n* For a Weekly plan, select the days of the week that you want backups to run. For example, you can select Monday, Wednesday, and Friday. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Monthly\n\n\n\n* For a Monthly plan, select the day of the month that you want backups to run. For example, \"1\" schedules a backup every first of the month. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Specify by using cron expression\n\n\n\n* Under Cron expression (UTC), enter the backup creation frequency in cron-spec format: minute, hour, day, month, and weekday. For example, to create a backup every day at 5:30 PM, you need to enter 30 17 * * .\n\n\n\n\n\nThe Backup destination shows the Block Storage for VPC volume's region. The Backup resource group is the resource group that is associated with the volume.\n3. Specify a Retention type for the backups. You can specify either how long to keep them by number of days or the total number to retain.\n\n\n\n* For Age, specify the number of days that you want to retain the backups. A default value for the maximum number of days to keep a backup is not provided.\n* For Count, provide the number of backups that you want to keep.\n\n\n\nTo keep costs down, set a retention period or snapshots count adequate to your needs. For example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=terraform"}, {"document_id": "ibmcld_09956-1678-3537", "score": 18.868899980248592, "text": "\nTo view DATA_VERSION_RETENTION_TIME for a specific object, run one of these commands. The commands display DATA_VERSION_RETENTION_TIME only if it is a nonzero value.\n\nd <table_name>\n\nSHOW SCHEMA <schema_name>\n\nl+ <all databases, with detail>\n\nRetention time interval and retention lower bound for an object are available in the dataverretntime and dataverretnlowerbound columns of the following system views:\n\n\n\n* _v_table\n* _v_schema\n* _v_database\n\n\n\n\n\n\n\n\n\n Viewing the retention time interval with the web console \n\n\n\n Viewing the default retention time interval for the system with the web console \n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https://cloud.ibm.com/docs/netezza?topic=netezza-getstarted-console).\n2. Go to Databases. The retention time interval for the system is displayed in the Retention time interval section at the top of the page.\n\n\n\n\n\n\n\n Viewing the retention time interval for tables, schemas, and databases with the web console \n\n\n\n1. Log in to the web console as described in [Getting started with the web console](https://cloud.ibm.com/docs/netezza?topic=netezza-getstarted-console).\n2. View the retention time interval:\n\n\n\n* For a table:\n\n\n\n\n\n1. Go to Databases.\n2. Select the database and schema in which the table that you want to view the retention interval is located.\n3. Ensure that you are in the DB Objects > Tables tab.\n4. Identify the table for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.\n\n\n\n\n\n* For a schema:\n\n\n\n\n\n1. Go to Databases.\n2. Select the database in which the schema that you want to view the retention interval is located.\n3. Identify the schema for which you want to view the retention interval.\n\nThe retention interval is displayed in the Retention time interval (days) column.", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-dataretentioninterval_tt"}, {"document_id": "ibmcld_15160-5628-7463", "score": 18.685147493053485, "text": "\nLocal time conversion is automatically provided on the screen, for example, 12 PM Central Daylight Time.\n\n\n\n* Weekly\n\n\n\n* For a Weekly plan, select the days of the week that you want backups to run. For example, you can select Monday, Wednesday, and Friday. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Monthly\n\n\n\n* For a Monthly plan, select the day of the month that you want backups to run. For example, \"1\" schedules a backup every first of the month. Specify the starting time in the same manner as a Daily plan.\n\n\n\n* Specify by using cron expression\n\n\n\n* Under Cron expression (UTC), enter the backup creation frequency in cron-spec format: minute, hour, day, month, and weekday. For example, to create a backup every day at 5:30 PM, you need to enter 30 17 * * .\n\n\n\n\n\nThe Backup destination shows the Block Storage for VPC volume's region. The Backup resource group is the resource group that is associated with the volume.\n3. Specify a Retention type for the backups. You can specify either how long to keep them by number of days or the total number to retain.\n\n\n\n* For Age, specify the number of days that you want to retain the backups. A default value for the maximum number of days to keep a backup is not provided.\n* For Count, provide the number of backups that you want to keep.\n\n\n\nTo keep costs down, set a retention period or snapshots count adequate to your needs. For example, setting \"7\" for Age retains a week's worth of backups.\n4. Under Optional, you can configure two options.\n\n\n\n* Fast snapshot restore - When you enable this feature, you must specify the zone or zones where you want [fast restore](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore) enabled. You can also specify the maximum number of fast restore snapshots that you want to retain.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03369-75826-77957", "score": 30.558523223108118, "text": "\n* Fixed an issue with adding a jump-to from a conditional response in one node to a conditional response in another node.\n* The page now responds better when you scroll horizontally to see multiple levels of child nodes.\n\n\n\n\n\n\n\n 15 July 2020 \n\nSupport ended for @sys-location and @sys-person\n: The person and location system entities, which were available as a beta feature in English dialog skills only, are no longer supported. You cannot enable them. If your dialog uses them, they are ignored by the service.\n\nUse contextual entities to teach your skill to recognize the context in which such names are used. For more information about contextual entities, see [Annotation-based method](https://cloud.ibm.com/docs/assistant?topic=assistant-entitiesentities-annotations-overview).\n\nFor more information about how to use contextual entites to identify names of people, see the [Detecting Names And Locations With Watson Assistant](https://medium.com/ibm-watson/detecting-names-and-locations-with-watson-assistant-e3e1fa2a8427) blog post on Medium.\n\nHow legacy numeric system entities are processed has changed\n: All new dialog skills use the new system entities automatically.\n\nFor existing skills that use legacy numeric system entities, how the entities are processed now differs based on the skill language.\n\n\n\n* Arabic, Chinese, Korean, and Japanese dialog skills that use legacy numeric system entities function the same as before.\n* If you choose to continue to use the legacy system entities in European-language dialog skills, a new legacy API format is used. The new legacy API format simulates the legacy system entities behavior. In particular, it returns a metadata object and does not stop the service from idenfifying multiple system entities for the same input string. In addition, it returns an interpretation object, which was introduced with the new version of system entities. Review the interpretation object to see the useful information that is returned by the new version.\n\n\n\nUpdate your skills to use the new system entities from the Options>System Entities page.\n\nWeb chat security is generally available", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_16364-7497-9493", "score": 28.754766513662886, "text": "\nThese changes are the result of migrating the Watson Assistant platform to Java 17, where locale values are updated by using specifications in [CLDR 39](https://cldr.unicode.org/index/downloads/cldr-39).\n\nTo avoid or minimize the impact of similar changes in the future, you can use [Display formats](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-actions-global-settingsactions-global-settings-display-formats).\n\n\n\n\n\n 18 May 2023 \n\nDifferences in contextual entity detection for dialog skills with few annotations\n: If you have 10 to 20 examples of contextual entities in your dialog skill, you might see differences in the entities detected due to updates made to address critical vulnerabilities. The impact of these differences is limited to only newly-trained models. Existing models are unaffected. You can mitigate these differences by annotating more examples. For more information, see [Annotation-based method](https://cloud.ibm.com/docs/assistant?topic=assistant-entitiesentities-annotations-overview).\n\n\n\n\n\n 17 May 2023 \n\nDisplay iframe inline\n: In the web chat, there are now two ways an iframe response can be included:\n\n\n\n* As a preview card that describes the embedded content. Customers can click this card to display the frame and interact with the content.\n* Inline, meaning within the conversation. This new option is good for smaller pieces of iframe content.\n\n\n\nFor more information, see [Adding an iframe response](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-respondrespond-add-iframe).\n\n\n\n\n\n 15 May 2023 \n\nChange to dialog skill context variables named request\n: If your dialog skill used a context variable that is named request, it was removed from the response payload of any /message calls in the V1 or V2 API, or through the Watson Assistant user interface. After 15 May 2023, this behavior changes. Watson Assistant doesn't remove context variables that are named request from the response payload anymore.\n\n\n\n\n\n 5 May 2023", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03139-1239-2954", "score": 28.49187937399077, "text": "\nSee [Log limits](https://cloud.ibm.com/docs/assistant?topic=assistant-logslogs-limits) for more information.\n\nYou cannot import logs from one skill into another skill.\n\n\n\n\n\n Downloading a skill \n\nTo back up actions or dialog skill data, download the skill as a JSON file, and store the JSON file.\n\n\n\n1. Find the actions or dialog skill tile on the Skills page or on the configuration page of an assistant that uses the skill.\n2. Click the ![open and close list of options](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png) icon, and then choose Download.\n3. Specify a name for the JSON file and where to save it, and then click Save.\n\n\n\nAlternatively, you can use the /workspaces API to export a dialog skill. Include the export=true parameter with the GET workspace request. See the [API reference](https://cloud.ibm.com/apidocs/assistant/assistant-v1getworkspace) for more details.\n\n\n\n\n\n Uploading a skill \n\nTo reinstate a backup copy of an actions or dialog skill that you exported from another service instance or environment, create a new skill by importing the JSON file of the skill you exported.\n\nIf the Watson Assistant service changes between the time you export the skill and import it, due to functional updates which are regularly applied to instances in cloud-hosted continuous delivery environments, your imported skill might function differently than it did before.\n\n\n\n1. Click the Skills icon ![Skills menu icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/nav-skills-icon.png).\n2. Click Create skill.\n3. Choose to create either an actions or dialog skill, then click Next.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-backup"}, {"document_id": "ibmcld_03369-1415-3586", "score": 28.325005791483832, "text": "\nThese changes are the result of migrating the Watson Assistant platform to Java 17, where locale values are updated by using specifications in [CLDR 39](https://cldr.unicode.org/index/downloads/cldr-39).\n\nTo avoid or minimize the impact of similar changes in the future, you can use [Actions display formats](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-actions-global-settingsactions-global-settings-display-formats).\n\n\n\n\n\n 18 May 2023 \n\nDifferences in contextual entity detection for dialog skills with few annotations\n: If you have 10 to 20 examples of contextual entities in your dialog skill, you might see differences in the entities detected due to updates made to address critical vulnerabilities. The impact of these differences is limited to only newly-trained models. Existing models are unaffected. You can mitigate these differences by annotating more examples. For more information, see [Annotation-based method](https://cloud.ibm.com/docs/assistant?topic=assistant-entitiesentities-annotations-overview).\n\n\n\n\n\n 15 May 2023 \n\nChange to dialog skill context variables named request\n: If your dialog skill used a context variable that is named request, it was removed from the response payload of any /message calls in the V1 or V2 API, or through the Watson Assistant user interface. After 15 May 2023, this behavior changes. Watson Assistant doesn't remove context variables that are named request from the response payload anymore.\n\n\n\n\n\n 3 May 2023 \n\nAlgorithm version Beta provides improved intent detection and action matching\n: The algorithm version Beta now provides improved intent detection and action matching. It includes a new foundation model that is trained using a transformer architecture to improve intent detection and action matching for English.\n\nImprovements include:\n\n\n\n* Improved robustness to variations in user inputs such as typos and different inflection forms\n* Less training data required to reach the same level of performance compared to previous algorithms\n\n\n\nFor more information, see [Algorithm version and training](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-algorithm-version).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_02990-7468-9182", "score": 28.01934053064117, "text": "\nFor more information, see the [API reference](https://cloud.ibm.com/apidocs/assistant-data-v1listlogs) and the [Filter query reference](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-filter-reference).\n\n\n\n\n\n Can I export and import dialog nodes? \n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n\n\n\n\n How long are log files kept for a workspace? \n\nMessages are retained for 90 days. For more information, see [Log limits](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logslogs-limits).\n\n\n\n\n\n How do I create a webhook? \n\nTo define a webhook and add its details, open the skill where you want to add the webhook. Open the Options page, and then click Webhooks to add details about your webhook. To invoke the webhook, call it from one or more of your dialog nodes. For more information, see [Making a programmatic call from dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-webhooks).\n\n\n\n\n\n Can I have more than one entry in the URL field for a webhook?", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-faqs"}, {"document_id": "ibmcld_03054-19820-21851", "score": 27.858578814125863, "text": "\nClick Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first. The dialog addresses any user input that it has a high confidence it can answer correctly. You can configure the dialog such that any queries that would normally trigger the anything_else node in the dialog tree are sent to the search skill instead. To do so, add a search skill response type to the Anything else node.\n\nYou can prevent the search from being triggered from the anything_else node by following the steps in [Disabling search](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-addsearch-skill-add-disable).\n* If you want a specific search query to be triggered for specific questions, add a search skill response type to the appropriate dialog node. See [Responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia) for more details.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* Anything else node: Searches an external data source for a relevant answer when none of the dialog nodes can address the user's query.\n\nInstead of showing a standard message, such as I don't know how to help you with that. the assistant can say, Maybe this information can help: followed by the passage returned by the search. If a search skill is linked to your assistant, then whenever the anything_else node is triggered, rather than displaying the node response, you can set it up to trigger a search instead. The assistant passes the user input as the query to your search skill, and returns the search results as the response.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add"}, {"document_id": "ibmcld_03313-12458-14207", "score": 27.814039470639166, "text": "\nFollow the steps in the [Getting started with Watson Assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n\n\n\n\n\n Can I export the user conversations from the Analytics page? \n\nYou cannot directly export conversations from the User conversation page. You can, however, use the /logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [API reference](https://cloud.ibm.com/apidocs/assistant/assistant-v1listlogs) and the [Filter query reference](https://cloud.ibm.com/docs/assistant?topic=assistant-filter-reference). Or, you can use a Python script to export logs. For more information, see [export_logs_py](https://github.com/watson-developer-cloud/community/blob/master/watson-assistant/export_logs_py.py).\n\n\n\n\n\n Can I export and import dialog nodes? \n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n\n\n\n\n Is it possible to recover a deleted skill?", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-faqs"}, {"document_id": "ibmcld_07578-85554-87392", "score": 27.668129779639813, "text": "\nFollow the steps in the [Getting started with Watson Assistant](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page. You can, however, use the /logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [API reference](https://cloud.ibm.com/apidocs/assistant-data-v1listlogs) and the [Filter query reference](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-filter-reference).\n* Can I export and import dialog nodes?\n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n* How long are log files kept for a workspace?\n\nMessages are retained for 90 days. For more information, see [Log limits](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logslogs-limits).\n* How do I create a webhook?\n\nTo define a webhook and add its details, open the skill where you want to add the webhook.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-85529-87367", "score": 27.668129779639813, "text": "\nFollow the steps in the [Getting started with Watson Assistant](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page. You can, however, use the /logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [API reference](https://cloud.ibm.com/apidocs/assistant-data-v1listlogs) and the [Filter query reference](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-filter-reference).\n* Can I export and import dialog nodes?\n\nNo, you cannot export and import dialog nodes from the product user interface.\n\nIf you want to copy dialog nodes from one skill into another skill, follow these steps:\n\n\n\n1. Download as JSON files both the dialog skill that you want to copy the dialog nodes from and the dialog skill that you want to copy the nodes to.\n2. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes from.\n3. Find the dialog_nodes array, and copy it.\n4. In a text editor, open the JSON file for the dialog skill that you want to copy the dialog nodes to, and then paste the dialog_nodes array into it.\n5. Import the JSON file that you edited in the previous step to create a new dialog skill with the dialog nodes you wanted.\n\n\n\n* How long are log files kept for a workspace?\n\nMessages are retained for 90 days. For more information, see [Log limits](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logslogs-limits).\n* How do I create a webhook?\n\nTo define a webhook and add its details, open the skill where you want to add the webhook.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03273-14436-16185", "score": 27.637140256348456, "text": "\nhttps://{location}.assistant.watson.cloud.ibm.com/{location}/{instance-id}/skills/{skill-id}/build/dialognode={node-id}\n4. Edit the URL by replacing the current {node-id} value with the ID of the node you want to find, and then submit the new URL.\n5. If necessary, highlight the edited URL again, and resubmit it.\n\n\n\nThe page refreshes, and shifts focus to the dialog node with the node ID that you specified. If the node ID is for a slot, a Found or Not found slot condition, a slot handler, or a conditional response, then the node in which the slot or conditional response is defined gets focus and the corresponding modal is displayed.\n\nIf you still cannot find the node, you can export the dialog skill and use a JSON editor to search the skill JSON file.\n\n\n\n How many nodes are in my dialog? \n\nTo see the number of dialog nodes in a dialog skill, do one of the following things:\n\n\n\n* If it is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n* Send a GET request to the /dialog_nodes API endpoint, and include the include_count=true parameter. For example:\n\ncurl -u \"apikey:{apikey}\" \"{url}/v1/workspaces/{workspace_id}/dialog_nodes?version=2018-09-20&include_count=true\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https://cloud.ibm.com/apidocs/assistant/assistant-v1service-endpoint).\n\nIn the response, the total attribute in the pagination object contains the number of dialog nodes.\n\n\n\nIf the total seems larger than you expected, it might be because the dialog that you build from the application is translated into a JSON object.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-tasks"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02932-4408-6545", "score": 18.53813463035318, "text": "\nFor example, if the user enters boook, and your training data contains a @reading_material entity with a book value, then fuzzy matching recognizes that the two terms (boook and book) mean the same thing.\n\nWhen you enable both autocorrection and fuzzy matching, the fuzzy matching function runs before autocorrection is triggered. If it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.\n\nFor example, if a user enters a sentence like I wnt to buy a boook, fuzzy matching recognizes that the term boook means the same thing as your entity value book, and adds it to the protected words list. Your assistant corrects the input to be, I want to buy a boook. Notice that it corrects wnt but does not correct the spelling of boook. If you see this type of result when you are testing your dialog, you might think your assistant is misbehaving. However, your assistant is not. Thanks to fuzzy matching, it correctly identifies boook as a @reading_material entity mention. And thanks to autocorrection revising the term to want, your assistant is able to map the input to your buy_something intent. Each feature does its part to help your assistant understand the meaning of the user input.\n\n\n\n\n\n How autocorrection works \n\nNormally, user input is saved as-is in the text field of the input object of the message. If, and only if the user input is corrected in some way, a new field is created in the input object, called original_text. This field stores the user's original input that includes any misspelled words in it. And the corrected text is added to the input.text field.\n\nIf you want to ask users to confirm the assistant's understanding of their meaning, you can do so in a way that takes into account that their input might have been corrected. Set the condition for the dialog node or conditional response that is asking for confirmation to original_text. This means that if the user's input was automatically corrected, show the corresponding response. And the response can contain the expression: You said: <?", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-spell-check"}, {"document_id": "ibmcld_03137-4194-5167", "score": 18.314349235217108, "text": "\nIf it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.\n\nFor example, if a user enters a sentence like I wnt to buy a boook, fuzzy matching recognizes that the term boook means the same thing as your entity value book, and adds it to the protected words list. Your assistant corrects the input to be, I want to buy a boook. Notice that it corrects wnt but does not correct the spelling of boook. If you see this type of result when you are testing your dialog, you might think your assistant is misbehaving. However, your assistant is not. Thanks to fuzzy matching, it correctly identifies boook as a @reading_material entity mention. And thanks to autocorrection revising the term to want, your assistant is able to map the input to your buy_something intent. Each feature does its part to help your assistant understand the meaning of the user input.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-autocorrection"}, {"document_id": "ibmcld_16267-2886-4844", "score": 18.276489702450334, "text": "\n* Words containing special characters, such as hyphens (-), asterisks (*), ampersands (&), or at signs (@), including those used in email addresses or URLs.\n* Words that belong, meaning words that have implied significance because they occur in your action steps or dialog entity values, entity synonyms, or intent user examples.\n\n\n\n\n\n How is spelling autocorrection related to fuzzy matching? \n\nIn dialog, fuzzy matching helps your assistant recognize dictionary-based entity mentions in user input. It uses a dictionary lookup approach to match a word from the user input to an existing entity value or synonym in the skill's training data. For example, if the user enters boook, and your training data contains a @reading_material entity with a book value, then fuzzy matching recognizes that the two terms (boook and book) mean the same thing.\n\nIn dialog, when you enable both autocorrection and fuzzy matching, the fuzzy matching function runs before autocorrection is triggered. If it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.\n\nFor example, if a user enters a sentence like I wnt to buy a boook, fuzzy matching recognizes that the term boook means the same thing as your entity value book, and adds it to the protected words list. Your assistant corrects the input to be, I want to buy a boook. Notice that it corrects wnt but does not correct the spelling of boook. If you see this type of result when you are testing your dialog, you might think your assistant is misbehaving. However, your assistant is not. Thanks to fuzzy matching, it correctly identifies boook as a @reading_material entity mention. And thanks to autocorrection revising the term to want, your assistant is able to map the input to your buy_something intent. Each feature does its part to help your assistant understand the meaning of the user input.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-autocorrection"}, {"document_id": "ibmcld_07043-7-2215", "score": 18.192024492794793, "text": "\nGlossary \n\n\n\nDefinitions of Discovery terms\n\n Term Definition \n\n Classifier A resource that you can train to recognize document types and categorize them in your collection. You can create two types of classifiers, a text classifier and a document classifier. A text classifier can classify documents based on words and phrases that are extracted from the body text with their part of speech information taken into account. A document classifier can classify documents based on words and phrases that are extracted from the body text fields with information from their part of speech and the other enrichments that are applied to the body text taken into account. The information from the other nonbody fields are also used. [Learn more](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-cm-doc-classifier) \n Collection A set of documents that you can enrich and later search for meaningful information. [Learn more](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collections). \n Content Intelligence A feature that you can use to enrich documents in a Document Retrieval project such that the project can recognize information that is relevant to business contracts. A Document Retrieval project with this feature enabled is referred to as a Document Retrieval for Contracts project type. [Learn more](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-projectsdoc-retrieval-contracts) \n Data source An external application or service where valuable knowledge resources are stored. Connect to a service where your data is stored so you can crawl the data without having to move it. [Learn more](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collections). \n Domain-specific Relates to terms and concepts that have special meaning to an industry or business. In tennis, for example, the term love has a special meaning. It represents a zero score. If you built a tennis-related application, you would teach Discovery that the term love has a meaning in the domain of tennis that is different from the generally understood meaning. \n Enrichment What you add to documents in your collection to identify or tag terms in the document that are significant.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-glossary"}, {"document_id": "ibmcld_07033-18031-20115", "score": 18.169011307390843, "text": "\nThe system learns from the types of examples you label, and applies what it learns to identify potential new examples. For example, after you label red, orange, yellow, green, and blue as examples of the color entity type, the Example suggestions panel might show indigo and violet as suggested examples for you to label. Suggestions are not displayed until after you label many examples of an entity type.\n\nThe following example shows suggestions that are made for family member mentions.\n\nZoom\n\n![Shows suggestions for family member entities.](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/suggestions-example.png)\n\nFigure 10. Entity example suggestions\n\nYou might notice that a term that you chose to bulk label is not labeled, but is displayed as a suggestion instead. A term is skipped in the following situations:\n\n\n\n* The term might occur in different noun phrases in different sections of the document. For example, the term father might occur in the noun phrases the kindest father and to her father. When a word is included in a noun phrase with adjectives, the meaning can change. Therefore, such terms sometimes are suggested rather than labeled automatically.\n* A word might be a valid example on its own and as part of a multiple-word mention. For example, a mention of IBM might refer to the company International Business Machines, Corp. or might be used as part of a product name, such as IBM Cloud Pak for Data. However, a word or phrase can be part of only one example. Example labels cannot overlap one another. Therefore, you must choose which example suggestion is the most accurate. In this example, where the term IBM is used as part of a product name, it is more accurate to label the full phrase as an example of the Product entity type.\n* The service might recognize that a term is a possible example of more than one entity type. For example, the word top might mean the best or might mean shirt.\n\n\n\nTo investigate a suggestion further, click it to see the word in context within the document.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-entity-extractor"}, {"document_id": "ibmcld_07108-7-1958", "score": 18.088110828661673, "text": "\nExpanding the meaning of queries \n\nYou can improve the quality of search results by expanding the meaning of the queries that are submitted by customers.\n\nTo expand the scope of a query beyond exact matches, add a synonyms list to your collection. When synonyms are defined, the customer does not need to submit an exact phrase or keyword that your project is trained to understand. Even variations of the term are recognized and used to find the best results. For example, you can expand a query for ibm to include international business machines and big blue. Query expansion terms are typically synonyms, antonyms, or common misspellings for terms.\n\nSynonyms that you add to improve the search results function differently from synonyms that you add to a dictionary. Dictionary synonyms are recognized and tagged at the time that a document is ingested. The synonyms that you define are recognized and tagged as occurrences of the associated dictionary term, so that they can be retrieved later by search. For more information about adding synonyms that are recognized when documents are processed, see [Dictionaries](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-domain-dictionary).\n\nYou can define two types of expansions:\n\nBidirectional\n: Each entry in the expanded_terms list expands to include all expanded terms. For example, a query for ibm expands to ibm OR international business machines OR big blue.\n\nBidirectional example:\n\n{\n\"expansions\": [\n{\n\"expanded_terms\":\n\"ibm\",\n\"international business machines\",\n\"big blue\"\n]\n}\n]\n}\n\nUnidirectional\n: The input_terms in the query is replaced by the expanded_terms. For example, a query for banana is converted to plantain OR fruit and does not contain the original term, banana. If you want an input term to be included in the query, then repeat the input term in the expanded terms list.\n\nUnidirectional example:\n\n{\n\"expansions\": [\n{\n\"input_terms\":\n\"banana\"\n],\n\"expanded_terms\":", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-search-settings"}, {"document_id": "ibmcld_07043-1723-3942", "score": 17.817697008365933, "text": "\nDomain-specific Relates to terms and concepts that have special meaning to an industry or business. In tennis, for example, the term love has a special meaning. It represents a zero score. If you built a tennis-related application, you would teach Discovery that the term love has a meaning in the domain of tennis that is different from the generally understood meaning. \n Enrichment What you add to documents in your collection to identify or tag terms in the document that are significant. For example, when you apply the Entity enrichment, terms that mention city names or famous people are tagged as locations or people of interest. \n Facet A category by which you can filter search query results. Automatically, facets based on entity types are applied to the query results for Document Retrieval projects and facets based on the parts of speech are applied to Content Mining projects. You can define your own facet categories based on document fields, including fields generated by enrichments, or based on dictionaries or patterns. [Learn more](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-facets) \n Index As you upload data or connect to data that is stored in an external repository, the data is crawled and ingested. As part of the processing, an index is created to keep track of important information that is recognized from the source. The main difference between a data source and a collection is that content in the data source is crawled, normalized, and indexed as it is added to a collection. \n Project A container for the collections of data that fuel your research or search applications. [Learn more](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-projects). \n Regular expression A regular expression, also known as a regex, is a standardized format for defining search patterns. You can define patterns with special significance to your application. For example, the bill of materials (BOM) numbers for parts that you manufacture might have a standard syntax of two uppercase letters followed by four numbers (GT2345). You can teach Discovery to recognize BOM mentions by adding a regular expression that can recognize and tag occurrences of the pattern in text.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-glossary"}, {"document_id": "ibmcld_03137-2586-4710", "score": 17.390434052370146, "text": "\nIf there are misspelled terms that you expected your assistant to correct, but it did not, then review the rules that your assistant uses to decide whether to correct a word to see if the word falls into the category of words that your assistant intentionally does not change.\n\n\n\n\n\n Autocorrection rules \n\nTo avoid overcorrection, your assistant does not correct the spelling of the following types of input:\n\n\n\n* Capitalized words\n* Emojis\n* Locations, such as states and street addresses\n* Numbers and units of measurement or time\n* Proper nouns, such as common first names or company names\n* Text within quotation marks\n* Words containing special characters, such as hyphens (-), asterisks (*), ampersands (&), or at signs (@), including those used in email addresses or URLs.\n* Words that belong, meaning words that have implied significance because they occur in your action steps or dialog entity values, entity synonyms, or intent user examples.\n\n\n\n\n\n How is spelling autocorrection related to fuzzy matching? \n\nIn dialog, fuzzy matching helps your assistant recognize dictionary-based entity mentions in user input. It uses a dictionary lookup approach to match a word from the user input to an existing entity value or synonym in the skill's training data. For example, if the user enters boook, and your training data contains a @reading_material entity with a book value, then fuzzy matching recognizes that the two terms (boook and book) mean the same thing.\n\nIn dialog, when you enable both autocorrection and fuzzy matching, the fuzzy matching function runs before autocorrection is triggered. If it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.\n\nFor example, if a user enters a sentence like I wnt to buy a boook, fuzzy matching recognizes that the term boook means the same thing as your entity value book, and adds it to the protected words list. Your assistant corrects the input to be, I want to buy a boook. Notice that it corrects wnt but does not correct the spelling of boook.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-autocorrection"}, {"document_id": "ibmcld_07549-23293-25526", "score": 17.271925888206734, "text": "\nIf a license document contains a further restriction but permits relicensing or conveying under this License, you may add to a covered work material governed by the terms of that license document, provided that the further restriction does not survive such relicensing or conveying.If you add terms to a covered work in accord with this section, you must place, in the relevant source files, a statement of the additional terms that apply to those files, or a notice indicating where to find the applicable terms.Additional terms, permissive or non-permissive, may be stated in the form of a separately written license, or stated as exceptions; the above requirements apply either way.<-- </section \"id=\"section-en-notice-add-term\" \"> --><-- <section \"id=\"section-en-notice-term\" \"> --> 8. Termination You may not propagate or modify a covered work except as expressly provided under this License. Any attempt otherwise to propagate or modify it is void, and will automatically terminate your rights under this License (including any patent licenses granted under the third paragraph of section 11).However, if you cease all violation of this License, then your license from a particular copyright holder is reinstated (a) provisionally, unless and until the copyright holder explicitly and finally terminates your license, and (b) permanently, if the copyright holder fails to notify you of the violation by some reasonable means prior to 60 days after the cessation.Moreover, your license from a particular copyright holder is reinstated permanently if the copyright older notifies you of the violation by some reasonable means, this is the first time you have received notice of violation of this License (for any work) from that copyright holder, and you cure the violation prior to 30 days after your receipt of the notice.Termination of your rights under this section does not terminate the licenses of parties who have received copies or rights from you under this License. If your rights have been terminated and not permanently reinstated, you do not qualify to receive new licenses for the same material under section 10.<-- </section \"id=\"section-en-notice-term\" \"> --><-- <section \"id=\"section-en-notice-accept\" \"> --> 9.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-notices"}, {"document_id": "ibmcld_02932-2728-4915", "score": 16.71611012343527, "text": "\nIf there are misspelled terms that you expected your assistant to correct, but it did not, then review the rules that your assistant uses to decide whether to correct a word to see if the word falls into the category of words that your assistant intentionally does not change.\n\n\n\n\n\n Autocorrection rules \n\nTo avoid overcorrection, your assistant does not correct the spelling of the following types of input:\n\n\n\n* Capitalized words\n* Emojis\n* Location entities, such as states and street addresses\n* Numbers and units of measurement or time\n* Proper nouns, such as common first names or company names\n* Text within quotation marks\n* Words containing special characters, such as hyphens (-), asterisks (*), ampersands (&), or at signs (@), including those used in email addresses or URLs.\n* Words that belong in this skill, meaning words that have implied significance because they occur in entity values, entity synonyms, or intent user examples.\n\nMentions of a contextual entity can be corrected inadvertently. That's because terms that function as contextual entity mentions are fluid; they cannot be predetermined and avoided by the spell checker function in the way a list of dictionary-based terms can be.\n\n\n\nIf the word that is not corrected is not obviously one of these types of input, then it might be worth checking whether the entity has fuzzy matching enabled for it.\n\n\n\n How is spelling autocorrection related to fuzzy matching? \n\nFuzzy matching helps your assistant recognize dictionary-based entity mentions in user input. It uses a dictionary lookup approach to match a word from the user input to an existing entity value or synonym in the skill's training data. For example, if the user enters boook, and your training data contains a @reading_material entity with a book value, then fuzzy matching recognizes that the two terms (boook and book) mean the same thing.\n\nWhen you enable both autocorrection and fuzzy matching, the fuzzy matching function runs before autocorrection is triggered. If it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-spell-check"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00512-1696-3972", "score": 18.005568643921784, "text": "\nDocuments with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database. All documents are assigned to a partition, and many documents are typically given the same partition key. A partition's primary JSON data and its indexes end up colocated, meaning that the database can query data within a partition more efficiently.\n\nA partitioned database offers both partitioned and global querying. Partitioned querying takes advantage of the data layout within the database cluster to deliver improved and more scalable query performance. Partition queries are also often cheaper than global queries.\n\nAs partitioned databases offer the advantages of both global and partition querying, IBM Cloudant recommends that new applications take advantage of them.\n\n\n\n\n\n What makes a good partition key? \n\nIf you're thinking of using IBM Cloudant's new partitioned database feature, then the choice of a partition key is important. A partition key must have:\n\n\n\n* Many values - lots of small partitions are better than a few large ones. A million partitions are perfectly fine, but keep each partition under 10 GB in total size.\n* No hot spots - avoid designing a system that makes one partition handle a high proportion of the workload. If the work is evenly distributed around the partitions, the database performs more smoothly.\n* Repeating - If each partition key is unique, one document per partition exists. To get the best out of partitioned databases, multiple documents per partition must exist - documents that logically belong together.\n\n\n\nLet's look at some use cases and some good and bad choices for a partition key.\n\n\n\nTable 1. Good and bad choices for a partition key\n\n Use Case Description Partition Key Effectiveness \n\n E-commerce system - orders One document per order order_id Neutral - one document per partition is fine, but it doesn't provide the benefits of Partition Queries.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-database-partitioning"}, {"document_id": "ibmcld_00513-7-2197", "score": 17.37680744377606, "text": "\nDatabase overview \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases contain JSON objects. These JSON objects are called [documents](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-documentsdocuments).\n\nAll documents must be contained in a database. For more information, see [partitioned databases](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-databasespartitioned-databases-database).\n\nThe [Grouping related documents together in IBM Cloudant](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudantgrouping-related-documents-together-in-ibm-cloudant) guide provides an example of how documents for an e-commerce application might be used within an IBM Cloudant database.\n\n\n\n Partitioned databases \n\nIBM Cloudant supports two types of databases:\n\n\n\n* Partitioned\n* Nonpartitioned\n\n\n\nA partitioned database offers significant query performance and cost advantages but requires you to specify a logical partitioning of your data. The partitioning is specified as part of each document's ID. A partitioned database provides both global and partition queries. Partition queries target queries at a single, given document partition, meaning they need to process less data to return results. Therefore, partition queries offer significant performance advantages, and also often provide cost advantages over global queries. Global queries target the entire database, which leads to extra complexity, slower performance, and increased cost, but offers results that draw from all data.\n\nAlternatively, a nonpartitioned database might be created. This type of database can be less complex to work with since no partitioning scheme needs to be defined, but you can create only global secondary indexes.\n\nIBM Cloudant strongly encourages you to use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nThe partitioning type of a database is set at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-databases"}, {"document_id": "ibmcld_00512-7-2158", "score": 16.704068236328403, "text": "\nDatabase partitioning \n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae supports two types of databases:\n\n\n\n* Partitioned\n* Non-partitioned\n\n\n\nA partitioned database offers significant performance and cost advantages but requires you to specify a logical partitioning of your data. This process is described more in the following text.\n\nAlternatively, you can create a non-partitioned database. This type of database might be easier to work with as no partitioning scheme needs to be defined, but only global secondary indexes can be created.\n\nIBM Cloudant strongly recommends that you use a partitioned database for best long-term database performance where the data model allows for logical partitioning of documents.\n\nYou can decide whether to partition at database creation time. When you create a database, use the partitioned query string parameter to set whether the database is partitioned. The default for partitioned is false, maintaining compatibility with an earlier version.\n\nThe partitioning type can't be changed for an existing database.\n\n\n\n Database shards \n\nBefore you read this document, you must understand the [sharding concept](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-is-data-stored-in-ibm-cloudant-how-is-data-stored-in-ibm-cloudant-) within IBM Cloudant.\n\n\n\n\n\n Non-partitioned databases \n\nA non-partitioned database is the older type of IBM Cloudant database, and the one that is familiar if you used CouchDB or IBM Cloudant previously.\n\nWithin a non-partitioned database, documents are distributed to shards in an arbitrary manner based on a transformation of their document ID. Therefore, no real relation exists between a document's ID and the shard it ends up on. Documents with similar document IDs are unlikely to be placed onto the same shard.\n\nA non-partitioned database offers only global querying, described in more detail later.\n\n\n\n\n\n Partitioned databases \n\nA partitioned database is the newest type of IBM Cloudant database. Within a partitioned database, documents are formed into logical partitions by use of a partition key. The partition key is part of the document ID for documents within a partitioned database.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-database-partitioning"}, {"document_id": "ibmcld_00576-7385-9302", "score": 14.9856944927317, "text": "\nIBM Cloudant doesn't have the concept of joins like a relational database, so data isn't normalized. However, data can repeat across objects. For example, an order document can include a subset of the product documents that were purchased.\n\nIt's common to store several object types in the same database: a convention is that a type attribute is used to denote the object type. This option is a good one if you need to perform queries that return several object types or if a database needs to be replicated to another location altogether. Otherwise, separate databases, for example, users, orders, products, might be better so that secondary indexes are specific to each object type.\n\nIf you're storing arrays of objects within a document, consider whether the array items must really be their own document. For example, a product and each product review must be stored in separate documents, but a user and each of that user's orders must have their own document.\n\nIf you have an ever-growing data set, then you probably don't want to store data in a single, ever-growing database. Data is best stored in time-boxed databases that allow older data to be archived and deleted cleanly. Deleting an IBM Cloudant document leaves a tombstone document behind, so don't rely on deleting documents to recover disk space. Instead, you must rely on deleting whole databases.\n\nJSON doesn't offer a native way to store dates or timestamps. Choose your [date format](https://blog.cloudant.com/2018/05/24/Date-formats.html) carefully if you intend to query it later.\n\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https://blog.cloudant.com/2019/05/10/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https://blog.cloudant.com/2019/04/08/Time-series-data-storage.html)", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-basics"}, {"document_id": "ibmcld_00580-20968-23077", "score": 14.90616457492241, "text": "\nTo open an IBM Cloudant service's Dashboard, log in to IBM Cloud, find your IBM Cloudant service, and click Launch IBM Cloudant Dashboard button. A new window opens, logging you into your IBM Cloudant Dashboard.\n\nIf you leave the dashboard window unattended for a length of time, you find yourself logged out (for security purposes) and must click Launch again.\n\nThe dashboard has a number of tabs. Its default tab, Databases, lists the databases that you created in groups of 20. Each database is shown with the number of documents that it is storing and how much disk space is being used. Click a database name to examine its contents.\n\nTo create a database, click Create Database and supply the name of the database to create.\n\nWe now have a new empty database. The database's documents would be listed here in ID order. However, since this database is new, no documents exist. To add a document, click Create Document.\n\nThe IBM Cloudant Dashboard created a template document for you with a pre-generated _id. Complete the rest of the attributes yourself to complete the JSON document, and click Create Document to save.\n\nNow it's time for another practical exercise. Create a database called books, and in that database, create three or more documents with fields: title, author, date, publisher, and ISBN - each representing a book of your choice.\n\nOnce created, edit one of the documents, modifying the publication date.\n\nThen, delete one of the documents.\n\nTo summarize, the IBM Cloudant Dashboard is a web app that is built into the IBM Cloudant service and is part of the CouchDB open source offering. It is used to manage databases, documents, indexes, queries, and replication jobs. It can also be used to monitor service throughput. The Dashboard is simply an API client - anything that can be achieved with the dashboard can be scripted by you using the HTTP API.\n\nThat's the end of this part. The next part is called HTTP API Basics.\n\n\n\n\n\n\n\n HTTP API Basics video \n\nLearn how to use the command line to make HTTP requests and to add, edit, and delete documents.\n\n\n\n* HTTP API Basics video script", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_00589-25445-26913", "score": 14.633246790898035, "text": "\nGET /$DATABASE/_design/$DOCUMENT_ID/_search_disk_size/$FURTHER_PATH_PARTS cloudantnosqldb.any-document.read \n GET /$DATABASE/_design/$DOCUMENT_ID/_search_info/$FURTHER_PATH_PARTS cloudantnosqldb.any-document.read \n GET/HEAD /$DATABASE/_index/$FURTHER_PATH_PARTS cloudantnosqldb.any-document.read \n GET /$DATABASE/_design_docs cloudantnosqldb.any-document.read \n GET /$DATABASE/_design/$DOCUMENT_ID cloudantnosqldb.any-document.read \n GET/HEAD /$DATABASE/_design/$DOCUMENT_ID/$ATTACHMENT cloudantnosqldb.any-document.read \n PUT /$DATABASE/_design/$DOCUMENT_ID cloudantnosqldb.design-document.write \n COPY /$DATABASE/_design/$DOCUMENT_ID cloudantnosqldb.design-document.write \n DELETE /$DATABASE/_design/$DOCUMENT_ID cloudantnosqldb.design-document.write \n PUT /$DATABASE/_design/$DOCUMENT_ID/$ATTACHMENT cloudantnosqldb.design-document.write \n DELETE /$DATABASE/_design/$DOCUMENT_ID/$ATTACHMENT cloudantnosqldb.design-document.write \n POST/DELETE /$DATABASE/_index/$FURTHER_PATH_PARTS cloudantnosqldb.design-document.write \n GET/HEAD /$DATABASE/_security cloudantnosqldb.database-security.read \n PUT /$DATABASE/_security cloudantnosqldb.database-security.write \n GET/HEAD /$DATABASE/_shards cloudantnosqldb.database-shards.read \n COPY (Depends on write document type.) /$DATABASE/$DOCUMENT_ID cloudantnosqldb.any-document.read + cloudantnosqldb.design-document.write either or both cloudantnosqldb.local-document.write either or both cloudantnosqldb.data-document.write", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudant"}, {"document_id": "ibmcld_00612-7-2163", "score": 14.486708120142296, "text": "\nMigration overview \n\nThe [IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae](https://www.ibm.com/cloud/cloudant) database-as-a-service offering is a JSON document store that runs on multi-tenant clusters. The service is available with a choice of geographical locations with predictable costs, scalability, and a service-level agreement (SLA).\n\nYou can migrate to an IBM Cloudant Lite or Standard plan instance on IBM Cloud from one of the following plans:\n\n\n\nTable 1. IBM Cloudant migration paths\n\n Plan Description \n\n IBM Cloudant Enterprise Dedicated, single-tenant clusters \n Apache CouchDB The self-hosted, open source database on which IBM Cloudant is based. \n\n\n\n\n\n Benefits of the IBM Cloudant Lite and Standard plans \n\nWith the Standard plan, you can reserve throughput capacity for your database service, that is, to specify how much throughput your application's database is going to need to handle demand. The Standard plan also charges for the amount of storage you use. Capacity is measured with the following metrics:\n\n\n\nTable 2. Capacity metrics\n\n Metric Description \n\n Reads per second The rate when simple document fetches are performed, for example, retrieving a document by its _id, or querying against a partitioned database that uses a partition key. \n Writes per second The rate when data is written to the database. API calls dealing with document creation, update, or deletion count as \"writes\". \n Global Queries per second The rate when the database is queried by global indices, typically by accessing the _find endpoint, secondary MapReduce, or search indices. \n Storage The amount of disk space occupied by your JSON data, attachments, and secondary indices. \n\n\n\nAs an example, the Lite plan offers 20 reads per second, 10 writes per second, 5 global queries per second, and 1 GB of storage for free. This plan is ideal when you're evaluating the product and during product development. When your application goes into QA or production, switch to the Standard plan to scale the instance. The Standard plan's smallest capacity has 100 reads per second, 50 writes per second, 5 global queries per second, and 20 GB of storage for USD$76.65 per month.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-to-ibm-cloudant-on-ibm-cloud"}, {"document_id": "ibmcld_06633-1299-3259", "score": 14.480205810810599, "text": "\nYou can extend high-availability further by adding [PostgreSQL members](https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-horizontal-scaling) to the instance, for greater in-region redundancy, or by provisioning [read-only replicas](https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-read-only-replicas) for cross-regional failover or read offloading.\n\nDatabases for PostgreSQL is designed and built to provide a robust, resilient, and performant Database as a Service offering. Review the PostgreSQL documentation on [replication techniques](https://www.postgresql.org/docs/current/wal-async-commit.html) to understand the constraints and tradeoffs that are associated with the asynchronous replication strategy that is deployed by default with Databases for PostgreSQL.\n\nIn scenarios where a database becomes critically unhealthy, such as a server crash on the leader, Databases for PostgreSQL attempts a failover. This auto failover capability is capped at 16 MB of data lag from leader to follower (a few rows of data once accounting for more PostgreSQL data overhead) and is not performed if the lag threshold is exceeded. If the potential for 16 MB of data loss is intolerable for the application, horizontally scale your Databases for PostgreSQL instance to three members and configure Databases for PostgreSQL to use a synchronous replication strategy on a per user or per database basis.\n\n\n\n Synchronous replication \n\nBy default, streaming replication is asynchronous. If the primary server crashes, some transactions that were committed might not have been replicated to the standby server, causing data loss. Cloud Databases ensures that data loss is kept to a minimum substantial data loss; however, synchronous replication offers the ability to confirm that all changes were made by a transaction have been transferred to a synchronous member, ensuring consistency across a cluster.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-high-availability"}, {"document_id": "ibmcld_00550-7-2005", "score": 14.473191316464435, "text": "\nGrouping related documents together in IBM Cloudant \n\nTraditionally, e-commerce systems are built with relational databases. These databases typically use a number of tables joined to record sales, customer details, purchased products, and delivery tracking information.\n\nRelational databases offer high consistency, which means that application developers can build their applications to a database's strengths. This practice includes joins between collections, enumerations to record the state of an object, and database transactions to guarantee atomic operations.\n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae favors availability over consistency. It's a high-availability, fault-tolerant, distributed database that is eventually consistent. A distributed database means the customer's shopping service is always available and scalable enough to cope with many users who make purchases at the same time. With that in mind, your application can leverage IBM Cloudant's strengths and not treat it like a relational database.\n\nThis discussion outlines some of the factors that are involved in building an e-commerce system that takes advantage of IBM Cloudant's strengths. IBM Cloudant uses concepts that are applicable to many other domains, such as:\n\n\n\n* Using multiple documents to represent the state of a purchase, rather than frequently updating a single document.\n* Storing copies of related objects in order instead of joining to another collection.\n* Creating views to collate documents by order_id to reflect the current state of a purchase.\n\n\n\nFor example, you might create a purchase document that includes details such as the items ordered, customer information, cost, and delivery information.\n\nSee the following example document that describes a purchase:\n\n{\n\"_id\": \"023f7a21dbe8a4177a2816e4ad1ea27e\",\n\"type\": \"purchase\",\n\"order_id\": \"320afa89017426b994162ab004ce3383\",\n\"basket\": [\n{\n\"product_id\": \"A56\",\n\"title\": \"Adele - 25\",\n\"category\": \"Audio CD\",\n\"price\": 8.33,\n\"tax\": 0.2,\n\"quantity\": 2\n},\n{", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudant"}, {"document_id": "ibmcld_09521-7-2114", "score": 14.292760881273008, "text": "\nLimitations & Exclusions \n\nMaximo Application Suite SaaS is implemented using a defined set of technologies and operates within a security profile designed to ensure our client's data is secure and the applications operate efficiently and effectively. As a result of the decisions made regarding technologies and to meet the high security standards, there are differences between what is available using the Managed Services and what a client could do if they hosted and operated the Suite themselves.\n\nThe following items are not included or allowed in the Maximo Application Suite SaaS offering:\n\n\n\n Databases \n\nThe following are database limitations of the MAS-SaaS offering:\n\n\n\n* Only IBM DB2 Warehouse is supported. Oracle and SQLServer are not supported. Conversion services are available.\n* If converting from Oracle to DB2, Oracle compatibility mode is not supported.\n* Customers are not allowed direct access to MAS-SaaS database(s). If direct database access is needed, customer should look into the [MAS-Dedicated](https://cloud.ibm.com/docs/mas-ms) offering.\n* DB2 Text Search is not supported.\n* Running SQL statements (update/insert/delete) directly on the database is not allowed and IBM SRE team will not be able to execute those statements for you. DBC scripts are not allowed. Customers should carry out these changes using the Maximo UI via [Automation Scripts](https://ibm-maximo-dev.github.io/maximo-autoscript-documentation/introduction/whatisautoscript) or the [Maximo Integration Framework](https://www.ibm.com/docs/en/maximo-ora-con/8.1.0?topic=architecture-maximo-integration-framework-overview).\n\n\n\n\n\n\n\n Java Extensions \n\nJava extensions are not supported. Maximo Manage [Automation Scripting](https://ibm-maximo-dev.github.io/maximo-autoscript-documentation/introduction/whatisautoscript) capability should instead be used. Existing Maximo customers who have Java extensions will need to migrate / convert these functions into automation scripts within the application.\n\n\n\n\n\n 3rd Party Applications \n\nMaximo Application Suite SaaS will not host or support 3rd party applications.", "title": "", "source": "https://cloud.ibm.com/docs/mas-saas?topic=mas-saas-limitations-exclusions"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03369-66296-68553", "score": 40.57091027615436, "text": "\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_03329-1102-2607", "score": 40.51482259742078, "text": "\n[Finish creating the new assistant](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n![Add actions or dialog skill button](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-addskill.png)\n2. Give your skill the name My first skill.\n3. Optional. If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n4. For skill type, choose Dialog.\n\n![Finish creating the skill](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-add-skill-done.png)\n5. Click Create skill.\n\nThe skill is created and appears in your assistant.\n\n\n\n\n\n\n\n Step 3: Add intents from a content catalog \n\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-gs-dialog"}, {"document_id": "ibmcld_16364-103662-105841", "score": 40.364081917110795, "text": "\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nThe actions skill is available as a beta feature. For more information, see [Adding an actions skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-actions-add).\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance. For more information, see [Integrating the web chat with your website](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat).\n\nText messaging integration was renamed\n: The Twilio messaging integration was renamed to SMS with Twilio.\n\n\n\n\n\n 9 October 2020 \n\nSearch skill update", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_02998-1325-2715", "score": 40.0552478252944, "text": "\nName the assistant My first assistant.\n3. Click Create assistant.\n\n![Finish creating the new assistant](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-create-assistant-done.png)\n\n\n\n\n\n\n\n Step 3: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click the My first assistant tile to open the assistant.\n2. Click Add dialog skill.\n\n![Shows the Add skill button from the home page](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-add-dialog-skill.png)\n3. Click the Create skill tab.\n4. Give your skill the name My first skill.\n5. Optional: If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n\n![Finish creating the skill](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-add-skill-done.png)\n6. Click Create skill.\n\n![Shows the My first assistant with the My first skill added to it](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-my-first-skill.png)\n7. Click the skill you just created to open it.\n\n\n\n\n\n\n\n Step 4: Add intents from a content catalog", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started"}, {"document_id": "ibmcld_03049-1355-3132", "score": 39.170887516517766, "text": "\nClick Import skill, and then click Choose JSON File, and select the JSON file you want to import.\n\nImportant:\n\n\n\n* The imported JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding.\n* The maximum size for a skill JSON file is 10MB. If you need to import a larger skill, consider importing the intents and entities separately after you have imported the skill. (You can also import larger skills using the REST API. For more information, see the [API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-data-v1?curl=createworkspace).)\n* The JSON cannot contain tabs, newlines, or carriage returns.\n\n\n\nSpecify the data you want to include:\n\n\n\n* Select Everything (Intents, Entities, and Dialog) if you want to import a complete copy of the exported skill, including the dialog.\n* Select Intents and Entities if you want to use the intents and entities from the exported skill, but you plan to build a new dialog.\n\n\n\nClick Import.\n\nIf you have trouble importing a skill, see [Troubleshooting skill import issues](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-dialog-addskill-dialog-add-import-errors).\n\n\n\n5. Specify the details for the skill:\n\n\n\n* Name: A name no more than 100 characters in length. A name is required.\n* Description: An optional description no more than 200 characters in length.\n* Language: The language of the user input the skill will be trained to understand. The default value is English.\n\n\n\n\n\nAfter you create the dialog skill, it appears as a tile on the Skills page. Now, you can start identifying the user goals that you want the dialog skill to address.\n\n\n\n* To add prebuilt intents to your skill, see [Using content catalogs](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-catalog).", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-dialog-add"}, {"document_id": "ibmcld_07578-18457-20516", "score": 38.98058138459098, "text": "\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https://cloud.ibm.com/docs/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https://cloud.ibm.com/docs/services/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-18457-20516", "score": 38.98058138459098, "text": "\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https://cloud.ibm.com/docs/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https://cloud.ibm.com/docs/services/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_16364-146046-148039", "score": 37.41021981366418, "text": "\n: For some first-time users, a new introductory product tour is shown that the user can choose to follow to perform the initial steps of creating an assistant.\n\n\n\n\n\n 1 August 2019 \n\nWebhook callouts are available\n: Add webhooks to dialog nodes to make programmatic calls to an external application as part of the conversational flow. The new Webhook support simplifies the callout implementation process. (No more action JSON objects required.) For more information, see [Making a programmatic call from a dialog node](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-webhooks).\n\nImproved dialog page responsiveness\n: In all service instances, the user interface of the Dialog page was updated to use a new JavaScript library that increases the page responsiveness. As a result, the look of some graphical user interface elements, such as buttons, changed slightly, but the function did not.\n\n\n\n\n\n 31 July 2019 \n\nSearch skill and autocorrection are generally available\n: The search skill and spelling autocorrection features, which were previously available as beta features, are now generally available.\n\n\n\n* Search skills can be created by users of Plus or Premium plans only.\n* You can enable autocorrection for English-language dialog skills only. It is enabled automatically for new English-language dialog skills.\n\n\n\n\n\n\n\n 26 July 2019 \n\nMissing skills issue is resolved\n: In some cases, workspaces that were created through the API only were not being displayed when you opened the Watson Assistant user interface. This issue has been addressed. All workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_16364-101992-104197", "score": 36.94163912682321, "text": "\n: The new model, which is being offered as a beta feature in English-language dialog and actions skills, is faster and more accurate. It combines traditional machine learning, transfer learning, and deep learning techniques in a cohesive model that is highly responsive at run time. For more information, see [Improved intent recognition](https://cloud.ibm.com/docs/assistant?topic=assistant-intent-detection).\n\n\n\n\n\n 3 November 2020 \n\nSuggestions are now generally available\n: The Suggestions feature that is available for the web chat integration is generally available and is enabled by default when you create a new web chat integration. For more information, see [Showing more suggestions](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nNew languages supported by the dialog analysis notebook\n: The Dialog skill analysis notebook was updated with language support for French, German, Spanish, Czech, Italian, and Portuguese. For more information, see [Analysis notebooks](https://cloud.ibm.com/docs/assistant?topic=assistant-logs-resourceslogs-resources-jupyter-logs).\n\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03313-17920-19395", "score": 36.94029416375304, "text": "\nTo do so, add a new intent or entity, and then delete it. This action starts a new training process.\n\n\n\n\n\n Is there a range of IP addresses that are being used by a webhook? \n\nUnfortunately, the IP address ranges from which Watson Assistant may call a webhook URL are subject to change, which in turn prevent using them in any static firewall configuration. Please use the https transport and specify an authorization header to control access to the webhook.\n\n\n\n\n\n How do I see my monthly active users in Watson Assistant? \n\nTo see your monthly active users (MAU) do the following:\n\n\n\n1. Sign in to [https://cloud.ibm.com](https://cloud.ibm.com)\n2. Click on the Manage menu, then choose Billing and usage.\n3. Click on Usage.\n4. For Watson Assistant, select View Plans.\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n\n\n\n\n Error: New Off Topic not supported \n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https://cloud.ibm.com/docs/assistant?topic=assistant-irrelevance-detection).\n\n\n\n\n\n Is it possible to increase the number of intents per skill \n\nNo, it is not possible to increase the number of intents per skill.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-faqs"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09120-94597-96242", "score": 9.33976852550383, "text": "\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-protect-cli-reference"}, {"document_id": "ibmcld_08988-95785-97389", "score": 9.338351179661633, "text": "\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https://cloud.ibm.com/docs/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy", "title": "", "source": "https://cloud.ibm.com/docs/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"}, {"document_id": "ibmcld_04488-93746-95375", "score": 9.3324969525045, "text": "\nA unique, human readable name for the key-ring. Required if the user doesn't have permissions on the default key ring.\n\n\n\n\n\n\n\n\n\n kp key schedule-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https://cloud.ibm.com/docs/cli?topic=cli-key-protect-cli-referencekp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n[--key-ring KEY_RING_ID]\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID_OR_ALIAS\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID_OR_ALIAS --output json\n\n[\n{", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-key-protect-cli-reference"}, {"document_id": "ibmcld_09055-22025-23534", "score": 9.286016928071994, "text": "\ncorrelation_id='cbc0d18b-a816-45ab-af6a-b8e18dc3e628',\nmsg='Conflict: 1 prior authorization(s) are required for deletion: Key could not be deleted. Please see \"reasons\" for more details.',\nreasons='[AUTHORIZATIONS_NOT_MET: Number of authorizations required to delete is not met -\nFOR_MORE_INFO_REFER: https://cloud.ibm.com/apidocs/key-protect]'\n\n\n\n\n\n\n\n Required parameters \n\n-d, --disable\nor\n-e, --enable\n: Disable or enable the dual authorization policy. One option is required.\n\n\n\n\n\n\n\n kp key cancel-delete \n\nA key with a dual-auth-delete policy requires authorization from two administrative users to delete the key.\n\nThis command (kp key cancel-delete) cancels, or removes, a prior authorization.\n\nThe [kp key schedule-delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-cli-reference-five-twokp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-cli-reference-five-two"}, {"document_id": "ibmcld_09120-29325-30645", "score": 9.268322525058146, "text": "\nThe [kp key schedule-delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-protect-cli-reference"}, {"document_id": "ibmcld_08988-30080-31503", "score": 9.265104713706297, "text": "\nThis command (kp key cancel-delete) cancels, or removes, a prior authorization.\n\nThe [kp key schedule-delete](https://cloud.ibm.com/docs/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",", "title": "", "source": "https://cloud.ibm.com/docs/key-protect-cli-plugin?topic=key-protect-cli-plugin-key-protect-cli-reference"}, {"document_id": "ibmcld_09055-69659-70937", "score": 9.262557478910121, "text": "\nUser 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nThe [kp key cancel-delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-cli-reference-five-twokp-key-cancel-delete) command cancels, or removes, a prior authorization.\n\nibmcloud kp key schedule-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of scheduleing a key to be deleted.\n\n schedule this key to be deleted\n$ ibmcloud kp key schedule-delete $KEY_ID\n\nScheduling key for deletion...\nOK\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-cli-reference-five-two"}, {"document_id": "ibmcld_08987-28071-29358", "score": 9.261164682016894, "text": "\nThe [kp key schedule-delete](https://cloud.ibm.com/docs/key-protect-cli-pluginkp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",", "title": "", "source": "https://cloud.ibm.com/docs/key-protect-cli-plugin"}, {"document_id": "ibmcld_04488-28730-30034", "score": 9.253285954772211, "text": "\nThe [kp key schedule-delete](https://cloud.ibm.com/docs/cli?topic=cli-key-protect-cli-referencekp-key-schedule-delete) command is the \"authorization\" to delete the key.\n\nFollow this process to delete a key with a dual-auth-delete policy.\n\n\n\n1. Create a key and enable the dual-auth-delete policy\n2. User 1 schedules (authorizes) a key deletion with the kp key schedule-delete command\n3. User 2 schedules (authorizes) a key deletion\n4. The key is deleted after the second schedule-delete is performed, which is supported in the user interface, API, and CLI\n5. If a second authorization does not occur within 7 days, the key returns to its default status\n\n\n\nThere are two ways to enable the dual-auth-delete policy:\n\n\n\n* Set the policy for a single key using kp key policy-update dual-auth-delete\n* Set the policy for the instance using kp instance policy-update dual-auth-delete; all keys created after the instance policy is enabled inherit the instance policy setting\n\n\n\nibmcloud kp key cancel-delete KEY_ID_OR_ALIAS\n-i, --instance-id INSTANCE_ID\n\n\n\n Example \n\nThis is an example of canceling a previously scheduled key delete.\n\n this key has a dual-auth-delete policy\n$ ibmcloud kp key policies $KEY_ID --output json\n\n[\n{\n\"createdBy\": \"user id ...<redacted>...\",\n\"creationDate\": \"2020-06-22T19:13:00Z\",", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-key-protect-cli-reference"}, {"document_id": "ibmcld_09087-21484-22833", "score": 9.238510457336597, "text": "\n\"collectionType\": \"application/vnd.ibm.kms.error+json\",\n\"collectionTotal\": 1\n},\n\"resources\": [\n{\n\"errorMsg\": \"Key could not be deleted. Please 'reasons' for more details.\",\n\"reasons\":\n{\n\"code\": \"PREV_KEY_DEL_ERR\",\n\"message\": \"The key cannot be deleted because it's protecting a cloud resource that has a retention policy.\",\n\"status\": 409,\n\"moreInfo\":\"https://cloud.ibm.com/apidocs/key-protect\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n\n\n 7 - Key has already been deleted... \n\n\n\n Message \n\nKey has already been deleted: Please delete references to this key\n\nReason code: KEY_DELETED_ERR\n\n\n\n\n\n HTTP status code \n\n410 - Gone\n\nThe HTTP 410 Gone client error response code indicates that access to the target resource is no longer available at the origin server and that this condition is likely to be permanent.\n\nIf you don't know whether this condition is temporary or permanent, a 404 status code should be used instead.\n\nA 410 response is cacheable by default.\n\n\n\n\n\n Context \n\nThe delete key request fails because the key was previously deleted. You cannot delete a key more than once.\n\n\n\n Example \n\n delete an existing key\n$ ibmcloud kp key delete $KEY_ID -i $KP_INSTANCE_ID\n\nDeleting key: '0c17...<redacted>...5c34', from instance: 'a192...<redacted>...7411'...\nOK\nDeleted Key\n0c17...<redeacted>...5c34\n\n this request fails because the key was previously deleted", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-error-messages"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07836-0-1892", "score": 25.494833501475476, "text": "\n\n\n\n\n\n\n  PS-4 - Personnel Termination \n\n\n\n  Control requirements \n\nThe organization, upon termination of individual employment:\n\nPS-4 (a)\n:   Disables information system access within [IBM Assignment: same day];\n\nPS-4 (b)\n:   Terminates/revokes any authenticators/credentials associated with the individual;\n\nPS-4 (c)\n:   Conducts exit interviews that include a discussion of [Assignment: organization-defined information security topics];\n\nPS-4 (d)\n:   Retrieves all security-related organizational information system-related property;\n\nPS-4 (e)\n:   Retains access to organizational information and information systems formerly controlled by terminated individual; and\n\nPS-4 (f)\n:   Notifies [Assignment: organization-defined personnel or roles] within [IBM Assignment: same day].\n\n\n\n\n\n  NIST supplemental guidance \n\nInformation system-related property includes, for example, hardware authentication tokens, system administration technical manuals, keys, identification cards, and building passes. Exit interviews ensure that terminated individuals understand the security constraints imposed by being former employees and that proper accountability is achieved for information system-related property. Security topics of interest at exit interviews can include, for example, reminding terminated individuals of nondisclosure agreements and potential limitations on future employment. Exit interviews may not be possible for some terminated individuals, for example, in cases related to job abandonment, illnesses, and nonavailability of supervisors. Exit interviews are important for individuals with security clearances. Timely execution of termination actions is essential for individuals terminated for cause. In certain situations, organizations consider disabling the information system accounts of individuals that are being terminated prior to the individuals being notified.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ps-4"}, {"document_id": "ibmcld_07147-7609-10190", "score": 24.685918777714726, "text": "\nAlso includes discussion of the consequences of violation of intellectual property rights. \n Liability Elements that describe the method for determining when and how fault attaches to any party. Examples might include, but are not limited to, statements regarding limitations of liability, third-party claims, and repairs, replacements, or reimbursements as required of the party at fault. \n Payment Terms & Billing Elements that detail how and when a party is to pay or get paid, as well as the items or fees the parties are paying or billed for. Includes references to modes of payment or payment mechanisms. \n Pricing & Taxes Elements that refer to specific amounts or figures that are associated with individual deliverables that are exchanged (for example, how much something costs) as part of satisfying the terms of the contract. Includes references to specific figures or methods for calculating prices or tax amounts. \n Privacy Elements that are particularly concerned with the treatment of sensitive personal information, usually regarding its protection, for example to satisfy regulations such as GDPR. \n Responsibilities Elements that discuss tasks ancillary to the contract that are in only one party\u2019s control, specifically focused on discussion of own employee oversight. \n Safety and Security Elements referring to physical safety or cybersecurity protection for people, data, or systems. Examples include discussions of background checks, safety precautions, workplace security, secure access protocols, and product defects that might pose a danger. \n Scope of Work Elements that define what is in the contract versus is not in the contract; consequently, what is promised to be done. Examples include statements defining a particular order, or describing the goals or aim outlined in the contract. \n Subcontracts Elements referring to the hiring of third parties to perform certain duties under the contract, and the permissions, rights, restrictions, and consequences thereto and arising therefrom. \n Term & Termination Elements referring to duration of the contract, the schedule and terms of contract termination, and any consequences of termination, including any obligations that apply at or after termination. \n Warranties Elements that refer to ongoing promises and obligations that are made in the contract that are currently true and will continue to be true in the future. Also, elements discussing the consequences of such promises or obligations being broken, and the rights to remedy the situation (for example, but not limited to, seeking damages).", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-contract_parsing"}, {"document_id": "ibmcld_08813-3093-4221", "score": 20.896177832368835, "text": "\n* Select the Add/Modify Context Address Translations and Apply Configurations to save and apply the configuration.\n\n\n\nThis action sets up a static one-to-one network translation for the return traffic, which is used by your hosts behind the IBM Cloud VPN concentrator to communicate with the hosts behind the remote VPN peer. For example, all traffic for IP 10.1.255.92 will be translated and forwarded to the customer's IP 192.168.10.15. This forwarding eliminates the need for more route entries on the IBM Cloud server.\n\nDue to security reasons, IBM does not provide specific hardware or software/operating system information about the equipment used to host our IPsec and SSL VPN services.\n\n\n\n\n\n Known restrictions \n\nDue to incompatibilities with our IBM CLoud IPsec VPN service, you are unable to build IPsec VPN tunnels with other major cloud providers, such as AWS, Azure, and Google Cloud. If you feel that building an IPsec VPN tunnel between your IBM Cloud environment and any of these providers is necessary, reach out to the IBM Sales team to discuss options that are available, such as a personal gateway appliance.", "title": "", "source": "https://cloud.ibm.com/docs/iaas-vpn?topic=iaas-vpn-setup-ipsec-vpn"}, {"document_id": "ibmcld_13121-7-1979", "score": 20.435104733577358, "text": "\nEnhance cloud security by applying context-based restrictions \n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nThis tutorial walks you through the process of implementing [context-based restrictions](https://cloud.ibm.com/docs/account?topic=account-context-restrictions-whatis) (CBRs) in your IBM Cloud account. CBRs help you to secure the cloud environment further and move towards a [zero trust security model](https://en.wikipedia.org/wiki/Zero_trust_security_model).\n\nThe tutorial discusses how to create network zones and context rules and how to verify that they work. In the tutorial, you learn how to create the CBR objects both in the browser console and as Infrastructure as Code with Terraform. You will also learn about criteria on how to define the access strategy for your cloud resources.\n\n\n\n Objectives \n\n\n\n* Learn about context-based restrictions to protect your cloud resources\n* Define network zones to identify traffic sources for allowed and denied access\n* Create rules that define context for access to your cloud resources\n* Know how to test and monitor context rules\n\n\n\nThe following diagram shows the solution architecture as used in the tutorial [Apply end to end security to a cloud application](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-cloud-e2e-security). The additional boxes with dashed, blue lines around the Kubernetes Service cluster, Container Registry, Key Protect, and Object Storage denote context-based restrictions implemented as context rules. Note that Secrets Manager could have been protected, too, but is only an optional service and not used in this tutorial.\n\nZoom\n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution67-cbr-enhanced-security/architecture-e2e-security-cbr.svg)\n\nSolution architecture", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security"}, {"document_id": "ibmcld_08172-22268-23768", "score": 19.771240690257876, "text": "\necho export TF_VAR_ibmcloud_api_key=$(ibmcloud iam service-api-key-create $team $basename-$team --output json | jq .apikey) > local.env\ncat local.env\nsource local.env\n2. Optionally, dig deeper at this point into some of the Terraform source code. The shared team is going to provide microservices. Although the network team has already created the shared VPC and some network resources the shared team will create the instance and choose the instance profile. A Linux configuration script and simple demo application is provided in the user_data attribute and discussed in the Application Team section below.\n\nIn main.tf notice these two resources:\n\nlocals {\nnetwork_context = data.terraform_remote_state.network.outputs.shared\n}\n\nresource ibm_is_instance \"vsishared\" {\nname = \"${var.basename}-shared-vsi\"\nvpc = local.network_context.vpc.id\nresource_group = data.ibm_resource_group.shared.id\nzone = local.network_context.subnets[\"z1\"].zone\nkeys = [data.ibm_is_ssh_key.ssh_key.id]\nimage = data.ibm_is_image.image.id\nprofile = var.profile[var.generation]\n\nprimary_network_interface {\nsubnet = local.network_context.subnets[\"z1\"].id\nsecurity_groups = [\nlocal.network_context.security_group_outbound_all.id, nodejs is not available on an IBM mirror\nlocal.network_context.security_group_ibm_dns.id,\nlocal.network_context.security_group_data_inbound.id,\n]\n}\nuser_data = module.user_data_app.user_data_centos\n}\n\nresource ibm_dns_resource_record \"shared\" {\ncount = var.shared_lb ? 0 : 1 shared load balancer?", "title": "", "source": "https://cloud.ibm.com/docs/hardware-firewall-shared?topic=hardware-firewall-shared-vpc-tg-dns-iam"}, {"document_id": "ibmcld_13873-22214-23714", "score": 19.771240690257876, "text": "\necho export TF_VAR_ibmcloud_api_key=$(ibmcloud iam service-api-key-create $team $basename-$team --output json | jq .apikey) > local.env\ncat local.env\nsource local.env\n2. Optionally, dig deeper at this point into some of the Terraform source code. The shared team is going to provide microservices. Although the network team has already created the shared VPC and some network resources the shared team will create the instance and choose the instance profile. A Linux configuration script and simple demo application is provided in the user_data attribute and discussed in the Application Team section below.\n\nIn main.tf notice these two resources:\n\nlocals {\nnetwork_context = data.terraform_remote_state.network.outputs.shared\n}\n\nresource ibm_is_instance \"vsishared\" {\nname = \"${var.basename}-shared-vsi\"\nvpc = local.network_context.vpc.id\nresource_group = data.ibm_resource_group.shared.id\nzone = local.network_context.subnets[\"z1\"].zone\nkeys = [data.ibm_is_ssh_key.ssh_key.id]\nimage = data.ibm_is_image.image.id\nprofile = var.profile[var.generation]\n\nprimary_network_interface {\nsubnet = local.network_context.subnets[\"z1\"].id\nsecurity_groups = [\nlocal.network_context.security_group_outbound_all.id, nodejs is not available on an IBM mirror\nlocal.network_context.security_group_ibm_dns.id,\nlocal.network_context.security_group_data_inbound.id,\n]\n}\nuser_data = module.user_data_app.user_data_centos\n}\n\nresource ibm_dns_resource_record \"shared\" {\ncount = var.shared_lb ? 0 : 1 shared load balancer?", "title": "", "source": "https://cloud.ibm.com/docs/transit-gateway?topic=transit-gateway-vpc-tg-dns-iam"}, {"document_id": "ibmcld_13244-21896-23396", "score": 19.771240690257876, "text": "\necho export TF_VAR_ibmcloud_api_key=$(ibmcloud iam service-api-key-create $team $basename-$team --output json | jq .apikey) > local.env\ncat local.env\nsource local.env\n2. Optionally, dig deeper at this point into some of the Terraform source code. The shared team is going to provide microservices. Although the network team has already created the shared VPC and some network resources the shared team will create the instance and choose the instance profile. A Linux configuration script and simple demo application is provided in the user_data attribute and discussed in the Application Team section below.\n\nIn main.tf notice these two resources:\n\nlocals {\nnetwork_context = data.terraform_remote_state.network.outputs.shared\n}\n\nresource ibm_is_instance \"vsishared\" {\nname = \"${var.basename}-shared-vsi\"\nvpc = local.network_context.vpc.id\nresource_group = data.ibm_resource_group.shared.id\nzone = local.network_context.subnets[\"z1\"].zone\nkeys = [data.ibm_is_ssh_key.ssh_key.id]\nimage = data.ibm_is_image.image.id\nprofile = var.profile[var.generation]\n\nprimary_network_interface {\nsubnet = local.network_context.subnets[\"z1\"].id\nsecurity_groups = [\nlocal.network_context.security_group_outbound_all.id, nodejs is not available on an IBM mirror\nlocal.network_context.security_group_ibm_dns.id,\nlocal.network_context.security_group_data_inbound.id,\n]\n}\nuser_data = module.user_data_app.user_data_centos\n}\n\nresource ibm_dns_resource_record \"shared\" {\ncount = var.shared_lb ? 0 : 1 shared load balancer?", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-tg-dns-iam"}, {"document_id": "ibmcld_16096-22142-23642", "score": 19.771240690257876, "text": "\necho export TF_VAR_ibmcloud_api_key=$(ibmcloud iam service-api-key-create $team $basename-$team --output json | jq .apikey) > local.env\ncat local.env\nsource local.env\n2. Optionally, dig deeper at this point into some of the Terraform source code. The shared team is going to provide microservices. Although the network team has already created the shared VPC and some network resources the shared team will create the instance and choose the instance profile. A Linux configuration script and simple demo application is provided in the user_data attribute and discussed in the Application Team section below.\n\nIn main.tf notice these two resources:\n\nlocals {\nnetwork_context = data.terraform_remote_state.network.outputs.shared\n}\n\nresource ibm_is_instance \"vsishared\" {\nname = \"${var.basename}-shared-vsi\"\nvpc = local.network_context.vpc.id\nresource_group = data.ibm_resource_group.shared.id\nzone = local.network_context.subnets[\"z1\"].zone\nkeys = [data.ibm_is_ssh_key.ssh_key.id]\nimage = data.ibm_is_image.image.id\nprofile = var.profile[var.generation]\n\nprimary_network_interface {\nsubnet = local.network_context.subnets[\"z1\"].id\nsecurity_groups = [\nlocal.network_context.security_group_outbound_all.id, nodejs is not available on an IBM mirror\nlocal.network_context.security_group_ibm_dns.id,\nlocal.network_context.security_group_data_inbound.id,\n]\n}\nuser_data = module.user_data_app.user_data_centos\n}\n\nresource ibm_dns_resource_record \"shared\" {\ncount = var.shared_lb ? 0 : 1 shared load balancer?", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-tg-dns-iam"}, {"document_id": "ibmcld_07011-25032-27645", "score": 19.595262814413523, "text": "\nExamples may include, but are not limited to, statements regarding limitations of liability, third-party claims, and repairs, replacements, or reimbursements as required of the party at fault. \n Payment Terms & Billing Elements that detail how and when a party is to pay or get paid, and the items or fees the parties will be paying or billed for. Includes references to modes of payment or payment mechanisms. \n Pricing & Taxes Elements that refer to specific amounts or figures that are associated with individual deliverables that are exchanged (for example, how much something costs) as part of satisfying the terms of the contract. Includes references to specific figures or methods for calculating prices or tax amounts. \n Privacy Elements that are particularly concerned with the treatment of sensitive personal information, usually regarding its protection (for example, to satisfy regulations such as GDPR). \n Responsibilities Elements that discuss tasks ancillary to the contract that are in only one party's control and are focused on discussion of employee oversight. \n Safety and Security Elements referring to physical safety or cybersecurity protection for people, data, or systems. Examples include discussions of background checks, safety precautions, workplace security, secure access protocols, and product defects that might pose a danger. \n Scope of Work Elements that define what is in the contract versus is not in the contract; consequently, what is promised to be done. Examples include statements that define an order, or describe the goals or aims outlined in the contract. \n Subcontracts Elements referring to the hiring of third parties to perform certain duties under the contract, and the permissions, rights, restrictions, and consequences thereto and arising therefrom. \n Term & Termination Elements referring to duration of the contract, the schedule and terms of contract termination, and any consequences of termination, including any obligations that apply at or after termination. \n Warranties Elements that refer to ongoing promises and obligations that are made in the contract that are currently true and will continue to be true in the future. Also, elements that discuss the consequences of such promises or obligations that are broken, and the rights to remedy the situation (for example, but not limited to, seeking damages). This category does not apply to elements that are concerned with representation statements (statements of fact about the past or the present), or to elements that lay out assumptions about things that occurred in the past. \n\n\n\n\n\n\n\n Attributes", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-contracts-schema"}, {"document_id": "ibmcld_10916-4487-6524", "score": 18.17868549618581, "text": "\nAn API key is used to track and control how the API is being used, for example, to prevent malicious use or abuse of the API.\n\n\n\n\n\n API operation \n\nA unit of a REST API that can be invoked. An API operation comprises an HTTP verb and a URL path that is subordinate to the context root of the API.\n\n\n\n\n\n API resource \n\nA unit of a REST API that can be invoked. An API resource comprises an HTTP verb and a unique URL path that is subordinate to the context root of the API.\n\n\n\n\n\n app \n\nA web or mobile device application. See also [web application](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx2116500), [mobile application](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx4258535).\n\n\n\n\n\n artifact \n\nAn entity that is used or produced by a software or systems development process. Examples of artifacts include designs, requirements, source files, plans, scripts, simulations, models, test plans, and binary executable files. In an HTTP context, artifacts have a URI and are called resources.\n\n\n\n\n\n assembly \n\nAn application programming interface that provides rich functionality for interacting with an application. The assembly makes side calls to external services and then transforms and aggregates the response before a response is relayed to the calling application.\n\n\n\n\n\n asset \n\nTangible or intangible goods, services, or property represented as an entity that is traded on a blockchain network.\n\n\n\n\n\n attachment \n\nIn Security and Compliance Center, the connection between a profile and scope.\n\n\n\n\n\n attribute \n\nA characteristic or trait of an entity that describes the entity; for example, the telephone number of an employee is one of the employee attributes.\n\n\n\n\n\n authentication (AuthN) \n\nThe process of validating the identity of a user or server.\n\n\n\n\n\n AuthN \n\nSee [authentication](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx2014567).\n\n\n\n\n\n authorization (AuthZ) \n\nIn computer security, the right granted to a user to communicate with or make use of a computer system.\n\n\n\n\n\n AuthZ", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-glossary"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16417-3559-5683", "score": 34.359973863017224, "text": "\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16481-3559-5682", "score": 34.359973863017224, "text": "\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16464-12399-14287", "score": 26.171851722751686, "text": "\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.]", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16417-1764-4158", "score": 25.814158549794712, "text": "\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16481-1764-4158", "score": 25.814158549794712, "text": "\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16563-12333-14196", "score": 25.71233596962041, "text": "\nThe IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https://cloud.ibm.com/docs-content/v1/content/50eddb8fd81f33092880335ff107a78ff5cd0f65/watson-knowledge-studio/images/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}, {"document_id": "ibmcld_16417-5155-7505", "score": 25.22020284373318, "text": "\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16481-5154-7504", "score": 25.22020284373318, "text": "\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16563-10714-12816", "score": 23.90322579672045, "text": "\nFrom the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\nIn a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}, {"document_id": "ibmcld_16464-13891-15856", "score": 23.894768099174765, "text": "\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https://cloud.ibm.com/docs-content/v1/content/148d3bd95f946aa1bb53ea1540475f522e6b61c9/watson-knowledge-studio-data/images/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-842782-844922", "score": 32.92063799724741, "text": "\nFor HA, a Hardware Firewall (High Availability) or FortiGate Security Appliance (High Availability) is required. The Network Gateway product also has an HA option with firewall capabilities.\n* I am running a hypervisor on an IBM Cloud server. Will the Hardware Firewall protect the Virtual Machines running on my hypervisor?\n\nNo. Portable IPs are used for the VMs in a hypervisor environment and portable IPs are not protected by the hardware firewall. A FortiGate Security Appliance is recommended.\n* What are the grayed out ports in my Windows Firewall?\n\nIBM Cloud offers many different services that you can utilize with your server including Evault, SNMP and Nagios monitoring. These services require that our internal systems communicate with your server to some degree. The grayed out ports you see in the Exceptions list are ports open on the internal network port only. They are still blocked on the public (internet) network connection. Since the internal network is a secured network having these ports open is considered secure.\n\nThese ports generally cannot be modified; however, if you reset the firewall rules, it will clear them from the Exceptions list. Please beware that resetting the firewall rules may have an adverse affect not only on these additional services but also could cause other issues as well with your server depending on its current configuration.\n* What Hardware Firewall options are available for 10Gbps servers?\n\nFSA 10G is the only option to support 10Gbps servers for both public and private traffic. If 10Gbps is only required on the private network (for database, backup, storage, etc), then customers can request a downgrade of only their public uplinks and order any of the Hardware Firewall products.\n* What IP ranges do I allow through the firewall?\n\nFor the list of IP addresses and IP ranges to allow through the firewall, go [here](https://cloud.ibm.com/docs/hardware-firewall-shared?topic=cloud-infrastructure-ibm-cloud-ip-ranges).\n* What VPN options are included with each firewall product?\n\nNot all firewalls offer VPN and not all VPN options are the same. The general options for VPN are:", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-842655-844795", "score": 32.92063799724741, "text": "\nFor HA, a Hardware Firewall (High Availability) or FortiGate Security Appliance (High Availability) is required. The Network Gateway product also has an HA option with firewall capabilities.\n* I am running a hypervisor on an IBM Cloud server. Will the Hardware Firewall protect the Virtual Machines running on my hypervisor?\n\nNo. Portable IPs are used for the VMs in a hypervisor environment and portable IPs are not protected by the hardware firewall. A FortiGate Security Appliance is recommended.\n* What are the grayed out ports in my Windows Firewall?\n\nIBM Cloud offers many different services that you can utilize with your server including Evault, SNMP and Nagios monitoring. These services require that our internal systems communicate with your server to some degree. The grayed out ports you see in the Exceptions list are ports open on the internal network port only. They are still blocked on the public (internet) network connection. Since the internal network is a secured network having these ports open is considered secure.\n\nThese ports generally cannot be modified; however, if you reset the firewall rules, it will clear them from the Exceptions list. Please beware that resetting the firewall rules may have an adverse affect not only on these additional services but also could cause other issues as well with your server depending on its current configuration.\n* What Hardware Firewall options are available for 10Gbps servers?\n\nFSA 10G is the only option to support 10Gbps servers for both public and private traffic. If 10Gbps is only required on the private network (for database, backup, storage, etc), then customers can request a downgrade of only their public uplinks and order any of the Hardware Firewall products.\n* What IP ranges do I allow through the firewall?\n\nFor the list of IP addresses and IP ranges to allow through the firewall, go [here](https://cloud.ibm.com/docs/hardware-firewall-shared?topic=cloud-infrastructure-ibm-cloud-ip-ranges).\n* What VPN options are included with each firewall product?\n\nNot all firewalls offer VPN and not all VPN options are the same. The general options for VPN are:", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1006129-1007999", "score": 28.90901706665085, "text": "\n* How can I filter internet-bound traffic and only allow specific protocols and destinations?\n\nThis is a common question when Source NAT and a firewall must be combined.\n\nKeep in mind the order of operations in the VRA you design your rulesets.\n\nIn short, firewall rules are applied after SNAT.\n\nTo block all outgoing traffic in a firewall, but allow specific SNAT flows, you must move the filtering logic onto your SNAT. For example, to only allow HTTPS internet-bound traffic for a host, the SNAT rule would be:\n\nset service nat source rule 10 description 'SNAT https traffic from server 10.1.2.3 to Internet'\nset service nat source rule 10 destination port 443\nset service nat source rule 10 outbound-interface 'dp0bond1'\nset service nat source rule 10 protocol 'tcp'\nset service nat source rule 10 source address '10.1.2.3'\nset service nat source rule 10 translation address '150.1.2.3'\n\n150.1.2.3 would be a public address for the VRA.\n\nIt is recommended to use the VRRP public address of the VRA so that you can differentiate between host and VRA public traffic.\n\nAssume that 150.1.2.3 is the VRRP VRA address, and 150.1.2.5 is the real dp0bond1 address. The stateful firewall applied on dp0bond1 out would be:\n\nset security firewall name TO_INTERNET default-action drop\nset security firewall name TO_INTERNET rule 10 action accept\nset security firewall name TO_INTERNET rule 10 description 'Accept host traffic to Internet - SNAT to VRRP'\nset security firewall name TO_INTERNET rule 10 source address '150.1.2.3'\nset security firewall name TO_INTERNET rule 10 state 'enable'\nset security firewall name TO_INTERNET rule 20 action accept\nset security firewall name TO_INTERNET rule 20 description 'Accept VRA traffic to Internet'\nset security firewall name TO_INTERNET rule 20 source address '150.1.2.5'\nset security firewall name TO_INTERNET rule 20 state 'enable'", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1006000-1007870", "score": 28.90901706665085, "text": "\n* How can I filter internet-bound traffic and only allow specific protocols and destinations?\n\nThis is a common question when Source NAT and a firewall must be combined.\n\nKeep in mind the order of operations in the VRA you design your rulesets.\n\nIn short, firewall rules are applied after SNAT.\n\nTo block all outgoing traffic in a firewall, but allow specific SNAT flows, you must move the filtering logic onto your SNAT. For example, to only allow HTTPS internet-bound traffic for a host, the SNAT rule would be:\n\nset service nat source rule 10 description 'SNAT https traffic from server 10.1.2.3 to Internet'\nset service nat source rule 10 destination port 443\nset service nat source rule 10 outbound-interface 'dp0bond1'\nset service nat source rule 10 protocol 'tcp'\nset service nat source rule 10 source address '10.1.2.3'\nset service nat source rule 10 translation address '150.1.2.3'\n\n150.1.2.3 would be a public address for the VRA.\n\nIt is recommended to use the VRRP public address of the VRA so that you can differentiate between host and VRA public traffic.\n\nAssume that 150.1.2.3 is the VRRP VRA address, and 150.1.2.5 is the real dp0bond1 address. The stateful firewall applied on dp0bond1 out would be:\n\nset security firewall name TO_INTERNET default-action drop\nset security firewall name TO_INTERNET rule 10 action accept\nset security firewall name TO_INTERNET rule 10 description 'Accept host traffic to Internet - SNAT to VRRP'\nset security firewall name TO_INTERNET rule 10 source address '150.1.2.3'\nset security firewall name TO_INTERNET rule 10 state 'enable'\nset security firewall name TO_INTERNET rule 20 action accept\nset security firewall name TO_INTERNET rule 20 description 'Accept VRA traffic to Internet'\nset security firewall name TO_INTERNET rule 20 source address '150.1.2.5'\nset security firewall name TO_INTERNET rule 20 state 'enable'", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_13915-6476-8449", "score": 28.745431906498734, "text": "\nUnlike the firewall rules applied for packets traversing through the VRA, the default action of firewall rules for traffic entering or leaving the control plane is Allow. Users must add explicit drop rules if the default behavior is not desired.\n\nThe VRA provides a basic CPP rule set as template. You can merge it into your configuration by running:\n\nvyatta@vrouter merge /opt/vyatta/etc/cpp.conf\n\nAfter this rule set is merged, a new firewall rule set named CPP is added and applied to the loopback interface. It is recommend that you modify this rule set to suit your environment.\n\nPlease note that CPP rules cannot be stateful, and will only apply on ingress traffic.\n\n\n\n\n\n Zone firewalling \n\nAnother firewall concept within the IBM Cloud\u00ae Virtual Router Appliance is zone based firewalls. In zone-based firewall operation an interface is assigned to a zone (only one zone per interface) and firewall rule sets are assigned to the boundaries between zones with the idea that all interfaces within a zone have the same security level and are allowed to route freely. Traffic is only scrutinized when it is passing from one zone to another. Zones drop any traffic coming into them which is not explicitly allowed.\n\nAn interface can either belong to a zone or have a per-interface firewall configuration; an interface cannot do both.\n\nImagine the following office scenario with three departments, each department with its own VLAN:\n\n\n\n* Department A - VLANs 10 and 20 (interface dp0bond1.10 and dp0bond1.20)\n* Department B - VLANs 30 and 40 (interface dp0bond1.30 and dp0bond1.40)\n* Department C - VLAN 50 (interface dp0bond1.50)\n\n\n\nA zone can be created for each department and the interfaces for that department can be added to the zone. The following example illustrates this:\n\nset security zone-policy zone DEPARTMENTA interface dp0bond1.10\nset security zone-policy zone DEPARTMENTA interface dp0bond1.20\nset security zone-policy zone DEPARTMENTB interface dp0bond1.30", "title": "", "source": "https://cloud.ibm.com/docs/virtual-router-appliance?topic=virtual-router-appliance-manage-your-ibm-firewalls"}, {"document_id": "ibmcld_04109-7-2036", "score": 28.743321006067756, "text": "\nAssigning firewall rule actions \n\nFirewall rule actions tell CIS how to respond to requests that match the criteria you define.\n\nFor lightweight firewall rules, navigate to Security > IP firewall, which contains IP rules, User Agent rules, and Domain Lockdown rules. Firewall rules are based on IP address, IP address range, Autonomous System Number (ASN), or country/region.\n\nDomain lockdown rules specify a list of IP addresses, CIDR ranges, or networks that can access a domain, subdomain, or URL. Anything not on the list is blocked.\n\nFor more robust firewall rules, navigate to Security > Firewall rules, where you can create rules that examine incoming HTTP traffic against a set of filters to block, challenge, log, or allow matching requests.\n\nThe following table describes the actions that you can assign to your rules. The priority column shows what precedence the action receives. If a request matches two different rules that have the same priority, precedence determines the action to take.\n\n\n\nTable 1. Firewall rule actions and priority\n\n Action Available in Description Priority \n\n Log <br><br> * Firewall rules<br><br><br> Logs matching requests on the CIS edge for access with Enterprise Logpush and Logpull. Recommended for testing rule effectiveness you commit to a more severe action. Available to Enterprise customers only. 1 \n Bypass <br><br> * Firewall rules<br><br><br> Allows dynamic disabling of security features for a request. Exempts matching requests from evaluation, based on a user-defined list that contains one or more of the following features: Browser Integrity Check, Domain Lockdown, Hotlink Protection, Rate Limiting, Security Level, User Agent Block, WAF Managed Rules. Matching requests are still subject to evaluation within Firewall Rules, based on order of execution. 2 \n Allow <br><br> * Firewall rules<br> * IP firewall<br><br><br> Allows matching requests to access the site, on condition that no other CIS firewall features block the request, such as IP firewall or access rules. 3", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-actions"}, {"document_id": "ibmcld_13915-3198-5235", "score": 28.468430994409076, "text": "\nset security firewall name ALLOW_LEGACY rule 1 action drop\nset security firewall name ALLOW_LEGACY rule 1 source address network-group1\nset security firewall name ALLOW_LEGACY rule 2 action drop\nset security firewall name ALLOW_LEGACY rule 2 destination port 23\nset security firewall name ALLOW_LEGACY rule 2 log\nset security firewall name ALLOW_LEGACY rule 2 protocol tcp\nset security firewall name ALLOW_LEGACY rule 2 source address network-group2\n\nIn the ruleset, ALLOW_LEGACY, there are two rules defined. The first rule drops any traffic sourced from an address group named network-group1. The second rule discards and logs any traffic destined for the telnet port (tcp/23) from the address group named network-group2. The default-action indicates that anything else is accepted.\n\n\n\n\n\n Allowing data center access \n\nIBM\u00a9 offers several IP subnets to provide services and support to systems running within the data center. For example, DNS resolver services are running on 10.0.80.11 and 10.0.80.12. Other subnets are used during provisioning and support. You can find the IP ranges used in the data centers in [this topic](https://cloud.ibm.com/docs/hardware-firewall-dedicated?topic=hardware-firewall-dedicated-ibm-cloud-ip-ranges).\n\nYou can allow data center access by placing the proper SERVICE-ALLOW rules at the beginning of the firewall rule sets with an action of accept. Where the rule set must be applied depends on the routing and firewall design being implemented.\n\nIt is recommended that you place the firewall rules in the location which causes the least duplication of work. For example, allowing backend subnets inbound on dp0bond0 would be less work than allowing backend subnets outbound toward each VLAN virtual interface.\n\n\n\n Per-interface firewall rules \n\nOne method for configuring the firewall on a VRA is to apply firewall rule sets to each interface. In this case an interface can be a dataplane interface (dp0s0) or a virtual interface (dp0bond0.303). Each interface has three possible firewall assignments:", "title": "", "source": "https://cloud.ibm.com/docs/virtual-router-appliance?topic=virtual-router-appliance-manage-your-ibm-firewalls"}, {"document_id": "ibmcld_13915-1601-3647", "score": 28.401516447731623, "text": "\nAs GLOBAL_STATELESS does not specify protocol tcp, the global-state-policy tcp command would not apply on this rule.\n\nset security firewall name GLOBAL_STATEFUL_TCP rule 1 action accept\nset security firewall name GLOBAL_STATEFUL_TCP rule 1 protocol tcp\n\nIn this case protocol tcp is explicitly defined. The global-state-policy tcp command would enable stateful tracking of traffic that matches rule 1 of GLOBAL_STATEFUL_TCP\n\nTo make individual firewall rules 'stateful':\n\nset security firewall name TEST rule 1 allow\nset security firewall name TEST rule 1 state enable\n\nThis would enable stateful tracking of all traffic that can be tracked statefully and matches rule 1 of TEST, regardless of the existence of global-state-policy commands.\n\n\n\n\n\n ALG for assisted stateful tracking \n\nA few protocols such as FTP utilize more complex sessions that the normal stateful firewall operation can track. There are preconfigured modules that enable these protocols to be statefully managed.\n\nIt is suggested to disable these ALG modules, unless they are required for the successful use of the respective protocols.\n\nset system alg ftp 'disable'\nset system alg icmp 'disable'\nset system alg pptp 'disable'\nset system alg rpc 'disable'\nset system alg rsh 'disable'\nset system alg sip 'disable'\nset system alg tftp 'disable'\n\n\n\n\n\n Firewall rule sets \n\nFirewall rules are grouped together into named sets to make applying rules to multiple interfaces easier. Each rule set has a default action associated with it. Consider the following example:\n\nset security firewall name ALLOW_LEGACY default-action accept\nset security firewall name ALLOW_LEGACY rule 1 action drop\nset security firewall name ALLOW_LEGACY rule 1 source address network-group1\nset security firewall name ALLOW_LEGACY rule 2 action drop\nset security firewall name ALLOW_LEGACY rule 2 destination port 23\nset security firewall name ALLOW_LEGACY rule 2 log\nset security firewall name ALLOW_LEGACY rule 2 protocol tcp\nset security firewall name ALLOW_LEGACY rule 2 source address network-group2", "title": "", "source": "https://cloud.ibm.com/docs/virtual-router-appliance?topic=virtual-router-appliance-manage-your-ibm-firewalls"}, {"document_id": "ibmcld_14644-7-1990", "score": 28.020184933293468, "text": "\nNetworking considerations for vCenter Server instances \n\nReview the following information for details about networking considerations and requirements for your VMware vCenter Server\u00ae instances. Ensure that you meet the requirements so that your instance functions properly.\n\n\n\n Networking components for vCenter Server instances \n\nTo review the networking components that are included in your vCenter Server instance, see [Technical specifications for vCenter Server instances](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_vcenterserveroverviewvc_vcenterserveroverview-specs).\n\n\n\n\n\n Firewall considerations \n\nIf you're using firewalls, you must configure rules for all communications from the IBM\u00ae CloudDriver virtual server instance (VSI) and the SDDC Manager virtual machines (VMs). These rules must allow all protocols to communicate on the IP addresses 10.0.0.0/8 and 161.26.0.0/16. Examples of such firewalls are NSX Distributed Firewalls (DFW) or vSRX gateway cluster firewalls.\n\nSome components might attempt to connect to the public network, although they are deployed to your private network. In some cases, such as Zerto Virtual Replication or FortiGate-VM, this connection is required for licensing or to report usage. These components are configured to connect either by using the instance NAT or a proxy you provide. You might need to allow these connections in your firewall. In other cases, these connection attempts are only for diagnostic and usage data, and the connections fail since no public connectivity is available or configured.\n\n\n\n\n\n Using NSX with your virtual machines \n\nDuring vCenter Server instance deployment, VMware NSX\u00ae is ordered, installed, licensed, and configured in your instance. Also, NSX Manager, VMware NSX Controllers\u2122, and NSX Transport Zone are set up, and each VMware ESXi\u2122 server is configured with the NSX components.\n\nAn VMware NSX Edge\u2122 Services Gateway is also deployed to be used by your workload VM or VMs.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_networkingonvcenterserver"}, {"document_id": "ibmcld_07578-1007575-1009533", "score": 27.87481244976642, "text": "\nset security firewall name TO_INTERNET rule 10 source address '150.1.2.3'\nset security firewall name TO_INTERNET rule 10 state 'enable'\nset security firewall name TO_INTERNET rule 20 action accept\nset security firewall name TO_INTERNET rule 20 description 'Accept VRA traffic to Internet'\nset security firewall name TO_INTERNET rule 20 source address '150.1.2.5'\nset security firewall name TO_INTERNET rule 20 state 'enable'\n\nThe combination of Source NAT and firewall achieves the required design goal.\n\nEnsure that the rules are appropriate for your design, and that no other rules allow traffic that should be blocked.\n* How do I protect the VRA itself with a zone-based firewall?\n\nThe VRA does not have a local zone. You can use the Control Plane Policing (CPP) functionality instead as it is applied as a local firewall on loopback.\n\nThis is a stateless firewall and you must explicitly allow the returning traffic of outbound sessions that originate on the VRA itself.\n* How do I restrict SSH and block connections that come from the internet?\n\nIt is considered a best practice to not allow SSH connections from the internet, and to use another means of accessing the private address, such as SSL VPN.\n\nBy default, the VRA accepts SSH on all interfaces. To listen only for SSH connections on the private interface, you must set the following configuration:\n\nset service ssh listen-address '10.1.2.3'\n\nKeep in mind that you must replace the IP address with the address that belongs to the VRA.\n\n\n\nPlatform Building infrastructure\n\n\n\n* What is the RMM server?\n\nRackWare Management Module (RMM) server is a software appliance that is offered by RackWare that replatforms your server from a VMware (on-premises or classic) to an IBM Cloud VPC virtual server instance.\n* Where can I find more information about the RMM server?\n\nFor RMM server overview information, see [RackWare's Cloud Migration](https://www.rackwareinc.com/cloud-migration) documentation.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06160-11142-12906", "score": 38.92533887991043, "text": "\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_10596-11475-13230", "score": 38.92533887991043, "text": "\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_10596-5350-7330", "score": 31.80180814234653, "text": "\nIf the previous steps do not solve the issue, [reload](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_06160-5357-7356", "score": 31.64824935779805, "text": "\nIf the previous steps do not solve the issue, [reload](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\nIf some, but not all, of your worker nodes frequently enter a Critical or NotReady state, consider enabling [worker autorecovery](https://cloud.ibm.com/docs/containers?topic=containers-health-monitorautorecovery) to automate these recovery steps.\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_06160-12611-14167", "score": 30.533249483939585, "text": "\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\nkubectl describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https://cloud.ibm.com/docs/containers?topic=containers-debug-tool) . Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.\n\nkubectl get mutatingwebhookconfigurations\n\nkubectl get validatingwebhookconfigurations\n4.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_10596-12943-14509", "score": 30.000462223815408, "text": "\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\noc describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https://cloud.ibm.com/docs/containers?topic=containers-debug-tool) and the [Openshift Diagnostics and Debug Tool](https://cloud.ibm.com/docs/openshift?topic=openshift-debug-tool). Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_10596-9883-11854", "score": 29.545833231675584, "text": "\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_05713-581893-583377", "score": 29.018088692431803, "text": "\n* [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https://cloud.ibm.com/docs/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https://cloud.ibm.com/docs/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https://cloud.ibm.com/docs/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https://cloud.ibm.com/docs/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_sitemap"}, {"document_id": "ibmcld_10534-545406-546780", "score": 28.98844197595087, "text": "\n* [If all worker nodes in a single zone, subnet, or VLAN are affected](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-zone)\n* [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https://cloud.ibm.com/docs/openshift?topic=openshift-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https://cloud.ibm.com/docs/openshift?topic=openshift-bm_machine_idbm_machine_id)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_06160-10037-11653", "score": 28.980267364177156, "text": "\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07498-0-1649", "score": 22.061718542252677, "text": "\n\n\n\n\n\n\n  Enterprise account architecture \n\nLarge enterprises that allow an account structure, cross account networking, resource deployment, and billing to develop organically run the risk of encountering governance, scaling, security, and accounting issues. This document provides a recommendation for how to address these concerns across accounts so that a robust, compliant, and scalable solution can be achieved.\n\nThis recommendation extends and compliments the account and resource level guidance that is found in the [IBM Cloud Framework for Financial Services](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-about) and other IBM Cloud best practices such as:\n\n\n\n*  [Cloud best practices for IT executives](https://www.ibm.com/downloads/cas/NYWPPW6K)\n*  [Best practices for setting up an enterprise](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-best-practices)\n*  [Best practices for organizing resources and assigning access](https://cloud.ibm.com/docs/account?topic=account-account_setup)\n*  [Best practices for organizing users, teams, and applications](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applications)\n*  [Best practices for working with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-best-practices)\n*  [Best practices for billing and usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-best-practices)\n*  [Advanced networking for IBM Cloud VPC](https://www.ibm.com/cloud/architecture/content/course/advanced-networking-for-vpc)\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/enterprise-account-architecture?topic=enterprise-account-architecture-about"}, {"document_id": "ibmcld_14774-18795-21198", "score": 21.494541353273842, "text": "\nWhile this design has only one backup server instance, it is recommended to deploy Enterprise Manager when encryption is used for backup or backup copy jobs. It is advised to install the Enterprise Manager server on the recovery site so it is available for disaster recovery.\n* Proxy server - This proxy is used for management components that are located in the recovery region.\n* Repository - A location used to store backup files for the management components in the recovery region and also the target for backup copy jobs from the protected region.\n* SFTP/SMB server - These servers are not Veeam services but native Windows services that are used for file-level backups of some of the management components. A Veeam file copy job copies files to the protected region for extra protection.\n\n\n\nReview the following Veeam design decisions:\n\n\n\n* For optimal performance and availability, placing the Veeam components on separate virtual and physical servers is considered best practice. However, this practice increases complexity in smaller environments. Therefore, the all-in-one deployment scenario for use case 1 is selected.\n* As the total number of protected VMs is low, the embedded database option for the database for use case 1 is selected.\n* The bare metal servers with direct attached storage option are used as it provides a backup infrastructure that is separated from the virtualized infrastructure compute and storage.\n* In a two-site environment, it is best practice to install the Veeam Backup server component in the DR site. In a disaster situation, Veeam Backup server is available to start the recovery.\n* Deploy Enterprise Manager to use password loss protection. Enterprise Manager administrators can unlock backup files by using a challenge-response mechanism.\n* It is recommended that the proxy is as close as possible to the source data with a high-bandwidth connection. The traffic from the source to the proxy is not yet optimized, meaning that 100% of the backup data is transferred over this link. A good connection is required between proxy and repository as optimized data (normally 50% of the source data size) is transferred across this link. Therefore, place proxies in both the protected and recovery regions.\n* Proxies can be hosted on Windows Server or Linux OS with almost no performance differences. For the all-in-one deployment scenario, a Windows OS is used.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vrw-dualregion-design"}, {"document_id": "ibmcld_04113-7-2190", "score": 21.394036455526194, "text": "\nBest practices for CIS setup \n\nBecause IBM Cloud\u00ae Internet Services is positioned at the edge of your network, you\u2019ll need to take a few steps to guarantee a smooth integration with your CIS services. Here are some recommended best practices for integrating CIS with your origin servers.\n\nYou can do these steps either before or after you change your DNS and activate our proxy service. These recommendations allow CIS to connect to your origin servers properly. They\u2019ll help you prevent any issues with API or HTTPS traffic, and help your logs capture the correct IP addresses of your customers, rather than the protective CIS IP addresses.\n\nHere\u2019s what you\u2019ll need to set up:\n\n\n\n* Restore the originating IPs of your customers\n* Incorporate CIS IP addresses\n* Make sure your security settings don't interfere with API traffic\n* Configure your security settings as strictly as possible\n\n\n\n\n\n Best practice 1: Know how to restore the originating IPs of your customers \n\nAs a reverse proxy, CIS provides the origination IP in these headers:\n\n\n\n* CF-Connecting-IP\n* X-Forwarded-For\n* True-Client-IP (optional)\n\n\n\nYou can restore user IP addresses using a variety of tools, for infrastructures such as Apache, Windows IIS, and NGINX.\n\n\n\n\n\n Best practice 2: Incorporate CIS IP addresses to make integration smoother \n\nHere are the two steps to take:\n\n\n\n* Remove any rate limiting of CIS IP addresses\n* Set up your ACLs to allow only CIS IP addresses and other trusted parties\n\n\n\nYou can find the updated list of IP ranges for IBM CIS [at this location](https://cloud.ibm.com/docs/cis?topic=cis-cis-allowlisted-ip-addresses).\n\n\n\n\n\n Best practice 3: Review your security settings to make sure they don\u2019t interfere with API traffic \n\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-best-practices-for-cis-setup"}, {"document_id": "ibmcld_04178-7-2164", "score": 20.900713452309684, "text": "\nManaging your CIS deployment for best performance \n\nIBM Cloud\u00ae Internet Services (CIS) can provide the fastest experience for your customers because it optimizes your images, and it stores your web content as near as possible to your end-users. Your content is loaded from proxied edge servers (which reduces latency).\n\nWith CIS, you can enhance your site's performance further by using best practices to speed up the loading of your web content. Here are some specific best practices for enhancing the performance of your web content within CIS.\n\nRecommended and best practices:\n\n\n\n* Cache as much of your static and semi-static web content as possible\n* For event-driven content, purge your cache using the API\n\n\n\n\n\n Best practice 1: Cache as much static and semi-static content as possible \n\n\n\n* Enable Cache Everything for static HTML web pages\n* Use conservative Time-to-live (TTL) for your content that changes occasionally\n\n\n\n\n\n Utilize conservative TTLs (Time-to-Lives) for content that changes occasionally \n\nIf content rarely changes, you can set a conservative TTL to utilize our cache as much as possible. If you have a high percentage of re-validation requests, you could increase the TTLs of your content without negatively affecting your customers. By using the cache more effectively, you'll increase performance because you'll revalidate less often.\n\n\n\n\n\n How do I tell if items are being cached? \n\nCIS adds the response header CF-Cache-Status when it attempts to cache an object. If caching is successful, the value of this header indicates its status with one of these keywords:\n\n\n\n* MISS: The asset was not yet in the cache or the TTL had expired (that is, it had reached the cache-control maximum age of 0).\n* HIT: The asset was delivered from the cache.\n* EXPIRED: This asset was delivered from cache, but the next request requires revalidation.\n* REVALIDATED: The asset was delivered from cache. The TTL was expired, but an If-Modified-Since request to the origin indicated that the asset had not changed. Therefore, the version in cache is considered valid again.\n\n\n\n\n\n\n\n\n\n Best practice 2: For event-driven content, purge your cache", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-manage-your-cis-deployment-for-best-performance"}, {"document_id": "ibmcld_07984-3902-5502", "score": 20.37285851933801, "text": "\nDesign your application for high availability (recommended)](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-high-availability)\n* [14. Use endpoint detection and remediation (EDR) tooling to detect malicious code](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-endpoint-detection-remediation)\n* [15. Regularly scan for open ports / protocols](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-network-threat-detection)\n* [16. Secure and manage secrets and certificates](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-secrets-management)\n* [17. Tag all IBM Cloud resources with security attributes](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-security-attributes)\n* [18. Monitor for security and compliance against a baseline configuration](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-security-compliance-monitoring)\n* [Next steps](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-next-steps)\n\n\n\n[Best practices and requirements for software](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practices-softwarebest-practices-software)\n\n\n\n* [1.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-sitemap"}, {"document_id": "ibmcld_07984-2706-4346", "score": 19.889848466053532, "text": "\nEnsure all operator actions are executed through a bastion host](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-bastion-host)\n* [8. Capture audit events and forward to a SIEM](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-audit-logs)\n* [9. Ensure operational logging and monitoring is implemented](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-operational-logging-and-monitoring)\n* [10. Follow secure development processes and ensure software integrity](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-development-processes)\n* [11. Encrypt consumer data at rest and in transit](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-encryption)\n* [12. Implement business continuity and disaster recovery](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-bcdr)\n* [13. Design your application for high availability (recommended)](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-high-availability)\n* [14. Use endpoint detection and remediation (EDR) tooling to detect malicious code](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-endpoint-detection-remediation)\n* [15.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-sitemap"}, {"document_id": "ibmcld_14375-6433-7293", "score": 19.21852281391903, "text": "\nIt is a security best practice to replace user-facing certificates with certificates that are signed by a third-party or enterprise certificate authority (CA). Certificates for machine-to-machine communication can remain as VMCA\u2013signed certificates. However, it is recommended that you follow best practices for your organization, which typically involve the use of an identified enterprise CA.\n\nYou can use the Windows AD servers within this design to create certificates that are signed by the local instance. However, you can also choose to configure CA services if needed.\n\n\n\n\n\n Related links \n\n\n\n* [Physical infrastructure design](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-design_physicalinfrastructure)\n* [Virtual infrastructure design](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-design_virtualinfrastructure)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-design_commonservice"}, {"document_id": "ibmcld_12453-9092-11379", "score": 19.209784959785104, "text": "\nWhen you update a root CA certificate, the change impacts your entire public-key infrastructure. To minimize impact, it is recommended that you set a long validity period for your root CA certificate. In Secrets Manager, the default TTL for root certificates is 10 years.\n\n\n\n\n\n\n\n Choosing an algorithm for generating keys \n\nBefore you create a certificate authority in Secrets Manager, you must choose a key algorithm for generating the public and private keys for your CA. The public and private key-pair is used to authenticate an SSL/TLS connection. If you're not sure where to start, you can use the following suggested guide for selecting a key algorithm.\n\n\n\n1. Choose an algorithm family.\n\nThe key algorithm that you select determines the encryption algorithm and key size to use to generate keys and sign certificates. As a best practice, use the same algorithm family for all certificates that belong to a certificate chain. Secrets Manager supports the following families of algorithms.\n\n\n\nTable 2. Supported algorithm families and key sizes\n\n Algorithm family Description Supported key sizes \n\n RSA Widely used and compatible with most browsers and servers, RSA is the industry standard for public-key cryptography. 2048 bits <br>4096 bits \n Elliptic curve (EC) Generates stronger keys and smaller certificates. For example, a 256-bit EC key is equivalent in encryption strength to a 3072-bit RSA key. 224 bits <br>256 bits <br>384 bits <br>521 bits \n\n\n\n2. Choose a key size.\n\nThe key size or length that you select determines the encryption strength. The larger the key size for an algorithm family, the more difficult it is to break. Keep in mind that longer key lengths results in more data to store and transmit, which can impact the performance of your certificate. As a best practice, choose a key size that is appropriate for the TTL or validity period of your certificate.\n\nFor longer living certificates, it is recommended to use longer key lengths to provide more encryption protection.\n\n\n\n\n\n\n\n\n\n Using certificate authority unauthenticated endpoints \n\nIf you're using leaf certificates that are issued by a CA in Secrets Manager for your applications, use the following API calls to gain access to the issuing CA Certificate Revocation List (CRL) and CA certificate.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-prepare-create-certificates"}, {"document_id": "ibmcld_03836-0-316", "score": 18.941914470452957, "text": "\n\n\n\n\n\n\n  Best practices for application development \n\nInformation previously contained on this page has been refreshed and merged into the [Creating Applications tutorial](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-app). For the most up to date recommendations, refer to that tutorial.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-best-practices-app"}, {"document_id": "ibmcld_09109-8993-10845", "score": 18.668046841936643, "text": "\nTo encode your key material, first you should download and install [OpenSSL](https://github.com/openssl/opensslfor-production-use).\n\nOnce OpenSSL has been downloaded and installed, there are two recommended commands for encoding the key material. Both methods are equivalent, in that they convert a string , whether <key_material_string> or , as you can see below, into a base64 string. If your material is in a file (for example, you might have a file with credentials, not just an encrypted key, that you want to store in Key Protect), the best option is to issue:\n\n {: pre}\nopenssl base64 -in <infile> -out <outfile>\n\nReplace the variables in the example request according to the following table.\n\n\n\nTable 2. Describes the variables that are needed to base64-encode your key material.\n\n Variable Description \n\n infile The name of the binary file where your key material string resides. <br> <br>Ensure that the file is not larger than 7,500 bytes. \n outfile The name of the file where your base64-encoded key material will be created once the command has run. \n\n\n\nIf you want to output the base64 material in the command line directly rather than a file, run the command openssl enc -base64 <<< '<key_material_string>', where key_material_string is the key material input for your imported key.\n\nIf you want to base 64 encode key material which is not in a file, you can issue:\n\n {: pre}\necho -n <password> | base64\n\nWhere \"password\" is the key material you want to use.\n\nTo avoid extra characters, for example an extra new line, it is a best practice to copy the base64 to the clipboard, especially when the base64 string is going to be posted in the console.\n\n\n\n\n\n Using OpenSSL to create and encode new key material \n\nUse this process to create a random base64-encoded key material with a specific byte length. 32 bytes (256 bits) is recommended.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-import-standard-keys"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07765-0-1628", "score": 23.95166653743482, "text": "\n\n\n\n\n\n\n  IA-5 (4) - Automated Support for Password Strength Determination \n\n\n\n  Control requirements \n\nIA-5 (4) - 0\n:   The organization employs automated tools to determine if password authenticators are sufficiently strong to satisfy [Assignment: organization-defined requirements].\n\n\n\n\n\n  IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\n\n\n*  Check whether App ID advanced password policies are enabled\n*  IBMid employs automated tools to determine if password authenticators satisfy IBMid password requirements\n*  Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n*  Check whether App ID password strength regex is configured\n*  Check whether IBMid password policy policy contains spaces or any of the following characters: ;:(\"?)<>\n*  Check whether VPN for VPC authentication is configured with a strong pre-shared key with at least # characters\n*  Check whether IBMid password policy requires at least one uppercase letter\n*  Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nThis control enhancement focuses on the creation of strong passwords and the characteristics of such passwords (e.g., complexity) prior to use, the enforcement of which is carried out by organizational information systems in IA-5 (1).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ia-5.4"}, {"document_id": "ibmcld_07787-0-1608", "score": 19.227157600569225, "text": "\n\n\n\n\n\n\n  MA-4 - Nonlocal Maintenance \n\n\n\n  Control requirements \n\nThe organization:\n\nMA-4 (a)\n:   Approves and monitors nonlocal maintenance and diagnostic activities;\n\nMA-4 (b)\n:   Allows the use of nonlocal maintenance and diagnostic tools only as consistent with organizational policy and documented in the security plan for the information system;\n\nMA-4 (c)\n:   Employs strong authenticators in the establishment of nonlocal maintenance and diagnostic sessions;\n\nMA-4 (d)\n:   Maintains records for nonlocal maintenance and diagnostic activities; and\n\nMA-4 (e)\n:   Terminates session and network connections when nonlocal maintenance is completed.\n\n\n\n\n\n  NIST supplemental guidance \n\nNonlocal maintenance and diagnostic activities are those activities conducted by individuals communicating through a network, either an external network (e.g., the Internet) or an internal network. Local maintenance and diagnostic activities are those activities carried out by individuals physically present at the information system or information system component and not communicating across a network connection. Authentication techniques used in the establishment of nonlocal maintenance and diagnostic sessions reflect the network access requirements in IA-2. Typically, strong authentication requires authenticators that are resistant to replay attacks and employ multifactor authentication. Strong authenticators include, for example, PKI where certificates are stored on a token protected by a password, passphrase, or biometric. Enforcing requirements in MA-4 is accomplished in part by other controls.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ma-4"}, {"document_id": "ibmcld_02746-7-1681", "score": 17.923965821769407, "text": "\nDefining password policies \n\nPassword policies, such as strength requirements, help you to enforce more secure applications. By defining advanced policies, you can define the rules that a user must conform to when they set their password or attempt to sign in to your app. For example, you can set the number of times that a user can try to sign in before they are locked out of their account.\n\n\n\n Policy: password strength \n\nA strong password makes it difficult, or even improbable for someone to guess the password in either a manual or automated way. To set requirements for the strength of a user's password, you can use the following steps.\n\nTo set this configuration by using the GUI:\n\n\n\n1. Go to the Cloud Directory > Password policies tab of the App ID dashboard.\n2. In the Define password strength box, click Edit. A screen opens.\n3. Enter a valid regex string in the Password strength box.\n\nExamples:\n\n\n\n* Must be at least 8 characters. (^.{8,}$)\n* Must have one number, one lowercase letter, and one capital letter. (^(?:(?=.d)(?=.[a-z])(?=.[A-Z]).)$)\n* Must have only English letters and numbers. (^[A-Za-z0-9]$)\n* Must have at least one unique character. (^(w)w?(?!1)w+$)\n\n\n\n4. Click Save.\n\n\n\nPassword strength can be set in the Cloud Directory settings page in the App ID dashboard, or by using [the management APIs](https://us-south.appid.cloud.ibm.com/swagger-ui//Management%20API%20-%20Config/mgmt.set_cloud_directory_password_regex).\n\n\n\n Setting a custom error message \n\nIf you set your own password regex policy and a user chooses a password that does not meet your requirements, the default message is The password doesn't meet the strength requirements.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-cd-strength"}, {"document_id": "ibmcld_00708-54925-56282", "score": 17.771681692035198, "text": "\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"}, {"document_id": "ibmcld_00684-54925-56282", "score": 17.771681692035198, "text": "\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"}, {"document_id": "ibmcld_04341-54906-56263", "score": 17.771681692035198, "text": "\nrule-e76a3a81-b0d0-41fc-947d-13dc9cfff379 - Check whether IBMid password policy prevents password reuse below the minimum of \nrule-759d504b-9eed-4602-8b5b-7244bf3f5690 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\nrule-bcbd57e1-3cdc-4b6d-820b-2c63bc777e19 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"?)<>\nrule-fa06f6f2-b98e-49ac-aa55-d57de9e320d3 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\nrule-548a3321-6a39-400c-9c2d-0df9a13afd02 - Check whether IAM roles are used to create IAM policies for IBM resources\nrule-726ec899-505e-4de9-ac1b-9578ef62f89f - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\nrule-962e2bde-2a4f-4e07-a352-ce17708b1e85 - Check whether API keys are not created in IAM during the initial setup of IAM users\nrule-61fa114a-2bb9-43fd-8068-b873b48bdf79 - Check whether IAM users are attached to at least one access group\nrule-4d86c074-097e-4ff3-a763-ccff128388e2 - Check whether multifactor authentication (MFA) is enabled at the account level\nrule-0704e840-e443-4781-b9be-ec57469d09c1 - Check whether permissions for API key creation are limited and configured in IAM settings for the account owner", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cra-cli-plugin"}, {"document_id": "ibmcld_00708-32460-34303", "score": 17.119424720821932, "text": "\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"}, {"document_id": "ibmcld_00684-32460-34303", "score": 17.119424720821932, "text": "\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"}, {"document_id": "ibmcld_04341-32441-34284", "score": 17.119424720821932, "text": "\n\"no_pre_shared_key_characters\": 30,\n\"dns_port\": 60,\n\"vm_nic_count\": 1,\n\"no_of_admins_for_container_registry \": 3,\n\"no_of_service_id_admins_for_container_registry\": 3,\n\"no_of_managers_for_container_registry\": 0,\n\"no_of_service_id_managers_for_container_registry\": 0,\n\"access_tokens_expire\": 120\n}\n}\nShow more\n\n\n\n\n\n\n\n Security and Compliance Center goals \n\nThe Terraform Analyzer supports the following Security and Compliance Center goals:\n\n3000001 - Check whether IBMid password policy requires at least one uppercase letter\n3000002 - Check whether IBMid password policy requires at least one lowercase letter\n3000003 - Check whether IBMid password policy requires at least one number\n3000004 - Check whether IBMid password policy requires minimum length of 12 characters\n3000005 - Check whether IBMid password policy prevents password reuse below the minimum of \n3000006 - Check whether IBMid password may contain only printable ASCII characters (in the range 33 - 126)\n3000007 - Check whether IBMid password policy contains spaces or any of the following characters: ;:(\"\"?)<>\"\n3000008 - Check whether IBMid uses a password meter that coaches users to create strong passwords that exceed the minimum requirements\n3000009 - Check whether IAM roles are used to create IAM policies for IBM resources\n3000010 - Check whether a support role has been assigned in IAM to manage cases in the IBM Cloud Support Center\n3000011 - Check whether API keys are not created in IAM during the initial setup of IAM users\n3000015 - Check whether IAM users are attached to at least one access group\n3000016 - Check whether IAM policies for users are attached only to groups or roles\n3000030 - Check whether IAM policies for service IDs are attached only to groups or roles\n3000017 - Check whether multifactor authentication (MFA) is enabled at the account level", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cra-cli-plugin"}, {"document_id": "ibmcld_03638-1509-3624", "score": 16.78743862012598, "text": "\nYou can record these details for both an individual device and for all devices associated with your account:\n\n\n\n* View individual device IPs from the Device List.\n* View individual device root passwords in the Snapshot View for the device.\n* View multiple device IPs by using the Download CSV option from the Device List. Then, select Download CSV from the Settings cog to download a full list of devices and details in spreadsheet format.\n\n\n\n4. Update the credentials for operating systems and other software. All of the software that was loaded onto your device during the provisioning process was assigned temporary credentials. You can view and manage these credentials on the Passwords tab of each device in the IBM Cloud\u00ae console. Use these temporary credentials to access your software for the first time. Then, change the password to your software by following strong password practices. Create a password that consists of a combination of letters, numbers, and symbols. Optionally, you can store password updates on the Passwords tab for each device. However, when you store passwords, any person with access to the account and appropriate permissions can view the passwords that are stored on the Passwords screen.\n5. Access your server on the private network. You can use the IBM Cloud infrastructure private network to interact with your devices through remote desktop (RDP) by using SSH and KVM over IP. You can use the VPN Access tool for private network connection to either the closest SSL VPN endpoint or to the endpoint of your choice. VPN access is also required to interact with several services. To access the private network, edit the user\u2019s VPN access from the User List. To access the User List, click Account > Users > User list. Use the [Virtual Private Network](https://www.ibm.com/cloud/vpn-access) page to connect to one of the various VPN options.\n6. After you have your infrastructure and environments up and running, you are ready to set up your monitoring service. IBM Cloud Monitoring gives you insight into the performance and health of your applications, services, and platforms.", "title": "", "source": "https://cloud.ibm.com/docs/bare-metal?topic=bare-metal-bm-set-up"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03113-4-2033", "score": 18.74190943460981, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Modifying a dialog using the API \n\nThe Watson Assistant REST API supports modifying your dialog programmatically, without using the Watson Assistant tool. You can use the /dialog_nodes API to create, delete, or modify dialog nodes.\n\nRemember that the dialog is a tree of interconnected nodes, and that it must conform to certain rules in order to be valid. This means that any change you make to a dialog node might have cascading effects on other nodes, or on the structure of your dialog. Before using the /dialog_nodes API to modify your dialog, make sure you understand how your changes will affect the rest of the dialog. You can make a backup copy of the current dialog by exporting the conversational skill in which it resides. See [Downloading a skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-tasksskill-tasks-download) for details.\n\nA valid dialog always satisfies the following criteria:\n\n\n\n* Each dialog node has a unique ID (the dialog_node property).\n* A child node is aware of its parent node (the parent property). However, a parent node is not aware of its children.\n* A node is aware of its immediate previous sibling, if any (the previous_sibling property). This means that all siblings that share the same parent form a linked list, with each node pointing to the previous node.\n* Only one child of a given parent can be the first sibling (meaning that its previous_sibling is null).\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-modify"}, {"document_id": "ibmcld_03270-3352-5135", "score": 18.425391193105654, "text": "\nAdd a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\nFor more information about different service desk solutions, see the following resources:\n\n\n\n* [Adding service desk support to the web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-support"}, {"document_id": "ibmcld_03113-6206-7586", "score": 18.3185271944047, "text": "\n[Example dialog](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog_api_1.png)\n\nWe can create a new node by making a POST request to /dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n![Example dialog 2](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog_api_2.png)\n\nBecause node_8 was created without specifying a value for parent or previous_sibling, it is now the first node in the dialog. Note that in addition to creating node_8, the service also modified node_1 so that its previous_sibling property points to the new node.\n\nYou can create a node somewhere else in the dialog by specifying the parent and previous sibling:\n\n{\n\"dialog_node\": \"node_9\",\n\"parent\": \"node_2\",\n\"previous_sibling\": \"node_5\"\n}\n\nThe values you specify for parent and previous_node must be valid:\n\n\n\n* Both values must refer to existing nodes.\n* The specified parent must be the same as the parent of the previous sibling (or null, if the previous sibling has no parent).\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog_api_3.png)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-modify"}, {"document_id": "ibmcld_03113-4996-6502", "score": 18.189460899977867, "text": "\n[UI location where the code that is triggered by named event handlers is authored](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/api-event-handlers.png)\n* A node of type event_handler with an event_name of generic can have a parent of type slot or frame.\n* A node of type event_handler with an event_name of focus, input, filled, or nomatch must have a parent of type slot.\n* If more than one event_handler with the same event_name is associated with the same parent node, then the order of the siblings reflects the order in which the event handlers will be executed.\n* For event_handler nodes with the same parent slot node, the order of execution is the same regardless of the placement of the node definitions. The events are triggered in this order by event_name:\n\n\n\n1. focus\n2. input\n3. filled\n4. generic*\n5. nomatch\n\n\n\n*If an event_handler with the event_name generic is defined for this slot or for the parent frame, then it is executed between the filled and nomatch event_handler nodes.\n\n\n\nThe following examples show how various modifications might cause cascading changes.\n\n\n\n Creating a node \n\nConsider the following simple dialog tree:\n\n![Example dialog](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog_api_1.png)\n\nWe can create a new node by making a POST request to /dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-modify"}, {"document_id": "ibmcld_03273-11911-13556", "score": 17.984117271652746, "text": "\n[More icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png) icon on the folder, and then select Add node to folder.\n\nThe dialog node is added to the end of the dialog tree within the folder.\n\n\n\n\n\n\n\n\n\n Deleting a folder \n\nYou can delete either a folder alone or the folder and all of the dialog nodes in it.\n\nTo delete a folder, complete the following steps:\n\n\n\n1. From the tree view of the Dialog tab, find the folder that you want to delete.\n2. Click the More![More icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png) icon on the folder, and then select Delete.\n3. Do one of the following things:\n\n\n\n* To delete the folder only, and keep the dialog nodes that are in the folder, deselect the Delete the nodes inside the folder checkbox, and then click Yes, delete it.\n* To delete the folder and all of the dialog nodes in it, click Yes, delete it.\n\n\n\n\n\nIf you deleted the folder only, then the nodes that were in the folder are displayed in the dialog tree in the spot where the folder used to be.\n\n\n\n\n\n\n\n Dialog node limits \n\nThe number of dialog nodes you can create per skill depends on your plan type.\n\n\n\nPlan details\n\n Plan Dialog nodes per skill \n\n Enterprise 100,000 \n Premium (legacy) 100,000 \n Plus 100,000 \n Trial 25,000 \n Lite 25,000 \n\n\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\n\n\n\n\n Finding a dialog node by its node ID", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-tasks"}, {"document_id": "ibmcld_03113-7328-8943", "score": 17.96490500342041, "text": "\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog_api_3.png)\n\nIn addition to creating node_9, the service automatically updates the previous_sibling property of node_6 so that it points to the new node.\n\n\n\n\n\n Moving a node to a different parent \n\nLet's move node_5 to a different parent by using the POST /dialog_nodes/node_5 method with the following body:\n\n{\n\"parent\": \"node_1\"\n}\n\nThe specified value for parent must be valid:\n\n\n\n* It must refer to an existing node.\n* It must not refer to the node being modified (a node cannot be its own parent).\n* It must not refer to a descendant of the node being modified.\n* It must not refer to a node of type response_condition or event_handler.\n\n\n\nThis results in the following changed structure:\n\n![Example dialog 4](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog_api_4.png)\n\nSeveral things have happened here:\n\n\n\n* When node_5 moved to its new parent, node_7 went with it (because the parent value for node_7 did not change). When you move a node, all descendants of that node stay with it.\n* Because we did not specify a previous_sibling value for node_5, it is now the first sibling under node_1.\n* The previous_sibling property of node_4 was updated to node_5.\n* The previous_sibling property of node_9 was updated to null, because it is now the first sibling under node_2.\n\n\n\n\n\n\n\n Resequencing siblings", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-modify"}, {"document_id": "ibmcld_02952-1632-3754", "score": 17.87912643605398, "text": "\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-support"}, {"document_id": "ibmcld_02952-3289-5462", "score": 17.723510696705596, "text": "\nAdd meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\n\n\n\n\n Measuring containment \n\nFrom the Analytics page, you can measure conversation containment. Containment is the rate at which your assistant is able to satisfy a customer's request without human intervention per conversation.\n\nTo measure containment accurately, the metric must be able to identify when a human intervention occurs. The metric primarily uses the Connect to human agent response type as an indicator. If a user conversation log includes a call to a Connect to human agent response type, then the conversation is considered to be not contained.\n\nHowever, not all human interventions are transacted by using a Connect to human agent response type. If you use an alternate method to deliver additional support, you must take additional steps to register the fact that the customer's need was not fulfilled by the assistant. For example, you might direct customers to your call center phone number or to an online support ticket form URL.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-support"}, {"document_id": "ibmcld_02882-27313-29495", "score": 17.677784823696964, "text": "\nThis response type only returns a valid response if the assistant to which you added this dialog skill also has a search skill associated with it.\n\n\n\n2. Click Add response to add another response type to the current response.\n\nYou might want to add multiple response types to a single response to provide a richer answer to a user query. For example, if a user asks for store locations, you could show a map and display a button for each store location that the user can click to get address details. To build that type of response, you can use a combination of image, options, and text response types. Another example is using a text response type before a pause response type so you can warn users before pausing the dialog.\n\nYou cannot add more than 5 response types to a single response. Meaning, if you define three conditional responses for a dialog node, each conditional response can have no more than 5 response types added to it.\n\nA single dialog node cannot have more than one Connect to human agent or more than one Search skill response.\n3. If you added more than one response type, you can click the Move up or down arrows to arrange the response types in the order you want your assistant to process them.\n\n\n\n\n\n\n\n\n\n Conditional responses \n\nA single dialog node can provide different responses, each one triggered by a different condition. Use this approach to address multiple scenarios in a single node.\n\nThe node still has a main condition, which is the condition for using the node and processing the conditions and responses that it contains.\n\nIn this example, your assistant uses information that it collected earlier about the user's location to tailor its response, and provide information about the store nearest the user. See [Context variables](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables) for more information about how to store information collected from the user.\n\n![Shows a node that shows a user ask, Where are you located, and the dialog has three different responses depending on conditions that use info from the $state context variable to specify locations in those states.]", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overview"}, {"document_id": "ibmcld_03188-1732-3801", "score": 17.65148036410876, "text": "\n* To add an entire dialog branch that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.chat, to the If assistant recognizes field of the dialog root node.\n* To add a single dialog node that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.zendesk, to the If assistant recognizes field of the dialog child node.\n* To add slightly different responses for a single dialog node based on the integration type, complete the following steps:\n\n\n\n* From the node's edit view, click Customize and then set the Multiple conditioned responses switch to On. Click Apply.\n* In the dialog node response section, add the appropriate condition and corresponding response for each custom response type.\n\n\n\nThe following examples show how to specify a hypertext link in the best format for the integration where the text response will be displayed. For the Web chat integration, which supports Markdown formatting, you can include a link label in the response text to make the response look nicer. For the SMS with Twilio integration, you can skip the formatting that makes sense in a web page, and add the straight URL.\n\n\n\nCustom conditioned responses\n\n Integration type Condition Sample text response \n\n SMS with Twilio `$integrations.text_messaging` `For more information, go to https://www.ibm.com.` \n Web chat `$integrations.chat` `For more information, go to [the ibm.com site](https://www.ibm.com).` \n Response to show if no other conditions are met. `true` `For more information, go to ibm.com.` \n\n\n\n\n\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-integrations"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16024-9702-11722", "score": 14.52057857699107, "text": "\nFor more information, see [Creating Block Storage for VPC volumes with customer-managed encryption](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-vpc-encryption). \n Encryption Instance Optional. A link to the provisioned KMS instance for a customer-managed encryption volume. \n Key Optional. The name and copiable ID of the root key that is used to encrypt the passphrase, which secures a customer-managed encryption volume. \n Backup policies The number of backup policies that are associated with the volume. Click the number link to go to the backup policies tab. \n Snapshots The number of snapshots that were created of the volume. Click the number link to go to the Snapshots and Backups tab. \n Attached virtual server Volumes attached to a virtual server instance are listed here. Click Attach to select an instance to attach this volume. For more information, see [Attaching a volume to an instance](https://cloud.ibm.com/docs/vpc?topic=vpc-attaching-block-storage). \n Status Tracks the overall lifecycle state of the volume, which ranges from volume creation to volume deletion. Attachment status, for example, attached when the volume is attached to an instance and attaching when in progress. \n Name Click the name of the virtual server instance to see instance details. \n Auto delete When enabled, the volume is automatically deleted when you delete the instance. Click the toggle to enable automatic deletion. \n Backup policies Shows backup policies that are associated with this volume. To associate backup policies, you can add a backup policy's tags for target resources to this volume. Click Apply to select a backup policy, then apply its tags for the target resource to the volume. \n\n\n\nTable 4 shows Actions menu options from the volume details page.\n\n\n\nTable 4. Actions menu options one the volume details page.\n\n Action Description \n\n Create snapshot Create a snapshot from a data volume or a \"bootable snapshot\" from a boot volume. Data volumes must be attached to a virtual server instance.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-viewing-block-storage&interface=ui"}, {"document_id": "ibmcld_15007-15361-17281", "score": 14.289573156379351, "text": "\nYou can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region. You can't create a copy of the backup snapshot in the source (local) region.\n\nCreating a cross-regional copy affects billing. You're charged for the data transfer and the storage consumption in the target region separately.\n\n\n\n\n\n\n\n User roles for backup policies \n\nDepending on your assigned role as a backup user, you can create and administer backup policies. Table 1 describes these capabilities.\n\n\n\nTable 1. Backup user roles for backup policies\n\n Backup user role What you can do: \n\n Viewer, Operator <br><br> * List all backup policies.<br> * View details of a backup policy.<br> * View a backup plan.<br><br><br> \n Editor, Administrator <br><br> * Organize and manage snapshots by using tags.<br> * Associate backup policies to volumes by using user tags.<br> * Create, update, and delete backup policies and plans.<br> * Specify CRON format to schedule snapshot creation.<br><br><br> \n\n\n\n\n\nTable 2. Volume user roles for backup policies\n\n Volume user role What you can do: \n\n Editor <br><br> * Create data volumes with user tags.<br> * View volume details with user tags.<br> * List volumes filtered by tag.<br> * Update user tags post volume creation.<br><br><br> \n\n\n\n\n\nTable 3. Snapshot user roles for backup policies\n\n Snapshot user role What you can do: \n\n Editor <br><br> * Create snapshots with user tags.<br> * View snapshot details with tags.<br> * List snapshots filtered by tag.<br> * Update user tags post snapshot creation.<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about"}, {"document_id": "ibmcld_15020-15400-17320", "score": 14.289573156379351, "text": "\nYou can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region. You can't create a copy of the backup snapshot in the source (local) region.\n\nCreating a cross-regional copy affects billing. You're charged for the data transfer and the storage consumption in the target region separately.\n\n\n\n\n\n\n\n User roles for backup policies \n\nDepending on your assigned role as a backup user, you can create and administer backup policies. Table 1 describes these capabilities.\n\n\n\nTable 1. Backup user roles for backup policies\n\n Backup user role What you can do: \n\n Viewer, Operator <br><br> * List all backup policies.<br> * View details of a backup policy.<br> * View a backup plan.<br><br><br> \n Editor, Administrator <br><br> * Organize and manage snapshots by using tags.<br> * Associate backup policies to volumes by using user tags.<br> * Create, update, and delete backup policies and plans.<br> * Specify CRON format to schedule snapshot creation.<br><br><br> \n\n\n\n\n\nTable 2. Volume user roles for backup policies\n\n Volume user role What you can do: \n\n Editor <br><br> * Create data volumes with user tags.<br> * View volume details with user tags.<br> * List volumes filtered by tag.<br> * Update user tags post volume creation.<br><br><br> \n\n\n\n\n\nTable 3. Snapshot user roles for backup policies\n\n Snapshot user role What you can do: \n\n Editor <br><br> * Create snapshots with user tags.<br> * View snapshot details with tags.<br> * List snapshots filtered by tag.<br> * Update user tags post snapshot creation.<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about&interface=ui"}, {"document_id": "ibmcld_15163-28736-29823", "score": 13.558202448215939, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=terraform"}, {"document_id": "ibmcld_15164-28701-29788", "score": 13.558202448215939, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=ui"}, {"document_id": "ibmcld_15160-28636-29723", "score": 13.558202448215939, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan"}, {"document_id": "ibmcld_15162-28726-29813", "score": 13.558202448215939, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=cli"}, {"document_id": "ibmcld_15161-28756-29853", "score": 13.538278405292491, "text": "\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy with the encryption_key subproperty. See the following example.\n\nThe following example creates a backup policy in the us-south region with a copy of the backup in us-east region.\n\ncurl -X POST \"$vpc_api_endpoint/v1/backup_policies/8758bd18-344b-486a-b606-5b8cb8cdd044/plans?version=2023-05-09&generation=2\"\n-H \"Authorization: $iam_token\"\n-d '{\n\"active\": true,\n\"attach_user_tags\": [\n\"hourly-backups\"\n],\n\"copy_user_tags\": true,\n\"cron_spec\": \"0 /2 * * \",\n\"deletion_trigger\": {\n\"delete_after\": 20,\n\"delete_over_count\": 20\n},\n\"remote_region_policies\": {\n\"delete_over_count\": 5,\n\"encryption_key\": [\n{\n\"CRN\": \"crn:v1:bluemix:public:kms:us-south:a/dffc98a0f1f0f95f6613b3b752286b87:e4a29d1a-2ef0-42a6-8fd2-350deb1c647e:key:5437653b-c4b1-447f-9646-b2a2a4cd617\"\n}\n],\n\"region\": [\n{\n\"name\":\"us-east\"\n}\n]\n},\n\"name\": \"my-hourly-plan-2\"\n}'\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=api"}, {"document_id": "ibmcld_15957-7-1803", "score": 13.437015866128732, "text": "\nAvailability and Durability of VPC storage \n\nIn today's fast-paced economy, companies rely on data in their decision-making. They need secure and immediate access to their data on a moment's notice. Data integrity is of high priority because compromised or incomplete data is of no use. Not to mention the dangers that are presented if sensitive data goes missing. When you store your data in Block Storage for VPC volumes, snapshots, backups, or in File Storage for VPC shares, it's durable, highly available, and encrypted.\n\n\n\nTable 1. Block Storage for VPC Storage durability and availability chart.\n\n Block Storage for VPC Storage type Use Case Durability Availability Encryption \n\n 3 IOPS per GB tier It is designed for general-purpose workloads such as workloads that host small databases for web applications or store virtual machine disk images for a hypervisor. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption \n 5 IOPS per GB tier It is designed for high I/O intensity workloads that are characterized by a large percentage of active data, such as transactional and other performance-sensitive databases. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption \n 10 IOPS per GB tier It is designed for demanding storage workloads such as data-intensive workloads created by NoSQL databases, data processing for video, machine learning, and analytics. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption \n custom Customers can specify capacity between 10 - 16000 MB with IOPS ranging 100 - 48000. 99.999999999% <br>(11 9's) 99.999% <br>(5 9's) Provider-managed AES-256 encryption, Customer-managed encryption", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-storageavailability"}, {"document_id": "ibmcld_14984-4-2041", "score": 13.37562336846253, "text": "\n* UI\n* CLI\n* API\n* Terraform\n\n\n\n\n\n\n\n Restoring a volume from a backup snapshot \n\nRestoring from a backup snapshot creates a fully provisioned boot or data volume that you can use to boot an instance or attach as auxiliary storage. You can restore volumes during instance creation or when you want to create stand-alone boot or data volumes to be used later. You can restore a data volume to add more storage to an existing instance. You can use backup snapshots to restore volumes in a different region for business continuity purposes or geographic expansion. You can restore volumes from backup snapshots in the UI, from the CLI, with the API, or Terraform.\n\n\n\n About restoring a volume from a backup snapshot \n\nWhen you restore a volume from a backup, the service creates another volume. The restored volume inherits the same [profile](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-profiles), capacity, data, and metadata as the original volume. However, you can choose a different profile and capacity if you prefer. If the source volume used [customer-managed encryption](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-aboutvpc-customer-managed-encryption), the new volume inherits that encryption.\n\nRestoring a volume from a backup snapshot creates a boot or data volume, depending on whether the snapshot is bootable or nonbootable. The volume appears first as pending while it's being created. During the restoration, your data is copied from IBM Cloud\u00ae Object Storage to Block Storage for VPC. After the volume is hydrated (fully provisioned), you can use the new boot or data volume. For more information about how performance is affected during restoration, see [Performance impact when backup snapshots are used](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restorebaas-performance-considerations).\n\nFor best performance, use backups with fast restore. You can enable fast restore backup snapshots in multiple zones and use them to restore a volume that is fully provisioned when the volume is created.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12528-1615-3608", "score": 22.574162802976623, "text": "\n* Share to this enterprise or account groups to select the enterprise or specific account groups within the enterprise.\n* Share with other enterprises to add IDs for enterprises or account groups in other enterprises that you are assigned Editor role or higher on. This option is used to create an allowlist of other enterprises or account groups to which you want to share your product. You must have the Editor role on the enterprise or account group that you are trying to add. Select Add accounts, enter the enterprise ID, and click Add > Share.\n\n\n\nWhen you share your product with another enterprise, the enterprise is added to a list of IDs that are granted access to your product. This list is also known as the allowlist. Any account that is not included in the allowlist can't access your product.\n7. Click Share.\n\n\n\n\n\n\n\n Sharing your product by using the CLI \n\nWhen you share a product with users in your account, enterprise, or account groups, they can create instances of any version that is validated and in the ready state. Versions that are in the draft state are not shared with users.\n\nRun the [ibmcloud catalog offering publish enterprise](https://cloud.ibm.com/docs/cli?topic=cli-manage-catalogs-pluginpublish-offering-enterprise) command to share your product to your enterprise:\n\nibmcloud catalog offering publish enterprise [--catalog CATALOG]\n\nRun the [ibmcloud catalog offering publish allowlist](https://cloud.ibm.com/docs/cli?topic=cli-manage-catalogs-pluginpublish-offering-allowllist) command to share your product to an allowlisted set of accounts:\n\nibmcloud catalog offering publish allowlist [--catalog CATALOG][--account-ids ACCOUNT-IDS]\n\nThe ibmcloud catalog offering publish allowlist command shares your product with stand-alone accounts, enterprises, or account groups based on the IDs listed in the command. You must have Editor role or higher on the other enterprise or enterprise account groups that you add to the list to successfully share the product.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-catalog-enterprise-share"}, {"document_id": "ibmcld_01752-3026-4629", "score": 22.143903031302543, "text": "\nThis list is also known as the allowlist. Any account that is not included in the allowlist can't access your product.\n7. Click Share.\n\n\n\n\n\n\n\n Sharing your product by using the CLI \n\nWhen you share a product with users in your account, enterprise, or account groups, they can create instances of any version that is validated and in the ready state. Versions that are in the draft state are not shared with users.\n\nRun the [ibmcloud catalog offering publish enterprise](https://cloud.ibm.com/docs/cli?topic=cli-manage-catalogs-pluginpublish-offering-enterprise) command to share your product to your enterprise:\n\nibmcloud catalog offering publish enterprise [--catalog CATALOG]\n\nRun the [ibmcloud catalog offering publish allowlist](https://cloud.ibm.com/docs/cli?topic=cli-manage-catalogs-pluginpublish-offering-allowllist) command to share your product to an allowlisted set of accounts:\n\nibmcloud catalog offering publish allowlist [--catalog CATALOG][--account-ids ACCOUNT-IDS]\n\nThe ibmcloud catalog offering publish allowlist command shares your product with stand-alone accounts, enterprises, or account groups based on the IDs listed in the command. You must have Editor role or higher on the other enterprise or enterprise account groups that you add to the list to successfully share the product. If you add a stand-alone account that is external to your enterprise, the account is added to your allowlist, but your product isn't shared to that account until you have [publishing approval for your product](https://cloud.ibm.com/docs/sell?topic=sell-sw-publish&interface=uisw-request-approval).", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-catalog-share"}, {"document_id": "ibmcld_12528-2982-3906", "score": 21.33406917678793, "text": "\nRun the [ibmcloud catalog offering publish allowlist](https://cloud.ibm.com/docs/cli?topic=cli-manage-catalogs-pluginpublish-offering-allowllist) command to share your product to an allowlisted set of accounts:\n\nibmcloud catalog offering publish allowlist [--catalog CATALOG][--account-ids ACCOUNT-IDS]\n\nThe ibmcloud catalog offering publish allowlist command shares your product with stand-alone accounts, enterprises, or account groups based on the IDs listed in the command. You must have Editor role or higher on the other enterprise or enterprise account groups that you add to the list to successfully share the product. If you add a stand-alone account that is external to your enterprise, the account is added to your allowlist, but your product isn't shared to that account until you have [publishing approval for your product](https://cloud.ibm.com/docs/sell?topic=sell-sw-publish&interface=uisw-request-approval).", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-catalog-enterprise-share"}, {"document_id": "ibmcld_02114-40817-42812", "score": 21.31567750927959, "text": "\nTo deprecate a published product from the IBM Cloud catalog, see [ibmcloud catalog offering deprecate-offering](https://cloud.ibm.com/docs/cli?topic=cli-manage-catalogs-pluginpublish-offering-deprecate).\n\nibmcloud catalog offering delete --catalog CATALOG --offering OFFERING\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish account \n\nRun the following command to publish a product from your private catalog to an account. After the product is published, users in the account that have access to the private catalog and its containing resource group can create an instance and start using it.\n\nibmcloud catalog offering publish account [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish allowlist \n\nRun the following command to publish a product from your private catalog to a set of allowlisted accounts. After the product is published, users in the allowlisted accounts can create an instance and start using it.\n\nibmcloud catalog offering publish allowlist [--catalog CATALOG][--account-ids ACCOUNT-IDS]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--account-ids ACCOUNT-IDS\n: The account IDs.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish enterprise \n\nRun the following command to publish a product to an enterprise. After the product is published, users within the enterprise can create an instance of the product.\n\nibmcloud catalog offering publish enterprise [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering suspend-offering \n\nRun the following command to suspend a product from the catalog. You can suspend it for a short time without permanently deleting or deprecating it.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-manage-catalogs-plugin"}, {"document_id": "ibmcld_04491-40793-42788", "score": 21.31567750927959, "text": "\nTo deprecate a published product from the IBM Cloud catalog, see [ibmcloud catalog offering deprecate-offering](https://cloud.ibm.com/docs/cli?topic=cli-manage-catalogs-pluginpublish-offering-deprecate).\n\nibmcloud catalog offering delete --catalog CATALOG --offering OFFERING\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish account \n\nRun the following command to publish a product from your private catalog to an account. After the product is published, users in the account that have access to the private catalog and its containing resource group can create an instance and start using it.\n\nibmcloud catalog offering publish account [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish allowlist \n\nRun the following command to publish a product from your private catalog to a set of allowlisted accounts. After the product is published, users in the allowlisted accounts can create an instance and start using it.\n\nibmcloud catalog offering publish allowlist [--catalog CATALOG][--account-ids ACCOUNT-IDS]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--account-ids ACCOUNT-IDS\n: The account IDs.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish enterprise \n\nRun the following command to publish a product to an enterprise. After the product is published, users within the enterprise can create an instance of the product.\n\nibmcloud catalog offering publish enterprise [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering suspend-offering \n\nRun the following command to suspend a product from the catalog. You can suspend it for a short time without permanently deleting or deprecating it.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-manage-catalogs-plugin"}, {"document_id": "ibmcld_12577-40877-42872", "score": 21.31567750927959, "text": "\nTo deprecate a published product from the IBM Cloud catalog, see [ibmcloud catalog offering deprecate-offering](https://cloud.ibm.com/docs/cli?topic=cli-manage-catalogs-pluginpublish-offering-deprecate).\n\nibmcloud catalog offering delete --catalog CATALOG --offering OFFERING\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish account \n\nRun the following command to publish a product from your private catalog to an account. After the product is published, users in the account that have access to the private catalog and its containing resource group can create an instance and start using it.\n\nibmcloud catalog offering publish account [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish allowlist \n\nRun the following command to publish a product from your private catalog to a set of allowlisted accounts. After the product is published, users in the allowlisted accounts can create an instance and start using it.\n\nibmcloud catalog offering publish allowlist [--catalog CATALOG][--account-ids ACCOUNT-IDS]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--account-ids ACCOUNT-IDS\n: The account IDs.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish enterprise \n\nRun the following command to publish a product to an enterprise. After the product is published, users within the enterprise can create an instance of the product.\n\nibmcloud catalog offering publish enterprise [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering suspend-offering \n\nRun the following command to suspend a product from the catalog. You can suspend it for a short time without permanently deleting or deprecating it.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-manage-catalogs-plugin"}, {"document_id": "ibmcld_02114-46642-48711", "score": 21.259616882431118, "text": "\nRun the following command to check your working directory's Terraform modules for updates from the catalog and update the source attribute to the latest version. The README.md is also updated.\n\nibmcloud catalog utility update-module-references\n\n\n\n\n\n ibmcloud catalog offering unpublish account \n\nRun the following command to unpublish a product from your account. After the product is unpublished, users in your account cannot create an instance of the product.\n\nibmcloud catalog offering unpublish account [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering unpublish allowlist \n\nRun the following command to remove account IDs from the product's allowlist. Accounts that are removed from the allowlist cannot create an instance of the product.\n\nibmcloud catalog offering unpublish allowlist [--catalog CATALOG][--account-ids ACCOUNT-IDS]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--account-ids ACCOUNT-IDS\n: The account IDs.\n\n\n\n\n\n\n\n ibmcloud catalog offering unpublish enterprise \n\nRun the following command to unpublish a product from an enterprise. After the product is unpublished, the enterprise cannot create an instance of the product.\n\nibmcloud catalog offering unpublish enterprise [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish public \n\nRun the following command to publish your private offering to the IBM Cloud catalog for all users to see and use. To get to this step in the publication process, you must first publish the offering to your account and to all IBMers to complete the testing process. After your testing is complete, you can run this command.\n\nThis option requires approval. As soon as your approval is complete, your tile is available for all IBM Cloud customers.\n\nibmcloud catalog offering publish public [--catalog CATALOG]", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-manage-catalogs-plugin"}, {"document_id": "ibmcld_04491-46618-48687", "score": 21.259616882431118, "text": "\nRun the following command to check your working directory's Terraform modules for updates from the catalog and update the source attribute to the latest version. The README.md is also updated.\n\nibmcloud catalog utility update-module-references\n\n\n\n\n\n ibmcloud catalog offering unpublish account \n\nRun the following command to unpublish a product from your account. After the product is unpublished, users in your account cannot create an instance of the product.\n\nibmcloud catalog offering unpublish account [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering unpublish allowlist \n\nRun the following command to remove account IDs from the product's allowlist. Accounts that are removed from the allowlist cannot create an instance of the product.\n\nibmcloud catalog offering unpublish allowlist [--catalog CATALOG][--account-ids ACCOUNT-IDS]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--account-ids ACCOUNT-IDS\n: The account IDs.\n\n\n\n\n\n\n\n ibmcloud catalog offering unpublish enterprise \n\nRun the following command to unpublish a product from an enterprise. After the product is unpublished, the enterprise cannot create an instance of the product.\n\nibmcloud catalog offering unpublish enterprise [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish public \n\nRun the following command to publish your private offering to the IBM Cloud catalog for all users to see and use. To get to this step in the publication process, you must first publish the offering to your account and to all IBMers to complete the testing process. After your testing is complete, you can run this command.\n\nThis option requires approval. As soon as your approval is complete, your tile is available for all IBM Cloud customers.\n\nibmcloud catalog offering publish public [--catalog CATALOG]", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-manage-catalogs-plugin"}, {"document_id": "ibmcld_12577-46702-48771", "score": 21.259616882431118, "text": "\nRun the following command to check your working directory's Terraform modules for updates from the catalog and update the source attribute to the latest version. The README.md is also updated.\n\nibmcloud catalog utility update-module-references\n\n\n\n\n\n ibmcloud catalog offering unpublish account \n\nRun the following command to unpublish a product from your account. After the product is unpublished, users in your account cannot create an instance of the product.\n\nibmcloud catalog offering unpublish account [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering unpublish allowlist \n\nRun the following command to remove account IDs from the product's allowlist. Accounts that are removed from the allowlist cannot create an instance of the product.\n\nibmcloud catalog offering unpublish allowlist [--catalog CATALOG][--account-ids ACCOUNT-IDS]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n--account-ids ACCOUNT-IDS\n: The account IDs.\n\n\n\n\n\n\n\n ibmcloud catalog offering unpublish enterprise \n\nRun the following command to unpublish a product from an enterprise. After the product is unpublished, the enterprise cannot create an instance of the product.\n\nibmcloud catalog offering unpublish enterprise [--catalog CATALOG]\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--offering OFFERING\n: The product name or ID.\n\n\n\n\n\n\n\n ibmcloud catalog offering publish public \n\nRun the following command to publish your private offering to the IBM Cloud catalog for all users to see and use. To get to this step in the publication process, you must first publish the offering to your account and to all IBMers to complete the testing process. After your testing is complete, you can run this command.\n\nThis option requires approval. As soon as your approval is complete, your tile is available for all IBM Cloud customers.\n\nibmcloud catalog offering publish public [--catalog CATALOG]", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-manage-catalogs-plugin"}, {"document_id": "ibmcld_02379-3588-5834", "score": 20.96642626951944, "text": "\nglobalcatalog-collection.instance.read An event is generated when you view a catalog. \n globalcatalog-collection.instance.update An event is generated when you update a catalog. \n globalcatalog-collection.instances.list An event is generated when you get a list of the catalogs in an account. \n\n\n\n\n\n\n\n Events for managing products in a private catalog \n\n\n\nTable 5. Actions that generate events for products in a private catalog\n\n Action Description \n\n globalcatalog-collection.offerings.list An event is generated when you get a list of the products in a catalog. \n globalcatalog-collection.offering.read An event is generated when you view a product in a catalog. \n globalcatalog-collection.offering.create An event is generated when you create a product. \n globalcatalog-collection.offering.update An event is generated when you update a product. \n globalcatalog-collection.offering.delete An event is generated when you delete a product. \n\n\n\n\n\n\n\n Events for managing catalog settings at the account level \n\n\n\nTable 6. Actions that generate events related to catalog management settings\n\n Action Description \n\n globalcatalog-collection.account-settings.read An event is generated when you view the account settings. \n globalcatalog-collection.account-settings.update An event is generated when you update the account settings. \n\n\n\n\n\n\n\n Events for managing catalog settings in enterprise accounts \n\n\n\nTable 7. Actions that generate events related to catalog management settings in enterprise accounts\n\n Action Description \n\n globalcatalog-collection.enterprise-settings.read An event is generated when you view the enterprise settings. \n globalcatalog-collection.enterprise-settings.update An event is generated when you update the enterprise settings. \n globalcatalog-collection.enterprise-settings.list An event is generated when you get a list of the enterprises in an account and their corresponding settings. \n\n\n\n\n\n\n\n Events for managing software licenses and entitlements \n\nThe following table lists the actions that generate an event:\n\n\n\nTable 8. Actions that generate events related to licenses and entitlements\n\n Action Description \n\n entitlement.entitlement.create An event is generated when an initiator binds a license to an account.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-at_events_acc_mgt"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01377-8075-10005", "score": 21.528980918585706, "text": "\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam"}, {"document_id": "ibmcld_01387-8101-10031", "score": 21.528980918585706, "text": "\nView, inspect, pull, push, delete, and restore images.<br><br>View, add, analyze, and remove namespaces.<br><br>Assign namespaces to resource groups.<br><br>View and set quotas.<br><br>View vulnerability reports.<br><br>View and create image signatures.<br><br>Review and change pricing plans.<br><br>Enable IAM access policy enforcement.<br><br>List, add, and remove Vulnerability Advisor security issue exemption policies.<br><br>List types of security exemptions.<br><br>Set and run retention policies.<br><br>View the contents of the trash.<br><br>Restore images.<br><br>View the contents of the manifest for an image.<br><br>Prevent or allow image pulls or pushes over public network connections for your account.<br><br>Check whether the use of public connections is prevented for image pushes or pulls in your account.<br><br>Delete all untagged images in your Container Registry account. \n\n\n\nFor the following Container Registry commands, you must have at least one of the specified roles as shown in the following tables. To create a policy that allows access to Container Registry, you must create a policy where the following criteria apply.\n\n\n\n* The service name is container-registry.\n* The service instance is empty.\n* The region is the region that you want to grant access to, or is empty to give access to all regions.\n\n\n\n\n\n Access roles for configuring Container Registry \n\nTo grant a user permission to configure Container Registry in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you must not specify a resource type or resource. Policies for configuring Container Registry must not be set at a resource group level.\n\nFor example, run the following ibmcloud iam user-policy-create command. Where <user_email> is the user's email address, <region> is the region, and <roles> is the role, or roles, that you want the user to have.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam&interface=ui"}, {"document_id": "ibmcld_01377-13470-15034", "score": 20.344236677667293, "text": "\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam"}, {"document_id": "ibmcld_01387-13496-15060", "score": 20.344236677667293, "text": "\ncontainer-registry.settings.set [ibmcloud cr platform-metrics](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_platform_metrics) Update registry service settings for the targeted account, such as enabling platform metrics. Manager \n\n\n\n\n\n\n\n Access roles for using Container Registry \n\nTo grant a user permission to access Container Registry content in your account, you must create a policy that grants one or more of the roles in the following table. When you create your policy, you can restrict access to a specific namespace by specifying the resource type namespace and the namespace name as the resource. If you don't specify a resource-type and a resource, the policy grants access to all resources in the account. Alternatively, if your namespace is within a resource group, permission can be granted by using an IAM access policy on that resource group.\n\nFor example, use the following command to create a user policy. Where <user_email> is the user's email address, <region> is the region, <roles> is the role, or roles, that you want the user to have, and <namespace_name> is the name of the namespace.\n\nibmcloud iam user-policy-create <user_email> --service-name container-registry --region <region> --roles <roles> [--resource-type namespace --resource <namespace_name>]\n\nThe following table details actions that are mapped to operations on the service and to the service access roles for using Container Registry.\n\n\n\nTable 5. Service actions and operations for using Container Registry\n\n Action Operation on service Role Status", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam&interface=ui"}, {"document_id": "ibmcld_01388-10517-12258", "score": 17.580759148371218, "text": "\nList the policies for User B by running the following command.\n\nibmcloud iam user-policies <user.b@example.com>\n\nFind the policies that you created and note the Policy IDs.\n3. Delete the policies that you created by running the following command, where <Policy_ID> is the Policy ID.\n\nibmcloud iam user-policy-delete <user.b@example.com> <Policy_ID>\n\n\n\n\n\n\n\n\n\n Step 3: Create a service ID and grant access to a resource \n\nConfigure a service ID and grant it access to your IBM Cloud Container Registry namespace.\n\n\n\n1. Set up a service ID with access to IBM Cloud Container Registry and create an\n\nAPI keyfor it.\n\n\n\n1. Log in to User A's account by running the following command.\n\nibmcloud login\n2. Create a service ID named cr-roles-tutorial with the description \"Created during the access control tutorial for Container Registry\" by running the following command.\n\nibmcloud iam service-id-create cr-roles-tutorial --description \"Created during the access control tutorial for Container Registry\"\n3. Create a service policy for the service ID that grants the Reader role on namespace_a by running the following command.\n\nibmcloud iam service-policy-create cr-roles-tutorial --service-name container-registry --region <cloud_region> --resource-type namespace --resource namespace_a --roles Reader\n4. Create a second service policy that grants the Writer role on namespace_b by running the following command.\n\nibmcloud iam service-policy-create cr-roles-tutorial --service-name container-registry --region <cloud_region> --resource-type namespace --resource namespace_b --roles Writer\n5. Create an API key for the service ID by running the following command.\n\nibmcloud iam service-api-key-create cr-roles-tutorial-apikey cr-roles-tutorial\n\n\n\n2.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam_access"}, {"document_id": "ibmcld_05256-22076-24099", "score": 17.256242770857934, "text": "\nIf you have a Service ID that you want to use, select it. If not, select Create, enter a name and description, and click Create.\n4. From the Service ID page, from the Access policies section, select Assign access.\n5. From the Assign service ID additional access section,\n\n\n\n1. Select Container Registry for type of access. Click Next.\n2. Select the type of access: All resources or Specific resources. If you specify Specific resources, you can add attributes based on resource group, geography, region, resource type, resource ID, or resource name to further restrict access. If you select a certain resource group, make sure to select Viewer access for Resource group access. Click Next.\n3. In the Roles and Actions section, select the type of access you want to grant. If you plan to use only images for your applications and jobs, select Reader. If you want to push the source code and images to Container Registry, then also select Writer. Click Review.\n4. Click Add and then Assign.\n\n\n\n\n\n\n\n\n\n Step 2 Enabling Container Registry discovery \n\nTo allow the Code Engine console to automatically discover Container registry, you must authenticate the service ID to the IAM Identity Service.\n\n\n\n1. From the Service ID page, from the Access policies section, select Assign access.\n2. From the Assign service ID additional access section,\n\n\n\n1. Select IAM Identity Service for type of access. Click Next.\n2. Select Specific resources for resource scope. Select Resource type as attribute type, keep string equals as operator and enter serviceid as value. Click Add a condition.\n3. Select Resource ID as attribute type, keep string equals as operator and put the identifier of your service ID. You can find your service ID on the Details page for the service ID or in the browser URL when configuring it. Click Next.\n4. In the Roles and Actions section, select Platform Operator access. Click Review\n5. Click Add and then Assign.\n\n\n\n\n\n\n\n\n\n Step 3 Creating an API key for a service ID \n\nCreate an API key for a service ID.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-add-registry"}, {"document_id": "ibmcld_01530-1294-3025", "score": 17.241444450127627, "text": "\n* Decide on the roles that each user needs and on which resources in IBM Cloud Container Registry, see [IAM roles](https://cloud.ibm.com/docs/Registry?topic=Registry-iamiam). You can create multiple policies, for example, you can grant write access on a resource but grant read access only on another resource. Policies are additive, which means that a global read policy and a resource-scoped write policy grants both read and write access on that resource.\n* [Invite users to an account](https://cloud.ibm.com/docs/account?topic=account-iamuserinviamuserinv).\n\nIf you want users to create clusters in IBM Cloud Kubernetes Service, ensure that you assign the IBM Cloud Container Registry Administrator role to those users, and don't assign a resource group. For more information, see [Preparing to create clusters](https://cloud.ibm.com/docs/containers?topic=containers-clusterscluster_prepare).\n\n\n\nTo create policies for IBM Cloud Container Registry, the service name field must be container-registry.\n\nIf you want to access resources, you must assign roles to users or service IDs. If you want to grant access to everything, don't specify a resource type or a resource. If you want to grant access to a specific namespace, specify the resource type as namespace and use the namespace name as the resource.\n\n\n\n* To create a policy for users, see [Managing access to resources](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n* To create a policy for service IDs, run the ibmcloud iam service-policy-create command or use the IBM Cloud console to bind roles to your service IDs. To create policies, you must have the Administrator role. You automatically have the Administrator role on your own account.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-user"}, {"document_id": "ibmcld_01388-2747-4448", "score": 17.099419793685506, "text": "\nibmcloud cr quota-set --traffic=4000\n\nThe command fails because User B doesn't have the correct access.\n\n\n\n3. Grant User B the Manager role so that User B can configure IBM Cloud Container Registry.\n\n\n\n1. Log back in to your account as yourself, User A, by running the following command.\n\nibmcloud login\n2. Create a policy that grants the Manager role to User B by running the following command.\n\nibmcloud iam user-policy-create <user.b@example.com> --service-name container-registry --roles Manager\n\n\n\n4. Prove that User B can now change quotas in User A's account.\n\n\n\n1. Log in as User B, targeting User A's account by running the following command.\n\nibmcloud login -c <YourAccountID>\n2. Try to edit your registry quota to 4 GB of traffic by running the following command.\n\nibmcloud cr quota-set --traffic=4000\n\nIt works because User B has the correct type of access.\n3. Now change the quota back by running the following command.\n\nibmcloud cr quota-set --traffic=5120\n\n\n\n5. Clean up.\n\n\n\n1. Log back in to your account as yourself, User A, by running the following command.\n\nibmcloud login\n2. List the policies for User B, find the policy that you created by running the following command, and note the ID.\n\nibmcloud iam user-policies <user.b@example.com>\n3. Delete the policy by running the following command, where <Policy_ID> is your Policy ID.\n\nibmcloud iam user-policy-delete <user.b@example.com> <Policy_ID>\n\n\n\n\n\n\n\n\n\n Step 2: Authorize a user to access specific namespaces \n\nCreate some\n\nnamespaceswith sample images, and grant access to them. You create policies to grant different roles to each namespace, and show what effect that has.\n\n\n\n1. Create three new namespaces in User A's account.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-iam_access"}, {"document_id": "ibmcld_01494-31513-33000", "score": 17.030393913091963, "text": "\n* [Enforce security in your cluster](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_tutorial_workflowregistry_tutorial_workflow_enforce_security)\n* [Resolve vulnerabilities in your image](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_tutorial_workflowregistry_tutorial_workflow_resolve_vulnerabilities)\n\n\n\n* [Deploying to nondefault Kubernetes namespaces](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_tutorial_workflowregistry_tutorial_workflow_deploy_nondefault_namespaces)\n\n\n\n\n\n\n\n Granting access to Container Registry resources tutorial \n\n[Granting access to Container Registry resources tutorial](https://cloud.ibm.com/docs/Registry?topic=Registry-iam_accessiam_access)\n\n\n\n* [Before you begin](https://cloud.ibm.com/docs/Registry?topic=Registry-iam_accessiam_access_prereq)\n* [Authorize a user to configure the registry](https://cloud.ibm.com/docs/Registry?topic=Registry-iam_accessconfigure_registry)\n* [Authorize a user to access specific namespaces](https://cloud.ibm.com/docs/Registry?topic=Registry-iam_accessaccess_resources)\n* [Create a service ID and grant access to a resource](https://cloud.ibm.com/docs/Registry?topic=Registry-iam_accessservice_id)\n* [Cleaning up your account](https://cloud.ibm.com/docs/Registry?topic=Registry-iam_accessclean_up)\n\n\n\n\n\n\n\n Solution tutorials \n\n[Moving a VM based app to Kubernetes](https://cloud.ibm.com/docs/Registry?topic=Registry-vm-to-containers-and-kubernetesvm-to-containers-and-kubernetes)", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-sitemap"}, {"document_id": "ibmcld_16729-71418-73421", "score": 17.015213370086364, "text": "\nIBM Cloud\u00ae Container Registry provides a multi-tenant private image registry that you can use to store and share your container images with users in your IBM Cloud account.\n\nKubernetes service Container Registry\n\n\n\n* 45 minutes\n* 2023-06-02\n\n\n\n[Encrypting images for content confidentiality](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_encrypt)Encrypting images for content confidentiality\n\nYou can protect the confidentiality of your IBM Cloud\u00ae Container Registry images, and ensure that hosts that aren't trusted can't run the images.\n\nKey Protect Container Registry\n\n\n\n* 2 hours\n* 2023-01-25\n\n\n\n[Granting access to Container Registry resources tutorial](https://cloud.ibm.com/docs/Registry?topic=Registry-iam_access)Granting access to Container Registry resources tutorial\n\nUse this tutorial to find out how to grant access to your resources by configuring IBM Cloud\u00ae Identity and Access Management (IAM) for IBM Cloud\u00ae Container Registry.\n\nContainer Registry\n\n\n\n* 45 minutes\n* 2023-01-31\n\n\n\n[Container Registry and Vulnerability Advisor workflow tutorial](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_tutorial_workflow)Container Registry and Vulnerability Advisor workflow tutorial\n\nUse this tutorial to find out about the basic functions of both IBM Cloud\u00ae Container Registry and Vulnerability Advisor.\n\nKubernetes service Container Registry\n\n\n\n* 2 hours\n* 2023-06-19\n\n\n\n[Onboarding a Certified Operator from a Red Hat registry](https://cloud.ibm.com/docs/account?topic=account-catalog-opbundle-tutorial)Onboarding a Certified Operator from a Red Hat registry\n\nThis tutorial walks you through how to onboard a sample Operator bundle from a Red Hat\u00ae registry to your account. By completing this tutorial, you learn how to create a private catalog in your account, import the Operator bundle, and validate that it can be installed on a Red Hat OpenShift on IBM Cloud cluster.\n\nContainer Registry Managing your account, resources, and access\n\n\n\n* 45 minutes\n* 2022-10-26", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04866-6428-8391", "score": 14.824493341769903, "text": "\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https://cloud.ibm.com/docs/cloud-object-storage/images/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-6428-8442", "score": 14.693175943030374, "text": "\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https://cloud.ibm.com/docs/images/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_08679-0-1368", "score": 13.78211818923754, "text": "\n\n\n\n\n\n\n  Why can't I delete an initialized service instance? \n\nYou get an error when you delete an initialized service instance.\n\n  What\u2019s happening \n\nYou might receive an error similar to the following one:\n\n> FAILED Error Code: RC-ServiceBrokerErrorResponse Message: Service Broker returned error status code 409\n\n  Why it\u2019s happening \n\nYou haven't cleared (zeroized) the initialized service instance before you delete the instance.\n\n  How to fix it \n\nThe procedure varies depending on the method that you use to initialize the service instance.\n\n\n\n*  If you've initialized your service instance through IBM Cloud Trusted Key Entry (TKE) command-line interface (CLI) plug-in, run the following command before you delete the instance:\n\nibmcloud tke cryptounit-zeroize\n*  If you've initialized your service instance through the TKE application, in the user interface of the application, select Imprint mode > Zeroize crypto unit.\n\n\n\nAfter you zeroize the crypto unit, the administrator signature keys and the master key are cleared from the crypto unit, which means you are not able to access any root keys or standard keys that are protected by the master key. Any resources that are associated with the root keys, such as the [Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable), cannot be accessed.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-troubleshoot-delete-instance"}, {"document_id": "ibmcld_12940-6831-8225", "score": 13.337413319831693, "text": "\nThis parameter is not used when you link to an existing repo. \n repo_id optional, immutable String repo_id The ID of the GitLab project. \n repo_name optional, immutable String repo_name The name of the GitLab repo to create. This parameter is required when you create a repo, or clone or fork a repo. This value is computed when you link to an existing repo. \n repo_url optional, immutable String repo_url The URL of the GitLab repo for this tool integration. This parameter is required when you link to an existing repo. This value is computed when you create a repo, or clone or fork a repo. \n source_repo_url optional, immutable String source_repo_url The URL of the repo that you want to fork or clone. This parameter is required when you fork or clone a repo, but it is not used when you create a repo or link to an existing repo. \n token_url optional, updatable String token_url The token URL that is used to authorize with the GitLab server. \n type required, immutable String type The operation to perform to initialize the new tool integration. Use new to create a Git repo, clone to clone an existing repo into a new Git repo, fork to fork an existing Git repo, or link to link to an existing Git repo. \n\n\n\n\n\n\n\n Learn more about GitLab \n\nTo learn more about GitLab, see the [GitLab article](https://www.ibm.com/garage/method/practices/code/tool_gitlab/) on the IBM Cloud Garage Method.", "title": "", "source": "https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-gitlab"}, {"document_id": "ibmcld_04761-7-2297", "score": 13.28024848984774, "text": "\nMigrating a virtual server between classic data centers \n\nYou have two ways to move your virtual server between IBM Cloud\u00ae classic infrastructure data centers:\n\n\n\n* Lift and Shift\n\n\n\nWhen you use the Lift and Shift method, you create an image template, provision it, and cancel the old virtual server. The advantage of this method is that it's usually the easier and quicker method to move a virtual server. However, while the image is being made, the virtual server is shut down.\n\n\n\n* System Rebuild\n\n\n\nWhen you use the System Rebuild method, you order a new virtual server and copy the data from the old virtual server to the new virtual server. This method is more involved because you need to rebuild the OS specifics and redeploy the application, which might also involve making modifications. The advantage of this method is that it provides an opportunity to start fresh with a new system or to upgrade to a newer OS.\n\nThe method that you choose depends on your business and timeline requirements.\n\n\n\n Lift and Shift method \n\n\n\n Before you begin \n\nBefore you create an image template:\n\n\n\n* Plan for maintenance time\n\n\n\nCreating an image template is an intrusive operation and shuts down the virtual server. After the template is complete, the virtual server powers back up. Powering down and up happens automatically and does not require user interaction.\n\n\n\n* Attached storage considerations\n\n\n\nCapturing the data on the attached storage is optional. You can select which attached storage disks are part of the image template. The Boot volume is always mandatory.\n\n\n\n* Network-attached storage considerations\n\n\n\nBlock Endurance and Performance and File storage volumes are not captured as part of the imaging process. You migrate data for these volumes at the OS level by using data migration tools such as scp, rsync, dd, or another third-party tool of choice. These storage services are data center specific. If you are moving your virtual server to a different data center, order new storage volumes at the same location where the new virtual server is being deployed.\n\n\n\n\n\n Evaluate and create an image template \n\n\n\n1. Evaluate the virtual server that you want to migrate to see which services it is using, such as:\n\n\n\n* Auto scale group\n* Placement group\n* Security group\n\n\n\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-infrastructure?topic=cloud-infrastructure-migrating-vsi-new-datacenter"}, {"document_id": "ibmcld_14041-7-2297", "score": 13.28024848984774, "text": "\nMigrating a virtual server between classic data centers \n\nYou have two ways to move your virtual server between IBM Cloud\u00ae classic infrastructure data centers:\n\n\n\n* Lift and Shift\n\n\n\nWhen you use the Lift and Shift method, you create an image template, provision it, and cancel the old virtual server. The advantage of this method is that it's usually the easier and quicker method to move a virtual server. However, while the image is being made, the virtual server is shut down.\n\n\n\n* System Rebuild\n\n\n\nWhen you use the System Rebuild method, you order a new virtual server and copy the data from the old virtual server to the new virtual server. This method is more involved because you need to rebuild the OS specifics and redeploy the application, which might also involve making modifications. The advantage of this method is that it provides an opportunity to start fresh with a new system or to upgrade to a newer OS.\n\nThe method that you choose depends on your business and timeline requirements.\n\n\n\n Lift and Shift method \n\n\n\n Before you begin \n\nBefore you create an image template:\n\n\n\n* Plan for maintenance time\n\n\n\nCreating an image template is an intrusive operation and shuts down the virtual server. After the template is complete, the virtual server powers back up. Powering down and up happens automatically and does not require user interaction.\n\n\n\n* Attached storage considerations\n\n\n\nCapturing the data on the attached storage is optional. You can select which attached storage disks are part of the image template. The Boot volume is always mandatory.\n\n\n\n* Network-attached storage considerations\n\n\n\nBlock Endurance and Performance and File storage volumes are not captured as part of the imaging process. You migrate data for these volumes at the OS level by using data migration tools such as scp, rsync, dd, or another third-party tool of choice. These storage services are data center specific. If you are moving your virtual server to a different data center, order new storage volumes at the same location where the new virtual server is being deployed.\n\n\n\n\n\n Evaluate and create an image template \n\n\n\n1. Evaluate the virtual server that you want to migrate to see which services it is using, such as:\n\n\n\n* Auto scale group\n* Placement group\n* Security group\n\n\n\n2.", "title": "", "source": "https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-migrating-vsi-new-datacenter"}, {"document_id": "ibmcld_12939-7720-9382", "score": 13.065812548179629, "text": "\nrepo_name optional, immutable String repo_name The name of the GitHub repo to create. This parameter is required when you create a repo, or clone or fork a repo. This value is computed when you link to an existing repo. \n repo_url optional, immutable String repo_url The URL of the GitHub repo for this tool integration. This parameter is required when you link to an existing repo. This value is computed when you create a repo, or clone or fork a repo. \n source_repo_url optional, immutable String source_repo_url The URL of the repo that you are forking or cloning. This parameter is required when you fork or clone a repo. It is not used when you create a repo or link to an existing repo. \n token_url optional, updatable String token_url The token URL that is used to authorize with the GitHub server. \n type required, immutable String type The operation to perform to initialize the new tool integration. Use new to create a Git repo, clone to clone an existing repo into a new Git repo, fork to fork an existing Git repo, or link to link to an existing Git repo. \n\n\n\n\n\n\n\n Learn more about GitHub \n\nTo learn more about GitHub, see the [GitHub article](https://www.ibm.com/garage/method/practices/culture/tool_github/) and the [GitHub and Issue Tracking: Social coding hosted by IBM article](https://www.ibm.com/garage/method/practices/code/tool_git_repos_and_issue_tracking) on the IBM Cloud Garage Method or take the [Ensure quality deployments by using the \"Deployment Risk Analytics with GitHub and Jenkins\" toolchain](https://www.ibm.com/cloud/architecture/tutorials/ensure-quality-deployment-risk-analytics-with-github-and-jenkins-toolchain) tutorial.", "title": "", "source": "https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-github"}, {"document_id": "ibmcld_00541-1796-4042", "score": 12.986249824696705, "text": "\nSharding allows the database to continue serving requests if a node fails, so saving a document involves writing to three nodes. If two updates are made concurrently to the same document, a subset of nodes might accept the first update, and another subset might accept the second update. When the cluster detects this discrepancy, it combines the documents in the same way as normal replication does for concurrent updates by creating a conflict.\n\n\n\n\n\n Why do I need to worry about conflicted documents? \n\nConflicted documents harm performance. A highly concurrent update-in-place pattern also increases the likelihood that writes get rejected. In that situation, the _rev parameter isn\u2019t the expected one, which forces your application to retry and delay processing.\n\nThis conflicted-document scenario is significantly more likely to happen for updates that occur more often than once a second. Use immutable documents for updates that occur more than once every 10 seconds to be on the safe side.\n\n\n\n\n\n How can I use views to pre-calculate results rather than as search indexes? \n\nRather than using views as search indexes, you can use the search get me all person documents and make the search extract the data for you. For example, you can retrieve all 10,000 person documents to calculate the combined hours worked. However, it's better to use a view with a composite key to pre-calculate the hours worked by year, month, day, half-day, and hour by using the _sum built-in reduce. You save work in your application and allow the database to concentrate on serving many small requests. This method is preferable to reading huge amounts of data from disk to service a single large request.\n\n\n\n\n\n Why this method helps me use views to pre-calculate results? \n\nIt's straightforward. First, both maps and reduces are precomputed, so the result of a reduce function is a cheap operation. The operation cost is low even when compared to the significant amounts of IO required to stream hundreds or even thousands of documents from the on-disk storage.\n\nAt a deeper level, when a node receives a view request, it asks the nodes that hold the shard replicas of the view's database for the results of the view request from the documents in each shard.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-five-tips-for-modeling-your-data-to-scale-faq"}, {"document_id": "ibmcld_07578-463038-465269", "score": 12.986249824696705, "text": "\nSharding allows the database to continue serving requests if a node fails, so saving a document involves writing to three nodes. If two updates are made concurrently to the same document, a subset of nodes might accept the first update, and another subset might accept the second update. When the cluster detects this discrepancy, it combines the documents in the same way as normal replication does for concurrent updates by creating a conflict.\n* Why do I need to worry about conflicted documents?\n\nConflicted documents harm performance. A highly concurrent update-in-place pattern also increases the likelihood that writes get rejected. In that situation, the _rev parameter isn\u2019t the expected one, which forces your application to retry and delay processing.\n\nThis conflicted-document scenario is significantly more likely to happen for updates that occur more often than once a second. Use immutable documents for updates that occur more than once every 10 seconds to be on the safe side.\n* How can I use views to pre-calculate results rather than as search indexes?\n\nRather than using views as search indexes, you can use the search get me all person documents and make the search extract the data for you. For example, you can retrieve all 10,000 person documents to calculate the combined hours worked. However, it's better to use a view with a composite key to pre-calculate the hours worked by year, month, day, half-day, and hour by using the _sum built-in reduce. You save work in your application and allow the database to concentrate on serving many small requests. This method is preferable to reading huge amounts of data from disk to service a single large request.\n* Why this method helps me use views to pre-calculate results?\n\nIt's straightforward. First, both maps and reduces are precomputed, so the result of a reduce function is a cheap operation. The operation cost is low even when compared to the significant amounts of IO required to stream hundreds or even thousands of documents from the on-disk storage.\n\nAt a deeper level, when a node receives a view request, it asks the nodes that hold the shard replicas of the view's database for the results of the view request from the documents in each shard.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-463020-465251", "score": 12.986249824696705, "text": "\nSharding allows the database to continue serving requests if a node fails, so saving a document involves writing to three nodes. If two updates are made concurrently to the same document, a subset of nodes might accept the first update, and another subset might accept the second update. When the cluster detects this discrepancy, it combines the documents in the same way as normal replication does for concurrent updates by creating a conflict.\n* Why do I need to worry about conflicted documents?\n\nConflicted documents harm performance. A highly concurrent update-in-place pattern also increases the likelihood that writes get rejected. In that situation, the _rev parameter isn\u2019t the expected one, which forces your application to retry and delay processing.\n\nThis conflicted-document scenario is significantly more likely to happen for updates that occur more often than once a second. Use immutable documents for updates that occur more than once every 10 seconds to be on the safe side.\n* How can I use views to pre-calculate results rather than as search indexes?\n\nRather than using views as search indexes, you can use the search get me all person documents and make the search extract the data for you. For example, you can retrieve all 10,000 person documents to calculate the combined hours worked. However, it's better to use a view with a composite key to pre-calculate the hours worked by year, month, day, half-day, and hour by using the _sum built-in reduce. You save work in your application and allow the database to concentrate on serving many small requests. This method is preferable to reading huge amounts of data from disk to service a single large request.\n* Why this method helps me use views to pre-calculate results?\n\nIt's straightforward. First, both maps and reduces are precomputed, so the result of a reduce function is a cheap operation. The operation cost is low even when compared to the significant amounts of IO required to stream hundreds or even thousands of documents from the on-disk storage.\n\nAt a deeper level, when a node receives a view request, it asks the nodes that hold the shard replicas of the view's database for the results of the view request from the documents in each shard.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05012-1659-3606", "score": 16.758916087394645, "text": "\nFor each of the One-Rate plan pricing regions(North America, Europe, South America,and Asia Pacific), the total aggregated Storage capacity across all instances (within a region) is used to determine the allowance thresholds.\n\n\n\n* Outbound bandwidth: No charge if Outbound bandwidth \u2264 100% of Storage capacity in GB, then list prices apply ($0.05/GBfor North America and Europe, $0.08/GB for South America and Asia Pacific). For example, for an account with aggregated monthly Storage capacity of 100 GB in North America, there are no Outbound bandwidth charges up to 100 GB of transferred data within that month.\n* Class A: No charge if class A requests \u2264 100 x Storage capacity in GB, then list prices apply ($0.005/1000). For example, for an account with aggregated monthly Storage capacity of 100 GB in North America, there are no Outbound bandwidth charges up to 10,000 class A requests that month in North America.\n* Class B: No charge for class B \u2264 1000 x Storage(GB), then list prices apply ($0.004/1000)For example, for an account with aggregated monthly Storage capacity of 100 GB in North America, there are no Outbound bandwidth charges up to 100,000 class A requests that month in North America.\n\n\n\n\n\n\n\n Which storage classes are supported in the One-Rate plan? \n\nThere is only one storage class available in the One-Rate plan: One-Rate Active\n\n\n\n\n\n What are the One-Rate pricing regions? \n\nThere are four One-Rate pricing regions: North America, Europe, South America and Asia Pacific. The following Regional and Single Sites are included in the four One-Rate pricing regions:\n\nNorth America:\n\n\n\n* Regional: us-south, us-east, ca-tor\n* Single Sites: mon01, sjc04\n\n\n\nEurope:\n\n\n\n* Regional: eu-gb, eu-de\n* Single Sites: ams03, mil01, par01\n\n\n\nSouth America:\n\n\n\n* Regional: br-sao\n\n\n\nAsia Pacific:\n\n\n\n* Regional: au-syd, jp-osa, jp-tok\n* Single Sites: che01, sng01\n\n\n\n\n\n\n\n Is the pricing different for the four One-Rate pricing regions?", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-faq-onerate"}, {"document_id": "ibmcld_14546-2844-4906", "score": 16.271601241250774, "text": "\nFor example, a single zone reserved virtual data center is created with 100 vCPU and 800 GB RAM. Later in the month, the data center is reduced to 50 vCPU and 400 GB RAM. The monthly peak usage is 100 vCPU and 800 GB RAM.\n\n\n\n\n\n Hourly peak metric usage \n\nThe maximum value of the metric used over an hour. For example, if 100 vCPU is used for a minute of the hour with 0 vCPU used for the other 59 mins, the hourly peak metric usage is 100 vCPU.\n\n\n\n\n\n\n\n VMware Shared on-demand billing plan \n\nVMware Shared on-demand virtual data center resources are allocated as needed. Pricing is hourly based on the resource usage in the virtual data center. The following metrics are part of this plan.\n\nThe standard storage policy pricing is the same as the 4-IOPS/GB storage policy. The number of IOPS/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 2. VMware Shared Solutions On-demand billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_BASE_COST Monthly Virtual data center price, which includes the edge gateway with five IP addresses. \n TOTAL_VCPU_HOURS Hourly The peak vCPU usage over the period of an hour. \n TOTAL_RAM_GB_HOURS Hourly The peak memory usage over the period of an hour. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of an hour. This value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS/GB storage policy. The number of IOPS/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-shared_pricing"}, {"document_id": "ibmcld_13967-6311-8229", "score": 15.530549365459922, "text": "\nDue to the level of CPU oversubscription that is allowed on the hosts for variable compute server instances, CPU performance levels might be less than other public profiles with the same number of cores, while RAM and storage remain consistent. These variable compute profiles are a lower-cost alternative. For example, you can use this function to test a new feature without incurring the higher cost of a full-performance virtual server instance.\n\nThe offering is available in the following profiles:\n\n\n\nTable 11. Variable compute profiles\n\n Profile vCPU RAM Storage Type \n\n U1.1x2 1 2 GB SAN \n U1.2x4 2 4 GB SAN \n U1.4x8 4 8 GB SAN \n\n\n\n\n\n Storage notes \n\n\n\n* SAN primary boot disk (25 or 100 GB) with an extra disk available, up to 2 TB. You can add one extra secondary disk to your variable compute instance.\n* Pricing for public virtual servers that use SAN storage includes virtual CPU, memory, and minimum primary boot disk. Extra disk prices depend on the disk size and quantity that you select.\n\n\n\nSupported operating systems (such as RHEL, CentOS, Ubuntu, and others), databases that are supported, and software add-ons are also available with this offering.\n\n\n\n\n\n\n\n Compute \n\nCompute profiles are best for workloads with intensive CPU demands, such as high web traffic workloads, production batch processing, and front-end web servers.\n\nThe offering is available in the following profiles:\n\n\n\nTable 12. Compute profiles\n\n Profile vCPU RAM Storage Type \n\n C1.1x1 1 1 GB SAN \n C1.2x2 2 2 GB SAN \n C1.4x4 4 4 GB SAN \n C1.8x8 8 8 GB SAN \n C1.16x16 16 16 GB SAN \n C1.32x32 32 32 GB SAN \n\n\n\n\n\n Storage notes \n\n\n\n* SAN primary boot disk (25 or 100 GB) with extra disks available, up to 2 TB each (five total disks allowed).\n* Pricing for public virtual servers that use SAN storage includes virtual CPU, memory, and minimum primary boot disk. Extra disk prices depend on the disk size and quantity that you select.", "title": "", "source": "https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-virtual-server-profiles"}, {"document_id": "ibmcld_13967-7837-9727", "score": 15.350490247364533, "text": "\nC1.8x8 8 8 GB SAN \n C1.16x16 16 16 GB SAN \n C1.32x32 32 32 GB SAN \n\n\n\n\n\n Storage notes \n\n\n\n* SAN primary boot disk (25 or 100 GB) with extra disks available, up to 2 TB each (five total disks allowed).\n* Pricing for public virtual servers that use SAN storage includes virtual CPU, memory, and minimum primary boot disk. Extra disk prices depend on the disk size and quantity that you select.\n\n\n\nAll supported operating systems (such as RHEL, CentOS, Windows, Ubuntu, and others), databases that are supported, and software add-ons are also available with this offering.\n\n\n\n\n\n\n\n Memory \n\nMemory profiles are best for memory intensive workloads, such as large caching workloads, intensive database applications, or in-memory analytics workloads.\n\nThe offering is available in the following profiles:\n\n\n\nTable 13. Memory profiles\n\n Profile vCPU RAM Storage Type \n\n M1.1x8 1 8 GB SAN \n M1.2x16 2 16 GB SAN \n M1.4x32 4 32 GB SAN \n M1.8x64 8 64 GB SAN \n M1.16x128 16 128 GB SAN \n M1.30x240 30 240 GB SAN \n M1.48x384 48 384 GB SAN \n M1.56x448 56 448 GB SAN \n M1.64x512 64 512 GB SAN \n\n\n\n\n\n Storage notes \n\n\n\n* SAN primary boot disk (25 or 100 GB) with extra disks available, up to 2 TB each (five total disks allowed).\n* Pricing for public virtual servers that use SAN storage includes virtual CPU, memory, and minimum primary boot disk. Extra disk prices depend on the disk size and quantity that you select.\n\n\n\nAll supported operating systems (such as RHEL, CentOS, Windows, Ubuntu, and others), databases that are supported, and software add-ons are also available with this offering.\n\n\n\n\n\n\n\n GPU \n\nGPU profiles are best for high-performance workloads that require more compute density to reduce resource management and costs. The GPU profiles are ideal for artificial intelligence processes, intense graphic and data applications, or developing new applications that require fast performance.", "title": "", "source": "https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-about-virtual-server-profiles"}, {"document_id": "ibmcld_00206-5686-6636", "score": 15.056431802735743, "text": "\n<orderData xsi:type=\"ns1:SoftLayer_Container_Product_Order_Network_Storage_AsAService_Upgrade\">\n<volume xsi:type=\"ns1:SoftLayer_Network_Storage\">\n<id xsi:type=\"xsd:int\">XXXXXXXXX</id>\n</volume>\n<iops xsi:type=\"xsd:int\">2007</iops> \n<packageId xsi:type=\"xsd:int\">759</packageId>\n<prices SOAP-ENC:arrayType=\"ns1:SoftLayer_Product_Item_Price[3]\" xsi:type=\"SOAP-ENC:Array\">\n<item xsi:type=\"ns1:SoftLayer_Product_Item_Price\">\n<id xsi:type=\"xsd:int\">189433</id> \n</item>\n<item xsi:type=\"ns1:SoftLayer_Product_Item_Price\">\n<id xsi:type=\"xsd:int\">190233</id> <!-- 2000 - 2999 GBs storage price--><!-- 2000 - 2999 GBs storage price-->\n</item>\n<item xsi:type=\"ns1:SoftLayer_Product_Item_Price\">\n<id xsi:type=\"xsd:int\">190293</id> <!-- 200 - 40000 IOPS price--><!-- 200 - 40000 IOPS price-->\n</item>\n</prices>\n</orderData>\n</ns1:placeOrder>\n</SOAP-ENV:Body>\n</SOAP-ENV:Envelope>\n* Adjust IOPS on Endurance storage volume.\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>", "title": "", "source": "https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-adjustingIOPS"}, {"document_id": "ibmcld_01225-4942-5949", "score": 15.047286838756854, "text": "\n<orderData xsi:type=\"ns1:SoftLayer_Container_Product_Order_Network_Storage_AsAService_Upgrade\">\n<volume xsi:type=\"ns1:SoftLayer_Network_Storage\">\n<id xsi:type=\"xsd:int\">XXXXXXXX</id> <!--where XXXXXXXXis the VolumeID-->\n</volume>\n<volumeSize xsi:type=\"xsd:int\">2007</volumeSize> \n<packageId xsi:type=\"xsd:int\">759</packageId>\n<prices SOAP-ENC:arrayType=\"ns1:SoftLayer_Product_Item_Price[3]\" xsi:type=\"SOAP-ENC:Array\">\n<item xsi:type=\"ns1:SoftLayer_Product_Item_Price\">\n<id xsi:type=\"xsd:int\">189433</id> \n</item>\n<item xsi:type=\"ns1:SoftLayer_Product_Item_Price\">\n<id xsi:type=\"xsd:int\">190233</id> <!-- 2000 - 2999 GBs storage price--><!-- 2000 - 2999 GBs storage price-->\n</item>\n<item xsi:type=\"ns1:SoftLayer_Product_Item_Price\">\n<id xsi:type=\"xsd:int\">190293</id> <!-- 200 - 40000 IOPS price--><!-- 200 - 40000 IOPS price-->\n</item>\n</prices>\n</orderData>\n</ns1:placeOrder>\n</SOAP-ENV:Body>\n</SOAP-ENV:Envelope>\n* Increase capacity on an Endurance storage volume.\n\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-expandCapacity"}, {"document_id": "ibmcld_11408-11687-13539", "score": 14.802830089861605, "text": "\nData volumes of 235 GB\n\nBoot volumes of 200 GB\n\nDeployed VMs of 160 GB\n\n\n\nTable 10. Account billable for storage use case\n\n Name Size State/Description \n\n data-volume-1 20 GB Available \n data-volume-2 25 GB In-use (attached to vm-1) \n data-volume-3 100 GB In-use (attached to vm-1) \n data-volume-4 30 GB Available \n data-volume-5 60 GB In-use (attached to vm-2) \n\n\n\nTotal billable storage = 595 GB\n\n\n\n* Data volumes: 235 GB\n* Image volumes: 200 GB\n* Deployed VMs: 160 GB\n\n\n\n\n\n\n\n\n\n Pricing for VPN connection \n\nWhen you use a VPN connection, you are billed monthly.\n\nIBM charges with the base price hourly per connection. The base price varies per geography. So if you use one vpn connection that is active for a month, the monthly bill would be $base price X 24 hours X 30 days.\n\n\n\n\n\n Pricing for Power Edge Router \n\nAs a Power Systems Virtual Server user, you are charged based on the Transit Gateway connections that you use:\n\n\n\n* New Transit Gateway that you create in a PER workspace.\n* Existing Transit Gateways that add Power Systems Virtual Server workspace to their existing connection.\n\n\n\nHere are some more PER charges based on the following Transit Gateway specifics:\n\n\n\n* Routing option\n* Number of connections\n\n\n\nThe following table shows the charges based on the routing option that you select:\n\n\n\nTable 13. TGW charges based on routing\n\n Routing type Charges \n\n Local routing data transfer No charges \n Global routing data transfer $0.009405 GB \n\n\n\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change.", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-pricing-virtual-server"}, {"document_id": "ibmcld_14546-4405-6573", "score": 14.630377329936875, "text": "\nThis value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS/GB storage policy. The number of IOPS/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 3. VMware Shared Solutions Reserved billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_VCPU Monthly The peak vCPU allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest vCPU reservation value that is selected by the customer over a one month period. \n MAX_RAM_GB Monthly The peak memory allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest memory reservation value that is selected by the customer over a one month period. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of one month. This value includes the outbound traffic through the virtual data center NSX edge to the public internet. \n\n\n\n\n\n\n\n Private network endpoint billing plan \n\nPrivate network endpoint usage incurs charges as part of the on-demand or reserved virtual data center plan. On the VMware Shared order page, select the About tab to view the pricing plan details.\n\n\n\nTable 4. Billing plan for private network endpoints\n\n Metric Frequency Description \n\n MAX_PRIVATE_NETWORK_ONE_G_COST Monthly Charge for private network endpoint at 1 GB uplink over a period of one month. \n MAX_PRIVATE_NETWORK_TEN_G_COST Monthly Charge for private network endpoint at 10 GB uplink over a period of one month. \n\n\n\n\n\n\n\n Licenses and fees for Veeam Availability Suite and Zerto \n\nVeeam\u00ae and Zerto usage incurs the following on-demand charges.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-shared_pricing"}, {"document_id": "ibmcld_07578-1315888-1317795", "score": 14.57233281448898, "text": "\nThe Standard plan bills for every stored capacity ($/GB/month), Outbound bandwidth ($/GB), class A ($/1,000), class B ($/10,000) and retrieval ($/GB) metrics, where applicable.\n* One Rate plan is suited for active workloads with large amounts of Outbound bandwidth (or varying Outbound bandwidth) as a percent of their Storage capacity (Outbound bandwidth > 20% of Storage capacity). Typical workloads belong to large enterprises and ISVs which may have sub-accounts with multiple divisions/departments or end-users. The plan offers a predictable TCO with an all-inclusive flat monthly charge ($/GB/month) that includes capacity, and built-in allowances for Outbound bandwidth and Operational requests. The built-in allowances for Outbound bandwidth and Operational requests (Class A, Class B) depend on the monthly stored capacity. There is no data retrieval charge.\n\n\n\n* How are the allowance thresholds (for Outbound bandwidth, class A and class B) calculated for the One-Rate plan?\n\nFor each of the One-Rate plan pricing regions(North America, Europe, South America,and Asia Pacific), the total aggregated Storage capacity across all instances (within a region) is used to determine the allowance thresholds.\n\n\n\n* Outbound bandwidth: No charge if Outbound bandwidth \u2264 100% of Storage capacity in GB, then list prices apply ($0.05/GBfor North America and Europe, $0.08/GB for South America and Asia Pacific). For example, for an account with aggregated monthly Storage capacity of 100 GB in North America, there are no Outbound bandwidth charges up to 100 GB of transferred data within that month.\n* Class A: No charge if class A requests \u2264 100 x Storage capacity in GB, then list prices apply ($0.005/1000). For example, for an account with aggregated monthly Storage capacity of 100 GB in North America, there are no Outbound bandwidth charges up to 10,000 class A requests that month in North America.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1318553-1320460", "score": 14.57233281448898, "text": "\nThe Standard plan bills for every stored capacity ($/GB/month), Outbound bandwidth ($/GB), class A ($/1,000), class B ($/10,000) and retrieval ($/GB) metrics, where applicable.\n* One Rate plan is suited for active workloads with large amounts of Outbound bandwidth (or varying Outbound bandwidth) as a percent of their Storage capacity (Outbound bandwidth > 20% of Storage capacity). Typical workloads belong to large enterprises and ISVs which may have sub-accounts with multiple divisions/departments or end-users. The plan offers a predictable TCO with an all-inclusive flat monthly charge ($/GB/month) that includes capacity, and built-in allowances for Outbound bandwidth and Operational requests. The built-in allowances for Outbound bandwidth and Operational requests (Class A, Class B) depend on the monthly stored capacity. There is no data retrieval charge.\n\n\n\n* How are the allowance thresholds (for Outbound bandwidth, class A and class B) calculated for the One-Rate plan?\n\nFor each of the One-Rate plan pricing regions(North America, Europe, South America,and Asia Pacific), the total aggregated Storage capacity across all instances (within a region) is used to determine the allowance thresholds.\n\n\n\n* Outbound bandwidth: No charge if Outbound bandwidth \u2264 100% of Storage capacity in GB, then list prices apply ($0.05/GBfor North America and Europe, $0.08/GB for South America and Asia Pacific). For example, for an account with aggregated monthly Storage capacity of 100 GB in North America, there are no Outbound bandwidth charges up to 100 GB of transferred data within that month.\n* Class A: No charge if class A requests \u2264 100 x Storage capacity in GB, then list prices apply ($0.005/1000). For example, for an account with aggregated monthly Storage capacity of 100 GB in North America, there are no Outbound bandwidth charges up to 10,000 class A requests that month in North America.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00953-7-2042", "score": 11.438679646449275, "text": "\nTroubleshooting for Pipeline Private Workers \n\nGeneral problems with using Pipeline Private Workers might include Kubernetes cluster and kubectl version issues. In many cases, you can recover from these problems by following a few easy steps.\n\n\n\n Why is my Delivery Pipeline Private Worker inactive? \n\nPrivate workers within a pool of workers can be in one of the following states:\n\n\n\n* Active with the current, supported version of private workers\n* Inactive with an unsupported version of private workers\n* Inactive\n\n\n\n What\u2019s happening \n\nYour private worker is inactive. Inactive private workers cannot handle incoming run requests. Pipeline stages that use an inactive private worker cannot complete.\n\n Why it\u2019s happening \n\nThere is an issue with your Kubernetes cluster and the worker cannot be contacted. Or, the version of the private worker that you are running is no longer supported.\n\n How to fix it \n\nTo activate your Delivery Pipeline private worker, [install](https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-install-private-workersinstall_pw) the private worker again. Then, [register](https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-install-private-workersregister_pw) the Delivery Pipeline private worker on the Kubernetes cluster again.\n\n\n\n\n\n I tried to install support for Delivery Pipeline Private Workers in Kubernetes. Why did the installation fail? \n\nIf there is an issue with the version of kubectl that you are running on the client machine, the Delivery Pipeline Private Worker installation fails.\n\n What\u2019s happening \n\nAfter you try to install support for private workers in Kubernetes, an error message is displayed to indicate that there is a schema mismatch and the installation fails.\n\nSchemaError(io.k8s.apimachinery.pkg.apis.meta.v1.APIGroup): invalid object doesn't have additional properties\n\n Why it\u2019s happening \n\nThere is a mismatch between the versions of kubectl that you are running on the Kubernetes server and the Kubernetes client.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-troubleshoot-pipeline-private-workers"}, {"document_id": "ibmcld_05818-2659-4377", "score": 11.231633137274759, "text": "\n* See [Getting help](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar) for more details about using the forums.\n\n\n\n\n\n\n\n\n\n Contacting support \n\nBefore you open a support case, gather relevant information about your cluster environment.\n\n\n\n1. Get your cluster details.\n\nibmcloud ks cluster get -c <cluster_name_or_ID>\n2. If your issue involves worker nodes, get the worker node details.\n\n\n\n1. List all worker nodes in the cluster, and note the ID of any worker nodes with an unhealthy State or Status.\n\nibmcloud ks worker ls -c <cluster_name_or_ID>\n2. Get the details of the unhealthy worker node.\n\nibmcloud ks worker get -w <worker_ID> -c <cluster_name_or_ID>\n\n\n\n3. For issues with resources within your cluster such as pods or services, log in to the cluster and use the Kubernetes API to get more information about them.\n\nYou can also use the [IBM Cloud Kubernetes Service Diagnostics and Debug Tool](https://cloud.ibm.com/docs/containers?topic=containers-debug-tool) to gather and export pertinent information to share with IBM Support.\n4. Contact IBM Support by [opening a case](https://cloud.ibm.com/unifiedsupport/cases/form). To learn about opening an IBM support case, or about support levels and case severities, see [Contacting support](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar).\n5. For the Problem type, search for or select Kubernetes Service.\n6. For the Case details, provide a descriptive title and include the details that you previously gathered. From the Resources, you can also select the cluster that the issue is related to.\n\n\n\n\n\n\n\n Requesting access to allowlisted features \n\n\n\n1. [Create a ticket](https://cloud.ibm.com/unifiedsupport/cases/form).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-get-help"}, {"document_id": "ibmcld_05736-9216-10856", "score": 11.192810372201592, "text": "\nUnsupported:kubectl apply --server-dry-run removed The deprecated --server-dry-run option is removed from the kubectl apply command. If your scripts rely on this option, update them to use the --dry-run=server option instead. \n Unsupported:kubectl get --export removed The deprecated --export option is removed from the kubectl get command. If your scripts rely on this option, refer to the [Deprecate --export option from get command pull request](https://github.com/kubernetes/kubernetes/pull/73787) issue for discussion and references to scripts that handle various use cases. \n kubectl --output jsonpath format changes The kubectl get--o jsonpath (or -o jsonpath) option now returns a JSON object for complex types such as structs, arrays, and slices. Previously, the option returned output in go format. If you use kubectl get to retrieve such fields using --output jsonpath, update your scripts to handle JSON objects. You might try using the -o go-template option to maintain compatibility with the previous behavior. \n Temporary kubectl latency RBAC operations are now performed asynchronously. After you run ibmcloud ks cluster config for the first time after the update, kubectl commands might fail for a few seconds while RBAC synchronizes for the first time. Afterward, kubectl commands perform as expected. If you use automation to access the cluster with kubectl commands, add retry logic for kubectl commands after a kubeconfig file is successfully retrieved. \n Unsupported: Select kubelet metrics The following kubelet metrics that were available via the /metrics and /metrics/resource endpoints are unsupported and removed.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_versions_119"}, {"document_id": "ibmcld_08848-0-1791", "score": 11.180008866018614, "text": "\n\n\n\n\n\n\n  How can I resolve the network error when working with the Kubernetes Service provider? \n\n  What\u2019s happening \n\nDuring the cluster upgrade from Kubernetes Service older version to new version. The Terraform apply fails with the TCP connection error message.\n\nError: Get \"http://localhost/api/v1/\": dial tcp [::1]:80: connect: connection refused\n\nOr\n\nError: {{site.data.keyword.containershort_notm}} cluster unreachable: invalid configuration: no configuration has been provided\n\n  Why it\u2019s happening \n\nYou are combining the cluster provisioning and working with the Kubernetes Service provider at the same time in your Terraform template in the IBM Cloud Schematics workspace or in your localhost. You make a change in the cluster configuration that leads to the cluster re-create. When you run terraform refresh command, you view strange errors such as, network or namespace issues.\n\n  How to fix it \n\nTo troubleshoot this error you need to ensure:\n\n\n\n*  You don't combine the Kubernetes Service provider with the cluster resource at the same time in the Terraform template.\n*  The resources should not be created in the same Terraform template or module where Kubernetes Service provider resources are in use.\n*  The Terraform provider evaluates the provider blocks versus actual resource, and the order in which the resources are defined. For more information, see [Provider configuration](https://developer.hashicorp.com/terraform/language/providers/configurationprovider-configuration).\n\n\n\nIf you cannot resolve this issue, contact support by opening a support case for the service that you want to work with. Make sure to include the incident ID. For more information, see [Using the Support Center](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-ks-network-error"}, {"document_id": "ibmcld_05838-13761-15409", "score": 11.071214511963039, "text": "\nupdate_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud ks versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n\n\n Setting up IBM Cloud\u00ae Monitoring alerts \n\nWhen you set up alerts, make sure to allow your cluster enough time to self-heal. Because Kubernetes has self healing capabilities, configure your alerts only for the issues that arise over time. By observing your cluster over time, you can learn which issues Kubernetes can resolve itself and which issues require alerts to avoid downtime.\n\nOn 15 June 2022, the naming convention for IBM Cloud\u00ae Monitoring alerts is changing to a Prometheus compatible format.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-health-monitor"}, {"document_id": "ibmcld_06179-0-1759", "score": 10.846136657785946, "text": "\n\n\n\n\n\n\n  Why does the Ingress status show an ESSSMG error? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\n  What\u2019s happening \n\nWhen you check the status of your cluster's Ingress components by running the ibmcloud ks ingress status-report get command, you see an error similar to the following example.\n\nCould not the secret group (ESSSMG).\n\n  Why it\u2019s happening \n\nIBM Cloud Kubernetes Service is unable to access the secret group that was registered with the cluster to upload the default Ingress certificates.\n\n  How to fix it \n\nReview your service-to-service authorization policies and verify that communication between IBM Cloud Kubernetes Service and Secrets Manager is enabled.\n\n\n\n1.  [Follow the steps to ensure there is a service-to-service authorization policy](https://cloud.ibm.com/docs/containers?topic=containers-secrets-mgrsecrets-mgr_setup_s2s) configured to enable communication between IBM Cloud Kubernetes Service and Secrets Manager.\n2.  If the policy exists, verify that the secret group registered with the cluster exists in the instance.\n\n\n\n*  To view the instance registration details for your cluster run the ibmcloud ks ingress instance ls command.\n*  To view and modify the secret groups available in your instance, see [Organizing your secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-secret-groups).\n*  To update the secret group for your cluster, run the ibmcloud ks ingress instance default set command and specify the --secret-group option.\n\n\n\n3.  If the issue persists, contact support. Open a [support case](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar). In the case details, be sure to include any relevant log files, error messages, or command outputs.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-ingress-esssmg"}, {"document_id": "ibmcld_10227-2655-4315", "score": 10.805364482418758, "text": "\n* See [Getting help](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar) for more details about using the forums.\n\n\n\n\n\n\n\n\n\n Contacting support \n\nBefore you open a support case, gather relevant information about your cluster environment.\n\n\n\n1. Get your cluster details.\n\nibmcloud oc cluster get -c <cluster_name_or_ID>\n2. If your issue involves worker nodes, get the worker node details.\n\n\n\n1. List all worker nodes in the cluster, and note the ID of any worker nodes with an unhealthy State or Status.\n\nibmcloud oc worker ls -c <cluster_name_or_ID>\n2. Get the details of the unhealthy worker node.\n\nibmcloud oc worker get -w <worker_ID> -c <cluster_name_or_ID>\n\n\n\n3. For issues with resources within your cluster such as pods or services, log in to the cluster and use the Kubernetes API to get more information about them.\n\nYou can also use the [IBM Cloud Kubernetes Service Diagnostics and Debug Tool](https://cloud.ibm.com/docs/openshift?topic=openshift-debug-tool) to gather and export pertinent information to share with IBM Support.\n4. Contact IBM Support by [opening a case](https://cloud.ibm.com/unifiedsupport/cases/form). To learn about opening an IBM support case, or about support levels and case severities, see [Contacting support](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar).\n5. For the Problem type, search for or select Red Hat OpenShift on IBM Cloud.\n6. For the Case details, provide a descriptive title and include the details that you previously gathered. From the Resources, you can also select the cluster that the issue is related to.\n\n\n\n\n\n\n\n Requesting access to allowlisted features \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-get-help"}, {"document_id": "ibmcld_06192-7-1899", "score": 10.690979277421796, "text": "\nWhy am I running out of SNAT ports for egress connections from pods in my cluster? \n\n What\u2019s happening \n\nAs of IBM Cloud Kubernetes Service 1.25 the source Network Address Translation (NAT) port range has change to 32768 - 65535, where previously it was 1024 - 65535. This change was made to resolve possible issues where the following scenarios might occur.\n\n\n\n* An SNAT port is chosen in a VPC cluster that conflicts with a NodePort of a LoadBalancer of type NLB. In this case, that egress connection fails.\n* An SNAT port is chosen for a long running egress connection in the NodePort range of 30,000 - 32,767 that a cluster service later wants to use for a NodePort. In this case, that cluster service won't get traffic on that NodePort until the connection using that SNAT port is finished and has been closed.\n* An SNAT port is chosen for a long running egress connection that a Linux service or hostPort pod port or hostNetwork pod port later wants to use. In that case, that service or pod won't start or work until the connection that is using that SNAT port is finished and has been closed.\n\n\n\n Why it\u2019s happening \n\nUsually, limiting this port range is fine. However, if you are running a highly scalable application in pod-network pods, where on a single worker you have either of the following cases.\n\n\n\n* Over 30,000 egress connections to destinations other than pods or nodes in the cluster open at once.\n* 30,000 egress connections are being opened within a few minutes of each other.\n\n\n\n How to fix it \n\nIt might be possible that the 32768 - 65535 range isn't large enough. Two possible solutions to this are the following options.\n\n\n\n* Add more nodes and have at least one pod per node that make all these egress connections so that each node needs less than 30,000 SNAT ports. This is the preferred solution\n* Explicitly set the pod natPortRange in Calico to a larger range.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-network-snat-125"}, {"document_id": "ibmcld_10382-0-1086", "score": 10.516835384406551, "text": "\n\n\n\n\n\n\n  What if my OpenShift Data Foundation issue is still unresolved? \n\nIf your ODF issue is still unresolved or is not addressed in the troubleshooting steps, contact ODF support by raising a case in the Red Hat customer portal.\n\n\n\n1.  [Access the Red Hat Customer Portal](https://access.redhat.com) and sign in with your support credentials.\n2.  Find the Troubleshoot a product issue section and select Red Hat OpenShift Data Foundation.\n3.  Select the version of your ODF instance.\n4.  Click Continue.\n5.  Use the Red Hat must-gather tool to collect data about your cluster in a compressed file. For more information, see [Gathering data about your cluster](https://docs.openshift.com/container-platform/4.6/support/gathering-cluster-data.htmlgathering-data-specific-features_gathering-cluster-data).\n\noc adm must-gather --image=registry.redhat.io/ocs4/ocs-must-gather-rhel8:latest --dest-dir=ocs_mustgather\n6.  Follow the prompts to describe the issue you have. Attach the file with the must-gather data you collected earlier.\n7.  Click Open a case to submit your issue.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ocs-error-unresolved"}, {"document_id": "ibmcld_10607-0-1848", "score": 10.446519972301527, "text": "\n\n\n\n\n\n\n  Why does the Ingress status show an ERRSEIPM error? \n\nSatellite\n\nYou can use the the ibmcloud oc ingress status-report ignored-errors add command to add an error to the ignored-errors list. Ignored errors still appear in the output of the ibmcloud oc ingress status-report get command, but are ignored when calculating the overall Ingress Status.\n\n  What\u2019s happening \n\nWhen you check the status of your cluster's Ingress components by running the ibmcloud oc ingress status-report get command, you see an error similar to the following example.\n\nThe service is missing one or more worker IPs (ERRSEIPM).\n\n  Why it\u2019s happening \n\nThe service that exposes the default Ingress Controller does not have all the necessary worker IP addresses.\n\n  How to fix it \n\nAdd the worker IP addresses to the external Ingress service.\n\n\n\n1.  Run the following command and make note of your worker IP addresses in the INTERNAL-IP column.\n\noc get nodes -o wide\n2.  Run the following command to edit the service.\n\noc edit service -n openshift-ingress router-external-default\n3.  Add the IP addresses that you retrieved in step 1 to the spec.externalIPs list.\n\nIf your cluster has many workers, you might not want to add all the IP addresses to the list. In this case, it is sufficient to add two IP addresses per zone. To see which worker belongs to which zone, look for the value of the topology.kubernetes.io/zone label in the output of the oc get nodes -o wide --show-labels command.\n4.  Wait 10 to 15 minutes, then check if the warning is resolved by running the ibmcloud oc ingress status-report get command.\n5.  If the issue persists, contact support. Open a [support case](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar). In the case details, be sure to include any relevant log files, error messages, or command outputs.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-ingress-errseipm"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03080-7-1901", "score": 44.89885795770722, "text": "\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-config"}, {"document_id": "ibmcld_16326-1697-3495", "score": 43.6748837045935, "text": "\nFor more information, see [Changing background website](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-preview-share"}, {"document_id": "ibmcld_16368-7-2072", "score": 43.554847983219645, "text": "\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_03421-4-1877", "score": 43.49484674555285, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_16295-7-1721", "score": 42.71711195570377, "text": "\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat"}, {"document_id": "ibmcld_16365-12876-14604", "score": 41.930464383791296, "text": "\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https://web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https://integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https://cloud.ibm.com/docs/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_03421-1518-3290", "score": 41.38813624018496, "text": "\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_16295-1365-2938", "score": 40.65662059877708, "text": "\nThe script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5. Edit the HTML source for the web page where you want the web chat widget to appear. Paste the code snippet into the page. Paste the code as close as possible to the closing </body> tag to ensure that your page renders faster.\n\nDo not modify the integrationID or region property values in the generated embed script.\n\nIf you aren't ready to add the web chat to a live website, you can quickly test it using a local HTML file. Use this HTML code as the source for a test page:\n\n<html>\n<head></head>\n<body>\n<title>My Test Page</title>\n<p>The body of my page.</p>\n\n</body>\n</html>\n\nJust copy this code into a file with the .html extension, and replace the script element with the embed script you copied in the previous step.\n\nThe identifiers in the embed script (such as integrationIDserviceInstanceID) are not considered secret, and are visible to anyone who has access to your website. For more information, see [Security](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architectureweb-chat-architecture-security).\n6. If the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the URLs that host the web chat are accessible.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat"}, {"document_id": "ibmcld_03196-30333-32476", "score": 40.56359948282925, "text": "\nIn the Message before link to web chat field, edit the introductory message to display to the user (in the originating channel) before the link that initiates the transfer. By default, this message is OK, click this link for additional help. Chat will continue on a new web page.\n3. In the URL to web chat field, type the URL for your website where the web chat widget is embedded.\n\n\n\nIn the integration that processes the Channel transfer response, the introductory message is displayed, followed by a link to the URL you specify. The user must then click the link to initiate the transfer.\n\nWhen a conversation is transferred from one channel to another, the session history and context are preserved, so the destination channel can continue the conversation from where it left off. Note that the message output that contains the Channel transfer response is processed first by the channel that initiates the transfer, and then by the target channel. If the output contains multiple responses (perhaps using different response types), these will be processed by both channels (before and after the transfer). If you want to target individual responses to specific channels, you can do so by editing the response using the JSON editor. For more information, see [Targeting specific integrations](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-responses-jsondialog-responses-json-target-integrations).\n\n\n\n\n\n Adding an Image response type \n\nSometimes a picture is worth a thousand words. Include images in your response to do things like illustrate a concept, show off merchandise for sale, or maybe to show a map of your store location.\n\nTo add an Image response type, complete the following steps:\n\n\n\n1. Choose Image.\n2. Add the full URL to the hosted image file into the Image source field.\n\nThe image must be in .jpg, .gif, or .png format. The image file must be stored in a location that is publicly addressable by an https: URL.\n\nFor example: https://www.example.com/assets/common/logo.png.\n\nIf you want to display an image title and description above the embedded image in the response, then add them in the fields provided.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overview"}, {"document_id": "ibmcld_03166-4-2012", "score": 40.216790933280095, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https://medium.com/ibm-watson/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16288-6287-8401", "score": 22.088439874008767, "text": "\nWhen you use the phone integration as the first line of assistance for customers, it's a good idea to have a live agent backup available. You can design your assistant to transfer a call to a human in case the phone connection fails, or if a user asks to speak to someone.\n\nYour company might already have one or more phone numbers that connect to an automatic call dispatcher (ACD) that can queue callers until an appropriate agent is available. If not, choose a call center service to use as your backup.\n\nA conversation cannot be transferred from one integration type to another. For example, if you use the web chat integration with service desk support, you cannot transfer a phone call to the service desk that is set up for the web chat.\n\nYou must provide the call center SIP URI for the call center service you use. You must specify this information in your assistant when you enable a call transfer from a dialog node or action step. For more information, see [Transferring a call to a live agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer).\n\n\n\n\n\n Optimize your actions for phone interaction \n\nFor the best customer experience, design your dialog with the capabilities of the phone integration in mind:\n\n\n\n* Do not include HTML elements in your action responses. To add formatting, use Markdown. For more information, see [Formatting responses](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-respondrespond-formatting).\n* You can use a search extension to include search results in actions that the phone integration will read. When search results are returned, the phone integration reads the introductory message (for example, I found this information that might be helpful), and then the body of only the first search result.\n\nThe entire search response (meaning the introductory message plus the body of the first search result) must be less than 5,000 characters long or the response will not be read at all. Be sure to test the search results that are returned and curate the data collection that you use as necessary.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_03165-4477-6547", "score": 21.64680669164174, "text": "\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https://community.ibm.com/community/user/watsonapps/viewdocument/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-sms"}, {"document_id": "ibmcld_16288-1733-3996", "score": 21.61995456546125, "text": "\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_03216-18448-20174", "score": 20.83627435399964, "text": "\ndtmf \n\nSends commands to the phone integration to control input or output using dual-tone multi-frequency (DTMF) signals. (DTMF is a protocol used to transmit the tones that are generated when a user presses keys on a push-button phone.)\n\n\n\n Fields \n\n\n\n Name Type Description Required? \n\n response_type string dtmf Y \n command_info object Information specifying the DTMF command to send to the phone integration. Y \n command_info.type string The DTMF command to send (collect, disable_barge_in, enable_barge_in, or send). Y \n command_info.parameters object See [Handling phone interactions](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions) N \n\n\n\nThe command_info.type field can specify any of the following supported commands:\n\n\n\n* collect: Collects DTMF keypad input.\n* disable_barge_in: Disables DTMF barge-in so that playback from the phone integration is not interrupted when the customer presses a key.\n* enable_barge_in: Enables DTMF barge-in so that the customer can interrupt playback from the phone integration by pressing a key.\n* send: Sends DTMF signals.\n\n\n\nFor detailed information about how to use each of these commands, see [Handling phone interactions](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions).\n\n\n\n\n\n Example \n\nThis example shows the dtmf response type with the collect command, used to collect DTMF input. For more information, including examples of other DTMF commands, see [Handling phone interactions](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions).\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"dtmf\",\n\"command_info\": {\n\"type\": \"collect\",\n\"parameters\": {\n\"termination_key\": \"\",\n\"count\": 16,\n\"ignore_speech\": true\n}", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-responses-json"}, {"document_id": "ibmcld_16321-7-1807", "score": 20.49383306686041, "text": "\nHandling phone interactions \n\nIf your assistant uses the phone integration, you can use various response types to customize the behavior of the integration or manage the flow of conversations that your assistant has with customers over the telephone.\n\nYou can use response types to perform the following phone-specific actions:\n\n\n\n* [Apply advanced settings to the Speech to Text service](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-speech-advanced)\n* [Apply advanced settings to the Text to Speech service](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-text-advanced)\n* [Transfer a call to a live agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer)\n* [Play hold music or a voice recording](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hold-music)\n* [Enable keypad entry](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-dtmf)\n* [Transfer the conversation to the web chat integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-transfer-channel)\n* [End the call](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-hangup)\n* [Send a text message during a phone conversation](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same action step. For more information, see the following:", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_16337-10301-11908", "score": 20.421939776439554, "text": "\nThe command_info.type field can specify any of the following supported commands:\n\n\n\n* collect: Collects DTMF keypad input.\n* disable_barge_in: Disables DTMF barge-in so that playback from the phone integration is not interrupted when the customer presses a key.\n* enable_barge_in: Enables DTMF barge-in so that the customer can interrupt playback from the phone integration by pressing a key.\n* send: Sends DTMF signals.\n\n\n\nFor detailed information about how to use each of these commands, see [Handling phone interactions](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions).\n\n\n\n\n\n Example \n\nThis example shows the dtmf response type with the collect command, used to collect DTMF input. For more information, including examples of other DTMF commands, see [Handling phone interactions](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions).\n\n{\n\"generic\": [\n{\n\"response_type\": \"dtmf\",\n\"command_info\": {\n\"type\": \"collect\",\n\"parameters\": {\n\"termination_key\": \"\",\n\"count\": 16,\n\"ignore_speech\": true\n}\n},\n\"channels\":\n{\n\"channel\": \"voice_telephony\"\n}\n]\n}\n]\n}\nShow more\n\n\n\n\n\n\n\n end_session \n\nSends a command to the channel ending the session. This response type instructs the phone integration to hang up the call.\n\n\n\n Integration channel support \n\n\n\n Phone SMS \n\n ![Yes](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/checkmark-icon.svg) \n\n\n\n\n\n* The SMS integration supports ending a session by using the terminateSession action command.\n\n\n\n\n\n\n\n Fields \n\n\n\n Name Type Description Required?", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-response-types-reference"}, {"document_id": "ibmcld_16321-1374-3426", "score": 20.257011284282395, "text": "\n* [Send a text message during a phone conversation](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same action step. For more information, see the following:\n\n\n\n* [Define a sequence of phone commands](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-sequence)\n\n\n\nYou can also perform the following phone-specific actions:\n\n\n\n* [Inject custom values into CDR log events](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-cdr-custom-data)\n* [Access phone integration context variables from your action](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actionsphone-actions-access-context-variables)\n\n\n\nFor reference information about response types, see [Response types reference](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-response-types-reference).\n\n\n\n Adding phone-specific responses to your assistant \n\nTo initiate a voice-specific interaction from a an action step, add a response within the generic array using the appropriate response type. For more information about using the JSON editor to add responses, see [Defining responses using the JSON editor](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-assistant-responses-json).\n\n\n\n\n\n Applying advanced settings to the Speech to Text service \n\nUse the speech_to_text response type to send configuration commands to the Speech to Text service instance used by the phone integration. By sending a speech_to_text response from an action step, you can dynamically change the Speech to Text configuration during a conversation.\n\nBy default, any Speech to Text configuration changes you make persist for the remainder of the conversation, or until you update them again.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_03179-4-1759", "score": 20.199521156811166, "text": "\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Integrating with WhatsApp](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-whatsapp). To see all documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Integrating with WhatsApp \n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https://www.twilio.com/).\n2. Create an account.\n3. From the All Products and Services menu ![Twilio All products and services icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/twilio-products.png), click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp. \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-whatsapp"}, {"document_id": "ibmcld_03285-1272-3273", "score": 19.958647165992936, "text": "\n* [Transfer the conversation to the web chat integration](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-transfer-channel)\n* [End the call](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-hangup)\n* [Send a text message during a phone conversation](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-sms)\n\n\n\nIn some cases, you might want to combine response types to perform multiple actions. For example, you might want to implement two-factor authentication by requesting phone keypad entry and sending a text message from the same dialog node or step. For more information, see [Defining a sequence of phone actions](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actionsdialog-voice-actions-sequence).\n\nFor reference information about phone-specific repsonse types and related context variables, see [Phone context variables](https://cloud.ibm.com/docs/assistant?topic=assistant-phone-context).\n\n\n\n Adding phone-specific responses to your dialog or actions \n\nTo initiate a voice-specific interaction from a dialog node or a step in an action, add a response within the output.generic array using the appropriate response type.\n\nAlthough many response types can be specified using the Watson Assistant user interface, phone-specific response types must currently be added using the JSON editor.\n\nFor more information about using the JSON editor to add responses, see [Defining responses using the JSON editor](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-responses-json).\n\n\n\n\n\n Applying advanced settings to the Speech to Text service \n\nUse the speech_to_text response type to send configuration commands to the Speech to Text service instance used by the phone integration. By sending a speech_to_text response from a dialog node or action step, you can dynamically change the Speech to Text configuration during a conversation.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions"}, {"document_id": "ibmcld_16337-9125-10721", "score": 19.7690582663768, "text": "\nName Type Description Required? \n\n response_type string date Y \n\n\n\n\n\n\n\n Example \n\nThis example sends a text response asking the user to specify a date, and then shows an interactive date picker.\n\n{\n\"generic\": [\n{\n\"response_type\": \"text\",\n\"text\": \"What day will you be checking in?\"\n},\n{\n\"response_type\": \"date\"\n}\n]\n}\n\n\n\n\n\n\n\n dtmf \n\nSends commands to the phone integration to control input or output using dual-tone multi-frequency (DTMF) signals. (DTMF is a protocol used to transmit the tones that are generated when a user presses keys on a push-button phone.)\n\n\n\n Integration channel support \n\n\n\n Phone \n\n ![Yes](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/checkmark-icon.svg) \n\n\n\n\n\n\n\n Fields \n\n\n\n Name Type Description Required? \n\n response_type string dtmf Y \n command_info object Information specifying the DTMF command to send to the phone integration. Y \n command_info.type string The DTMF command to send (collect, disable_barge_in, enable_barge_in, or send). Y \n command_info.parameters object See [Handling phone interactions](https://cloud.ibm.com/docs/watson-assistant?topic=phone-actions) N \n\n\n\nThe command_info.type field can specify any of the following supported commands:\n\n\n\n* collect: Collects DTMF keypad input.\n* disable_barge_in: Disables DTMF barge-in so that playback from the phone integration is not interrupted when the customer presses a key.\n* enable_barge_in: Enables DTMF barge-in so that the customer can interrupt playback from the phone integration by pressing a key.\n* send: Sends DTMF signals.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-response-types-reference"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04170-7-2189", "score": 37.66998981431243, "text": "\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https://research.google/pubs/pub45581/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with /cdn-cgi/challenge-platform/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_04105-3403-5572", "score": 33.2212736421763, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-5067-6335", "score": 30.621956967595082, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04168-6066-7283", "score": 28.47815020450537, "text": "\n* [Querying Edge Functions metrics with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https://cloud.ibm.com/docs/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https://cloud.ibm.com/docs/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https://cloud.ibm.com/docs/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https://cloud.ibm.com/docs/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https://cloud.ibm.com/docs/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https://cloud.ibm.com/docs/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https://cloud.ibm.com/docs/cis?topic=cis-at_events)", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-http-concepts"}, {"document_id": "ibmcld_04105-7-2225", "score": 25.153767304060292, "text": "\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-1672-3877", "score": 25.141106319686827, "text": "\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04172-7-2047", "score": 24.264870133785575, "text": "\nAccessing log fields \n\nIf fields are not specified in the request, a limited set of default fields are returned. Find the full list of all available fields using the following request.\n\nibmcloud cis logpull DNS_DOMAIN_ID --available-fields\n\nFields are passed as a comma-separated list. For example, to have \"ZoneID\" and \"RayID\", use:\n\nibmcloud cis logpull DNS_DOMAIN_ID --start 2019-01-02T01:00:00+00:00 --end 2019-01-02T01:00:00+00:00 --fields ZoneId,RayID\n\n\n\n Available Fields \n\nThe following tables describe the fields available by log category.\n\n\n\n HTTP requests \n\nThis table contains the fields available for HTTP requests.\n\n\n\nTable 1. HTTP events\n\n Field Value Type \n\n BotScore Cloudflare Bot Score (available for Bot Management customers; please contact your account team to enable) int \n BotScoreSrc Underlying detection engine or source on where a Bot Score is calculated. Possible values are Not ComputedHeuristicsMachine LearningBehavioral AnalysisVerified Bot string \n CacheCacheStatus unknownmissexpiredupdatingstalehitignoredbypassrevalidated string \n CacheResponseBytes Number of bytes returned by the cache int \n CacheResponseStatus HTTP status code returned by the cache to the edge; all requests (including non-cacheable ones) go through the cache; also see CacheStatus field int \n CacheTieredFill Tiered Cache was used to serve this request bool \n ClientASN Client AS number int \n ClientCountry Country of the client IP address string \n ClientDeviceType Client device type string \n ClientIP IP address of the client string \n ClientIPClass unknowncleanbadHostsearchEnginewhitelistgreylistmonitoringServicesecurityScannernoRecordscanbackupServicemobilePlatformtor string \n ClientRequestBytes Number of bytes in the client request int \n ClientRequestHost Host requested by the client string \n ClientRequestMethod HTTP method of client request string \n ClientRequestPath URI path requested by the client string \n ClientRequestProtocol HTTP protocol of client request string \n ClientRequestReferer HTTP request referrer string", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-log-fields"}, {"document_id": "ibmcld_16286-1338-3308", "score": 23.870929972176285, "text": "\nClick Next to begin app registration.\n\n\n\n\n\n App registration \n\n\n\n1. Go to the [Microsoft Azure portal](https://portal.azure.com/), and log in with your admin credentials.\n2. On the App registrations page, click New registration.\n3. On the Register an application page, enter a name, select the multi-tenant option that applies to your app, and then click Register.\n4. Copy the application ID from the Overview page of your app, and paste it into the App registration field of your Watson Assistant Microsoft Teams integration.\n5. On the same Microsoft Azure Overview page, click the hyperlink Add a certificate or secret next to Client Credentials.\n6. On the Certificates & secrets page for token creation, click New client secret. Enter a description and then select Recommended 180 days. Click Add.\n7. Copy the string under Value and paste into Client secret value on the App registration page of your Watson Assistant Microsoft Teams integration. Note: You must generate a new value before the current one expires on day 180.\n8. Click Next to create your bot.\n\n\n\n\n\n\n\n Create your bot \n\n\n\n1. Go to the [Microsoft Bot Framework developer portal](https://dev.botframework.com/bots/new), and log in with your admin credentials.\n2. On the Tell us about your bot page, complete your bot profile.\n3. Copy the generated endpoint from the Create your bot page of your Watson Assistant Microsoft Teams integration and paste into the Messaging endpoint field of the Configuration section.\n4. Select Multi-Tenant as the app type.\n5. Copy and paste your app ID, and then click Register.\n6. On the Connect to channels page, click Configure Microsoft Teams channel in the Add a featured channel section.\n7. On the Configure Microsoft Teams page, specify options in the Messaging, Calling, and Publish tabs that fit your bot needs, and then click Save.\n8. In your Watson Assistant Microsoft Teams integration, click Next to create your Teams app.\n\n\n\n\n\n\n\n Create your Teams app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-microsoft-teams"}, {"document_id": "ibmcld_04118-5438-6061", "score": 23.547955021618687, "text": "\nAdvanced rate limiting No No Yes Yes Yes \n Bot management No No No Yes No \n\n\n\n\n\n Deprecated plans \n\nThe following plans are scheduled for deprecation or deprecated.\n\n\n\n* The Standard plan reached the end of marketing on 30 April 2023. End of support is not yet determined.\n* Enterprise Package, Enterprise GLB, and Enterprise Security plans will reach the end of marketing on 31 August, 2023. End of support is not yet determined.\n\n\n\nFor more information about changing to a new plan if you are currently on a deprecated plan, see [Transitioning to updated plans](https://cloud.ibm.com/docs/cis?topic=cis-transition-plans).", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-cis-plan-comparison"}, {"document_id": "ibmcld_04175-0-1274", "score": 23.499956067858417, "text": "\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10817-1342-3184", "score": 35.91596420121161, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-7-1743", "score": 24.545050719905994, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_04518-1426-3052", "score": 24.252864882206875, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_07551-14062-16080", "score": 21.76047920563084, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_07551-15747-17355", "score": 20.42638444122974, "text": "\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https://github.com/IBM/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n/Register iOS devices/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_04442-5207-6911", "score": 20.379585416917436, "text": "\nibmcloud plugin download PLUGIN_NAME [-r REPO_NAME] [-v VERSION] [-d, --dest DOWNLOAD_DIRECTORY] [-f]\n\nibmcloud plugin download [-a, --all] [-r REPO_NAME] [-f]\n\nibmcloud plugin download URL [-f] [-d DOWNLOAD_DIRECTORY]\n\nIf no repository is specified, the command uses the default plug-in repository IBM Cloud. If you are downloading a single plug-in, and no version is specified, the command selects the latest available version to download. If the '-a, --all' flag is specified, the command downloads all latest available plug-ins in the repository.\n\nCommand options:\n\n-a, --all (optional)\n: Downloads all latest available plug-ins in the repository.\n\n-r REPO_NAME (optional)\n: The name of the repository where the plug-in binary is located. If no repository is specified, the command uses the default plug-in repository IBM Cloud.\n\n-v VERSION (optional)\n: Version of the plug-in to be downloaded. Accepts specific semantic version or constraint.\n\n-d, --dest DOWNLOAD_DIRECTORY (optional)\n: The destination directory for the downloaded plug-in. If not specified, this is the working directory.\n\n-f\n: Force downloads the plug-in without confirmation.\n\nThe IBM Cloud CLI has the official repository name of IBM Cloud.\n\nExamples:\n\nDownload a plug-in from the remote URL:\n\nibmcloud plugin download http://example.com/downloads/my-plugin\n\nDownload the container-service plug-in of the latest version from the IBM Cloud repository:\n\nibmcloud plugin download container-service -r \"IBM Cloud\"\n\nOr you can run:\n\nibmcloud plugin download container-service\n\nDownload the container-service plug-in with the version 0.1.425 from the official plug-in repository:\n\nibmcloud plugin download container-service -v 0.1.425", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_settings"}, {"document_id": "ibmcld_12332-1034-2510", "score": 20.346006932166286, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}, {"document_id": "ibmcld_04442-3871-5648", "score": 20.094750797938225, "text": "\n-v VERSION (optional)\n: Version of the plug-in to be installed. Accepts specific semantic version or constraint.\n\n-f\n: Force installs the plug-in without confirmation.\n\nThe IBM Cloud CLI has the official repository name of IBM Cloud.\n\nExamples:\n\nInstall a plug-in from the local file:\n\nibmcloud plugin install /downloads/new_plugin\n\nInstall a plug-in from the remote URL:\n\nibmcloud plugin install http://example.com/downloads/my-plugin\n\nInstall the container-service plug-in of the latest version from the IBM Cloud repository:\n\nibmcloud plugin install container-service -r \"IBM Cloud\"\n\nor you can run:\n\nibmcloud plugin install container-service\n\nInstall the container-service plug-in with the version 0.1.425 from the official plug-in repository:\n\nibmcloud plugin install container-service -v 0.1.425\n\nInstall all latest available plug-ins from the official plug-in repository:\n\nibmcloud plugin install --all\n\nInstall all latest available plug-ins from the official plug-in repository without confirmation:\n\nibmcloud plugin install --all -f\n\nInstall multiple plug-ins at the same time:\n\nibmcloud plugin install container-service@0.1.425 secrets-manager@0.1.25\n\n\n\n\n\n ibmcloud plugin download \n\nDownload a specific version of a plug-in to IBM Cloud CLI from the specified repository, or all latest available plug-ins in the repository.\n\nibmcloud plugin download PLUGIN_NAME [-r REPO_NAME] [-v VERSION] [-d, --dest DOWNLOAD_DIRECTORY] [-f]\n\nibmcloud plugin download [-a, --all] [-r REPO_NAME] [-f]\n\nibmcloud plugin download URL [-f] [-d DOWNLOAD_DIRECTORY]\n\nIf no repository is specified, the command uses the default plug-in repository IBM Cloud. If you are downloading a single plug-in, and no version is specified, the command selects the latest available version to download.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_settings"}, {"document_id": "ibmcld_04442-6477-8304", "score": 19.95015955147391, "text": "\nibmcloud plugin download http://example.com/downloads/my-plugin\n\nDownload the container-service plug-in of the latest version from the IBM Cloud repository:\n\nibmcloud plugin download container-service -r \"IBM Cloud\"\n\nOr you can run:\n\nibmcloud plugin download container-service\n\nDownload the container-service plug-in with the version 0.1.425 from the official plug-in repository:\n\nibmcloud plugin download container-service -v 0.1.425\n\nDownload the container-service plug-in with the version 0.1.425 from the official plug-in repository, into the /my_downloads directory:\n\nibmcloud plugin download container-service -v 0.1.425 -d /my_downloads\n\nDownload all latest available plug-ins from the official plug-in repository:\n\nibmcloud plugin download --all\n\nDownload all latest available plug-ins from the official plug-in repository without confirmation:\n\nibmcloud plugin download --all -f\n\n\n\n\n\n ibmcloud plugin update \n\nUpgrade the plug-in from a repository.\n\nibmcloud plugin update [PLUGIN NAME] [-r REPO_NAME] [-v VERSION] [--all]\n\nIf no repository is specified, the command uses the default plug-in repository IBM Cloud. If no version is specified, the command selects the latest available version to install.\n\nCommand options:\n\nPLUGIN NAME\n: Name of the plug-in to update. If not specified, the command checks upgrades for all plug-ins installed.\n\n-r REPO_NAME\n: The name of the repository where the plug-in binary is located. If not specified, the command uses the default plug-in repository IBM Cloud.\n\n-v VERSION (optional)\n: The version of the plug-in to be updated to. If not provided, update the plug-in to the most recent version.\n\n--all\n: Update all available plug-ins.\n\nExamples:\n\nCheck for all available upgrades in the official plug-in repository IBM Cloud:\n\nibmcloud plugin update -r \"IBM Cloud\"\n\nor you can run:", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_settings"}, {"document_id": "ibmcld_13114-2662-3951", "score": 18.6954195852681, "text": "\n[https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-on-windows](https://kubernetes.io/docs/tasks/tools/install-kubectl/install-kubectl-on-windows).\n2. Move kubectl.exe binary to your PATH.\n3. Verify the installation with:\n\nkubectl version --client=true\n\n\n\n\n\n\n\n oc \n\n\n\n1. Download the latest 4.x OpenShift CLI (oc) from [https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/](https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/).\n2. Move oc.exe binary to your PATH.\n3. Verify the installation with:\n\noc version\n\n\n\n\n\n\n\n Helm 3 \n\n\n\n1. Download helm from [https://github.com/helm/helm/releases/latest](https://github.com/helm/helm/releases/latest).\n2. Uncompress the downloaded archive.\n3. Move helm.exe binary to your PATH.\n4. Verify the installation with:\n\nhelm version\n\n\n\n\n\n\n\n Terraform \n\n\n\n1. Download terraform from [https://www.terraform.io/downloads.html](https://www.terraform.io/downloads.html).\n2. Uncompress the downloaded archive.\n3. Move the terraform.exe binary to your PATH.\n4. Verify the installation with:\n\nterraform version\n\n\n\nTo manage IBM Cloud resources with Terraform, you also need to install the IBM Cloud Provider. Starting with Terraform 0.13, the provider can be automatically downloaded from Terraform plugin registry.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10852-44214-45420", "score": 55.536427342857934, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10852-43319-44485", "score": 54.30096642404142, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10817-1342-3184", "score": 51.62739455974479, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-7-1743", "score": 46.561074468850414, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10817-7-1802", "score": 44.107578035021206, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-1426-3052", "score": 43.398788178197364, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_07551-15747-17355", "score": 36.099779540195485, "text": "\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https://github.com/IBM/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n/Register iOS devices/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_10817-2884-4620", "score": 36.08764710698891, "text": "\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in /Library/Developer/Xcode/DerivedData/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_07551-14062-16080", "score": 34.708909097346435, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_12332-1034-2510", "score": 33.81621559251314, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08867-20399-21926", "score": 22.730969713607763, "text": "\n+-------------------------------------------+\nSubscription Name: 30 Day Self-Supported Red Hat OpenShift Container Platform, 2-Core Evaluation\nProvides: Red Hat Ansible Engine\nRed Hat Software Collections (for RHEL Server for IBM Power LE)\nRed Hat OpenShift Enterprise Infrastructure\nRed Hat JBoss Core Services\nRed Hat Enterprise Linux Fast Data path\nRed Hat OpenShift Container Platform for Power\nJBoss Enterprise Application Platform\n:\nRed Hat OpenShift Container Platform Client Tools for Power\nRed Hat Enterprise Linux Fast Datapath (for RHEL Server for IBM Power LE)\nRed Hat OpenShift Enterprise JBoss EAP add-on\nRed Hat OpenShift Container Platform\nRed Hat Gluster Storage Management Console (for RHEL Server)\nRed Hat OpenShift Enterprise JBoss A-MQ add-on\nRed Hat Enterprise Linux for Power, little endian Beta\nRed Hat OpenShift Enterprise Client Tools\n:\nRed Hat OpenShift Enterprise Application Node\n:\nRed Hat OpenShift Service Mesh\n:\nRed Hat OpenShift Enterprise JBoss FUSE add-on\nSKU: SER0419\nContract: 123456789\nPool ID: 1a2345bcd6789098765abcde43219bc3\nProvides Management: Yes\nAvailable: 10\nSuggested: 1\nService Level: Self-Support\nService Type: L1-L3\nSubscription Type: Stackable\nStarts: 12/03/2018\nEnds: 01/02/2019\nSystem Type: Physical\n7. Exit the secure shell to return to your OpenShift installation directory inside your container.\n\nexit\n\nExample output:\n\nlogout\nConnection to 169.47.XXX.XX closed.\n/go/bin/terraform-ibm-openshift \n\n\n\n2. Finish setting up and registering the nodes with the Red Hat Network.", "title": "", "source": "https://cloud.ibm.com/docs/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-redhat"}, {"document_id": "ibmcld_14491-1340-3282", "score": 22.63335570090781, "text": "\nRed Hat OpenShift for VMware configuration \n\nWhen you order the service, you must provide a Red Hat\u00ae pull secret. This pull secret is used to associate the new Red Hat OpenShift cluster with your existing Red Hat account. You can obtain a copy of your pull secret by [logging in to your Red Hat account](https://cloud.redhat.com/openshift/install/vsphere/user-provisioned) and clicking Copy Pull Secret.\n\n\n\n\n\n Setting up DNS to access your Red Hat OpenShift console \n\nRed Hat OpenShift depends on DNS to function properly. The ocp wildcard zone in your VMware environment root zone resolves all names to the IP address of the Red Hat OpenShift cluster application. This way, all applications that run within Red Hat OpenShift are routed through the Load Balancer, as needed.\n\nBecause the Red Hat OpenShift web console runs as an application within Red Hat OpenShift, your system must properly resolve DNS names before you can connect to the Red Hat OpenShift web console. You must complete the following steps before you open the Red Hat OpenShift console:\n\n\n\n1. Ensure you are connected to your environment by using the IBM Cloud infrastructure VPN.\n2. Ensure the system that you use to connect to the Red Hat OpenShift web console can properly resolve hostnames in the DNS zone for your VMware environment. For an existing DNS infrastructure, configure the DNS delegation. Therefore, the queries for hostnames within the VMware instance's root zone are handled by the AD DNS server that is running within your VMware environment.\n\n\n\nAlternately, you can configure your local hosts file with the following entries so you can access the Red Hat OpenShift web console. Use the following details for the example.\n\n\n\n* Replace APPLICATION_IP with the Red Hat OpenShift application IP address shown in the Red Hat OpenShift service details page.\n* Replace ROOTDOMAIN with the root domain shown on the Summary page for the vCenter Server instance.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-ocp_ordering"}, {"document_id": "ibmcld_10422-7-1877", "score": 22.456798528201727, "text": "\nRed Hat OpenShift on IBM Cloud version information \n\nReview information about the supported Red Hat OpenShift versions for Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features, which are subject to change, are disabled.\n\nCheck the [Security Bulletins on IBM Cloud Status](https://cloud.ibm.com/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't also refer to an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions).\n\nFor more details about the Red Hat OpenShift and Kubernetes project versions, review the Red Hat OpenShift release notes.\n\n\n\n* [Red Hat OpenShift 4.13 release notes overview](https://docs.openshift.com/container-platform/4.13/release_notes/ocp-4-13-release-notes.html)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions"}, {"document_id": "ibmcld_14492-10142-11408", "score": 22.402103251855216, "text": "\n* If you are using a vSAN datastore, delete any persistent volumes that you no longer need before you uninstall Red Hat OpenShift. Any volumes that are not deleted will remain in the vSAN storage after the Red Hat OpenShift uninstallation.\n* Before you delete the service, you must remove any personal VMs that were deployed with this service, from the storage. Red Hat OpenShift only orders personal VMs if it\u2019s not vSAN.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [vCenter Server and Red Hat OpenShift architecture overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* [VMware Solutions and Red Hat OpenShift overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro)\n* [Red Hat OpenShift Container Platform 4.7 documentation](https://docs.openshift.com/container-platform/4.7/welcome/index.html)\n* [Red Hat OpenShift Container Platform 4.7 release notes](https://docs.openshift.com/container-platform/4.7/release_notes/ocp-4-7-release-notes.html)\n* [What's new in Red Hat OpenShift](https://www.openshift.com/learn/whats-new)\n* [Succeeding with Red Hat OpenShift and VMware\u2019s Software-Defined Datacenter (SDDC)](https://blog.openshift.com/red-hat-openshift-and-vmware-better-together/)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-ocp_overview"}, {"document_id": "ibmcld_10702-7-1940", "score": 22.3294262729773, "text": "\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https://docs.openshift.com/container-platform/4.11/welcome/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorial"}, {"document_id": "ibmcld_10422-1393-2886", "score": 22.308741060383266, "text": "\nFor more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions).\n\nFor more details about the Red Hat OpenShift and Kubernetes project versions, review the Red Hat OpenShift release notes.\n\n\n\n* [Red Hat OpenShift 4.13 release notes overview](https://docs.openshift.com/container-platform/4.13/release_notes/ocp-4-13-release-notes.html)\n* [Red Hat OpenShift 4.12 release notes overview](https://docs.openshift.com/container-platform/4.12/release_notes/ocp-4-12-release-notes.html)\n* [Red Hat OpenShift 4.11 release notes overview](https://docs.openshift.com/container-platform/4.11/release_notes/ocp-4-11-release-notes.html)\n* [Red Hat OpenShift 4.10 release notes overview](https://docs.openshift.com/container-platform/4.10/release_notes/ocp-4-10-release-notes.html)\n* [Red Hat OpenShift 4.9 release notes overview](https://docs.openshift.com/container-platform/4.9/release_notes/ocp-4-9-release-notes.html)\n* [Kubernetes change log](https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG)\n\n\n\n\n\n Available Red Hat OpenShift versions \n\nRed Hat OpenShift on IBM Cloud supports the following versions of Red Hat OpenShift. Note that different Red Hat OpenShift versions might support different RHEL versions.\n\nDates that are marked with a dagger (\u2020) are tentative and subject to change.\n\nRHEL 7 is deprecated and becomes unsupported soon.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions"}, {"document_id": "ibmcld_07968-7-1612", "score": 22.271227789457676, "text": "\nWorking with Red Hat OpenShift on IBM Cloud \n\nIf you want to use containers in either either the VPC or Satellite reference architectures, you should use [Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-roks-overview). Red Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift on IBM Cloud cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\n\n\n Deploying Red Hat OpenShift on IBM Cloud \n\n\n\n1. Install the CLI plugins for Red Hat OpenShift on IBM Cloud. For more information, see [Installing the Red Hat OpenShift on IBM Cloud CLI](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-containers-openshift).\n2. Setup the API for Red Hat OpenShift on IBM Cloud. For more information, see [Setting up the API](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_api_install).\n3. Create your Red Hat OpenShift on IBM Cloud cluster. For more information, see [Creating a Red Hat OpenShift on IBM Cloud cluster in your VPC](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorial).\n4.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-containers-openshift"}, {"document_id": "ibmcld_14497-11060-12784", "score": 22.245314948778105, "text": "\nThe NSX DLR virtual machines are configured as an active - passive pair, and vSphere Distributed Resource Scheduler (DRS) anti-affinity rules are created to ensure that the DLR VMs do not run on the same host. This step is described in [Red Hat OpenShift NSX DLR configuration](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-nsxdlr-intro).\n* Update DNS - The infrastructure DNS, provisioned with the vCenter Server instance is updated with the names and IP addresses for the Red Hat OpenShift components by using a PowerShell script. This step is described in [VMware Solutions DNS configuration](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-dns-intro).\n\n\n\n* Phase 2 - Red Hat OpenShift installation. These steps are described in [Red Hat OpenShift 4.7 user provider infrastructure installation](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-install-intro).\n\n\n\n* A Red Hat virtual machine, the bastion node, is provisioned to run the Red Hat OpenShift installer and to host an HTTP Server. It is registered with Red Hat by using your subscription, and the Red Hat OpenShift installer is downloaded.\n* On the bastion node, the install-config.yaml file is populated with the required Red Hat OpenShift parameters and Red Hat OpenShift ignition is used to generate a number of files used for the installation of the bootstrap, control plane, and worker machines.\n* Terraform, on the bastion node, uses the files that are created by Ignition to create the Red Hat OpenShift VMs.\n\n\n\n* Phase 3 - Post deployment activities. Configure a persistent volume for use by the Red Hat OpenShift cluster.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"}, {"document_id": "ibmcld_14492-7-1792", "score": 22.23753195492817, "text": "\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-ocp_overview"}, {"document_id": "ibmcld_10203-7-1859", "score": 22.224004917298913, "text": "\nDeploying apps in Red Hat OpenShift clusters \n\nWith Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters, you can deploy apps from a remote file or repository such as GitHub with a single command. Also, your clusters come with various built-in services that you can use to help operate your cluster.\n\n\n\n Moving your apps to Red Hat OpenShift \n\nTo create an app in your Red Hat OpenShift on IBM Cloud cluster, you can use the Red Hat OpenShift console or CLI.\n\nSeeing errors when you deploy your app? Red Hat OpenShift has different default settings than community Kubernetes, such as stricter security context constraints. Review the [common scenarios where you might need to modify your apps](https://cloud.ibm.com/docs/openshift?topic=openshift-plan_deployopenshift_move_apps_scenarios) so that you can deploy them on Red Hat OpenShift clusters.\n\n\n\n Deploying apps through the console \n\nYou can create apps through various methods in the Red Hat OpenShift console by using the Developer perspective. For more information, see the [Red Hat OpenShift documentation](https://docs.openshift.com/container-platform/4.11/applications/creating_applications/odc-creating-applications-using-developer-perspective.html).\n\n\n\n1. From the [Red Hat OpenShift clusters console](https://cloud.ibm.com/kubernetes/clusters?platformType=openshift), select your cluster.\n2. Click Red Hat OpenShift web console.\n3. From the perspective switcher, select Developer. The Red Hat OpenShift web console switches to the Developer perspective, and the menu now offers items such as +Add, Topology, and Builds.\n4. Click +Add.\n5. In the Add pane menu bar, select the Project that you want to create your app in from the drop-down list.\n6. Click the method that you want to use to add your app, and follow the instructions. For example, click From Git.\n\n\n\n\n\n\n\n Deploying apps through the CLI", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-deploy_app"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01441-7-2257", "score": 34.76585278422909, "text": "\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4"}, {"document_id": "ibmcld_01442-7-2257", "score": 34.76585278422909, "text": "\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}, {"document_id": "ibmcld_01441-1679-3819", "score": 34.209893283360834, "text": "\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4"}, {"document_id": "ibmcld_01442-1679-3832", "score": 34.18571867878412, "text": "\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}, {"document_id": "ibmcld_01329-58331-60199", "score": 33.83862559484852, "text": "\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_01533-4-2366", "score": 33.77670547492336, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4-2366", "score": 33.77670547492336, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01533-6329-8623", "score": 32.768753191480606, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-6381-8675", "score": 32.768753191480606, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01471-5654-7396", "score": 32.431704160956805, "text": "\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4 to run the ibmcloud cr va, ibmcloud cr image-list, or ibmcloud cr image-digests commands, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nFor more information about Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout). For more information about Vulnerability Advisor API 4, see [Vulnerability Advisor 4 for IBM Cloud Container Registry](https://cloud.ibm.com/apidocs/container-registry/va-v4).\n\nNew commands for setting and checking the Vulnerability Advisor version are available from Container Registry plug-in 1.0.0\n: From Container Registry plug-in 1.0.0, you can use new commands to check and set Vulnerability Advisor versions.\n\nIf you want to continue to use version 3, you don't need to do anything.\n\nIf you want to use version 4, you can set the version by running the [ibmcloud cr va-version-set](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_va_version_set) command.\n\nFor more information about setting the version by using the ibmcloud cr va-version-set command, see [ibmcloud cr va-version-set](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_va_version_set) and [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nTo find out which version of Vulnerability Advisor that you're running, see [ibmcloud cr va-version](https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcliic_cr_va_version).\n\n\n\n\n\n 3 August 2022", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_release_notes"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12573-2772-4341", "score": 5.305070230671173, "text": "\n--recursive (optional)\n: Show descendant account groups.\n\n\n\n\n\n\n\n ibmcloud enterprise account-create \n\nCreate an account.\n\nibmcloud enterprise account-create NAME [--parent-account-group ACCOUNT_GROUP_NAME] [--owner USER_ID]\n\n\n\n Command options \n\nNAME (required)\n: Account group name.\n\n--owner USER_ID (optional)\n: User ID of the account group.\n\n--parent-account-group ACCOUNT_GROUP_NAME (optional).\n: Name of the parent account group. If omitted, the parent would be the current enterprise.\n\n\n\n\n\n\n\n ibmcloud enterprise account-delete \n\nDelete an account.\n\nibmcloud enterprise account-delete (-n, --name NAME | --id ID) [-q, --quiet]\n\n\n\n Command options \n\n--id ID (required)\n: ID of the account group. This option is exclusive with -n, --name.\n\n-n, --name NAME\n: Name of the account group. This option is exclusive with --id.\n\n-q, --quiet\n: Suppress verbose output.\n\n\n\n\n\n\n\n ibmcloud enterprise account-move \n\nMove an account under different parent.\n\nibmcloud enterprise account-move (-n, --name NAME | --id ID) (--parent-account-group ACCOUNT_GROUP_NAME | --parent-account-group-id ACCOUNT_GROUP_ID | --parent-enterprise)\n\n\n\n Command options \n\n--id ID (required)\n: ID of target account. This option is exclusive with -n, --name.\n\n-n, --name NAME (required)\n: Name of target account. This option is exclusive with --id.\n\n--parent-account-group ACCOUNT_GROUP_NAME (required)\n: Name of parent account group. This option is exclusive with --parent-account-group-id and --parent-enterprise.\n\n--parent-account-group-id ACCOUNT_GROUP_ID (required)\n: ID of parent account group.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-ibmcloud_enterprise"}, {"document_id": "ibmcld_12573-1474-3115", "score": 5.294445693652684, "text": "\nibmcloud enterprise account-group-update \n\nUpdate an account group.\n\nibmcloud enterprise account-group-update (-n, --name NAME | --id ID) (--new-name NEW_NAME)\n\n\n\n Command options \n\n--id ID (required)\n: ID of target account group. This option is exclusive with -n, --name.\n\n-n, --name NAME (required)\n: Name of target account group. This option is exclusive with --id.\n\n--new-name NEW_NAME (required)\n: New name of target account group.\n\n\n\n\n\n\n\n ibmcloud enterprise account-group \n\nDisplay details of account group.\n\nibmcloud enterprise account-group (-n, --name NAME | --id ID)\n\n\n\n Command options \n\n--id ID (required)\n: ID of the account group. This option is exclusive with -n, --name.\n\n-n, --name NAME (required)\n: Name of the account group. This option is exclusive with --id.\n\n\n\n\n\n\n\n ibmcloud enterprise account-groups \n\nList account groups.\n\nibmcloud enterprise account-groups [--parent-account-group ACCOUNT_GROUP_NAME | --parent-account-group-id ACCOUNT_GROUP_ID] [--recursive]\n\n\n\n Command options \n\n--parent-account-group ACCOUNT_GROUP_NAME (optional)\n: Name of the parent account group. This option is exclusive with --parent-account-group-id.\n\n--parent-account-group-id ACCOUNT_GROUP_ID (optional)\n: ID of the parent account group. This option is exclusive with --parent-account-group.\n\n--recursive (optional)\n: Show descendant account groups.\n\n\n\n\n\n\n\n ibmcloud enterprise account-create \n\nCreate an account.\n\nibmcloud enterprise account-create NAME [--parent-account-group ACCOUNT_GROUP_NAME] [--owner USER_ID]\n\n\n\n Command options \n\nNAME (required)\n: Account group name.\n\n--owner USER_ID (optional)\n: User ID of the account group.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-ibmcloud_enterprise"}, {"document_id": "ibmcld_12559-4953-7138", "score": 5.161650685958092, "text": "\nTo import an existing account, the following access is required:\n\n\n\n* Within the account to be imported, you must be the account owner or have the Administrator role on the Enterprise and Billing account management services within the account.\n* Within the enterprise account, you need the Editor or Administrator role on the Enterprise service and the Administrator role on the Billing service.\n\n\n\nComplete the following steps to import the example UX-UI account to the Design account group:\n\n\n\n1. From the enterprise dashboard, click Accounts to view the accounts and account groups in the enterprise.\n2. In the Accounts section, click Add > Import account.\n3. Select UX-UI from the Account list.\n\nIf no accounts are displayed, you likely don't have the correct access in any existing accounts.\n4. Select Design as the parent of the UX-UI account. This determines where in the enterprise hierarchy the account exists.\n5. Review the information about the impacts to your account, and select I understand the impact to my account. Then, click Import.\n\n\n\nRepeat the steps to import more accounts.\n\n\n\n\n\n Step 4: Create new accounts \n\nYou can create new accounts within your enterprise. The accounts are created as Pay-As-You-Go accounts, and usage is billed to the enterprise. To create an account, you need an access policy with the Editor or Administrator role on the Enterprise service.\n\nComplete the following steps to create the example Web account in your enterprise:\n\n\n\n1. From the Enterprise dashboard, click Accounts to view the accounts and account groups in the enterprise.\n2. In the Accounts section, select Add > Create account.\n3. Enter Web as the name of the account.\n4. If you want to assign a different user as the account owner, enter their IBMid in the Owner field. The account owner has full access to manage the account.\n5. Select Marketing as the parent of this account.\n6. Click Create.\n\n\n\nAfter you create the account, the account owner can log in to the account to invite other users and manage their access.\n\nRepeat the steps to create more accounts. As an example, the Example Corp enterprise has the following child account and parent account group hierarchy.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-tutorial&interface=ui"}, {"document_id": "ibmcld_12546-10144-11384", "score": 5.128414536184477, "text": "\n\"name\": \"Example Account\",\n\"owner_iam_id\": \"$OWNER_IAM_ID\"\n}'\n\nCreateAccountOptions createAccountOptions = new CreateAccountOptions.Builder()\n.parent(parentCRN)\n.name(\"Example Account\")\n.ownerIamId(enterpriseAccountIamId)\n.build();\n\nResponse<CreateAccountResponse> response = service.createAccount(createAccountOptions).execute();\nCreateAccountResponse createAccountResponse = response.getResult();\n\nSystem.out.println(createAccountResponse);();\n\ncreate_account_response = enterprise_management_service.create_account(\nparent=parent_crn,\nname='Example Account',\nowner_iam_id=enterprise_account_iam_id,\n).get_result()\n\nprint(json.dumps(create_account_response, indent=2))\n\ncreateAccountOptions := enterpriseManagementService.NewCreateAccountOptions(\nparentCRN,\n\"Example Account\",\nenterpriseAccountIamID,\n)\n\ncreateAccountResponse, response, err := enterpriseManagementService.CreateAccount(createAccountOptions)\nif err != nil {\npanic(err)\n}\nb, _ := json.MarshalIndent(createAccountResponse, \"\", \" \")\nfmt.Println(string(b))\n\nconst params = {\nparent: parentCrn,\nname: 'Example Account',\nownerIamId: enterpriseAccountIamId,\n};\n\nenterpriseManagementService.createAccount(params)\n.then(res => {\nconsole.log(JSON.stringify(res.result, null, 2));\n})", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-add"}, {"document_id": "ibmcld_12546-7171-9158", "score": 5.1184592805460465, "text": "\nAfter you finish building your configuration file, initialize the Terraform CLI. For more information, see [Initializing Working Directories](https://www.terraform.io/cli/init).\n\nterraform init\n3. Provision the resources from the main.tf file. For more information, see [Provisioning Infrastructure with Terraform](https://www.terraform.io/cli/run).\n\n\n\n1. Run terraform plan to generate a Terraform execution plan to preview the proposed actions.\n\nterraform plan\n2. Run terraform apply to create the resources that are defined in the plan.\n\nterraform apply\n\n\n\n\n\n\n\n\n\n\n\n Creating new accounts \n\nYou can create new accounts within your enterprise. The accounts are created as Pay-As-You-Go accounts, and usage is billed to the enterprise. To create an account, you need an access policy with the Editor or Administrator role on the Enterprise service.\n\n\n\n Creating accounts in the console \n\n\n\n1. From the Enterprise dashboard, click Accounts to view accounts and account groups in the enterprise.\n2. In the Accounts section, select Add > Create account.\n3. Enter a name for the account that's unique within the enterprise. Because it's one of many accounts, a unique, descriptive name helps you understand the purpose of the account at a glance.\n4. If you want to assign a different user as the account owner, enter their IBMid in the Owner field. The account owner has full access to manage the account.\n5. If you want to add the account to an account group, select the account group to be its parent. The parent that you choose determines where in the enterprise hierarchy the account exists.\n6. Click Create.\n\n\n\nAfter you create the account, the account owner can log in to the account to invite other users and manage their access.\n\n\n\n\n\n Creating accounts by using the CLI \n\n\n\n1. If you want to add the account to an account group, find the names and IDs of existing account groups.\n\nibmcloud enterprise account-groups --recursive\n2. Create the account by running the following command.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-add"}, {"document_id": "ibmcld_12553-4545-5875", "score": 5.1151743541484915, "text": "\n-H \"Authorization: Bearer <IAM_Token>\"\n-H 'Content-Type: application/json'\n-d '{\n\"parent\": \"crn:v1:bluemix:public:enterprise::a/$ENTERPRISE_ACCOUNT_ID::enterprise:$ENTERPRISE_ID\",\n\"name\": \"Example Account Group\",\n\"primary_contact_iam_id\": \"$PRIMARY_CONTACT_IAM_ID\"\n}'\n\nCreateAccountGroupOptions createAccountGroupOptions = new CreateAccountGroupOptions.Builder()\n.parent(parentCRN)\n.name(\"Example Account Group\")\n.primaryContactIamId(enterpriseAccountIamId)\n.build();\n\nResponse<CreateAccountGroupResponse> response = service.createAccountGroup(createAccountGroupOptions).execute();\nCreateAccountGroupResponse createAccountGroupResponse = response.getResult();\n\nSystem.out.println(createAccountGroupResponse);\n\ncreate_account_group_response = enterprise_management_service.create_account_group(\nparent=parent_crn,\nname='Example Account Group',\nprimary_contact_iam_id=enterprise_account_iam_id,\n).get_result()\n\nprint(json.dumps(create_account_group_response, indent=2))\n\ncreateAccountGroupOptions := enterpriseManagementService.NewCreateAccountGroupOptions(\nparentCRN,\n\"Example Account Group\",\nenterpriseAccountIamID,\n)\n\ncreateAccountGroupResponse, response, err := enterpriseManagementService.CreateAccountGroup(createAccountGroupOptions)\nif err != nil {\npanic(err)\n}\nb, _ := json.MarshalIndent(createAccountGroupResponse, \"\", \" \")", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise-organize"}, {"document_id": "ibmcld_12571-37602-39455", "score": 5.065357198156893, "text": "\n: Version of the access policy API.\n\n\n\n\n\n Examples \n\nList all access policies under the current account:\n\nibmcloud iam access-policies\n\nList all user access policies under the current account:\n\nibmcloud iam access-policies --type user\n\nList all service ID access policies under the current account:\n\nibmcloud iam access-policies --type service_id\n\nList all access group access policies under the current account:\n\nibmcloud iam access-policies --type access_group\n\nList all trusted profile access policies under the current account:\n\nibmcloud iam access-policies --type trusted_profile\n\nList all trusted profile access policies sorted by created_at in ascending order under the current account:\n\nibmcloud iam access-policies --type trusted_profile --sort-by created_at\n\nList all trusted user policies sorted by last_modified_at in descending order under the current account:\n\nibmcloud iam access-policies --type user --sort-by -last_modified_at\n\n\n\n\n\n\n\n ibmcloud iam account-policies \n\nList all account policies under current account:\n\nibmcloud iam account-policies [-t, --type access | auth] [--output FORMAT] [-q, --quiet] [--api-version v1 | v2]\n\n\n\n Command options \n\n-t, --type access | auth\n: List all policies under current account filtered by policy type. Valid options are: access | auth\n\n--output FORMAT\n: Specify output format. Only 'JSON' is supported.\n\n-q, --quiet\n: Suppress verbose output.\n\n--api-version\n: Version of the access policy API.\n\n\n\n\n\n Examples \n\nList all account policies under current account:\n\nibmcloud iam account-policies\n\nList all authorization policies under current account. Provides the same list as ibmcloud iam authorization-policies:\n\nibmcloud iam account-policies -t auth\n\nList all access policies under current account. Provides the same list as ibmcloud iam access-policies:\n\nibmcloud iam account-policies -t access", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-ibmcloud_commands_iam"}, {"document_id": "ibmcld_00696-1740-4173", "score": 5.053529824831694, "text": "\nWhen you log in, any of the following types of accounts might be associated with your user credentials:\n\n\n\n* Personal account\n* Corporate account\n* Corporate individual account\n\n\n\n\n\n Personal accounts \n\nTypically, each user has their own account that is their personal account. You can easily identify your personal account because it usually contains your name, for example, John Smith's Account.\n\nYou have full rights over all objects that are created in your personal account. You can invite other users to join your account, assign them rights over objects that you create, and assign them rights to create objects in your account. Because of these rights, the personal data of other users might be in your account, and your personal data might be in other user's accounts.\n\nIf you have permission to create an object in an account, you also have the right to modify and delete it, regardless of which account the object is stored in. When two users collaborate, they often share a personal account.\n\n\n\n\n\n Corporate accounts \n\nA corporate account is set up by your company. Typically, you are added automatically to the account, rather than being invited. Although corporate accounts provide users with a place to work, communicate, and share resources and charging, this set up is just a convention. A corporate account is really no different than a personal account. Objects that are created in a corporate account are associated with the account and users can be invited to the account.\n\nTeams of people who work for a corporation often collaborate by using a corporate account.\n\n\n\n\n\n Corporate individual accounts \n\nWhen you work for a corporation, the work in your account might be legally owned by the corporation. Many users who work for a corporation have a corporate individual account. If you log in to your account by using credentials that contain your corporation's name and also have what appears to be a personal account, the work within your personal account might belong to the corporation.\n\nA corporate individual account is no different from any other account. You can invite users to a corporate individual account and objects that are created in a corporate individual account are owned by the account.\n\nIf you work for a corporation that owns your work, a personal account that usually contains your name is considered a corporate individual account.\n\n\n\n\n\n\n\n Modifying, exporting, and deleting personal data", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cd_personal_data"}, {"document_id": "ibmcld_00330-1604-3194", "score": 4.970249412400285, "text": "\ncdn-powered-by-akamai.origin-path.create Create an origin path. \n cdn-powered-by-akamai.origin-path.update Update an origin path. \n cdn-powered-by-akamai.origin-path.delete Delete an origin path. \n\n\n\n\n\n\n\n List of Time To Live events \n\nThe following table lists the actions taken related to TTL. With each of these actions, an event is generated:\n\n\n\nTable 3. Tive to Live events\n\n Action Description \n\n cdn-powered-by-akamai.ttl.create Create TTL. \n cdn-powered-by-akamai.ttl.update Update TTL. \n cdn-powered-by-akamai.ttl.delete Delete TTL. \n\n\n\n\n\n\n\n List of Purge events \n\nThe following table lists the actions taken related to purge. With each of these actions, an event is generated:\n\n\n\nTable 4. Purge events\n\n Action Description \n\n cdn-powered-by-akamai.purge.create Create purge. \n cdn-powered-by-akamai.purge.save Save purge. \n cdn-powered-by-akamai.purge.unsave Unsave purge. \n\n\n\n\n\n\n\n List of CDN Account events \n\nThe following table lists the actions taken related to CDN account. With each of these actions, an event is generated:\n\n\n\nTable 5. CDN Account events\n\n Action Description \n\n cdn-powered-by-akamai.account.create Create CDN account. \n cdn-powered-by-akamai.account.cancel Cancel CDN account. \n cdn-powered-by-akamai.account.delete Delete CDN account. \n\n\n\n\n\n\n\n List of Geolocation events \n\nThe following table lists the actions taken related to geolocation. With each of these actions, an event is generated:\n\n\n\nTable 6. Geolocation events\n\n Action Description \n\n cdn-powered-by-akamai.geo.create Create Geo location. \n cdn-powered-by-akamai.geo.update Update Geo location.", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-at_events"}, {"document_id": "ibmcld_02379-9575-11799", "score": 4.941107254908431, "text": "\nrequestData.request_body.old_restrict_create_platform_apikey Reports the original value for the Restrict API key creation setting. <br>Valid values: NOT_RESTRICTED and RESTRICTED \n requestData.request_body.new_restrict_create_platform_apikey Reports the new value for the Restrict API key creation setting. <br>Valid values: NOT_RESTRICTED and RESTRICTED \n requestData.request_body.old_restrict_create_service_id Reports the original value for the Restrict service ID creation setting. <br>Valid values: NOT_RESTRICTED and RESTRICTED \n requestData.request_body.new_restrict_create_service_id Reports the new value for the Restrict service ID creation setting. <br>Valid values: NOT_RESTRICTED and RESTRICTED \n requestData.request_body.old_allowed_ip_addresses Reports the original value for the Restrict IP address access setting. <br>Valid values: NOT_RESTRICTED and RESTRICTED \n requestData.request_body.new_allowed_ip_addresses Reports the new value for the Restrict IP address access setting. <br>Valid values: NOT_RESTRICTED and RESTRICTED \n requestData.team_directory_enabled Reports the boolean value that is set when the Restrict user list visibility setting is modified. \n\n\n\nThe following table lists the deprecated actions that generate an event when an account setting that is controlled from the Manage > Access IAM > Settings dashboard is modified:\n\n\n\nTable 11. Actions that generate events when the account settings are changed\n\n Action Description \n\n billing.account-traits.update An event is generated when an account setting is modified. \n billing.account-mfa.set-on An event is generated when the Account Login setting sets on multifactor authentication in the account. \n billing.account-mfa.set-off An event is generated when the Account Login setting sets off multifactor authentication in the account. \n\n\n\n\n\n\n\n Events for managing organizations \n\nThe following table lists the actions that generate an event:\n\n\n\nTable 12. Actions that generate events\n\n Action Description \n\n billing.account-org.create An event is generated when you add an organization to the account. \n\n\n\n\n\n\n\n Events for managing software instances \n\nThe following table lists the actions that generate an event for software instances:", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-at_events_acc_mgt"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09984-0-1283", "score": 26.880697362845957, "text": "\n\n\n\n\n\n\n  Overview \n\nData lakes are an essential tool for storing structured and unstructured data on the cloud. With IBM\u00ae Netezza\u00ae Performance Server for IBM Cloud Pak\u00ae for Data as a Service, you can use external tables to access parquet files that are stored outside of your database in data lakes (on AWS S3). Also, you can analyze this data by using the robust and massively parallel Netezza Performance Server execution engine.\n\nExternal data sources use connection strings to specify how you can access an external system. Each connection string describes where your data is placed and how to authenticate to your data source. Each external data source has a definition (schema), but the actual data exists external to the Netezza Performance Server database.\n\nYou cannot backup (nzbackup) and restore (nzrestore) external data source objects.\n\nUse cases for external data source include:\n\n\n\n*  [Running queries against parquet data that is stored in a data lake](https://cloud.ibm.com/docs/netezza?topic=netezza-querying_singularity).\n*  [Ingesting data into Netezza Performance Server](https://cloud.ibm.com/docs/netezza?topic=netezza-ingest_singularity).\n*  [Querying both local and remote data](https://cloud.ibm.com/docs/netezza?topic=netezza-merging_singularity).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-overview_singularity"}, {"document_id": "ibmcld_14654-7-1943", "score": 22.530834932549162, "text": "\nPlanning for vCenter Server instances \n\nPlan your instance based on the IBM Cloud\u00ae data center location, your workload capacity requirements, and add-on services requirements. Review the following requirements before you order your VMware vCenter Server\u00ae instance.\n\n\n\n* New deployments of vCenter Server instances with VMware vSphere\u00ae 6.5 or 6.7 are not supported.\n* New deployments of vCenter Server multizone instances are not supported.\n* New deployments of vCenter Server with NSX-V instances are not supported.\n\n\n\n\n\n Account requirements \n\nThe account that you are using must meet certain requirements. For more information, see [Signing up for required accounts](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-signing_required_accounts).\n\n\n\n\n\n IBM Cloud data center availability \n\nThe vCenter Server deployment has strict requirements on the physical infrastructure. Therefore, you can deploy instances only in IBM Cloud data centers that meet the requirements. The following IBM Cloud data centers are available for vCenter Server deployment.\n\nAsia-Pacific\n\nEurope\n\nNA East\n\n\n\nTable 1. Available IBM Cloud data centers for vCenter Server instances\n\n Geography Data center Pod Server options for NSX-T<br><br>[1] Server options for NSX-V<br><br>[2] \n\n Asia-Pacific CHE01 01 Skylake, Cascade Lake Skylake, Cascade Lake, SAP-certified Cascade Lake<br><br>[3] \n Asia-Pacific OSA21 01 Cascade Lake, SAP-certified Cascade Lake Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA22 01 Cascade Lake, SAP-certified Cascade Lake Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA23 01 Cascade Lake, SAP-certified Cascade Lake Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SNG01 02 Skylake, Cascade Lake, SAP-certified Cascade Lake Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SYD01 01-02 Skylake, Cascade Lake, SAP-certified Skylake, Cascade Lake, SAP-certified Cascade Lake", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_planning"}, {"document_id": "ibmcld_14823-7-1880", "score": 21.864166374539046, "text": "\nPlanning for VMware vSphere \n\nReview the following requirements before you order a VMware vSphere\u00ae instance. Plan your VMware vSphere based on the IBM Cloud\u00ae data center location and your workload capacity requirements.\n\nYou are responsible for setting up the environment, installing, and configuring various VMware\u00ae components after the VMware ESXi\u2122 servers are deployed. The following examples are VMware components: VMware vCenter Server\u00ae, VMware NSX\u00ae, and VMware vSAN\u2122.\n\n\n\n Account requirements \n\nThe account that you are using must meet certain requirements. For more information, see [Signing up for required accounts](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-signing_required_accounts).\n\n\n\n\n\n IBM Cloud data center availability \n\nThe vSphere deployment has strict requirements on the physical infrastructure. Therefore, you can deploy clusters only in IBM Cloud data centers that meet the requirements. The following IBM Cloud data centers are available for vSphere deployment.\n\nCascade Lake bare metal servers are available in\n\nmultizone regionIBM Cloud data centers. For more information, see [Multizone region (MZR) overview](https://cloud.ibm.com/docs/loadbalancer-service?topic=loadbalancer-service-multi-zone-region-mzr-overview).\n\nIf you select a vSAN component, the location list is filtered by SSD (Solid-State Disk) availability.\n\nAsia-Pacific\n\nEurope\n\nNA East\n\n\n\nTable 1. Available IBM Cloud data centers for VMware vSphere instances\n\n Geography Data center Pod Server options<br><br>[1] \n\n Asia-Pacific CHE01 01 Skylake, Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA21 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA22 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific OSA23 01 Cascade Lake, SAP-certified Cascade Lake \n Asia-Pacific SNG01 02 Skylake, Cascade Lake, SAP-certified Cascade Lake", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vs_planning"}, {"document_id": "ibmcld_13497-1510-3518", "score": 21.625397105408958, "text": "\nExisting instances still work but will be fully deprecated on 31 October.\n\n\n\n\n\n May 2022 \n\nRebranding\n: IBM Cloud SQL Query was rebranded to IBM Cloud Data Engine.\n\nHive\n: Data Engine provides an external [Hive metastore (HMS) service](https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore).\n\n\n\n\n\n November 2021 \n\nAdd columns to Catalog tables\n: You can add columns to existing Catalog tables with the newly supported ALTER TABLE ... ADD COLUMNS statement.\n\n\n\n\n\n July 2021 \n\nStream landing tutorial\n: A detailed [getting started tutorial](https://www.ibm.com/cloud/blog/stream-landing-from-event-streams-kafka-service-to-ibm-cloud-data-lake-on-object-storage) for stream landing with Data Engine is now available.\n\nNew region for stream landing\n: The stream landing capability is now also available in Frankfurt, in addition to Dallas.\n\n\n\n\n\n June 2021 \n\nStream landing support\n: Data Engine now supports stream landing that enables you to stream your data in real time from a topic to a bucket of your choice. This capability enables efficient analytics on the new objects created.\n\nConnect to data lakes with Cloud Pak for Data\n: IBM Cloud Pak\u00ae for Data now comes with an integrated connector to Data Engine that allows to connect to cloud data lakes and import data assets into projects and catalogs in Cloud Pak for Data. For more information, see [Connecting to a Cloud Data Lake with IBM Cloud Pak for Data](https://www.ibm.com/cloud/blog/connecting-to-a-cloud-data-lake-with-ibm-cloud-pak-for-data).\n\n\n\n\n\n December 2020 \n\nSupported regions\n: Data Engine is available in Chennai, India. When you provision new instances, you can select whether it is being provisioned in Dallas, Frankfurt, or Chennai.\n\nIBM Cloud Object Storage\n: IBM Cloud Object Storage web console discovers SQL-queryable objects and folders and directly starts the Data Engine web console with a prefilled SQL statement for seamless interactive data exploration.\n\n\n\n\n\n November 2020 \n\nModify location of Hive partitions", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-query-relnotes"}, {"document_id": "ibmcld_16627-0-1141", "score": 21.468529559536428, "text": "\n\n\n\n\n\n\n  About Data manager \n\nThe Data manager page in IBM\u00ae watsonx.data is the entry point to browse the schemas and tables by engine. You can select an engine to view the associated catalogs, schemas, and tables.\n\nFrom the Data manager page, you can create schemas and tables by using the Create option that is provided in the left window. You can also select a catalog or schema, click the overflow menu, and use the corresponding Create option to create a schema or table. Create table from file option in the overflow menu of schema is also used to ingest a data file into watsonx.data. Similarly, schemas and tables can be dropped from the catalogs.\n\nWait for a few minutes to view the changes after a schema or table is dropped.\n\nAdding, renaming, or dropping a column are the other tasks that can be performed in the Data manager page.\n\nYou can browse the Table schema and upto 25 rows of Data sample for some tables. You can view the Time travel snapshots and use the Rollback feature to rollback to a given snapshot for Iceberg tables.\n\nPresto cannot roll back to the snapshots that are not ancestors of the current snapshot.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-exp_objects"}, {"document_id": "ibmcld_09978-4314-6065", "score": 21.007800955958263, "text": "\n* Automatic pause and resume is enabled in the web console.\n\n\n\n\n\n\n\n Components \n\n\n\n* Netezza Performance Server 11.2.2.5\n* Web console 4.0.11\n\n\n\n\n\n\n\n Known issues \n\nIf a common table expression or derived table query contains column names or column aliases, which begin with an underscore, Netezza Performance Server deletes these columns in the query result set.\nIf there are no columns to display, Netezza Performance Server returns the following error.\n\nERROR: No columns are selected due to column alias begin with underscore\n\nExample:\n\ncreate table t1 ( c1 int , c2 int);\nCREATE TABLE\nwith tab1 as ( select c1 as _c1 , c2 as _c2 from t1 ) select tab1.* from tab1; ERROR: No columns are selected due to column alias begin with underscore\nselect tab1.* from ( select c1 as _c1 , c2 as _c2 from t1 ) as tab1; ERROR: No columns are selected due to column alias begin with underscore\n\n\n\n\n\n\n\n July 2022 \n\nAs of July 28, 2022, you can access data from data lakes and move data between applications with Kafka.\n\n\n\n New features \n\n\n\n* Use the technology preview of the Netezza Performance Server external tables to access and query parquet files that are stored outside of your database in data lakes (on AWS S3). For more information, see [Querying data from data lakes](https://cloud.ibm.com/docs/netezza?topic=netezza-overview_singularity).\n* Use Netezza Performance Server as a data source or data sink. For more information, see [Using Netezza Performance Server as a data source](https://cloud.ibm.com/docs/netezza?topic=netezza-netezzakafkadatasourcekafka) and [Using Netezza Performance Server as a data sink](https://cloud.ibm.com/docs/netezza?topic=netezza-netezzakafkadatasinkkafka).\n\n\n\n\n\n\n\n Known issues \n\ndatasource is a reserved keyword now.", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-my-service-relnotes"}, {"document_id": "ibmcld_16669-7-2101", "score": 20.513496152907184, "text": "\nIngesting data from object storage bucket \n\nIn this tutorial, you learn to move data into a data lake or an object storage bucket and load the data files to Presto. You will also learn to optimize the file format to choose the table format and run complex SQL query in IBM\u00ae watsonx.data.\n\nSample Scenario : You need to run SQL query on data files that is in your object storage bucket. For this, you must attach the data files in your object storage bucket to Presto. You can also convert data into an optimized analytical format in Parquet or ORC to enhance query performance and reduce server and storage resource consumption. Now, you can run SQL query against the table you created.\n\n\n\n Objective \n\n\n\n* Creating infrastructure within the watsonx.data service.\n* Establishing connection with the customer data bucket.\n* Querying from the bucket\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* Subscription of watsonx.data on cloud.\n* The configuration details of data bucket that you bring in. This is required for establishing connection with the watsonx.data.\n* Ensure that the data bucket has data.\n\n\n\n\n\n\n\n Step 1: Uploading data into an object storage bucket and attaching to Presto \n\nIn this section of the tutorial, you are going to manage data in an object storage bucket and attach the bucket to HMS and associate with Presto engine.\n\n\n\n1. Access any one of the object storage access tools like S3 Browser, AWS S3 console, direct S3 APIs, and various CLI/UI object storage tools.\n2. Load data files to your object storage bucket by using the tool.\n3. Register and attach the object storage bucket to HMS and associate with Presto engine by using watsonx.data UI.\n4. Alternatively, you can also register and attach an object storage bucket with pre-existing data to HMS.\n\nORC, Parquet, Avro, RCFile, SequenceFile, JSON, Text (CSV) are the Hive supported file formats.\n\n\n\n\n\n\n\n Step 2: Load data files into Presto \n\nAfter attaching the object storage bucket to HMS, you need to load data files into Presto by creating schema and external tables through the Hive connector.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-tutorial_ingest_osbckt"}, {"document_id": "ibmcld_09969-7-1689", "score": 20.229156796054205, "text": "\nIngesting data from data lakes \n\nIf you plan on regularly querying your data, load it into Netezza Performance Server first to get the best performance benefits.\n\n\n\n Before you begin \n\nIn the examples, the publicly available [New York taxi trip record data](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page) for yellow taxis in January 2022 is used. To follow this example, make sure that the data is in an accessible S3 bucket.\n\n\n\n\n\n 1. Create an external data source. \n\nExternal datasources allow an administrator to grant access to S3 without providing the keys directly to a user.\n\na) Set ENABLE_EXTERNAL_DATASOURCE.\n\nset ENABLE_EXTERNAL_DATASOURCE = 1;\n\nb) Create an external data source.\n\ncreate EXTERNAL DATASOURCE 'DATA SOURCE' on 'REMOTE SOURCE'\nusing (\nACCESSKEYID 'ACCESS KEY ID' SECRETACCESSKEY 'SECRET ACCESS KEY' BUCKET 'BUCKET' REGION 'REGION'\n);\n\nExample:\n\ncreate EXTERNAL DATASOURCE EXAMPLEDATALAKE\u00a0on AWSS3\u00a0\nusing (\nACCESSKEYID 'XXXX' SECRETACCESSKEY 'XXXX' BUCKET 'exampledatalakebucket' REGION 'US-EAST-1'\n);\n\nFor more information, see [CREATE EXTERNAL DATASOURCE command](https://www.ibm.com/docs/en/netezza?topic=tables-create-external-datasource-command).\n\n\n\n\n\n 2. Create an external table for the data from a data lake. \n\nAfter you created an external data source, you can create an external table that accesses the yellow taxi data from January 2022.\n\nEnsure that you have the necessary privileges as described in [Privileges for creating external tables](https://www.ibm.com/docs/en/netezza?topic=et-create-external-table-command-2).\n\ncreate EXTERNAL table 'TABLE NAME' on 'DATA SOURCE'\nusing (\u00a0\nDATAOBJECT ('DATA OBJECT') FORMAT 'PARQUET'\u00a0\n);", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-ingest_singularity"}, {"document_id": "ibmcld_16669-1692-3354", "score": 20.045014571326206, "text": "\nAlternatively, you can also register and attach an object storage bucket with pre-existing data to HMS.\n\nORC, Parquet, Avro, RCFile, SequenceFile, JSON, Text (CSV) are the Hive supported file formats.\n\n\n\n\n\n\n\n Step 2: Load data files into Presto \n\nAfter attaching the object storage bucket to HMS, you need to load data files into Presto by creating schema and external tables through the Hive connector.\n\n\n\n1. Run the following command to create schema for the data you want to access.\n\nCREATE SCHEMA <SCHEMA_NAME> WITH ( location = '<SCHEMA_LOCATION>' );\n\nFor example:\n\nCREATE SCHEMA hive.gosales WITH ( location = 's3a://lhbeta/gosales' );\n2. Run the following command to create table by using an external location by pointing to an existing table.\n\nCREATE TABLE IF NOT EXISTS <TABLE_NAME> (\"<COLUMN_NAMES>\" <DATA_TYPE>) WITH ( format = '<DATA_FORMAT>', external_location = '<TABLE_LOCATION>' );\n\nFor example:\n\nCREATE TABLE IF NOT EXISTS hive.gosales.branch (\"BRANCH_CODE\" int, \"ADDRESS1\" varchar, \"ADDRESS1_MB\" varchar, \"ADDRESS2\" varchar, \"ADDRESS2_MB\" varchar, \"CITY\" varchar, \"CITY_MB\" varchar, \"PROV_STATE\" varchar, \"PROV_STATE_MB\" varchar, \"POSTAL_ZONE\" varchar, \"COUNTRY_CODE\" int, \"ORGANIZATION_CODE\" varchar, \"WAREHOUSE_BRANCH_CODE\" int) WITH ( format = 'CSV', external_location = 's3a://lhbeta/gosales/branch' );\n\n\n\n\n\n\n\n Step 3: Generate statistics with analyze table \n\nIf you want to use the data without creating a new copy for a different table format or more table optimizations, you can generate statistics alone with analyze table.\n\n\n\n1. To generate statistics with analyze table, run the following command:\n\nanalyze <TABLE_NAME>;\n\nFor example:", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-tutorial_ingest_osbckt"}, {"document_id": "ibmcld_09958-4322-5978", "score": 20.024149616448966, "text": "\nTo create a temporal table, set DATA_VERSION_RETENTION_TIME to a nonzero value.\n\nFor detailed syntax and privileges, see [the CREATE TABLE command](https://www.ibm.com/docs/en/netezza?topic=npsscr-create-table-2).\n\nCREATE TABLE <tablename> ( <col>[, <col>\u2026 ] ) DATA_VERSION_RETENTION_TIME <number-of-days>;\n\nExample:\n\nCREATE TABLE PRODUCT (prodid int, proddesc char(100)) DATA_VERSION_RETENTION_TIME 30;\n\nWhen you insert a row into the table, the row receives a virtual insert timestamp that is equal to the commit time of the inserting transaction.\n\nWhen you delete a row from the table, the row receives a virtual delete timestamp that is equal to the commit time of the deleting (or truncating) transaction.\n\n\n\n\n\n Creating temporal schemas with the command-line \n\nTo create a temporal schema, set DATA_VERSION_RETENTION_TIME to a nonzero value.\n\nFor detailed syntax and privileges, see [the CREATE SCHEMA](https://www.ibm.com/docs/en/netezza?topic=npsscr-create-schema-2) command.\n\nCREATE SCHEMA <schema_name> DATA_VERSION_RETENTION_TIME <number-of-days>;\n\nExample:\n\nCREATE SCHEMA SCHEMA1 DATA_VERSION_RETENTION_TIME 30;\n\n\n\n\n\n Creating temporal databases with the command-line \n\nTo create a temporal database, set DATA_VERSION_RETENTION_TIME to a nonzero value.\n\nFor detailed syntax and privileges, see [the CREATE DATABASE command](https://www.ibm.com/docs/en/netezza?topic=npsscr-create-database-2).\n\nCREATE DATABASE <db_name> DATA_VERSION_RETENTION_TIME <number-of-days>;\n\nExample:\n\nCREATE DATABASE DB1 DATA_VERSION_RETENTION_TIME 30;\n\n\n\n\n\n\n\n Creating time travel objects with the web console \n\n\n\n Creating temporal tables with the web console \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-enablingdisabling_tt"}]}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03040-17293-19179", "score": 14.001848035653982, "text": "\n: You can deploy IBM Cloud Pak\u00ae for Data Version 4.5 on the following versions of Red Hat OpenShift Container Platform:\n\n\n\n* Version 4.6.29 or later fixes\n* Version 4.8.0 or later fixes\n* Version 4.10.0 or later fixes\n\n\n\nNew IBM Cloud Pak\u00ae for Data CLI commands and reference\n: Starting in IBM Cloud Pak\u00ae for Data Version 4.5, the cpd-cli includes new commands and a new command reference. For more information, see the [cpd-cli command reference](https://www.ibm.com/docs/en/cloud-paks/cp-data/4.5.x?topic=interface-cpd-cli-command-reference).\n\nMicrosoft Edge browser support\n: Beginning in Version 4.5, Microsoft Edge is fully supported for use with IBM Cloud Pak\u00ae for Data. For more information, see [Browser support](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-indexindex-browser-support).\n\nLanguage support improvements\n: Entity recognition and intent classification for Japanese and Korean languages changed to improve the reliability of Watson Assistant. You might see minor differences in how Watson Assistant handles entity recognition and intent classification.\n\nAny visible changes are most likely to be seen in dictionary-based or pattern-based entity matching. For more information about defining entities, see [Adding entities](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-entities). As a suggested practice, you can test your dialog skill with your current test framework to determine whether your workspace is impacted before you update your production workspace.\n\nIf entity values or synonyms that previously matched no longer match, you can update the entity and add a synonym with white space between the tokens, for example:\n\n\n\n* Japanese: Add \u201c\u898b \u305f\u201d as a synonym for \u201c\u898b\u305f\u201d\n* Korean: Add \u201c\uc798 \uc790 \uc694\u201d as a synonym for \u201c\uc798\uc790\uc694\u201d\n\n\n\nAssistant preview link can be disabled\n: Assistant preview now includes a toggle to disable the preview link.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-release-notes"}, {"document_id": "ibmcld_05873-80552-82182", "score": 13.708016300945554, "text": "\n* [CVE-2020-1752](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-1752).\n\n\n\n: For more information, see the [Istio security bulletin 2020-008](https://istio.io/latest/news/security/istio-security-2020-008/)\n\n\n\n\n\n Change log for 1.6, released 08 July 2020 \n\nReview the changes that are in version 1.6 of the managed Istio add-on.\n\nPrevious version\n: 1.5.7\n\nCurrent version\n: 1.6\n\nUpdates in this version\n: See the Istio release notes for [Istio 1.6](https://istio.io/latest/news/releases/1.6.x/announcing-1.6/).\n: Support is added for the istio-knative-cluster-local-gateway-enabled and istio-monitoring-telemetry options in the [managed-istio-custom ConfigMap resource](https://cloud.ibm.com/docs/containers?topic=containers-istiocustomize). You can use these options to manage inclusion of Knative apps in the service mesh and the Istio telemetry enablement. Support for IBM Cloud Monitoring is enabled for Istio by default.\n\n\n\n\n\n\n\n Version 1.5 (unsupported) \n\nVersion 1.5 of the managed Istio add-on is unsupported. (: deprecated)\n\n\n\n Differences between version 1.5 of managed and community Istio \n\nReview the following differences between the installation profiles of version 1.5 of the managed IBM Cloud Kubernetes Service Istio and version 1.5 of the community Istio.\n\nTo see options for changing settings in the managed version of Istio, see [Customizing the version 1.5 Istio installation](https://cloud.ibm.com/docs/containers?topic=containers-istiocustomize).\n\n\n\nTable 1. Differences between the managed IBM Cloud Kubernetes Service Istio and the community Istio\n\n Setting Differences in the managed Istio add-on", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-istio-changelog"}, {"document_id": "ibmcld_13724-61483-63206", "score": 13.08192905166218, "text": "\n: The POST /v1/customizations/{custom_id}/words and PUT /v1/customizations/{customization_id}/words/{word} methods now return HTTP response code 400 with the error message Part of speech is supported for ja-JP language only if you attempt to specify a part_of_speech for a language other than Japanese.\n\nChanges to response body for adding words method\n: The POST /v1/customizations/{custom_id}/words method now returns an empty response body ({}).\n\n\n\n\n\n 1 December 2016 \n\nNew Latin American Spanish voice: es-LA_SofiaVoice\n: The service includes a new voice, es-LA_SofiaVoice, which is the Latin American equivalent of the es-US_SofiaVoice voice. The most significant difference between the two voices concerns how they interpret a $ (dollar sign): The Latin American version uses the term pesos; the North American version uses the term dolares. Other minor differences might also exist between the two voices.\n\nNew US English voices: en-US_LisaVoice and en-US_MichaelVoice\n: In addition to the en-US_AllisonVoice, two more voices are now transformable with SSML voice transformation: en-US_LisaVoice and en-US_MichaelVoice.\n\nChanges to customization for Japanese\n: When you use the customization interface with Japanese, the service now matches the longest word from the word/translation pairs that are defined for a custom model. For example, consider the following two entries for a custom model:\n\n{\n\"words\": [\n{\"word\":\"\uff2e\uff39\", \"translation\":\"\u30cb\u30e5\u30fc\u30e8\u30fc\u30af\", \"part_of_speech\":\"Mesi\"},\n{\"word\":\"\uff2e\uff39\uff23\", \"translation\":\"\u30cb\u30e5\u30fc\u30e8\u30fc\u30af\u30b7\u30c6\u30a3\", \"part_of_speech\":\"Mesi\"}\n]\n}\n\nIf the service finds the string \uff2e\uff39\uff23 in the input text, it matches that word because it is a longer match than \uff2e\uff39. Previously, the service would have matched the string \uff2e\uff39.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-release-notes"}, {"document_id": "ibmcld_09919-29346-31291", "score": 12.973308830082516, "text": "\n19 April 2018 \n\nBug fixes and performance improvements\n: Added support for Japanese relations.\n: Improved German keywords.\n: Fixed a bug that caused incorrect entity mention text to be returned.\n: Fixed a bug that could cause poor results for targeted sentiment.\n: Fixed a bug that caused the returned analyzed_text to include characters that were not analyzed.\n\n\n\n\n\n 5 April 2018 \n\nWebpage improvements\n: Improved webpage content fetching. If you use the url parameter to analyze webpages, you'll see better results, especially from webpages that use framesets and cookies.\n\nKorean concept improvement\n: Minor improvements to Korean concepts.\n\n\n\n\n\n\n\n 16 March 2018 \n\nLanguage support improvements\n: Added support for German categories, relations, and semantic roles.\n: A new relation type system is used for German relations. To view details, see the [Relation types (Version 2)](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-relation-types-version-2) page.\n: Improved German keywords and sentiment.\n: Added support for Japanese categories and concepts.\n: Language detection improvements.\n: Improved webpage cleaning.\n: Improved French and German entities models. The models use a new entity type system. Check out the new entity types and subtypes on the [Entity types and subtypes (Version 2)](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-entity-types-version-2) page. When your application is compatible with the new type system, change the version date parameter in your requests to 2018-03-16 to use the new model. The following are the differences between the Version 1 type system and the Version 2 type system.\n\n\n\n* New entity types:\n\n\n\n* Date\n* Duration\n* Measure\n* Money\n* Number*\n* Percent*\n* PhoneNumber*\n* Ordinal\n* Time\n* URL*\n\n\n\n* Removed entity types:\n\n\n\n* Anatomy\n* Award\n* Broadcaster\n* Company\n* Crime\n* Drug\n* HealthCondition", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-release-notes"}, {"document_id": "ibmcld_03369-1415-3586", "score": 12.46065030930279, "text": "\nThese changes are the result of migrating the Watson Assistant platform to Java 17, where locale values are updated by using specifications in [CLDR 39](https://cldr.unicode.org/index/downloads/cldr-39).\n\nTo avoid or minimize the impact of similar changes in the future, you can use [Actions display formats](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-actions-global-settingsactions-global-settings-display-formats).\n\n\n\n\n\n 18 May 2023 \n\nDifferences in contextual entity detection for dialog skills with few annotations\n: If you have 10 to 20 examples of contextual entities in your dialog skill, you might see differences in the entities detected due to updates made to address critical vulnerabilities. The impact of these differences is limited to only newly-trained models. Existing models are unaffected. You can mitigate these differences by annotating more examples. For more information, see [Annotation-based method](https://cloud.ibm.com/docs/assistant?topic=assistant-entitiesentities-annotations-overview).\n\n\n\n\n\n 15 May 2023 \n\nChange to dialog skill context variables named request\n: If your dialog skill used a context variable that is named request, it was removed from the response payload of any /message calls in the V1 or V2 API, or through the Watson Assistant user interface. After 15 May 2023, this behavior changes. Watson Assistant doesn't remove context variables that are named request from the response payload anymore.\n\n\n\n\n\n 3 May 2023 \n\nAlgorithm version Beta provides improved intent detection and action matching\n: The algorithm version Beta now provides improved intent detection and action matching. It includes a new foundation model that is trained using a transformer architecture to improve intent detection and action matching for English.\n\nImprovements include:\n\n\n\n* Improved robustness to variations in user inputs such as typos and different inflection forms\n* Less training data required to reach the same level of performance compared to previous algorithms\n\n\n\nFor more information, see [Algorithm version and training](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-algorithm-version).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_12491-5201-7070", "score": 12.217438689361368, "text": "\n\"version_custom_metadata\": {\n\"custom_version_key\": \"custom_version_value\"\n}\n}'\n\"https://{instance_ID}.{region}.secrets-manager.appdomain.cloud/api/v2/secrets\"\n\n\n\n\n\n Adding user credentials with Terraform \n\nYou can store a username and password programmatically by using Terraform for Secrets Manager.\n\nBy default, Terraform detects any difference in the settings of an infrastructure object and creates a plan to update the remote object to match the configuration.\n\nYou can use the Terraform meta-argument ignore_changes when you create a resource with references to data that might change in the future, but ignore_changes does not affect the resource after you create it. With the ignore_changes meta-argument, you can specify resource attributes that Terraform ignores when it updates the associated remote object. When secrets are set to auto-rotation, Secrets Manager generates a new version of the secret with a computed new value of the password property.\n\nThe following example shows a query that you can use to create a username and password secret with auto-rotation, by using the Terraform lifecycle meta-argument ignore_changes for the password field.\n\n\n\n1. Create the user credentials by running the following command.\n\n\n\nresource \"ibm_sm_username_password_secret\" \"test_username_password_secret\" {\ninstance_id = local.instance_id\nregion = local.region\nsecret_group_id = \"default\"\nname = \"test-user-creds-secret\"\nusername = \"sm_username\"\npassword = \"sm_password\"\nrotation {\nauto_rotate = true\ninterval = 10\nunit = \"day\"\n}\nlifecycle {\nignore_changes = [\npassword,\n]\n}\n}\n\n\n\n2. After 10 days, the secret is auto-rotated in Secrets Manager. When you check the Terraform plan, it shows that the password field was changed outside of Terraform, as displayed in the following example.\n\n\n\nterraform plan\ndata.ibm_resource_instance.sm_resource_instance: Reading...", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials"}, {"document_id": "ibmcld_09051-6026-7724", "score": 12.071129073048173, "text": "\nThere are minor changes in this [release](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-protect-cli-reference).\n\n\n\n* [Key purge](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-protect-cli-reference) command supports purging a deleted key resulting in the permanent deletion of information related to that key. After being purged, the key is not available to be restored: ibmcloud kp key purge <keyID>.\n* Support for the new ca-tor regional [endpoint](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-protect-cli-reference); all Key Protect operations supported via CLI can be performed for this region: ibmcloud kp region-set ca-tor (sets the target endpoint to key protect ca-tor endpoint).\n\n\n\n\n\n\n\n\n\n CLI version 0.6.1 \n\nRelease date: 2021-04-30\n\n\n\n Changes \n\nThere are minor changes in this [release](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-protect-cli-reference).\n\n\n\n* Key Update command has been added, supporting transferring your key from its current key ring to a new key ring.\n\n\n\n\n\n\n\n\n\n CLI version 0.6.0 \n\nRelease date: 2021-02-25\n\n\n\n Changes \n\nThere are major changes in this [release](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-protect-cli-reference).\n\n\n\n* Key Ring support is added to the CLI supporting customization and best practices.\n* Key Alias feature is added to the CLI adding first-in-class management support.\n* Added support for Osaka (jp-osa) endpoint.\n* Instance policy command supports the new sub commands.\n* Minor changes include JSON output support in sub commands and the deprecation of some commands, features and flags.\n\n\n\n\n\n\n\n\n\n CLI version 0.5.2 \n\nRelease date: 2020-09-21\n\n\n\n Changes", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-cli-changelog"}, {"document_id": "ibmcld_09051-7272-8797", "score": 11.78281229300162, "text": "\n* Key Ring support is added to the CLI supporting customization and best practices.\n* Key Alias feature is added to the CLI adding first-in-class management support.\n* Added support for Osaka (jp-osa) endpoint.\n* Instance policy command supports the new sub commands.\n* Minor changes include JSON output support in sub commands and the deprecation of some commands, features and flags.\n\n\n\n\n\n\n\n\n\n CLI version 0.5.2 \n\nRelease date: 2020-09-21\n\n\n\n Changes \n\n\n\n* Commands that specify JSON outout (--output json) now return an empty JSON structure if there is no output.\n\n\n\n\n\n\n\n\n\n CLI version 0.5.1 (deprecated) \n\nRelease date: 2020-07-21\n\n\n\n Changes \n\n\n\n* Changed the command successful message from SUCCESS TO OK.\n* Remove additional line breaks in the response.\n* For Windows, OK and FAILED messages are the same color as the ibmcloud command colors.\n\n\n\n\n\n\n\n\n\n CLI version 0.5.0 (deprecated) \n\nRelease date: 2020-06-19\n\nDocumentation: [CLI reference, version 0.5.0](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-protect-cli-reference)\n\n\n\n Add these commands \n\n\n\n kp instance \n\n\n\n* kp instance [policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-protect-cli-referencekp-instance-policies) : list policies associated with an instance\n* kp instance [policy-update allowed-network](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-protect-cli-referencekp-instance-policy-update-allowed) : update the instance policy and set the \"allowed network\" to public-and-private or private-only", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-cli-changelog"}, {"document_id": "ibmcld_05873-81662-83420", "score": 11.604794873365787, "text": "\nReview the following differences between the installation profiles of version 1.5 of the managed IBM Cloud Kubernetes Service Istio and version 1.5 of the community Istio.\n\nTo see options for changing settings in the managed version of Istio, see [Customizing the version 1.5 Istio installation](https://cloud.ibm.com/docs/containers?topic=containers-istiocustomize).\n\n\n\nTable 1. Differences between the managed IBM Cloud Kubernetes Service Istio and the community Istio\n\n Setting Differences in the managed Istio add-on \n\n egressGateways[name: istio-egressgateway].enabled: true In the managed Istio add-on, the egress gateway is enabled by default. \n istiod, istio-ingressgateway, and istio-egressgateway In the managed Istio add-on, istiod and all Istio ingress and egress gateways are set up for basic high availability support. High availability support on these components includes the following settings by default: node anti-affinity, HorizontalPodAutoscaler, PodDisruptionBudget, and automatic scaling of replicas. \n prometheus.enabled: false In the managed Istio add-on, the Prometheus, Grafana, Jaeger, and Kiali monitoring components are disabled by default due to current security concerns in the community release of Istio that can't be adequately addressed for a production environment. \n values.global.pilot.enableProtocolSniffingForInbound and values.global.pilot.enableProtocolSniffingForOutbound In the managed Istio add-on, protocol sniffing is disabled by default until the feature becomes more stable in the community Istio. \n\n\n\n\n\n\n\n Change log for 1.5.10, released 1 September 2020 \n\nReview the changes that are in version 1.5.10 of the managed Istio add-on.\n\nPrevious version\n: 1.5.9\n\nCurrent version\n: 1.5.10\n\nUpdates in this version", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-istio-changelog"}, {"document_id": "ibmcld_03369-10944-13163", "score": 11.565244438335641, "text": "\n24 June 2022 \n\nAlgorithm version options available in more languages\n: Algorithm version options are now available in Chinese (Traditional), Japanese, and Korean. This allows you to choose which Watson Assistant algorithm to apply to your future trainings. For more information, see [Algorithm version](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-algorithm-version).\n\nImproved enhanced intent detection available in more languages\n: Previously, the exact match in enhanced intent detection was improved to better handle small differences between training examples and runtime utterances when the differences do not change the meaning of a sentence. For example, suppose in your training examples, covid-19 is in the covid intent and @doctortype_facilitytype around Palm Beach is in the find_provide_master intent. In this example, the @doctortype_facilitytype direct entity reference contains entity values, including hospital. At run time, covid19 is predicted as 100% confident for the covid intent, and hospital around palm beach is predicted as 100% confident for the find_provide_master intent.\n\nThis update now includes the following languages: Chinese (Simplified), Chinese (Traditional), German, Japanese, Korean, and Portuguese. For more information, see [Accessing intents](https://cloud.ibm.com/docs/assistant?topic=assistant-expression-languageexpression-language-intent).\n\n\n\n\n\n 16 June 2022 \n\nAlgorithm version\n: Algorithm version allows you to choose which Watson Assistant algorithm to apply to your future trainings. In the Options section of a dialog skill, Algorithm Version replaces Intent Detection. For more information, see [Algorithm version](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-algorithm-version).\n\nAlgorithm beta version (2022-06-10)\n: Algorithm beta version (2022-06-10) includes a new irrelevance detection algorithm to improve off-topic detection accuracy. Utterances with similar meanings are expected to have more similar confidences in comparison to previous irrelevance detection algorithms. For example, in the Customer Care Sample Skill, the training utterance please suggest route from times square has 100% confidence at runtime.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09275-30068-31881", "score": 23.614359213562224, "text": "\nFor example, you can reuse your logging resources across different environments for your stage, pre-production, and production logging instances. [Learn more](https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-reuse_resource_definitions).\n\nBackup logging resource definitions into a version control system such as a git repository where you can control access to the archived files and manage versions.\n\n\n\n\n\n Archive log data to a COS bucket \n\nEnable archiving of your data from a logging instance to an IBM Cloud Object Storage (COS) bucket.\n\nAfter you provision a logging instance, you can configure archiving to an IBM Cloud Object Storage (COS) bucket. You can create different types of buckets based on your requirements.\n\nWhen you plan the bucket for a logging instance, consider the following information:\n\n\n\nTable 5. COS bucket requirements\n\n Requirement Question to answer Information \n\n Type of workload [1] How often do you need to access the data? [Information about storage classes](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-classesclasses-about) \n Retention policy [2] Do you need to protect data from being deleted? [Information about Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest?", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-adoption"}, {"document_id": "ibmcld_02361-22962-24900", "score": 23.226277346716657, "text": "\nIn the UI, you can define custom views, dashboards, parsing templates, screens, and exclusion rules that you can use to view and analyze data.\n\nTo reuse resource definitions that you define in your auditing instance, you can export these resources from an IBM Cloud Activity Tracker instance as a JSON file. Then, you can import the definitions into other auditing instances. For example, you can reuse your resources across different environments for your stage, pre-production, and production instances. [Learn more](https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-reuse_resource_definitions).\n\nBackup resource definitions into a version control system such as a git repository where you can control access to the archived files and manage versions.\n\n\n\n\n\n Archive log data to a COS bucket \n\nEnable archiving of your data from an auditing instance to an IBM Cloud Object Storage (COS) bucket.\n\nAfter you provision an auditing instance, you can configure archiving to an IBM Cloud Object Storage (COS) bucket. You can create different types of buckets based on your requirements.\n\nWhen you plan the bucket for an auditing instance, consider the following information:\n\n\n\nTable 5. COS bucket requirements\n\n Requirement Question to answer Information \n\n Type of workload [1] How often do you need to access the data? [Information about storage classes](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-classesclasses-about) \n Retention policy [2] Do you need to protect data from being deleted? [Information about Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time?", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-adoption"}, {"document_id": "ibmcld_05075-8514-10699", "score": 22.245712077852694, "text": "\nDeleting a versioned object creates a delete marker. The object may appear to be deleted, but if the object is protected it is not possible to delete the protected version. Delete markers themselves are not protected.\n\n\n\n\n\n Replication \n\nObject Lock cannot be used on the source bucket for replication, only on the destination. Objects will be assigned the default retention period.\n\n\n\n\n\n Key Management Systems \n\nProtected objects will be encrypted using the root key of the bucket. When Object Lock is enabled on a bucket, the root key hosted by Key Protect or Hyper Protect Crypto Services is protected from deletion as long as an associated bucket has Object Lock enabled. This prevents crypto shredding of protected objects.\n\n\n\n\n\n Lifecycle configurations \n\nIt is possible to enable lifecycle policies that [archive locked objects](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-archive), but naturally not those that [expire objects](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-expiry) under retention or legal hold (unprotected objects in the bucket can still be expired).\n\n\n\n\n\n Immutable Object Storage \n\nObject Lock is an alternative to the retention policies available when using Immutable Object Storage. As Object Lock requires versioning to be enabled, and Immutable Object Storage is not compatible with versioning, it is not possible to have both WORM solutions enabled on the same bucket. It is possible to have a mix of buckets in a Service Instance, each using either Immutable Object Storage or Object Lock.\n\n\n\n\n\n Object Tagging \n\nThere are no restrictions on adding or modifying tags on a protected object.\n\n\n\n\n\n Other interactions \n\nThere should be no adverse interactions when using Object Lock with other Object Storage features, such as setting CORS policies, setting IP firewalls or condition based restrictions, bucket quotas, or Code Engine.\n\n\n\n\n\n\n\n IAM actions \n\nThere are new IAM actions associated with Object Lock.\n\n\n\n IAM Action Role \n\n cloud-object-storage.bucket.get_object_lock_configuration Manager, Writer, Reader \n cloud-object-storage.bucket.put_object_lock_configuration Manager, Writer", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-ol-overview"}, {"document_id": "ibmcld_04866-7-2136", "score": 21.76465317634823, "text": "\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-7-2136", "score": 21.76465317634823, "text": "\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05138-7979-9034", "score": 21.71603471383248, "text": "\nAfter your bucket is created with Activity Tracker and Monitoring, it may take a few minutes for the rules to take effect.\n\nYou are now ready to store data in a secure content store with encryption, monitoring, and audit observability!\n\n\n\n\n\n Get started by uploading data \n\n\n\n* See [uploading data](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-upload) for more information.\n\n\n\n\n\n\n\n Add capabilities \n\nAdd capabilities to protect objects from ransomware and accidental deletion such as [versioning](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-versioning) and [immutable retention polices](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-ol-overview) for supporting immutable storage, and immutable backup and archive data.\n\n\n\n\n\n Library of Object Storage tutorials \n\nCheck out the IBM Cloud Tutorials library for more tutorials when deploying solutions with [Cloud Object Storage](https://cloud.ibm.com/docs?tab=tutorials&page=1&pageSize=20&tags=cloud-object-storage).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-secure-content-store"}, {"document_id": "ibmcld_02361-24500-26305", "score": 21.703924331057955, "text": "\n[Information about Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-adoption"}, {"document_id": "ibmcld_04960-1454-3384", "score": 21.468546958670657, "text": "\nSee [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availability) for more details.\n\nIt isn't possible to use Aspera high-speed transfer if a targeted bucket has an [Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable) policy.\n\n\n\n Using the console \n\nIf you add objects by using the console in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availability), you are prompted with an option to install the Aspera Connect client. This browser plug-in provides Aspera high-speed transfer to upload files or folders.\n\n\n\n Install Aspera Connect \n\n\n\n1. Select Install Aspera Connect client.\n2. Follow the installation instructions for your operating system and browser.\n3. Resume file or folder upload.\n\n\n\nThe Aspera Connect plug-in can also be installed from the [Aspera website](https://downloads.asperasoft.com/connect2/) directly. For help troubleshooting issues with the Aspera Connect plug-in, [see the documentation](https://downloads.asperasoft.com/en/documentation/8).\n\nAfter the plug-in is installed, you have the option to set Aspera high-speed transfer as the default for any uploads to the target bucket that use the same browser. Select Remember my browser preferences. Options are also available in the bucket configuration page under Transfer options. These options allow you to choose between Standard and High speed as the default transport for uploads and downloads.\n\nTypically, using the IBM Cloud Object Storage web-based console isn't the most common way to use Object Storage. The Standard transfer option limits objects size to 200 MB and the file name and key will be the same. Support for larger object sizes and improved performance (depending on network factors) is provided by Aspera high-speed transfer.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-aspera"}, {"document_id": "ibmcld_04862-1468-3398", "score": 21.468546958670657, "text": "\nSee [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availability) for more details.\n\nIt isn't possible to use Aspera high-speed transfer if a targeted bucket has an [Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable) policy.\n\n\n\n Using the console \n\nIf you add objects by using the console in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availability), you are prompted with an option to install the Aspera Connect client. This browser plug-in provides Aspera high-speed transfer to upload files or folders.\n\n\n\n Install Aspera Connect \n\n\n\n1. Select Install Aspera Connect client.\n2. Follow the installation instructions for your operating system and browser.\n3. Resume file or folder upload.\n\n\n\nThe Aspera Connect plug-in can also be installed from the [Aspera website](https://downloads.asperasoft.com/connect2/) directly. For help troubleshooting issues with the Aspera Connect plug-in, [see the documentation](https://downloads.asperasoft.com/en/documentation/8).\n\nAfter the plug-in is installed, you have the option to set Aspera high-speed transfer as the default for any uploads to the target bucket that use the same browser. Select Remember my browser preferences. Options are also available in the bucket configuration page under Transfer options. These options allow you to choose between Standard and High speed as the default transport for uploads and downloads.\n\nTypically, using the IBM Cloud Object Storage web-based console isn't the most common way to use Object Storage. The Standard transfer option limits objects size to 200 MB and the file name and key will be the same. Support for larger object sizes and improved performance (depending on network factors) is provided by Aspera high-speed transfer.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-aspera"}, {"document_id": "ibmcld_05168-15740-17188", "score": 21.298785397776854, "text": "\nfmt.Println(r)\nfmt.Println(e)\n\n}\n\nShow more\n\nThe typical response is exemplified here.\n\n{\nRules: [{\nFilter: {\n\n},\nID: \"id3\",\nStatus: \"Enabled\",\nTransitions: {\nDays: 5,\nStorageClass: \"GLACIER\"\n}]\n}]\n}\n\n\n\n\n\n Immutable Object Storage \n\nUsers can configure buckets with an Immutable Object Storage policy to prevent objects from being modified or deleted for a defined period of time. The retention period can be specified on a per-object basis, or objects can inherit a default retention period set on the bucket. It is also possible to set open-ended and permanent retention periods. Immutable Object Storage meets the rules set forth by the SEC governing record retention, and IBM Cloud administrators are unable to bypass these restrictions.\n\nNote: Immutable Object Storage does not support Aspera transfers via the SDK to upload objects or directories at this stage.\n\nfunc main() {\n\n// Create Client\nsess := session.Must(session.NewSession())\nclient := s3.New(sess, conf)\n\n// Create a bucket\ninput := &s3.CreateBucketInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\n}\nd, e := client.CreateBucket(input)\nfmt.Println(d) // should print an empty bracket\nfmt.Println(e) // should print <nil>\n\n// PUT BUCKET PROTECTION CONFIGURATION\npInput := &s3.PutBucketProtectionConfigurationInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\nProtectionConfiguration: &s3.ProtectionConfiguration{\nDefaultRetention: &s3.BucketProtectionDefaultRetention{\nDays: aws.Int64(100),\n},", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-using-go"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16306-8539-10329", "score": 34.70546219024649, "text": "\nIf no utterance is received before the timeout occurs, the phone integration sends a message to the assistant that includes the post_response_timeout_occurred property set to true. \n cdr_custom_data Object A JSON object containing key/value pairs to be stored in the CDR record for the call. Each time this object is sent, its contents are merged with data sent previously during the call. \n turn_settings.timeout_count Integer The time (in milliseconds) to wait for Watson Assistant to finish processing each conversation turn. \n\n\n\n\n\n\n\n Example request JSON \n\n\"voice_telephony\" : {\n\"post_response_timeout_count\":10000,\n\"final_utterance_timeout_count\":30000,\n\"turn_settings\": {\n\"timeout_count\": 5000\n},\n\"cdr_custom_data\" : {\n\"custom_data_1\": \"data 1\",\n\"custom_data_2\": \"data 2\"\n}\n}\n\n\n\n\n\n\n\n text_messaging \n\nIncluded only if the SMS with Twilio integration is in use.\n\n\n\n Properties \n\nProperties contained in the private object are treated as private variables, which are not included in logs.\n\n\n\nProperties of the text_messaging object\n\n Name Type Description \n\n assistant_phone_number String The phone number associated with with the Watson Assistant end of the conversation. \n private.user_phone_number String The phone number from which the customer's SMS message originated. \n\n\n\n\n\n\n\n Example JSON \n\n\"text_messaging\": {\n\"private\":{\n\"user_phone_number\":\"+18595553456\"\n},\n\"assistant_phone_number\":\"+18885556789\"\n}\n\n\n\n\n\n\n\n whatsapp \n\nIncluded only if the WhatsApp integration is in use.\n\n\n\n Properties \n\nProperties contained in the private object are treated as private variables, which are not included in logs.\n\n\n\nProperties of the whatsapp object\n\n Name Type Description \n\n assistant_phone_number String The phone number associated with with the Watson Assistant end of the conversation.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-expression-integration-variables"}, {"document_id": "ibmcld_16261-12076-14011", "score": 34.68289504105475, "text": "\nBecause we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.\n\nIn addition to maintaining our place in the conversation, the context can also contain action variables that store any other data you want to pass back and forth between your application and the assistant. This can include persistent data you want to maintain throughout the conversation (such as a customer's name or account number), or any other data you want to track (such as the contents of a shopping cart or user preferences).\n\n\n\n* Python\n* Node\n\n\n\n Example 3: Preserves context to maintain state.\n\nfrom ibm_watson import AssistantV2\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n\n Create Assistant service object.\nauthenticator = IAMAuthenticator('{apikey}') replace with API key\nassistant = AssistantV2(\nversion = '2021-11-27',\nauthenticator = authenticator\n)\nassistant.set_service_url('{url}') replace with service instance URL\nassistant_id = '{environment_id}' replace with environment ID\n\n Initialize with empty message to start the conversation.\nmessage_input = {\n'message_type:': 'text',\n'text': ''\n}\ncontext = {}\n\n Initialize with empty message to start the conversation.\nmessage_input = {\n'message_type:': 'text',\n'text': ''\n}\ncontext = {}\n\n Main input/output loop\nwhile message_input['text'] != 'quit':\n\n Send message to assistant.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-client"}, {"document_id": "ibmcld_16261-10613-12744", "score": 33.71271905944459, "text": "\nBecause we need a way to end the conversation, the client app is also watching for the literal command quit to indicate that the program should exit.\n\nBut something still isn't right:\n\nWelcome to the Watson Assistant example. What's your name?\n>> Robert\nI'm afraid I don't understand. Please rephrase your question.\n>> I want to make an appointment.\nWhat day would you like to come in?\n>> Thursday\nI'm afraid I don't understand. Please rephrase your question.\n>>\n\nThe assistant is starting out with the correct greeting, but it doesn't understand when you tell it your name. And if you tell it you want to make an appointment, the correct action is triggered; but once again, it doesn't understand when you answer the follow-up question.\n\nThis is happening because we are using the stateless message method, which means that it is the responsibility of our client application to maintain state information for the conversation. Because we are not yet doing anything to maintain state, the assistant sees every round of user input as the first turn of a new conversation. Because it has no memory of asking a question, it tries to interpret your answer as a new question or request.\n\n\n\n\n\n Maintaining state \n\nState information for your conversation is maintained using the context. The context is an object that is passed back and forth between your application and the assistant, storing information that can be preserved and updated as the conversation goes on. Because we are using the stateless message method, the assistant does not store the context, so it is the responsibility of our client application to maintain it from one turn of the conversation to the next.\n\nThe context includes a session ID for each conversation, as well as a counter that is incremented with each turn of the conversation. The assistant updates the context and returns it with each response. But our previous version of the example did not preserve the context, so these updates were lost, and each round of input appeared to be the start of a new conversation. We can fix that by saving the context and sending it back to the assistant each time.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-client"}, {"document_id": "ibmcld_03363-4-2165", "score": 33.14729830875145, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_16262-6573-7996", "score": 33.03333723149295, "text": "\n{\n\"output\": {\n\"generic\": [!\n{\n\"response_type\": \"text\",\n\"text\": \"Welcome to the Watson Assistant example\"\n}\n],\n\"intents\": [\n{\n\"intent\": \"hello\",\n\"confidence\": 1\n}\n],\n\"entities\": []\n},\n\"user_id\": \"my_user_id\",\n\"context\": {\n\"global\": {\n\"system\": {\n\"turn_count\": 1,\n\"user_id\": \"my_user_id\"\n}\n},\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"account_number\": \"123456\"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n Restoring conversation state \n\nIn some situations, you might want the ability to restore a conversation to a previous state.\n\nYou can use the export option on stateful message requests to specify that you want the context object in the response to include complete session state data. If you specify true for this option, the returned skill context includes an encoded state property that represents the current conversation state.\n\nIf you are using the stateful message API, the service stores conversation state data only for the life of the session. However, if you save this context data (including state) and send it back to the service with a subsequent message request, you can restore the conversation to the same state, even if the original session expired or was deleted.\n\nIf you are using the stateless message API, the state property is always included in responses (along with the rest of context). Although stateless sessions do not expire, you can still use this state data to reset a conversation to a previous state.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-client-get-context"}, {"document_id": "ibmcld_03363-4413-6535", "score": 32.98568649212893, "text": "\nFor more information, see [Ending the conversation gracefully](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-startdialog-start-anything-else).\n\nThe containment and coverage metrics are available to Plus or Enterprise plan users.\n* Total conversations: The total number of conversations between active users and your assistant during the selected time period. This number counts exchanges in which the welcome message is displayed to a user, even if the user doesn't respond.\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter to be specified with the messages. This value is typically specified by all integrations because it is used for billing purposes. For more information, see [User-based plans explained](https://cloud.ibm.com/docs/assistant?topic=assistant-admin-managing-planadmin-managing-plan-user-based).\n\n\n\n\n\n\n\n Controls \n\nYou can use the following controls to filter the information:\n\n\n\n* Time period control - Use this control to choose the period for which data is displayed. This control affects all data shown on the page: not just the number of conversations displayed in the graph, but also the statistics displayed along with the graph, and the lists of top intents and entities.\n\nThe statistics can cover a longer time period than the period for which logs of conversations are retained.\n\n![Time period control](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/oview-time.png)\n\nYou can choose whether to view data for a single day, a week, a month, or a quarter.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_16322-7-2220", "score": 32.68527514624036, "text": "\nPhone integration context variables \n\nYou can use context variables to manage the flow of conversations with customers who interact with your assistant over the telephone.\n\nThe following tables describe the context variables that have special meaning in the context of the phone integration. They should not be used for any purpose other than the documented use.\n\n\n\n Context variables that are set by the phone channel \n\n\n\nContext variables set by the phone channel\n\n Name Type Description \n\n sip_call_id string The SIP call ID associated with the Watson Assistant session. \n sip_custom_invite_headers object A JSON object containing key/value pairs defining SIP headers that are pulled from the initial SIP INVITE request and passed to the Watson Assistant service (for example, {\"Custom-Header1\": \"123\"}). \n private.sip_from_uri string The SIP From URI associated with the Watson Assistant service. \n private.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.\n\n\n\nInput parameters set by the phone channel\n\n Name Type Description \n\n post_response_timeout_occurred boolean Whether the post response timeout expired. \n barge_in_occurred boolean Whether barge-in occurred. \n final_utterance_timeout_occurred true or false Whether the final utterance timeout expired. \n dtmf_collection_succeeded boolean Whether the DTMF collection succeeded or failed. When true, a DTMF collection succeeded, and returns the expected number of digits. When false, a DTMF collection failed to collect the specified number of digits. Even when dtmf_collection_succeeded is false, all collected digits are passed to the dialog in the input string of the turn request. \n is_dtmf boolean Whether the input to Watson Assistant is dual-tone multi-frequency signaling (DTMF).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-context"}, {"document_id": "ibmcld_03036-2789-4951", "score": 32.542407654567825, "text": "\nIf you have [selected a data source](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_03367-2935-4844", "score": 32.176545716916245, "text": "\nprivate.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.\n\n\n\nInput parameters set by the phone channel\n\n Name Type Description \n\n post_response_timeout_occurred boolean Whether the post response timeout expired. \n barge_in_occurred boolean Whether barge-in occurred. \n final_utterance_timeout_occurred true or false Whether the final utterance timeout expired. \n dtmf_collection_succeeded boolean Whether the DTMF collection succeeded or failed. When true, a DTMF collection succeeded, and returns the expected number of digits. When false, a DTMF collection failed to collect the specified number of digits. Even when dtmf_collection_succeeded is false, all collected digits are passed to the dialog in the input string of the turn request. \n is_dtmf boolean Whether the input to Watson Assistant is dual-tone multi-frequency signaling (DTMF). \n speech_to_text_result object The final response from the Speech to Text service in JSON format, including the transcript and confidence score for the top hypothesis and any alternatives. The format matches exactly the format that is received from the Speech to Text service. (For more information, see the [Speech to Text API documentation](https://cloud.ibm.com/apidocs/speech-to-textrecognize).) \n\n\n\n\n\n Example \n\n{\n\"input\": {\n\"text\": \"agent \",\n\"integrations\": {\n\"voice_telephony\": {\n\"speech_to_text_result\": {\n\"result_index\": 0,\n\"stopTimestamp\": \"2021-09-29T17:43:31.036Z\",\n\"transaction_ids\": {", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-phone-context"}, {"document_id": "ibmcld_03367-1712-3458", "score": 32.1387467256472, "text": "\nIf this time is exceeded, the phone integration tries again to contact Watson Assistant. If the service still can't be reached, the call fails. N/A \n cdr_custom_data object Any JSON key/value pairs to collect and store with the CDR record at the end of the phone call. Each time this object is received, it is merged with any previously received cdr_custom_data context. N/A \n\n\n\n\n\n Example \n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text\",\n\"text\": \"Hello\"\n}\n]\n},\n\"context\": {\n\"integrations\": {\n\"voice_telephony\": {\n\"post_response_timeout_count\": 10000,\n\"turn_settings\": {\n\"timeout_count\": 5000\n},\n\"cdr_custom_data\": {\n\"key1\": \"value1\",\n\"key2\": \"value2\"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n\n\n Context variables that are set by the phone channel \n\n\n\nContext variables set by the phone channel\n\n Name Type Description \n\n sip_call_id string The SIP call ID associated with the Watson Assistant session. \n sip_custom_invite_headers object A JSON object containing key/value pairs defining SIP headers that are pulled from the initial SIP INVITE request and passed to the Watson Assistant service (for example, {\"Custom-Header1\": \"123\"}). \n private.sip_from_uri string The SIP From URI associated with the Watson Assistant service. \n private.sip_request_uri string The SIP request URI that started the conversation session. \n private.sip_to_uri string The SIP To URI associated with the conversation session. \n private.user_phone_number string The phone number that the call was received from. \n assistant_phone_number string The phone number associated with the Watson Assistant side that received the phone call. \n\n\n\n\n\n\n\n Input parameters that are set by the phone channel \n\nThe following input parameters are only valid for the current conversation turn.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-phone-context"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04866-6428-8391", "score": 24.700591114348928, "text": "\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https://cloud.ibm.com/docs/cloud-object-storage/images/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-6428-8442", "score": 24.48021562379038, "text": "\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https://cloud.ibm.com/docs/images/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_03618-1804-3397", "score": 22.7399012211904, "text": "\nThe TPM device is integrated within the server system and provides a range of Intel TXT security-related functions.\n\n\n\n\n\n What does Intel TXT does for you \n\nIntel TXT is especially advantageous for large enterprises subject to compliance and audit regulations, such as healthcare, financial services, and government organizations. It helps assure that tracking of all trusted resources can be integrated, managed, and reported on with the relevant compliance organizations (HIPAA, PCI, FedRAMP, ISO, FISMA, and SSAE 16). For the first time, these organizations are able to certify that a cloud computing system is secured for workloads such as\n\n\n\n* Governance and enterprise risk\n* Information and lifecycle management\n* Compliance and audit\n* Application security\n* Identity and access management\n* Incident response\n\n\n\nFor more information about Intel TXT on IBM Cloud Bare Metal Servers, see [Intel\u00ae Trusted Execution Technology](https://www.ibm.com/cloud/bare-metal-servers/intel-txt).\n\n\n\n\n\n Special technical notice \n\nIntel TXT is provided by Intel\u00ae and operates on the IBM Cloud Bare Metal Servers that require specific technical knowledge to support and manage. The IBM Cloud current delivery model can turn Intel\u00ae TXT either on or off. IBM Cloud can't assist with configuration of Intel TXT settings because of the sensitivity of customer environments and data. The recommendation is that you either include staff who is trained in Intel TXT technologies or engage with a consulting firm with expertise in orchestrating root of trust and measured launch environment (MLE) architecture.", "title": "", "source": "https://cloud.ibm.com/docs/bare-metal?topic=bare-metal-bm-hardware-monitroing-security-controls"}, {"document_id": "ibmcld_07679-0-891", "score": 20.944463049056196, "text": "\n\n\n\n\n\n\n  AU-14 - Session Audit \n\n\n\n  Control requirements \n\nAU-14 - 0\n:   The information system provides the capability for authorized users to select a user session to capture/record or view/hear.\n\n\n\n\n\n  Implementation guidance \n\nSee the resources that follow to learn more about how to implement this control.\n\n\n\n*  [Running operator actions through a bastion host](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-bastion)\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nSession audits include, for example, monitoring keystrokes, tracking websites visited, and recording information and/or file transfers. Session auditing activities are developed, integrated, and used in consultation with legal counsel in accordance with applicable federal laws, Executive Orders, directives, policies, regulations, or standards.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-au-14"}, {"document_id": "ibmcld_14708-2831-4126", "score": 19.074766949189552, "text": "\nThis action allows data to be received from the proxy servers during backup and restore processes.\n\nufw status\nStatus: active\nTo Action From\n-- ------ ----\n6162/tcp ALLOW 10.38.207.157 Allow Veeam Mgmt from Veeam BUR server\n2500/tcp ALLOW Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n2501/tcp ALLOW Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n6162/tcp ALLOW OUT Anywhere Veeam transport rule\n2500/tcp ALLOW OUT Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n2501/tcp ALLOW OUT Anywhere Veeam rule 876f0752-7209-4e8b-8b34-fa0af7dbced4\n\nZoom\n\n![Veeam backup](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/veeam-cr-sa-lhbr-proxy.svg)\n\nFigure 2. Veeam backup\n\n\n\n Best practices for a Linux hardened repository \n\nThe [Compliance assessment report (by Cohasset)](https://www.veeam.com/wp-compliance-assessment-report-cohasset.html) describes the settings that must be configured to become compliant with the following regulations:\n\n\n\n* FINRA Rule 4511.\n* SEC Rule 17a-4(f).\n* CFTC Rule 1 .31 (c)-(d).\n\n\n\nThe previous assessment report considers the following details as best practice for a Linux hardened repository:\n\n\n\n* The Linux hardened repository can be independent or Scale-out backup repository.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr"}, {"document_id": "ibmcld_06104-3423-5552", "score": 18.274354629565806, "text": "\nFor data that is read and written, it is important to understand if the operations are read-heavy, write-heavy, or balanced.\n\nDetermine the frequency that your data is accessed.\n: Hot data: Data that is accessed frequently. Common use cases are web or mobile apps.\n: Cool or warm data: Data that is accessed infrequently, such as once a month or less. Common use cases are archives, short-term data retention, or disaster recovery.\n: Cold data: Data that is rarely accessed, if at all. Common use cases are archives, long-term backups, historical data.\n: Frozen data: Data that is not accessed and that you need to keep due to legal reasons.\n\nIf you can't predict the frequency or the frequency does not follow a strict pattern, determine whether your workloads are read-heavy, write-heavy, or balanced. Then, look at the storage option that fits your workload and investigate what storage tier gives you the flexibility that you need. For example, IBM Cloud Object Storage provides a flex storage class that considers how frequent data is accessed in a month and takes into account this measurement to optimize your monthly billing.\n\nInvestigate if your data must be shared across multiple app instances, zones, or regions.\n: Access across pods: When you use Kubernetes persistent volumes to access your storage, you can determine the number of pods that can mount the volume at the same time. Some storage solutions can be accessed by one pod at a time only. With other storage solutions, you can share volume across multiple pods.\n: Access across zones and regions: You might require your data to be accessible across zones or regions. Some storage solutions, such as file and block storage, are data center-specific and can't be shared across zones in a multizone cluster setup.\n\nIf you want to make your data accessible across zones or regions, make sure to consult your legal department to verify that your data can be stored in multiple zones or a different country.\n\nUnderstand other storage characteristics that impact your choice.\n: Consistency: The guarantee that a read operation returns the latest version of a file.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-storage-plan"}, {"document_id": "ibmcld_10545-3427-5556", "score": 18.274354629565806, "text": "\nFor data that is read and written, it is important to understand if the operations are read-heavy, write-heavy, or balanced.\n\nDetermine the frequency that your data is accessed.\n: Hot data: Data that is accessed frequently. Common use cases are web or mobile apps.\n: Cool or warm data: Data that is accessed infrequently, such as once a month or less. Common use cases are archives, short-term data retention, or disaster recovery.\n: Cold data: Data that is rarely accessed, if at all. Common use cases are archives, long-term backups, historical data.\n: Frozen data: Data that is not accessed and that you need to keep due to legal reasons.\n\nIf you can't predict the frequency or the frequency does not follow a strict pattern, determine whether your workloads are read-heavy, write-heavy, or balanced. Then, look at the storage option that fits your workload and investigate what storage tier gives you the flexibility that you need. For example, IBM Cloud Object Storage provides a flex storage class that considers how frequent data is accessed in a month and takes into account this measurement to optimize your monthly billing.\n\nInvestigate if your data must be shared across multiple app instances, zones, or regions.\n: Access across pods: When you use Kubernetes persistent volumes to access your storage, you can determine the number of pods that can mount the volume at the same time. Some storage solutions can be accessed by one pod at a time only. With other storage solutions, you can share volume across multiple pods.\n: Access across zones and regions: You might require your data to be accessible across zones or regions. Some storage solutions, such as file and block storage, are data center-specific and can't be shared across zones in a multizone cluster setup.\n\nIf you want to make your data accessible across zones or regions, make sure to consult your legal department to verify that your data can be stored in multiple zones or a different country.\n\nUnderstand other storage characteristics that impact your choice.\n: Consistency: The guarantee that a read operation returns the latest version of a file.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-storage-plan"}, {"document_id": "ibmcld_05088-40304-41974", "score": 18.176953705171584, "text": "\nAdd or remove a legal hold to or from a protected object \n\nThe object can support 100 legal holds:\n\n\n\n* A legal hold identifier is a string of maximum length 64 characters and a minimum length of 1 character. Valid characters are letters, numbers, !, _, ., , (, ), - and \\.\n* If the addition of the given legal hold exceeds 100 total legal holds on the object, the new legal hold will not be added, a 400 error is returned.\n* If an identifier is too long, it will not be added to the object and a 400 error is returned.\n* If an identifier contains invalid characters, it will not be added to the object and a 400 error is returned.\n* If an identifier is already in use on an object, the existing legal hold is not modified and the response indicates that the identifier was already in use with a 409 error.\n* If an object does not have retention period metadata, a 400 error is returned and adding or removing a legal hold is not allowed.\n\n\n\nThe user making adding or removing a legal hold must have Manager permissions for this bucket.\n\ndef add_legal_hold_to_object(bucket_name, object_name, legal_hold_id):\nprint(\"Adding legal hold {0} to object {1} in bucket {2}n\".format(legal_hold_id, object_name, bucket_name))\n\ncos.add_legal_hold(\nBucket=bucket_name,\nKey=object_name,\nRetentionLegalHoldId=legal_hold_id\n)\n\nprint(\"Legal hold {0} added to object {1} in bucket {2}!n\".format(legal_hold_id, object_name, bucket_name))\n\ndef delete_legal_hold_from_object(bucket_name, object_name, legal_hold_id):\nprint(\"Deleting legal hold {0} from object {1} in bucket {2}n\".format(legal_hold_id, object_name, bucket_name))\n\ncos.delete_legal_hold(\nBucket=bucket_name,\nKey=object_name,", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-python"}, {"document_id": "ibmcld_14708-3638-5837", "score": 18.157541376740706, "text": "\nThe [Compliance assessment report (by Cohasset)](https://www.veeam.com/wp-compliance-assessment-report-cohasset.html) describes the settings that must be configured to become compliant with the following regulations:\n\n\n\n* FINRA Rule 4511.\n* SEC Rule 17a-4(f).\n* CFTC Rule 1 .31 (c)-(d).\n\n\n\nThe previous assessment report considers the following details as best practice for a Linux hardened repository:\n\n\n\n* The Linux hardened repository can be independent or Scale-out backup repository. A repository that retains immutable backup files for compliance with SEC 17a-4(f) must be configured as a stand-alone backup repository as a Veeam Scale-Out backup Repository is not compliant with this rule.\n* It is recommended that the name and description attributes for the repository include the word \u201cimmutable\" when the Linux hardened repository feature is enabled.\n* To protect against the possibility of premature deletion of backup files that can result from accelerating the system time clock, Linux OS must be configured to synchronize with a secure time source. For example, with a network time protocol (NTP) clock.\n* Ensure separation of duties by assigning management of Linux hardened repositories to a team other than backup administrators.\n* Veeam recommends XFS for performance and space efficiency reasons (block cloning support). Due to the requirement for periodic full backups, means that due to fast cloning, synthetic full backups take no physical disk space, except for metadata.\n* Only backup job configurations with forward incremental with synthetic or active full are supported. Forward incremental with synthetic full is the default backup job setting.\n* For backup copy jobs, GFS must be enabled.\n* Encryption of backup files is available as follows:\n\n\n\n* When configured in a backup job, Veeam Backup and Replication can use 256-bit AES block cypher encryption.\n* For data in transit, a global network traffic rule can be configured to enable all traffic to be encrypted through 256-bit AES encryption. When enable and two backup infrastructure components need to communicate, a dynamic key is generated by the backup server and communicated to each node over a secure channel.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr"}, {"document_id": "ibmcld_05070-23003-24661", "score": 17.617652105814184, "text": "\nCopySource: sourceBucketName + '/' + sourceObjectName,\nRetentionDirective: 'Copy'\n}).promise()\n.then((data) => {\nconsole.log(Protected object copied from ${sourceBucketName}/${sourceObjectName} to ${destinationBucketName}/${newObjectName});\n})\n.catch((e) => {\nconsole.log(ERROR: ${e.code} - ${e.message}n);\n});\n}\nShow more\n\n\n\n\n\n Add or remove a legal hold to or from a protected object \n\nThe object can support 100 legal holds:\n\n\n\n* A legal hold identifier is a string of maximum length 64 characters and a minimum length of 1 character. Valid characters are letters, numbers, !, _, ., , (, ), - and \\.\n* If the addition of the given legal hold exceeds 100 total legal holds on the object, the new legal hold will not be added, a 400 error will be returned.\n* If an identifier is too long it will not be added to the object and a 400 error is returned.\n* If an identifier contains invalid characters, it will not be added to the object and a 400 error is returned.\n* If an identifier is already in use on an object, the existing legal hold is not modified and the response indicates the identifier was already in use with a 409 error.\n* If an object does not have retention period metadata, a 400 error is returned and adding or removing a legal hold is not allowed.\n\n\n\nThe user making adding or removing a legal hold must have Manager permissions for this bucket.\n\nfunction addLegalHoldToObject(bucketName, objectName, legalHoldId) {\nconsole.log(Adding legal hold ${legalHoldId} to object ${objectName} in bucket ${bucketName});\nreturn cos.client.addLegalHold({\nBucket: bucketName,\nKey: objectId,\nRetentionLegalHoldId: legalHoldId\n}).promise()\n.then(() => {", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-node"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13498-93516-95314", "score": 3.5940799623010435, "text": "\n-A All number types Unary negative operator. The type of the result is the same as the type of A. \n +A All number types Unary positive operator. The type of the result is the same as the type of A. \n A All number types Bitwise NOT operator. The type of the result is the same as the type of A. \n\n\n\n\n\n\n\n Arithmetic operators \n\n\n\nTable 51. Arithmetic operators.\n\n Operator Operand types Description \n\n A + B All number types Returns the result of adding A and B. The type of the result is the same as the type of the operand that is highest in the type hierarchy. For example, if A is of type FLOAT and B is of type INT, the result is of type FLOAT. \n A - B All number types Returns the result of subtracting B from A. The type of the result is the same as the type of the operand that is highest in the type hierarchy. For example, if A is of type FLOAT and B is of type INT, the result is of type FLOAT. \n A * B All number types Returns the result of multiplying A and B. The type of the result is the same as the type of the operand that is highest in the type hierarchy. For example, if A is of type FLOAT and B is of type INT, the result is of type FLOAT. If the operation causes an overflow, cast at least one of the operators to a type that is higher in the type hierarchy. \n A / B All number types Returns the result of dividing A by B. The type of the result is DOUBLE. \n A % B All number types Returns the remainder after dividing A by B. For example, 13.7 % 3 returns 1.7. The type of the result is the same as the type of the operand that is highest in the type hierarchy. For example, if A is of type FLOAT and B is of type INT, the result is of type FLOAT. \n A DIV B Integer types Returns the integer part of the result of dividing A by B. For example, 13.7 DIV 3 returns the integer 4.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference"}, {"document_id": "ibmcld_00708-29824-30761", "score": 3.5683265051102215, "text": "\n\"title\": \"User Profile Standard v2 Schema\",\n\"type\": \"object\",\n\"properties\": {\n\"id\": {\n\"type\": \"string\"\n},\n\"profile_name\": {\n\"type\": \"string\"\n},\n\"profile_version\": {\n\"type\": \"string\"\n},\n\"controls\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"control_specifications\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_count\": {\n\"type\": \"number\"\n},\n\"assessments\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_type\": {\n\"type\": \"string\"\n},\n\"assessment_method\": {\n\"type\": \"string\"\n},\n\"assessment_description\": {\n\"type\": \"string\"\n},\n\"assessment_id\": {\n\"type\": \"string\"\n},\n\"parameter_count\": {\n\"type\": \"number\"\n},\n\"parameters\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"parameter_name\": {\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n},\n\"default_parameters\": {", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"}, {"document_id": "ibmcld_00684-29824-30761", "score": 3.5683265051102215, "text": "\n\"title\": \"User Profile Standard v2 Schema\",\n\"type\": \"object\",\n\"properties\": {\n\"id\": {\n\"type\": \"string\"\n},\n\"profile_name\": {\n\"type\": \"string\"\n},\n\"profile_version\": {\n\"type\": \"string\"\n},\n\"controls\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"control_specifications\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_count\": {\n\"type\": \"number\"\n},\n\"assessments\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_type\": {\n\"type\": \"string\"\n},\n\"assessment_method\": {\n\"type\": \"string\"\n},\n\"assessment_description\": {\n\"type\": \"string\"\n},\n\"assessment_id\": {\n\"type\": \"string\"\n},\n\"parameter_count\": {\n\"type\": \"number\"\n},\n\"parameters\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"parameter_name\": {\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n},\n\"default_parameters\": {", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"}, {"document_id": "ibmcld_04341-29805-30742", "score": 3.5683265051102215, "text": "\n\"title\": \"User Profile Standard v2 Schema\",\n\"type\": \"object\",\n\"properties\": {\n\"id\": {\n\"type\": \"string\"\n},\n\"profile_name\": {\n\"type\": \"string\"\n},\n\"profile_version\": {\n\"type\": \"string\"\n},\n\"controls\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"control_specifications\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_count\": {\n\"type\": \"number\"\n},\n\"assessments\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_type\": {\n\"type\": \"string\"\n},\n\"assessment_method\": {\n\"type\": \"string\"\n},\n\"assessment_description\": {\n\"type\": \"string\"\n},\n\"assessment_id\": {\n\"type\": \"string\"\n},\n\"parameter_count\": {\n\"type\": \"number\"\n},\n\"parameters\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"parameter_name\": {\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n},\n\"default_parameters\": {", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cra-cli-plugin"}, {"document_id": "ibmcld_13498-94895-96764", "score": 3.5448231312886693, "text": "\nA % B All number types Returns the remainder after dividing A by B. For example, 13.7 % 3 returns 1.7. The type of the result is the same as the type of the operand that is highest in the type hierarchy. For example, if A is of type FLOAT and B is of type INT, the result is of type FLOAT. \n A DIV B Integer types Returns the integer part of the result of dividing A by B. For example, 13.7 DIV 3 returns the integer 4. \n A & B All number types Returns the result of bitwise AND of A and B. The type of the result is the same as the type of the operand that is highest in the type hierarchy. \n `A B` All number types \n A ^ B All number types Returns the result of bitwise XOR of A and B. The type of the result is the same as the type of the operand that is highest in the type hierarchy. \n\n\n\n\n\n\n\n String operator \n\n\n\nTable 52. String operator.\n\n Operator Operand types Description \n\n `A B` \n\n\n\n\n\n\n\n Comparison operators \n\n\n\nTable 53. Comparison operators.\n\n Operator Operand types Description \n\n A = B All primitive types Returns TRUE if A is equal to B, FALSE otherwise. \n A == B All primitive types Synonym for the equal (=) operator. \n A <> B All primitive types Returns NULL if A or B is NULL, TRUE if A is not equal to B, FALSE otherwise. \n A != B All primitive types Synonym for the not equal (<>) operator. \n A < B All primitive types Returns NULL if A or B is NULL, TRUE if A is less than B, FALSE otherwise. \n A <= B All primitive types Returns NULL if A or B is NULL, TRUE if A is less than or equal to B, FALSE otherwise. \n A !> B All primitive types Returns NULL if A or B is NULL, TRUE if A is not greater than B, FALSE otherwise. \n A > B All primitive types Returns NULL if A or B is NULL, TRUE if A is greater than B, FALSE otherwise. \n A >= B All primitive types Returns NULL if A or B is NULL, TRUE if A is greater than or equal to B, FALSE otherwise.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference"}, {"document_id": "ibmcld_00708-30606-31461", "score": 3.4969764850296228, "text": "\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n},\n\"default_parameters\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_type\": {\n\"type\": \"string\"\n},\n\"assessment_id\": {\n\"type\": \"string\"\n},\n\"parameter_name\": {\n\"type\": \"string\"\n},\n\"parameter_default_value\": {\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n},\n\"required\": [\"default_parameters\", \"controls\", \"profile_name\", \"profile_version\"]\nShow more\n\n\n\n\n\n Example SCC V2 classic profile file for the terraform-validate command \n\nYou can prefix the rule ID with rule-.\n\n{\n\"schema_version\": \"2.0\",\n\"scc_rules\": [\n{\n\"scc_rule_id\": \"548a3321-6a39-400c-9c2d-0df9a13afd02\"\n},\n{\n\"scc_rule_id\": \"726ec899-505e-4de9-ac1b-9578ef62f89f\"\n},\n{", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cra-cli-plugin"}, {"document_id": "ibmcld_00684-30606-31461", "score": 3.4969764850296228, "text": "\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n},\n\"default_parameters\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_type\": {\n\"type\": \"string\"\n},\n\"assessment_id\": {\n\"type\": \"string\"\n},\n\"parameter_name\": {\n\"type\": \"string\"\n},\n\"parameter_default_value\": {\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n},\n\"required\": [\"default_parameters\", \"controls\", \"profile_name\", \"profile_version\"]\nShow more\n\n\n\n\n\n Example SCC V2 classic profile file for the terraform-validate command \n\nYou can prefix the rule ID with rule-.\n\n{\n\"schema_version\": \"2.0\",\n\"scc_rules\": [\n{\n\"scc_rule_id\": \"548a3321-6a39-400c-9c2d-0df9a13afd02\"\n},\n{\n\"scc_rule_id\": \"726ec899-505e-4de9-ac1b-9578ef62f89f\"\n},\n{", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-cd-configure-cra-repos"}, {"document_id": "ibmcld_04341-30587-31442", "score": 3.4969764850296228, "text": "\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n}\n},\n\"default_parameters\": {\n\"type\": \"array\",\n\"items\": {\n\"type\": \"object\",\n\"properties\": {\n\"assessment_type\": {\n\"type\": \"string\"\n},\n\"assessment_id\": {\n\"type\": \"string\"\n},\n\"parameter_name\": {\n\"type\": \"string\"\n},\n\"parameter_default_value\": {\n\"type\": \"string\"\n},\n\"parameter_display_name\": {\n\"type\": \"string\"\n},\n\"parameter_type\": {\n\"type\": \"string\"\n}\n}\n}\n}\n},\n\"required\": [\"default_parameters\", \"controls\", \"profile_name\", \"profile_version\"]\nShow more\n\n\n\n\n\n Example SCC V2 classic profile file for the terraform-validate command \n\nYou can prefix the rule ID with rule-.\n\n{\n\"schema_version\": \"2.0\",\n\"scc_rules\": [\n{\n\"scc_rule_id\": \"548a3321-6a39-400c-9c2d-0df9a13afd02\"\n},\n{\n\"scc_rule_id\": \"726ec899-505e-4de9-ac1b-9578ef62f89f\"\n},\n{", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cra-cli-plugin"}, {"document_id": "ibmcld_09252-4848-5733", "score": 3.489199755229625, "text": "\nNot all rule types support all comparison types. For example, if you are using FILE_TYPE, it is best to use comparison types REGEX and ENDS_WITH.\n\n\n\n\n\n Layer 7 rule properties \n\n\n\n Property Description \n\n Type Specifies the type of rule. Rule types can be HOST_NAME, FILE_TYPE, HEADER, COOKIE, or PATH. \n Comparison Type Comparison types are used in association with the rule type, key, and value to define a rule and classify traffic. Comparison types can be: REGEX, STARTS_WITH, ENDS_WITH, CONTAINS, and EQUAL_TO. \n Key The description key for the rule types HEADER and COOKIE. \n Value For the rule types HEADER and COOKIE, the value is compared against the key. \n Invert If you set the value to 1, the value of this L7 rule comparison is set to true whenever the specified rule is not matched. \n Layer 7 Policy ID The unique identifier of the policy to which the rules are attached.", "title": "", "source": "https://cloud.ibm.com/docs/loadbalancer-service?topic=loadbalancer-service-layer-7-policy"}, {"document_id": "ibmcld_09254-1704-2604", "score": 3.48661519259526, "text": "\nNot all rule types support all comparison types. For example, if you are using FILE_TYPE, it is best to use comparison types REGEX and ENDS_WITH.\n\n\n\n Layer 7 rule properties \n\n\n\nRule properties\n\n Property Description \n\n Type Specifies the type of rule. Rule types can be HOST_NAME, FILE_TYPE, HEADER, COOKIE, or PATH. \n Comparison Type Comparison types are used in association with the rule type, key, and value to define a rule and classify traffic. Comparison types can be: REGEX, STARTS_WITH, ENDS_WITH, CONTAINS, and EQUAL_TO. \n Key The description key for the rule types HEADER and COOKIE. \n Value For the rule types HEADER and COOKIE, the value is compared against the key. \n Invert If you set the value to 1, the value of this L7 rule comparison is set to true whenever the specified rule is not matched. \n Layer 7 Policy ID The unique identifier of the policy to which the rules are attached.", "title": "", "source": "https://cloud.ibm.com/docs/loadbalancer-service?topic=loadbalancer-service-layer-7-rules"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03776-5228-7163", "score": 38.899394411617536, "text": "\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https://myibm.ibm.com/billing/).", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-overview"}, {"document_id": "ibmcld_01623-6277-8255", "score": 36.74838032757554, "text": "\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https://cloud.ibm.com/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https://myibm.ibm.com/billing/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-account-getting-started"}, {"document_id": "ibmcld_08067-0-1736", "score": 36.40437180509487, "text": "\n\n\n\n\n\n\n  Viewing your support costs \n\nIf you have Advanced or Premium support, you can keep track of your monthly support costs from the Support costs page in the IBM Cloud\u00ae console.\n\n\n\n  How you're charged for support \n\nEach [IBM Cloud support plan](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans) has a minimum monthly price for providing support for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost. For details about your purchased support plan, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\n\n\n\n\n  Viewing support costs \n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https://cloud.ibm.com/docs/account?topic=account-userroles).\n\nIn the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. You can view your support plan and relevant cost details:\n\n\n\n*  If your support costs are billed monthly, you can view your costs for the current month. These costs include the starting price for the plan and any additional costs from your resource usage. After each billing cycle, these charges are added to your monthly invoice.\n*  If you have a support subscription, you can view the remaining credit in your active subscriptions and any overages for the current month. Overage is charged if you run out of credit in your active subscriptions. You can also view upcoming support subscriptions, which are subscriptions that you bought but are not yet valid.\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-support"}, {"document_id": "ibmcld_07578-335595-337885", "score": 36.16852043554412, "text": "\nEach device has a unique SSH key, so the key for the newly provisioned or reloaded device is different from the image. However, SSH keys that are associated with either a Flex Image or a standard image templates are associated with the device when it is provisioned or reloaded. You can also add keys during the setup process.\n* Which virtual server instance types can be reserved?\n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n* Can I combine different CPUxRAM sizes or change the sizes later?\n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n* Is my payment upfront or monthly?\n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n* What happens at the end of my contract?\n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https://www.ibm.com/cloud/virtual-servers).\n* What happens if I don't need my reserved virtual server instances anymore?\n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n* Does the reservation include everything that I configured into my virtual server instance?\n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n* Why do I need to choose hourly or monthly billing on the virtual server instance?\n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n* What types of virtual servers are available for use?\n\nIBM Cloud\u00ae offers a couple types of virtual servers within its Classic Infrastructure.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-335569-337859", "score": 36.16852043554412, "text": "\nEach device has a unique SSH key, so the key for the newly provisioned or reloaded device is different from the image. However, SSH keys that are associated with either a Flex Image or a standard image templates are associated with the device when it is provisioned or reloaded. You can also add keys during the setup process.\n* Which virtual server instance types can be reserved?\n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n* Can I combine different CPUxRAM sizes or change the sizes later?\n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n* Is my payment upfront or monthly?\n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n* What happens at the end of my contract?\n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https://www.ibm.com/cloud/virtual-servers).\n* What happens if I don't need my reserved virtual server instances anymore?\n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n* Does the reservation include everything that I configured into my virtual server instance?\n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n* Why do I need to choose hourly or monthly billing on the virtual server instance?\n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n* What types of virtual servers are available for use?\n\nIBM Cloud\u00ae offers a couple types of virtual servers within its Classic Infrastructure.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_11408-13151-14243", "score": 34.437766283491456, "text": "\nThe following table shows the charges based on the number of connections (includes all types of connection such as DL, VPC, etc.) that you create:\n\n\n\nTable 14. TGW charges based on number of connections\n\n Number of connections Charges \n\n 1 - 4 No charges \n 5 - 20 $9.405 \n 21 - 50 $7.315 \n 51+ $4.7025 \n\n\n\nThe Transit Gateway charges indicated in the tables above are subjected to change. To calculate your pricing, use the [IBM cost estimator](https://cloud.ibm.com/estimator) in IBM Cloud console.\n\n\n\n\n\n End of billing \n\nThe monthly billing cycle ends when you delete the LPAR. If you scale your infrastructure up and down in response to workload requirements, your billing follows the timing of the LPAR provision change. If you stop the LPAR, the billing process is not stopped. You must delete the LPAR to stop the billing cycle.\n\nYou are still charged if the VM is in a suspended state. When your VM is inactive, you can use Dynamic Logical Partitioning (DLPAR) to resize it to a minimal state. You can drastically decrease the price per hour by reducing the VM's core count and memory.", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-pricing-virtual-server"}, {"document_id": "ibmcld_03729-7-2197", "score": 34.38640630198157, "text": "\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_14007-0-1917", "score": 34.33269347424845, "text": "\n\n\n\n\n\n\n  FAQs: Reserved capacity and instances \n\n\n\n  Which virtual server instance types can be reserved? \n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n\n\n\n\n\n  Can I combine different CPUxRAM sizes or change the sizes later? \n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n\n\n\n\n\n  Is my payment upfront or monthly? \n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n\n\n\n\n\n  What happens at the end of my contract? \n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https://www.ibm.com/cloud/virtual-servers).\n\n\n\n\n\n  What happens if I don't need my reserved virtual server instances anymore? \n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n\n\n\n\n\n  Does the reservation include everything that I configured into my virtual server instance? \n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n\n\n\n\n\n  Why do I need to choose hourly or monthly billing on the virtual server instance? \n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-faqs-reserved-capacity-and-instances"}, {"document_id": "ibmcld_07578-508107-510221", "score": 33.428009580798744, "text": "\nIf the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID. You are not charged for entities that do not call App Configuration during the month. If your pricing plan includes a free allotment of Active Entity IDs, then you are not charged until the allotment is exceeded.\n\nActive Entity ID cost can be difficult to predict so you need to closely monitor your historical activity. See [How to view usage metrics for App Configuration?](https://cloud.ibm.com/docs/faqsfaq-ac-metrics) Rely on your own domain knowledge, business metrics, and usage forecasts to predict Active Entity ID cost.\n\nThe API Call cost is based on the number of API calls sent or received by App Configuration during the month over all your entities combined. Check section - [What are the charges to use App Configuration?](https://cloud.ibm.com/docs/faqsfaq-ac-charges) to determine what constitutes an API call.\n\nIf your pricing plan includes a free allotment of API calls, then you are not charged until the allotment is exceeded. Closely monitor your historical activity and check out [How to view usage metrics for App Configuration?](https://cloud.ibm.com/docs/faqsfaq-ac-metrics) Rely on your own domain knowledge, business metrics, and usage forecasts to predict cost.\n* Can you give some example pricing scenarios?\n\n\n\n Pricing Scenario 1: Mobile App with Feature Flags \n\nAssume you have a mobile app and you want feature flags and targeted segments to roll out features incrementally to different sets of users. Your historical metrics show 200,000 users but only about 50% are active in a month.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-508049-510175", "score": 33.35270564349286, "text": "\nIf the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID. You are not charged for entities that do not call App Configuration during the month. If your pricing plan includes a free allotment of Active Entity IDs, then you are not charged until the allotment is exceeded.\n\nActive Entity ID cost can be difficult to predict so you need to closely monitor your historical activity. See [How to view usage metrics for App Configuration?](https://cloud.ibm.com/docs?tab=faqsfaq-ac-metrics) Rely on your own domain knowledge, business metrics, and usage forecasts to predict Active Entity ID cost.\n\nThe API Call cost is based on the number of API calls sent or received by App Configuration during the month over all your entities combined. Check section - [What are the charges to use App Configuration?](https://cloud.ibm.com/docs?tab=faqsfaq-ac-charges) to determine what constitutes an API call.\n\nIf your pricing plan includes a free allotment of API calls, then you are not charged until the allotment is exceeded. Closely monitor your historical activity and check out [How to view usage metrics for App Configuration?](https://cloud.ibm.com/docs?tab=faqsfaq-ac-metrics) Rely on your own domain knowledge, business metrics, and usage forecasts to predict cost.\n* Can you give some example pricing scenarios?\n\n\n\n Pricing Scenario 1: Mobile App with Feature Flags \n\nAssume you have a mobile app and you want feature flags and targeted segments to roll out features incrementally to different sets of users. Your historical metrics show 200,000 users but only about 50% are active in a month.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_14341-0-681", "score": 22.137685293564324, "text": "\n\n\n\n\n\n\n  Step 3 - Application configuration \n\nThis step uses the Caveonix RiskForesight\u2122 configuration script. For the \u201call-in-one\u201d deployment, this script is started through the IBM Cloud\u00ae for VMware Solutions automation.\n\nFor scaling, the client needs to call the script to provision the partially distributed topology or the fully distributed topology.\n\nThe script configures the following RiskForesight services:\n\n\n\n*  Caveonix Apps (API, Central Collector)\n*  Elastic Search\n*  PostgresSQL\n*  Remote Collector\n*  UI\n*  Kafka\n*  Kibana\n*  Certificates for all services\n\n\n\nAt the end of this step, the application components are installed on the required virtual machines.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-caveonix-step3"}, {"document_id": "ibmcld_11552-4-2231", "score": 22.0442371497089, "text": "\n* UI\n* Terraform\n\n\n\n\n\n\n\n Automating SAP workload S/4HANA HA deployment on IBM Cloud\u00ae VPC with Terraform and Ansible \n\nTerraform on IBM Cloud\u00ae enables predictable and consistent provisioning of IBM Cloud Virtual Private Cloud (VPC) infrastructure resources so that you can rapidly build complex cloud environments. IBM Cloud VPC infrastructure consists of SAP certified hardware that uses Intel\u00ae Xeon CPUs and other Intel\u00ae technologies.\n\nYou can use Terraform scripts to create a VPC and create 2 clustered layers , one for SAP S/4HANA and 2nd for SAP HANA in-memory database in a HA Single Zone architecture on the bastion server that you create. Creating the bastion server is a prerequisite for all IBM SAP VPC automated solutions. The automation scripts use the VPC information that you provide and then call the Ansible playbook to create the SAP architecture on the specified VPC.\n\nYou have three deployment methods to choose from:\n\n\n\n* Terraform scripts rum from the CLI on your bastion server\n* Catalog tile user interfaced from the IBM Cloud catalog\n* IBM Cloud Schematics user interface accessed from the menu on your cloud dashboard\n\n\n\n\n\n Terraform scripts include \n\nThe scripts include Terraform scripts for deploying:\n\n\n\n* One Power Placement group to include all the four VMs involved in this solution\n* Four VSIs in an existing VPC with subnet and security group configurations. The VSIs scope: two for the HANA database cluster instance and two for the SAP application cluster.\n* And configuring three Application Load Balancers like HANA DB, SAP ASCS/ERS\n* And configuring one VPC DNS service that is used to map the ALB FQDN to the SAP ASCS/ERS and HANA virtual hostnames\n* And configuring seven file shares for VPC\n\n\n\nThe scripts include Ansible scripts for:\n\n\n\n* OS requirements installation and configuration for SAP applications\n* Cluster components installation\n* Ansible scripts for SAP application cluster configuration and SAP HANA cluster configuration\n* HANA installation\n* HANA DB backup\n* HANA system replica configuration\n* ASCS and ERS instances installation\n* DB load\n* Primary and extra application servers installation\n\n\n\nAnsible is started by Terraform and must be available on the same host.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-automate-s4hana-ha-terraform-ansible"}, {"document_id": "ibmcld_02817-7-1881", "score": 21.231098619087824, "text": "\nCreating an IBM Cloud Satellite environment on AWS by using scripts \n\nThis tutorial and set of scripts provide a mostly automated way to set up an IBM Cloud Satellite location and Red Hat OpenShift cluster on Amazon Web Services (AWS). This is not a production-ready solution, but it provides a useful tool for proof-of-concepts, learning, and experimenting.\n\nIBM Cloud Satellite\u00ae is a managed distributed cloud solution that allows you to run parts of IBM Cloud\u00ae with managed services in your data center or other public clouds. To learn more about Satellite, see the [IBM Cloud Satellite product page](https://www.ibm.com/cloud/satellite).\n\nThe scripts expect a Unix-like environment and work on MacOS or Linux\u2122. The scripts are likely to work on Windows\u2122 Subsystem for Linux (WSL), but this scenario is not tested.\n\nThis solution is not an officially supported IBM product; any support is on an unofficial, best-effort basis only. For more information, see the [MIT license](https://github.com/ibm-garage/try-sat-aws/blob/master/LICENSE.txt). This solution is not fully evaluated from a security, robustness, or any other nonfunctional perspective. The cluster that is created is public. Therefore, do not put anything sensitive on this cluster or location. If you plan to keep the location or cluster long term, you are responsible for reviewing the security of the infrastructure. Be sure to destroy the location or cluster when you no longer need it to minimize the possibility of attacks. You are responsible for costs that you incur on IBM Cloud or AWS.\n\n\n\n Before you begin \n\n\n\n* To complete this tutorial, use a [Pay-As-You-Go or Subscription IBM Cloud account](https://cloud.ibm.com/docs/account?topic=account-upgrading-account) where you are the owner or have [full Administrator access](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).", "title": "", "source": "https://cloud.ibm.com/docs/apps?topic=apps-tutorial-trysat"}, {"document_id": "ibmcld_14664-2979-4981", "score": 20.73592834430347, "text": "\nThis layer virtualizes the physical infrastructure through different VMware products:\n\n\n\n* VMware vSphere virtualizes the physical compute resources.\n* VMware NSX is the network virtualization platform that provides logical networking components and virtual networks.\n\n\n\n\n\n\n\n Virtualization management \n\nThis layer consists of the following components:\n\n\n\n* vCenter Server Appliance with embedded Platform Services Controller (PSC).\n* For NSX-T - three NSX Manager or Controller nodes (total of three nodes).\n* For NSX-V - one NSX Manager and three VMware NSX Controller\u2122 nodes (total of four nodes).\n* VMware NSX Edge\u2122 Services Gateways (ESGs) - four for NSX-T (two on the management cluster and two on the workload cluster) and two for NSX-V.\n* IBM CloudDriver virtual server instance (VSI). The CloudDriver VSI is deployed on demand as needed for certain operations such as adding hosts to the environment.\n\n\n\nThe base offering is deployed with a vCenter Server appliance that is sized to support an environment with up to 400 hosts and up to 4,000 VMs. The same vSphere API-compatible tools and scripts can be used to manage the IBM-hosted VMware environment.\n\nIn total, the base offering has the following requirements, which are reserved for the virtualization management layer.\n\n\n\n* For NSX-T, 42 vCPU and 128 GB vRAM\n* For NSX-V, 38 vCPU and 67 GB vRAM\n\n\n\nThe remaining host capacity for your virtual machines (VMs) depends on several factors, such as oversubscription rate, VM sizing, and workload performance requirements.\n\nFor more information about the architecture, see [Overview of VMware Solutions](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-solution_overview).\n\n\n\n\n\n Technical specifications for vCenter Server instances \n\nThe availability and pricing of standardized hardware configurations might vary based on the IBM Cloud data center that is selected for deployment.\n\nThe following components are included in your vCenter Server instance.\n\n\n\n Bare metal server", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_vcenterserveroverview"}, {"document_id": "ibmcld_13200-10220-12304", "score": 20.593662215867163, "text": "\nIn this script, upgrading the installed software and installing nginx and other packages using the operating system provided software installation tools demonstrates that even the isolated instances have access to the IBM provided mirrors. For Ubuntu, the apt-get commands will access mirrors.\n\nThe curl command accessing www.python.org demonstrates the attempt to access and potentially install software from the internet.\n\nBased on whether the host has internet connectivity, the script modifies the index.html page served by nginx.\n\n\n\n\n\n Upload from the filesystem and execute on the instance \n\nThere may be data and software that is available on the filesystem of your on-premise system or CI/CD pipeline that needs to be uploaded to the virtual server instance and then executed.\n\nIn such cases, you can use the SSH connection to the server to upload files with scp and then execute scripts on the server with ssh. The scripts could also retrieve software installers from the Internet, or from your on-premise systems assuming you have established a connection [such as a VPN](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-site2site-vpn) between your on-premise systems and the cloud.\n\nThe tutorial code contains a script named [uploaded.sh](https://github.com/IBM-Cloud/vpc-tutorials/blob/master/vpc-app-deploy/shared/uploaded.sh) which will be uploaded from your workstation to the virtual server instances (manually or through automation like Terraform and Ansible).\n\nIn the next sections, you will use the script [test_provision.bash](https://github.com/IBM-Cloud/vpc-tutorials/blob/master/vpc-app-deploy/test_provision.bash) to confirm that the servers have been provisioned successfully, are able (or not) to access the Internet and that the uploaded.sh script was correctly executed.\n\n\n\n\n\n\n\n Step 2: Using the IBM Cloud CLI and shell scripts \n\nThe IBM Cloud CLI provides commands to interact with all the resources you can create in the IBM Cloud. This section explains how to use these commands, but you are not going to create any resources.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-app-deploy"}, {"document_id": "ibmcld_08111-19721-21530", "score": 20.437078388820513, "text": "\n* Whether to enable auto-scaling in DBaaS - true or false\n\n\n\n6. If you are using DBaaS, you can modify the optional parameters in the root level db_variables.tf file. These variables are set to defaults and can be modified to match your solution.\n7. Initialize the Terraform CLI.\n\nterraform init\n8. Create a Terraform execution plan. The Terraform execution plan summarizes all the actions that are done to create the virtual private cloud instance in your account.\n\nterraform plan\n\nThe scripts prompt you for information about your resources if you did not specify them in the userinput.auto.tfvars file.\n9. Verify that the plan shows all of the resources that you want to create and that the names and values are correct. If the plan needs to be adjusted, edit the userinput.auto.tfvars and modules .tf files, and run terraform plan again.\n10. Create the virtual private cloud for SAP instance and IAM access policy in IBM Cloud.\n\nterraform apply\n\nThe virtual private cloud and components are created and you see output similar to the terraform plan output.\n\n\n\n\n\n\n\n Next Steps \n\nIf you need to rename your resources after they are created, modify the example.userinput.auto.tfvars and modules.tf files to change the names, and run terraform plan and terraform apply again.\n\nDo not use the IBM Cloud Dashboard and user interface to modify your VPC after it is created. The Terraform scripts create a complete solution and selectively modifying resources with the user interface might cause unexpected results.\n\nIf you need to remove your VPC, use terraform destroy. The Bastion server is protected for inadvertent deletion. Before you run the terraform destroy command, you need to set the prevent_destroy flag to false to remove your VPC. The prevent_destroy flag is located in ./modules/bastion/compute.tf.", "title": "", "source": "https://cloud.ibm.com/docs/ha-infrastructure?topic=ha-infrastructure-create-three-tier-resilient-vpc-mzr-modular"}, {"document_id": "ibmcld_11565-1408-3072", "score": 20.356021604321686, "text": "\nFor more information about this architecture, see [Automating SAP HANA stand-alone virtual server instance on IBM Cloud\u00ae VPC by using Terraform and Ansible](https://cloud.ibm.com/docs/sap?topic=sap-automate-terraform-sap-hana-vsi).\n\n\n\n\n\n Script files \n\nThe configuration and script files are provided in GitHub. There are two repositories for each SAP solution:\n\n\n\n* Using the bastion server CLI to run the Terraform scripts - [GitHub repository](https://github.com/IBM-Cloud/sap-bw4hana/tree/main/cli)\n* Using Schematics user interface on IBM Cloud - [GitHub repository](https://github.com/ibm-cloud/sap-bw4hana/tree/main/schematics)\n\n\n\n\n\n\n\n Terraform scripts \n\nFor SAP BW/4HANA virtual server instance on IBM Cloud VPC, you modify the:\n\n\n\n* terraform.tfvars file to add your IBM Cloud API key\n* input.auto.tfvars file to customize the resources for your solution. You specify zones, resource names, SSH keys, and SAP variables.\n\n\n\nAll of the other configuration files are provided and do not need to be modified.\n\nThe IBM Cloud Provider Plug-in for Terraform on IBM Cloud uses these configuration files to provision a VPC in your IBM Cloud account.\n\n\n\n\n\n Single-host SAP HANA system \n\nA single-host system is the simplest system installation type that runs an SAP HANA system entirely on one host. You can scale the system up as needed. The single-host system has these components:\n\nZoom\n\n![Figure 1. SAP NetWeaver 7.x SAP HANA single-host installation with AAS](https://cloud.ibm.com/docs-content/v1/content/f89cc64b006ca59b35404693959c83d5747fee3e/sap/images/sap-hana-vpc-std-pas-aas.svg)\n\nFigure 1. SAP NetWeaver 7.x SAP HANA single-host installation with AAS", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-bw4hana-automation-on-vpc"}, {"document_id": "ibmcld_14566-7-2015", "score": 20.086118299612664, "text": "\nOverview of VMware Solutions \n\nThe IBM Cloud\u00ae for VMware Solutions offerings help you extend your existing VMware\u00ae virtualized datacenter into the IBM Cloud, or to house cloud native applications.\n\nThe solution supports use cases, such as capacity expansion into the cloud (and contraction when not needed), migration to the cloud, disaster recovery to the cloud, and backup into the cloud. With the solution, you can create a dedicated cloud environment for development, testing, training, lab, or production.\n\nReview this information for the design of the IBM Cloud for VMware Solutions vCenter Server, whose target workloads require high levels of availability and scalability.\n\nThis design serves as a baseline architecture that provides the foundation for other internal or vendor-specific components to be added for specific use cases.\n\nZoom\n\n![Overview of VMware on IBM Cloud](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/vcsv4radiagrams-ra-variationsonatheme.svg)\n\nFigure 1. Overview of VMware on IBM Cloud\n\n\n\n Key benefits of VMware Solutions \n\nVMware vCenter Server\u00ae provides the fundamental building blocks, which include VMware vSphere\u00ae, vCenter Server, VMware NSX\u00ae, and shared storage options, such as vSAN\u2122. These components are needed to flexibly design a VMware software-defined data center solution that best fits your workloads.\n\nBy applying advanced automation and single-tenant bare metal infrastructure, you can quickly deploy the entire VMware environment to the IBM Cloud in hours. Then, you can access and manage the IBM-hosted environment through the native VMware clients, command-line interface (CLI), existing scripts, or other familiar vSphere API-compatible tools.\n\nPost deployment, you can add to (and remove from) VMware ESXi\u2122 servers for an instance, add and remove clusters, join additional vCenter Server instances to an existing instance, and add products and services by using the VMware Solutions console.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-solution_overview"}, {"document_id": "ibmcld_13146-1752-3695", "score": 19.917182179645888, "text": "\nIn [this other tutorial, we've introduced best practices to organize users, teams and applications](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applicationsusers-teams-applications) and a sample scenario. The sample scenario considers three environments, Development, Testing and Production. How to automate the creation of these environments? What tools could be used?\n\n\n\n Objectives \n\n\n\n* Define a set of environments to deploy\n* Write scripts using the IBM Cloud CLI and Terraform to automate the deployment of these environments\n* Deploy these environments in your account\n\n\n\nZoom\n\n![Architecture Diagram](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution26-plan-create-update-deployments/architecture.svg)\n\nArchitecture diagram\n\n\n\n1. A set of Terraform files are created to describe the target infrastructure as code.\n2. An operator uses terraform apply to provision the environments.\n3. Shell scripts are written to complete the configuration of the environments.\n4. The operator runs the scripts against the environments.\n5. The environments are fully configured, ready to be used.\n\n\n\n\n\n\n\n Step 1: Overview of the available tools \n\nAll of the operations will be done in a bash shell and making use of terraform and ibmcloud commands. You will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools you can use the [Cloud Shell](https://cloud.ibm.com/shell) from the IBM Cloud console.\n\nWith ibmcloud and its plugins, you can automate the creation and configuration of your cloud resources. Virtual Servers, Kubernetes clusters, Cloud Functions, Code Engine, and services, you can provision all of them from the command line.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-plan-create-update-deployments"}, {"document_id": "ibmcld_11553-14909-16582", "score": 19.75175523606023, "text": "\nThe virtual private cloud and components are created and you see output similar to the terraform plan output.\n9. Add the SAP credentials and the virtual server instance IP to the SAP GUI. For more information about the SAP GUI, see SAP GUI.\n\n\n\n\n\n\n\n Next steps for Terraform \n\nIf you need to rename your resources after they are created, modify the input.auto.tfvars file to change the names and run terraform plan and terraform apply again. Do not use the IBM Cloud Dashboard and user interface to modify your VPC after it is created. The Terraform scripts create a complete solution and selectively modifying resources with the user interface might cause unexpected results.\n\nIf you need to remove your VPC, go to your project folder and run terraform destroy.\n\n\n\n\n\n Deploying SAP S/4HANA with the Catalog Tile interface \n\nUse these steps to configure the SAP S/4HANA on your existing VPC by using the Catalog Tile interface. The scripts can take 1 - 2 hours to complete.\n\n\n\n1. From the IBM Cloud Catalog, select the SAP S/4HANA tile. The Tile opens the Create tab for SAP S/4HANA. For more information about this deployment, see the About tab or the Readme file link.\n2. On the SAP S/4HANA page, configure your workspace:\n\n\n\n* Enter a name for the workspace or use the default.\n* The Resource Group to use to create resources. Use the Default or create a Resource Group.\n* Select a Location to create your Schematics workspace. The workspace location does not have to match the resource location.\n\n\n\n3. Enter the required deployment values, review the default input variables, and provide values that match your solution. These parameters are specific to your deployment.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-automate-s4hana-terraform-ansible"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16258-1324-3123", "score": 21.069397697013066, "text": "\n[Time period](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_16258-7-1952", "score": 21.03209164481625, "text": "\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_02844-1555-3643", "score": 20.448503021984138, "text": "\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-audit-events"}, {"document_id": "ibmcld_03162-10976-13038", "score": 19.977355351581583, "text": "\nThe routing rules identify the queue of agents to which messages from the assistant are transferred by default.\n\nThe code that you add to the setup page when you configure the service desk integration shares the following required information with Watson Assistant:\n\n\n\n* organization_id: Unique ID of the organization. A company can have more than one organization set up in Salesforce.\n* chat_api_endpoint: Salesforce API endpoint that is used by the integration to communicate with Salesforce.\n* deployment_id: Unique ID of the deployment. An organization can have multiple deployments.\n* button_id: Unique ID of a button, which defines the specific routing rules for incoming messages. Each deployment can have multiple buttons associated with it.\n\n\n\nTo override the default routing rules, you must specify a new value for the button_id. Before you perform this procedure, find out the ID of the Salesforce button implementation with the alternative routing rules that you want to use.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific group of Salesforce agents which is distinct from the default group.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Salesforce from the Service desk routing field.\n4. In the Button ID field, add the button_id value for the alternate routing destination that you want the assistant to use for conversations about only this topic. For example, 5733i0000008yGz.\n\nBe sure to specify the exact right syntax for the button_id value. The value is not validated by the service as you add it to your dialog.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-salesforce"}, {"document_id": "ibmcld_03180-11118-12801", "score": 19.291078943051883, "text": "\nIf the customer is on the Returns page, you might want to route the chat transfer to agents who know how to help customers return merchandise.\n\nFor more information, see [Web chat: Accessing browser information](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-integrationsdialog-integrations-chat-browser-info).\n\n\n\n\n\n Routing by topic \n\nYou can specify a routing preference for specific topics of conversation in your dialog. When specified, the chat is transferred to the department that you designate. You can choose a department that you know has agents who are best able to address the topic.\n\nBefore you perform this procedure, determine which department you want users to be routed to.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific Zendesk department.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Zendesk from the Service desk routing field.\n4. In the Department field, add the department to which you want the assistant to transfer customers who want to discuss this topic. For example, sales.\n\nBe sure to specify the exact right syntax for the department name. The value is not validated by the service as you add it to your dialog.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-zendesk"}, {"document_id": "ibmcld_03043-1537-3553", "score": 19.141944895756744, "text": "\nTo train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.\n* [Dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-build): A dialog is a branching conversation flow that defines how your application responds when it recognizes the defined intents and entities. You use the dialog editor in the tool to create conversations with users, providing responses based on the intents and entities that you recognize in their input.\n\n![Diagram of a basic implementation that uses intent and dialog only.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/basic-impl.png)\n\n\n\nTo enable your dialog skill to handle more nuanced questions, define entities and reference them from your dialog.\n\n\n\n* [Entities](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-entities); An entity represents a term or object that is relevant to your intents and that provides a specific context for an intent. For example, an entity might represent a city where the user wants to find a business location, or the amount of a bill payment. In the tool, the name of an entity is always prefixed with the @ character.\n\nYou can train the skill to recognize your entities by providing entity term values and synonyms, entity patterns, or by identifying the context in which an entity is typically used in a sentence. To fine tune your dialog, go back and add nodes that check for entity mentions in user input in addition to intents.\n\n\n\n![Diagram of a more complex implementation that uses intent, entity, and dialog.]", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-add"}, {"document_id": "ibmcld_07068-2140-4064", "score": 19.025654214465348, "text": "\nList fields across collections [GET /v1/environments/{environment_id}/fields](https://cloud.ibm.com/apidocs/discoverylistfields) [GET /v2/projects/{project_id}/fields](https://cloud.ibm.com/apidocs/discovery-datalistfields) \n\n\n\n\n\n\n\n Configurations \n\nThe v2 API does not have an endpoint that is dedicated to configurations. Instead, configuration settings for projects, collections, and queries are specified directly in the API for those objects. Not all of the configuration parameters that are available in v1 are available or applicable in v2.\n\nIn the [v1 configuration API](https://cloud.ibm.com/apidocs/discoverycreateconfiguration), the JSON object that is used to specify a configuration object contains several parameters that are either available in different formats from other v2 endpoints or are not available in v2. The following table describes how to find related parameters in v2.\n\nYou cannot customize the conversion of documents during the ingestion process in v2 as you can in v1.\n\n\n\nConfiguration setting details\n\n v1 configuration parameter v2 API \n\n \"conversions.html\": { ... } Not available \n \"conversions.image_text_recognition\": { ... } Not available from the API. However, you can enable optical character recognition (OCR) for a collection from the product user interface to extract text from images. OCR has other benefits, too. For example, if a page in a document can't be processed, OCR converts the page into an image and scans it to ensure that the document is uploaded successfully. \n \"conversions.json_normalizations\": { ... } Moved to the [Collections API](https://cloud.ibm.com/apidocs/discovery-datalistcollections). \n \"conversions.pdf\": { ... } Not available. If you used special parameters to extract text from images in PDFs, enable optical character recognition (OCR) from the product user interface for the collection that contains the PDFs instead. \n \"conversions.segment\": { ...", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2-api"}, {"document_id": "ibmcld_10143-7-2020", "score": 18.773019365061764, "text": "\nWhy can't I view or work with my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n What\u2019s happening \n\nYou are not able to find a cluster. When you run ibmcloud oc cluster ls, the cluster is not listed in the output.\n\nOr, you are not able to work with a cluster. When you run ibmcloud oc cluster config or other cluster-specific commands, the cluster is not found.\n\n Why it\u2019s happening \n\nIn IBM Cloud, each resource must be in a resource group. For example, cluster mycluster might exist in the default resource group.\n\nWhen the account owner gives you access to resources by assigning you an IBM Cloud IAM platform access role, the access can be to a specific resource or to the resource group. When you are given access to a specific resource, you don't have access to the resource group. In this case, you don't need to target a resource group to work with the clusters you have access to. If you target a different resource group than the group that the cluster is in, actions against that cluster can fail. Conversely, when you are given access to a resource as part of your access to a resource group, you must target a resource group to work with a cluster in that group. If you don't target your CLI session to the resource group that the cluster is in, actions against that cluster can fail.\n\nIf you can't find or work with a cluster, you might be experiencing one of the following issues:\n\n\n\n* You have access to the cluster and the resource group that the cluster is in, but your CLI session is not targeted to the resource group that the cluster is in.\n* You have access to the cluster, but not as part of the resource group that the cluster is in. Your CLI session is targeted to this or another resource group.\n* You don't have access to the cluster.\n\n\n\n How to fix it \n\nTo check your user access permissions:\n\n\n\n1. List all your user permissions.\n\nibmcloud iam user-policies <your_user_name>\n2. Check if you have access to the cluster and to the resource group that the cluster is in.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_cluster_access"}, {"document_id": "ibmcld_05690-7-2020", "score": 18.773019365061764, "text": "\nWhy can't I view or work with my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n What\u2019s happening \n\nYou are not able to find a cluster. When you run ibmcloud ks cluster ls, the cluster is not listed in the output.\n\nOr, you are not able to work with a cluster. When you run ibmcloud ks cluster config or other cluster-specific commands, the cluster is not found.\n\n Why it\u2019s happening \n\nIn IBM Cloud, each resource must be in a resource group. For example, cluster mycluster might exist in the default resource group.\n\nWhen the account owner gives you access to resources by assigning you an IBM Cloud IAM platform access role, the access can be to a specific resource or to the resource group. When you are given access to a specific resource, you don't have access to the resource group. In this case, you don't need to target a resource group to work with the clusters you have access to. If you target a different resource group than the group that the cluster is in, actions against that cluster can fail. Conversely, when you are given access to a resource as part of your access to a resource group, you must target a resource group to work with a cluster in that group. If you don't target your CLI session to the resource group that the cluster is in, actions against that cluster can fail.\n\nIf you can't find or work with a cluster, you might be experiencing one of the following issues:\n\n\n\n* You have access to the cluster and the resource group that the cluster is in, but your CLI session is not targeted to the resource group that the cluster is in.\n* You have access to the cluster, but not as part of the resource group that the cluster is in. Your CLI session is targeted to this or another resource group.\n* You don't have access to the cluster.\n\n\n\n How to fix it \n\nTo check your user access permissions:\n\n\n\n1. List all your user permissions.\n\nibmcloud iam user-policies <your_user_name>\n2. Check if you have access to the cluster and to the resource group that the cluster is in.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_cluster_access"}, {"document_id": "ibmcld_07068-3701-5336", "score": 18.634639095418848, "text": "\n} Moved to the [Collections API](https://cloud.ibm.com/apidocs/discovery-datalistcollections). \n \"conversions.pdf\": { ... } Not available. If you used special parameters to extract text from images in PDFs, enable optical character recognition (OCR) from the product user interface for the collection that contains the PDFs instead. \n \"conversions.segment\": { ... } Not available programmatically. You can split a document at each occurrence of an SDU-generated field such as subtitle from the product user interface. <br>The segment_metadata object with parent_id, id, and total_segments information is not available in v2. You can use the metadata.parent_document_id field to find the common parent for many document segments. \n \"conversions.word\": { ... } Not available \n \"enrichments\": { ... } [/v2/projects/{project_id}/enrichments](https://cloud.ibm.com/apidocs/discovery-datalistenrichments), [/v2/projects/{project_id}/collections/{collection_id}](https://cloud.ibm.com/apidocs/discovery-datagetcollection) <br>Use the enrichments API to explore existing enrichments. Use the collections API to see and change the enrichments that are enabled on a field in a collection. <br>Some enrichments are applied to the service by default based on the type of project that you create. For more details, see [Default project settings](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-project-defaults). <br>The version of the Entities enrichment that is available in v2 doesn't include the disambiguation field, which in v1 contains the disambiguation information for the entity and includes the entity subtype information.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2-api"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13498-7173-9446", "score": 19.55390238507217, "text": "\nWhen specified in combination with PARTITIONED BY, it sorts the rows within each partition by the sort order that is specified in the SORT BY clause. When specified in combination with PARTITIONED INTO, the same is done, which is often referred to as clustering the rows by the specified columns into the fixed number of partitions specified by PARTITIONED INTO. When specified without the PARTITIONED clause, it is equivalent to an ORDER BY clause specified at the top level of the SQL SELECT statement. If PARTITIONED INTO is specified, the ORDER BY clause is ignored.\n\n\n\n Partition by columns \n\nWhen you use the PARTITIONED BY (column-list) clause without specifying INTO x BUCKETS/OBJECTS, you can store the query result by using Hive-style partitioning, which is to create partitions that contain only rows that have certain values for one or more columns. Choose this physical layout if the stored object is further analyzed by using SQL queries that specify predicates on the partition columns.\n\nFor example, a result object that contains worldwide order data has a column country to represent the country that the order is initiated from. Partitioning the result object by the column PARTITIONED BY (country), would create a result object with a partition for each country present in the query result.\n\nWhen the result object is stored this way on Cloud Object Storage, each SQL query that contains a predicate, such as country = 'USA' or country in ('MALTA', 'ITALY', 'VATICAN CITY'), benefits from this physical layout. The reason is that during SQL query execution partitions must be read only if they contain data for the countries of interest. This layout tremendously cuts down the I/O traffic of the SQL query.\n\nSee the following extra remarks on Hive-style partitioning.\n\n\n\n* Hive-style partitions have an eye-catching naming scheme because the column names that are used for partitioning are part of the partition object prefix, for example, /order/COUNTRY=USA/part-m-00000.snappy.parquet.\n* Hive-style partitions do not contain any values for partition columns since their values are stored in the object prefix of the partition. Thus, if you copy a HIVE-style partition and rename the object prefix by removing the partition column values, you lose data.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference"}, {"document_id": "ibmcld_13480-4908-6825", "score": 17.324071441080402, "text": "\nIncorrect column name specification results in an empty column, that is, the column seems to contain no data. To solve such a problem, use the automatic schema detection, reorder the columns, or omit some columns.\n\nThe SHOW TABLES statement provides you with an overview of the existing tables in your instance. This statement allows an optional search filter to limit the number of results:\n\nSHOW TABLES LIKE 'cus'\n\nIt is not possible to use a different namespace than default.\n\nTo clean up catalog entries for unused data, use the DROP TABLE statement. This statement removes the table definition from the catalog without affecting the actual data on Object Storage:\n\nDROP TABLE customers\n\n\n\n\n\n Partitioned tables \n\nYou can manage a table in the catalog that references data that is organized in multiple partitions on Object Storage. The naming of the objects must adhere to the Hive-style partition naming convention: The object names must include the structure /columm=value/. The column must be a column name that is included in the schema definition of the CREATE TABLE statement. You can also have more than one partitioning columns in the object names, such as /columm1=value/column2=value/.\n\nFollowing is an example list of object names on Object Storage that is partitioned on the country column with the Hive-style partition naming convention:\n\ncustomers_partitioned.csv/country=Germany/cust-1.csv\ncustomers_partitioned.csv/country=Germany/cust-2.csv\ncustomers_partitioned.csv/country=Spain/cust-1.csv\ncustomers_partitioned.csv/country=Austria/cust-1.csv\ncustomers_partitioned.csv/country=Austria/cust-2.csv\ncustomers_partitioned.csv/country=USA/cust-1.csv\ncustomers_partitioned.csv/country=USA/cust-2.csv\ncustomers_partitioned.csv/country=USA/cust-3.csv\ncustomers_partitioned.csv/country=Sweden/cust-1.csv\n\nTo query partitioned tables, you must perform two mandatory steps:\n\n\n\n Step 1: Register the table", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalog"}, {"document_id": "ibmcld_13480-6528-8270", "score": 16.208403296931465, "text": "\ncustomers_partitioned.csv/country=USA/cust-1.csv\ncustomers_partitioned.csv/country=USA/cust-2.csv\ncustomers_partitioned.csv/country=USA/cust-3.csv\ncustomers_partitioned.csv/country=Sweden/cust-1.csv\n\nTo query partitioned tables, you must perform two mandatory steps:\n\n\n\n Step 1: Register the table \n\nThis data partitioning is reflected in the PARTITIONED BY clause of the following CREATE TABLE statement:\n\nCREATE TABLE customers (\ncustomerID string,\ncompanyName string,\ncontactName string,\ncontactTitle string,\naddress string,\nregion string,\npostalCode string,\ncountry string,\nphone string,\nfax string\n)\nUSING CSV\nPARTITIONED BY (country)\nLOCATION cos://us-geo/sql/customers_partitioned.csv\n\nAutomatic schema detection also recognizes partitioned tables from the structure of the object names, so the same table definition is created from the following statement:\n\nCREATE TABLE customers\nUSING CSV\nLOCATION cos://us-geo/sql/customers_partitioned.csv\n\nIf your data on Object Storage does not adhere to this naming convention, you can convert it to a Hive-partitioned layout by using Data Engine in a data preparation step. Use SELECT * to copy the data to a new location and specify [PARTITION BY](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencepartitionedClause) in the INTO clause:\n\nSELECT * FROM cos://us-geo/sql/customers.csv\nINTO cos://us-geo/mybucket/customers_partitioned.csv\nPARTITIONED BY (country)\n\n\n\n\n\n Step 2: Attach table partitions \n\nAfter you defined a partitioned table, it is initially empty and you must attach the partitions to it explicitly. A convenient way to add all partitions that exist on Object Storage, is to use the following RECOVER PARTITIONS clause.\n\nALTER TABLE customers RECOVER PARTITIONS", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalog"}, {"document_id": "ibmcld_00576-8941-10714", "score": 15.809219442965293, "text": "\nThe maximum document size is 1 MB, but documents must be much smaller than that size, typically a few KB.\n\nFor more information, see the following blog posts:\n\n\n\n* [Optimal IBM Cloudant Indexing](https://blog.cloudant.com/2019/05/10/Optimal-Cloudant-Indexing.html)\n* [Time-series Data Storage](https://blog.cloudant.com/2019/04/08/Time-series-data-storage.html)\n* [Partitioned databases - data design](https://blog.cloudant.com/2019/03/05/Partition-Databases-Data-Design.html)\n\n\n\n\n\n\n\n Making the most of the primary index \n\nIBM Cloudant has a primary index on the document's _id attribute. This index allows documents to be retrieved by _id (GET /db/id) or a range of _ids (GET /db/_all_docs?startkey=\"a\"&endkey=\"z\"). By storing data in the primary key and ensuring that each _id is unique, the primary index can be used to fetch documents and ranges of documents without secondary indexing. See the following list of ideas:\n\n\n\n* If you have something unique in your object that would be useful to query against, use it as your _id field, for example, bob.smith@gmail.com, isbn9780241265543, or oakland,ca.\n* If your objects contain a hierarchy, model that in your _id: usa:ca:oakland or books:fiction:9780241265543. The hierarchy goes from largest to smallest, so you can use the primary index to find all the cities in usa or all the cities in usa:ca, without secondary indexing.\n* If you're storing time-series data, encoding time at the start of your _id sorts the primary index by time, for example, 001j40Ox1b2c1B2ubbtm4CsuLB4L35wQ.\n* Partitioned databases group documents that share a partition key together. A partition key must have many values and must not include hot spots to avoid directing a large proportion of your application's traffic to a few partitions.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-basics"}, {"document_id": "ibmcld_00381-3303-3948", "score": 15.053826892875097, "text": "\nSierra Leone,\nSan Marino,\nSenegal,\nSomalia,\nSuriname,\nSao Tome and Principe,\nEl Salvador,\nSint Maarten,\nSyrian Arab Republic,\nSwaziland,\nTurks and Caicos Islands,\nChad,\nFrench Southern Territories,\nTogo,\nThailand,\nTajikistan,\nTokelau,\nTurkmenistan,\nTunisia,\nTonga,\nEast Timor,\nTurkey,\nTrinidad and Tobago,\nTuvalu,\nTaiwan,\nTanzania, United Republic of,\nUkraine,\nUganda,\nUSA Minor Outlying Islands,\nUnited States,\nUruguay,\nUzbekistan,\nVatican City State,\nSt Vincent and the Grenadines,\nVenezuela,\nVirgin Islands, British,\nVirgin Islands, U.S.,\nViet Nam,\nVanuatu,\nWallis and Futuna,\nSamoa,\nYemen,\nMayotte,\nSouth Africa,\nZambia,\nZimbabwe\n]\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-geoblocking-class"}, {"document_id": "ibmcld_13118-27377-28138", "score": 14.36729840156319, "text": "\nnull 7634piweba3y.prodigy.comGET /shuttle/miss... 20001/Jul/1995:04:1...\n null25218 ntigate.nt.comGET /software/win... 20001/Jul/1995:04:1...\n null 4441 ntigate.nt.comGET /software/win... 20001/Jul/1995:04:1...\n null 1414 ntigate.nt.comGET /images/const... 20001/Jul/1995:04:1...\n null45308line03.pm1.abb.mi...GET /shuttle/miss... 20001/Jul/1995:04:1...\n null 669 source.iconz.co.nzGET /images/WORLD... 20001/Jul/1995:04:1...\n null 234 source.iconz.co.nzGET /images/USA-l... 20001/Jul/1995:04:1...\n null 363 source.iconz.co.nzGET /images/MOSAI... 20001/Jul/1995:04:1...\n null13372 ntigate.nt.comGET /software/win... 20001/Jul/1995:04:1...\n+---------------------------+-----+--------------------+--------------------+------------+--------------------+\n\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-big-data-log-analytics"}, {"document_id": "ibmcld_11602-17406-18830", "score": 14.099364883841865, "text": "\n[IBM Cloud compliance programs](https://www.ibm.com/cloud/compliance) provide compliance and trust certifications, which reaffirm IBM's commitment to protection of customer data and applications. These compliance programs are for regulations, standards, and frameworks across Global, Government, Industry, and Regional.\n\nMore supplementary information to the IBM Cloud compliance programs is available on [IBM Cloud service offering descriptions and terms](https://www-03.ibm.com/software/sla/sladb.nsf/sla/bm?OpenDocument) which contain links to individual Data Processing and Protection data sheets for IBM Cloud offerings.\n\nEach IBM Cloud\u00ae for SAP offering uses different infrastructure configurations and approaches to providing the service and will therefore be certified independent of each other. These certifications can be checked on the previous links or clarified by contacting IBM Cloud or your IBM representative. Following is a small extract from the full list of recognized compliance, certifications, attestations, or reports available across the various IBM Cloud\u00ae for SAP offerings:\n\n\n\n* ISO 27001\n* ISO 27017\n* ISO 27018\n* EU-US Privacy Shield Policy\n* GDPR Ready\n* Germany Federal Office for Information Security (BSI) C5\n* HIPAA for Healthcare USA\n* ITAR Compliant\n* PCI-DSS for Payment Card Industry USA\n* Singapore Multi-Tier Cloud Security Standard (MTCS)\n* SOC1 Type 2\n* SOC2 Type 2\n* SOC3\n* ...more", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-iaas-offerings"}, {"document_id": "ibmcld_00530-9526-10355", "score": 13.126137897874653, "text": "\n\"Person_name\": \"Robert De Niro\",\n\"Movie_year\": map[string][]interface{}{\n\"$in\": []interface{}{1978, 2009},\n},\n},\n)\n\nfindResult, _, err := service.PostFind(postFindOptions)\nif err != nil {\npanic(err)\n}\n\nb, _ := json.MarshalIndent(findResult, \"\", \" \")\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding/json\"\n\"fmt\"\n\"github.com/IBM/cloudant-go-sdk/cloudantv1\"\n)\n\nSee the following example result from the search:\n\n{\n\"docs\": [\n{\n\"_id\": \"d9e6a7ae2363d6cfe81af75a392eb9f2\",\n\"_rev\": \"1-9faa75d7ea524448b1456a6c69a4391a\",\n\"Movie_runtime\": 183,\n\"Movie_rating\": \"R\",\n\"Person_name\": \"Robert De Niro\",\n\"Movie_genre\": \"DW\",\n\"Movie_name\": \"Deer Hunter, The\",\n\"Person_pob\": \"New York, New York, USA\",\n\"Movie_year\": 1978,\n\"Person_dob\": \"1943-08-17\"\n}\n],\n\"bookmark\": \"g2w ... c2o\"\n}\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-example-movies-demo-database"}, {"document_id": "ibmcld_00530-4127-5130", "score": 12.745854522247598, "text": "\nservice = CloudantV1.new_instance()\n\nresponse = service.post_find(\ndb='my-movies',\nselector={'Person_name': 'Zoe Saldana'}\n).get_result()\n\nprint(response)\n\npostFindOptions := service.NewPostFindOptions(\n\"my-movies\",\nmap[string]interface{}{\n\"Person_name\": \"Zoe Saldana\",\n},\n)\n\nfindResult, _, err := service.PostFind(postFindOptions)\nif err != nil {\npanic(err)\n}\n\nb, _ := json.MarshalIndent(findResult, \"\", \" \")\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding/json\"\n\"fmt\"\n\"github.com/IBM/cloudant-go-sdk/cloudantv1\"\n)\n\nSee the following example result from the search:\n\n{\n\"docs\": [\n{\n\"_id\": \"d9e6a7ae2363d6cfe81af75a3941110b\",\n\"_rev\": \"1-556aec0e89fa13769fbf59d651411528\",\n\"Movie_runtime\": 162,\n\"Movie_rating\": \"PG-13\",\n\"Person_name\": \"Zoe Saldana\",\n\"Movie_genre\": \"AVYS\",\n\"Movie_name\": \"Avatar\",\n\"Movie_earnings_rank\": \"1\",\n\"Person_pob\": \"New Jersey, USA\",\n\"Movie_year\": 2009,\n\"Person_dob\": \"1978-06-19\"\n}\n],\n\"bookmark\": \"g2wA ... Omo\"\n}\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-example-movies-demo-database"}, {"document_id": "ibmcld_10067-2911-4724", "score": 12.623117612248063, "text": "\nibmcloud cbr zone-create --addresses 129.XX.XX.XX --description \"Allow only client IP\" --name allow-client-ip\n2. Verify the network zone was created.\n\nibmcloud cbr zones\n\n\n\n\n\n\n\n Step 2: Creating your CBR rule \n\n\n\n1. After you create your network zone (allowlist), create a CBR rule and add the network zone you created in the previous step. The following example creates a rule that uses the cluster API type. Replace NETWORK-ZONE-ID with the ID of the allow-client-ip network zone that you created in step 1.\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --description \"privateAccess=allowAll, publicAccess=oneIP\" --service-name containers-kubernetes --service-instance CLUSTER-ID --context-attributes endpointType=private --context-attributes endpointType=public,networkZoneId=NETWORK-ZONE-ID\n\nUnderstanding the command options.\n\n--api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster\n: Set the crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster API to allow only resources in the network zone you created earlier to access only the cluster APIs, which include the APIs for various oc commands.\n\n--service-instance CLUSTER-ID\n: Scope the rule to a single cluster so that only resources in the network zone you created earlier can access only the CLUSTER-ID.\n\n--context-attributes endpointType=private\n: Set the context attribute endpointType=private without associating a network zone allows all private traffic to the cluster.\n\n--context-attributes endpointType=public,networkZoneId=all-client-ip\n: Set the context attribute endpointType=public and associate the networkZoneId=allow-client-ip that you created earlier to allow only the resources in the allow-client-ip zone to access the cluster over the public network.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cbr-tutorial"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06320-2897-4555", "score": 31.30390374623852, "text": "\n[NodeSync](https://docs.datastax.com/en/dse/6.7/dse-admin/datastax_enterprise/config/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs. Traditional repairs are unnecessary, as the automation ensures that NodeSync handles the repairs for you.\n\nWhile the automation enables NodeSync, you can also manually create tables with NodeSync enabled so that the service can repair the tables' data when necessary:\n\nCREATE TABLE myTable (...) WITH nodesync = { 'enabled': 'true'};\n\nFor more information, see [enabling the NodeSync service](https://docs.datastax.com/en/dse/6.7/dse-admin/datastax_enterprise/config/enablingNodesync.html).\n\nNodetool is unsupported. Manual repairs that are issued against any table that is enabled with the NodeSync service [are ignored](https://docs.datastax.com/en/opscenter/6.5/opsc/online_help/services/opscNodeSyncService.htmlNodeSyncServiceversusRepairService). See error:\n\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https://github.com/nosqlbench/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-getting-started"}, {"document_id": "ibmcld_06320-1330-3318", "score": 24.588171423978395, "text": "\nAfter you click Create, the system displays a message to say that the instance is being provisioned, which returns you to the Resource list. From the Resource list, you see that the status for your instance is, Provision in progress.\n8. When the status changes to Active, select the instance.\n\n\n\n\n\n\n\n Step 3: Set your admin password \n\n\n\n* [Set the Admin Password](https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-admin-password) for your deployment.\n\n\n\nReview the [Getting to production](https://cloud.ibm.com/docs/cloud-databases?topic=cloud-databases-best-practices) documentation for general guidance on setting up a basic IBM Cloud\u00ae Databases for DataStax deployment.\n\n\n\n\n\n Step 4: Connect with DataStax drivers \n\nDrivers are a key component to connecting external applications to your Databases for DataStax deployment. Review the information on [Connecting an external application](https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-external-app) for details on compatible drivers. Further details on specific drivers, including upgrade guides, can be found at [Developing applications with Apache Cassandra and DataStax Enterprise](https://docs.datastax.com/en/devapp/doc/devapp/aboutDrivers.html).\n\nOnly DataStax drivers that are explicitly listed in the [Connecting an external application](https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-external-app) table function correctly for connecting to Databases for DataStax.\n\n\n\n\n\n Step 5: Node repairs with NodeSync \n\n[NodeSync](https://docs.datastax.com/en/dse/6.7/dse-admin/datastax_enterprise/config/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-getting-started"}, {"document_id": "ibmcld_10534-166414-167777", "score": 21.597720404326576, "text": "\n* [Enabling KMS encryption for the cluster through the console](https://cloud.ibm.com/docs/openshift?topic=openshift-encryptionkms_ui)\n* [Rotating the root key for your cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-encryptionkms_rotate)\n\n\n\n* [Verifying secret encryption](https://cloud.ibm.com/docs/openshift?topic=openshift-encryptionverify_kms)\n* [Managing encryption for the worker nodes in your cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-encryptionworker-encryption)\n\n\n\n* [Classic worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-encryptionworker-encryption-classic)\n* [VPC worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-encryptionworker-encryption-vpc)\n* [Satellite worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-encryptionworker-encryption-satellite)\n\n\n\n\n\n[Configuring security context constraints](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_sccopenshift_scc)\n\n\n\n* [Customizing security context constraints](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_scccustomize_sccs)\n* [Default Red Hat OpenShift security context constraints](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_sccoc_sccs)\n* [Default IBM security context constraints](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_sccibm_sccs)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_06251-14621-16000", "score": 21.305443636962558, "text": "\nIf you want to attach raw, unformatted block storage to a classic worker node, you must install the [IBM Cloud Block Storage attacher plug-in](https://cloud.ibm.com/docs/containers?topic=containers-utilitiesblock_storage_attacher).\n\nBefore you begin:\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\n\n\n1. Check which region and zone your VPC worker node is in.\n\nibmcloud ks worker ls -c <cluster_name>\n2. Decide on the [Block Storage for Classic profile](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-profiles) that best meets the capacity and performance requirements that you have.\n3. [Provision a Block Storage for Classic volume](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-block-storage). The volume that you provision must be in the same resource group, region, and zone as the worker node.\n4. Retrieve your IAM token.\n\nibmcloud iam oauth-tokens\n5. Retrieve the ID of the worker node that you want to attach to the Block Storage for Classic instance. Make sure to select a worker node that is located in the same zone as your Block Storage for Classic volume.\n\nibmcloud ks worker ls --cluster <cluster_name_or_ID>\n6. Use a POST request to attach your Block Storage for Classic volume to the worker node.\n\nExample request", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-utilities"}, {"document_id": "ibmcld_06251-22863-24659", "score": 20.81383465882361, "text": "\nThe instructions in this topic are available for VPC worker nodes only. If you want to attach raw, unformatted block storage to a classic worker node, you must install the [IBM Cloud Block Storage attacher plug-in](https://cloud.ibm.com/docs/containers?topic=containers-utilitiesblock_storage_attacher).\n\nBefore you begin:\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\n\n\n1. List your storage volumes and note the ID of the volume that you want to attach.\n\nibmcloud is vols\n2. List the worker nodes in your cluster and note the ID of the worker node where you want to attach your volume.\n\nibmcloud ks worker ls -c <cluster_name_or_ID>\n3. Attach your Block Storage for Classic to your VPC worker node.\n\nibmcloud ks storage attachment create --cluster <cluster_name_or_ID> --volume <volume> --worker <worker_ID>\n\n\n\n\n\n Removing raw Block Storage for VPC from VPC worker nodes by using the CLI \n\nYou can remove storage from your worker node by using the ibmcloud ks storage attachment rm command.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\n\n\n1. List your storage volumes and note the ID of the volume that you want to remove.\n\nibmcloud is vols\n2. Get the details of your volume such as the worker-id where the volume is attached. The worker-id is listed as the Instance name in the Volume Attachment Instance Reference section of the command output.\n\nibmcloud is vol <volume-ID>\n\nExample output\n\nVolume Attachment Instance Reference Attachment type Instance ID Instance name Auto delete Attachment ID Attachment name", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-utilities"}, {"document_id": "ibmcld_10208-19720-21415", "score": 20.140572036436563, "text": "\nIf you try to set the context for your cluster by running ibmcloud oc cluster config, the command fails.\n\noc get secrets --all-namespaces\n\nExample output\n\nUnable to connect to the server: dial tcp 169.48.110.250:32346: i/o timeout\n7. For clusters that run Red Hat OpenShift version 4.5 or later, check that your cluster is in a warning state. Your cluster remains in this state and is unusable until you enable your root key again.\n\nibmcloud oc cluster get -c <cluster_name_or_ID>\n8. In your KMS instance, [enable the root key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keys) so that your cluster returns to a normal state and becomes usable again.\n\n\n\n\n\n\n\n Managing encryption for the worker nodes in your cluster \n\nYou can manage the encryption of the local disks in your worker nodes by using a [key management service (KMS) provider](https://cloud.ibm.com/docs/openshift?topic=openshift-encryptionkms) such as [Key Protect](https://cloud.ibm.com/docs/key-protect?topic=key-protect-getting-started-tutorial). The way that you manage encryption for worker nodes depends on the infrastructure provider.\n\n\n\n Classic worker nodes \n\nClassic infrastructure: Classic worker nodes have two disks, and you can manage encryption for the second disk.\n\n\n\n* The primary disk has the kernel images to boot your worker node. This disk is unencrypted.\n* The secondary disk has the container file system and locally pulled images. This disk is AES 256-bit encrypted with an IBM-managed LUKS encryption key that is unique to the worker node and stored as a Kubernetes secret in your cluster. When you reload or update your worker nodes, the LUKS keys are rotated.\n\n\n\n\n\n\n\n VPC worker nodes", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-encryption"}, {"document_id": "ibmcld_10394-7-1848", "score": 20.03598119930232, "text": "\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-classic"}, {"document_id": "ibmcld_10068-140831-142138", "score": 19.6768658544308, "text": "\nIBM Cloud Block Storage driver and plug-in 1.17.2 v2.0.0 Updated to use the universal base image (UBI), to use Go version 1.15.5, to run with a least privileged security context, and to improve logging. Updated image to implement additional IBM security controls. \n IBM Cloud Controller Manager v1.17.15-1 v1.17.16-1 Updated to support the Kubernetes 1.17.16 release. \n IBM Cloud File Storage for Classic plug-in N/A N/A Updated to run with a privileged security context. \n IBM Cloud RBAC Operator c148a8a f859228 Updated image for [CVE-2020-1971](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-1971) and [CVE-2020-24659](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-24659). \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.3.40_1549_openshift, released 21 December 2020 \n\nThe following table shows the changes that are in the worker node fix pack update 4.3.40_1549_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.40_1548_openshift\n\n Component Previous Current Description \n\n HAProxy db4e6d 9b2dca Image update for [CVE-2020-1971](https://nvd.nist.gov/vuln/detail/CVE-2020-1971) and [CVE-2020-24659](https://nvd.nist.gov/vuln/detail/CVE-2020-24659).", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-changelog_archive"}, {"document_id": "ibmcld_06145-7-1743", "score": 19.652520913076728, "text": "\nClassic: Why can't I add worker nodes with an invalid VLAN ID? \n\nClassic infrastructure\n\n What\u2019s happening \n\nYour IBM Cloud account was suspended, or all worker nodes in your cluster were deleted. After the account is reactivated, you can't add worker nodes when you try to resize or rebalance your worker pool. You see an error message similar to the following:\n\nSoftLayerAPIError(SoftLayer_Exception_Public): Could not obtain network VLAN with id 123456.\n\n Why it\u2019s happening \n\nWhen an account is suspended, the worker nodes within the account are deleted. If a cluster has no worker nodes, IBM Cloud infrastructure reclaims the associated public and private VLANs. However, the cluster worker pool still has the previous VLAN IDs in its metadata and uses these unavailable IDs when you rebalance or resize the pool. The nodes fail to create because the VLANs are no longer associated with the cluster.\n\n How to fix it \n\nYou can [delete your existing worker pool](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_pool_rm), then [create a new worker pool](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_pool_create).\n\nAlternatively, you can keep your existing worker pool by ordering new VLANs and using these to create new worker nodes in the pool.\n\nBefore you begin: [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\n\n\n1. To get the zones that you need new VLAN IDs for, note the Location in the following command output. Note: If your cluster is a multizone, you need VLAN IDs for each zone.\n\nibmcloud ks cluster ls\n2.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-suspended"}, {"document_id": "ibmcld_10576-7-1739", "score": 19.652520913076728, "text": "\nClassic: Why can't I add worker nodes with an invalid VLAN ID? \n\nClassic infrastructure\n\n What\u2019s happening \n\nYour IBM Cloud account was suspended, or all worker nodes in your cluster were deleted. After the account is reactivated, you can't add worker nodes when you try to resize or rebalance your worker pool. You see an error message similar to the following:\n\nSoftLayerAPIError(SoftLayer_Exception_Public): Could not obtain network VLAN with id 123456.\n\n Why it\u2019s happening \n\nWhen an account is suspended, the worker nodes within the account are deleted. If a cluster has no worker nodes, IBM Cloud infrastructure reclaims the associated public and private VLANs. However, the cluster worker pool still has the previous VLAN IDs in its metadata and uses these unavailable IDs when you rebalance or resize the pool. The nodes fail to create because the VLANs are no longer associated with the cluster.\n\n How to fix it \n\nYou can [delete your existing worker pool](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_worker_pool_rm), then [create a new worker pool](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_worker_pool_create).\n\nAlternatively, you can keep your existing worker pool by ordering new VLANs and using these to create new worker nodes in the pool.\n\nBefore you begin: [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\n\n\n1. To get the zones that you need new VLAN IDs for, note the Location in the following command output. Note: If your cluster is a multizone, you need VLAN IDs for each zone.\n\nibmcloud oc cluster ls\n2.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-suspended"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16729-112397-114109", "score": 35.379678801339125, "text": "\n[Migrating an Enterprise plan to a Lite or Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan)Migrating an Enterprise plan to a Lite or Standard plan\n\nMigration from the Enterprise plans to IBM Cloudant Lite or Standard plans includes these tasks, which are described in the following steps.\n\nCloudant\n\n\n\n* 30 minutes\n* 2023-04-06\n\n\n\n[Migrating from a Lite plan to a Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan)Migrating from a Lite plan to a Standard plan\n\nMigrating from the free Lite plan to the Standard plan by completing the following tasks.\n\nCloudant\n\n\n\n* 15 minutes\n* 2023-04-06\n\n\n\n[Finding your IBM Cloudant plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan)Finding your IBM Cloudant plan\n\nYou can subscribe to different IBM Cloudant plans, including the Lite, Standard, or Enterprise plans.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-03-30\n\n\n\n[Combining IBM Cloudant with other IBM services](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-combine-ibm-services)Combining IBM Cloudant with other IBM services\n\nEach database technology has its own strengths and weaknesses. Some are built for high availability and data durability (at the expense of more hardware and extra cost). Others favor speed and can churn out blazingly fast queries (but might lose data in a sudden power failure).\n\nCloudant\n\n\n\n* 2023-03-30\n\n\n\n[Enhance cloud security by applying context-based restrictions](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_07578-447531-449109", "score": 35.258785702047724, "text": "\n[Upload](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https://www.ibm.com/cloud/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-447513-449091", "score": 35.258785702047724, "text": "\n[Upload](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https://www.ibm.com/cloud/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_00535-0-1738", "score": 35.180728793881805, "text": "\n\n\n\n\n\n\n  Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\n  Which plans can I migrate? \n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n*  IBM Cloudant Enterprise\n*  Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\n  Can I back up my data before I migrate? \n\nThe IBM Cloudant team advises that you use the [couchbackup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https://www.ibm.com/cloud/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\n  Can I keep my username.cloudant.com domain and redirect it to the new service on IBM Cloudant? \n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\n  Who do I contact if I have questions? \n\nGo to the [IBM Cloud Support portal](https://www.ibm.com/cloud/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-migration"}, {"document_id": "ibmcld_07578-448564-450242", "score": 34.85183286585423, "text": "\nThe IBM Cloudant team advises that you use the [couchbackup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https://www.ibm.com/cloud/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https://www.ibm.com/cloud/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-448546-450224", "score": 34.85183286585423, "text": "\nThe IBM Cloudant team advises that you use the [couchbackup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https://www.ibm.com/cloud/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https://www.ibm.com/cloud/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_00558-1499-3456", "score": 33.477943581962045, "text": "\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-public"}, {"document_id": "ibmcld_12904-1535-3460", "score": 33.3326251559079, "text": "\nThe available plans include Lite and Standard. When you select a plan, Capacity displays, and the Cost estimator shows the monthly charge for the selected plan. By default, the [Lite plan](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-publiclite-plan) is selected.\n\n\n\n Lite plan \n\nThe Lite plan is free, and is designed for development and evaluation purposes. All of IBM Cloudant's functions are included, but Lite plan instances have a fixed amount of provisioned throughput capacity and data storage. The provisioned throughput capacity is fixed at 20 reads per second, 10 writes per second, and 5 global queries per second, and data storage is capped at 1 GB.\n\nStorage usage is checked daily. If you exceed your 1-GB storage limit, requests to the IBM Cloudant instance receive a 402 status code with the following error message, Account exceeded its data usage quota. An upgrade to a paid plan is required. A banner also appears on the IBM Cloudant Dashboard. You can still read and delete data. However, to write new data, you have two options. First, you can upgrade to a paid [Standard plan](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan), which removes the write limitation immediately. Alternatively, you can delete data so that your total storage falls under the 1-GB limit and wait until the next daily storage check runs for your instance to allow writes again.\n\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message.", "title": "", "source": "https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-public"}, {"document_id": "ibmcld_00532-0-1979", "score": 33.27665473360652, "text": "\n\n\n\n\n\n\n  Availability zones FAQ \n\nYou can create an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance on IBM Cloud in a multi-zone or single-zone region.\n\nThe following tutorials demonstrate how to create an instance:\n\n\n\n*  Using the dashboard. For more information, see [Getting started with IBM Cloudant](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudant).\n\n\n\nIf you want to create an IBM Cloudant Dedicated Hardware plan instance, follow the [Creating and leveraging an IBM Cloudant Dedicated Hardware plan instance on IBM Cloud](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-creating-and-leveraging-an-ibm-cloudant-dedicated-hardware-plan-instance-on-ibm-cloudcreating-and-leveraging-an-ibm-cloudant-dedicated-hardware-plan-instance-on-ibm-cloud) tutorial.\n\n\n\n  What is an availability zone? \n\nWhen you create an instance, after you select the IBM Cloudant tile, you must select a region. These locations are called availability zones. An availability zone is an IBM Cloud\u00ae Public location that hosts your data. All Lite and Standard plans automatically deploy into a multi-zone region. Dedicated Hardware plan instances can be deployed in most [IBM data center locations](https://www.ibm.com/cloud/data-centers/).\n\n\n\n\n\n  What is the difference between a single-zone and a multi-zone region? \n\nA multi-zone region includes three availability zones that can be used by an instance that is deployed to that region. The multi-zone regions available with IBM Cloudant include the following regions:\n\n\n\n*  Dallas\n*  Frankfurt\n*  London\n*  Osaka\n*  Sydney\n*  Tokyo\n*  Washington DC\n\n\n\nA single-zone region offers only one availability zone for that region. The single-zone regions available with IBM Cloudant include the following regions:\n\n\n\n*  Seoul\n*  Chennai\n\n\n\nFor more information, see [Plans and provisioning](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-publiclocations-and-tenancy).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-availability-zones"}, {"document_id": "ibmcld_07578-449817-451754", "score": 33.23722042967061, "text": "\nFor more information, see [Migrating from a Lite plan to a Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https://www.ibm.com/cloud/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n* Can I keep my username.cloudant.com domain and redirect it to the new service on IBM Cloudant?\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n* Who do I contact if I have questions?\n\nGo to the [IBM Cloud Support portal](https://www.ibm.com/cloud/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n* Modeling data to scale FAQ\n\n Modeling data to scale FAQ \n\nThe way you model data on IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae significantly impacts how your application can scale. The underlying data model differs substantially from a relational model, and ignoring this distinction can be the cause of performance issues down the road.\n\nAs always, successful modeling involves achieving a balance between ease of use versus the performance characteristics you're hoping to achieve.\n\n(The FAQ for modeling data to scale is based on a blog article by Mike Rhodes, My top five tips for modeling your data to scale.)\n\n\n\nIf you're changing the same piece of state at a rate of once per second or more, consider making your documents immutable. This practice significantly reduces the chance that you create conflicted documents.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03068-35822-37326", "score": 22.986289427170185, "text": "\ndefaultMode: 420\ncontainers:\n- name: skill-search\nvolumeMounts:\n- name: updated-cacerts\nmountPath: /opt/ibm/java/jre/lib/security/cacerts\nsubPath: cacerts\nEOF\nShow more\n6. Wait until new search skill pods are created. It might take up to 10 minutes before the updates take affect.7. Check that the search skill feature is working as expected.<-- </ol> --><-- </section \"id=\"section-apply-the-fix\" \"> --><-- </section \"id=\"section-troubleshoot-150-search-skill\" \"> --><-- <section \"id=\"section-troubleshoot-150-disable-hpa\" \"> --> Disable Horizontal Pod Autoscaling and set a maximum number of master pods Horizontal Pod Autoscaling (HPA) is enabled automatically for Watson Assistant. As a result, the number of replicas changes dynamically in the range of 1 to 10 replicas. You can disable HPA if you want to limit the maximum number of master pods or if you're concerned about master pods being created and deleted too frequently.<-- <ol> -->1. First, disable HPA for the master microservice by running the following command. In these steps, substitute your instance name for the INSTANCE_NAME variable:\noc patch wa ${INSTANCE_NAME} --type='json' --patch='{\"op\": \"add\", \"path\": \"/appConfigOverrides/clu\", \"value\":{\"master\":{\"autoscaling\":{\"enabled\":false}}}}] ! ! ! '\n2. Wait until the information propagates into the Watson Assistant operator:\nsleep 600\n3. Run the following command to remove HPA for the master microservice\noc delete hpa ${INSTANCE_NAME}-master\n4. Wait for about 30 seconds:\nsleep 30", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-troubleshoot"}, {"document_id": "ibmcld_03373-7076-8670", "score": 21.951506896225183, "text": "\nYou can then create a collection from a data source and configure your search skill to search this collection for answers to customer queries.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question gets routed to the search skill.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/search-skill-diagram.png)\n\n\n\n\n\n Creating a skill \n\nYou can add one conversation skill (actions or dialog) and one search skill to an assistant.\n\n\n\n Conversation \n\n\n\n* [Actions skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-actions-add)\n* [Dialog Skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add)\n\n\n\n\n\n\n\n Search \n\n\n\n* [Search Skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add)\n\n\n\n\n\n\n\n\n\n Skill limits \n\nThe number of skills you can create depends on your Watson Assistant plan type. Any sample dialog skills that are available for you to use do not count toward your limit unless you use them. A skill version does not count as a skill.\n\n\n\nPlan details\n\n Plan Maximum number of skills of each type per service instance \n\n Enterprise 100 \n Premium (legacy) 100 \n Plus 50 \n Standard (legacy) 20 \n Lite, Trial 5 \n\n\n\n* After 30 days of inactivity, an unused skill in a Lite plan service instance might be deleted to free up space.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add"}, {"document_id": "ibmcld_16364-147609-149563", "score": 21.211054707386705, "text": "\nAll workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do. For more information about disambiguation, see [Disambiguation](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation).\n\nDialog search issue\n: In some skills, the search function is not working in the Dialog page. A new user interface library, which increases the page responsiveness, is being rolled out to existing service instances in phases. This search issue affects only dialog skills for which the new library is not yet enabled.\n\nMissing skills issue\n: In some cases, workspaces that were created through the API only are not being displayed when you open the Watson Assistant user interface. Normally, these workspaces are displayed as dialog skills. If you do not see your skills from the UI, don't worry; they are not gone. Contact support to report the issue, so the team can enable the workspaces to be displayed properly.\n\n\n\n\n\n 15 July 2019 \n\nNumeric system entities upgrade available in Dallas\n: The new system entities are now also available as a beta feature for instances that are hosted in Dallas. See [New system entities](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 12 June 2019 \n\nNumeric system entities upgrade\n: New system entities are available as a beta feature that you can enable in dialog skills that are written in English or German. The revised system entities offer better date and time understanding. They can recognize date and number spans, national holiday references, and classify mentions with more precision.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03026-3251-4928", "score": 20.513707895464794, "text": "\nFor example, questions about politics for an assistant that makes pet grooming appointments exclusively.\n\nYou teach your assistant about subjects to ignore by marking utterances that discuss subjects which are out of scope for your application as being irrelevant. Such utterances become counterexamples for the model.\n\n\n\nThe best way to build an assistant that understands your domain and the specific needs of your customers is to take the time to build good training data, especially data that includes counterexamples.\n\nIrrelevance detection is designed to bridge any gaps you might have in your counterexample data as you start to build your skill. An alternative method for evaluating the relevance of a newly submitted utterance is triggered in addition to the standard method.\n\nThe supplemental method examines the structure of the new utterance and compares it to the structure of the user example utterances in your training data. This alternate approach helps skills that have few or no counterexamples recognize irrelevant utterances. It is likely to have less of an effect for skills that have a sufficient number of counterexamples defined already.\n\nNote that the new method relies on structural information that is based on data from outside your skill. So, while the new method can be useful as you are starting out, to build an assistant that provides a more customized experience, you want it to use information from data that is derived from within the application's domain. The way to ensure that your assistant does so is by adding your own counterexamples.\n\n\n\n\n\n Counterexample limits \n\nThe maximum number of counterexamples that you can create is 25,000.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-irrelevance-detection"}, {"document_id": "ibmcld_03369-109994-112063", "score": 20.24919750982755, "text": "\nIt is enabled automatically for new English-language dialog skills.\n\n\n\n\n\n\n\n 26 July 2019 \n\nMissing skills issue is resolved\n: In some cases, workspaces that were created through the API only were not being displayed when you opened the Watson Assistant user interface. This issue has been addressed. All workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do. For more information about disambiguation, see [Disambiguation](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-runtimedialog-runtime-disambiguation).\n\nDialog search issue\n: In some skills, the search function is not working in the Dialog page. A new user interface library, which increases the page responsiveness, is being rolled out to existing service instances in phases. This search issue affects only dialog skills for which the new library is not yet enabled.\n\nMissing skills issue\n: In some cases, workspaces that were created through the API only are not being displayed when you open the Watson Assistant user interface. Normally, these workspaces are displayed as dialog skills. If you do not see your skills from the UI, don't worry; they are not gone. Contact support to report the issue, so the team can enable the workspaces to be displayed properly.\n\n\n\n\n\n 15 July 2019 \n\nNumeric system entities upgrade available in Dallas\n: The new system entities are now also available as a beta feature for instances that are hosted in Dallas. See [New system entities](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities)\n\n\n\n\n\n 12 June 2019 \n\nNumeric system entities upgrade\n: New system entities are available as a beta feature that you can enable in dialog skills that are written in English or German.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_16364-146046-148039", "score": 20.159263785142375, "text": "\n: For some first-time users, a new introductory product tour is shown that the user can choose to follow to perform the initial steps of creating an assistant.\n\n\n\n\n\n 1 August 2019 \n\nWebhook callouts are available\n: Add webhooks to dialog nodes to make programmatic calls to an external application as part of the conversational flow. The new Webhook support simplifies the callout implementation process. (No more action JSON objects required.) For more information, see [Making a programmatic call from a dialog node](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-webhooks).\n\nImproved dialog page responsiveness\n: In all service instances, the user interface of the Dialog page was updated to use a new JavaScript library that increases the page responsiveness. As a result, the look of some graphical user interface elements, such as buttons, changed slightly, but the function did not.\n\n\n\n\n\n 31 July 2019 \n\nSearch skill and autocorrection are generally available\n: The search skill and spelling autocorrection features, which were previously available as beta features, are now generally available.\n\n\n\n* Search skills can be created by users of Plus or Premium plans only.\n* You can enable autocorrection for English-language dialog skills only. It is enabled automatically for new English-language dialog skills.\n\n\n\n\n\n\n\n 26 July 2019 \n\nMissing skills issue is resolved\n: In some cases, workspaces that were created through the API only were not being displayed when you opened the Watson Assistant user interface. This issue has been addressed. All workspaces that you create by using the API are displayed as dialog skills when you open the user interface.\n\n\n\n\n\n 23 July 2019 \n\nDialog search is fixed\n: In some skills, the search function was not working in the Dialog page. The issue is now fixed.\n\n\n\n\n\n 17 July 2019 \n\nDisambiguation choice limit\n: You can now set the maximum number of options to show to users when the assistant asks them to clarify what they want to do.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03218-6464-8324", "score": 19.891658360475382, "text": "\nYou can change the settings that are applied automatically to disambiguation from the Options page.To edit the disambiguation settings, complete the following steps:<-- <ol> -->1. From the Skills menu, click Options.2. Click Disambiguation.3. In the Disambiguation message field, add text to show before the list of dialog node options. For example, What do you want to do?4. In the Anything else field, add text to display as an additional option that users can pick if none of the other dialog node options reflect what the user wants to do. For example, None of the above.\nKeep the message short, so it displays inline with the other options. The message must be less than 512 characters. For information about what your assistant does if a user chooses this option, see Handling none of the above]] ! .\n5. If you want to limit the number of disambiguation options that can be displayed to a user, then in the Maximum number of suggestions field, specify a number between 2 and 5.<-- </ol> -->Your changes are automatically saved.You can use the API to modify additional disambiguation settings. These settings include the disambiguation sensitivity, which affects how often disambiguation is triggered and how many choices are included. For more information, see the API Reference]] ! ! ! !!.Next, you must decide which dialog nodes you want to make eligible for disambiguation. From the Skills menu, click Dialog.<-- </section \"id=\"section-dialog-runtime-disambig-edit\" \"> --><-- <section \"id=\"section-dialog-runtime-disambig-choose-nodes\" \"> --> Choosing nodes to not show as disambiguation options All nodes are eligible to be included in the disambiguation list. - Nodes at any level of the tree hierarchy are included.\n- Nodes that condition on intents, entities, special conditions, context variables, or any combination of these values are included.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-runtime"}, {"document_id": "ibmcld_07232-18187-19918", "score": 18.91254488178031, "text": "\n* Select language - Choose the language of the websites from the list of supported languages. For the list of languages that Discovery supports, see [Language support](https://cloud.ibm.com/docs/discovery?topic=discovery-language-support). You should create a separate collection for each language.\n* URL group to sync - Enter your URL and click the Add button to add it to the URL group. To specify the Crawl settings for this URL group, click the ![Cog](https://cloud.ibm.com/docs-content/v1/content/ded4adc3ea0bd2a81b113c579f2b1183926da211/discovery/images/icon_settings.png) icon. You can set the Maximum hops, which is the number of consecutive links to follow from the starting URL (the starting URL is 0). The default number of hops is 2 and the maximum is 20. If you are using the API, the maximum is 1000. You can specify URL paths to exclude from the crawl in the Exclude URLs where the path includes field. Separate the paths, using commas, for example, if you specified the URL http://domain.com, you could exclude http://domain.com/licenses and http://domain.com/pricing by entering /licenses/, /pricing/.\n\n\n\nFAQ extraction was available as a beta feature that was supported only with web crawl connectors built for use from a Search skill in Watson Assistant. The beta feature is deprecated. FAQ extraction will stop being supported in v1 Discovery service instances on 1 March 2022.\n\nWhen you specify a URL to crawl, the final / determines the subtree to crawl. For example, if you enter the URL https://www.example.com/banking/faqs.html, all URLs that begin with https://www.example.com/banking/ are crawled, and the input of https://www.example.com/banking crawls all URLs that begin with https://www.example.com/.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-sources"}, {"document_id": "ibmcld_02900-24807-26597", "score": 18.862812785231945, "text": "\nFrom the Skills menu of the dialog skill where you want to enable disabmiguation, click Options.2. On the Disambiguation page, switch the toggle to On.3. In the Disambiguation message field, add text to show before the list of dialog node options. For example, What do you want to do?4. In the Anything else field, add text to display as an additional option that users can pick if none of the other dialog node options reflect what the user wants to do. For example, None of the above.\nKeep the message short, so it displays inline with the other options. The message must be less than 512 characters. For information about what your assistant does if a user chooses this option, see Handling none of the above]] !!.\n5. If you want to limit the number of disambiguation options that can be displayed to a user, then in the Maximum number of suggestions field, specify a number between 2 and 5.\nYour changes are automatically saved.\n6. Now, click Dialog from the Skills menu. Review your dialog to decide which dialog nodes you want the assistant to ask for help with.\n<-- <ul> -->\n\n* You can pick nodes at any level of the tree hierarchy.\n* You can pick nodes that condition on intents, entities, special conditions, context variables, or any combination of these values.\n\n<-- </ul> -->\n\nSee Choosing nodes]]!Shows where to add the external node name information in the node edit view.Shows where to add the external node name information in the node edit view_.]!! ! ! for tips.\n\nFor each node that you want to make available from the disambiguation options list, complete the following steps:\n\n<-- <ol> -->\n\n1. Click to open the node in edit view.\n2. In the external node name field, describe the user task that this dialog node is designed to handle. For example, Cancel an account.\n\n!]", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime"}, {"document_id": "ibmcld_03385-4855-5395", "score": 18.469485190491223, "text": "\nThe JSON cannot contain tabs, newlines, or carriage returns.\n\nFor dialog skills only: The maximum size for a skill JSON file is 10 MB. If you need to upload a larger skill, consider using the REST API. For more information, see the [API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v1?curl=createworkspace).\n5. Click Upload and overwrite.\n\nIf you have trouble uploading a dialog skill, see [Troubleshooting skill upload issues](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-tasksskill-dialog-add-import-errors).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-tasks"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09559-3849-5260", "score": 23.62373063422695, "text": "\nIf you delete a deployment that is protected with an HPCS key, the deployment remains registered against the key during the soft-deletion period (up to 9 days). If you need to delete the key in the soft-deletion period, you must [force delete](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys) the key. After the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-hpcs"}, {"document_id": "ibmcld_01034-3831-4923", "score": 23.619792502524227, "text": "\nAfter the soft-deletion period, the key can be deleted without the force. You can check the [association between the key and your deployment](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-key-details) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nHyper Protect Crypto Services enables [initiation of a force delete](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them. Key deletion is [sent to the Activity Tracker](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-at-events) as hs-crypto.secrets.delete.", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-hpcs"}, {"document_id": "ibmcld_09562-3760-5490", "score": 23.2190666729515, "text": "\nWhen you rotate a key, the process initiates a syncing KMS state task, and your deployment is reencrypted with the new key. The task is displayed on the Tasks page on your deployment's Overview and the associated Key Protect and Cloud Databases events are sent to Activity Tracker.\n\nFor more information, see [Rotating manually or automatically](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-rotationcompare-key-rotation-options).\n\n\n\n\n\n Deleting the Deployment \n\nIf you delete a deployment that is protected with a Key Protect key, the deployment remains registered against the key during the soft-deletion period (up to 9 days). To delete the key in the soft-deletion period, [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) the key. After the soft-deletion period, the key can be deleted without the force. To determine when you can delete the key, check the [association between the key and your deployment](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources).\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nKey Protect allows you to [initiate a force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them.", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-key-protect"}, {"document_id": "ibmcld_06638-3770-5500", "score": 23.2190666729515, "text": "\nWhen you rotate a key, the process initiates a syncing KMS state task, and your deployment is reencrypted with the new key. The task is displayed on the Tasks page on your deployment's Overview and the associated Key Protect and Cloud Databases events are sent to Activity Tracker.\n\nFor more information, see [Rotating manually or automatically](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-rotationcompare-key-rotation-options).\n\n\n\n\n\n Deleting the Deployment \n\nIf you delete a deployment that is protected with a Key Protect key, the deployment remains registered against the key during the soft-deletion period (up to 9 days). To delete the key in the soft-deletion period, [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) the key. After the soft-deletion period, the key can be deleted without the force. To determine when you can delete the key, check the [association between the key and your deployment](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources).\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable.\n\nKey Protect allows you to [initiate a force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks that contain your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data that is contained within them.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-key-protect"}, {"document_id": "ibmcld_01041-3464-4855", "score": 22.77991243447966, "text": "\nAfter the soft-deletion period the key can be deleted without the force. You can check the [association between the key and your deployment](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) to determine when you can delete the key.\n\n\n\n\n\n Cryptoshredding \n\nCryptoshredding is a destructive action. Once the key is deleted your data is unrecoverable.\n\nKey Protect or Hyper Protect Crypto Services allows you to initiate a force delete of a key that is in use by IBM Cloud\u00ae services using [Key Protect](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) or [Hyper Protect Crypto Services](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys), including your Db2 on Cloud deployments. This action is called cryptoshredding. Deleting a key that is in use on your deployment locks the disks containing your data and disables your deployment. You are still able to access the UI and some metadata such as security settings in the UI, CLI, and API but you are not able to access any of the databases or data contained within them. Key deletion is sent to the Log Analysis Activity Tracker as kms.secrets.delete using [Key Protect](https://cloud.ibm.com/docs/key-protect?topic=key-protect-at-events) and as hs-crypto.secrets.delete using [Hyper Protect Crypto Services](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-at-events).", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-key-management-services"}, {"document_id": "ibmcld_06341-2428-3641", "score": 22.170940399648487, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"}, {"document_id": "ibmcld_06499-2416-3629", "score": 22.170940399648487, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"}, {"document_id": "ibmcld_06443-2410-3623", "score": 22.170940399648487, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-etcd?topic=databases-for-etcd-deprovisioning"}, {"document_id": "ibmcld_06627-2422-3635", "score": 22.170940399648487, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"}, {"document_id": "ibmcld_06696-2412-3625", "score": 22.170940399648487, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-redis?topic=databases-for-redis-deprovisioning"}]}
{"task_id": "674aa142d92a6b4262de254df0c3f7b2<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16324-3229-5312", "score": 37.11467924403293, "text": "\nChoose a narrow set of user goals first. If you start small and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. After your assistant is live, the built-in metrics of active user conversations help you understand what your customers are asking about, how well your assistant is able to meet their needs, and what to focus on next.\n\n\n\n\n\n 3. Choose the tone and language of your assistant \n\nBefore you build your assistant, it can also be helpful to choose the tone with which your assistant communicates. Is your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Write conversations that reflect your assistant's personality. Don't overdo it by sacrificing usability for the sake of keeping your assistant in character. Strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe that the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chatbots to identify themselves as chatbots.\n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-support).\n\n\n\n\n\n 4. Connect to content sources \n\nThe answer to common questions might already be documented somewhere in your organization's technical information. Plan whether you want to connect the assistant to existing content sources by taking an inventory of relevant help content (for example, product information, knowledge articles, FAQs) available to your customers.\n\nYou can give your assistant access to this information by adding a [search integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-add) to your assistant. The search integration uses IBM Watson\u00ae Discovery to return smart answers to natural language questions.\n\n\n\n\n\n 5. Plan your handoff strategy", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-plan-assistant"}, {"document_id": "ibmcld_03330-4-2191", "score": 36.20770158907905, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-index"}, {"document_id": "ibmcld_16233-7-2298", "score": 35.79794306992702, "text": "\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-about"}, {"document_id": "ibmcld_07148-7-2060", "score": 35.1815584086072, "text": "\nUsing the COVID-19 kit \n\nThe COVID-19 kit is a special collection available in US instances of IBM Watson\u2122 Discovery. This pre-built collection includes more than 10 data sources you can use to fuel a dynamic chatbot built with IBM Watson\u2122 Assistant and Discovery to answer your customers' questions about COVID-19.\n\nFAQ extraction is a beta feature that was used to create question and answer pairs for the kit. The FAQ extraction beta feature is now deprecated and will stop being supported in v1 Discovery service instances on 1 March 2022. As a consequence, the COVID-19 kit data collection will stop being supported also.\n\nThe COVID-19 kit extracts answers from trusted sources and automatically updates your chatbot as the content from those sources are updated. It uses FAQ extraction machine learning models developed by IBM Research labs to extract question/answer pairs. The kit is pre-configured with web crawl seeds from trusted sources such as the CDC, Harvard, and the United States Department of Labor. An expanded stopwords list and query expansions are also included in this collection to improve search results. It is designed to be augmented with your own data and customized to your needs.\n\nFor more information about this kit, and how you can create a chatbot and connect it to a data source with the IBM Watson\u2122 Assistant search skill using IBM Watson\u2122 Assistant and Discovery, see [COVID-19 \u2014 Are Your Virtual Assistant\u2019s Answers Up-To-Date?](https://medium.com/ibm-watson/covid-19-are-your-virtual-assistants-answers-up-to-date-c9e1ba70eb65654b).\n\nTo learn how to create a search skill in Watson Assistant, see [Creating a search skill](https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add). (This feature is available only to Watson Assistant Plus or Premium plan users.)\n\nSee the following to learn more about working with Discovery:\n\n\n\n* To learn how to create a service instance, see [Getting started with the Discovery tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-getting-started).", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-covidkit"}, {"document_id": "ibmcld_07080-6045-7467", "score": 34.87087398021036, "text": "\n[checkbox](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/checkbox.png) Deploy your solution. [Deploying your project](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-deploy) \n\n\n\n\n\n\n\n Enhance your chatbot \n\nDelight your customers by fortifying your chatbot with an answer to every question. Discovery is designed to work seemlessly with Watson Assistant to search and deliver answers from help content that you already own.\n\nZoom\n\n![Shows a chat bot with emphasize the answer enabled.](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/convo-search.png)\n\nFigure 3. Answer finding enabled in the Watson Assistant web chat\n\nIf enhancing your chatbot is your goal, complete the steps that are listed in the following table.\n\n\n\nChecklist for enhancing your chatbot\n\n Step Task Related information \n\n ![checkbox](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/checkbox.png) Create a Conversational Search project. [Creating projects](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-projects) \n ![checkbox](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/checkbox.png) Add a collection that connects to an external data source or contains uploaded files.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-product-overview"}, {"document_id": "ibmcld_03330-3253-5192", "score": 34.21350375345668, "text": "\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.\n\n\n\n\n\nFor more information about the architecture, read the [How to Make Chatbot Orchestration Easier](https://medium.com/ibm-watson/how-to-make-chatbot-orchestration-easier-c8ed61620b8d) blog on Medium.com.\n\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https://www.ibm.com/blogs/watson/2020/03/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits/) blog on ibm.com.\n\nThis documentation describes managed instances of Watson Assistant that are offered in IBM Cloud or in Cloud Pak for Data as a Service. If you are interested in on-premises or installed deployments, see [this documentation](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-index).\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add)\n* [Adding skills to your assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-index"}, {"document_id": "ibmcld_13160-7-1812", "score": 33.89504506397006, "text": "\nBuild a database-driven Slackbot \n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\nThe Slack integration sends messages between Slack and Watson Assistant. A custom extension, written in Python and deployed as serverless Code Engine app, exposes a REST API against the database backend.\n\nThis tutorial uses the new experience of Watson Assistant and an action skill. A former version was based on the dialog skill and the database was integrated using IBM Cloud\u00ae Functions with code written in Node.js. You can find that version of the tutorial in the [cloud-functions branch of the related code repository](https://github.com/IBM-Cloud/slack-chatbot-database-watson/tree/cloud-functions).\n\n\n\n Objectives \n\n\n\n* Build a chatbot using Watson Assistant which interacts with a database backend\n* Connect Watson Assistant to Slack using an integration\n* Create and deploy a Python database app to Code Engine\n* Access a Db2 on Cloud database via a Watson Assistant custom extension\n\n\n\nZoom\n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution19/SlackbotArchitecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The user interacts with [IBM Watson\u00ae Assistant](https://cloud.ibm.com/docs/watson-assistant), either through Slack or using a web chat client\n2.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"}, {"document_id": "ibmcld_01090-0-821", "score": 33.84266197517916, "text": "\n\n\n\n\n\n\n  Assessing your database compatibility \n\nIBM Database Conversion Workbench (DCW) is a no-charge plug-in that adds database migration capabilities to IBM Data Studio. You can download both Data Studio and Database Conversion Workbench from the web console.\n\nTo assess the compatibility of your database with Db2 and convert the SQL, you can also use the free, light-weight tool called [IBM Database Harmony Profiler](https://community.ibm.com/community/user/hybriddatamanagement/blogs/jordan-hodges1/2020/01/15/introducing-database-harmony-profiler).\n\nFor more information about the Database Conversion Workbench and Database Harmony Profiler, see: [IBM Database Conversion Workbench (DCW)](https://www.ibm.com/support/knowledgecenter/en/SS6NHC/com.ibm.swg.im.dashdb.apdv.porting.doc/doc/c_compat_dcw.html).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/Db2whc?topic=Db2whc-dcw"}, {"document_id": "ibmcld_01018-0-821", "score": 33.84266197517916, "text": "\n\n\n\n\n\n\n  Assessing your database compatibility \n\nIBM Database Conversion Workbench (DCW) is a no-charge plug-in that adds database migration capabilities to IBM Data Studio. You can download both Data Studio and Database Conversion Workbench from the web console.\n\nTo assess the compatibility of your database with Db2 and convert the SQL, you can also use the free, light-weight tool called [IBM Database Harmony Profiler](https://community.ibm.com/community/user/hybriddatamanagement/blogs/jordan-hodges1/2020/01/15/introducing-database-harmony-profiler).\n\nFor more information about the Database Conversion Workbench and Database Harmony Profiler, see: [IBM Database Conversion Workbench (DCW)](https://www.ibm.com/support/knowledgecenter/en/SSFMBX/com.ibm.swg.im.dashdb.apdv.porting.doc/doc/c_compat_dcw.html).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/Db2onCloud?topic=Db2onCloud-dcw"}, {"document_id": "ibmcld_13160-14797-16607", "score": 33.27217346428933, "text": "\nEnd the action under And then.\n13. Create a new step with the condition for 8 Ran successfully being false. Use something like It seems there was a problem creating the new event record for the Assistant to say and end the action under And then. Save and close the action with the icons in the upper right.\n14. Test the new action by clicking on Preview on the left and using the webchat. Type add new event and submit. When prompted by the bot, enter my conference as name, home office as location, pick dates for begin and end, and use [http://localhost](http://localhost) as URL. Thereafter, confirm that the data is correct.\n\n\n\nWhen creating a chatbot, you may want to [publish a chatbot](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-publish). It is the controlled release of a version which allows rolling back changes and to continue with development without impacting the chatbot interacting with real customers.\n\n\n\n\n\n Step 6: Integrate with Slack \n\nNow, you will integrate the chatbot with Slack.\n\n\n\n1. On the lower left, click on Integrations.\n2. In the integrations overview, in the section Channels, locate Slack and click Add.\n3. Follow the step by step instructions to integrate the Draft environment of your chatbot with Slack. More information about it is available in the topic [Integrating with Slack](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-slack).\n4. Once done, open up your Slack workspace. Begin a direct chat with the bot and say show me event details. Then, similar to above, answer with Think when prompted for an event name.\n\n\n\nZoom\n\n![Slack with the eventbot](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution19/Slackbot_event.png)\n\nSlack with the eventbot", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16516-12409-14637", "score": 30.445825899472474, "text": "\nAnnotation tasks Assets & Tools > Documents > Tasks Machine Learning Model > Annotation Tasks \n Coreferences tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Dictionaries page (management) Assets & Tools > Pre-annotators > Manage Dictionaries Assets \n Dictionaries tab (mapping to classes for rule-based model) Document Annotation Rule-based Model > Rules \n Documents page Assets & Tools Assets \n Entity Types page Assets & Tools Assets \n Mentions tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Performance page Model Management Machine Learning Model \n Pre-annotators page Assets & Tools Machine Learning Model > Pre-annotation \n Regex tab Document Annotation Rule-based Model > Rules \n Relation Types page Assets & Tools Assets \n Relations tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Rules tab Document Annotation Rule-based Model \n Tasks tab Assets & Tools > Documents Machine Learning Model > Annotation Tasks \n Versions page (machine learning model) Model Management Machine Learning Model \n Versions page (rule-based model) Model Management Rule-based Model \n\n\n\n\n\n\n\n\n\n May 2018 \n\n\n\n New features and changes \n\nConfiguration issue fixed\n: A configuration issue was fixed that caused service instances in Sydney region to not appear in US South region.\n\nDeploy Model window support changes\n: In the Deploy Model window, if the region you're deploying to supports both IBM Cloud\u00ae Identity and Access Management resource groups and Cloud Foundry spaces, to see the list, you will need to choose the method of access management that your service instance uses.\n\nData collection setting added\n: Added the data collection setting on the Service Details page. For more information about data collection, see [Troubleshooting, support, and FAQs](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-troubleshootingcontent)\n\nSupport for Chinese (Traditional)\n: Added Chinese (traditional) language support.\n\nAdministrators can see number of workspaces\n: Users who have the Admin role can now see the number of workspaces that are used.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-release-notes"}, {"document_id": "ibmcld_16516-10835-12899", "score": 28.342337895346834, "text": "\n: In addition, the following functionality was reorganized:\n\n\n\n* In the previous version, management of dictionaries was included as part of the Pre-annotators page. Now, management of dictionaries is located on the Dictionaries page in the Assets section of the navigation.\n* In the previous version, human annotation functionality was distributed across the Mentions, Relations, and Coreferences tabs in the Document Annotation section of the navigation. Now, the functionality is merged under the Annotation Tasks page in the Machine Learning Model section of the navigation.\n* To manage human annotation tasks, in the previous version, you found the Tasks tab under the Assets & Tools > Documents page. Now, you add tasks and manage existing tasks on the Annotation Tasks page in the Machine Learning Model section of the navigation.\n* In the previous version, the Rules, Regex and Dictionaries pages were separate pages in the Document Annotation section of the navigation. Now, the functionality is merged under the Rules page in the Rule-based Model section of the navigation.\n\n\n\nFor more details about the navigation changes, see Figure 1 and Table 3.\n\n![Screen captures of the previous navigation (left side) and new navigation (right side).](https://cloud.ibm.com/docs-content/v1/content/50eddb8fd81f33092880335ff107a78ff5cd0f65/watson-knowledge-studio/images/nav3-0718.svg) Figure 1. Screen captures of the previous navigation (left side) and new navigation (right side).\n\n\n\nTable 3. Navigation changes (July 2018)\n\n Feature Previous location Current location \n\n Annotation tasks Assets & Tools > Documents > Tasks Machine Learning Model > Annotation Tasks \n Coreferences tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Dictionaries page (management) Assets & Tools > Pre-annotators > Manage Dictionaries Assets \n Dictionaries tab (mapping to classes for rule-based model) Document Annotation Rule-based Model > Rules \n Documents page Assets & Tools Assets \n Entity Types page Assets & Tools Assets", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-release-notes"}, {"document_id": "ibmcld_16507-9193-11335", "score": 28.15823712385937, "text": "\nClick Run.\n\nIf you are doing a validation check of the pre-annotator, then open the annotated documents and review the annotations that were added. Make sure a sufficient number of accurate annotations were created. If the annotations are accurate, then you can run the annotator again on more and larger document sets. If the annotations are not accurate, then consider mapping different Natural Language Understanding entity types to your types. If the types do not naturally overlap, then the Natural Language Understanding pre-annotator is not the best pre-annotator for you to use.\n\nPre-annotation is applied to individual documents without regard for the various document sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\n\n\n\n\n Results \n\nGround truth that is produced by documents that were pre-annotated by the Natural Language Understanding service cannot be used directly outside of Knowledge Studio. You can download the ground truth (in non-readable form) to move it from one Knowledge Studio workspace to another. And you can continue to develop the ground truth and use it to build a machine learning model or rule-based model that can be deployed for use in services outside of Knowledge Studio.\n\nDocuments that were pre-annotated with Natural Language Understanding are obscured into a non-readable format when they are downloaded. But, all annotations in those documents are obscured, including annotations that were added to the documents by human annotators.\n\nRelated information:\n\n[Natural Language Understanding](https://www.ibm.com/watson/services/natural-language-understanding/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_16507-10816-12778", "score": 28.105129797497412, "text": "\n[Natural Language Understanding](https://www.ibm.com/watson/services/natural-language-understanding/)\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries. The human annotator can change or remove the pre-annotated entity types and assign entity types to unannotated mentions. Pre-annotation by a dictionary does not annotate relations, coreferences. Relations and coreferences must be annotated by human annotators.\n\nThis task shows you how to create a dictionary that is editable. If you want to upload and pre-annotate your documents with a read-only dictionary, click the Menu icon next to the Create Dictionary button, and then select Upload Dictionary.\n\n\n\n\n\n Procedure \n\nTo create an editable dictionary and pre-annotate documents, follow these steps:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select the Assets > Dictionaries page.\n3. Click Create Dictionary, enter a name, and then click Save.\n4. From the Entity type list, select an entity type to associate with the dictionary.\n\nYou can also associate an entity type with the dictionary from the Machine Learning Model > Pre-annotation page. Click the overflow menu button in the Dictionaries row in the page, then click Map entity types.\n5. Add entries for the dictionary or upload a file that contains dictionary terms.\n6. Go to the Machine Learning Model > Pre-annotation page.\n7. Click Run Pre-annotators.\n8. Select Dictionaries, and then click Next.\n9. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_16444-4487-6387", "score": 28.071978820231763, "text": "\nIf a dictionary that is first in the order labels IBM as an Organization entity type, a machine learning model that is second in the order can't annotate IBM Watson as a Software Brand entity type because that would override the earlier annotation made to IBM.\n\nYou can view the current order of pre-annotators in the Order column on the Machine Learning Model > Pre-annotation page. To change the order, complete the following steps.\n\n\n\n1. Click Order Settings.\n2. Click the Move up and Move down arrow** buttons to move pre-annotation methods earlier or later in the order.\n3. Click Save.\n4. Double check the Order column on the Pre-annotation page to make sure that it matches the order that you want.\n\n\n\n\n\n\n\n Run pre-annotators \n\n\n\n1. After your pre-annotation methods are prepared and you have configured the order of your pre-annotators, click Run Pre-annotators.\n2. Select the pre-annotators that you want to use, and then click Next.\n3. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n4. Select the document sets that you want to pre-annotate.\n5. Click Run.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with a dictionary \n\nTo help human annotators get started with their annotation tasks, you can create a dictionary and use it to pre-annotate documents that you add to the corpus.\n\n\n\n About this task \n\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries. The human annotator can change or remove the pre-annotated entity types and assign entity types to unannotated mentions. Pre-annotation by a dictionary does not annotate relations, coreferences. Relations and coreferences must be annotated by human annotators.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"}, {"document_id": "ibmcld_16444-5943-7800", "score": 27.214064536108037, "text": "\nWhen a human annotator begins work on documents that were pre-annotated, it is likely that a number of mentions will already be marked by entity types based on the dictionary entries. The human annotator can change or remove the pre-annotated entity types and assign entity types to unannotated mentions. Pre-annotation by a dictionary does not annotate relations, coreferences. Relations and coreferences must be annotated by human annotators.\n\nThis task shows how to create a dictionary that is editable. If you want to upload and pre-annotate your documents with a read-only dictionary, click the Menu icon next to the Create Dictionary button. Select Upload Dictionary.\n\n\n\n\n\n Procedure \n\nTo create an editable dictionary and pre-annotate documents, follow these steps:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select the Assets > Dictionaries page.\n3. Click Create Dictionary, enter a name, and then click Save.\n4. From the Entity type list, select an entity type to associate with the dictionary.\n5. Add entries for the dictionary or upload a file that contains dictionary terms.\n6. Go to the Machine Learning Model > Pre-annotation page.\n7. Click Run Pre-annotators.\n8. Select Dictionaries, and then click Next.\n9. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n10. Select the check box for each document set that you want to pre-annotate and click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets or annotation sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\nRelated information:", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"}, {"document_id": "ibmcld_16464-4463-6317", "score": 27.06014520656652, "text": "\nOn the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\n> Note: In a realistic scenario, you would create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16563-4292-6145", "score": 26.231010108333045, "text": "\nSelect the document set that you created in [Lesson 1](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introtut_lessml1).\n6. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\nIn a realistic scenario, you create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3. Specify the details for the task:\n\n\n\n* In the Task name field, enter Test.\n* In the Deadline field, select a date in the future.\n\n\n\n4.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}, {"document_id": "ibmcld_16563-8147-9811", "score": 25.69783722210835, "text": "\nLog in to Knowledge Studio as a user who is assigned to the annotation task that you created in [Lesson 3](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introwks_tutless_ml2).\n\nIf you have access only to a single administrator ID for this tutorial, you can use that ID to perform human annotation. However, remember that in a realistic scenario, human annotation is performed by different users with the Human Annotator role.\n2. Open the My workspace workspace and click Machine Learning Model > Annotations.\n3. Click the Annotation Tasks tab, then open the Test annotation task you created in [Lesson 3](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introwks_tutless_ml2).\n4. Click Annotate for one of the assigned annotation sets.\n\nDepending on how you set up the annotation tasks, you could have one or more annotation tasks assigned to the user ID you logged in with.\n5. From the list of documents, find the Technology - gmanews.tv document and open it.\n\nNotice that the term IBM was already annotated with the ORGANIZATION entity type. This annotation was added by the dictionary pre-annotator that was applied in [Lesson 2](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introwks_tutless_ml3). This pre-annotation is correct, so it does not need to be modified.\n\n![This screen capture shows an open document with an existing pre-annotation for \"IBM\".](images/wks_tut_preannotation.png \"This screen capture shows an open document with an existing pre-annotation for \"IBM\".\")\n6. Annotate a mention:\n\n\n\n1. Click the Entity tab.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}, {"document_id": "ibmcld_16464-8477-10131", "score": 25.633458277280212, "text": "\nLog in to Knowledge Studio as a user who is assigned to the annotation task that you created in [Lesson 3](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introwks_tutless_ml2).\n\n> Note: If you have access only to a single administrator ID for this tutorial, you can use that ID to perform human annotation. However, remember that in a realistic scenario, human annotation is performed by different users with the Human Annotator role.\n2. Open the My workspace workspace and click Machine Learning Model > Annotations.\n3. Click the Annotation Tasks tab, then open the Test annotation task you created in [Lesson 3](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introwks_tutless_ml2).\n4. Click Annotate for one of the assigned annotation sets.\n\nDepending on how you set up the annotation tasks, you could have one or more annotation tasks assigned to the user ID you logged in with.\n5. From the list of documents, find the Technology - gmanews.tv document and open it.\n\nNotice that the term IBM was already annotated with the ORGANIZATION entity type. This annotation was added by the dictionary pre-annotator that was applied in [Lesson 2](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introwks_tutless_ml3). This pre-annotation is correct, so it does not need to be modified.\n\n![This screen capture shows an open document with an existing pre-annotation for \"IBM\".](images/wks_tut_preannotation.png \"This screen capture shows an open document with an existing pre-annotation for \"IBM\".\")\n6.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09148-7815-9285", "score": 31.71317377831736, "text": "\n(https://cloud.ibm.com/docs-content/v1/content/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc/key-protect/images/monitor-dashboard-menu.png)\n\nFigure 2. The dashboard menu that lists the dashboards in your Monitoring instances.\n\nBelow are figures that show the metric views available to you on the default dashboard.\n\nZoom\n\n![An example of a Key Protect metrics dashboard.](https://cloud.ibm.com/docs-content/v1/content/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc/key-protect/images/monitor-operation-dash1.png)\n\nFigure 3. Some of the metrics available on the Monitoring dashboard.\n\nZoom\n\n![An example of a Key Protect dashboard view.](https://cloud.ibm.com/docs-content/v1/content/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc/key-protect/images/monitor-operation-view2.png)\n\nFigure 4. Some of the metrics available on the Monitoring dashboard.\n\nYou will not be able to see any metrics in your Monitoring instance until you enable a metrics policy for your Key Protect instance and make API requests to your Key Protect instance.\n\n\n\n\n\n\n\n Setting Alerts \n\nYou can set alerts on your Monitoring dashboard to notify you of certain metrics.\n\nTo setup a metric, complete the follow steps.\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert at the top of the page.\n3. Select Metric as the alert type.\n4. Select the aggregation and the metric that you would like to be performed on.\n5. Select the scope if applicable.\n6. Set the metric and time requirements for the alert to trigger.\n7.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-operational-metrics"}, {"document_id": "ibmcld_09685-5899-7847", "score": 30.725471350858427, "text": "\nFor more information, see [Collecting metrics](https://cloud.ibm.com/docs/monitoring?topic=monitoring-about-collect-metrics).\n\n\n\n\n\n Sending metrics \n\nYou can send metrics via the public or the private endpoints by using the appropriate ingestion URL. Details can be found in the [endpoints](https://cloud.ibm.com/docs/monitoring?topic=monitoring-endpointsendpoints) section.\n\n\n\n\n\n Viewing metrics \n\nYou can monitor and manage metrics through the Monitoring Web UI. For more information, see [Viewing metrics](https://cloud.ibm.com/docs/monitoring?topic=monitoring-monitoring).\n\nNotice that there is a delay showing metric data for new time series. Data is not ready until the initial indexing of a new metric source is completed. Therefore, new sources such as clusters, platform metrics, or systems that you configure, all take some time to become visible through the Monitoring UI.\n\n\n\n\n\n Sending notifications \n\nYou can configure single alerts and multi-condition alerts to notify about problems that may require attention. When an alert is triggered, you can be notified through 1 or more notification channels. An alert definition can generate multi-channel notifications.\n\nAn alert is a notification event that you can use to warn about situations that require attention. Each alert has a severity status. This status informs you about the criticality of the information it reports on.\n\nFor example, you can set up Monitoring to send alert notifications to IBM Cloud Event Notifications.\n\n\n\n* [Sending email notifications to IBM Cloud Event Notifications](https://cloud.ibm.com/docs/monitoring?topic=monitoring-tutorial)\n* [Sending SMS notifications to IBM Cloud Event Notifications](https://cloud.ibm.com/docs/monitoring?topic=monitoring-tutorial-en-sms)\n\n\n\nFor more information, see [Working with alerts and events](https://cloud.ibm.com/docs/monitoring?topic=monitoring-alerts).\n\n\n\n\n\n Data location \n\nMetric data is hosted on the IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-about-monitor"}, {"document_id": "ibmcld_09148-8939-9806", "score": 30.52029163030946, "text": "\nTo setup a metric, complete the follow steps.\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert at the top of the page.\n3. Select Metric as the alert type.\n4. Select the aggregation and the metric that you would like to be performed on.\n5. Select the scope if applicable.\n6. Set the metric and time requirements for the alert to trigger.\n7. Configure and set up the notification channel and notification interval.\n8. Click the CREATE button.\n\n\n\nThe figure as shown provides an example of how to configure an alert when your service instance receives multiple 401 and 403 errors within a 10 minute time span.\n\nZoom\n\n![An example of a 401 and 403 configuration.](https://cloud.ibm.com/docs-content/v1/content/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc/key-protect/images/monitor-401-alert.png)\n\nFigure 5. The configuration for a 401 alert in a Monitoring dashboard.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-operational-metrics"}, {"document_id": "ibmcld_09794-9435-11301", "score": 29.954234224295096, "text": "\n[Panel options](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/platform/images/sysdig-platform-15.png)\n\nPanel options\n\nIf you have multiple queries defined in a panel, you are prompted to select the metric for which you want to create an alert.\n7. Configure the alert. Set the following fields:\n\nName: Enter a name for the alert.\n\nDescription: Add a description that other users can read to get more context. This field is optional.\n\nGroup: The alert group this alert will be part of. If not specified, the alert will be part of the default group.\n\nSeverity: Set the level of criticality of the alert. Valid values are High, Medium, Low, and Info.\n\nMetric: This field is set to the metric that you have selected from the panel. Check that the metric and aggregation are the ones that you need.\n\nScope: This field is set to the scope that you have defined for the metric in the panel. Check that the scope is the one that you need.\n\nTrigger: Define the condition and threshold value that must be evaluated. It also defines whether the alert sends a single alert or multiple alerts. Valid time scales are minute, hour, or day. A single alert fires an alert for the entire scope. Multiple Alerts are sent if 1 or more segments breach the threshold at once. An alert is sent for each segment that you specify.\n\nNotification Channel: Enable 1 or more notification channels.\n\n\n\n\n\n\n\n\n\n Configuring an alert from the Alerts section \n\nYou can define a metric alert directly from the Alerts section.\n\nComplete the following steps to define an alert on a metric:\n\n\n\n1. [Launch the monitoring UI](https://cloud.ibm.com/docs/monitoring?topic=monitoring-launch).\n2. Verify that you have a notification channel that defines how you want to be notified.\n\nYou can enabled 1 or more notification channels when you configure an alert.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-platform_metrics_working"}, {"document_id": "ibmcld_05838-14949-16513", "score": 29.760277970657768, "text": "\nWhen you set up alerts, make sure to allow your cluster enough time to self-heal. Because Kubernetes has self healing capabilities, configure your alerts only for the issues that arise over time. By observing your cluster over time, you can learn which issues Kubernetes can resolve itself and which issues require alerts to avoid downtime.\n\nOn 15 June 2022, the naming convention for IBM Cloud\u00ae Monitoring alerts is changing to a Prometheus compatible format. For more information, see the [Sysdig release notes](https://docs.sysdig.com/en/docs/release-notes/enhanced-metric-store/new-features-and-enhancements), [Mapping Legacy Sysdig Kubernetes Metrics with Prometheus Metrics](https://docs.sysdig.com/en/docs/sysdig-monitor/using-monitor/metrics/metrics-library/metrics-and-labels-mapping/mapping-legacy-sysdig-kubernetes-metrics-with-prometheus-metrics/), and [Mapping Classic Metrics with PromQL](https://docs.sysdig.com/en/docs/sysdig-monitor/using-monitor/metrics/metrics-library/metrics-and-labels-mapping/mapping-classic-metrics-with-promql-metrics/).\n\nDepending on the size of your cluster, consider setting up alerts on the following levels:\n\n\n\n* [Apps](https://cloud.ibm.com/docs/containers?topic=containers-health-monitorapp-level-alerts)\n* [Worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-health-monitorworker-node-level-alerts)\n* [Cluster](https://cloud.ibm.com/docs/containers?topic=containers-health-monitorcluster-level-alerts)\n* [Zone](https://cloud.ibm.com/docs/containers?topic=containers-health-monitorzone-level-alerts)", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-health-monitor"}, {"document_id": "ibmcld_09701-12088-14157", "score": 29.689159562671357, "text": "\nSeverity Severity status \n\n 0 HIGH \n 1 HIGH \n 2 MEDIUM \n 3 MEDIUM \n 4 LOW \n 5 LOW \n 6 INFO \n 7 INFO \n\n\n\n\n\n\n\n segmentBy (array of strings) \n\nDefines additional segmentation criteria.\n\nFor example, you can segment a CPU alert by ['host.mac', 'proc.name'] so the alert can report on any process in any machine for which you get data in the monitoring instance.\n\n\n\n\n\n segmentCondition (string) \n\nDefines when the alert is triggered for each monitored entity that is specified in the segmentBy parameter. This parameter is required for MANUAL alerts only.\n\nValid values are the following:\n\n\n\n* ANY: The alert is triggered when at least one of the monitored entities satisfies the condition.\n* ALL: The alert is triggered when all of the monitored entities satisfy the condition.\n\n\n\n\n\n\n\n teamId (string) \n\nDefines the GUID of the team that owns the alert.\n\n\n\n\n\n type (string) \n\nDefines the type of alert. Valid values are MANUAL, BASELINE, and HOST_COMPARISON.\n\nSet to MANUAL for alerts that you want to control when a notification is sent. You must define the threshold that determines when the alert is triggered.\n\nSet to BASELINE for alerts that you want to notify when unexpected metric values are detected. New metric data is compared with metric values that are collected over time.\n\nSet to HOST_COMPARISON for alerts that you want to notify when 1 host in a group reports metrics values that are different from the other hosts in the group.\n\n\n\n\n\n timespan (integer) \n\nMinimum time interval, in microseconds, for which the alert condition must be met before the alert is triggered.\n\nThe minimum value is 60000000 microseconds, that is, 1 minute.\n\nThe value of this parameter must be a multiple of 60000000 microseconds.\n\n\n\n\n\n version (integer) \n\nVersion of an alert.\n\nThe version changes every time you update an alert.\n\nThe version is used for optimistic locking.\n\n\n\n\n\n\n\n Query parameters \n\n\n\n alertId (integer) \n\nID of an alert.\n\n\n\n\n\n from (long) \n\nDefines the start timestamp, in microseconds, that is used when you request information about alerts that are defined.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert_api"}, {"document_id": "ibmcld_08592-8007-9409", "score": 29.548203824724695, "text": "\nYou can scope down your metrics by using the following scope filters.\n\n\n\nTable 4. Describes the scope filters for Hyper Protect Crypto Services metrics.\n\n Attribute Name Description \n\n ibmResourceGroupName The name of the resource group associated with the Hyper Protect Crypto Services service instance. \n ibmScope The account, organization, or space GUID associated with the metric. \n ibmServiceInstanceName The service instance associated with the metric. \n ibmHpcsApi The Hyper Protect Crypto Services API calls associated with the metric. \n\n\n\nBecause of Monitoring limitations, you are able to see the values in the filters for up to 6 hours at a time. You can manually type in value into scope variables to use scope filters for given time periods.\n\n\n\n\n\n\n\n Setting Alerts \n\nYou can set alerts on your Monitoring dashboard to notify you of certain metrics. To set up alerts, complete the following steps:\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert and select Metric as the alert type.\n3. Select the aggregation and the metric that you would like to be performed on.\n4. Select the scope if applicable.\n5. Set the metric and time requirements for the alert to trigger.\n6. Configure and set up the notification channel and notification interval.\n7. Click CREATE.\n\n\n\nFor more information about configuring metric alerts, see [Metric Alerts](https://docs.sysdig.com/en/metric-alerts.html).", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-operational-metrics"}, {"document_id": "ibmcld_09785-1462-3323", "score": 29.122400471150982, "text": "\nFor example, change https://us-east.monitoring.cloud.ibm.com//alerts/rules?direction=asc&sortBy=name to https://us-east.monitoring.cloud.ibm.com//alerts/legacy-editor/new\n\n\n\n\n\n 14 April 2023 \n\nIBM Cloud\u00ae Monitoring Secure is now IBM Cloud\u00ae Monitoring Workload Protection\n: The UI now displays IBM Cloud\u00ae Monitoring Secure functions under the new name Workload Protection.\n\n\n\n* The Secure icon has changed and now includes the text Workload Protection.\n* [To access the Secure UI, select Workload Protection instead of Secure.](https://cloud.ibm.com/docs/monitoring?topic=monitoring-launchlaunch_step3)\n* All instructions in the [IBM Cloud\u00ae Monitoring documentation](https://cloud.ibm.com/docs/monitoring) referring to Secure apply to Workload Protection.\n\n\n\n\n\n\n\n 07 October 2022 \n\nIBM Cloud\u00ae Monitoring has improved Explorer support for customers with only platform metrics.\n: For customers monitoring only platform metrics, the Explorer view will now show the metrics organized by metric namespace. The ability to query metrics using PromQL is also supported.\n\n\n\n\n\n 05 August 2022 \n\nIBM Cloud\u00ae Monitoring has released support for trusted profiles.\n: For more information, see [Trusted Profiles](https://cloud.ibm.com/docs/monitoring?topic=monitoring-trusted_profiles).\n\n\n\n\n\n 06 July 2022 \n\nIBM Cloud\u00ae Monitoring has released a new Alert Editor interface.\n: The following changes have been made:\n\n\n\n* New user interface to manage alerts.\n\nYou can still manage alerts by using the legacy editor. However, notice that new features are only available through the new editor.\n* New configuration settings to help you troubleshoot issues. You can configure a dashboard and a runbook with an alert.\n\n\n\nDeprecated features:\n\n\n\n* Deprecation of the Anomaly Detection and Group Outlier alert types. You can view and manage existing alerts but you cannot define new ones.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-monitoring-release-notes"}, {"document_id": "ibmcld_09703-1640-3664", "score": 28.928258793964915, "text": "\n* Alerts are executed in 1 minute or less from receipt, with the option to configure the trigger wait time by hour or day.\n* For PromQL alerts only, you can optionally configure a 0 minute wait time.\n\n\n\nYou can enable predefined alerts, modify alerts, and create custom alerts in the web UI and by using the IBM Cloud Monitoring API.\n\nYou manage alerts in the Alerts view of the web UI. You can configure the table columns that are displayed in the Alerts view. Valid column options are Name, Scope, Alert When, Segment By, Notifications, Enabled, Modified, Captures, Channels, Created, Description, Email recipients, For at least, OpsGenie, PagerDuty, Severity, Slack, WebHook, Type, and VictorOps.\n\n\n\n Types of alerts \n\nThe IBM Cloud Monitoring service includes pre-defined alerts that you can enable. In addition, you can configure custom alerts from panels in a dashboard, by using the REST API, or in the Alerts section of the web UI.\n\nIn the IBM Cloud Monitoring service, you can define any of the following types of alerts:\n\n\n\n* Downtime: Use this type of alert to monitor sources and alert when they are down, for example, a bare metal.\n* Metric: Use this type of alert to monitor time-series metrics and alert when they reach the thresholds defined.\n* PromQL: Use this type of metric to monitor metrics by using a PromQL query.\n* Event: Use this type of alert to monitor occurrences of specific events and alert when they reach the thresholds defined. For example, you can use this alert to monitor when a number of unauthorize access requests are reported.\n* Anomaly Detection: Use this type of alert to monitor hosts based on historical behaviors and alert when they deviate from the expected pattern.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n* Group Outlier: Use this type of alert to monitor hosts and be notified when 1 acts differently from the rest.\n\nThis type of alert is deprecated. You can only manage existing alerts of this type.\n\n\n\n\n\n\n\n Notification channels", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alerts"}, {"document_id": "ibmcld_09794-11989-13744", "score": 28.73714658688963, "text": "\nSet the following fields:\n\nName: Enter a name for the alert.\n\nDescription: Add a description that other users can read to get more context. This field is optional.\n\nGroup: The alert group this alert will be part of. If not specified, the alert will be part of the default group.\n\nSeverity: Set the level of criticality of the alert. Valid values are High, Medium, Low, and Info.\n\nMetric: Configure the metric.\n\nScope: Configure the scope\n\nTrigger: Define the condition and threshold value that must be evaluated. It also defines whether the alert sends a single alert or multiple alerts. Valid time scales are minute, hour, or day. A single alert fires an alert for the entire scope. Multiple Alerts are sent if 1 or more segments breach the threshold at once. An alert is sent for each segment that you specify.\n\nNotification Channel: Enable 1 or more notification channels.\n\n\n\n\n\n\n\n Controlling the access to platform metrics for a team \n\nYou can control the data that is visible to all the users that are members of a team.\n\nFirst navigate to the Settings section.\n\nZoom\n\n![Settings section](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/platform/images/sysdig-platform-12.png)\n\nSettings\n\nAs an administrator of the service, you can create, modify, and delete teams. When you configure a team, you can define the scope of the data in the Visibility section.\n\nTo allow a team to view platform metrics, you must select Platform metrics.\n\nZoom\n\n![Team platform metrics option](https://cloud.ibm.com/docs-content/v1/content/220cdcbf6f4421bd7fee83fd1028048dba3f16c8/monitoring/platform/images/sysdig-platform-10.png)\n\nTeam platform metrics\n\nEnabling platform metrics, grants access to all platform metrics.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-platform_metrics_working"}]}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05873-73055-74805", "score": 13.752830545319435, "text": "\n: All istio-monitoring support is deprecated in version 1.7 of the Istio add-on and is automatically removed in version 1.8 of the Istio add-on. To use monitoring with Istio, you must install the components separately from the Istio add-on.\n: For more information, see the [Istio documentation](https://istio.io/latest/docs/ops/integrations/).\n: The istio-ingressgateway-public-(n)-enabled and istio-ingressgateway-zone-(n) options in the [managed-istio-custom ConfigMap resource](https://cloud.ibm.com/docs/containers?topic=containers-istiocustomize) are generally available for production use.\n\n\n\n\n\n\n\n Version 1.6 (unsupported) \n\nVersion 1.6 of the managed Istio add-on is unsupported. (: deprecated)\n\n\n\n Differences between version 1.6 of managed and community Istio \n\nReview the following differences between the installation profiles of version 1.6 of the managed IBM Cloud Kubernetes Service Istio and version 1.6 of the community Istio.\n\nTo see options for changing settings in the managed version of Istio, see [Customizing the Istio installation](https://cloud.ibm.com/docs/containers?topic=containers-istiocustomize).\n\n\n\nTable 1. Differences between the managed IBM Cloud Kubernetes Service Istio and the community Istio\n\n Setting Differences in the managed Istio add-on \n\n meshConfig.enablePrometheusMerge=true and values.telemetry.v2.enabled=true In the managed Istio add-on, support for telemetry with IBM Cloud Monitoring is enabled by default. This support can be disabled by [customizing the Istio installation](https://cloud.ibm.com/docs/containers?topic=containers-istiocustomize). \n istio-ingressgateway and istio-egressgateway In the managed Istio add-on, placement of gateways on edge worker nodes is preferred, but not required.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-istio-changelog"}, {"document_id": "ibmcld_05873-80552-82182", "score": 13.667257632755266, "text": "\n* [CVE-2020-1752](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-1752).\n\n\n\n: For more information, see the [Istio security bulletin 2020-008](https://istio.io/latest/news/security/istio-security-2020-008/)\n\n\n\n\n\n Change log for 1.6, released 08 July 2020 \n\nReview the changes that are in version 1.6 of the managed Istio add-on.\n\nPrevious version\n: 1.5.7\n\nCurrent version\n: 1.6\n\nUpdates in this version\n: See the Istio release notes for [Istio 1.6](https://istio.io/latest/news/releases/1.6.x/announcing-1.6/).\n: Support is added for the istio-knative-cluster-local-gateway-enabled and istio-monitoring-telemetry options in the [managed-istio-custom ConfigMap resource](https://cloud.ibm.com/docs/containers?topic=containers-istiocustomize). You can use these options to manage inclusion of Knative apps in the service mesh and the Istio telemetry enablement. Support for IBM Cloud Monitoring is enabled for Istio by default.\n\n\n\n\n\n\n\n Version 1.5 (unsupported) \n\nVersion 1.5 of the managed Istio add-on is unsupported. (: deprecated)\n\n\n\n Differences between version 1.5 of managed and community Istio \n\nReview the following differences between the installation profiles of version 1.5 of the managed IBM Cloud Kubernetes Service Istio and version 1.5 of the community Istio.\n\nTo see options for changing settings in the managed version of Istio, see [Customizing the version 1.5 Istio installation](https://cloud.ibm.com/docs/containers?topic=containers-istiocustomize).\n\n\n\nTable 1. Differences between the managed IBM Cloud Kubernetes Service Istio and the community Istio\n\n Setting Differences in the managed Istio add-on", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-istio-changelog"}, {"document_id": "ibmcld_05873-81662-83420", "score": 13.019381106456708, "text": "\nReview the following differences between the installation profiles of version 1.5 of the managed IBM Cloud Kubernetes Service Istio and version 1.5 of the community Istio.\n\nTo see options for changing settings in the managed version of Istio, see [Customizing the version 1.5 Istio installation](https://cloud.ibm.com/docs/containers?topic=containers-istiocustomize).\n\n\n\nTable 1. Differences between the managed IBM Cloud Kubernetes Service Istio and the community Istio\n\n Setting Differences in the managed Istio add-on \n\n egressGateways[name: istio-egressgateway].enabled: true In the managed Istio add-on, the egress gateway is enabled by default. \n istiod, istio-ingressgateway, and istio-egressgateway In the managed Istio add-on, istiod and all Istio ingress and egress gateways are set up for basic high availability support. High availability support on these components includes the following settings by default: node anti-affinity, HorizontalPodAutoscaler, PodDisruptionBudget, and automatic scaling of replicas. \n prometheus.enabled: false In the managed Istio add-on, the Prometheus, Grafana, Jaeger, and Kiali monitoring components are disabled by default due to current security concerns in the community release of Istio that can't be adequately addressed for a production environment. \n values.global.pilot.enableProtocolSniffingForInbound and values.global.pilot.enableProtocolSniffingForOutbound In the managed Istio add-on, protocol sniffing is disabled by default until the feature becomes more stable in the community Istio. \n\n\n\n\n\n\n\n Change log for 1.5.10, released 1 September 2020 \n\nReview the changes that are in version 1.5.10 of the managed Istio add-on.\n\nPrevious version\n: 1.5.9\n\nCurrent version\n: 1.5.10\n\nUpdates in this version", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-istio-changelog"}, {"document_id": "ibmcld_03369-1415-3586", "score": 12.713980953283972, "text": "\nThese changes are the result of migrating the Watson Assistant platform to Java 17, where locale values are updated by using specifications in [CLDR 39](https://cldr.unicode.org/index/downloads/cldr-39).\n\nTo avoid or minimize the impact of similar changes in the future, you can use [Actions display formats](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-actions-global-settingsactions-global-settings-display-formats).\n\n\n\n\n\n 18 May 2023 \n\nDifferences in contextual entity detection for dialog skills with few annotations\n: If you have 10 to 20 examples of contextual entities in your dialog skill, you might see differences in the entities detected due to updates made to address critical vulnerabilities. The impact of these differences is limited to only newly-trained models. Existing models are unaffected. You can mitigate these differences by annotating more examples. For more information, see [Annotation-based method](https://cloud.ibm.com/docs/assistant?topic=assistant-entitiesentities-annotations-overview).\n\n\n\n\n\n 15 May 2023 \n\nChange to dialog skill context variables named request\n: If your dialog skill used a context variable that is named request, it was removed from the response payload of any /message calls in the V1 or V2 API, or through the Watson Assistant user interface. After 15 May 2023, this behavior changes. Watson Assistant doesn't remove context variables that are named request from the response payload anymore.\n\n\n\n\n\n 3 May 2023 \n\nAlgorithm version Beta provides improved intent detection and action matching\n: The algorithm version Beta now provides improved intent detection and action matching. It includes a new foundation model that is trained using a transformer architecture to improve intent detection and action matching for English.\n\nImprovements include:\n\n\n\n* Improved robustness to variations in user inputs such as typos and different inflection forms\n* Less training data required to reach the same level of performance compared to previous algorithms\n\n\n\nFor more information, see [Algorithm version and training](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-algorithm-version).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_16302-0-1237", "score": 12.438914010955626, "text": "\n\n\n\n\n\n\n  Publishing dialog and actions \n\nIf the dialog feature is enabled, the publishing and deployment processes remain the same. However, some slight differences in functionality exist.\n\nTo learn about the overall publishing and deployment model for Watson Assistant, see the [Publishing and deploying your assistant overview](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-publish-overview). For more information about the Publish page and how the publishing process works, see [Publishing your content](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-publish). The following slight differences exist when the dialog feature is enabled in an assistant:\n\n\n\n*  On the Publish page, the information in the Content type column lists whether your content changes contain a dialog.\n*  The version tiles on the Publish and Environments pages show whether the published content contains actions, or actions and a dialog. For example, if the dialog feature is enabled in your assistant, the version tile displays Contains actions & dialog.\n*  When you export a version of your content from the Publish page, two JSON files are downloaded. One file is for actions and one file is for the dialog.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-dialog-publish"}, {"document_id": "ibmcld_06941-0-1401", "score": 12.132088091406214, "text": "\n\n\n\n\n\n\n  Migration FAQ \n\nFind answers to questions that are commonly asked about migrating from Discovery v1 to v2.\n\nDo the two versions have all the same features?\n:   There are many feature differences between the two versions. For a full feature comparison, see [Getting the most from Discovery](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-version-choose).\n\nHow do I know which version I'm using now?\n:   When you open the product user interface in v2, the following page is displayed:\n\nZoom\n\n![Shows the main My Projects page with a single Sample Project tile.](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/gs-home-page.png)\n\nFigure 1. Home page from the Sample Project\n\nHow long will the migration take?\n:   The time you need to set aside for the migration differs based on the amount of data you want to retain in your existing v1 service instance.\n\nDo I need to update my existing applications for them to work with v2?\n:   Yes. You will need to edit any existing applications to account for changes that are introduced with Discovery v2. For more information, see the [API version comparison](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2-api).\n\nTo get started, see [Migrating to Discovery v2](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data--migration-faq"}, {"document_id": "ibmcld_07067-1816-3544", "score": 12.108066040335029, "text": "\n* For more information about feature differences, see [the feature comparison table](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-version-chooseversion-choose-comparison).\n* For more information about detailed API differences, see [API version comparison](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2-api).\n\n\n\nDiscovery v2 is available for all users of Plus or Enterprise plan instances, or Premium plan instances that were created after 15 July 2020. v2 is also available for IBM Watson\u00ae Discovery Cartridge for IBM Cloud Pak\u00ae for Data users.\n\n\n\n Migration overview \n\nMigrating from Discovery v1 to v2 is a multistep process that you can do independently.\n\nThe two versions of the Discovery service have many differences, but you can adopt techniques and utilities that were applied to a v1 instance for use with your new v2 instance.\n\nTo migrate from v1 to v2, you must complete the following high-level steps:\n\n\n\n1. [Plan the migration](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-plans).\n2. [Transfer your documents](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-docs).\n3. [Update your application to use the v2 API](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-difs).\n4. Regression test and deploy the updated application.\n5. [Delete your v1 plan service instance](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2migrate-to-v2-delete).\n\n\n\nSome steps require you to make programmatic changes by using the API and others involve changes that you can make from the product user interface.\n\n\n\n\n\n Plan the migration", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2"}, {"document_id": "ibmcld_10534-328324-329702", "score": 11.881180186123379, "text": "\n(https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmarkbenchmark-meaning)\n* [What parts of the benchmark am I responsible for?](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmarkbencmark-resp)\n* [What if some part of the service fails to comply with a recommendation?](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmarkbencmark-service-compliance)\n* [What else can I do to increase the security and compliance of my cluster?](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmarkbenchmark-what-else)\n\n\n\n* [Running the worker node CIS Kubernetes benchmark](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmarkcis-worker-test)\n\n\n\n[Comparing the CIS Kubernetes and the Compliance Operator benchmarks](https://cloud.ibm.com/docs/openshift?topic=openshift-benchmark-comparisonbenchmark-comparison)\n\n\n\n* [Major differences](https://cloud.ibm.com/docs/openshift?topic=openshift-benchmark-comparisonbenchmark-comparison-major)\n* [Minor differences](https://cloud.ibm.com/docs/openshift?topic=openshift-benchmark-comparisonbenchmark-comparison-minor)\n\n\n\n\n\n Version 4.13 \n\n[4.13 version information and update actions](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_versions_413cs_versions_413)\n\n\n\n* [Release timeline](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_versions_413release_timeline_413)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_07068-7-1672", "score": 11.759840989606676, "text": "\nAPI version comparison \n\nFor most API methods, the request parameters and response bodies differ between v1 and v2. Learn about the equivalent or alternative v2 methods that you can use to do actions that are supported by the v1 API.\n\nThe comparison information assumes you are using the latest version of the v1 API (version 2019-04-30) and compares it to the latest version of the v2 API (version 2020-08-30).\n\n\n\n Environments \n\nThere is no concept of an environment in v2. The deployment details such as size and index capacity are managed based on the service plan type. In v2, collections are organized in projects. You can create different types of projects to apply default configuration settings to the collections that you add to the projects.\n\nThere are no equivalent methods in v2 for the v1 environment methods. However, the following table shows v2 methods that serve similar functions to the corresponding v1 methods. The supported parameters and response bodies that are returned for each method differ also.\n\n\n\nEnvironment API action support details\n\n Action v1 API Related v2 API \n\n Create an environment [POST /v1/environments](https://cloud.ibm.com/apidocs/discoverycreateenvironment) [POST /v2/projects](https://cloud.ibm.com/apidocs/discovery-datacreateproject) \n List environments [GET /v1/environments](https://cloud.ibm.com/apidocs/discoverylistenvironments) [GET /v2/projects](https://cloud.ibm.com/apidocs/discovery-datalistprojects) \n Get environment info [GET /v1/environments/{environment_id}](https://cloud.ibm.com/apidocs/discoverygetenvironment) [GET /v2/projects/{project_id}](https://cloud.ibm.com/apidocs/discovery-datagetproject)", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2-api"}, {"document_id": "ibmcld_14105-0-1469", "score": 11.61805661772066, "text": "\n\n\n\n\n\n\n  Differences between versions of XenServer \n\nLicensing is the only difference between versions of XenServer that are installed on the system. If you want to upgrade your license to a higher class license after installation, you experience no downtime to reinstall your server. Contact IBM Cloud\u00ae sales for pricing information.\n\nNote: Not all available features are supported.\n\nThe following lists of features are included for each of the different licenses that are offered (as of XenServer 6.0):\n\nXenServer free, advanced, enterprise license features\n\n\n\n*  XenServer Hypervisor\n*  Conversion Tools\n*  Management integration with Microsoft System Center VMM\n*  Resilient distributed management architecture\n*  VM disk snapshot and revert\n*  XenCenter Management Console\n*  XenMotion Live Migration\n\n\n\nXenServer advanced and enterprise license features\n\n\n\n*  Automated VM protection and recovery (Automated VM protection and recovery is only available for the Advanced and Enterprise editions in the 6.0 release and later.)\n*  Distributed virtual switching\n*  Heterogeneous Pools\n*  High Availability\n*  Memory Optimization\n*  Performance alerting and reporting\n\n\n\nXenServer Enterprise license features\n\n\n\n*  Dynamic workload balancing\n*  GPU pass-thru\n*  Host power management\n*  IntelliCache\n*  Live memory snapshot and revert\n*  Provisioning Services (virtual)\n*  Role-based administration\n*  StorageLink\n*  Web management console with delegated admin\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/virtualization?topic=virtualization-differences-between-versions-of-xenserver"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12571-37602-39455", "score": 7.865249831101993, "text": "\n: Version of the access policy API.\n\n\n\n\n\n Examples \n\nList all access policies under the current account:\n\nibmcloud iam access-policies\n\nList all user access policies under the current account:\n\nibmcloud iam access-policies --type user\n\nList all service ID access policies under the current account:\n\nibmcloud iam access-policies --type service_id\n\nList all access group access policies under the current account:\n\nibmcloud iam access-policies --type access_group\n\nList all trusted profile access policies under the current account:\n\nibmcloud iam access-policies --type trusted_profile\n\nList all trusted profile access policies sorted by created_at in ascending order under the current account:\n\nibmcloud iam access-policies --type trusted_profile --sort-by created_at\n\nList all trusted user policies sorted by last_modified_at in descending order under the current account:\n\nibmcloud iam access-policies --type user --sort-by -last_modified_at\n\n\n\n\n\n\n\n ibmcloud iam account-policies \n\nList all account policies under current account:\n\nibmcloud iam account-policies [-t, --type access | auth] [--output FORMAT] [-q, --quiet] [--api-version v1 | v2]\n\n\n\n Command options \n\n-t, --type access | auth\n: List all policies under current account filtered by policy type. Valid options are: access | auth\n\n--output FORMAT\n: Specify output format. Only 'JSON' is supported.\n\n-q, --quiet\n: Suppress verbose output.\n\n--api-version\n: Version of the access policy API.\n\n\n\n\n\n Examples \n\nList all account policies under current account:\n\nibmcloud iam account-policies\n\nList all authorization policies under current account. Provides the same list as ibmcloud iam authorization-policies:\n\nibmcloud iam account-policies -t auth\n\nList all access policies under current account. Provides the same list as ibmcloud iam access-policies:\n\nibmcloud iam account-policies -t access", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-ibmcloud_commands_iam"}, {"document_id": "ibmcld_04377-11298-12907", "score": 7.666710459517854, "text": "\nibmcloud account org-account ORG_NAME [-r, --region REGION] [--guid]\n\n\n\n Command options \n\n-r (optional)\n: Region name. Default to current region if not specified.\n\n--guid (optional)\n: Display account ID only\n\n\n\n\n\n\n\n ibmcloud account show \n\nShow account details:\n\nibmcloud account show\n\n\n\n Examples \n\nShow details of currently targeted account:\n\nibmcloud account show\n\n\n\n\n\n\n\n ibmcloud account update \n\nUpdate a specific account:\n\nibmcloud account update (--service-endpoint-enable true | false)\n\n\n\n Command options \n\n--service-endpoint-enable true | false\n: Enable or disable service endpoints connectivity for a SoftLayer account.\n\n\n\n\n\n Examples \n\nEnable service endpoint connectivity for current account:\n\nibmcloud account update --service-endpoint-enable true\n\n\n\n\n\n\n\n Classic infrastructure account audit-logs \n\nList SoftLayer account audit logs:\n\naccount audit-logs [-u, --user-name USER_NAME] [-t, --object-type OBJECT_TYPE] [-o, --object OBJECT] [-a, --action ACTION] [-s, --start-date START_DATE] [-e, --end-date END_DATE]\n\n\n\n Command options \n\n-a, --action ACTION\n: Action. List audit logs with the action.\n\n-e, --end-date END_DATE\n: End date. List audit logs before the end date. Supported formats are yyyy-MM-ddTHH:mm:ss.\n\no, --object OBJECT\n: Object. List audit logs with the object.\n\nt, --object-type OBJECT_TYPE\n: Object type. List audit logs with the object type.\n\ns, --start-date START_DATE\n: Start date. List audit logs after the start date. Supported formats are yyyy-MM-ddTHH:mm:ss.\n\nu, --user-name USER_NAME\n: User name. List audit logs with the user name.\n\n\n\n\n\n Examples \n\nList audit logs:", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_account"}, {"document_id": "ibmcld_12572-28465-30093", "score": 7.533716055238084, "text": "\nibmcloud resource tag-delete (--tag-name TAG_NAME | -a, --all [-f, --force]) [-p, --provider PROVIDER] [--tag-type TAG_TYPE] [--account-id ACCOUNT_ID]\n\n\n\n Command options \n\n--tag-name value\n: Tag name to be deleted.\n\n--provider value, -p value\n: Delete the tag in the specified provider (only supported value is classic-infrastructure). Use it for resources of type SoftLayer_Hardware, SoftLayer_Network_Application_Delivery_Controller, SoftLayer_Network_Subnet_IpAddress or SoftLayer_Network_Vlan.\n\n--tag-type value\n: Type of the tag. Only allowed values are: user, service or access (default value : user).\n\naccount-id value\n: The ID of the account that owns the tags to be deleted (required if tag-type is set to service).\n\n--force, -f\n: Delete the tags without confirmation.\n\n--all, -a\n: Delete all tags not attatched to any resources.\n\n-q, --quiet\n: Suppress verbose output.\n\nA tag can be deleted only if it isn't attached to any resource.\n\n\n\n\n\n Examples \n\n\n\n* To delete the user tag MyTag from the account:\n\nibmcloud resource tag-delete --tag-name \"MyTag\"\n* To delete the access management tag project:myproject from the account:\n\nibmcloud resource tag-delete --tag-name \"project:myproject\" --tag-type access\n* To delete all unused user tags from the account:\n\nibmcloud resource tag-delete -a\n* To delete all unused access management tags from the account:\n\nibmcloud resource tag-delete -a --tag-type access\n\n\n\n\n\n\n\n\n\n ibmcloud resource reclamations \n\nList reclaimed resources that can be restored or deleted:\n\nibmcloud resource reclamations [--resource-instance-id INSTANCE_ID]\n\n\n\n Command options \n\n--resource-instance-id", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-ibmcloud_commands_resource"}, {"document_id": "ibmcld_02379-22602-24722", "score": 7.4395464011221595, "text": "\nEnterprise usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n children Boolean Indicates whether the usage is aggregated at account level. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the sub-account ID that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-instances-usage-report.download:\n\n\n\nTable 19. Enterprise instances usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the the sub-account IDs that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\n\n\n\n\n\n\n Account IAM settings events (Deprecated) \n\nThis section explains events that are generated when you configure the IAM account settings from the Access (IAM) > Settings dashboard.\n\n\n\n Configuring MFA \n\nWhen you set on MFA in your account by configuring the Account Login section in the Access (IAM) > Settings dashboard, you get 2 events:\n\n\n\n* Event with action billing.account-traits.update that reports the type of MFA that is configured in the account in the requestData.mfa field.\n* Event with action billing.account-mfa.set-on that indicates that MFA is enabled in the account.\n\n\n\nWhen you set off MFA, you get the following 2 events:\n\n\n\n* Event with action billing.account-traits.update that reports the type of MFA that is configured in the account in the requestData.mfa field.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-at_events_acc_mgt"}, {"document_id": "ibmcld_03435-20211-22413", "score": 7.418322070984466, "text": "\nAccount usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n usage_report_type String Indicates the type of report. <br>Valid values are instances and rollup. Included always in the event \n sub_account_id String Indicates the sub-account ID. Optional \n resource_group String Indicates the resource group. Optional <br>Included if the user filters data by resource group. \n organization_id String Indicates the organization ID. Optional \n daily Boolean Indicates the frequency of the report. Optional \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-usage-report.read and billing.enterprise-usage-report.download:\n\n\n\nTable 18. Enterprise usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n children Boolean Indicates whether the usage is aggregated at account level. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the sub-account ID that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-instances-usage-report.download:\n\n\n\nTable 19. Enterprise instances usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the the sub-account IDs that is requested in the report. Optional \n account_group_id String Indicates the account group when a user selects one. Optional <br>Included if the user filters data by selecting 1 account group. \n\n\n\n\n\n\n\n\n\n Account IAM settings events (Deprecated)", "title": "", "source": "https://cloud.ibm.com/docs/atracker?topic=atracker-at_events_acc_mgt"}, {"document_id": "ibmcld_02379-20817-23063", "score": 7.298886711976948, "text": "\nThis section explains events that are generated when a user looks at the information that is provided through the Manage > Billing and usage > Usage section, or request an export of the data.\n\nYou can get events with reason.reasonCode = 404 that are generated when there is no usage data available for the request. The severity is set to normal.\n\n\n\n requestData fields \n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.account-summary.read, billing.account-summary.download, and billing.account-instances-usage-report.download:\n\n\n\nTable 16. Account usage summary requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.account-usage-report.read:\n\n\n\nTable 17. Account usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n usage_report_type String Indicates the type of report. <br>Valid values are instances and rollup. Included always in the event \n sub_account_id String Indicates the sub-account ID. Optional \n resource_group String Indicates the resource group. Optional <br>Included if the user filters data by resource group. \n organization_id String Indicates the organization ID. Optional \n daily Boolean Indicates the frequency of the report. Optional \n\n\n\nThe following table lists the fields that are available through the requestData field in the events with actions billing.enterprise-usage-report.read and billing.enterprise-usage-report.download:\n\n\n\nTable 18. Enterprise usage requestData fields\n\n Field Type Description Status \n\n month String Indicates the month that the user selects to view usage data. Included always in the event \n children Boolean Indicates whether the usage is aggregated at account level. Included always in the event \n enterprise_id String Indicates the ID of the enterprise. Included always in the event \n account_id String Indicates the sub-account ID that is requested in the report. Optional", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-at_events_acc_mgt"}, {"document_id": "ibmcld_02379-24279-26117", "score": 7.286254776179945, "text": "\n* Event with action billing.account-traits.update that reports the type of MFA that is configured in the account in the requestData.mfa field.\n* Event with action billing.account-mfa.set-on that indicates that MFA is enabled in the account.\n\n\n\nWhen you set off MFA, you get the following 2 events:\n\n\n\n* Event with action billing.account-traits.update that reports the type of MFA that is configured in the account in the requestData.mfa field.\n* Event with action billing.account-mfa.set-off that indicates that MFA is disabled in the account.\n\n\n\nFor example, see the requestData field for the event billing.account-traits.update:\n\n\"action\": \"billing.account-traits.update\",\n\"message\": \"Billing service: update account traits\",\n\"requestData\": {\n\"mfa\": \"\",\n\"origin\": \"BSS\"\n}\n\n\n\n\n\n Configuring user list visibility restriction \n\nWhen you modify the User list visibility restriction IAM account setting in the Manage > Access (IAM) > Settings dashboard, you get 1 event with action billing.account-traits.update.\n\nFor example, see the requestData field for the event billing.account-traits.update:\n\n\"action\": \"billing.account-traits.update\",\n\"message\": \"Billing service: update account traits\",\n\"requestData\": {\n\"origin\": \"BSS\",\n\"team_directory_enabled\": false\n}\n\n\n\n\n\n requestData fields \n\nThe following table lists requestData fields that you can find in events that are generated when the IAM account settings are modified from the Access (IAM) > Settings dashboard:\n\n\n\nTable 20. Account IAM settings requestData fields\n\n Field Type Description \n\n team_directory_enabled Boolean Defines the status of the User list visibility restriction IAM account setting. <br>When it is set to true, users in your account can view other users from the Users page. \n mfa String Defines the MFA method that is required for users to log in to the account.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-at_events_acc_mgt"}, {"document_id": "ibmcld_12571-36315-38014", "score": 7.283690748381439, "text": "\nibmcloud iam role-create PreviewCDCI --display-name \"Preview Toolchains\" --service-name toolchain --actions toolchain.dashboard.view --output JSON\n\nCreate a role that has a description:\n\nibmcloud iam role-create ServiceIDCreator --display-name \"Service ID Creator\" --service-name iam-identity --actions iam-identity.serviceid.create --description \"Can only create service keys\"\n\n\n\n\n\n\n\n ibmcloud iam access-policies \n\nList all access policies under the current account:\n\nibmcloud iam access-policies [-t, --type user | service_id | access_group | trusted_profile] [--sort-by id | type | href | created_at | created_by_id | last_modified_at | last_modified_by_id | state ] [--output FORMAT] [-q, --quiet ] [--api-version v1 | v2]\n\n\n\n Command options \n\n-t, --type ACCESS_POLICY_TYPE\n: List all access policies under current account filtered by policy type. Valid options are: user | service_id | access_group | trusted_profile\n\n--sort-by ATTRIBUTE\n: Sort the policies based on attributes. Valid options are: id | type | href | created_at | created_by_id | last_modified_at | last_modified_by_id | state. Prepend a minus (for example, -id, -type) for reverse sorting.\n\n--output FORMAT\n: Specify output format. Only 'JSON' is supported.\n\n-q, --quiet\n: Suppress verbose output.\n\n--api-version\n: Version of the access policy API.\n\n\n\n\n\n Examples \n\nList all access policies under the current account:\n\nibmcloud iam access-policies\n\nList all user access policies under the current account:\n\nibmcloud iam access-policies --type user\n\nList all service ID access policies under the current account:\n\nibmcloud iam access-policies --type service_id\n\nList all access group access policies under the current account:", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-ibmcloud_commands_iam"}, {"document_id": "ibmcld_01890-8166-9612", "score": 7.1867933496235015, "text": "\nThe following examples show how you can use the attribute names in the CLI to build trusted profile links and conditions.\n\n\n\n Linking a trusted profile to Kubernetes a cluster \n\nTo link the trusted profile Test to the Kubernetes cluster c0pigdctkkc07fs7pm06 in the account 444aebb0657c7f0f3aae8e7bdc78709a and service account my-service-account in the namespace my-namespace, specify the following command:\n\nibmcloud iam trusted-profile-link-create Test --name NewLink4IKS --cr-type IKS_SA \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 --link-crn\u00a0\ncrn:v1:bluemix:public:containers-kubernetes:us-east:a/444aebb0657c7f0f3aae8e7bdc78709a:c0pigdctkkc07fs7pm06:: \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 --link-namespace \"my-namespace\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 --link-name \"my-service-account\"\n\n\n\n\n\n Creating trusted profile conditions for Kubernetes \n\nTo connect the trusted profile with the ID Profile-b2f13064-2b8c-4e4b-9181-c1973a408e3c to all service accounts in the Kubernetes cluster c0pigdctkkc07fs7pm06 in the account 444aebb0657c7f0f3aae8e7bdc78709a and the service account namespace my-namespace, specify the following command:\n\nibmcloud iam trusted-profile-rule-create Profile-b2f13064-2b8c-4e4b-9181-c1973a408e3c \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 --name NewRule4IKS --type Profile-CR --cr-type IKS_SA \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 --conditions \"claim:service_instance,operator:EQUALS,vlaue:c0pigdctkkc07fs7pm06\" \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 --conditions \"claim:namespace,operator:EQUALS,value:my-namespace\"\n\n\n\n\n\n Creating trusted profile conditions for VPC", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-iam-condition-properties"}, {"document_id": "ibmcld_12583-20983-21896", "score": 7.170290840126592, "text": "\n\"locator_id\" : \"1082e7d2-5e2f-0a11-a3bc-f88a8e1931fc.018edf04-e772-4ca2-9785-03e8e03bef72-global\",\n\"type\" : \"terraform_template\",\n\"input\" : {\n\"name\" : \"account_id\",\n\"value\" : \"$configs].name\"account-stage\"].input.account_id\",\n\"type\" : \"string\"\n}, {\n\"name\" : \"resource_group\",\n\"value\" : \"stage\",\n\"type\" : \"string\"\n}, {\n\"name\" : \"access_tags\",\n\"value\" : \"env:stage\" ],\n\"type\" : \"string\"\n}, {\n\"name\" : \"logdna_name\",\n\"value\" : \"name of the LogDNA stage service instance\",\n\"type\" : \"string\"\n}, {\n\"name\" : \"sysdig_name\",\n\"value\" : \"name of the SysDig stage service instance\",\n\"type\" : \"string\"\n} ],\n\"output\" : {\n\"name\" : \"resource_group_id\"\n}, {\n\"name\" : \"logdna_id\"\n}, {\n\"name\" : \"sysdig_id\"\n} ] ! ! !\n},\n\"active_draft\" : {\n\"version\" : 2,\n\"state\" : \"ACTIVE\",\n\"pipeline_state\" : \"PIPELINE_SUCCEEDED\",\n\"href\" : \"/v1/projects/db268db0-160b-4911-8f93-89659000a927/configs/9c7afed6-17fb-4c56-a13d-440a78f936bd/drafts/2\"\n},", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-projects-cli"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>10", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03709-0-1479", "score": 24.6230723345431, "text": "\n\n\n\n\n\n\n  Why can't I apply a feature code? \n\nTo successfully apply a feature code, make sure the code is valid and that you have the correct account type.\n\n  What\u2019s happening \n\nWhen you try to apply a feature code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error for any of the following reasons:\n\n\n\n*  Your account doesn't meet the requirements for the feature code.\n*  You don't have the required access in the account.\n*  The code expired.\n\n\n\n  How to fix it \n\nUse the following steps to successfully apply a feature code:\n\n\n\n*  Verify that you have the correct account type. For example, some feature codes for educational promotions are only for Lite accounts. To view your account type, in the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings. For more information, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https://cloud.ibm.com/docs/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n*  If you are unable to apply a feature code that you received from an educational provider, contact that educational provider for further assistance.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cannot-apply-feature-code"}, {"document_id": "ibmcld_03704-7496-9340", "score": 23.83783243026363, "text": "\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n\n\n\n\n\n Where can I get a promo code? \n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/account?topic=billing-usage-applying-promo-codes).\n\n\n\n\n\n Where can I get a feature code? \n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n\n\n\n\n\n How do I apply a promo code? \n\nTo apply your promo code, go to the [Promotions](https://cloud.ibm.com/billing/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_07578-1048947-1050776", "score": 23.83783243026363, "text": "\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https://cloud.ibm.com/billing/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1048818-1050647", "score": 23.83783243026363, "text": "\nThe codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops. They're typically random alphanumeric codes, like a1b2c3def456. For more information about feature codes, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n* Where can I get a promo code?\n\nPromo codes are provided on a limited basis by IBM Cloud sales to customers with Pay-As-You-Go and Subscription accounts. Promotions provide specific discounts for a set amount of time. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/account?topic=billing-usage-applying-promo-codes).\n* Where can I get a feature code?\n\nFeature codes are provided by IBM Cloud sales and educational providers on a limited basis. Feature codes are meant for select groups and are typically given out at hackathons, conferences, and other events. If you are taking a course through an educational provider and need additional resources to complete the course, contact your educational provider to determine if a feature code is applicable.\n* How do I apply a promo code?\n\nTo apply your promo code, go to the [Promotions](https://cloud.ibm.com/billing/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03732-0-1673", "score": 23.582446396842386, "text": "\n\n\n\n\n\n\n  Applying feature codes \n\nYou can apply feature codes to take advantage of extra IBM Cloud\u00ae resources or capabilities. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.\n\nAre you looking for details about adding subscription credit to your account? See [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions) for more information.\n\nYou must have the Editor role or higher for all account management services to apply a feature code. The extra resources or capabilities that are provided vary depending on the particular code but include one or more of the following items in general:\n\n\n\n*  Increase the memory quota to a number of GB that is specified by the code\n*  Add one organization with a memory quota that is specified by the code\n*  Add an unlimited number of organizations\n*  Upload an extra number of SSL certificates, as specified by the code\n*  Use premium service plans\n*  Convert a Lite account to a trial account, which provides access to more services but only within a limited trial period\n\n\n\nComplete the following steps to apply a feature code to your existing account:\n\nIf you don't have an account yet, you can add your feature code when you [register](https://cloud.ibm.com/registration) for a new account by clicking Register with a code instead of entering your credit card information.\n\n\n\n1.  In the IBM Cloud console, go to Manage > Account, and select Account settings.\n2.  Click Apply code.\n3.  Enter the feature code, which is typically a random alphanumeric value such as a1b2c3def456.\n4.  Click Apply.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-codes"}, {"document_id": "ibmcld_03711-0-822", "score": 23.222892063465757, "text": "\n\n\n\n\n\n\n  Why can\u2019t I create a service after I apply a feature code? \n\nYou can recover from issues with creating service after a feature code is applied by following a few easy steps.\n\n  What\u2019s happening \n\nWhen you try to create an instance of a service from the catalog, you're prompted to upgrade with a message such as Upgrade your account to create instances of the offering.\n\n  Why it\u2019s happening \n\nYour account wasn't enabled to create resources of that type after you applied the feature code. The resources or capabilities that are provided vary for each feature code.\n\n  How to fix it \n\nContact the person who gave you the feature code to verify the capabilities that it can enable for your account. For example, contact your educational provider for feature codes that they gave you for use with coursework.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cant-create-service-feature-code"}, {"document_id": "ibmcld_03699-7-2091", "score": 21.931903872779912, "text": "\nApplying promo codes \n\nPromotions are limited-time credits toward your IBM Cloud\u00ae account and services that you can get by applying promo codes. Each promo code can be used one time and is valid only for a certain amount of time. Promo codes are provided on a limited basis by IBM Cloud sales to customers with billable accounts.\n\nPromo codes are typically based on short phrases, like PROMO200. If you have an alphanumeric code, such as a1b2c3def456, it's a different type of code that is referred to as a feature code. You can apply these codes on the Manage > Account > Account settings page or when you register for a new account. For more information, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n\nPromotions are one type of credit for your account. For example, if you have a Pay-As-You-Go or Subscription account, you can use promo codes for limited-time credits toward your account and IBM Cloud products. Promo codes are different from feature codes that provide access to Trial accounts, or subscriptions that add credits as discounts to your account.\n\n\n\n Types of available promotion credits \n\nBoth one-time credit promotions and recurring dollar credit promotions are available for all IBM Cloud products.\n\n\n\n1. One-time credit promotion\n\n\n\n* Credit promotions can be used only one time, for a set time period, and you can't remove them after you apply them. Credit promotions use the following format: $X off for Y days.\n\n\n\n2. Recurring dollar credit promotion\n\n\n\n* Recurring dollar credits are offered for a set time period. For example, you can have a promotion of $100 USD value that is recurring every 30 days for 6 months. Recurring dollar credit promotions use the following format: $X every Y months, repeats Z times.\n* Promo credit expires at the end of the committed term. Any credit that isn't used doesn't roll over to the next term.\n\nWith a recurring credit, if the amount of credit that is allocated to a client is not used within the allocated time, the credit expires.\n\n\n\n\n\n\n\n\n\n Applying promo codes to your account", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes"}, {"document_id": "ibmcld_03704-10459-12479", "score": 21.509080729154647, "text": "\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and click Create a case.\n\n\n\n\n\n How do I apply a feature code? \n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https://cloud.ibm.com/account/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Why did my account get billed for additional services charges? \n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_07578-1051890-1053900", "score": 21.509080729154647, "text": "\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https://cloud.ibm.com/account/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1051761-1053771", "score": 21.509080729154647, "text": "\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case. Go to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and click Create a case.\n* How do I apply a feature code?\n\nFeature codes add extra capabilities in an account and are typically provided for educational initiatives or special events. To redeem your code, go to the [Account settings](https://cloud.ibm.com/account/settings) page in the console, and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration).\n\nYou might be looking for information about promo codes and subscription codes, which are available for certain account types. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n* Why did my account get billed for additional services charges?\n\nAs the account owner, you're responsible for all charges that are incurred by users in your account, including invited users. Ensure that each user is assigned only the level of access that is required to complete their job, including the ability to create new instances that might incur extra charges in your account. For more information, see [Managing access to resources](https://cloud.ibm.com/docs/account?topic=account-assign-access-resources).\n\nResources and applications that are left running in an account are subject to charges based on the pricing and description of the product.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01441-7-2257", "score": 32.326827483557885, "text": "\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4"}, {"document_id": "ibmcld_01442-7-2257", "score": 32.326827483557885, "text": "\nUpdate Vulnerability Advisor to version 4 by 19 June 2023 \n\nThe Vulnerability Advisor component of IBM Cloud\u00ae Container Registry is being updated. From 19 June 2023, Vulnerability Advisor version 3 will be replaced as the default by Vulnerability Advisor version 4.\n\nVulnerability Advisor version 3 is being deprecated as the default on 19 June 2023. From 19 June 2023, the default will be Vulnerability Advisor version 4. If you have version 3 set as the default, you can continue to use version 3 until the end of support date. An end of support date is not available yet.\n\n\n\n What you need to know about this change \n\nIf you use the IBM Cloud console to access Vulnerability Advisor, no action is required. The IBM Cloud console is automatically updated to Vulnerability Advisor version 4.\n\nIf you use the IBM Cloud CLI and you want to use version 4 as the default, you must update the Container Registry CLI plug-in to version 1.0.0, or later, by 19 June 2023. Updating the Container Registry CLI plug-in to version 1.0.0, or later, enables the ibmcloud cr va command and the --va option on the ibmcloud cr images and ibmcloud cr digests commands to work with Vulnerability Advisor version 4.\n\nOn 19 June 2023, when the default changes to Vulnerability Advisor version 4, the Container Registry CLI automatically starts to use this version unless the ibmcloud cr va-version-set v3 command was run, in which case Vulnerability Advisor version 3 continues to be used. You can use the ibmcloud cr va-version command to determine which Vulnerability Advisor version is being used and the ibmcloud cr va-version-set v4 command to switch to Vulnerability Advisor version 4. When Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}, {"document_id": "ibmcld_01441-1679-3819", "score": 31.83748641160135, "text": "\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4notices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4"}, {"document_id": "ibmcld_01442-1679-3832", "score": 31.81643516356797, "text": "\nWhen Vulnerability Advisor version 3 reaches its end of support date, any Container Registry CLI commands that access Vulnerability Advisor version 3 cease to work. An end of support date is not available yet.\n\nIf you use the Vulnerability Advisor REST API to access Vulnerability Advisor, you must update your client call from /va/api/v3 APIs to /va/api/v4 APIs.\n\nIf you use one of the Vulnerability Advisor version 3 SDKs to access Vulnerability Advisor, you must update to the Vulnerability Advisor version 4 SDK.\n\nAny exemptions that you previously defined continue to work. However, the security notice value that comes back in Vulnerability Advisor version 4 might not be the same as for Vulnerability Advisor version 3 because different sources of data are used. Therefore, if the returned value isn't the same as for Vulnerability Advisor version 3, you might have to update any existing exemptions that specify a security notice. Red Hat\u00ae security notices are unaffected. Exemptions that are defined by CVE value are also unaffected.\n\nDifferences in Vulnerability Advisor version 4 behavior are documented in [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\n\n\n\n\n What actions you must take by 19 June 2023 \n\nYou can choose whether to update to use version 4, the default, or to continue to use version 3, which is deprecated.\n\n\n\n* If you want to use Vulnerability Advisor version 4 as the default, update the following items as described in [What you need to know about this change](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=uinotices_va_v4_change):\n\n\n\n* The Container Registry CLI plug-in and, if you have explicitly run the ibmcloud cr va-version-set v3 command previously, run the following command.\n\nibmcloud cr va-version-set v4\n* Any code that calls Vulnerability Advisor version 3 either through the API or through the SDK.\n* You might have to update any existing exemptions that specify a security notice.\n\n\n\n* If you want to continue to use Vulnerability Advisor version 3, run the following command:\n\nibmcloud cr va-version-set v3", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui"}, {"document_id": "ibmcld_01533-4-2366", "score": 31.767130160191254, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4-2366", "score": 31.767130160191254, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01329-58331-60199", "score": 31.65923080490092, "text": "\nibmcloud cr va-version-set \n\nSet the version of Vulnerability Advisor. You can set the version to either v3, the default, or v4. If you want to use version 4 temporarily, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nibmcloud cr va-version-set VERSION\n\n\n\n Prerequisites \n\nNone.\n\n\n\n\n\n Command options \n\nVERSION\n: The version of Vulnerability Advisor that you want to use. Valid values are v3 and v4.\n\n\n\n\n\n Example \n\nTo set the Vulnerability version to version 4, run the following command:\n\nibmcloud cr va-version-set v4\n\n\n\n\n\n\n\n ibmcloud cr vulnerability-assessment (ibmcloud cr va) \n\nView a vulnerability assessment report for your images.\n\nFrom version 1.0.0 of the container-registry plug-in, you can choose whether to run the ibmcloud cr vulnerability-assessment command in either version 3 (the default) or version 4 of Vulnerability Advisor. If you want to run Vulnerability Advisor in a different version, see [Setting the Vulnerability Advisor version](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_set_version). For more information about the versions of Vulnerability Advisor, see [About Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiabout).\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-containerregcli"}, {"document_id": "ibmcld_01533-8109-9900", "score": 31.347809141280944, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https://gitlab.alpinelinux.org/) and [CVE](https://cve.mitre.org/data/downloads/index.html). \n CentOS Version 7 [CentOS announce archives](https://lists.centos.org/pipermail/centos-announce/) and [CentOS CR announce archives](https://lists.centos.org/pipermail/centos-cr-announce/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https://lists.debian.org/debian-security-announce/) and [Debian LTS Security Information](https://www.debian.org/lts/security/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https://github.com/GoogleContainerTools/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-8161-9952", "score": 31.347809141280944, "text": "\nFor more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.\n\nVulnerability Advisor supports only releases of platforms that are currently supported by the vendor of that platform.\n\n\n\nTable 1. Supported Docker base images that Vulnerability Advisor 3 checks for vulnerable packages\n\n Docker base image Supported versions Source of security notices \n\n Alpine All stable versions with vendor security support. [Git - Alpine Linux](https://gitlab.alpinelinux.org/) and [CVE](https://cve.mitre.org/data/downloads/index.html). \n CentOS Version 7 [CentOS announce archives](https://lists.centos.org/pipermail/centos-announce/) and [CentOS CR announce archives](https://lists.centos.org/pipermail/centos-cr-announce/). \n Debian All stable versions with vendor security support or long-term support. [Debian security announcements](https://lists.debian.org/debian-security-announce/) and [Debian LTS Security Information](https://www.debian.org/lts/security/). \n GoogleContainerTools distroless All stable versions with vendor security support. [GoogleContainerTools distroless](https://github.com/GoogleContainerTools/distroless) \n Red Hat\u00ae Enterprise Linux\u00ae (RHEL) RHEL/UBI 7, RHEL/UBI 8, and RHEL/UBI 9 [Red Hat Security Data API](https://access.redhat.com/labsinfo/securitydataapi). \n Ubuntu All stable versions with vendor security support.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01533-6329-8623", "score": 30.95578152754983, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_14682-7-2113", "score": 39.176927378589205, "text": "\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https://www.ibm.com/cloud/architecture/architectures/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"}, {"document_id": "ibmcld_14497-7-1724", "score": 37.808725662334815, "text": "\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https://www.ibm.com/cloud/architecture/architectures/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"}, {"document_id": "ibmcld_14492-7-1792", "score": 36.34518055076008, "text": "\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-ocp_overview"}, {"document_id": "ibmcld_14747-73981-75972", "score": 33.64187807960863, "text": "\n* Red Hat OpenShift for VMware v4.4.13\n\n\n\nPromotions for VMware Solutions add-on services\n: IBM Cloud for VMware Solutions offers promotions for some VMware services. Promotional pricing offers a number of months free of charge for a service\u2019s licenses, if the service has license charges.\n\nYou can use one promotion (promo) code for one or more of the following services.\n\n\n\n* Ordering a new VMware vCenter Server\n* Adding a service to an existing vCenter Server\n* Ordering a stand-alone service (license), such as Caveonix or Veeam\n\n\n\nResource requirements for add-on services\n: Capacity checks are performed to ensure that resource requirements are met for services installation. Capacity checks are performed for the following services during instance deployment.\n\n\n\n* Caveonix RiskForesight\n* F5 BIG-IP\n* FortiGate Virtual Appliance\n* HyTrust CloudControl\n* Zerto\n\n\n\nSelecting the target cluster for Red Hat OpenShift for VMware\n: The target cluster for installing Red Hat OpenShift varies with the following scenarios.\n\n\n\n* During deployment, you aren't prompted for the cluster. The service is automatically installed to the management cluster.\n* During Day 2 operations, you are prompted for the cluster. You can install the service to a management cluster or a workload cluster.\n\n\n\nDeleting services from a cluster before deleting the cluster\n: If you remove a nonmanagement cluster that has services installed on it, the services are also deleted as part of the process.\n\nPreviously, when you removed a nonmanagement cluster, for example, an edge services cluster, any services installed on that cluster were not removed. You had to first delete the services from the cluster and then delete the cluster itself.\n\nThis change affects the Juniper vSRX and Red Hat OpenShift for VMware services.\n\nREST APIs\n: APIs are now available for the Red Hat OpenShift for VMware service.\n\nNew and updated documentation\n: A new topic, Resource requirements for add-on services, is now available.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vmwaresolutions-relnotes"}, {"document_id": "ibmcld_13145-2436-4270", "score": 31.980199752061335, "text": "\n5. The user securely(HTTPS) accesses the application via browser.\n6. The admin monitors the health and performance of the microservices using the metrics, traces, logs.\n\n\n\n\n\n\n\n Before you begin \n\nThis tutorial requires:\n\n\n\n* IBM Cloud CLI,\n\n\n\n* IBM Cloud Kubernetes Service plugin (kubernetes-service),\n\n\n\n* oc to interact with OpenShift.\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools, you can use the [Cloud Shell](https://cloud.ibm.com/shell) from the IBM Cloud console. Use oc version to ensure the version of the Red Hat OpenShift on IBM Cloud CLI matches your cluster version (4.12.x). If they do not match, install the matching version by following [these instructions](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-tutorialsgetting-started-cloud-shell).\n\n\n\n\n\n Step 1: Create a Red Hat OpenShift on IBM Cloud cluster \n\nWith Red Hat OpenShift on IBM Cloud, you have a fast and secure way to containerize and deploy enterprise workloads in clusters. Red Hat OpenShift on IBM Cloud clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nIn this section, you will provision a Red Hat OpenShift on IBM Cloud cluster in one (1) zone with two (2) worker nodes:\n\n\n\n1. Log into your IBM Cloud account and create a Red Hat OpenShift on IBM Cloud cluster from the [Red Hat OpenShift on IBM Cloud cluster create page](https://cloud.ibm.com/kubernetes/catalog/create?platformType=openshift).\n2. Set the Orchestration service to 4.12.x version of Red Hat OpenShift on IBM Cloud.\n3. Select your OCP entitlement.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-openshift-service-mesh"}, {"document_id": "ibmcld_08259-0-511", "score": 31.719918616773736, "text": "\n\n\n\n\n\n\n  Release notes for Red Hat OpenShift for HPC \n\nUse these release notes to learn about the latest updates to Red Hat\u00ae OpenShift\u00ae for HPC that are grouped by date.\n\n\n\n  March 2022 \n\n\n\n  24 March 2022 \n\nIntroducing Red Hat OpenShift for HPC solutions\n:   You can now take advantage of automated deployment of a Red Hat OpenShift cluster along with a deployer virtual server instance, which allows you to easily assemble, compile, and deploy your HPC applications to the Red Hat OpenShift cluster.\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/hpc-openshift?topic=hpc-openshift-release-notes"}, {"document_id": "ibmcld_16729-218252-220002", "score": 31.715075160561916, "text": "\nA VPC allows you to create your own space in IBM Cloud so that you can run an isolated environment in the public cloud with custom network policies.\n\nVirtual Private Cloud (VPC) Terraform on IBM Cloud\n\n\n\n* 2 hours\n* 2023-04-21\n\n\n\n[Updating VPC worker nodes that use OpenShift Data Foundation](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-vpc)Updating VPC worker nodes that use OpenShift Data Foundation\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster\n\nOpenShift Data Foundation is a highly available storage solution that you can use to manage persistent storage for your containerized workloads in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-05-09\n\n\n\n[Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorial)Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)\n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 45 minutes\n* 2023-07-07", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_13150-2578-4333", "score": 31.56821557097749, "text": "\n* (optional) IBM Cloud GitLab configured with your SSH key.Check the instructions under the Generate an SSH key pair and Add an SSH key to your GitLab account sections of the [documentation here](https://us-south.git.cloud.ibm.com/help/user/ssh.md)\n\n\n\nYou will find instructions to download and install these tools for your operating environment in the [Getting started with tutorials](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-tutorials) guide.\n\nTo avoid the installation of these tools, you can use the [Cloud Shell](https://cloud.ibm.com/shell) from the IBM Cloud console. Use oc version to ensure the version of the Red Hat OpenShift on IBM Cloud CLI matches your cluster version (4.12.x). If they do not match, install the matching version by following [these instructions](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-tutorialsgetting-started-cloud-shell).\n\nIn addition, make sure you [set up a registry namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_setup_cli_namespaceregistry_namespace_setup).\n\n\n\n\n\n Step 1: Create an Red Hat OpenShift on IBM Cloud cluster \n\nWith Red Hat OpenShift on IBM Cloud, you have a fast and secure way to containerize and deploy enterprise workloads in Red Hat OpenShift on IBM Cloud clusters. Red Hat OpenShift on IBM Cloud clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nIn this section, you will provision a Red Hat OpenShift on IBM Cloud cluster in one (1) zone with two (2) worker nodes:\n\n\n\n1. Create an Red Hat OpenShift on IBM Cloud cluster from the [IBM Cloud\u00ae catalog](https://cloud.ibm.com/kubernetes/catalog/create?platformType=openshift).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-scalable-webapp-openshift"}, {"document_id": "ibmcld_16728-14320-15936", "score": 31.55580833004387, "text": "\nThis tutorial walks you through steps for setting up highly available and isolated workloads by provisioning IBM Cloud\u00ae Virtual Private Clouds (VPCs). You will create virtual server instances (VSIs) in multiple zones within one region to ensure the high availability of the application. You will create additional VSIs in a second region and configure a global load balancer (GLB) to provide high availability between regions and reduce network latency for users in different geographies.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Deploy microservices with Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-openshift-microservices)Deploy microservices with Red Hat OpenShift on IBM Cloud Solution tutorial\n\nThis tutorial demonstrates how to deploy applications to Red Hat OpenShift on IBM Cloud. Red Hat OpenShift on IBM Cloud provides a great experience for developers to deploy software applications and for System Administrators to scale and observe the applications in production.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Deploy NSX-T Managers ](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-bm-vmware-nsx-t-deploy)Deploy NSX-T Managers Solution tutorial\n\nIn this tutorial, NSX-T will be deployed on the VMware Cluster. This includes deploying NSX-T managers, adding compute manager and adding host and edge transport nodes. This phase is optional, if you plan to use NSX-T for your Virtual Machine networking.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs?tab=solutions"}, {"document_id": "ibmcld_16728-34612-36286", "score": 31.455431624871267, "text": "\n[solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Public frontend and private backend in a Virtual Private Cloud](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-public-app-private-backend)Public frontend and private backend in a Virtual Private Cloud Solution tutorial\n\nThis tutorial walks you through creating your own IBM Cloud\u00ae Virtual Private Cloud (VPC) with multiple subnets and a virtual server instance (VSI) in each subnet. A VPC is your own, private cloud on shared cloud infrastructure with logical isolation from other virtual networks.\n\n![solution tutorial icon](https://cloud.ibm.com/media/docs/images/homepage/solution-tutorial.svg) [Red Hat OpenShift Container Platform on VPC landing zone](https://cloud.ibm.com/docs/deployable-reference-architectures?topic=deployable-reference-architectures-ocp-ra)Red Hat OpenShift Container Platform on VPC landing zone Reference architecture\n\nRed Hat OpenShift Container Platform on VPC landing zone is a deployable architecture solution that is based on the IBM Cloud for Financial Services reference architecture. It creates secure and compliant Red Hat OpenShift Container Platform workload clusters on a Virtual Private Cloud (VPC) network.\n\nDeployable![ref architecture icon](https://cloud.ibm.com/media/docs/images/homepage/reference-architecture.svg) [Resilient and secure multi-region Kubernetes clusters with IBM Cloud Internet Services](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-multi-region-k8s-cis)Resilient and secure multi-region Kubernetes clusters with IBM Cloud Internet Services Solution tutorial", "title": "", "source": "https://cloud.ibm.com/docs?tab=solutions"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10852-44214-45420", "score": 59.90155174023518, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10852-43319-44485", "score": 58.78093192073511, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10817-1342-3184", "score": 56.023579654831195, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10817-7-1802", "score": 47.405606478835296, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-7-1743", "score": 46.85938283103106, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_04518-1426-3052", "score": 43.398788178197364, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10817-2884-4620", "score": 40.81365304937614, "text": "\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in /Library/Developer/Xcode/DerivedData/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_07551-14062-16080", "score": 38.77521984450604, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_07551-15747-17355", "score": 36.099779540195485, "text": "\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https://github.com/IBM/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n/Register iOS devices/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_12332-1034-2510", "score": 33.81621559251314, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10817-7-1802", "score": 23.44391944978554, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_13724-72779-74671", "score": 23.237011119467343, "text": "\nThe customization interface includes a collection of new HTTP methods that have the names POST /v1/customizations, POST /v1/customizations/{customization_id}, POST /v1/customizations/{customization_id}/words, and PUT /v1/customizations/{customization_id}/words/{word}. The service also provides a new GET /v1/pronunciation method that returns the pronunciation for any word and a new GET /v1/voices/{voice} method that returns detailed information about a specific voice. In addition, existing methods of the service's interface now accept custom model parameters as needed.\n\nFor more information about customization and its interface, see [Understanding customization](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-customIntro) and the [API & SDK reference](https://cloud.ibm.com/apidocs/text-to-speech).\n\nThe customization interface is a beta release that currently supports US English only. All customization methods and the GET /v1/pronunciation method can currently be used to create and manipulate custom models and word translations only in US English.\n\nNew Brazilian Portuguese voice: pt-BR_IsabelaVoice\n: The service supports a new voice, pt-BR_IsabelaVoice, to synthesize audio in Brazilian Portuguese with a female voice. For more information, see [Languages and voices](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile Software Development Kits (SDKs) are available for the speech services. The SDKs enable mobile applications to interact with both the Text to Speech and Speech to Text services. You can use the SDKs to send text to the Text to Speech service and receive an audio response.\n\n\n\n* The Watson Swift SDK is available from the [swift-sdk repository](https://github.com/watson-developer-cloud/swift-sdk) in the watson-developer-cloud namespace on GitHub.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-release-notes"}, {"document_id": "ibmcld_01660-16615-18504", "score": 23.184401924865437, "text": "\nThe account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/account/images/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n\n\n\n\n\n Can I move data between IBM Cloud accounts? \n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https://cloud.ibm.com/unifiedsupport/supportcenter) for assistance with data migration questions.\n\n\n\n\n\n Can I bookmark a console page for a specific account? \n\nYou can target URLs for any IBM Cloud console page to a specific account. If you have multiple accounts, you can bookmark the account-specific URLs to easily access resources in different accounts without having to manually switch between them.\n\n\n\n1. Switch to the account that you want to target, and go to the [Account settings](https://cloud.ibm.com/account/settings) page in the console. In the Account section, find the account ID, such as a1b2c3d4e5f61234567890fedcba4321.\n2. Go to the console page that you want to bookmark, and add ?bss_account=<account-id> to the URL, replacing <account-id> with the ID from your account. For example,:", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_13429-166159-168045", "score": 22.835219290864835, "text": "\nNew UK English and Arabic models\n: The service supports more languages with its transcription models: en-UK_BroadbandModel and en-UK_NarrowbandModel for UK English, and ar-AR_BroadbandModel for Modern Standard Arabic. For more information, see [Previous-generation languages and models](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-models).\n\nNew session_closed field for session-based methods\n: In the JSON responses that it returns for errors with session-based methods, the service now also includes a new session_closed field. The field is set to true if the session is closed as a result of the error. For more information about possible return codes for any method, see the [API & SDK reference](https://cloud.ibm.com/apidocs/speech-to-text).\n\nHTTP platform timeout no longer applies\n: HTTP recognition requests are no longer subject to a 10-minute platform timeout. The service now keeps the connection alive by sending a space character in the response JSON object every 20 seconds as long as recognition is ongoing. For more information, see [Timeouts](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-inputtimeouts).\n\nRate limiting with curl command no longer needed\n: When you use the curl command to transcribe audio with the service, you no longer need to use the --limit-rate option to transfer data at a rate no faster than 40,000 bytes per second.\n\nChanges to HTTP error codes\n: The service no longer returns HTTP status code 490 for the session-based HTTP methods GET /v1/sessions/{session_id}/observe_result and POST /v1/sessions/{session_id}/recognize. The service now responds with HTTP status code 400 instead.\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile SDKs are available for the speech services. The SDKs enable mobile applications to interact with both the Speech to Text and Text to Speech services.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-release-notes"}, {"document_id": "ibmcld_07642-0-563", "score": 22.379116063409107, "text": "\n\n\n\n\n\n\n  AC-19 (5) - Full Device / Container-based Encryption \n\n\n\n  Control requirements \n\nAC-19 (5) - 0\n:   The organization employs [IBM Assignment: file level, full disk/device, or both] to protect the confidentiality and integrity of information on [Assignment: organization-defined mobile devices].\n\n\n\n\n\n  NIST supplemental guidance \n\nContainer-based encryption provides a more fine-grained approach to the encryption of data/information on mobile devices, including for example, encrypting selected data structures such as files, records, or fields.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ac-19.5"}, {"document_id": "ibmcld_16727-1086316-1088349", "score": 22.289197899136983, "text": "\nThe account selector displays the account name and account number.\n* How can I join accounts?\n\nThe account owner, organization manager, or a user with the correct permissions can invite you to join their account.\n\n\n\n* If you're new to IBM Cloud\u00ae, you receive an email that contains all the information you need.\n* As an existing member of IBM Cloud\u00ae, you can accept the invitation in your notifications, by email, or by using the CLI to onboard to the new account. To accept invitations in the CLI, use the [ibmcloud login](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_cliaccept-invitation-to-join-a-new-account-) command.\n\n\n\n* Can I switch between multiple accounts?\n\nIf you have access to more than one account, you can click your account name in the console menu bar to switch to another account.\n\n![A screen capture of the account selector in the console menu bar. The account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https://cloud.ibm.com/images/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n* Can I move data between IBM Cloud accounts?\n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https://cloud.ibm.com/unifiedsupport/supportcenter) for assistance with data migration questions.\n* Can I bookmark a console page for a specific account?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1083825-1085863", "score": 22.246306273551486, "text": "\nThe account selector displays the account name and account number.\n* How can I join accounts?\n\nThe account owner, organization manager, or a user with the correct permissions can invite you to join their account.\n\n\n\n* If you're new to IBM Cloud\u00ae, you receive an email that contains all the information you need.\n* As an existing member of IBM Cloud\u00ae, you can accept the invitation in your notifications, by email, or by using the CLI to onboard to the new account. To accept invitations in the CLI, use the [ibmcloud login](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_cliaccept-invitation-to-join-a-new-account-) command.\n\n\n\n* Can I switch between multiple accounts?\n\nIf you have access to more than one account, you can click your account name in the console menu bar to switch to another account.\n\n![A screen capture of the account selector in the console menu bar. The account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https://cloud.ibm.com/docs/images/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n* Can I move data between IBM Cloud accounts?\n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https://cloud.ibm.com/unifiedsupport/supportcenter) for assistance with data migration questions.\n* Can I bookmark a console page for a specific account?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_14390-16273-17983", "score": 21.559594430147076, "text": "\n* At the end of the documented process, your vCenter Server instance is running vSphere 7.0 Update 1c with N-VDS distributed switches. This configuration is different than the currently supported [Software BOM for vCenter Server instances](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_bomvc_bom-software), which is vSphere 7.0 Update 3c with Distributed vSwitch 7.0.0.\n* For more information about the migration of N-VDS to VDS switches for vSphere 7.0 or later and NSX-T Data Center 3.0 and later, see [Migrate host switch to vSphere Distributed Switch](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/3.1/administration/GUID-1039A36F-F55E-4A0A-B6C6-2C383F4A716D.html). Currently, this procedure is not verified on a VMware Solutions vCenter Server instance.\n* IBM Cloud is undertaking an assessment of the N-VDS to VDS conversion and the required changes to the automation database to allow this in-place upgrade.\n* Currently, Day 2 automation workflows such as add host or add cluster, are not tested against VMware Solutions vCenter Server instances that are upgraded from vSphere 6.7 to 7 and still using N-VDS distributed switches. Customers must assume that this automation might fail and that if this automation is required then the lift and shift migration approach used. If this automation is not needed, you can use the upgrade process that is documented.\n* A workaround for the add nodes and add cluster features is to use the VMware vSphere offering. For more information, see [VMware vSphere overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview). You must complete a number of manual tasks after the automated deployment.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-faq-v2t-migration"}, {"document_id": "ibmcld_10852-44214-45420", "score": 21.129944587457004, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_00959-2830-5215", "score": 20.802380309873136, "text": "\n* Avoid application downtime.\n* Enable production testing of new functions without impacting customers.\n* Limit the impact of production issues to a subset of users.\n* Enable rapid rollback to the previous version if issues are found.\n\n\n\nMany possible deployment strategies are available. In general, they depend on running multiple instances of the application and managing how the various instances are updated. You can pre-configure the following common deployment strategies in Continuous Delivery:\n\nBasic\n: Deploys the new release by stopping and updating all of the running instances simultaneously, causing downtime. For rollback, you must deploy the previous version again, which causes extra downtime. Although this strategy is simple, fast, and has low runtime resource requirements, it is the riskiest and causes downtime. The Basic deployment strategy is not recommended for critical apps that must be highly available.\n\nRolling update\n: Similar to the Basic strategy, this deployment strategy is simple, fast, and has low runtime resource requirements. However, because each running instance is taken down and updated individually, avoiding downtime, rollback requires you to deploy the previous release again. This time consuming approach might cause issues if the current version of the app in production is broken.\n\nBlue-Green deployment\n: Creates two separate, permanent production environments (blue and green), and only one of those environments receives traffic at a time. The current release is always deployed to the idle environment and traffic is switched to it after deployment completes, with no downtime. Because you need to switch only the traffic to the unchanged environment, rollback does not cause downtime. Because this strategy requires two full production environments, the resource requirements are higher. However, this strategy enables powerful Developer flows, such as the ability to test new app versions in the production environment before it allows customer traffic. Blue-Green deployment also supports fast rollback.\n\nCanary release\n: Deploys a new release in parallel with the original production environment (similar to Blue-Green), with no downtime. The amount of traffic that is sent to both the updated and original instances is managed so that the new version is available to a controlled subset of users while the deployment proceeds.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-kubernetes"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16628-0-1541", "score": 15.058880633739205, "text": "\n\n\n\n\n\n\n  About Visual Explain \n\nThe visual explain feature in IBM\u00ae watsonx.data shows the execution plan for a specified SQL query. This feature also validates the SQL query. The output results can be visualized in different formats, which can be rendered into a graph or a flow chart. Data exchange happens between single or multiple nodes within a fragment. Each fragment has a set of data that is distributed between the nodes.\n\nWith this visual explain feature, you can run the query and show the output in a distributed environment. You can output the results in different formats. When queries are run, they scan through the database. The queries retrieve table metadata to fetch the correct output.\n\nWith this visual explain feature, you can visualize the query in a graphical representation. When a query is run in the SQL editor and selects the Explain option, watsonx.data uses an EXPLAIN SQL statement on the query to create a corresponding graph. This graph can be used to analyze, fix, and improve the efficiency of your queries by saving time and cost.\n\nTo view the execution plans for a query that is run in watsonx.data SQL editor, follow the steps:\n\n\n\n1.  In the Query workspace page, enter the query and click Run on starter to get the results.\n2.  Click Explain on the screen to visualize the graphical representation of the query.\n\n\n\nOn the Explain window, click a stage to view the details on the right window. The details of each stage that is displayed are the estimate values for rows, CPU, memory, and network.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-explain_sql_query"}, {"document_id": "ibmcld_11164-6586-7646", "score": 13.507802169898309, "text": "\n* A design document explains how load balancing is used to keep a service highly available.\n* Where multi-site failover occurs, the disaster recovery plan must explain who does what to cause the failover and ensure restart.\n* The disaster recovery plan must define how the solution works and include restore point objectives that clearly explain how much data might be lost in the outage, if any. The disaster recovery plan also includes a detailed recovery workflow for restoring services and data if a multi-availability zone failure.\n* It must confirm how the Maximum Tolerable Downtime is met and be stored on the Disaster Recovery Plan database.\n* The disaster recovery plan specifies the security controls for running in Disaster mode, if they are different from what's running in production.\n\n\n\n\n\n\n\n Management of the disaster recovery plan \n\nThe requirements that IBM Cloud follows are:\n\n\n\n* The disaster recovery plan must be updated after any major infrastructure change, major application release, and after any test.\n* It must be approved annually.", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-zero-downtime"}, {"document_id": "ibmcld_16670-7352-7811", "score": 13.08625902284866, "text": "\ngosales\".\"order_detail\" AS header\nON details.order_number=header.order_number\nLIMIT 10;\n4. Click the Run on button to run the query.\n5. Select Result set or Details tab to view the combined result. If required, you can save the query.\n6. Click Saved queries to view the saved queries.\n7. Click [Explain](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-tutorial_join_data"}, {"document_id": "ibmcld_09988-1469-3494", "score": 12.63186803918322, "text": "\nGo to Queries > Stored queries.\n2. Select a query.\n3. From the overflow menu, click Remove.\n4. Confirm your choice by clicking Remove again.\n\n\n\n\n\n\n\n\n\n Query history \n\nTo access the page, go to Queries > Query history or select Query history from the home page.\n\nWhen you are on the Query history page, you can do the following:\n\n\n\n* View your data in a table or card view.\n* Export data to export your query history to a data file.\n* Sort any column by placing the cursor on the column header.\n* Find specific queries by using various filtering criteria.\n\nFor example, you can use it to find queries that are submitted by a particular user or group, or queries that run on a particular database.\n* Search the query history but clicking Search. You can use a predefined search criteria, or create a new search option.\n* Select the columns to display in the table.\n\nClick the settings icon next to the Find query history field to edit columns.\n* View metrics, access the explain graph, explain summary, explain verbose, explain distribution pages, and view the plan file and statistics status.\n\n\n\n\n\n Query history columns \n\n\n\n* Start time Specifies the time when the query started.\n* End time Specifies the time when the query finished.\n* Elapsed time Specifies the time that it took the query to run.\n* Query text Specifies the SQL command of the query.\n* Database Specifies the name of the database on which the query ran.\n* Schema Specifies the schema that was used for the query.\n* User name Species the name of the user that ran the query.\n* Group Specifies the group of users from which the query originates.\n* Result rows Specifies the number of result rows that were returned by the query.\n* Prep time Specifies the preparation time that was needed for the query.\n* Status Specifies the completion status of the query.\n* Plan ID Specifies the ID of the system-generated plan for the query.\n* Client IP Specifies the IP of the client that ran the SQL query.\n* GRA time Specifies the time that the query spent at the GRA.", "title": "", "source": "https://cloud.ibm.com/docs/netezza?topic=netezza-queries"}, {"document_id": "ibmcld_09888-10897-12309", "score": 12.301418603752477, "text": "\n* [Connections in C MQI&JMS programs](https://cloud.ibm.com/docs/mqcloud?topic=mqcloud-mqoc_connect_app_ssl)\n\n\n\n\n\n\n\n Enabling TLS between a client and a queue manager \n\nIf TLS security has not been enabled on a queue manager, the following document explains how to correctly configure a queue manager. This walkthrough covers an \"anonymous\" one-way TLS connection as well as a \"mutual\" two-way connection.\n\n\n\n* [Enabling TLS between a client and a queue manager](https://cloud.ibm.com/docs/mqcloud?topic=mqcloud-mqoc_jms_tls)\n\n\n\n\n\n\n\n Advanced Message Security (AMS) \n\nThe following documents explains queue manager advanced message security, and how to enable it, along with application advanced message security.\n\n\n\n* [Enabling queue manager Advanced Message Security (AMS)](https://cloud.ibm.com/docs/mqcloud?topic=mqcloud-mqoc_qm_ams)\n* [Enabling application Advanced Message Security (AMS)](https://cloud.ibm.com/docs/mqcloud?topic=mqcloud-mqoc_app_ams)\n\n\n\nThe queue manager you wish to apply AMS to must not have TLS already enabled on it.\n\n\n\n\n\n Refreshing the queue manager TLS security \n\nA TLS security refresh will be needed if a change has been made to the queue manager key store or trust store, otherwise the change won't take effect. The following document explains this process:\n\n\n\n* [Refreshing the queue manager TLS security](https://cloud.ibm.com/docs/mqcloud?topic=mqcloud-mqoc_refresh_security)", "title": "", "source": "https://cloud.ibm.com/docs/mqcloud?topic=mqcloud-security"}, {"document_id": "ibmcld_00499-6096-7785", "score": 12.20523760180574, "text": "\nIf two or more candidate indexes still exist, the index with the first alphabetical name is chosen.\n* If a json type index and a text type index might both satisfy a selector, the json index is chosen by default.\n* The text type index is chosen when the following conditions are met:\n\n\n\n* A json type index and a text type index exist in the same field (for example fieldone).\n* The selector can be satisfied only by using a text type index.\n\n\n\n\n\nFor example, assume that you have a text type index and a json type index for the field foo, and you want to use a selector similar to the following sample:\n\n{\n\"foo\": {\n\"$in\": [\"red\",\"blue\",\"green\"]\n}\n}\n\nIBM Cloudant Query uses the text type index because a json type index can't satisfy the selector.\n\nHowever, you might use a different selector with the same indexes:\n\n{\n\"foo\": {\n\"$gt\": 2\n}\n}\n\nIn this example, IBM Cloudant Query uses the json type index because both types of indexes can satisfy the selector.\n\nTo identify which index is being used by a particular query, send a POST to the _explain endpoint for the database, with the query as data. The details of the index in use are shown in the index object within the result.\n\nSee the following example that uses HTTP to show how to identify the index that was used to answer a query:\n\nPOST /movies/_explain HTTP/1.1\nHost: $SERVICE_URL\nContent-Type: application/json\n{\n\"selector\": {\n\"$text\": \"Pacino\",\n\"year\": 2010\n}\n}\n\nSee the following example that uses the command line to show how to identify the index that was used to answer a query:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl \"$SERVICE_URL/movies/_explain\" \t-X POST \t-H \"Content-Type: application/json\" \t-d '{\n\"selector\": {", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-selector-expressions"}, {"document_id": "ibmcld_00539-3574-5364", "score": 12.18935346860861, "text": "\nThe [POST /{db}/_explain](https://cloud.ibm.com/apidocs/cloudant?code=javapostexplain) API endpoint when passed a JSON object that is usually sent to the [POST /{db}/_find](https://cloud.ibm.com/apidocs/cloudantpostfind) endpoint, explains how such a query is handled and which indexes, if any, might be used.\n\nIf the index object in the response indicates that \"all_docs\" is being used, a full database scan is required to service the query. We recommend that you use the _explain mechanism to check each IBM Cloudant query to ensure it is using an index before you deploy to production.\n\nFor example, a type=json index on firstname, surname and date is suitable for finding documents for:\n\n\n\n* A known firstname, lastname, and date.\n* A known firstname, lastname, and a range of date values (that use $lt, $lte, $gt, $gte operators).\n* A known firstname and lastname sorted by date.\n\n\n\nIt can also be used to assist queries on firstname, surname, date, and other attributes. In other words, it might be able to answer only part of the query but it can help reduce the number of documents that are scanned to find the answer.\n\n\n\n\n\n How can I ensure that my query is efficent? \n\nIdeally, an IBM Cloudant Query execution would need to scan only one document for each document returned. If a query has to scan a million documents for each one returned, it is clearly not optimal, and is in need of a secondary index to help.\n\nWhen you execute a query, passing execution_stats: true as an extra parameter forces IBM Cloudant to enumerate the number of documents it scanned in performing the query, for example:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\"date\"],\n\"limit\": 10,\n\"execution_stats\": true\n}\n\nThe returned data now includes an extra JSON object:\n\n{\n...", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-using-cloudant-query"}, {"document_id": "ibmcld_02934-31538-33861", "score": 12.017318185192762, "text": "\nFor Not found responses (that are displayed when the user does not provide a valid value), you can choose one of these actions to perform:\n\n\n\n* Wait for user input (Default): Pauses the conversation and your assistant waits for the user to respond. In the simplest case, the text you specify here can more explicitly state the type of information you need the user to provide. If you use this action with a conditional response, be sure to word the conditional response such that you clearly state what was wrong with the user's answer and what you expect them to provide instead.\n* Prompt again: After displaying the Not found response, your assistant repeats the slot prompt again and waits for the user to respond. If you use this action with a conditional response, the response can merely explain what was wrong about the answer the user provided. It does not need to reiterate the type of information you want the user to provide because the slot prompt typically explains that.\n\nIf you choose this option, consider adding at least one variation of the Not found response so that the user does not see the exact same text more than once. Take the opportunity to use different wording to explain to the user what information you need them to provide and in what format.\n* Skip this slot: Instructs your assistant to stop trying to fill the current slot, and instead, move on to the prompt for the next empty slot. This option is useful in a slot where you want to both make the slot optional and to display a prompt that asks the user for information. For example, you might have a @seating entity that captures restaurant seating preferences, such as outside, near the fireplace, private, and so on. You can add a slot that prompts the user with, Do you have any seating preferences? and checks for @seating.values. If a valid response is provided, it saves the preference information to $seating_preferences. However, by choosing this action as the Not found response next step, you instruct your assistant to stop trying to fill this slot if the user does not provide a valid value for it.\n* Skip to response: If, when the condition you define is met, you no longer need to fill any of the remaining slots in this node, choose this action to skip the remaining slots and go directly to the node-level response next.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slots"}, {"document_id": "ibmcld_03249-32329-34629", "score": 12.017318185192762, "text": "\n* Wait for user input (Default): Pauses the conversation and your assistant waits for the user to respond. In the simplest case, the text you specify here can more explicitly state the type of information you need the user to provide. If you use this action with a conditional response, be sure to word the conditional response such that you clearly state what was wrong with the user's answer and what you expect them to provide instead.\n* Prompt again: After displaying the Not found response, your assistant repeats the slot prompt again and waits for the user to respond. If you use this action with a conditional response, the response can merely explain what was wrong about the answer the user provided. It does not need to reiterate the type of information you want the user to provide because the slot prompt typically explains that.\n\nIf you choose this option, consider adding at least one variation of the Not found response so that the user does not see the exact same text more than once. Take the opportunity to use different wording to explain to the user what information you need them to provide and in what format.\n* Skip this slot: Instructs your assistant to stop trying to fill the current slot, and instead, move on to the prompt for the next empty slot. This option is useful in a slot where you want to both make the slot optional and to display a prompt that asks the user for information. For example, you might have a @seating entity that captures restaurant seating preferences, such as outside, near the fireplace, private, and so on. You can add a slot that prompts the user with, Do you have any seating preferences? and checks for @seating.values. If a valid response is provided, it saves the preference information to $seating_preferences. However, by choosing this action as the Not found response next step, you instruct your assistant to stop trying to fill this slot if the user does not provide a valid value for it.\n* Skip to response: If, when the condition you define is met, you no longer need to fill any of the remaining slots in this node, choose this action to skip the remaining slots and go directly to the node-level response next. For example, if after capturing the one-way flight information, the slot prompt is, Are you buying round trip tickets?", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-slots"}, {"document_id": "ibmcld_03354-5778-8129", "score": 11.614948526353576, "text": "\nAny edits you then make within the dialog skill for the Development assistant will only affect the Development assistant's dialog skill, even though you\u2019re using data from messages sent to the Production assistant.\n\nSimilarly, if you create multiple versions of a skill, you might want to use message data from one version to improve the training data of another version.\n\nYou cannot access log data from assistants that were created in other service instances.\n\n\n\n Picking a data source \n\nThe term data source refers to the logs compiled from conversations between customers and the assistant or custom application by which a dialog skill was deployed.\n\nWhen you open the Analytics page, metrics are shown that were generated by user interactions with the current dialog skill. No metrics are shown if the current skill has not been deployed and used by customers.\n\nTo populate the metrics with message data from a dialog skill or skill version that was added to a different assistant or custom application, one that has interacted with customers, complete these steps:\n\n\n\n1. Click the Data source field to see a list of assistants with log data that you might want to use.\n\nThe list includes assistants that have been deployed and to which you have access. Or you can choose to show a list of other deployments. For more information about other types of deployments, see [Show deployment IDs explained](https://cloud.ibm.com/docs/assistant?topic=assistant-logslogs-deployment-id-explained).\n2. Choose a data source.\n\n\n\nStatistical information for the selected data source is displayed.\n\nNotice the list does not include skill versions. To get data that is associated with a specific skill version, you must know the time frame during which a specific skill version was used by a deployed assistant. You can select the assistant as the data source, and then filter the metrics by the appropriate dates to see only log data that was generated by the assistant while it was using the skill version.\n\n\n\n\n\n Show deployment IDs explained \n\nApplications that use the older v1 runtime API must specify a deployment ID in each messages sent using the /message API. This ID identifies the deployed app that the call was made from. The Analytics page can use this deployment ID to retrieve and display logs that are associated with a specific live application.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07191-7-2252", "score": 15.112442575861634, "text": "\nQuery parameters \n\nIBM Watson\u2122 Discovery offers powerful content search capabilities through queries. After your content is uploaded and enriched by Discovery, you can build queries, integrate Discovery into your own projects, or create a custom application by using the Watson Explorer Application Builder. To get started with queries, see [Query concepts](https://cloud.ibm.com/docs/discovery?topic=discovery-query-concepts). For the complete list of parameters, see the [Query reference](https://cloud.ibm.com/docs/discovery?topic=discovery-query-referenceparameter-descriptions).\n\nSearch parameters\n\nSearch parameters enable you to search your collection, identify a result set, and perform analysis on the result set.\n\nThe results set is the group of documents identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is performed, the results set is equal to all the documents in the collection.\n\n\n\n query \n\nA query search returns all documents in your data set with full enrichments and full text in order of relevance. A query also excludes any documents that don't mention the query content. These queries are written using the [Discovery Query Language](https://cloud.ibm.com/docs/discovery?topic=discovery-query-operators).\n\n\n\n\n\n filter \n\nA cacheable query that excludes any documents that don't mention the query content. Filter search results are not returned in order of relevance. These queries are written using the [Discovery Query Language](https://cloud.ibm.com/docs/discovery?topic=discovery-query-operators).\n\n\n\n Differences between the filter and query parameters \n\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-query-parameters"}, {"document_id": "ibmcld_07178-6197-7974", "score": 14.587107471263938, "text": "\n[Example query structure](https://cloud.ibm.com/docs-content/v1/content/ded4adc3ea0bd2a81b113c579f2b1183926da211/discovery/images/query_structure2.png)\n\nOperators that evaluate a field (<= , >=, <, >) require a number or date as the value. Using quotations around a value always makes it a string. Therefore score>=0.5 is a valid query and score>=\"0.5\" is not. See [Query operators](https://cloud.ibm.com/docs/discovery?topic=discovery-query-operators) for a complete list of operators.\n\nConsiderations:\n\n\n\n* Not sure when to query on an entity, concept, or keyword? See [Understanding the difference between Entities, Concepts, and Keywords](https://cloud.ibm.com/docs/discovery?topic=discovery-configserviceudbeck).\n\n\n\nAfter you click Run query and open the JSON tab, query highlighting is turned on, by default. The setting adds a highlight field to your query results. Within the highlight field, the words that match your query are wrapped in HTML <em> (emphasis) tags. For more information, see the [Query parameters](https://cloud.ibm.com/docs/discovery?topic=discovery-query-parametershighlight).\n\n\n\n\n\n\n\n Building combined queries \n\nYou can combine query parameters together to build more targeted queries. For example, you can use the both the filter and query parameters together. For more information about filtering vs. querying, see [Differences between the filter and query parameters](https://cloud.ibm.com/docs/discovery?topic=discovery-query-parametersfiltervquery).\n\n\n\n\n\n How to structure an aggregation \n\nAggregations return a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see [Aggregations](https://cloud.ibm.com/docs/discovery?topic=discovery-query-referenceaggregations).", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-query-concepts"}, {"document_id": "ibmcld_02590-7911-9371", "score": 14.39031812105696, "text": "\nTo prevent [dangerous client bugs and backward-compatibility hazards](https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-robustnesssanitation-and-validation), unrecognized query parameters SHOULD and invalid parameter values MUST result in a 400 status code and appropriate error response model.\n\n\n\n\n\n Case insensitivity \n\nQuery parameter names SHOULD NOT be case-normalized to support case insensitivity; a parameter that does not match the case of a defined parameter but otherwise matches its name SHOULD be treated as any other extraneous input\n\n[4].\n\nHowever, parameter name case normalization MAY be supported for backward compatibility with existing clients.\n\n\n\n\n\n Parameter duplication \n\nRequests that provide a query string with duplicate single-value\n\n[5]query parameters of the same name and differing values[6] MUST result in a 400 status and appropriate error response model. For backward compatibility with existing clients, query strings containing duplicate query parameters of the same name and with the same value MAY be supported [7].\n\nIf a service supports parameter name [case insensitivity](https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-uriscase-insensitivity), parameter names MUST be normalized prior to validating uniqueness.\n\nSupport for array input in query parameters SHOULD use comma-separated values within a single parameter (for example, foo=1,2,3) instead of duplicated\n\n[8]parameters ( foo=1&foo=2&foo=3).", "title": "", "source": "https://cloud.ibm.com/docs/api-handbook?topic=api-handbook-uris"}, {"document_id": "ibmcld_07191-1691-3739", "score": 14.082574994920815, "text": "\nIf you test the same search term on a small data set, you might find that the filter and query parameters return very similar (if not identical) results. However, there is a difference between the two parameters.\n\n\n\n* Using a filter parameter alone returns search results in no specific order.\n* Using a query parameter alone returns search results in order of relevance.\n\n\n\nIn large data sets, if you need results returned in order of relevance, it is advisable that you combine the filter and query parameters because using them together improves performance. The reason is because the filter parameter runs first and caches results, and then the query parameter ranks them. For an example of using filters and queries together, see [Building combined queries](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsbuilding-combined-queries). Filters can also be used in aggregations.\n\nWhen you write a query that includes both a filter, and an aggregation, query, or natural_language_query parameter; the filter parameters run first, after which any aggregation, query, or natural_language_query parameters run in parallel.\n\nWith a simple query, especially on a small data set, filter and query often return the exact same (or similar) results. If a filter and query call return similar results, and getting a response in order of relevance does not matter, it is better to use filter because filter calls are faster and are cached. Caching means that the next time you make that call, you get a much quicker response, particularly in a big data set.\n\n\n\n\n\n\n\n aggregation \n\nAggregation queries return a count of documents matching a set of data values; for example, top keywords, overall sentiment of entities, and more. For the full list of aggregation options, see the [Aggregations table](https://cloud.ibm.com/docs/discovery?topic=discovery-query-aggregations). These aggregations are written using the [Discovery Query Language](https://cloud.ibm.com/docs/discovery?topic=discovery-query-operators).\n\n\n\n\n\n natural_language_query", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-query-parameters"}, {"document_id": "ibmcld_13406-1732-4088", "score": 13.841183085485266, "text": "\nThey can also help you distinguish the absence of results due to\n\n\n\n* Lack of audio.\n* Lack of speech in submitted audio.\n* Engine stalls at the server and network stalls between the client and the server. To differentiate between engine and network stalls, results are periodic rather than event-based.\n\n\n\nThe metrics can also help you estimate response jitter by examining the periodic arrival times. Metrics are generated at a constant interval, so any difference in arrival times is caused by jitter.\n\n\n\n Requesting processing metrics \n\nTo request processing metrics, use the following optional parameters:\n\n\n\n* processing_metrics is a boolean that indicates whether the service is to return processing metrics. Specify true to request the metrics. By default, the service returns no metrics.\n* processing_metrics_interval is a float that specifies the interval in seconds of real wall-clock time at which the service is to return metrics. By default, the service returns metrics once per second. The service ignores this parameter unless the processing_metrics parameter is set to true.\n\nThe parameter accepts a minimum value of 0.1 seconds. The level of precision is not restricted, so you can specify values such as 0.25 and 0.125. The service does not impose a maximum value.\n\n\n\nHow you provide the parameters and how the service returns processing metrics differ by interface:\n\n\n\n* With the WebSocket interface, you specify the parameters with the JSON start message for a speech recognition request. The service calculates and returns metrics in real-time at the requested interval.\n* With the asynchronous HTTP interface, you specify query parameters with a speech recognition request. The service calculates the metrics at the requested interval, but it returns all metrics for the audio with the final transcription results.\n\n\n\nThe service also returns processing metrics for transcription events. If you request interim results with the WebSocket interface, you can receive metrics with greater frequency than the requested interval.\n\nTo receive processing metrics only for transcription events instead of at periodic intervals, set the processing interval to a large number. If the interval is larger than the duration of the audio, the service returns processing metrics only for transcription events.\n\n\n\n\n\n Understanding processing metrics", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metrics"}, {"document_id": "ibmcld_07098-7-2215", "score": 13.576183637052269, "text": "\nQuery parameters \n\nYou can use these parameters when you write queries with the Discovery Query Language. For more information, see the Discovery [API reference](https://cloud.ibm.com/apidocs/discovery-dataquery). For an overview of query concepts, see the [Query overview](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-concepts).\n\nQueries that are written in the Discovery Query Language can include both search and structure parameters.\n\nThe default values for query parameters can differ by project type. For more information about default values, see [Default query settings](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-defaults).\n\n\n\n Search parameters \n\nUse search parameters to search your collection, identify a result set, and analyze the result set.\n\nThe results set is the group of documents that are identified by the combined searches of the search parameters. The results set might be significantly larger than the returned results. If an empty query is submitted, the results set is equal to all the documents in the collection.\n\nDocuments that you do not have permissions to access are not returned in query results.\n\n\n\n\n\n Answer finding \n\nIBM Cloud\n\nThe find_answers parameter is supported in managed deployments only.\n\nBy default, Discovery provides answers by returning the entire [passage](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parameterspassages) that contains the answer to a natural language query. When the answer-finding feature is enabled, Discovery also provides a \"short answer\" within the passage, and a confidence score to show whether the \"short answer\" answers the question that is explicit or implicit in the user query. Applications that use the answer-finding feature can display the short answer alone or can display the short answer emphasized in the context of the full passage. For most applications, displaying the short answer emphasized within the full passage is preferable, because answers generally make more sense in context.\n\nThe answer finding feature behaves in the following ways:\n\nIn the passage examples that follow, the short answers are shown in bold font.\n\n\n\n* Finds answers.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parameters"}, {"document_id": "ibmcld_07067-26099-28206", "score": 13.305914496840167, "text": "\nIf false, ranks the passages from all of the documents by passage quality regardless of the document quality and returns them in a separate passages field in the response.\n* When passages are returned for a query, you can also enable answer finding. When true, answer objects are returned as part of each passage in the query results. When find_answers and per_document are both set to true, the document search results and the passage search results within each document are reordered by using the answer confidences. The goal of this reordering is to place the best answer as the first answer of the first passage of the first document. Similarly, if the find_answers parameter is set to true and per_document parameter is set to false, then the passage search results are reordered in decreasing order of the highest confidence answer for each document and passage.\n* Both v1 and v2 support custom stop words. However, there are a few differences in how custom stop words are used:\n\n\n\n* There is no default custom stop words list for Japanese collections in v2.\n* When you define custom stop words in v1, your stop words list replaces the existing stop words list. In v2, your list augments the default list. You cannot replace the list, which means you cannot remove stop words that are part of the default list in v2.\n\n\n\n\n\n\n\n Update how your application handles query results \n\nThe way that your application shows query results might need to be updated due to the following differences between the query results document syntax between the v1 and v2 queries:\n\n\n\n* At the entity enrichment level, the following information is not supported in v2:\n\n\n\n* Disambiguation\n* Emotion\n* Sentiment\n\n\n\nThe Part of Speech enrichment is applied automatically to documents in most project types in v2, but the index fields that are generated by the enrichment are not displayed in the JSON representation of the document.\n\nZoom\n\n![Difference in entities data structure](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/discovery-data/images/compare-result-syntax.png)\n\nFigure 1.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2"}, {"document_id": "ibmcld_13446-15041-17074", "score": 13.15047452859988, "text": "\nAvailability and usage Description \n\n Previous-generation models Not available. \n Next-generation models Generally available or beta for next-generation models that support low latency. For more information, see [Supported next-generation language models](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-models-ngmodels-ng-supported). \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST /v1/recognize method \n Asynchronous HTTP Query parameter of POST /v1/recognitions method \n\n\n\n\n\n\n\n max_alternatives \n\nAn optional integer that specifies the maximum number of alternative hypotheses that the service returns. By default, the service returns a single final hypothesis. For more information, see [Maximum alternatives](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-metadatamax-alternatives).\n\n\n\nTable 17. The max_alternatives parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Parameter of JSON start message \n Synchronous HTTP Query parameter of POST /v1/recognize method \n Asynchronous HTTP Query parameter of POST /v1/recognitions method \n\n\n\n\n\n\n\n model \n\nAn optional model that specifies the language in which the audio is spoken and the rate at which it was sampled: broadband/multimedia or narrowband/telephony. By default, en-US_BroadbandModel is used. For more information, see [Using a model for speech recognition](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-models-use).\n\n\n\nTable 18. The model parameter\n\n Availability and usage Description \n\n Previous-generation models Generally available for all languages. \n Next-generation models Generally available for all languages. \n WebSocket Query parameter of /v1/recognize connection request \n Synchronous HTTP Query parameter of POST /v1/recognize method \n Asynchronous HTTP Query parameter of POST /v1/recognitions method \n\n\n\n\n\n\n\n processing_metrics", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-summary"}, {"document_id": "ibmcld_03285-5746-7932", "score": 13.026052717373895, "text": "\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https://cloud.ibm.com/apidocs/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions"}, {"document_id": "ibmcld_16321-5729-7915", "score": 13.026052717373895, "text": "\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https://cloud.ibm.com/apidocs/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16365-12876-14604", "score": 38.20878885173021, "text": "\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https://web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https://integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https://cloud.ibm.com/docs/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_16295-7-1721", "score": 37.61700388509601, "text": "\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat"}, {"document_id": "ibmcld_16374-0-2178", "score": 36.06853412124076, "text": "\n\n\n\n\n\n\n  Supporting global audiences \n\nYou can build an assistant that understands customer messages in any of the languages that are supported by the service. The responses from your assistant are defined by you and can be written in any language you want.\n\nHowever, some of the phrases that are displayed in the web chat widget are part of the web chat itself and do not come from the assistant. By default, these hardcoded phrases are specified in English, but you can apply a different language by adding lines to the embedded web chat script.\n\nThe hardcoded phrases used by the web chat widget are specified in language pack files. The web chat provides language packs that contain translations of each English-language phrase that is used by the web chat. You can instruct the web chat to use one of these other languages files by using the instance.updateLanguagePack() method.\n\nLikewise, the web chat applies an American English locale to content that is added by the web chat unless you specify something else. The locale setting affects how values such as dates and times are formatted.\n\nTo configure the web chat for customers outside the US, follow these steps:\n\n\n\n1.  To apply the appropriate syntax to dates and times and to use a translation of the English-language phrases, set the locale. Use the instance.updateLocale() method.\n\nFor example, if you apply the Spanish locale (es), the web chat uses Spanish-language phrases that are listed in the es.json file, and uses the DD-MM-YYYY format for dates instead of MM-DD-YYYY.\n\nThe locale you specify for the web chat does not impact the syntax of dates and times that are returned by the underlying skill.\n2.  To change only the language of the hardcoded English phrases, use the instance.updateLanguagePack() method.\n\nFor more information, see [Instance methods](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslanguages).\n3.  To change the text direction of the page from right to left, use the direction method. For more information, see [Configuration](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-global"}, {"document_id": "ibmcld_16366-1573-3444", "score": 35.38590985672727, "text": "\nOn the ![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)Integrations page, find the Web chat tile and click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\n\n\n\n\n Setup tasks \n\nYou can configure the web chat in the following ways:\n\nStyle and appearance\n: You can configure the overall appearance of the web chat widget, including the assistant name, the colors of various elements, and the avatar image. For more information, see [Configuring style and appearance](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-style).\n\nLauncher\n: You can change the greeting text that is shown by the launcher that invites users to open the web chat. On the Launcher tab, you can specify separate greeting messages for the desktop launcher and the mobile launcher.\n\nThe message you specify is immediately reflected by the launcher preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\nHome screen\n: You can configure the contents of the home screen that greets customers and helps them start the conversation. For more information, see [Configuring the home screen](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen).\n\nSuggestions\n: You can configure how and when the web chat offers offers suggestions to customers when the assistant isn't delivering what they expect. For more information, see [Configuring suggestions](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-suggestions).\n\nSecurity", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config"}, {"document_id": "ibmcld_16368-7-2072", "score": 35.252655894636284, "text": "\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_03080-7-1901", "score": 35.0326980415013, "text": "\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-config"}, {"document_id": "ibmcld_03421-4-1877", "score": 34.948533110911775, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_03421-1518-3290", "score": 34.83074661386324, "text": "\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_03422-13387-15045", "score": 34.7638612840062, "text": "\nconnect-src *.watsonplatform.net *.watson.appdomain.cloud \n\n\n\nThe following example shows a complete CSP metadata tag:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline';connect-src .watsonplatform.net .watson.appdomain.cloud\" />\n\n\n\n Allowing elements \n\nIf your CSP uses a nonce to add elements, such as <script> and <style> tags, to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta http-equiv=\"Content-Security-Policy\" content=\"default-src 'self' *.watson.appdomain.cloud fonts.gstatic.com 'nonce- ';connect-src *.watsonplatform.net *.watson.appdomain.cloud\"\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Security measures \n\nThe web chat integration undergoes tests and scans on a regular basis to find and address potential security issues, such as cross-site scripting (XSS) vulnerabilities.\n\nBe sure to run your own security reviews to see how the web chat fits in with your current website structure and policies. The web chat is hosted on your site and can inherit any vulnerabilities that your site has.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-security"}, {"document_id": "ibmcld_16334-24425-26157", "score": 34.656198130870365, "text": "\n(For more information about this feature, see the launcherBeta configuration option at [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).)\n\n\n\n\n\n\n\n 4.5.0 \n\nRelease date: 29 July 2021\n\n\n\n* A new scrollToMessage method is available for scrolling the web chat view to a specified message in the chat history. For more information, see [instance.scrollToMessage()](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsscrollToMessage).\n* A new pre:open event is available. This event is fired when the web chat window is opened, but before the welcome message or chat history are loaded. For more information, see [window:pre:open](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-eventswindowpreopen).\n* A new chat history widget is available for embedding in service desk agent UIs. This new widget is based on a read-only view of the standard web chat widget. For information about using the new chat history widget in integrations built using the starter kit, see [Embedded agent application](https://github.com/watson-developer-cloud/assistant-web-chat-service-desk-starter/blob/main/docs/AGENT_APP.md).\n\n\n\n\n\n\n\n 4.4.1 \n\nRelease date: 6 July 2021\n\n\n\n* Bug fixes.\n\n\n\n\n\n\n\n 4.4.0 \n\nRelease date: 25 June 2021\n\n\n\n* Bug fixes.\n\n\n\n\n\n\n\n 4.3.0 \n\nRelease date: 7 June 2021\n\n\n\n* Search suggestions: If a search skill is configured for your assistant, the suggestions include a new View related content section. This section contains search results that are relevant to the user input.\n* Focus trap: A new enableFocusTrap option enables maintaining focus inside the web chat widget while it is open.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-release-notes-chat"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03966-3327-5475", "score": 19.264394733911526, "text": "\n* Org admins: When you join a consortium that is hosted by an ordering service, you provide the signing certificates of identities that will become the administrators for your organization. You can use these identities to create or edit channels.\n* Peer or orderer admins: IBM Blockchain Platform nodes are deployed with the signing certificates of component administrators identities inside of them. These certificates allow the admins to operate the component from a remote client or by using the console.\n* Applications: Your applications need to sign their transactions before submitting them to be validated by the network. You need to create identities you can use to sign transactions from your client applications.\n\n\n\nYou can use the console to create these identities by using the [registration process](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-identitiesibp-console-identities-register). After you register your admin identities, you need to issue each identity a signing certificate and private key, provide the signing certificate to your organization MSP definition, and add the identity to your console wallet. You can complete these steps for one admin identity when you [create your organization MSP](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-organizationsconsole-organizations-create-msp). You can use separate identities as org admins or node admins, or you can use one identity to do both tasks. The [Build a network tutorial](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-build-networkibp-console-build-network) uses one identity to be an admin for each organization created in the tutorial.\n\n\n\n\n\n Associating the identity of the CA admin \n\nBefore you can create identities, you need to associate the identity of the CA admin. Open your CA on the Nodes tab. If you are using the CA for the first time, you can click the Associate identity button to generate the CA admin identity and import it into your console wallet. On the Associate identity side panel, provide the Enroll ID and Enroll secret of the CA admin that you provided when you created the CA.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-identities"}, {"document_id": "ibmcld_03893-74275-75877", "score": 18.881611412222668, "text": "\nConfigure an HSM client image[See Build a Docker image](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-hsm-build-docker).\n3. Configure the node to use HSM. From the APIs or the console, when you deploy a peer, CA, or ordering node, you can select the advanced option to use an HSM. See [Configure the node to use the HSM](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-cfg-hsm-node).\n\n\n\n\n\n\n\n Before you begin \n\n\n\n* The Kubernetes CLI is required to configure the HSM. If you are using a Kubernetes cluster on IBM Cloud see [Getting started with IBM Cloud CLI](https://cloud.ibm.com/docs/cli?topic=cli-getting-started) or [Installing the OpenShift CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-cli).\n* You need access to a container registry, such as Docker or the [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-started).\n\n\n\n\n\n\n\n Build a Docker image \n\nConfigure HSM on your blockchain network by publishing an HSM client image to a container registry, as described below.\n\nBuild an HSM client image\n\nNext we build a Docker file that contains the HSM client image. These instructions assume that you have successfully configured your HSM appliance and HSM client. Use these steps to generate an image that is consumable by the IBM Blockchain Platform operator.\n\n\n\n* Step one: Modify the HSM client configuration.\n* Step two: Build the HSM client image.\n* Step three: Push the Docker image to your container registry.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-adv-deployment"}, {"document_id": "ibmcld_16281-0-376", "score": 18.844001923874444, "text": "\n\n\n\n\n\n\n  Integrating with a custom client app \n\nIBM Cloud\n\nIf the available integration channels do not meet your needs, you can build your own client application as the interface between the assistant and your customers.\n\nFor more information, see [Building a custom client using the API](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-client).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-custom-app"}, {"document_id": "ibmcld_02998-8791-9815", "score": 18.520477554929627, "text": "\nYou created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:\n\n\n\n* Add standard nodes with the [Building a complex dialog](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial) tutorial.\n* Learn about slots with the [Adding a node with slots](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial-slots) tutorial.\n\n\n\n* Check out more [sample apps](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-sample-apps) to get ideas.\n\n\n\nWhen you're ready to deploy your assistant, see [Deploying](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-custom-app).", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started"}, {"document_id": "ibmcld_03982-9793-12132", "score": 18.11603474289884, "text": "\nBecause an MSP is the representation of an organization in the network, you select the MSP definition when you deploy your nodes (identifying the organization the node belongs to), are joined to the consortium (by an ordering service admin), create a channel, join a channel, edit a channel, or perform any action where you have to specify the organization that is performing the action.\n\n\n\n\n\n Downloading a connection profile \n\nAfter you create an organization MSP definition and create peers with that organization MSP definition, you can download a connection profile that can be used by a client application to connect to your network via one or more gateway peers. The gateway peers are the peers that are specified in the connection profile, and they are used to perform service discovery to find all of the endorsing peers in the network that will endorse transactions.\n\nClick the Organization MSP tile for the organization that your client application interacts with. Click Create connection profile to open a side panel where you can build and download your connection profile.\n\n![Create connection profile panel](https://cloud.ibm.com/docs-content/v1/content/c5288bed34c3820e3a5251d820ee91adcd2591a3/blockchain/images/create-connx-profile.png)\n\nIf you plan to use the client application to register and enroll users with the organization CA, you need to include the Certificate Authority in the connection profile definition.\n\nSelect the peers to include in the connection profile definition. When a peer is not available to process requests from a client application, service discovery ensures that the request is automatically sent to a different peer. Therefore, to accommodate for peer downtime during a maintenance cycle for example, it is recommended that you select more than one peer for redundancy. In addition to peers created by using the console or APIs, imported peers that have been imported into the console are eligible to be selected as well.\n\nThe list of channels that the selected peers have joined is also provided for your information. If a channel is missing from the list, it is likely because the peer joined to it is currently unavailable.\n\nYou can then download the connection profile to your local file system and use it with your client application to generate certificates and invoke smart contracts.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-organizations"}, {"document_id": "ibmcld_05070-7-1814", "score": 17.805974926943897, "text": "\nUsing Node.js \n\nThe IBM Cloud\u00ae Object Storage SDK for Node.js provides modern capabilities that make the most of IBM Cloud Object Storage.\n\n\n\n Installing the SDK \n\n[Node.js](https://cloud.ibm.com/docs/node?topic=node-getting-started) is an excellent way to build [web applications](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-mean-stack), and customize your instance of Object Storage for your end users. The preferred way to install the Object Storage SDK for Node.js is to use the [npm](https://www.npmjs.com) package manager for Node.js. Type the following command into a command line:\n\nnpm install ibm-cos-sdk\n\nTo download the SDK directly, the source code is hosted on [GitHub](https://github.com/IBM/ibm-cos-sdk-js).\n\nMore detail on individual methods and classes can be found in [the API documentation for the SDK](https://ibm.github.io/ibm-cos-sdk-js/).\n\n\n\n\n\n Getting Started \n\n\n\n Minimum requirements \n\nTo run the SDK, you need Node 4.x+.\n\n\n\n\n\n Creating a client and sourcing credentials \n\nTo connect to COS, a client is created and configured by providing credential information (API Key, Service Instance ID, and IBM Authentication Endpoint). These values can also be automatically sourced from a credentials file or from environment variables.\n\nAfter generating a [Service Credential](https://cloud.ibm.com/docs/services/cloud-object-storage/iam?topic=cloud-object-storage-service-credentials), the resulting JSON document can be saved to /.bluemix/cos_credentials. The SDK will automatically source credentials from this file unless other credentials are explicitly set during client creation. If the cos_credentials file contains HMAC keys the client authenticates with a signature, otherwise the client uses the provided API key to authenticate with a bearer token.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-node"}, {"document_id": "ibmcld_02680-7025-8620", "score": 17.7761153441287, "text": "\nproperty.getCurrentValue(entityId, entityAttributes); // returns the stringified yaml (check above Table 1)\n\n\n\n* Force fetch the configurations from server.\n\nappConfiguration.fetchConfigurations()\n\n\n\n\n\n\n\n\n\n\n\n Integrating client SDK for Android app written in Java \n\nApp Configuration service provides Android client SDK to integrate with your Android application. You can evaluate the values of your property and feature flag by integrating the SDK.\n\n\n\n1. Install the SDK by using either one of the options:\n\n\n\n* [Download](https://github.com/IBM/appconfiguration-android-client-sdk) and import the package to your Android studio project.\n* Get the package through Gradle by adding:\n\n\n\n* Add App Configuration Android client SDK dependency to Project level build.gradle file.\n\nrepositories {\nmavenCentral()\n}\n* Add App Configuration Android client SDK dependency to Module level build.gradle file.\n\ndependencies {\nimplementation \"com.ibm.cloud:appconfiguration-android-sdk:0.3.1\"\n}\n\n\n\n\n\n2. Configure the AndroidManifest.xml file for internet permission.\n\n<uses-permission android:name=\"android.permission.INTERNET\"/>\n3. Integrate Kotlin to your Java project with these steps:\n\n\n\n* Add the Kotlin Gradle plug-in to the Module level build.gradle\n\ndependencies {\nclasspath \"com.android.tools.build:gradle:4.1.1\"\nclasspath \"org.jetbrains.kotlin:kotlin-gradle-plugin:$kotlin_version\"\n}\n* Add kotlin-android plugin to the App level build.gradle\n\nplugins {\nid 'com.android.application'\nid 'kotlin-android'\n}\n\n\n\n4. Initialize the SDK.\n\nAppConfiguration appConfiguration = AppConfiguration.getInstance();", "title": "", "source": "https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-integrate-sdks-android"}, {"document_id": "ibmcld_03916-19063-21128", "score": 17.741417715129373, "text": "\nIf you manually built your organization MSP with certificates from an external CA, the connection profile will not include any information in the \"certificateAuthorities\": section.\n\n\n\n\n\n Service discovery \n\nService discovery allows your applications to dynamically find the peer and ordering endpoints of your network. If you do not use service discovery, you need to manually add the endpoint information of peer and ordering nodes on your channel to your connection profile or your application. You would need to edit your connection profile or update your application each time a node is added or removed from your network.\n\nBefore you can take advantage of the [Service Discovery](https://hyperledger-fabric.readthedocs.io/en/release-2.2/discovery-overview.html) feature of Hyperledger Fabric, you must configure anchor peers on the channel. Service discovery allows your application to learn which peers on the channel outside your organization need to endorse a transaction. Without service discovery, you will need to get the endpoint information of these peers out of band from other organizations and add them to your connection profile. For more information, see [Configuring anchor peers](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-governibp-console-govern-channels-anchor-peers).\n\nLater in this topic, we use the connection profile to build a Fabric gateway that is configured for [service discovery](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-appibp-console-app-sd-cfg).\n\n\n\n\n\n Enrolling by using the SDK \n\nOnce the network operator provides the enroll ID and secret of the application identity and the network connection profile, an application developer can use the Fabric SDKs or the Fabric CA client to generate client-side certificates. You can use the following steps to enroll an application identity by using the [Fabric SDK for Node.js](https://hyperledger.github.io/fabric-sdk-node/release-2.2/index.html).\n\n\n\n1. Save the connection profile to your local system and rename it connection.json.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-app"}, {"document_id": "ibmcld_02998-7662-9256", "score": 17.402907924455704, "text": "\n[An ending node was added to the dialog also.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-ending-node-added.png)\n\n\n\n\n\n Testing intent recognition \n\nYou built a simple dialog to recognize and respond to both greeting and ending inputs. Let's see how well it works.\n\n\n\n1. Click the ![Try it](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/try-it.png) icon to open the Try it out pane. There's that reassuring welcome message.\n2. In the text field, type Hello and press Enter. The output indicates that the General_Greetings intent was recognized, and the appropriate response (Good day to you.) is displayed.\n3. Try the following input:\n\n\n\n* bye\n* howdy\n* see ya\n* good morning\n* sayonara\n\n\n\n\n\nWatson can recognize your intents even when your input doesn't exactly match the examples that you included. The dialog uses intents to identify the purpose of the user's input regardless of the precise wording used, and then responds in the way you specify.\n\n\n\n\n\n Result of building a dialog \n\nThat's it. You created a simple conversation with two intents and a dialog to recognize them.\n\n\n\n\n\n\n\n Next steps \n\nThis tutorial is built around a simple example. For a real application, you need to define some more interesting intents, some entities, and a more complex dialog that uses them both. When you have a polished version of the assistant, you can make API calls to it from your client application.\n\n\n\n* Complete follow-on tutorials that build more advanced dialogs:", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started"}, {"document_id": "ibmcld_03916-39203-41294", "score": 17.254670131465925, "text": "\nSuccessfully enrolled client \"user1\" and imported it into the wallet\n\nYou can find the wallet that was created in the identity folder of the magnetocorp directory.\n\n\n\n\n\n Step four: Use the connection profile to build a Fabric gateway \n\nThe Hyperledger Fabric [Transaction Flow](https://hyperledger-fabric.readthedocs.io/en/release-2.2/txflow.html) spans multiple components, with the client applications playing a unique role. Your application needs to connect to the peers that need to endorse the transaction and needs to connect to the ordering service that will order the transaction and add it into a block. You can provide the endpoints of these nodes to your application by using your connection profile to construct a Fabric gateway. The gateway then conducts the low-level interactions with your Fabric network. To learn more, visit the [Fabric gateway](https://hyperledger-fabric.readthedocs.io/en/release-2.2/developapps/gateway.html) topic in the Fabric documentation.\n\nYou have already downloaded your connection profile and used it to connect to your organization's Certificate Authority. Now we use the connection profile to build a gateway.\n\nOpen the file issue.js in a text editor. Before you edit the file, notice that it imports the FileSystemWallet and Gateway classes from fabric-network library.\n\nconst { FileSystemWallet, Gateway } = require('fabric-network')\n\nYou will need to import the path class to build the gateway from the connection profile you downloaded from your console. Add the following line to the file to import the path class:\n\nconst path = require('path');\n\nThe Gateway class is used to construct a gateway that you will use to submit your transaction.\n\nconst gateway = new Gateway()\n\nThe FileSystemWallet class is used to load the wallet you created in the previous step. Edit the following line if you changed the location of the wallet on your file system.\n\nconst wallet = new FileSystemWallet('../identity/user/isabella/wallet');\n\nAfter you import your wallet, use the following code to pass your connection profile and wallet to the new gateway.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-app"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00007-7-2159", "score": 18.422562375976398, "text": "\nGetting started tutorial \n\nIBM Analytics Engine Serverless instance is allocated to compute and memory resources on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n\n\n\n* [Serverless instance architecture and concepts](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts)\n* [Provisioning a serverless instance](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n Getting started using serverless IBM Analytics Engine instances \n\nThe IBM Analytics Engine Standard Serverless plan for Apache Spark offers the ability to spin up IBM Analytics Engine serverless instances within seconds, customize them with library packages of your choice, and run your Spark workloads.\n\nCurrently, you can create IBM Analytics Engine serverless instances only in the US South region.\n\n\n\n\n\n Before you begin \n\nTo start running Spark applications in IBM Analytics Engine, you need:\n\n\n\n* An IBM Cloud\u00ae account.\n* Instance home storage in IBM Cloud Object Storage that is referenced from the IBM Analytics Engine instance. This storage is used to store Spark History events, which are created by your applications and any custom library sets, which need to be made available to your Spark applications.\n* An IBM Analytics Engine serverless instance.\n\n\n\n\n\n\n\n Provision an instance and create a cluster \n\nTo provision an IBM Analytics Engine instance:\n\n\n\n1. Get a basic understanding of the architecture and key concepts. See [Serverless instance architecture and concepts](https://cloud.ibm.com/docs/analyticsengine?-serverless-architecture-concepts).\n2. [Provision a serverless instance](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n\n\n Run applications \n\nTo run Spark applications in a serverless IBM Analytics Engine instance:\n\n\n\n1. Optionally, give users access to the provisioned instance to enable collaboration.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine"}, {"document_id": "ibmcld_00033-7-2292", "score": 18.11631642570071, "text": "\nFAQs \n\n\n\n What is IBM Analytics Engine serverless? \n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n\n\n\n\n\n What are the advantages of IBM Analytics Engine serverless instances? \n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n\n\n\n\n\n Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop? \n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n\n\n\n\n\n Can I change the instance home storage of a serverless instance? \n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n\n\n\n\n\n How is user management and access control managed in a serverless instance? \n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n\n\n\n\n\n How do I define the size of the cluster to run my Spark application? \n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-faqs-serverless"}, {"document_id": "ibmcld_07578-107943-110247", "score": 18.062634717838428, "text": "\n* Port 8443 Knox\n* Port 22 SSH\n* Port 9443 Ambari\n\n\n\n* What is IBM Analytics Engine serverless?\n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n* What are the advantages of IBM Analytics Engine serverless instances?\n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n* Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop?\n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n* Can I change the instance home storage of a serverless instance?\n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n* How is user management and access control managed in a serverless instance?\n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n* How do I define the size of the cluster to run my Spark application?\n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-107922-110226", "score": 18.062634717838428, "text": "\n* Port 8443 Knox\n* Port 22 SSH\n* Port 9443 Ambari\n\n\n\n* What is IBM Analytics Engine serverless?\n\nThe IBM Analytics Engine Standard serverless plan for Apache Spark offers a new consumption model using Apache Spark. An Analytics Engine serverless instance does not consume any resources when no workloads are running. When you submit Spark applications, Spark clusters are created in seconds and are spun down as soon as the applications finish running. You can develop and deploy Spark SQL, data transformation, data science, or machine learning jobs using the Spark application API.\n* What are the advantages of IBM Analytics Engine serverless instances?\n\nWith IBM Analytics Engine serverless, compute and memory resources are allocated on demand when Spark workloads are deployed. When an application is not in running state, no computing resources are allocated to the IBM Analytics Engine serverless instance. Pricing is based on the actual amount of resources consumed by the instance, billed on a per second basis.\n* Does the IBM Analytics Engine Standard serverless plan for Apache Spark support Hadoop?\n\nNo, currently, the IBM Analytics Engine Standard serverless plan for Apache Spark only supports Apache Spark.\n* Can I change the instance home storage of a serverless instance?\n\nNo, you can't. After an instance home storage is associated with an IBM Analytics Engine serverless instance, it cannot be changed because instance home contains all instance relevant data, such as the Spark events and custom libraries. Changing instance home would result in the loss of the Spark history data and custom libraries.\n* How is user management and access control managed in a serverless instance?\n\nUser management and access control of an IBM Analytics Engine serverless instance and its APIs is done through IBM Cloud\u00ae Identity and Access Management (IAM). You use IAM access policies to invite users to collaborate on your instance and grant them the necessary privileges. See [Granting permissions to users](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n* How do I define the size of the cluster to run my Spark application?\n\nYou can specify the size of the cluster either at the time the instance is created or when submitting Spark applications.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_00007-1713-3490", "score": 17.744450200438322, "text": "\nSee [Serverless instance architecture and concepts](https://cloud.ibm.com/docs/analyticsengine?-serverless-architecture-concepts).\n2. [Provision a serverless instance](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless)\n\n\n\n\n\n\n\n Run applications \n\nTo run Spark applications in a serverless IBM Analytics Engine instance:\n\n\n\n1. Optionally, give users access to the provisioned instance to enable collaboration. See [Managing user access to share instances](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-grant-permissions-serverless).\n2. Optionally, customize the instance to fit the requirements of your applications. See [Customizing the instance](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-cust-instance).\n3. Submit your Spark application by using the Spark application REST API. See [Running Spark batch applications](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-spark-batch-serverless).\n4. Submit your Spark application by using the Livy batch API. See [Running Spark batch applications using the Livy API](https://cloud.ibm.com/docs/analyticsengine?topic=AnalyticsEngine-livy-api-serverless).\n\n\n\n\n\n\n\n End-to-end scenario using the Analytics Engine serverless CLI \n\nTo help you get started quickly and simply with provisioning an Analytics Engine instance and submitting Spark applications, you can use the Analytics Engine serverless CLI.\n\nFor an end-to-end scenario of the steps you need to take, from creating the services that are required, to submitting and managing your Spark applications by using the Analytics Engine CLI, see [Create service instances and submit applications using the CLI](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-using-cli).", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine"}, {"document_id": "ibmcld_00055-7-1864", "score": 17.010561474090228, "text": "\nProvisioning an IBM Analytics Engine serverless instance \n\nYou can create a serverless IBM Analytics Engine service instance:\n\n\n\n* [Using the IBM Cloud console](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlessconsole-provisioning)\n* [Using the IBM Cloud command-line interface](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlesscli-provisioning)\n* [Using the Resource Controller REST API](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverlessrest-api-provisioning)\n\n\n\nNote that you are not able to define certain limitation and quota settings while provisioning a serverless instance. These values are predefined. See [Limits and quotas for Analytics Engine instances](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-limits) for a list of these settings and their values.\n\nYou must have access to either the IBM Cloud\u00ae us-south (Dallas) or the eu-de (Frankurt) region.\n\n\n\n Creating a service instance from the IBM Cloud console \n\nYou can create an instance using the IBM Cloud console. To understand the concepts behind provisioning settings in the UI, see [Architecture and concepts in serverless instances](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts).\n\nTo create an IBM Analytics Engine instance:\n\n\n\n1. Log into the [IBM Cloud\u00ae console](https://cloud.ibm.com/catalog).\n2. Click Sevices and select the category Analytics.\n3. Search for Analytics Engine and then click on the tile to open the service instance creation page.\n4. Choose the location in which you want the service instance to be deployed. Currently, us-south and eu-de are the only supported regions.\n5. Select a plan. Currently, Standard Serverless for Apache Spark is the only supported serverless plan.\n6.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless"}, {"document_id": "ibmcld_00052-7-2119", "score": 16.98190031413592, "text": "\nManaging serverless instances using the IBM Cloud console \n\nYou can manage your severless instance by:\n\n\n\n* Changing configuration settings, for example, to include library add-ons or to configure instance home after you created the instance.\n* Monitoring the status of submitted applications and kernels created in the instance.\n\n\n\n\n\n Console configuration tab \n\nYou can view and edit the current configuration settings for your IBM Analytics Engine serverless instance from the IBM Cloud\u00ae Resource list.\n\n\n\n1. Access the [IBM Cloud\u00ae Resource list](https://test.cloud.ibm.com/resources).\n2. Click Services and software, find your IBM Analytics Engine serverless instance and click the instance to see the details.\n3. Click Manage > Configuration to view:\n\n\n\n* The runtime. Currently, you can only select the Default Spark runtime which includes the geospatial, data skipping and Parquet encryption packages.\n* The instance home volume to add an instance home or change the access credentials of an existing instance home\n\n\n\n* You can set instance home after you created your IBM Analytics Engine serverless instance. Instance home must be associated with an IBM Cloud Object Storage instance. You can choose an instance:\n\n\n\n* In your account by selecting it from the list\n* From another account. For this instance, you need to enter:\n\n\n\n* The GUID of the IBM Cloud Object Storage instance\n* The endpoint\n* The region\n* The HMAC access and secret key\n\n\n\n\n\n* You can change the access credentials of an existing instance home volume. For this instance, you need to enter:\n\n\n\n* The new HMAC access and secret key\n\n\n\n\n\nFor details on how to access Object Storage, see [Using IBM Object Storage as the instance home volume](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-cos-serverless).\n* The default Spark configuration options to override configuration settings.\n\nFor a list of the default Spark configurations set for serverless instances, see [Default Spark configurations](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-conceptsdefault-spark-config).", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-manage-serverless-console"}, {"document_id": "ibmcld_00064-7-2200", "score": 16.906645655313646, "text": "\nArchitecture and concepts in serverless instances \n\nThis topic shows you the architecture of IBM Analytics Engine serverless instances and describes some key concepts and definitions.\n\n\n\n Instance architecture \n\nThe IBM Analytics Engine service is managed by using IBM Cloud\u00ae Identity and Access Management (IAM). As an IBM Cloud account owner, you are assigned the account administrator role.\n\nWith an IBM Cloud account, you can provision and manage your serverless Analytics Engine instance by using the:\n\n\n\n* IBM Cloud console\n* CLI\n* REST API\n\n\n\nThe Analytics Engine microservices in the control plane, accessed through an API gateway handle instance creation, capacity provisioning, customization and runtime management while your Spark applications run in isolated namespaces in the data plane. Each Spark application that you submit runs in its own Spark cluster, which is a combination of Spark master and executor nodes. See [Isolation and network access](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-security-model-serverlessisolation-network-access).\n\nEach Analytics Engine instance is associated with an IBM Cloud Object Storage instance for instance related data that is accessible by all applications that run in the instance. Currently, all Spark events are stored in this instance as well. Spark application logs are aggregated to a Log Analysis log server.\n\nZoom\n\n![Shows the IBM Analytics Engine serverless instance architecture.](https://cloud.ibm.com/docs-content/v1/content/cd4be197c8921ed12923aa899ac93a8ab643c158/AnalyticsEngine/images/AE-serverless-architecture.svg)\n\nFigure 1. Architecture flow diagram of IBM Analytics Engine\n\n\n\n\n\n Key concepts \n\nWith IBM Analytics Engine serverless instances, you can spin up Apache Spark clusters as needed and customize the Spark runtime and default Spark configuration options.\n\nThe following sections describe key concepts when provisioning serverless instances.\n\n\n\n IBM Analytics Engine service instance \n\nAn IBM Cloud\u00ae service is cloud extension that provides ready-for-use functionality, such as database, messaging, and web software for running code, or application management or monitoring capabilities.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts"}, {"document_id": "ibmcld_16642-2829-4672", "score": 16.77423549970289, "text": "\nibmcloud login\n\nParameter value:\n\n\n\n* DOMAIN_NAME: The API endpoint for your region. For example, cloud.ibm.com\n\n\n\n3. Get the list of the resource groups for your account and select one of the returned resource groups as the target resource group in which to create the IBM Analytics Engine serverless instance:\n\nibmcloud resource groups\nibmcloud target -g <RESOURCE_GROUP_NAME>\n\nParameter value:\n\n\n\n* RESOURCE_GROUP_NAME: Provide the same name as you specified while provisioning watsonx.data for efficient organizing.\n\n\n\n4. Create a service instance:\n\nibmcloud resource service-instance-create <SERVICE_INSTANCE_NAME> ibmanalyticsengine <PLAN_NAME> <REGION> -p @<PATH_to JSON file with cluster parameters>\n\nParameter value:\n\n\n\n* SERVICE_INSTANCE_NAME: Specify a name for the instance.\n* PLAN_NAME: Specify the plan name as plan_name8afde05e-5fd8-4359-a597-946d8432dd45.\n* REGION: Specify the region where you like to provision the instance.\n\n\n\nNote that currently, standard-serverless-spark is the only supported serverless plan and us-south and eu-de the only supported regions. Choose one that is closer to the region where you have provisioned watsonx.data.\n\n\n\n* PATH_to JSON file: Include the path to the JSON file that contains the provisioning parameters.\n\n\n\nFor example, for the Dallas region:\n\nibmcloud resource service-instance-create MyServiceInstance ibmanalyticsengine standard-serverless-spark us-south -p @provision.json\n\nYou can give the service instance any name you choose. Note that currently, standard-serverless-spark is the only supported serverless plan and us-south and eu-de the only supported regions.\n\nThe provision.json file contains the provisioning parameters for the instance that you want to create.\n\nThe endpoint to your IBM Cloud\u00ae Object Storage instance in the payload JSON file must be the direct endpoint.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-lh-provisioning-serverless"}, {"document_id": "ibmcld_00055-2916-4719", "score": 16.750684220977295, "text": "\nSet the API endpoint for your region and log in:\n\nibmcloud api https://cloud.ibm.com\nibmcloud login\n3. Get the list of the resource groups for your account and select one of the returned resource group as the target resource group in which to create the IBM Analytics Engine serverless instance:\n\nibmcloud resource groups\nibmcloud target -g <resource_group_name>\n4. Create a service instance:\n\nibmcloud resource service-instance-create <service_instance_name> ibmanalyticsengine <plan_name> <region> -p @<path_to JSON file with cluster parameters>\n\nFor example, for the Dallas region:\n\nibmcloud resource service-instance-create MyServiceInstance ibmanalyticsengine standard-serverless-spark us-south -p @provision.json\n\nYou can give the service instance any name you choose. Note that currently, standard-serverless-spark is the only supported serverless plan and us-south and eu-de the only supported regions.\n\nThe provision.json file contains the provisioning parameters for the instance you want to create.\n\nThe endpoint to your IBM Cloud Object Storage instance in the payload JSON file should be the direct endpoint. Direct endpoints provide better performance than public endpoints and do not incur charges for any outgoing or incoming bandwidth.\n\nThis is a sample of what the provision.json file can look like. See [Architecture and concepts in serverless instances](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-serverless-architecture-concepts) for a description of the provisioning parameters in the payload.\n\nNote that both Spark 3.1 and Spark 3.3 are supported. If you don't specify a default Spark runtime version when you create a service instance, Spark 3.1 is taken by default.\n\n{\n\"default_runtime\": {\n\"spark_version\": \"3.1\"\n},\n\"instance_home\": {\n\"region\": \"us-south\",", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-provisioning-serverless"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16368-14455-16070", "score": 31.674592107125626, "text": "\nDepending on whether you have enabled security for the web chat, you can use either the [updateUserID](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdateuserid) instance method or the [updateIdentityToken](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdateidentity) method to specify user identity information.\n\nFor more information about how user identity information is specified and how it is used, see [Managing user identity information](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\n\n\n\n\n Security and administration \n\nSecuring the web chat\n: To secure the web chat, you can use JSON Web Token (JWT) to authenticate users and encrypt private data. For more information, see [Securing the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security).\n\nControlling the web chat version\n: The web chat code hosted by IBM Cloud is regularly updated with improvements and new features. By default, the embed script automatically uses the latest version of the web chat. To avoid unexpected changes that might affect your website, you might want to control which version of the web chat your website uses, giving you an opportunity to test each new version before you deploy in in production., in order to avoid unexpected changes when a new version is released.\n\nFor more information about web chat versioning, see [Controlling the web chat version](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-versions).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_16368-13121-14853", "score": 29.87782050311699, "text": "\n[development icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/development-icon.png)Tutorial: For a tutorial showing how to render a custom response type as a replacement for the default options response, see [Tutorial: implementing custom option buttons in the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-custom-buttons).\n\nImplementing a contact center integration\n: You can use one of the web chat starter kits to integrate with a contact center (service desk) platform other than the ones available in as built-in Watson Assistant integrations. Fully functional reference implementations are available for several contact center platforms; in addition, you can use a starter kit to develop a custom integration with the platform of your choice.\n\nFor more information, see [Adding contact center support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat-haa).\n\n\n\n\n\n Managing data \n\nManaging user identity information\n: The web chat associates a user ID with each message it sends to the assistant; this user ID is used for user-based billing and other purposes. You can either allow the web chat to generate an anonymous ID for each user, or you can control the user ID yourself.\n\nDepending on whether you have enabled security for the web chat, you can use either the [updateUserID](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdateuserid) instance method or the [updateIdentityToken](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdateidentity) method to specify user identity information.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_03080-5624-7473", "score": 29.08150638803127, "text": "\nFor more information about how to customize it, see [HTML content](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-renderhtml).\n\n\n\nThe web chat is embedded directly on your page, not inside an iframe. Therefore, the cascading style sheet (CSS) rules for your website can sometimes override the web chat CSS rules. The web chat applies aggressive CSS resets, but the resets can be affected if your website uses the !important property in elements where style is defined.\n\n\n\n Passing values \n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-set-context)\n* [Adding user identity information (if you don't enable security)](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-userid)\n\n\n\nFor a tutorial that describes how to set context values from the web chat, see [Setting context](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-setting-context).\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-config"}, {"document_id": "ibmcld_16365-15662-16934", "score": 29.011781904110876, "text": "\nOn Apple devices, the Intelligent Tracking Prevention feature automatically deletes any client-side cookie after 7 days. This means that if an anonymous customer accesses your website and then visits again two weeks later, the two visits are treated as two different MAUs. For information about how to avoid this problem, see [Managing user identity information](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nFor information about how to customize the handling of user identity information for billing purposes, see [Managing user identity information](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-userid).\n\nThe usage is measured differently depending on the plan type. For Lite plans, usage is measured by the number of /message calls (API) are sent to the assistant from the web chat integration. For all other plans, usage is measured by the number of monthly active users (MAU) that the web chat interacts with. The maximum number of allowed MAUs differs depending on your Watson Assistant plan type.\n\n\n\nPlan details\n\n Plan Maximum usage \n\n Enterprise Unlimited MAU \n Premium (legacy) Unlimited MAU \n Plus Unlimited MAU \n Trial 5,000 MAU \n Lite 10,000 API (approximately 1,000 MAU)", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_03421-5573-7330", "score": 28.82180689474461, "text": "\nFor more information about the home screen, see [Adding a home screen](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-home-screen). For more information about how to customize it, see [HTML content](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-renderhtml)\n\n\n\nThe web chat is embedded directly on your page, not inside an iframe. Therefore, the cascading style sheet (CSS) rules for your website can sometimes override the web chat CSS rules. The web chat applies aggressive CSS resets, but the resets can be affected if your website uses the !important property in elements where style is defined.\n\n\n\n Passing values \n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-set-context%7D)\n* [Adding user identity information (if you don't enable security)](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-userid)\n\n\n\nFor a tutorial that describes how to set context values from the web chat, see [Setting context](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-setting-context).\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_02855-13982-15842", "score": 28.699629953452153, "text": "\nFor more information about rich response types, see [Rich responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia).\n\n\n\n\n\n Extending the web chat \n\nA developer can extend the capabilities of the web chat by using the Watson Assistant web chat toolkit on [GitHub](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html).\n\nIf you choose to use the provided methods, you implement them by editing the code snippet that was generated earlier. You then embed the updated code snippet into your web page.\n\nHere are some common tasks you might want to perform:\n\n\n\n* [Setting and passing context variable values](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-set-context%7D)\n* [Adding user identity information (if you don't enable security)](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chatdeploy-web-chat-userid)\n\n\n\n\n\n Setting and passing context variable values \n\nA context variable is a variable that you can use to pass information to your assistant before a conversation starts. It can also collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on.\n\nThe following script preserves the context of the conversation. In addition, it adds an $ismember context variable and sets it to true.\n\nThe name that is specified for the skill (main skill) is a hardcoded name that is used to refer to any skill that you create from the product user interface. You do not need to edit your skill name.\n\n<script>\nfunction preSendhandler(event) {\nevent.data.context.skills['main skill'].user_defined.ismember = true;\n}\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_16385-1806-3819", "score": 28.63593713979191, "text": "\n* Customizing the web chat configuration to provide the generated JWT\n* Enabling security in the web chat security settings\n\nAfter you enable web chat security, any message received by the web chat integration that is not accompanied by a properly signed JWT will be rejected.\n\n\n\nFor detailed information about how to complete these steps, see [Enabling web chat security](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security-enable).\n\nWith web chat security enabled, you can optionally implement additional security measures as needed:\n\n\n\n* You can use JWTs to securely [authenticate customers](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-securityweb-chat-security-authenticate) by user ID, which makes it possible for your assistant to control access to functions that require authorization.\n\nWithout web chat security enabled, each customer who uses your assistant is identified only by the user_id property that is part of the message request. This is sufficient for identifying unique users for billing purposes, but it is not secure, because it could be modified.\n\nBy encoding user identity information as part of the JWT payload, you can authenticate users securely. The JWT is signed and cannot be modified by the user.\n\nFor more information about using JWTs for secure authentication, see [Authenticating users](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security-authenticate).\n* You can [prevent unauthorized access](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-securityweb-chat-security-encrypt) to sensitive customer information by encrypting it and including it as part of the JWT user payload.\n\nThe user payload is a part of the JWT you can use to send information you want your assistant to have access to, but that you do not want customers to see. This information is stored only in private variables, which cannot be seen by customers and are never included in logs.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security"}, {"document_id": "ibmcld_16382-7-1870", "score": 28.443515024201695, "text": "\nManaging user identity information \n\nWatson Assistant charges based on the number of unique monthly active users (MAU).\n\nIf you do not pass an identifier for the user when the session begins, the web chat creates one for you. It creates a first-party cookie with a generated anonymous ID. The cookie remains active for 45 days. If the same user returns to your site later in the month and chats with your assistant again, the web chat integration recognizes the user. And you are charged only once when the same anonymous user interacts with your assistant multiple times in a single month.\n\nIf you want to perform tasks where you need to know the user who submitted the input, then you must pass the user ID to the web chat integration. Choose a non-human-identifiable ID. For example, do not use a person's email address as the user ID.\n\nIn addition, the ability to delete any data created by someone who requests to be forgotten requires that a customer_id be associated with the user input. When a user_id is defined, the product can reuse it to pass a customer_id parameter. (For more information about deleting user data, see [Labeling and deleting data](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-securingsecuring-gdpr-wa).)\n\nBecause the user_id value that you submit is included in the customer_id value that is added to the X-Watson-Metadata header in each message request, the user_id syntax must meet the requirements for header fields as defined in [RFC 7230](https://tools.ietf.org/html/rfc7230section-3.2).\n\nTo support these user-based capabilities, add the [updateUserID() method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdateuserid) in the code snippet before you paste it into your web page.\n\nIf you enable security, you set the user ID in the JSON Web Token instead.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-userid"}, {"document_id": "ibmcld_16386-7-2009", "score": 28.425052249178158, "text": "\nAuthenticating users \n\nWith web chat security enabled, you can securely authenticate customers by user ID.\n\nThe default behavior of the web chat integration is to identify unique users by setting the value of the user_id property that is sent as part of each message to the assistant. (For more information, see [Managing user identity information](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-userid).)\n\nThis approach is sufficient for tracking unique users for billing purposes, but it is not secure and should not be used for access control. If you enable web chat security, you can use JSON Web Tokens (JWTs) to securely authenticate your users and control access to functions of your assistant that require authorization.\n\n\n\n Authenticating with the sub claim \n\nTo use this method for authenticating users, you must first enable the web chat security feature. For more information, see [Enabling web chat security](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security-enable).\n\nWhen you create a JWT for the web chat, you must specify a value for the sub (subject) claim, which identifies the user. (For anonymous users, you can use a generated unique ID.)\n\nWhen you generate a user ID for an anonymous user, be sure to save the generated ID in a cookie to prevent being billed multiple times for the same customer.\n\nWhen the web chat integration receives a message signed with this JWT, it stores the user ID from the sub claim as context.global.system.user_id. For user-based plans, this user ID is used for billing purposes. (You cannot use the updateUserID() instance method to set the user ID if web chat security is enabled.) The same user ID is also used as the customer ID, which can be used to make requests to delete user data. Because the customer ID is sent in a header field, the ID you specify must meet the requirements for header fields as defined in [RFC 7230](https://tools.ietf.org/html/rfc7230section-3.2).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security-authenticate"}, {"document_id": "ibmcld_16368-7-2072", "score": 27.999460740498943, "text": "\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04105-1672-3877", "score": 29.850010065645975, "text": "\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-3403-5572", "score": 27.56998170710024, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-7-2225", "score": 24.03308739625832, "text": "\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04111-35313-36062", "score": 20.22126061362581, "text": "\nGet Bot Management settings. GET /v1/{crn}/zones/{domain_id}/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT /v1/{crn}/zones/{domain_id}/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET /v1/{crn}/zones/{domain_id}/bot_analytics/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET /v1/{crn}/zones/{domain_id}/bot_analytics/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET /v1/{crn}/zones/{domain_id}/bot_analytics/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-at_iam_CIS"}, {"document_id": "ibmcld_04105-5067-6335", "score": 19.63422369605354, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04146-1603-3385", "score": 19.511838165112813, "text": "\nhttp.request.method String POST The HTTP method, in upper case \n http.request.uri String /articles/index?section=539061&expand=comments The absolute URI of the request \n http.request.uri.path String /articles/index The path of the request \n http.request.uri.query String section=539061&expand=comments The whole query string, minus the delimiting prefix \"?\" \n http.user_agent String Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/65.0.3325.181 Safari/537.36 The whole HTTP user agent \n http.x_forwarded_for String The full X-Forwarded-For HTTP header \n ip.src IP address 93.155.208.22 The client TCP IP address, which can be adjusted to reflect the real client IP of the original client as applicable (for example, using HTTP headers like X-Forwarded-For or X-Real-IP) \n ip.geoip.asnum Number 222 The [Autonomous System](https://ibm.biz/BdzqdD) (AS) number \n ip.geoip.country String GB The [2-letter country code](https://www.iso.org/obp/ui/search/code/) \n ssl Boolean true Whether the HTTP connection to the client is encrypted \n\n\n\nThese standard fields follow the naming convention of the Wireshark display field reference. However, some subtle variations might exist in the preceding example values.\n\nIn addition to the standard fields, the following Cloudflare-defined fields are also available:\n\n\n\nTable 2. Available Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-fields-and-expressions"}, {"document_id": "ibmcld_04146-2946-5057", "score": 19.511838165112813, "text": "\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-fields-and-expressions"}, {"document_id": "ibmcld_04111-34153-35639", "score": 18.52922048800587, "text": "\nGET /v1/{crn}/zones/{domain_id}/setting/origin_error_page_pass_thru internet-svcs.zones.update internet-svcs.origin-error-page-pass-thru-setting.update \n Get brotli compression settings. GET /v1/{crn}/zones/{domain_id}/setting/brotli internet-svcs.performance.read internet-svcs.brotli-setting.read \n Update brotli compression settings. PUT /v1/{crn}/zones/{domain_id}/setting/brotli internet-svcs.performance.update internet-svcs.brotli-setting.update \n Get Email obfuscation settings. GET /v1/{crn}/zones/{domain_id}/setting/email_obfuscation internet-svcs.security.read internet-svcs.email-obfuscation-setting.read \n Update Email obfuscation settings. PUT /v1/{crn}/zones/{domain_id}/setting/email_obfuscation internet-svcs.security.update internet-svcs.email-obfuscation-setting.update \n Get ciphers settings. GET /v1/{crn}/zones/{domain_id}/setting/ciphers internet-svcs.security.read internet-svcs.ciphers-setting.read \n Update ciphers settings. PUT /v1/{crn}/zones/{domain_id}/setting/ciphers internet-svcs.security.update internet-svcs.ciphers-setting.update \n\n\n\n\n\n\n\n Bot Management \n\n\n\nTable 22. Bot Management\n\n Action Method IAM ACTION AT ACTION \n\n Get Bot Management settings. GET /v1/{crn}/zones/{domain_id}/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT /v1/{crn}/zones/{domain_id}/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-at_iam_CIS"}, {"document_id": "ibmcld_16286-1338-3308", "score": 18.065764732353216, "text": "\nClick Next to begin app registration.\n\n\n\n\n\n App registration \n\n\n\n1. Go to the [Microsoft Azure portal](https://portal.azure.com/), and log in with your admin credentials.\n2. On the App registrations page, click New registration.\n3. On the Register an application page, enter a name, select the multi-tenant option that applies to your app, and then click Register.\n4. Copy the application ID from the Overview page of your app, and paste it into the App registration field of your Watson Assistant Microsoft Teams integration.\n5. On the same Microsoft Azure Overview page, click the hyperlink Add a certificate or secret next to Client Credentials.\n6. On the Certificates & secrets page for token creation, click New client secret. Enter a description and then select Recommended 180 days. Click Add.\n7. Copy the string under Value and paste into Client secret value on the App registration page of your Watson Assistant Microsoft Teams integration. Note: You must generate a new value before the current one expires on day 180.\n8. Click Next to create your bot.\n\n\n\n\n\n\n\n Create your bot \n\n\n\n1. Go to the [Microsoft Bot Framework developer portal](https://dev.botframework.com/bots/new), and log in with your admin credentials.\n2. On the Tell us about your bot page, complete your bot profile.\n3. Copy the generated endpoint from the Create your bot page of your Watson Assistant Microsoft Teams integration and paste into the Messaging endpoint field of the Configuration section.\n4. Select Multi-Tenant as the app type.\n5. Copy and paste your app ID, and then click Register.\n6. On the Connect to channels page, click Configure Microsoft Teams channel in the Add a featured channel section.\n7. On the Configure Microsoft Teams page, specify options in the Messaging, Calling, and Publish tabs that fit your bot needs, and then click Save.\n8. In your Watson Assistant Microsoft Teams integration, click Next to create your Teams app.\n\n\n\n\n\n\n\n Create your Teams app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-microsoft-teams"}, {"document_id": "ibmcld_04170-7-2189", "score": 17.94354016976808, "text": "\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https://research.google/pubs/pub45581/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with /cdn-cgi/challenge-platform/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04518-1426-3052", "score": 24.467059044996507, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_12332-1034-2510", "score": 23.06354055420028, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}, {"document_id": "ibmcld_10817-1342-3184", "score": 21.90360003306896, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_07551-15747-17355", "score": 21.359054280979127, "text": "\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https://github.com/IBM/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n/Register iOS devices/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_07551-14062-16080", "score": 19.966898723777327, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_04518-7-1743", "score": 19.65343164351721, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_14546-6172-8106", "score": 15.945398321278365, "text": "\nMetric Frequency Description \n\n MAX_PRIVATE_NETWORK_ONE_G_COST Monthly Charge for private network endpoint at 1 GB uplink over a period of one month. \n MAX_PRIVATE_NETWORK_TEN_G_COST Monthly Charge for private network endpoint at 10 GB uplink over a period of one month. \n\n\n\n\n\n\n\n Licenses and fees for Veeam Availability Suite and Zerto \n\nVeeam\u00ae and Zerto usage incurs the following on-demand charges. You can view the charges on the IBM Cloud billing and usage view along with the usage and charges from all other IBM Cloud services.\n\nIn the IBM Cloud Usage view, locate the VMware Solutions service type. Locate the Organization plan to find the Veeam and Zerto usage across all virtual data centers in that organization. The virtual data center usage is located in a separate plan for either VMware Shared on-demand or VMware Shared Reserved.\n\nVeeam\n\nZerto\n\n\n\nTable 5. Licenses and fees for Veeam\n\n Metric Frequency Description \n\n MAX_VEEAM_LICENSES Monthly Veeam license charge for every VM under backup. The monthly charge is for the highest number of VMs under backup at any time period in the month. \n TOTAL_VEEAM_BLOCK_STORAGE_GB_HOURS Hourly Charge per GB of block storage used for all backups. \n TOTAL_VEEAM_OBJECT_STORAGE_GB_HOURS Hourly Charge per GB of object storage used for all backups. \n\n\n\nNo additional Veeam or Zerto usage charges for VMware Shared are incurred.\n\nFor the Veeam service, initially, all backups go to the block storage that is closest to their VM workloads. Backups that are a part of an inactive backup chain are immediately moved to Cloud Object Storage. The restore speed for these inactive backups might be impacted.\n\nYou can change how fast the inactive backup chains are moved to Cloud Object Storage by opening an IBM Cloud for VMware Solutions service ticket.\n\n\n\n\n\n Related links \n\n\n\n* [VMware Shared overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-shared_overview)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-shared_pricing"}, {"document_id": "ibmcld_13612-0-945", "score": 15.44874637310539, "text": "\n\n\n\n\n\n\n  Charge Metrics and Order consideration \n\n\n\n  Release Notes \n\n\n\n\n\n  Abstract \n\nBefore submitting an order, the following should be considered to ensure the order is 'right sized' and will meet the requirements of the client.\n\nImportant: Customers must purchase (or own) App Points for TRIRIGA Application Suite (TAS) prior to (or in conjunction with) ordering the IBM Managed Service. The managed service provides IBM Cloud based hosting, product installation, operation, maintenance and support for TAS.\n\nInformation should be gathered about the potential usage of the suite, including which applications will be required, how many users on each application and the primary usage of the applications.\n\nThere are three (3) TAS-MS part numbers:\n\nD02QTZX - Capacity\n\nD02QUZX - Data\n\nD02QWZX - VPC (Virtual Processor Core)\n\nFor additional information, please contact:\n\nPedro Echeverria [pedech@br.ibm.com](mailto:pedech@br.ibm.com)\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/tas-ms?topic=tas-ms-charge-metrics"}, {"document_id": "ibmcld_10852-43319-44485", "score": 15.347053362023614, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_11408-1663-2873", "score": 15.207902734264287, "text": "\nAll prices mentioned on this page are illustrative and do not represent the actual amounts used for billing. To calculate the exact pricing, use the [IBM cost estimator](https://cloud.ibm.com/estimator).\n\n\n\nTable 2. Monthly LPAR charges\n\n Hours elapsed in a month Amount charged LPAR description \n\n 300 hours (300 hours x $0.343)/month = $103 1 core, 8 GB memory, 150 GB disk, AIX \n 430 hours (430 hours x $0.465)/month = $200 1 core, 16 GB memory, 150 GB disk, AIX \n 730 hours (Monthly Total) $103 + $200 = $303 (Monthly Total) 1 core, 16 GB memory, 150 GB disk, AIX \n\n\n\nIn this example, the LPAR resources are increased (after reaching 300 hours in the month) from 8 GB to 16 GB of memory. The price of the LPAR is prorated by the hour for the final monthly price of $303.\n\nFor detailed usage and billing information, you can refer to the part number in your invoice. The part numbers in the invoice represent the charge unit. Refer to the following table to view the part numbers and its corresponding description.\n\n\n\n Part number Description \n\n SOS_VIRTUAL_PROCESSOR_CORE_HOURS Scale out shared uncapped processor per core-hour \n SOD_VIRTUAL_PROCESSOR_CORE_HOURS Scale out dedicated processor per core-hour", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-pricing-virtual-server"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08117-7-2019", "score": 37.87192348933664, "text": "\nIBM Cloud Disaster Recovery (DR) and Backup and Restore \n\nLocal service interruption can be caused by many things: hardware failures, bugs, power failures, planned and unplanned maintenance. To minimize a single point of failure, IBM Cloud\u00ae architects create resilient designs that have multiple virtual server instances to provide the highest availability.\n\nHowever, extreme failure events, such as data center wide failures due to network outages, natural disasters, or ransomware are harder to anticipate and plan for. Your Business Continuity and Disaster Recovery (BCDR) plan becomes a critical part of recovering from these types of events. Business continuity focuses on the processes and procedures that you implement to help your people minimize interruptions to business operations. Disaster recovery focuses on the IT components and restoring systems after a disaster.\n\n\n\n Disaster recovery components \n\nThe DR model has two main components that deal with what can be tolerated:\n\n\n\n* Recovery Time Objective (RTO) - the maximum time that the service can be down.\n* Recovery Point Objective (RPO) - the maximum amount of data loss.\n\n\n\nZoom\n\n![DR backup diagram.](https://cloud.ibm.com/docs-content/v1/content/df269b100c3499f1efcbb7d030dce8dec25c539b/ha-infrastructure/images/ha-DR-backup-diagram.svg)\n\nFigure 1. DR backup diagram\n\nThese values are directly correlated to both cost and complexity. A lower amount of time and data loss equates to higher cost and complexity.\n\n\n\n\n\n DR Strategies \n\nYou can implement your DR strategy in one of two ways:\n\n\n\n Strategy Description Benefits \n\n Cold (Active/Standby) With a Cold DR strategy, your solution is running in one environment and duplicate resources are available on standby. When an event occurs, you react and build up the standby site. A cold strategy is a reactive approach, where the upfront cost is minimal, other than storage costs for snapshots and backups. The cold approach typically entails higher RPO/RTO times and is simple to implement.", "title": "", "source": "https://cloud.ibm.com/docs/ha-infrastructure?topic=ha-infrastructure-ha-dr-backup-restore"}, {"document_id": "ibmcld_14598-9419-11893", "score": 34.81400303614131, "text": "\nResponsibilities for security and regulation compliance for VMware Solutions offerings (other than VMware Shared)\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Encryption Provide integration with Key Protect and Hyper Protect Crypto Services through KMIP service as an option for implementing data at-rest encryption. Configure and manage encryption for both data at rest and in transit, as needed. \n\n\n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as:\n\n\n\n* Providing dependencies on disaster recovery sites\n* Provision disaster recovery environments\n* Data and configuration backup\n* Replicating data and configuration to the disaster recovery environment\n* Fail over on disaster events\n\n\n\n\n\n Disaster recovery for VMware Shared \n\nThe following table describes the responsibilities that are related to disaster recovery for VMware Shared.\n\n\n\nTable 8. Responsibilities for disaster recovery for VMware Shared\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsible for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Task IBM responsibilities Your responsibilities \n\n Backup of configuration data Backups are conducted of the shared management components to include customer environment configurations. Offsite backup copies are enabled and they run daily. \n Backup of workload Backup services are enabled for customer workload. Configure individual backup jobs to include critical systems. Offsite copies can be enabled per request. \n Recovery of configuration Recovery will be conducted in the original data center after the infrastructure is available. If long-term outage occurs, offsite recovery is conducted. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, customer restore services will be provided after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover. Restore systems from the configured backup jobs. \n\n\n\n\n\n\n\n Disaster recovery for VMware Solutions offerings (other than VMware Shared)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-understand-responsib"}, {"document_id": "ibmcld_07578-873193-875161", "score": 34.55053961671978, "text": "\nUsing the [backup service](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https://www.ibm.com/cloud/disaster-recovery).\n\n\n\n\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the backup snapshot can exist in each region. You can't create a copy of the backup snapshot in the source (local) region.\n\n\n\n* Can I use data backups for disaster recovery?\n\n Can I use data backups for disaster recovery? \n\nUsing the [backup service](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https://www.ibm.com/cloud/disaster-recovery).\n* How many copies of my backup can I create in other regions?\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-873070-875038", "score": 34.55053961671978, "text": "\nUsing the [backup service](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https://www.ibm.com/cloud/disaster-recovery).\n\n\n\n\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. Only one copy of the backup snapshot can exist in each region. You can't create a copy of the backup snapshot in the source (local) region.\n\n\n\n* Can I use data backups for disaster recovery?\n\n Can I use data backups for disaster recovery? \n\nUsing the [backup service](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. You can also create copies of your backup snapshot in other regions. However, the backup service does not provide continual backup with automatic failover. Restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https://www.ibm.com/cloud/disaster-recovery).\n* How many copies of my backup can I create in other regions?\n\n How many copies of my backup can I create in other regions? \n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_08669-6042-7847", "score": 34.47425719051428, "text": "\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events. IBM is responsible for the recovery of Hyper Protect Crypto Services components in case of disaster. You are responsible for the recovery of the workloads that run Hyper Protect Crypto Services and your application data.\n\n\n\nTable 5. Responsibilities for disaster recovery\n\n Task IBM responsibilities Your responsibilities \n\n Instance backups Continuously perform in-region and cross-region backups of key resources and perform continuous testing of backups. Back up your master key; validate the backups and restore data when needed. \n Disaster recovery When an in-region disaster occurs, automatically recover and restart service components. When a regional disaster that affects all available zones occurs, ensure that all data except the master key is replicated to another region. IBM will also make additional crypto units available in a different region and manage routing requests to the new crypto units. When a regional disaster that affects all available zones occurs, load your master key to the new crypto units that IBM provisions in a different region for restoring data. You can also enable and initialize failover crypto units before a disaster occurs, which reduces the downtime. \n Availability Provide high availability capabilities, such as IBM-owned infrastructure in multizone regions, to meet local access and low latency requirements for each supported region. Use the list of [available regions](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-regions) to plan for and create new instances of the service.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-shared-responsibilities"}, {"document_id": "ibmcld_14738-7598-10031", "score": 34.37179253889252, "text": "\nThe first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Encryption Provide secure SSL connections to administration portals and replication endpoints. Workload can be deployed by using AES 256-bit encrypted data stores with unique key per customer instance. Backups are encrypted uniquely per customer. Choose encrypted data stores when you are deploying workloads into the environment where appropriate. Use encrypted networking for workload to workload and workload to IBM Cloud Service connections. Use the IBM Cloud private network where appropriate. \n\n\n\n\n\n\n\n Disaster recovery \n\nDisaster recovery includes tasks such as providing dependencies on disaster recovery sites, provision disaster recovery environments, data and configuration backup, replicating data and configuration to the disaster recovery environment, and failover on disaster events.\n\n\n\nTable 5. Responsibilities for disaster recovery\nThe rows are read from left to right. The first column describes the task that a customer or IBM might be responsibility for. The second column describes IBM responsibilities for that task. The third column describes your responsibilities as the customer for that task.\n\n Item IBM responsibilities Your responsibilities \n\n Backup of management configuration data Conduct backups of the management component configurations. These backups include single-tenant vCenter Server, VMware NSX-T, VMware Cloud Director\u2122, and service configurations. Offsite immutable backup copies are enabled in an independent backup account and they run daily. \n Backup of workloads Enable backup services for customer workload. Choose and implement a backup provider for critical workloads. For more information, see [Understanding business continuity and disaster recovery](https://cloud.ibm.com/docs/vmware-service?topic=vmware-service-bc-dr). \n Recovery of configuration Conduct recovery in the original data center after the infrastructure is available. \n Recovery of workloads Restore capabilities are available in normal operations. For configuration restores, provide customer restore services after the infrastructure is available. If an offsite recovery is required, IBM works with the customer to help recover.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vmaas-understand-responsib"}, {"document_id": "ibmcld_01092-7-2034", "score": 34.164399594202834, "text": "\nDisaster recovery \n\nDisaster recovery (DR) backups for IBM\u00ae Db2\u00ae Warehouse on Cloud are enabled by default and supplement daily snapshot backups. DR backups are used exclusively for system recovery purposes by IBM service operators if there is a disaster or system loss.\n\nIf a disaster event occurs at the data center where your Db2 Warehouse on Cloud instance is deployed, IBM service operators will work with you to stand up a new data warehouse in a different data center, by using the most recent disaster recovery backup. There is no additional charge for these backups.\n\nThe RPO (Recovery Point Objective) and RTO (Recovery Time Objective) for DR backups for each cloud provider are described in the following sections. On IBM Cloud, DR backups are geo-replicated by default. You can open a support ticket to not have your DR backups replicated to certain regions to comply with your data retention policies. On AWS, DR backups are stored in another Availability Zone in the same region and can also be geo-replicated at an additional cost.\n\nFor more information about DR and replication on Db2 Warehouse on Cloud, see [Replication](https://www.ibm.com/support/knowledgecenter/SS6NHC/com.ibm.swg.im.dashdb.idrca.doc/overview/ovu-db2woc.html).\n\n\n\n IBM Cloud \n\nWhen deployed on IBM Cloud, a full backup of the database is taken once a week for disaster recovery. This DR backup is encrypted and stored in IBM Cloud Object Storage (COS).\n\nIBM COS replicates each DR backup across multiple IBM Cloud regions to ensure availability if a single zone fails.\n\nDR backups of the last 2 weeks are retained by default. The RPO for DR backups on IBM Cloud is 1 week. The RTO if a disaster occurs is dependent upon the size of the database \u2013 1.5 hours per terabyte of data.\n\n\n\n\n\n Amazon Web Services \n\nWhen deployed on Amazon Web Services, a full backup of the database is taken once a day for disaster recovery. This DR backup is encrypted and stored in Amazon Web Services S3.\n\nDR backups of the last 7 days are retained by default.", "title": "", "source": "https://cloud.ibm.com/docs/Db2whc?topic=Db2whc-dr"}, {"document_id": "ibmcld_10885-11108-13084", "score": 34.10678564200799, "text": "\nIn the event of a disaster, the only change that is needed will be to reconfigure DNS to point to the cluster in US East.\n\nBenefits\n: Fastest recovery time, dependent only on the time it takes to verify that the data was replicated and make the DNS switch.\n\nImpacts\n: Cost. To support the RTO, the only viable option is the active/hot-standby model.\n: Development teams need to update their deployment pipelines to also deploy their apps to the standby IBM Cloud Code Engine project every time they deploy to production. And, validate that it was successful.\n\n\n\n\n\n Continuous Availability profile application - PostgreSQL \n\nZoom\n\n![PostgreSQL example application architecture](https://cloud.ibm.com/docs-content/v1/content/adcecdbe4e86955f88aac7f3c1e7ec3ff44992ef/overview/images/BCDR-Architecture-Diagram-Image9.svg)\n\nFigure 8. PostgreSQL example application architecture\n\nIn this scenario, the data is replicated automatically by IBM Cloud Databases to a read-only replica in the backup MZR. In the event of a disaster, the application team needs to manually trigger a promotion of the read-only replica to become the leader. This action will take some time as a read-only replica of the service instance is not configured using a high availability (HA) topology. When the promotion occurs, several steps happen to elevate the instance to an HA configuration.\n\nThe only other change that is needed is to reconfigure DNS to point to the cluster in US East when the database promotion is complete.\n\nBenefits\n: Faster recovery time, as the data is already replicated to the backup MZR. There is still some latency related to the time it takes to reconfigure the database to an HA configuration.\n\nImpacts\n: Cost. To support the recovery time objective the only viable option is the active/hot standby model.\n: Development teams need to update their deployment pipelines to also deploy their apps to the standby IBM Cloud Code Engine project every time they deploy to production.", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-bcdr-app-recovery"}, {"document_id": "ibmcld_00557-2965-3896", "score": 34.05767256966771, "text": "\n[HIPAA](https://en.wikipedia.org/wiki/Health_Insurance_Portability_and_Accountability_Act) compliance is available upon request, so request HIPAA compliance during the purchase process with an IBM sales representative.\n\n\n\n\n\n High availability, disaster recovery, and backup \n\nTo provide high availability (HA) and disaster recovery (DR) within a data center, all data is stored in triplicate across three separate physical servers in a cluster. When available, you can provision accounts in multiple locations, then use continuous data replication to provide HA/DR across data centers. IBM Cloudant data isn't automatically backed up, but supported tools are provided to handle backups. Review the [Disaster recovery and backup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-disaster-recovery-and-backupdisaster-recovery-and-backup) guide to explore all HA, DR, and backup considerations to meet your application requirements.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-dedicated"}, {"document_id": "ibmcld_12523-0-1829", "score": 33.529624808195265, "text": "\n\n\n\n\n\n\n  Understanding business continuity and disaster recovery for projects \n\nDisaster recovery involves a set of policies, tools, and procedures for returning a system, an application, or an entire data center to full operation after a catastrophic interruption. It includes procedures for copying and storing an installed system's essential data in a secure location, and for recovering that data to restore normalcy of operation.\n\n\n\n  Responsibilities \n\nFor more information about your responsibilities when using projects, see [Shared responsibilities for projects](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-responsibilities-projects).\n\n\n\n  Disaster recovery strategy \n\nIBM Cloud has business continuity plans in place to provide for the recovery of services within hours if a disaster occurs. You are responsible for your data backup and associated recovery of your content.\n\nIBM Cloud performs regular electronic backups of project data with Recovery Time Objective (RTO) and Recovery Point Objective (RPO) of hours as documented in the [IBM Cloud Disaster Recovery Plan](https://cloud.ibm.com/docs/overview?topic=overview-zero-downtimedisaster-recovery). Projects don't replicate data outside of a region, except for backup data. When possible, backup data is kept within the data centers of a country but data is always kept within a geography. European data does not leave the EU.\n\n\n\nTable 1. RPO and RTO for projects\n\n Disaster recovery objective  Target Value \n\n RPO                          1 hour       \n RTO                          4 hours      \n\n\n\n\n\n\n\n\n\n  Locations \n\nFor more information about service availability within regions and data centers, see [Service and infrastructure availability by location](https://cloud.ibm.com/docs/overview?topic=overview-services_region).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-bc-dr"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10214-7-1980", "score": 37.889780100084685, "text": "\nFAQs \n\nReview frequently asked questions (FAQs) for using Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\n\n\n How does Red Hat OpenShift on IBM Cloud work? \n\nWith Red Hat OpenShift on IBM Cloud, you can create your own Red Hat OpenShift cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov).\n\n\n\n\n\n Why should I use Red Hat OpenShift on IBM Cloud? \n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-faqs"}, {"document_id": "ibmcld_10534-1033-2260", "score": 37.116878278239156, "text": "\n[Understanding Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewoverview)\n\n\n\n* [What is Red Hat OpenShift on IBM Cloud and how does it work?](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewwhat-is-overview)\n* [What is Kubernetes?](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewwhat-is-kube-overview)\n* [What are containers?](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewwhat-are-containers-overview)\n* [What is Red Hat OpenShift?](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewwhat-is-openshift-overview)\n* [What compute host infrastructure does the service offer?](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewwhat-compute-infra-is-offered)\n* [Related resources](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewkubernetes-resources)\n\n\n\n[Benefits and service offerings](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_07578-394005-396150", "score": 36.446512905836855, "text": "\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-393979-396124", "score": 36.446512905836855, "text": "\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_10154-7-1896", "score": 36.14547948816795, "text": "\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https://www.ibm.com/products/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}, {"document_id": "ibmcld_05707-7-2073", "score": 34.210551071871805, "text": "\nBenefits and service offerings \n\n[IBM Cloud\u00ae Kubernetes Service](https://www.ibm.com/cloud/kubernetes-service) delivers powerful tools by combining Docker containers, the Kubernetes technology, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts. For more information about certification, see [Compliance on the IBM Cloud](https://www.ibm.com/cloud/compliance).\n\n\n\n Benefits of using the service \n\nClusters are deployed on compute hosts that provide native Kubernetes and IBM-specific capabilities.\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud. For more information, see Comparison between [Red Hat OpenShift](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovopenshift_kubernetes) and community Kubernetes clusters.\n\nSingle-tenant Kubernetes clusters with compute, network, and storage infrastructure isolation\n: Create your own customized infrastructure that meets the requirements of your organization.\n: Choose between [IBM Cloud Classic or VPC infrastructure providers](https://cloud.ibm.com/docs/containers?topic=containers-infrastructure_providers).\n: Provision a dedicated and secured Kubernetes master, worker nodes, virtual networks, and storage by using the resources provided by IBM Cloud infrastructure.\n: Fully managed Kubernetes master that is continuously monitored and updated by IBM to keep your cluster available.\n: Option to provision worker nodes as bare metal servers for compute-intensive workloads such as data, GPU, and AI.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_ov"}, {"document_id": "ibmcld_10534-1903-3343", "score": 34.00686800784817, "text": "\n[Benefits and service offerings](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes)\n* [Comparison between clusters that run in IBM Cloud and standard OCP](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovcompare_ocp)\n\n\n\n[Supported infrastructure providers](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersinfrastructure_providers)\n\n\n\n* [Virtual Private Cloud (VPC)](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersvpc-gen2-infra-overview)\n* [Satellite](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providerssatellite-infra-overview)\n* [Classic](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersclassic-infra-overview)\n* [Troubleshooting and support](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersinfra-troubleshoot)\n\n\n\n[Your responsibilities with using Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-responsibilities_iksresponsibilities_iks)\n\n\n\n* [Overview of shared responsibilities](https://cloud.ibm.com/docs/openshift?topic=openshift-responsibilities_iksoverview-by-resource)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_10214-1438-3413", "score": 32.69342452167289, "text": "\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits).\n\n\n\n\n\n What container platforms are available for my cluster? \n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform. If you want to use multiple container platforms, create a separate cluster for each.\n\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https://kubernetes.io/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-faqs"}, {"document_id": "ibmcld_10214-12307-14229", "score": 32.2566987903263, "text": "\nRed Hat OpenShift security bulletins that affect Red Hat OpenShift on IBM Cloud users or the IBM Cloud platform are published in the [IBM Cloud security bulletin](https://cloud.ibm.com/status?component=containers-kubernetes&selected=security).\n\nSome CVEs require the latest patch update for a version that you can install as part of the regular [cluster update process](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) in Red Hat OpenShift on IBM Cloud. Make sure to apply security patches in time to protect your cluster from malicious attacks. For more information about what is included in a security patch, refer to the [version change log](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionscs_versions_available).\n\n\n\n\n\n Does the service offer support for bare metal and GPU? \n\nCertain VPC worker node flavors offer GPU support. For more information, see the [VPC flavors](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-flavors).\n\nYes, you can provision your worker node as a single-tenant physical bare metal server. Bare metal servers come with high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have to worry about \"noisy neighbors\".\n\nFor more information about available bare metal flavors and how bare metal is different from virtual machines, see [Physical machines (bare metal)](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesbm).\n\n\n\n\n\n What is the smallest size cluster that I can make? \n\nYour cluster must have at least 2 worker nodes to run default Kubernetes and OpenShift Container Platform components. You can't have a cluster with 0 worker nodes, and you can't power off or suspend billing for your worker nodes. Additionally, the type of cluster and the number of worker pools that you have can impact the size of your cluster.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-faqs"}, {"document_id": "ibmcld_10154-1411-3594", "score": 32.07916943422635, "text": "\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud. For more information, see Comparison between [Red Hat OpenShift](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes) and community Kubernetes clusters.\n\nSingle-tenant Kubernetes clusters with compute, network, and storage infrastructure isolation\n: Create your own customized infrastructure that meets the requirements of your organization.\n: Choose between [IBM Cloud Classic or VPC infrastructure providers](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providers).\n: Provision a dedicated and secured Red Hat OpenShift master, worker nodes, virtual networks, and storage by using the resources provided by IBM Cloud infrastructure.\n: Fully managed Kubernetes master that is continuously monitored and updated by IBM to keep your cluster available.\n: Option to provision worker nodes as bare metal servers for compute-intensive workloads such as data, GPU, and AI.\n: Store persistent data, share data between Kubernetes pods, and restore data when needed with the integrated and secure volume service.\n: Benefit from full support for all native Kubernetes APIs.\n\nMultizone clusters to increase high availability\n: Easily manage worker nodes of the same flavor (CPU, memory, virtual or physical) with worker pools.\n: Guard against zone failure by spreading nodes evenly across select multizones and by using anti-affinity pod deployments for your apps.\n: Decrease your costs by using multizone clusters instead of duplicating the resources in a separate cluster.\n: Benefit from automatic load balancing across apps with the multizone load balancer (MZLB) that is set up automatically for you in each zone of the cluster.\n\nHighly available masters", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01533-4546-6910", "score": 38.476026392107, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4585-6962", "score": 38.4397413703024, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01533-6329-8623", "score": 38.3053829876066, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-6381-8675", "score": 38.3053829876066, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_07578-365833-367834", "score": 37.88754203308693, "text": "\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-365807-367808", "score": 37.88754203308693, "text": "\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_01415-6473-8616", "score": 37.46018291042721, "text": "\nFor more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_faq&interface=ui"}, {"document_id": "ibmcld_00882-2700-4149", "score": 36.41299843139626, "text": "\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \"./Report-final.xml\" --type staticsecurityscan\n\nChange the type to dynamicsecurityscan if the report is from a dynamic scan.\n\n\n\n\n\n Uploading SonarQube results \n\nTo upload data from SonarQube, you must provide the SonarQube server token by using --token. Your SonarQube server is required to be accessible from your CI/CD tool.\n\nAfter you run a scan by using SonarQube, you can upload SonarQube results by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".scannerwork/report-task.txt\" --type=sonarqube --token=$SONARQUBE_TOKEN\n\nreport-task.txt is a file that is generated during the SonarQube scan.\n\n\n\n\n\n Uploading IBM Vulnerability Advisor results \n\nTo get the result of the vulnerability advisor scan from the CLI, use the following command:\n\nibmcloud cr va ${PIPELINE_IMAGE_URL} -o json > vulnerability_advisor.json\n\nYou can get your image's repository and tag from the Vulnerability Advisor UI or in the CLI by using ibmcloud cr image-list. DevOps Insights accepts only the JSON output. You can upload Vulnerability Advisor output file to DevOps Insights by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"${APP_NAME}\" --buildnumber \"${BUILD_NUMBER}\" --filelocation \"vulnerability_advisor.json\" --type vulnerabilityadvisor", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-publishing-test-data"}, {"document_id": "ibmcld_01533-4-2366", "score": 35.74146097124232, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4-2366", "score": 35.74146097124232, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00436-0-941", "score": 17.506955243131713, "text": "\n\n\n\n\n\n\n  Updating CDN configuration details \n\nAfter your CDN is running, you can update CDN configuration details. Follow these steps.\n\n\n\n1.  On the CDN page, select your CDN, which takes you to the Overview page.\n2.  Select the Settings tab. Your CDN configuration details are displayed.\n\nYou only see SSL Certificate if your CDN was configured with HTTPS.\n\nFor Server, the following fields can be changed:\n\n\n\n*  Host header\n*  Origin server address\n*  HTTP/HTTPS Port\n*  Serve Stale Content\n*  Respect Headers\n*  Optimization options\n*  Cache-query\n\n\n\nFor Object Storage, the following fields can be changed:\n\n\n\n*  Host header\n*  Endpoint\n*  Bucket name\n*  HTTPS Port\n*  Allowed file extensions\n*  Serve Stale Content\n*  Respect Headers\n*  Optimization options\n*  Cache-query\n\n\n\n3.  Update the Origin or Other Options details if needed, then click the Save button in the lower right corner to update your CDN configuration details.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/CDN?topic=CDN-updating-cdn-configuration-details"}, {"document_id": "ibmcld_15263-5634-7460", "score": 16.840630162888232, "text": "\nibmcloud is instance-delete $vsi\n\nThe status of the instance changes to deleting immediately, but it still appears in a list query result. The deletion of an instance can take up to 30 minutes.\n\nYou can request other subnet resources to be deleted in parallel while you wait for the instance to be deleted. However, the subnet cannot be deleted until the instance and all other resources in the subnet no longer appear in the list query results.\n\nIf a secondary network interface exists in the subnet you are trying to delete, you must delete the instance. A network interface cannot be deleted from the instance without deleting the instance.\n\n\n\n\n\n Delete the subnet \n\nAfter all the resources inside the subnet were deleted, which means that they are not returned in a list query result, run the following command to delete the subnet:\n\nibmcloud is subnet-delete $subnet\n\nThe status of the subnet changes to deleting immediately, but it might take a few minutes until the subnet is deleted and no longer appears in the list query results.\n\n\n\n\n\n\n\n Step 3: Delete all public gateways in the VPC, if any \n\nTo list all public gateways in your account, run the following command:\n\nibmcloud is public-gateways\n\nFor each public gateway in the VPC you want to delete, run the following command to delete the public gateway, where $gateway is the public gateway ID.\n\nibmcloud is public-gateway-delete $gateway\n\n\n\n\n\n Step 4: Delete the VPC \n\nAfter all subnets and public gateways in the VPC are deleted, run the following command to delete the VPC, where $vpc is the ID of the VPC you are deleting.\n\nibmcloud is vpc-delete $vpc\n\nThe status of the VPC changes to deleting immediately, but it might take a few minutes until the VPC is deleted and no longer appears in the list query results.\n\n\n\n\n\n\n\n Deleting a VPC by using the REST APIs", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-deleting-vpc-resources"}, {"document_id": "ibmcld_16666-11924-13606", "score": 16.809282010484054, "text": "\nFor the steps to perform ingestion, see the [Ingesting data through the command-line interface (CLI)](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-ingest_data_cli)\n\n\n\n\n\n Step 7: Querying data \n\nIn this section of the tutorial, you learn how to navigate to the Query workspace, and create SQL queries to query your data from the bucket.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Select a catalog, for example, default schema, and a table, for example, order_detail, to run the query.\n4. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.\n* For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n* For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\nConsider the following sample query to view the details from the table:\n\nExample:\n\n!/bin/bash\nSELECT * FROM \"iceberg-beta\".\"default\".\"order_detail\" LIMIT 10;\n5. Click Run on to run the query.\n6. Select Result set or Details tab to view the results. If required, you can save the query.\n7. Click Saved queries to view the saved queries.\n8. Click [Explain](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n Step 8: Keep exploring \n\n\n\n1. Explore the other tutorials in the documentation.\n2. Monitor the promo code consumption to decide whether to buy, build on (default), decline or manually delete your instance.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-tutorial_hp_intro"}, {"document_id": "ibmcld_16670-5968-7639", "score": 16.54172050900066, "text": "\nYou must link the Db2 and Netezza databases to the Presto engine that is used to process the data.\n\nTo associate Db2 with the Presto engine, do the following steps:\n\n\n\n1. From the Infrastructure manager, select Db2 database. Click the overflow menu icon at the end of the row and click Associate.\n2. In the Associate with engine form, select the Presto engine that you want to use to process the data.\n3. Click Associate and restart engine. The Db2 database is associated with the Presto engine.\n\n\n\nSimilarly, select the Netezza database and link it to the Presto engine.\n\n\n\n\n\n Step 6: Combine data \n\nYou can also navigate to the Query workspace to create SQL queries to query your data.\n\nTo run the SQL query to join two tables, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.\n* For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n* For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\nConsider the following sample query to join the details from Db2 and Netezza:\n\nExample:\n\n!/bin/bash\nSELECT * FROM \"Db2\".\"default\".\"order_detail\" AS details\nLEFT JOIN \"Netezza\".\"gosales\".\"order_detail\" AS header\nON details.order_number=header.order_number\nLIMIT 10;\n4. Click the Run on button to run the query.\n5. Select Result set or Details tab to view the combined result. If required, you can save the query.\n6. Click Saved queries to view the saved queries.\n7.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-tutorial_join_data"}, {"document_id": "ibmcld_02522-7188-8827", "score": 16.380177355280388, "text": "\nWhen the Data Engine query UI opens, a COS bucket is automatically generated. This bucket is used by default by the Data Engine service to store the results from your SQL queries.\n\nWen you run queries, you can specify a custom bucket to store results in. If your query does not specify one, the default one is used.\n\n\n\n\n\n Step 3.2. Get information on the file that you want to query in COS \n\nComplete the following steps:\n\n\n\n1. In the IBM Cloud dashboard, click the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/6f3c07c34058f637b1c86044ca4f9b24214330a7/icons/icon_hamburger.svg) > Resource list > Storage.\n2. Select the Data Engine instance that has the bucket with the archive files.\n\nContact your IBM Cloud Activity Tracker administrator to get the COS information.\n3. Select Buckets.\n4. Select the bucket name. You can see the list of archive files in the bucket.\n5. Identify the file that you want to query.\n\nNotice that the file name has the name of your IBM Cloud Activity Tracker instance and the date, in UTC format, of the events that are included.\n\nIf you get a file of 20 bytes, that file does not have any data.\n6. For that file, select SQL URL.\n\nA window opens that shows the URL.\n7. Copy the URL.\n\n\n\n\n\n\n\n Step 3.3. Get information on the COS bucket that is used to store results from queries \n\nComplete the following steps:\n\n\n\n1. In the COS instance UI, select Buckets.\n2. Select the bucket name that you plan to use to store the results from queries.\n3. For that bucket, select SQL URL.\n\nA window opens that shows the URL.\n4. Copy the URL.\n\n\n\n\n\n\n\n Step 3.4. Transform an archive file to PARQUET format", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-sqlquery"}, {"document_id": "ibmcld_02547-1335-2984", "score": 16.3654034205056, "text": "\nSelect Everything to see all the events, or a view.\n\n\n\nYou can view events through the view that you have selected.\n\n\n\n\n\n View a subset of the events by applying a search query \n\nYou can select the events that are displayed through a view by applying a search query. You can save that view for reuse later. [Learn more](https://cloud.ibm.com/docs/services/activity-tracker?topic=activity-tracker-viewsviews_step2).\n\n\n\n\n\n View a subset of the events by applying a timeframe \n\nYou can select the events that are displayed through a view by applying a timeframe.\n\nYou can apply a timestamp by specifying an absolute time, a relative time, or a time range.\n\nComplete the following steps to jump to a specific time:\n\n\n\n1. [Go to the web UI](https://cloud.ibm.com/docs/services/activity-tracker?topic=activity-tracker-launchlaunch).\n2. Click the Views icon ![Views icon](https://cloud.ibm.com/docs-content/v1/content/6f3c07c34058f637b1c86044ca4f9b24214330a7/activity-tracker/images/views.png).\n3. Select Everything or a view.\n4. Enter a time query. Choose any of the following options:\n\n\n\n* Enter an abosute time to jump to a point in time in your events such as May 20 7:00pm.\n* Enter a relative time such as 2 days ago, today at 12am, or an hour ago.\n* Enter a time range such as yesterday 10am to yesterday 11am, last fri 4:30pm to 11/12 1 AM, last wed 4:30pm to 23/05 1 AM, or May 20 10am to May 22 10am. Make sure to include to to separate the initial timestamp from the end timestamp.\n\n\n\n5. Press ENTER.\n\nYou might get the error message: Your request is taking longer than expected, try refreshing your browser in a bit as we try to catch up. Retry.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-view_events"}, {"document_id": "ibmcld_09437-7403-8993", "score": 15.961329665592224, "text": "\nAfter you log in with your user ID and password, the IBM Cloud dashboard opens.\n2. Click the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a/icons/icon_hamburger.svg) > Resource list > Services.\n3. Select an Data Engine instance.\n4. From the Manage tab, select Launch Data Engine UI.\n\n\n\nWhen the Data Engine query UI opens, a COS bucket is automatically generated. This bucket is used by default by the Data Engine service to store the results from your SQL queries.\n\nWen you run queries, you can specify a custom bucket to store results in. If your query does not specify one, the default one is used.\n\n\n\n\n\n Step 3.2. Get information on the file that you want to query in COS \n\nComplete the following steps:\n\n\n\n1. In the IBM Cloud dashboard, click the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/f61dbc5d84bf0c89e477a05cab04c72f429e1b7a/icons/icon_hamburger.svg) > Resource list > Storage.\n2. Select the Data Engine instance that has the bucket with the archive files.\n\nContact your Log Analysis administrator to get the COS information.\n3. Select Buckets.\n4. Select the bucket name. You can see the list of archive files in the bucket.\n5. Identify the file that you want to query.\n\nNotice that the file name has the ID of your Log Analysis instance and the date, in UTC format.\n6. For that file, copy the Object Data Engine URL.\n\n\n\n\n\n\n\n Step 3.3. Get information on the COS bucket that is used to store results from queries \n\nComplete the following steps:\n\n\n\n1. In the COS instance UI, select Buckets.", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-sqlquery"}, {"document_id": "ibmcld_02522-8519-10234", "score": 15.906644440017693, "text": "\nComplete the following steps:\n\n\n\n1. In the COS instance UI, select Buckets.\n2. Select the bucket name that you plan to use to store the results from queries.\n3. For that bucket, select SQL URL.\n\nA window opens that shows the URL.\n4. Copy the URL.\n\n\n\n\n\n\n\n Step 3.4. Transform an archive file to PARQUET format \n\nWhen you query an archive file, the format of the data is JSON. You must transform the format to PARQUET to query successfully the data.\n\nParquet is an open source file format that stores nested data structures into a flat columnar format, and preserves the schema of the original data.\n\nThe Data Engine UI is an editor that lets you immediately start composing SQL queries. Since SQL Query uses Spark SQL, you can use Spark SQL functions and ANSI SQL to compose both simple and complex queries that involve large amounts of data.\n\nComplete the following steps to run the query to transform content from JSON into PARQUET:\n\n\n\n1. In the SQL editor field of the Data Engine UI, enter the following SELECT statement:\n\nSELECT * FROM cleancols(SQL_URL STORED AS JSON)\nINTO RESULTS_BUCKET STORED AS PARQUET\n\nWhere\n\n\n\n* SQL_URL is the SQL URL of the archive file in COS\n* RESULTS_BUCKET is the SQL URL of the custom COS bucket that you plan to use to upload the query results\n* Use [cleancols](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference) to avoid transformation problems into PARQUET format when the name of the columns include special characters or blanks.\n\n\n\nFor example, the following query is used to transform an archive file:\n\nSELECT * FROM cleancols(cos://ams03/at-eu-de/999999d8f1f.2019-06-03.62.json.gz STORED AS JSON)\nINTO cos://eu-de/results-at STORED AS PARQUET\n2. Click Run.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-sqlquery"}, {"document_id": "ibmcld_02522-5994-7615", "score": 15.610872916811704, "text": "\nChoose any of the following actions to manage IAM policies in the IBM Cloud:\n\n\n\n* To grant permissions to a user, see [Assigning access](https://cloud.ibm.com/docs/account?topic=account-assign-access-resourcesassign-new-access).\n* To revoke permissions, see [Removing access](https://cloud.ibm.com/docs/account?topic=account-assign-access-resourcesremoving-access-console)).\n* To review a user's permissions, see [Reviewing your assigned access](https://cloud.ibm.com/docs/account?topic=account-assign-access-resourcesreview-your-access-console).\n\n\n\n\n\n\n\n Step 3. Running a query through the Data Engine UI \n\nIn SQL, the term query is just another way of saying SELECT statement.\n\nTo run a query, complete the following steps:\n\n\n\n Step 3.1. Launch the Data Engine query UI \n\n\n\n1. [Log in to your IBM Cloud account](https://cloud.ibm.com/login).\n\nAfter you log in with your user ID and password, the IBM Cloud dashboard opens.\n2. Click the Menu icon ![Menu icon](https://cloud.ibm.com/docs-content/v1/content/6f3c07c34058f637b1c86044ca4f9b24214330a7/icons/icon_hamburger.svg) > Resource list > Services.\n3. Select an Data Engine instance.\n4. From the Manage tab, select Launch Data Engine UI.\n\n\n\nWhen the Data Engine query UI opens, a COS bucket is automatically generated. This bucket is used by default by the Data Engine service to store the results from your SQL queries.\n\nWen you run queries, you can specify a custom bucket to store results in. If your query does not specify one, the default one is used.\n\n\n\n\n\n Step 3.2. Get information on the file that you want to query in COS \n\nComplete the following steps:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-sqlquery"}, {"document_id": "ibmcld_16671-4467-6313", "score": 15.55756838211273, "text": "\nWhen you register your own bucket, ensure to provide the correct details for bucket configuration. Quick start wizard does not validate the bucket configuration details and you cannot modify them later.\n\nEnsure that the data bucket contains data.\n2. Click Next. This displays the Catalogs configuration page.\n3. In the Catalogs configuration page, select Apache Iceberg.\n4. Click Next. This displays the Engine configuration page.\n5. In the Engine configuration page, select the engine type and size.\n\nDepending on the workload that you have, you can select the type and size of the Presto engine.\n6. Click Next. This displays the Summary page.\n7. In the Summary page, review the configurations before you finish setting up your data infrastructure.\n\nWhen the setup is complete, the watsonx.data home page is displayed. You are all set to use the watsonx.data or you can configure it further.\n8. Click Finish and go. This displays the Infrastructure manager page.\n\n\n\nYou can add more engines, catalogs, buckets, and databases in the Infrastructure manager page if you want to. For more information about creating engines, catalogs, buckets, databases, see Configuring watsonx.data components in the How To section.\n\n--------------------\n\n\n\n\n\n Step 4: Querying data \n\nIn this section of the tutorial, you learn how to navigate to the Query workspace, and create SQL queries to query your data from the bucket.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1. From the navigation menu, select SQL. The Query workspace page opens.\n2. Select the Presto engine from the Engine drop-down.\n3. Select the catalog. In this scenario, consider the Apache Iceberg catalog, default schema, order_detail table, to run the query.\n4. Click the overflow menu and select the required query.\n\n\n\n* For a catalog and schema, you can run the Generate Path query.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-tutorial_prov_custbckt"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-47319-49349", "score": 24.2632984714923, "text": "\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https://cloud.ibm.com/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-47304-49334", "score": 24.2632984714923, "text": "\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n* What pricing plan do I need to use the service's customization interface?\n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n* How do I upgrade from the Lite plan to the Plus plan?\n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https://cloud.ibm.com/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n* What does \"pricing per minute\" mean?\n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_13336-7-1965", "score": 23.545708564263936, "text": "\nPricing FAQs \n\nIBM Cloud\n\nThe IBM Watson\u00ae Speech to Text service is available at three pricing plans: Lite, Plus, and Premium. The following FAQs provide an overview of the pricing plans. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text).\n\nThe Standard plan is no longer available for purchase by users. The Standard plan continues to be available to its existing users indefinitely. For more information, see [Can I continue to use the Speech to Text Standard plan?](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-faq-pricingfaq-pricing-standard) For new users, read about the new Plus and Premium plans below.\n\n\n\n What is the price for using the Speech to Text Lite plan? \n\nThe Lite plan lets you get started with 500 minutes per month of speech recognition at no cost. You can use any available model for speech recognition. The Lite plan does not provide access to customization. You must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.\n\n\n\n\n\n What is the price for using the Speech to Text Plus plan? \n\nThe Plus plan provides access to all of the service's features:\n\n\n\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-faq-pricing"}, {"document_id": "ibmcld_13336-3083-5168", "score": 23.137216271364956, "text": "\nAnd, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n\n\n\n\n\n What pricing plan do I need to use the service's customization interface? \n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n\n\n\n\n\n How do I upgrade from the Lite plan to the Plus plan? \n\nYou can upgrade from the Lite plan to the Plus plan, for example, to gain access to customization. To upgrade from the Lite plan to the Plus plan, use the Upgrade button in the resource catalog page for your service instance:\n\n\n\n* From the [resource list](https://cloud.ibm.com/resources), click on your Speech to Text instance to go to the Speech to Text dashboard page.\n* From the Manage page, click Upgrade to move to the Plus plan.\n* Follow the steps on the Plan page to complete your upgrade.\n\n\n\n\n\n\n\n What does \"pricing per minute\" mean? \n\nFor the Plus plan, pricing is based on the cumulative amount (number of minutes) of audio that you send to the service in any one month. The per-minute price of all audio that you recognize in a month is reduced once you reach the threshold of one million minutes of audio for that month. The price does not depend on how long the service takes to process the audio. (Per-minute pricing is different for the Standard plan.)\n\nFor information about pricing for the Plus and Standard plans, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text).\n\n\n\n\n\n Do you round up to the nearest minute for every call to the API? \n\nIBM does not round up the length of the audio for every API call that the service receives. Instead, IBM aggregates all usage for the month and rounds to the nearest minute at the end of the month. For example, if you send two audio files that are each 30 seconds long, IBM sums the duration of the total audio for that month to one minute.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-faq-pricing"}, {"document_id": "ibmcld_07578-503127-505414", "score": 22.739586196634818, "text": "\nSelect a Pricing plan.\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a Resource group.\n7. Optional: Add Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key: value pairs to help group-related tags, such as costctr: 124.\n8. Optional: Add Access management tags that helps you apply flexible access policies on specific resources.\n9. Accept the licensing agreements and terms by clicking the checkbox.\n10. Click Create. A new service instance is created and the App Configuration service console displayed.\n\n\n\n* What pricing plans are available with App Configuration?\n\nApp Configuration has three pricing plans:\n\n\n\nTable 1. Pricing plans\n\n Plan Inclusions Capabilities \n\n Lite This plan is a free evaluation plan that includes 10 active entity IDs and 5,000 API calls. <br>Lite plan services are deleted after 30 days of inactivity. Includes all App Configuration capabilities for evaluation only. Not to be used for production. \n Standard The monthly instance price includes 1000 active entity IDs and 100,000 API calls. This plan includes feature flags in addition to the property management capabilities. \n Enterprise The monthly instance price includes 10,000 active entity IDs and 1,000,000 API calls. This plan includes percentage rollout and targeting segments in addition to property management and feature flags that are found in the Standard plan. \n\n\n\n* What are the charges to use App Configuration?\n\nThe fundamental pricing metrics for App Configuration are Application Instance, Active Entity ID, and API Call.\n\nApplication Instance - An Application Instance is a uniquely named copy of App Configuration created by you but managed by IBM. Multiple instances of App Configuration within a single environment are all considered separate application instances, as are individual App Configuration instances in multiple environments (such as test, development, staging, or production).\n\nA single instance of App Configuration can serve multiple environments, and in fact the service is designed to do so.\n\nActive Entity ID - An active entity ID is a unique identifier for each entity that interacts with the App Configuration service.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-503069-505356", "score": 22.739586196634818, "text": "\nSelect a Pricing plan.\n5. Configure your resource by providing a Service name for your instance, or use the preset name.\n6. Select a Resource group.\n7. Optional: Add Tags to help you to identify and organize the instance in your account. If your tags are billing related, consider writing tags as key: value pairs to help group-related tags, such as costctr: 124.\n8. Optional: Add Access management tags that helps you apply flexible access policies on specific resources.\n9. Accept the licensing agreements and terms by clicking the checkbox.\n10. Click Create. A new service instance is created and the App Configuration service console displayed.\n\n\n\n* What pricing plans are available with App Configuration?\n\nApp Configuration has three pricing plans:\n\n\n\nTable 1. Pricing plans\n\n Plan Inclusions Capabilities \n\n Lite This plan is a free evaluation plan that includes 10 active entity IDs and 5,000 API calls. <br>Lite plan services are deleted after 30 days of inactivity. Includes all App Configuration capabilities for evaluation only. Not to be used for production. \n Standard The monthly instance price includes 1000 active entity IDs and 100,000 API calls. This plan includes feature flags in addition to the property management capabilities. \n Enterprise The monthly instance price includes 10,000 active entity IDs and 1,000,000 API calls. This plan includes percentage rollout and targeting segments in addition to property management and feature flags that are found in the Standard plan. \n\n\n\n* What are the charges to use App Configuration?\n\nThe fundamental pricing metrics for App Configuration are Application Instance, Active Entity ID, and API Call.\n\nApplication Instance - An Application Instance is a uniquely named copy of App Configuration created by you but managed by IBM. Multiple instances of App Configuration within a single environment are all considered separate application instances, as are individual App Configuration instances in multiple environments (such as test, development, staging, or production).\n\nA single instance of App Configuration can serve multiple environments, and in fact the service is designed to do so.\n\nActive Entity ID - An active entity ID is a unique identifier for each entity that interacts with the App Configuration service.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_12824-7-1978", "score": 22.49664274708593, "text": "\nFAQs for migrated products \n\nFAQs about products that are migrated from the Resource Management Console might include questions about Lite plans, changing pricing plans, and brokers connected to approved pricing plans.\n\nTo find all FAQs for IBM Cloud, see our [FAQ library](https://cloud.ibm.com/docs/faqs).\n\n\n\n Why can't I add new block tier usage-based plans? \n\nBlock tier pricing plans are not currently supported in Partner Center. If you set up a block tier pricing plan in the Resource Management Console and the plan was approved and published, no changes have been made and it was migrated as-is with your product. However, you can't edit the plan or set up a new block tier pricing plan. If you have any questions, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https://cloud.ibm.com/docs/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n What changed with Lite plan support? \n\nLite plans are not supported in Partner Center. You can create a new free plan, and all users with Pay-As-You-Go and Subscription accounts can try out your product for free.\n\nIf you set up a Lite plan in the resource management console, and it was approved and published, no changes have been made and it was migrated as-is with your product. If you need to change a published pricing plan, open a support case. For information about opening a support case, see [Creating a Partner Center support case](https://cloud.ibm.com/docs/sell?topic=sell-get-pc-supportpc-support-case).\n\n\n\n\n\n Can I add a broker per location? \n\nNo. Brokers are added per pricing plan, not per location. And, brokers can't be disconnected from already approved plans.\n\n\n\n\n\n Can I set different locations per plan for a single product? \n\nYes. But, all plans for a single product must be set as either global or per location. Therefore, you can't have a plan that is set to global and then another plan set to be available for specific regions.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-migrated-products"}, {"document_id": "ibmcld_07214-60873-63067", "score": 22.326745560078475, "text": "\nThese queries can be used as a starting point for writing your own queries. Sample queries are available for both IBM Watson\u2122 Discovery News and private collections.\n\nNew beta visual aggregation builder : Added the beta ability to write aggregations with a visual builder. Click Build in visual mode above the Write an aggregation query using the Discovery Query Language field to try it out. As you build your aggregation visually, the query displays in the Discovery Query Language below it.\n: The visual aggregation builder is currently supported only as a beta capability.\n\n\n\n\n\n 31 July 2017 \n\nNew release of Discovery News : A new version of IBM Watson\u2122 Discovery News was released. The original version is renamed as IBM Watson\u2122 Discovery News Original and is retired, with a removal from service date of 15 January 2018. : If you create a new instance of Discovery, you only have access to the new version of IBM Watson\u2122 Discovery News.\n\nNew pricing structure : A new pricing plan for IBM Watson\u2122 Discovery was released. See [Discovery pricing plans](https://cloud.ibm.com/docs/discovery?topic=discovery-discovery-pricing-plans) for details.\n\nUpdate to version string : The version string for all API calls changed to 2017-08-01 from 2017-07-19. This version includes updates for the new pricing plan and the new version of Watson Discovery News. Update the version string to avoid conflicts and possible errors.\n\n\n\n\n\n 19 July 2017 \n\nChange to Pricing plans : Pricing changes will take effect on 1 August 2017. : Users that are currently on the deprecated 30 day free trial plan will be automatically migrated to the Lite plan. As a result of this transition, existing users might meet or exceed the lite plan limit on documents (2000), storage (200Mb), or number of collections (2). If you exceed the limit of the Lite plan, you cannot add any additional content into the service, but you can still query collections. : View the current status of all these limits by using the Discovery tooling or API. To resume adding content to the Discovery instance, you must complete one of the following actions: : Remove collections or documents so that limits of the Lite plan are not exceeded.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-release-notes"}, {"document_id": "ibmcld_03729-1672-3956", "score": 22.199271457924283, "text": "\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_00558-2925-4840", "score": 22.17702468173429, "text": "\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service. To create a new instance, either delete your existing Lite plan instance or select a paid plan.\n\n\n\n\n\n Standard plan \n\nThe IBM Cloudant Standard plan is available to all paid IBM Cloud\u00ae accounts, either as pay-as-you-go or subscription, and scales to meet the needs of your application. The Standard plan is priced based on two factors: the provisioned throughput capacity that is allocated, and the amount of data that is stored in the instance.\n\nPricing is pro-rated hourly with a starting provisioned throughput capacity of 100 reads per second, 50 writes per second, and 5 global queries per second. This rate is equal to a starting cost of USD $0.105 per hour. You can toggle the provisioned throughput capacity up or down by using the user interface or API. Toggle in increments of 100 reads per second, 50 writes per second, and 5 global queries per second. Costs are calculated for the provisioned throughput capacity that is allocated and not on the metered volume of requests. The Standard plan includes 20 GB of data storage. If you store more than 20 GB, you're charged a defined cost per GB per hour.\n\nRefer to the IBM Cloud Pricing Calculator in the dashboard for pricing at different capacities and currencies, and the [pricing](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-pricingpricing) information for examples to estimate costs.\n\n\n\n\n\n Dedicated Hardware plan", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-public"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>11", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03713-1710-3705", "score": 44.19499251291814, "text": "\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-3269-5168", "score": 40.97005333872684, "text": "\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-7-2194", "score": 38.22070108375017, "text": "\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-4689-6647", "score": 32.832554436115174, "text": "\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https://cloud.ibm.com/docs/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-7896-8949", "score": 31.57142335924045, "text": "\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https://cloud.ibm.com/billing/payments). Credit card transactions are automatically retried within 24 hours after you update the information.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03704-1531-3564", "score": 30.880219024950044, "text": "\nWhat's the difference between a Pay-As-You-Go and Subscription account? \n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accounts).\n\n\n\n\n\n What happens if my Lite plan instance reaches the monthly quota? \n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n\n\n\n\n\n Can I use PayPal as a payment method? \n\nAs of March 31, 2023, PayPal is no longer accepted.\n\n\n\n\n\n Can I update my credit card? \n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card. For more information, see [How do I add a credit card when the option isn't available through the console?]", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_03799-0-731", "score": 30.27655021550393, "text": "\n\n\n\n\n\n\n  Why can't I update my billing address? \n\nYou can't update the billing address for a credit card in the IBM Cloud console. You must contact support to update the billing address on an existing credit card.\n\n  What\u2019s happening \n\nWhen you try update your payment details, you can't update the billing address for the credit card.\n\n  Why it\u2019s happening \n\nOn the [Payment methods page](https://cloud.ibm.com/billing/payments), you can't edit the billing address in the IBM Cloud Console.\n\n  How to fix it \n\nTo update the billing address for a credit card, go to [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter). Depending on your level of support, you can chat with a support agent or open a case.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-update-billing-address"}, {"document_id": "ibmcld_03782-0-720", "score": 29.87663265194167, "text": "\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-section-error"}, {"document_id": "ibmcld_07578-1042894-1044946", "score": 29.707372034911643, "text": "\nContact an [IBM Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1042765-1044817", "score": 29.707372034911643, "text": "\nContact an [IBM Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) representative to request a quote for additional server bandwidth.\n* What's the difference between a Pay-As-You-Go and Subscription account?\n\nWith Pay-As-You-Go accounts, you're billed monthly for your resource usage. Your resource usage consists of recurring and fluctuating costs. This account type is a good fit for developers or companies that want to explore the entire IBM Cloud catalog but have smaller or variable workloads. You pay only for what you use or commit to on a monthly basis, with no long-term contracts. Usage consists of products, services, and resources.\n\nWith Subscription accounts, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For more information about the differences between account types, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accounts).\n* What happens if my Lite plan instance reaches the monthly quota?\n\nWhen you reach any quota for Lite plan instances, the service for that month is suspended. Quotas are based per org and not per instance. New instances that are created in the same org show any usage from previous instances. The quota resets on the first of every month.\n* Can I use PayPal as a payment method?\n\nAs of March 31, 2023, PayPal is no longer accepted.\n* Can I update my credit card?\n\nUpdating your credit card is just like adding a new one. Go to the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console. In the Add Payment Method section, enter the billing information for your new card, and click Add credit card.\n\nTo switch to a different payment method, select Pay with Other, and click Submit change request. A support case to change your payment method is then created for you.\n\nIf your payments are managed outside of the console, go to IBM.com and log in to the Manage Payment Method application to update your credit card.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03363-4-2165", "score": 29.667528756024314, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Metrics overview \n\nThe overview page provides a summary of the interactions between users and your assistant.\n\nAnalytics help you to understand the following things:\n\n\n\n* What do customers want help with today?\n* Is your assistant understanding and addressing customer needs?\n* How can you make your assistant better?\n\n\n\nTo see metrics information, select Overview in the navigation bar. The information in Analytics is not immediately updated after a user interacts with your assistant. Watson Assistant prepares the data for Analytics in the background.\n\nAfter the numbers in metrics hit the 3,000 and above range, the totals are approximated to prevent performance lags in the page.\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period. The total conversations metric and the User conversations page only include conversations in which both the assistant and customer participate. Conversations that only have welcome messages from the assistant, or that only have user messages of zero length, are not included. This metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_03036-4322-6185", "score": 27.413264260084055, "text": "\nper conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_03363-1671-3630", "score": 27.153909569740385, "text": "\nAn exchange with a user is not considered a billable conversation until the customer submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information. Click a data point on the graphs to see more detail.\n\n![Single data point](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/oview-point.png)\n\n\n\n* Containment: Number of conversations in which the assistant is able to satisfy the customer's request without human intervention.\n\n\n\n* The volume graph shows the total number of conversations per day and how many of the conversations were contained and not contained.\n* The trend graph shows the percentage of daily conversations that were contained. This graph helps you to see if the assistant is getting better or worse at containing conversations over time.\n\n\n\n![Shows the two containment metrics for volume and trend](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/containment-metric.png)\n\nThe containment metric requires that your dialog flag requests for external support when they occur. For more information, see [Measuring containment](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-supportdialog-support-containment).\n* Coverage: Number of conversations in which the assistant is confident that it can address a customer's request.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-overview"}, {"document_id": "ibmcld_03036-2789-4951", "score": 26.364443122315055, "text": "\nIf you have [selected a data source](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_14503-4971-7126", "score": 23.70796496402683, "text": "\nThe client can also configure their compute VMs to uses these forwarders, if required.\n* VMware Update Manager (VUM) provides updating of vSphere hosts and VM hardware and tools. VUM uses the Proxy to gain access to the internet repositories.\n\n\n\nVMware Aria Operations collects data from objects in the environment. Each piece of data that is collected is called a metric observation or value. VMware Aria Operations uses the vCenter adapter to collect raw metrics from vCenter. In addition to the metrics it collects, VMware Aria Operations calculates capacity metrics, badge metrics, and metrics to monitor the health of your system. Alert definitions are a combination of symptoms and recommendations that identify problem areas and generate alerts on which you act for those areas.\n\n\n\n\n\n Monitored components \n\n\n\n Monitoring of vCenter \n\nThe monitoring of vCenter is accomplished with VMware Aria Operations and the VMware SDDC Health Management Pack. VMware Aria Operations for Logs collects the log data from vCenter and the Content Pack for vSphere adds specific understanding to the logs and in turn sends alerts to VMware Aria Operations.\n\nThe VMware SDDC Health Management Pack monitors the SDDC Management stack and provides badges for health and alerts related to configuration and compliance of SDDC product components that include vCenter.\n\n\n\n\n\n Monitoring of vSphere hosts \n\nMonitoring of the vSphere hosts is accomplished with VMware Aria Operations through vCenter and the collection of logs through VMware Aria Operations for Logs.\n\n\n\n\n\n Monitoring of vSAN \n\nTo monitor vSAN, VMware Aria Operations, and VMware Aria Operations for Logs are used. In vCenter, you can use an extra set of vSAN Health Checks. Installation of the Management Pack for vSAN provides more dashboards to aid with the monitoring of vSAN.\n\nVMware Aria Operations generates an alert if a problem occurs in the SDDC product components in the storage area network that the VMware vSAN adapter is monitoring. An alert that is related to configuration compliance and health is passed through VMware SDDC Health Solution management pack from VMware vSAN Management Pack.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-opsmgmt-arch"}, {"document_id": "ibmcld_14510-3279-5082", "score": 23.031941919210304, "text": "\n* Preconfigured vSphere alarms - The vSphere event and alarm subsystem has a number of default alarms, which monitor the operations of vSphere inventory objects. You must set up actions only for these alarms.\n\n\n\n\n\n\n\n\n\n Alarm setup workflow \n\nVMware provides preconfigured vCenter alarms that are described in the following tables, but they are set with an action to display within the vCenter web client only. Configure the SMTP server details and then set the alert actions to send an email to the system administrators for the following alarms only initially so not to inundate the system administrator team. For more information, see [Send email as an alarm action](https://docs.vmware.com/en/VMware-vSphere/6.7/com.vmware.vsphere.monitoring.doc/GUID-1F940DAF-933B-44B7-A200-7A11B5D3E3D5.html).\n\nThe setting alarms workflow is as follows.\n\n\n\n* Configure the SMTP server details.\n* Configure the alert actions for clusters, hosts, datastores, and critical virtual appliances, such as vCenter Server Appliance, PSC, NSX Manager, and controllers.\n\n\n\n* Cluster - a VMware High Availability error.\n* Hosts - CPU status, memory status, storage status, hardware status that is, voltage, temperature, or power status changes.\n* Datastore - low on free disk space.\n* Critical virtual appliance - CPU usage, memory usage, disk latency\n\n\n\n* Use the proactive daily task to review the following information.\n\n\n\n* Review the alerts sent - are the alerts required?\n* Review the alerts that weren't sent - do you need to know about them?\n* Review the metrics - are the metrics correct? For example, confirm that CPU usage must be set to 75% rather than 90% now that you understand your baseline.\n* Do you need to configure your own alarms?\n* Do you need to include virtual machines?\n\n\n\n\n\n\n\n\n\n Typical alarm workflow", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-opsprocs-alarms"}, {"document_id": "ibmcld_09148-8939-9806", "score": 22.729666444972274, "text": "\nTo setup a metric, complete the follow steps.\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert at the top of the page.\n3. Select Metric as the alert type.\n4. Select the aggregation and the metric that you would like to be performed on.\n5. Select the scope if applicable.\n6. Set the metric and time requirements for the alert to trigger.\n7. Configure and set up the notification channel and notification interval.\n8. Click the CREATE button.\n\n\n\nThe figure as shown provides an example of how to configure an alert when your service instance receives multiple 401 and 403 errors within a 10 minute time span.\n\nZoom\n\n![An example of a 401 and 403 configuration.](https://cloud.ibm.com/docs-content/v1/content/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc/key-protect/images/monitor-401-alert.png)\n\nFigure 5. The configuration for a 401 alert in a Monitoring dashboard.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-operational-metrics"}, {"document_id": "ibmcld_09148-7815-9285", "score": 22.513084644389018, "text": "\n(https://cloud.ibm.com/docs-content/v1/content/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc/key-protect/images/monitor-dashboard-menu.png)\n\nFigure 2. The dashboard menu that lists the dashboards in your Monitoring instances.\n\nBelow are figures that show the metric views available to you on the default dashboard.\n\nZoom\n\n![An example of a Key Protect metrics dashboard.](https://cloud.ibm.com/docs-content/v1/content/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc/key-protect/images/monitor-operation-dash1.png)\n\nFigure 3. Some of the metrics available on the Monitoring dashboard.\n\nZoom\n\n![An example of a Key Protect dashboard view.](https://cloud.ibm.com/docs-content/v1/content/0bc8db34a3d90b2a5103c9c71b08a96de9525bbc/key-protect/images/monitor-operation-view2.png)\n\nFigure 4. Some of the metrics available on the Monitoring dashboard.\n\nYou will not be able to see any metrics in your Monitoring instance until you enable a metrics policy for your Key Protect instance and make API requests to your Key Protect instance.\n\n\n\n\n\n\n\n Setting Alerts \n\nYou can set alerts on your Monitoring dashboard to notify you of certain metrics.\n\nTo setup a metric, complete the follow steps.\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert at the top of the page.\n3. Select Metric as the alert type.\n4. Select the aggregation and the metric that you would like to be performed on.\n5. Select the scope if applicable.\n6. Set the metric and time requirements for the alert to trigger.\n7.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-operational-metrics"}, {"document_id": "ibmcld_09685-5899-7847", "score": 21.98266833741025, "text": "\nFor more information, see [Collecting metrics](https://cloud.ibm.com/docs/monitoring?topic=monitoring-about-collect-metrics).\n\n\n\n\n\n Sending metrics \n\nYou can send metrics via the public or the private endpoints by using the appropriate ingestion URL. Details can be found in the [endpoints](https://cloud.ibm.com/docs/monitoring?topic=monitoring-endpointsendpoints) section.\n\n\n\n\n\n Viewing metrics \n\nYou can monitor and manage metrics through the Monitoring Web UI. For more information, see [Viewing metrics](https://cloud.ibm.com/docs/monitoring?topic=monitoring-monitoring).\n\nNotice that there is a delay showing metric data for new time series. Data is not ready until the initial indexing of a new metric source is completed. Therefore, new sources such as clusters, platform metrics, or systems that you configure, all take some time to become visible through the Monitoring UI.\n\n\n\n\n\n Sending notifications \n\nYou can configure single alerts and multi-condition alerts to notify about problems that may require attention. When an alert is triggered, you can be notified through 1 or more notification channels. An alert definition can generate multi-channel notifications.\n\nAn alert is a notification event that you can use to warn about situations that require attention. Each alert has a severity status. This status informs you about the criticality of the information it reports on.\n\nFor example, you can set up Monitoring to send alert notifications to IBM Cloud Event Notifications.\n\n\n\n* [Sending email notifications to IBM Cloud Event Notifications](https://cloud.ibm.com/docs/monitoring?topic=monitoring-tutorial)\n* [Sending SMS notifications to IBM Cloud Event Notifications](https://cloud.ibm.com/docs/monitoring?topic=monitoring-tutorial-en-sms)\n\n\n\nFor more information, see [Working with alerts and events](https://cloud.ibm.com/docs/monitoring?topic=monitoring-alerts).\n\n\n\n\n\n Data location \n\nMetric data is hosted on the IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-about-monitor"}, {"document_id": "ibmcld_14510-4681-6664", "score": 21.98203205698584, "text": "\n* Review the alerts sent - are the alerts required?\n* Review the alerts that weren't sent - do you need to know about them?\n* Review the metrics - are the metrics correct? For example, confirm that CPU usage must be set to 75% rather than 90% now that you understand your baseline.\n* Do you need to configure your own alarms?\n* Do you need to include virtual machines?\n\n\n\n\n\n\n\n\n\n Typical alarm workflow \n\nAfter set-up, review the following example of an alarm workflow, typically adopted by system administrators, when an alarm is triggered.\n\n\n\n1. A host has an alarm set to monitor CPU usage and the alarm has an alarm action to send an email to the administrators when the alarm is triggered, as described in the previous section.\n2. The host CPU usage spikes, triggering the alarm, which sends an email to the administrators.\n3. One of the administrators logs in to vCenter and acknowledges the triggered alarm to allow the other administrators know the problem is being addressed, and to prevent the alarm from sending more email messages. However, the alarm is still visible in the system.\n4. The administrator finds the cause of the CPU spike and rectifies.\n5. The alarm is reset automatically.\n\n\n\n\n\n\n\n Preconfigured alarms - standard \n\n\n\n* Alarm name - The name of the alarm visible in vCenter.\n* Guidance - IBM Cloud for VMware Solutions guidance on the use of this alarm.\n* More Information - Additional information available from IBM or VMware to help with the resolution of these alarms when they are triggered.\n\n\n\nThe following table describes the standard preconfigured alarms.\n\n\n\nTable 1. Preconfigured alarms\n\n Alarm name Guidance Details \n\n Host connection and power state Configure to send email one time when set to Not Responding or Standby. [Alarms about the host connection state changing from green to red frequently occur (1020210)](https://kb.vmware.com/s/article/1020210) \n Host CPU usage Configure to send email one time when host CPU usage > 90% for 5 mins.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-opsprocs-alarms"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16487-4539-6619", "score": 27.70162491639962, "text": "\nAs another example, if a PDF document contains a very long word that is hyphenated at the end of a line, that word might be converted as two words. In cases like these, the documents might not be suitable for machine learning unless you pre-process the files to fix formatting limitations.\n\n\n\n\n\n Documents from another Watson Knowledge Studio workspace \n\nIf you previously downloaded documents from a Knowledge Studio workspace, you can upload the .zip file that you downloaded. An option lets you specify whether you want the ground truth annotations to be included in the imported files.\n\nAfter documents are annotated, the annotated documents are stored in JSON format. The markup language in these files, which shows how the original document text was parsed and tokenized, includes elements for all of the annotations that a human annotator added. To improve model accuracy over time, you can upload these files into another workspace, thus preserving all of the existing annotations. A human annotator can revise, delete, and add annotations to these documents, or you can bypass human annotation and use these files to create training, test, and blind document sets for evaluating and improving the model performance.\n\n\n\n\n\n UIMA CAS XMI files \n\nTo help train a model, you can upload documents that were pre-annotated by a UIMA analysis engine. The pre-annotated files must be in XMI serialization of UIMA Common Analysis Structure (UIMA CAS XMI) format and combined into a .zip file. For example, you can upload documents that were annotated in an IBM Watson Explorer collection.\n\nA human annotator can revise, delete, and add annotations to these documents, or you can bypass human annotation and use these files to create training, test, and blind document sets for evaluating and improving the model performance. For more information about how to create these files and requirements for uploading them, see [Uploading pre-annotated documents](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotationwks_uima).\n\n\n\n\n\n Anonymizing data", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotation"}, {"document_id": "ibmcld_16423-4898-6946", "score": 27.301967995970692, "text": "\nAn option lets you specify whether you want the ground truth annotations to be included in the imported files.\n\nAfter documents are annotated, the annotated documents are stored in JSON format. The markup language in these files, which shows how the original document text was parsed and tokenized, includes elements for all of the annotations that a human annotator added. To improve model accuracy over time, you can upload these files into another workspace, thus preserving all of the existing annotations. A human annotator can revise, delete, and add annotations to these documents, or you can bypass human annotation and use these files to create training, test, and blind document sets for evaluating and improving the model performance.\n\n\n\n\n\n UIMA CAS XMI files \n\nTo help train a model, you can upload documents that were pre-annotated by a UIMA analysis engine. The pre-annotated files must be in XMI serialization of UIMA Common Analysis Structure (UIMA CAS XMI) format and combined into a ZIP file. For example, you can upload documents that were annotated in an IBM Watson Explorer collection.\n\nA human annotator can revise, delete, and add annotations to these documents, or you can bypass human annotation and use these files to create training, test, and blind document sets for evaluating and improving the model performance. For details about how to create these files and requirements for uploading them, see [Uploading pre-annotated documents](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_uima).\n\n\n\n\n\n Anonymizing data \n\nIf you want to build a model that is optimized for your data, but do not want to upload the data as-is to Knowledge Studio for privacy reasons, you can strip the documents of any personally identifiable information (PII) first, and then use those anonymized documents to train the model. Do not redact the information or replace it wholesale with variables. For best results, replace the real information with fake information of the same type.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"}, {"document_id": "ibmcld_16468-3297-5708", "score": 26.50507568732473, "text": "\n* Involving domain subject matter experts to create the following resources, or to identify existing resources that can be re-used or modified for your domain:\n\n\n\n* Annotation guidelines and examples to help human annotators learn how words and passages in your domain content are to be annotated.\n* Type systems that define the domain-specific types (objects) and features (data classifications) that can be discovered in your domain content through text analysis. The type system controls the types of annotations that a human annotator can add to documents.\n* Dictionaries of terms that are to be treated as equivalent terms in your domain content.\n\n\n\n* Creating a corpus of documents that are representative of your domain content.\n* Pre-annotating documents based on the dictionaries that you add to a Knowledge Studio workspace. After you create a machine learning model, you can use the model to pre-annotate new documents that you add to the corpus. Pre-annotation is a process of machine-annotating a document to the extent possible before a machine learning model is available to do so. Pre-annotation can reduce human-annotation labor by replacing some human annotation creation with mere verification of the correctness of machine annotation.\n* Dividing documents among human annotators, who then use the IBM Watson\u00ae Knowledge Studio ground truth editor tool to manually add annotations to small sets of documents.\n* Comparing the human annotation results and resolving conflicts. Adjudication in this phase is needed to ensure accurate and consistently annotated documents are promoted to ground truth, where they can be used to train and test a machine learning model.\n\n\n\n\n\n\n\n Model development \n\nThis stage refers to the use of Knowledge Studio tools to create a model. After establishing ground truth, the human annotation results can be used to train an algorithm for automatically adding annotations to large collections of documents, such as collections that include millions of documents.\n\n\n\n\n\n Model evaluation \n\nThis stage refers to the use of Knowledge Studio tools to refine the model and improve performance. The results generated by the model are evaluated against a test set of ground truth documents. Accuracy analysis identifies the causes of annotation errors. Headroom analysis helps you assess which errors require focus and where model refinements can yield the greatest impact.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"}, {"document_id": "ibmcld_16516-12409-14637", "score": 26.37970221193338, "text": "\nAnnotation tasks Assets & Tools > Documents > Tasks Machine Learning Model > Annotation Tasks \n Coreferences tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Dictionaries page (management) Assets & Tools > Pre-annotators > Manage Dictionaries Assets \n Dictionaries tab (mapping to classes for rule-based model) Document Annotation Rule-based Model > Rules \n Documents page Assets & Tools Assets \n Entity Types page Assets & Tools Assets \n Mentions tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Performance page Model Management Machine Learning Model \n Pre-annotators page Assets & Tools Machine Learning Model > Pre-annotation \n Regex tab Document Annotation Rule-based Model > Rules \n Relation Types page Assets & Tools Assets \n Relations tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Rules tab Document Annotation Rule-based Model \n Tasks tab Assets & Tools > Documents Machine Learning Model > Annotation Tasks \n Versions page (machine learning model) Model Management Machine Learning Model \n Versions page (rule-based model) Model Management Rule-based Model \n\n\n\n\n\n\n\n\n\n May 2018 \n\n\n\n New features and changes \n\nConfiguration issue fixed\n: A configuration issue was fixed that caused service instances in Sydney region to not appear in US South region.\n\nDeploy Model window support changes\n: In the Deploy Model window, if the region you're deploying to supports both IBM Cloud\u00ae Identity and Access Management resource groups and Cloud Foundry spaces, to see the list, you will need to choose the method of access management that your service instance uses.\n\nData collection setting added\n: Added the data collection setting on the Service Details page. For more information about data collection, see [Troubleshooting, support, and FAQs](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-troubleshootingcontent)\n\nSupport for Chinese (Traditional)\n: Added Chinese (traditional) language support.\n\nAdministrators can see number of workspaces\n: Users who have the Admin role can now see the number of workspaces that are used.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-release-notes"}, {"document_id": "ibmcld_16552-2856-4585", "score": 25.956444691004894, "text": "\nYou can use the [documents-ml.csv](https://watson-developer-cloud.github.io/doc-tutorial-downloads/knowledge-studio/documents-ml.csv) file.\n\nFor more information about adding documents to a workspace, see [Adding documents for annotation](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotation).\n3. Create an annotation set that uses the documents-ml.csv file as the base set, and assign it to yourself, the administrator.\n\nAfter you complete the following steps to pre-annotate the new documents, you can view the annotation set to see how the machine learning model annotated the documents. Typically, you assign annotation sets to one or more human annotators. For more information about creating and assigning annotation sets, see [Adding documents for annotation](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotation).\n4. To pre-annotate the new documents:\n\n\n\n* On the Machine Learning Model > Pre-annotation page click Run Pre-annotators.\n* Select Machine Learning Model, then click Next.\n* Select the document set that you added to the corpus, documents-ml.csv, and click Run.\n\n\n\n5. After the pre-annotation is complete, create a human annotation task that includes the annotation set you created.\n\nFor more information about creating an annotation task, see [Annotation setup](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents).\n6. To view the annotations that were applied by the machine learning model to the new documents, open the annotation task.\n\nBecause the new documents were pre-annotated with the machine learning model, human annotation requires less time.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutboot_intro"}, {"document_id": "ibmcld_16463-4148-5042", "score": 25.76441814306859, "text": "\nAfter the pre-annotation is complete, create a human annotation task that includes the annotation set you created.\n\nFor more information about creating an annotation task, see [Annotation setup](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents).\n7. To view the annotations that were applied by the machine learning model to the new documents, open the annotation task.\n\nBecause the new documents were pre-annotated with the machine learning model, human annotation requires less time. For more information about adding annotations by human annotators, see [Annotating documents](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide).\n\n\n\n\n\n\n\n Results \n\nBy using your machine learning model to pre-annotate new document sets, you can expedite human annotation tasks for those documents.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutboot_intro"}, {"document_id": "ibmcld_16516-10835-12899", "score": 25.487468711430427, "text": "\n: In addition, the following functionality was reorganized:\n\n\n\n* In the previous version, management of dictionaries was included as part of the Pre-annotators page. Now, management of dictionaries is located on the Dictionaries page in the Assets section of the navigation.\n* In the previous version, human annotation functionality was distributed across the Mentions, Relations, and Coreferences tabs in the Document Annotation section of the navigation. Now, the functionality is merged under the Annotation Tasks page in the Machine Learning Model section of the navigation.\n* To manage human annotation tasks, in the previous version, you found the Tasks tab under the Assets & Tools > Documents page. Now, you add tasks and manage existing tasks on the Annotation Tasks page in the Machine Learning Model section of the navigation.\n* In the previous version, the Rules, Regex and Dictionaries pages were separate pages in the Document Annotation section of the navigation. Now, the functionality is merged under the Rules page in the Rule-based Model section of the navigation.\n\n\n\nFor more details about the navigation changes, see Figure 1 and Table 3.\n\n![Screen captures of the previous navigation (left side) and new navigation (right side).](https://cloud.ibm.com/docs-content/v1/content/50eddb8fd81f33092880335ff107a78ff5cd0f65/watson-knowledge-studio/images/nav3-0718.svg) Figure 1. Screen captures of the previous navigation (left side) and new navigation (right side).\n\n\n\nTable 3. Navigation changes (July 2018)\n\n Feature Previous location Current location \n\n Annotation tasks Assets & Tools > Documents > Tasks Machine Learning Model > Annotation Tasks \n Coreferences tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Dictionaries page (management) Assets & Tools > Pre-annotators > Manage Dictionaries Assets \n Dictionaries tab (mapping to classes for rule-based model) Document Annotation Rule-based Model > Rules \n Documents page Assets & Tools Assets \n Entity Types page Assets & Tools Assets", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-release-notes"}, {"document_id": "ibmcld_16552-4166-4924", "score": 25.46809093471621, "text": "\nFor more information about creating an annotation task, see [Annotation setup](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents).\n6. To view the annotations that were applied by the machine learning model to the new documents, open the annotation task.\n\nBecause the new documents were pre-annotated with the machine learning model, human annotation requires less time. For more information about adding annotations by human annotators, see [Annotating documents](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-user-guide).\n\n\n\n\n\n\n\n Results \n\nBy using your machine learning model to pre-annotate new document sets, you can expedite human annotation tasks for those documents.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutboot_intro"}, {"document_id": "ibmcld_16507-13849-15752", "score": 25.256149237001306, "text": "\nHowever, you can use the model to pre-annotate documents to help speed up the human annotation of subsequent documents. For example, if you add documents to the corpus after you train a machine learning model, you can use the model to pre-annotate the new document sets. Never run a pre-annotator on the same documents that have been annotated by a person. Pre-annotators remove human annotation.\n\n\n\n\n\n Procedure \n\nTo use an existing machine learning model to pre-annotate documents:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Go to the Machine Learning Model > Pre-annotation page.\n3. Click Run Pre-annotators.\n4. Select Machine Learning Model, and then click Next.\n5. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n6. Select the check box for each document set that you want to pre-annotate and click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets or annotation sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with the rule-based model \n\nYou can use an existing rule-based model to pre-annotate documents that you add to your corpus.\n\n\n\n Procedure \n\nTo use the rule-based model to pre-annotate documents, complete the following steps:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Go to the Machine Learning Model > Pre-annotation page.\n3. Click the overflow menu button in the Rule-based Model row in the page, then click Map entity types and classes to map entity types that you defined in the Knowledge Studio type system to one or more rule-based model classes.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_16507-12419-14261", "score": 25.134004407333038, "text": "\nAdd entries for the dictionary or upload a file that contains dictionary terms.\n6. Go to the Machine Learning Model > Pre-annotation page.\n7. Click Run Pre-annotators.\n8. Select Dictionaries, and then click Next.\n9. If you want to erase existing annotations made by pre-annotators before running the pre-annotator, select Wipe previous pre-annotation results. Human annotations are preserved even if this is selected.\n10. Select the check box for each document set that you want to pre-annotate and click Run.\n\nPre-annotation is applied to individual documents without regard for the various document sets or annotation sets that a document might belong to. A document that overlaps between a selected document set and an unselected document set will be pre-annotated in both document sets.\n\n\n\nRelated information:\n\n\n\n* [Creating dictionaries](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-dictionaries)\n* [Getting Started > Adding a dictionary](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutintrowks_tutless4)\n\n\n\n\n\n\n\n\n\n Pre-annotating documents with the machine learning model \n\nYou can use an existing machine learning model to pre-annotate documents that you add to your corpus.\n\n\n\n About this task \n\nAfter 10 to 30 documents are annotated, a machine learning model can be trained on the data. Don't use such a minimally trained model in production. However, you can use the model to pre-annotate documents to help speed up the human annotation of subsequent documents. For example, if you add documents to the corpus after you train a machine learning model, you can use the model to pre-annotate the new document sets. Never run a pre-annotator on the same documents that have been annotated by a person. Pre-annotators remove human annotation.\n\n\n\n\n\n Procedure", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04149-3050-4970", "score": 20.432574519072894, "text": "\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https://whois.icann.org/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-getting-started"}, {"document_id": "ibmcld_04334-199697-200931", "score": 19.187343295722478, "text": "\n<-- </section \"id=\"section-create-cis-service-instance-examples\" \"> --><-- </section \"id=\"section-create-cis-service-instance\" \"> --><-- <section \"id=\"section-delete-cis-service-instance\" \"> --> ibmcloud cis instance-delete Delete a CIS service instance. ibmcloud cis instance-delete INSTANCE -f, --force] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance. Required.-f, --force: Delete instance without prompting for confirmation.<-- </section \"id=\"section-delete-cis-service-instance-options\" \"> --><-- <section \"id=\"section-delete-cis-service-instance-examples\" \"> --> Examples Delete cis instance cis-demo ibmcloud cis instance-delete cis-demo -f\n<-- </section \"id=\"section-delete-cis-service-instance-examples\" \"> --><-- </section \"id=\"section-delete-cis-service-instance\" \"> --><-- <section \"id=\"section-update-cis-service-instance\" \"> --> ibmcloud cis instance-update Update a CIS service instance. ibmcloud cis instance-update INSTANCE --name NAME] --plan PLAN] --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-update-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04183-0-2205", "score": 18.777709601768443, "text": "\n\n\n\n\n\n\n  Securing your data in CIS \n\nTo ensure that you can securely manage your data when you use IBM Cloud\u00ae Internet Services, it is important to know exactly what data is stored and encrypted and how to delete any stored personal data.\n\n\n\n  How your data is stored and encrypted in CIS \n\nCIS interacts with Cloudflare services using a channel that is fully encrypted end-to-end using Transport Layer Security (TLS) 1.2. CIS does not store any customer data. Configuration data about your specific CIS configuration is encrypted in transit and at rest. CIS configuration data is deleted on your request through the UI, CLI, or API.\n\n\n\n\n\n  Protecting your sensitive data in CIS \n\nAll data related to CIS configuration is not considered sensitive data. The configuration data is encrypted at rest. No customer-managed keys are managed by the CIS offering. Therefore, neither Key Protect nor Hyper Protect Crypto Services are used.\n\n\n\n  Working with customer-managed keys for CIS \n\nNo customer-managed keys are managed by the CIS offering.\n\n\n\n\n\n\n\n  Deleting your data in CIS \n\nThe CIS configuration data is deleted on request through the UI, CLI or API.\n\n\n\n  Deleting CIS instances \n\nThe CIS data retention policy describes how long your data is stored after you delete the service. The data retention policy is included in the CIS service description, which you can find in [IBM Cloud Terms](https://cloud.ibm.com/docs/overview?topic=overview-terms). When a CIS instance is deleted by the UI, CLI, or API, the instance data is retained for seven days from deletion.\n\nBefore deleting an instance, all the domains in the instance must be removed.\n\nDeleting the CIS instance removes all data.\n\n\n\n\n\n  Restoring deleted data for CIS \n\nCIS can currently restore the deleted instance. After you delete an instance of CIS, you can restore the deleted service instance within the data retention period of seven days. After the seven-day period expires, the service instance is permanently deleted.\n\nTo view which service instances are available for restoration, use the ibmcloud resource reclamations command. To restore a deleted service instance, use the ibmcloud resource reclamation-restore command.\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-mng-data"}, {"document_id": "ibmcld_04186-18298-19703", "score": 18.755166865228063, "text": "\n[Page Rules](https://cloud.ibm.com/docs-content/v1/content/cb1eb27836421578019401fa7556779109430b29/cis/includes/solution-tutorials/includes/solution-tutorials/images/solution32-multi-region-k8s-cis/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https://cloud.ibm.com/docs/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https://cloud.ibm.com/docs/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https://cloud.ibm.com/docs/containers)\n* [Building containers from images](https://cloud.ibm.com/docs/containers?topic=containers-images)", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-multi-region-k8s-cis"}, {"document_id": "ibmcld_01391-18343-19753", "score": 18.66839219651129, "text": "\n[Page Rules](https://cloud.ibm.com/docs-content/v1/content/cbb80bf851fb762a838129cba09d5674f8bfffda/Registry/includes/solution-tutorials/includes/solution-tutorials/images/solution32-multi-region-k8s-cis/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https://cloud.ibm.com/docs/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https://cloud.ibm.com/docs/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)\n* [Kubernetes Service](https://cloud.ibm.com/docs/containers)\n* [Building containers from images](https://cloud.ibm.com/docs/containers?topic=containers-images)", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-multi-region-k8s-cis"}, {"document_id": "ibmcld_04334-198873-200152", "score": 18.562722393436175, "text": "\n<-- </section \"id=\"section-set-context-cis-service-examples\" \"> --><-- </section \"id=\"section-set-context-cis-service-instance\" \"> --><-- <section \"id=\"section-create-cis-service-instance\" \"> --> ibmcloud cis instance-create Create a CIS service instance. ibmcloud cis instance-create INSTANCE_NAME PLAN --output FORMAT] ! ! ! ! ! !\n<-- <section \"id=\"section-create-cis-service-instance-options\" \"> --> Command options INSTANCE_NAME: The name of CIS service instance. Required.PLAN: The name or ID of a service plan. Required.--output: Specify output format, only JSON is supported.<-- </section \"id=\"section-create-cis-service-instance-options\" \"> --><-- <section \"id=\"section-create-cis-service-instance-examples\" \"> --> Examples Create a standard plan cis instance cis-demo ibmcloud cis instance-create cis-demo standard\n<-- </section \"id=\"section-create-cis-service-instance-examples\" \"> --><-- </section \"id=\"section-create-cis-service-instance\" \"> --><-- <section \"id=\"section-delete-cis-service-instance\" \"> --> ibmcloud cis instance-delete Delete a CIS service instance. ibmcloud cis instance-delete INSTANCE -f, --force] ! ! ! ! ! !\n<-- <section \"id=\"section-delete-cis-service-instance-options\" \"> --> Command options INSTANCE: The name or ID of a CIS service instance.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04132-3821-5296", "score": 18.542757714658233, "text": "\nDeleting a webhook using the CLI \n\nTo delete a webhook using the CLI, run the following command.\n\nibmcloud cis alert-webhook-delete WEBHOOK_ID [-i, --instance INSTANCE] [-f, --force]\n\nWhere:\n\n\n\n* WEBHOOK_ID is the ID of webhook.\n* i, --instance value is the instance name or ID. If not set, the context instance specified by 'cis instance-set INSTANCE' is used.\n* -f, --force attempts to delete webhook without prompting for confirmation.\n\n\n\n\n\n\n\n\n\n Configuring webhooks using the API \n\nTo call these methods, you must be assigned one or more IAM access roles.\n\n\n\n* internet-svcs.zones.read\n* internet-svcs.zones.update\n\n\n\nYou can check your access by going to Users > name > Access policies.\n\n\n\n Creating a webhook using the API \n\nCreating a webhook alert is a two step process. First, create the webhook, then use the ID in the response that you receive to create the alert.\n\nTo create a webhook by using the API, follow these steps:\n\n\n\n1. Set up your API environment with the correct variables.\n2. Store your the following variable to be used in the API command:\n\n\n\n* crn: the full url-encoded CRN of the service instance.\n* name: the name of the webhook.\n* url: the URL of the webhook.\n* secret: the optional secret or API key needed to use the webhook.\n\n\n\n3. When all variables are initiated, create the webhook:\n\n\n\ncurl -X POST https://api.cis.cloud.ibm.com/v1/:crn/alerting/destinations/webhooks\n-H 'content-type: application/json'\n-H 'x-auth-user-token: Bearer xxxxxx'", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-configuring-webhooks"}, {"document_id": "ibmcld_13139-17831-19468", "score": 18.40378869917698, "text": "\nIn addition, you can now control what content gets cached by CIS and how long it stays cached. Go to Performance > Caching to define the global caching level and the browser expiration. You can customize the global security and caching rules with Page Rules. Page Rules enable fine-grained configuration using specific domain paths. As example with Page Rules, you could decide to cache all contents under /assets for 3 days:\n\nZoom\n\n![Page Rules](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution32-multi-region-k8s-cis/cis-pagerules.png)\n\nPage Rules\n\n\n\n\n\n\n\n Step 5: Remove resources \n\n\n\n Remove Kubernetes Cluster resources \n\n\n\n1. Remove the Ingress, you can do so by running the following command:\n\nkubectl delete -f glb-ingress.yaml\n2. Remove the service, you can do so by running the following command:\n\nkubectl delete service hello-world-service\n3. Remove the deployment, you can do so by running the following command:\n\nkubectl delete deployment hello-world-deployment\n4. Delete the clusters if you created them specifically for this tutorial.\n\n\n\n\n\n\n\n Remove CIS resources \n\n\n\n1. Remove the GLB.\n2. Remove the origin pools.\n3. Remove the health checks.\n4. Update the DNS for your custom domain.\n5. Delete the CIS instance if you created it specifically for this tutorial.\n\n\n\n\n\n\n\n\n\n Related content \n\n\n\n* [IBM Cloud Internet Services](https://cloud.ibm.com/docs/cis?topic=cis-getting-started)\n* [Manage your IBM CIS for optimal security](https://cloud.ibm.com/docs/cis?topic=cis-manage-your-ibm-cis-for-optimal-securitymanage-your-ibm-cis-for-optimal-security)", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-multi-region-k8s-cis"}, {"document_id": "ibmcld_04334-74160-75348", "score": 18.259775760660347, "text": "\n* lockdowns: Lock access to URLs in this domain to only permitted addresses or address ranges.\n\n\n\n-d, --domain\n: DNS Domain ID. For ua-rules and lockdowns type rule, it is a required parameter.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n\n\n\n\n Examples \n\nDelete a firewall rule.\n\nibmcloud cis firewall-delete dc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -i \"cis-demo\"\nibmcloud cis firewall-delete bc014906ccce4e7ea2e28be7df70d0d2 -t access-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall-delete 4af47b1518be478aa2c8f024af1c0bad -t ua-rules -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\nibmcloud cis firewall-delete e6106d7ec58e47ebb2fa053dedcd7dcb -t lockdown -d 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n\n\n Firewall rules \n\nManipulate how firewall rules perform using the following firewall-rules commands:\n\n\n\n ibmcloud cis firewall-rules \n\nRetrieve a list of currently existing firewall-rules for a given DNS domain.\n\nibmcloud cis firewall-rules DNS_DOMAIN_ID [--page PAGE] [--per-page PER_PAGE] [-i, --instance INSTANCE] [ ! ! ! ! ! ! --output FORMAT", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04334-196613-197723", "score": 18.25708903892303, "text": "\n! ! ! ! ! ! !\n<-- <section \"id=\"section-delete-ratelimit-rule-options\" \"> --> Command options DNS_DOMAIN_ID: The ID of DNS domain. Required.RATELIMIT_RULE_ID: The ID of rate limit rule. Required.-i, --instance: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.<-- </section \"id=\"section-delete-ratelimit-rule-options\" \"> --><-- <section \"id=\"section-delete-ratelimit-rule-examples\" \"> --> Examples Delete rate limiting rule 372e67954025e0ba6aaa6d586b9e0b60. ibmcloud cis ratelimit-rule-delete 31984fea73a15b45779fa0df4ef62f9b 372e67954025e0ba6aaa6d586b9e0b60 -i \"cis-demo\"\n<-- </section \"id=\"section-delete-ratelimit-rule-examples\" \"> --><-- </section \"id=\"section-delete-ratelimit-rule\" \"> --><-- </section \"id=\"section-ratelimit\" \"> --><-- <section \"id=\"section-resource-instance\" \"> --> Resource instance Manipulate CIS Service instances by using the following instance commands.<-- <section \"id=\"section-list-cis-service-instances\" \"> --> ibmcloud cis instances List all CIS service instances. ibmcloud cis instances --output FORMAT] ! ! ! ! ! !", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-1211120-1213024", "score": 37.6536606195382, "text": "\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1213753-1215657", "score": 37.6536606195382, "text": "\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_09192-5368-7014", "score": 36.73524274837354, "text": "\n\"message\": \"Key is protecting one or more cloud resources\",\n\"status\": 409,\n\"moreInfo\": \"https://cloud.ibm.com/apidocs/key-protect\",\n\"target\": {\n\"type\": \"query_param\",\n\"name\": \"force\"\n}\n}\n]\n}\n]\n}\n\n Why it\u2019s happening \n\nThis key is actively protecting one or more cloud resources, such as a IBM Cloud\u00ae Object Storage bucket or a Cloud Databases deployment.\n\n How to fix it \n\nFor your protection, Key Protect prevents the deletion of a key that's actively encrypting data in the cloud. Before you delete a key, [review which resources are encrypted by this key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nYou can get the current list of resources associated with your key by first [synchronizing the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-sync-associated-resources), which might take up to 4 hours. Then, proceed to [viewing associations between root keys and encrypted IBM Cloud resources](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources).\n\nAfter using Sync, associations between the key and other resources will be current and up to date. If there are no associations after using Sync, the key can be deleted normally.\n\nIf the associations are still there after Sync:\n\n\n\n* You can use the Key Protect API to [force deletion on the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete).\n* You can delete the resources associated with the key, and then delete the key normally.\n\n\n\n\n\n\n\n Getting help and support", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-troubleshooting"}, {"document_id": "ibmcld_08695-7-1852", "score": 35.38011981497322, "text": "\nWhy can't I delete keys? \n\nWhen you use the Hyper Protect Crypto Services user interface, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Hyper Protect Crypto Services service.\n\nYou're assigned a Manager access policy for the service instance. You try to delete a key, but the action fails with either of the following error messages:\n\n\n\n* Error message 1:\n\n> The service was not able to delete key \"<key_name>\". The key cannot be deleted because it is protecting one or more cloud resources that have a retention policy.\n* Error message 2:\n\n> The service was not able to delete key \"<key_name>\". Because the key is enabled with the dual authorization policy and you set the key for deletion, a second approver needs to continue with the key deletion operation.\n\n\n\n Why it\u2019s happening \n\nThe following reasons might cause the errors:\n\n\n\n* If error message 1 is displayed, this key is actively protecting one or more cloud resources, such as a Cloud Object Storage bucket.\n* If error message 2 is displayed, this key is enabled with the dual authorization policy that requires a deletion authorization from two users. You set the key for deletion and you need to contact the second approver to complete the deletion.\n\n\n\n How to fix it \n\nThe following instructions can help you solve the problems:\n\n\n\n* To resolve the error that is reported in error message 1, [review the resources](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key before you delete a key.\n\nYou can [force deletion on a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) that's protecting a cloud resource. However, the action won't succeed if the key's associated resource is nonerasable due to a retention policy.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys"}, {"document_id": "ibmcld_16059-9270-11112", "score": 34.36923354523698, "text": "\nWhen you delete a root key, the key is no longer available to decrypt passphrases that are used to protect your resources. Deleting a root key places it in a destroyed or deleted state in the KMS. Volume, snapshot, and image resources that are protected by the deleted root key have an unusable status and can't be used for normal operations. File Storage for VPC shares show a suspended status. The storage system is offline, and data cannot be accessed.\n\nYour data still exists. You have a 30-day grace period to [restore the deleted key](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managing&interface=uibyok-restore-root-key). Otherwise, your encrypted resources become inaccessible. After 30 days, your root key can't be restored, and your resources are unrecoverable.\n\nBy default, the KMS prevents you from deleting a root key that's actively protecting a resource. You can force delete a root key in Key Protect and Hyper Protect Crypto Services. When you force delete a root key, the following actions happen automatically:\n\n\n\n* If the deleted root key is protecting boot volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting data volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting file shares, the file share is suspended.\n* Deleting a root key purges usage of the key for all resources in the VPC.\n* Events are logged in the Activity Tracker.\n\n\n\nTo force the deletion of a root key in Hyper Protect Crypto Services, use the API. Hyper Protect Crypto Services requires that you delete all resources before you delete a root key that is protecting those resources. If you can't delete the key, see [troubleshooting key management service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managing&interface=ui"}, {"document_id": "ibmcld_09088-10880-12721", "score": 34.11779776454198, "text": "\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n\n\n\n\n\n What is a dual authorization policy? \n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n\n\n\n\n\n What happens after I enable a dual authorization policy? \n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https://cloud.ibm.com/docs/key-protect?topic=key-protect-set-dual-auth-key-policy).\n\n\n\n\n\n Can I disable a dual authorization settings for my Key Protect instance? \n\nYes.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-faqs"}, {"document_id": "ibmcld_15111-18994-20695", "score": 33.848241660994475, "text": "\nThe master key for each Block Storage for VPC volume is encrypted with a unique KMS-generated LUKS passphrase, which is then encrypted by your customer root key (CRK) and stored in the KMS. Passphrases are AES-256 cipher keys, which means that they are 32 bytes long and not limited to printable characters. You can view the cloud resource name (CRN) for the CRK that is used to encrypt a volume. However, the CRK, LUKS passphrase, and the volume's master encryption key are never exposed. For more information about all the keys IBM VPC uses to secure your data, see [IBM's encryption technology - How your data is secured](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-aboutbyok-technologies).\n\n\n\n\n\n I use customer-managed encryption for my volumes. What happens when I disable or delete my root key? \n\nThese actions are two separate actions. Disabling a root key in your KMS suspends its encryption and decryption operations, placing the key in a suspended state. Workloads continue to run in virtual server instances and boot volumes remain encrypted. Data volumes remain attached. However, if you power down the VM and then power it back on, any instances with encrypted boot volumes do not start. You can enable a root key in a suspended state and resume normal operations. For more information, see [Disabling root keys](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managingbyok-disable-root-keys).\n\nDeleting a root key has greater consequences. Deleting a root key purges usage of the key for all resources in the VPC. By default, the KMS prevents you from deleting a root key that's actively protecting a resource. However, you can still force the deletion of a root key.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-vpc-faq"}, {"document_id": "ibmcld_16045-9337-11274", "score": 33.794144651348304, "text": "\nVolume, snapshot, and image resources that are protected by the deleted root key have an unusable status and can't be used for normal operations. File Storage for VPC shares show a suspended status. The storage system is offline, and data cannot be accessed.\n\nYour data still exists. You have a 30-day grace period to [restore the deleted key](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managingbyok-restore-root-key). Otherwise, your encrypted resources become inaccessible. After 30 days, your root key can't be restored, and your resources are unrecoverable.\n\nBy default, the KMS prevents you from deleting a root key that's actively protecting a resource. You can force delete a root key in Key Protect and Hyper Protect Crypto Services. When you force delete a root key, the following actions happen automatically:\n\n\n\n* If the deleted root key is protecting boot volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting data volumes, the associated virtual server instance is stopped.\n* If the deleted root key is protecting file shares, the file share is suspended.\n* Deleting a root key purges usage of the key for all resources in the VPC.\n* Events are logged in the Activity Tracker.\n\n\n\nTo force the deletion of a root key in Hyper Protect Crypto Services, use the API. Hyper Protect Crypto Services requires that you delete all resources before you delete a root key that is protecting those resources. If you can't delete the key, see [troubleshooting key management service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys).\n\nBlock Storage for VPC volumes, snapshots, and custom images with a deleted root key appear in the list of resources with an unusable status. File Storage for VPC shares show a suspended status. The API reason code is encryption_key_deleted.\n\nDeletion of the root key results in the following conditions.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managing"}, {"document_id": "ibmcld_07578-903428-905242", "score": 30.255905800656073, "text": "\nHowever, if you power down the VM and then power it back on, any instances with encrypted boot volumes do not start. You can enable a root key in a suspended state and resume normal operations. For more information, see [Disabling root keys](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managingbyok-disable-root-keys).\n\nDeleting a root key has greater consequences. Deleting a root key purges usage of the key for all resources in the VPC. By default, the KMS prevents you from deleting a root key that's actively protecting a resource. However, you can still force the deletion of a root key. You have limited time to [restore a deleted root key](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managingbyok-restore-root-key) that you imported to the KMS. For more information, see [Deleting root keys](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managingbyok-delete-root-keys).\n* Can I remove IAM authorization from Cloud Block Storage for VPC to the KMS and still delete my Block Storage for VPC volumes with customer-managed encryption?\n\n Can I remove IAM authorization from Cloud Block Storage for VPC to the KMS and still delete my Block Storage for VPC volumes with customer-managed encryption? \n\nIf you remove IAM authorization before you delete your BYOK volume (or image), the delete operation completes without unregistering the root keys in the KMS instance. In other words, the root key remains registered for a resource that doesn't exist. Always delete a BYOK resource before you remove IAM authorization. For more information about safely removing service authorization, see [Removing service authorization to a root key](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managinginstance-byok-inaccessible-data).\n* What can I do if my root key is compromised?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-903305-905119", "score": 30.255905800656073, "text": "\nHowever, if you power down the VM and then power it back on, any instances with encrypted boot volumes do not start. You can enable a root key in a suspended state and resume normal operations. For more information, see [Disabling root keys](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managingbyok-disable-root-keys).\n\nDeleting a root key has greater consequences. Deleting a root key purges usage of the key for all resources in the VPC. By default, the KMS prevents you from deleting a root key that's actively protecting a resource. However, you can still force the deletion of a root key. You have limited time to [restore a deleted root key](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managingbyok-restore-root-key) that you imported to the KMS. For more information, see [Deleting root keys](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managingbyok-delete-root-keys).\n* Can I remove IAM authorization from Cloud Block Storage for VPC to the KMS and still delete my Block Storage for VPC volumes with customer-managed encryption?\n\n Can I remove IAM authorization from Cloud Block Storage for VPC to the KMS and still delete my Block Storage for VPC volumes with customer-managed encryption? \n\nIf you remove IAM authorization before you delete your BYOK volume (or image), the delete operation completes without unregistering the root keys in the KMS instance. In other words, the root key remains registered for a resource that doesn't exist. Always delete a BYOK resource before you remove IAM authorization. For more information about safely removing service authorization, see [Removing service authorization to a root key](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-encryption-managinginstance-byok-inaccessible-data).\n* What can I do if my root key is compromised?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00644-14024-16089", "score": 24.25774046691389, "text": "\nWhile IBM Cloudant strives to keep indexes updated in the background, no guarantee exists about how out-of-date the view is when queried with update=false or update=lazy.\n\nThe stable option indicates whether you would prefer to get results from a single, consistent set of shards. The false value means that all available shard replicas are queried and IBM Cloudant uses the fastest response. By contrast, setting stable=true forces the database to use just one replica of the index.\n\nUsing stable=true can cause high latency as it consults only one of the copies of the index, even if the other copies would respond faster.\n\n\n\n\n\n Combining parameters \n\nIf you specify stable=false and update=false, you see greater inconsistency between results, even for the same query and without making database changes. We recommend against this combination unless you are sure that your system can tolerate this behavior.\n\n\n\n\n\n\n\n Sorting returned rows \n\nThe data that is returned by a view query is in the form of an array. Each element within the array is sorted by using standard [UTF-8](https://en.wikipedia.org/wiki/UTF-8) sorting. The sort is applied to the key defined in the view function.\n\nThe basic order of the output is shown in the following table:\n\n\n\nTable 2. Order of returned rows\n\n Value Order \n\n null First \n false \n true \n Numbers \n Text (lowercase) \n Text (uppercase) \n Arrays (according to the values of each element, by using the order given in this table) \n Objects (according to the values of keys, in key order by using the order given in this table) Last \n\n\n\nYou can reverse the order of the returned view information by setting the descending query value true.\n\nWhen you issue a view request that specifies the keys parameter, the results are returned in the same order as the supplied keys array.\n\nSee the example of using HTTP to request the records in reversed sort order:\n\nGET $SERVICE_URL/$DATABASE/_design/$DDOC/_view/$VIEW_NAME?descending=true HTTP/1.1\nAccept: application/json\n\nSee the example of requesting the records in reverse sort order.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-using-views"}, {"document_id": "ibmcld_03403-24194-25608", "score": 23.405132017406896, "text": "\nThe user might include only the numbers or the letters too, but forget that they are meant to be uppercase. So, it would be a nice touch to give them a hint in such cases, correct? If you want to be kind, add another node to the dialog tree that checks for numbers in the user input.\n\n\n\n1. Find the @order_number node that is a child of the Ask order number node.\n2. Click the More![More options](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png) icon on the @order_number node, and then select Add node below.\n3. In the condition field, add input.text.find('d'), which is a SpEL expression that says if you find one or more numbers in the user input, trigger this response.\n4. In the text response field, add the following response:\n\nThe correct format for our order numbers is AAnnnnn. The A's represents 2 uppercase letters, and the n's represent 5 numbers. Do you have an order number in that format?\n5. Click ![Close](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/close.png) to close the edit view.\n6. Click the More![More options](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png) icon on the input.text.find('d') node, and then select Add child node.\n7. Type true into the If assistant recognizes field of this node.\n8.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial"}, {"document_id": "ibmcld_03069-24249-25669", "score": 23.32274613191771, "text": "\nThe user might include only the numbers or the letters too, but forget that they are meant to be uppercase. So, it would be a nice touch to give them a hint in such cases. If you want to be kind, add another node to the dialog tree that checks for numbers in the user input.\n\n\n\n1. Find the @order_number node that is a child of the Ask order number node.\n2. Click the More![More options](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kabob.png) icon on the @order_number node, and then select Add node below.\n3. In the condition field, add input.text.find('d'), which is a SpEL expression that says if you find one or more numbers in the user input, trigger this response.\n4. In the text response field, add the following response:\n\nThe correct format for our order numbers is AAnnnnn. The A's represents 2 uppercase letters, and the n's represent 5 numbers. Do you have an order number in that format?\n5. Click ![Close](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/close.png) to close the edit view.\n6. Click the More![More options](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kabob.png) icon on the input.text.find('d') node, and then select Add child node.\n7. Type true into the If assistant recognizes field of this node.\n8.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial"}, {"document_id": "ibmcld_00539-2548-4016", "score": 21.002045075521302, "text": "\n\"type\": \"json\"\n}\n\n\n\n\n\n Can I sort in reverse order? \n\nYes! IBM Cloudant Query supports sorting the result set in ascending or descending order, but not a combination of the two. For example, a query that sorts some fields in ascending order, and a query where descending is not allowed.\n\nThis query returns documents that match firstname and surname and sorts by surname/firstname/date descending:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\n{ \"firstname\": \"desc\" },\n{ \"surname\": \"desc\" },\n{ \"date\": \"desc\" }\n],\n\"limit\": 10\n}\n\nA suitable index must be present that contains the selector fields and the sort fields. Otherwise, IBM Cloudant refuses to execute the query. A suitable index definition for the previous query is shown next:\n\n{\n\"index\": {\n\"fields\": [\n\"firstname\",\n\"surname\",\n\"date\"\n]\n},\n\"ddoc\": \"jsonindexes\",\n\"name\": \"byNameAndDate\",\n\"type\": \"json\"\n}\n\nThe previous index is suitable for both ascending and descending sort order.\n\n\n\n\n\n How can I tell if an index is backing a query? \n\nThe [POST /{db}/_explain](https://cloud.ibm.com/apidocs/cloudant?code=javapostexplain) API endpoint when passed a JSON object that is usually sent to the [POST /{db}/_find](https://cloud.ibm.com/apidocs/cloudantpostfind) endpoint, explains how such a query is handled and which indexes, if any, might be used.\n\nIf the index object in the response indicates that \"all_docs\" is being used, a full database scan is required to service the query.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-using-cloudant-query"}, {"document_id": "ibmcld_00644-20617-22169", "score": 19.36375604776199, "text": "\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https://cloud.ibm.com/apidocs/cloudant?code=goauthentication-with-external-configuration) for examples.\n\nFor example, if you have a database that returns one result when you use a start_key of alpha and an end_key of beta, you would get a 400 (Bad request) error with a reversed order. The reason is that the entries in the view are reversed before the key filter is applied.\n\nSee the example that uses HTTP to illustrate why reversing the order of start_key and end_key might return a query parse error:\n\nGET $SERVICE_URL/$DATABASE/_design/$DDOC/_view/$VIEW_NAME?descending=true&start_key=\"alpha\"&end_key=\"beta\" HTTP/1.1\n\nSee the example illustrating why reversing the order of start_key and end_key might cause a 400 error.\n\nClient libraries use POST method instead of GET because they have the same behavior.\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X GET \"$SERVICE_URL/users/_design/allusers/_view/getVerifiedEmails?descending=true&start_key=\"alpha\"&end_key=\"beta\"\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.PostViewOptions;\nimport com.ibm.cloud.cloudant.v1.model.ViewResult;\n\nCloudant service = Cloudant.newInstance();\n\nPostViewOptions viewOptions = new PostViewOptions.Builder()\n.db(\"users\")\n.ddoc(\"allusers\")\n.view(\"getVerifiedEmails\")\n.descending(true)\n.startKey(\"alpha\")\n.endKey(\"beta\")\n.build();\n\nViewResult response =\nservice.postView(viewOptions).execute()", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-using-views"}, {"document_id": "ibmcld_03285-34490-35530", "score": 19.14479773935573, "text": "\nIf the assistant is unable to send an SMS message to the caller, a new turn is initiated with the text input vgwSMSFailed. This input indicates that an SMS message could not be sent the caller. You can design your dialog or actions to handle such a failure by creating intents or actions that are triggered by the input text vgwSMSFailed.\n\n{\n\"input\": {\n\"message_type\": \"text\",\n\"text\": \"vgwSMSMessage\"\n},\n\"context\": {\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"vgwSMSMessage\": \"1545 Lexington Ave.\"\n}\n}\n}\n}\n\n\n\n\n\n Defining a sequence of phone commands \n\nIf you want to run more than one command in succession, include multiple responses in the output.generic array. These commands are processed in the order in which they are specified in the array.\n\nThis example shows two responses: first a text response, followed by an end_session response to end the call.\n\n{\n\"output\": {\n\"generic\": [\n{\n\"values\":\n{\n\"text\": \"Goodbye.\"\n}\n],\n\"response_type\": \"text\",\n\"selection_policy\": \"sequential\"\n},\n{\n\"response_type\": \"end_session\"\n}\n]\n}\n}\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions"}, {"document_id": "ibmcld_03891-23613-25771", "score": 18.671908985611783, "text": "\nClusters that do not use a system channel can join and unjoin ordering nodes to an application channel. You can verify if a cluster does or does not use a system channel by clicking the cluster's tile and looking near the Orderer Type text.\n\nJoining an orderer to an application channel will make it either a follower or a consenter. It will be a consenter if the node is found in the the channel's config block in the consenters section. Otherwise the orderer will be a follower. Both types of orderers will receive transaction/block data, but only a consenter can vote and play a role in the consensus algorithm. A node can be promoted from a follower to a consenter by first joining it to the channel, and then editing the channel's config to add it as a consenter. Similarly these steps can be reversed to demote an orderer and unjoin it completely if need be.\n\nJoining an orderer to the application channel can be started by clicking the cluster's tile. Next click either the plus sign on a channel tile or the Join channel blue button. Follow the prompts and select which orderer nodes to join. Then click Submit. Once an orderer has joined it will begin downloading blocks to catch up to the current level.\n\n\n\n\n\n\n\n Removing ordering service nodes \n\nIf a user wants to delete an ordering node, it must first remove the node from all channels where it is a consenter. This is because the console does not distinguish between a deleted node and an unavailable node, and will keep an ordering node as part of its consenter set until it is removed.\n\nAs a result, when you delete a node, a check is performed to see if it is a consenter on any channels. If it is, you will not be able to delete the node until it has been removed as a consenter from all channels. After removing the node as a consenter from all channels, you will be able to delete the node by clicking the trash can icon. Note that this action will have to be taken in the console where the node was created.\n\nAs part of this same process, make sure to reach out to the other console operators to let them know that the node has been deleted so they can remove the tile from their console.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-add-remove-orderer"}, {"document_id": "ibmcld_09919-4253-6578", "score": 18.499155886085298, "text": "\nBy using the more generic v2 Entities type system together with other features, such as Concepts and Categories, you can achieve similar outcomes with more flexibility. For more information about v2 entity types, see [Entity types (Version 2)](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-entity-types-version-2).\n\n\n\n\n\n 9 June 2023 \n\nRetired Custom Sentiment Feature\n: The Custom Sentiment feature is retired. Custom sentiment models can no longer be created nor can they be used with Analyze API calls. To ensure we continue providing our clients with robust and powerful text classification capabilities, IBM recently announced the general availability of a new [single-label text classification capability](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-classifications). This new feature includes extended language support and training data customizations suited for building a custom sentiment classifier.\n\n\n\n\n\n 16 February 2023 \n\nUpdated training process for Custom Classifications\n: Updates were made to the Custom Classifications training process including improvements in the preprocessing stage, updating underlying libraries, and fixing minor bugs.\n\n\n\n\n\n 2 February 2023 \n\nSentiment support for additional languages\n: Support for sentiment is now available, for all public service instances, for the following languages: Czech, Danish, Finnish, Hebrew, Hindi, Norwegian Bokm\u00e5l, Norwegian Nynorsk, Polish, Romanian, Slovak, Swedish, Turkish. For details, see [Language support](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-support).\n\n\n\n\n\n 11 January 2023 \n\nImproved English and Korean Entities Model\n: Fixed a bug for English and Korean models using Version 2 Entity type system where not all entities are returned properly.\n\n\n\n\n\n 3 November 2022 \n\nImproved Error Handling and Validation for Sentiment and Custom Sentiment\n: If a request contains both an error in the sentiment feature and a valid feature request for another feature, the response returns a 200 with a warning for the sentiment feature.\n\nRequests for Custom Sentiment that include at least one target found in the document will now return a 200 with sentiment analysis for the found targets.", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-release-notes"}, {"document_id": "ibmcld_04126-7-1694", "score": 18.253981482962562, "text": "\nCompression and optimization concepts \n\nIBM Cloud\u00ae Internet Services applies gzip and brotli compression to some types of content. CIS also compresses items based on the browser's UserAgent to speed up page loading time.\n\nIf you're already using gzip, CIS honors your gzip settings as long as you're passing the details in a header from your web server for the files.\n\nCIS only supports the content type gzip towards your origin server and can also only deliver content either gzip-compressed, brotli-compressed, or not compressed.\n\nCIS's reverse proxy is also able to convert between compressed formats and uncompressed formats, meaning that it can pull content from a customer's origin server through gzip and serve it to clients uncompressed (or reversed). This is done independently of caching.\n\nThe Accept-Encoding header is not respected and is removed.\n\n\n\n What gets compressed \n\nIn addition to CIS's serving stale content and minification of CSS, JS, and HTML to speed up your site, CIS also provides gzip and brotli compression to help site owners.\n\nCIS returns gzip or brotli encoded responses to compatible clients and browsers for the following content-types:\n\ntext/html\ntext/richtext\ntext/plain\ntext/css\ntext/x-script\ntext/x-component\ntext/x-java-source\ntext/x-markdown\napplication/javascript\napplication/x-javascript\ntext/javascript\ntext/js\nimage/x-icon\nimage/vnd.microsoft.icon\napplication/x-perl\napplication/x-httpd-cgi\ntext/xml\napplication/xml\napplication/xml+rss\napplication/vnd.api+json\napplication/x-protobuf\napplication/json\nmultipart/bag\nmultipart/mixed\napplication/xhtml+xml\nfont/ttf\nfont/otf\nfont/x-woff\nimage/svg+xml\napplication/vnd.ms-fontobject\napplication/ttf", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-compression-concepts"}, {"document_id": "ibmcld_03069-6360-8216", "score": 18.17202727743159, "text": "\n[Try it](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/ask_watson.png) icon to open the Try it out pane.\n2. Enter, I want to learn more about your restaurant.\n\nYour assistant indicates that the about_restaurant intent is recognized, and returns a response with the image and text that you specified for the dialog node.\n\n![Shows the Try it out pane recognizing the #about_restaurant intent and showing the image and text response.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-ass-test-about-restaurant.png)\n\n\n\nCongratulations! You have added a custom intent, and a dialog node that knows how to handle it.\n\nThe about_restaurant intent is designed to recognize a variety of general questions about the restaurant. You added a single node to capture such questions. The response is long, but it is a single statement that can potentially answer questions about all of the following topics:\n\n\n\n* The restaurant owners\n* The restaurant history\n* The philosophy\n* The number of sites\n* The days of operation\n* The meals served\n* The fact that the restaurant bakes cakes to order\n\n\n\nFor general, low-hanging fruit types of questions, a single, general answer is suitable.\n\n\n\n\n\n\n\n Step 4: Manage cake orders \n\nCustomers place orders in person, over the phone, or by using the order form on the website. After the order is placed, users can cancel the order through the virtual assistant. First, define an entity that can recognize order numbers. Then, add an intent that recognizes when users want to cancel a cake order.\n\n\n\n Adding an order number pattern entity \n\nYou want the assistant to recognize order numbers, so you will create a pattern entity to recognize the unique format that the restaurant uses to identify its orders.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06160-11142-12906", "score": 38.92533887991043, "text": "\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_10596-11475-13230", "score": 38.92533887991043, "text": "\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_06320-2897-4555", "score": 34.06082946367011, "text": "\n[NodeSync](https://docs.datastax.com/en/dse/6.7/dse-admin/datastax_enterprise/config/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs. Traditional repairs are unnecessary, as the automation ensures that NodeSync handles the repairs for you.\n\nWhile the automation enables NodeSync, you can also manually create tables with NodeSync enabled so that the service can repair the tables' data when necessary:\n\nCREATE TABLE myTable (...) WITH nodesync = { 'enabled': 'true'};\n\nFor more information, see [enabling the NodeSync service](https://docs.datastax.com/en/dse/6.7/dse-admin/datastax_enterprise/config/enablingNodesync.html).\n\nNodetool is unsupported. Manual repairs that are issued against any table that is enabled with the NodeSync service [are ignored](https://docs.datastax.com/en/opscenter/6.5/opsc/online_help/services/opscNodeSyncService.htmlNodeSyncServiceversusRepairService). See error:\n\nWARNING: A manual nodetool repair or a repair operation from the OpsCenter node administration menu fails to run if a NodeSync-enabled table is targeted.\n\n\n\n\n\n Recommendations \n\n\n\n Benchmark before production \n\n\n\n* Do not use cqlsh and COPY for benchmarking, as COPY does not mimic typical client behavior. Instead, [nosqlbench](https://github.com/nosqlbench/nosqlbench) can be used for benchmarking.\n\n\n\n\n\n\n\n Data migrations \n\n\n\n* DSBULK is recommended for data migration.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-getting-started"}, {"document_id": "ibmcld_10596-5350-7330", "score": 31.80180814234653, "text": "\nIf the previous steps do not solve the issue, [reload](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_06160-5357-7356", "score": 31.64824935779805, "text": "\nIf the previous steps do not solve the issue, [reload](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\nIf some, but not all, of your worker nodes frequently enter a Critical or NotReady state, consider enabling [worker autorecovery](https://cloud.ibm.com/docs/containers?topic=containers-health-monitorautorecovery) to automate these recovery steps.\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_06160-12611-14167", "score": 30.533249483939585, "text": "\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\nkubectl describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https://cloud.ibm.com/docs/containers?topic=containers-debug-tool) . Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.\n\nkubectl get mutatingwebhookconfigurations\n\nkubectl get validatingwebhookconfigurations\n4.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_10596-12943-14509", "score": 30.000462223815408, "text": "\nIf any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2. Make sure that you have [removed any added webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) from the cluster.\n\n\n\n\n\n\n\n Gathering data \n\nFollow the steps to gather the relevant worker node data.\n\n\n\n1. Get the details of each node. Save the output details to include in your support ticket.\n\noc describe node <node-ip-address>\n2. Run the [Diagnostics and Debug Tool](https://cloud.ibm.com/docs/containers?topic=containers-debug-tool) and the [Openshift Diagnostics and Debug Tool](https://cloud.ibm.com/docs/openshift?topic=openshift-debug-tool). Export the kube and network test results to a compressed file and save the file to include in your support ticket. If all workers in your cluster are affected, you can skip this step as the debug tools cannot work properly if all worker nodes are disrupted.\n3. Show that there are no added mutating or validating webhooks remaining in your cluster by getting the webhook details. Save the command output to include in your support ticket. Note that the following mutating webhooks might remain and do not need to be deleted: alertmanagerconfigs.openshift, managed-storage-validation-webhooks, multus.openshift.io, performance-addon-operator, prometheusrules.openshift.io,snapshot.storage.k8s.io.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_10596-9883-11854", "score": 29.545833231675584, "text": "\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_06320-1330-3318", "score": 29.28955354618871, "text": "\nAfter you click Create, the system displays a message to say that the instance is being provisioned, which returns you to the Resource list. From the Resource list, you see that the status for your instance is, Provision in progress.\n8. When the status changes to Active, select the instance.\n\n\n\n\n\n\n\n Step 3: Set your admin password \n\n\n\n* [Set the Admin Password](https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-admin-password) for your deployment.\n\n\n\nReview the [Getting to production](https://cloud.ibm.com/docs/cloud-databases?topic=cloud-databases-best-practices) documentation for general guidance on setting up a basic IBM Cloud\u00ae Databases for DataStax deployment.\n\n\n\n\n\n Step 4: Connect with DataStax drivers \n\nDrivers are a key component to connecting external applications to your Databases for DataStax deployment. Review the information on [Connecting an external application](https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-external-app) for details on compatible drivers. Further details on specific drivers, including upgrade guides, can be found at [Developing applications with Apache Cassandra and DataStax Enterprise](https://docs.datastax.com/en/devapp/doc/devapp/aboutDrivers.html).\n\nOnly DataStax drivers that are explicitly listed in the [Connecting an external application](https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-external-app) table function correctly for connecting to Databases for DataStax.\n\n\n\n\n\n Step 5: Node repairs with NodeSync \n\n[NodeSync](https://docs.datastax.com/en/dse/6.7/dse-admin/datastax_enterprise/config/aboutNodesync.html) is a continuous repair service that runs automatically in the background to validate that your data is in sync on all replicas and reduces the need for manual repairs. For operational simplicity and performance, Databases for DataStax enables the NodeSync service on all key spaces and tables to handle node repairs.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-cassandra?topic=databases-for-cassandra-getting-started"}, {"document_id": "ibmcld_05713-581893-583377", "score": 29.018088692431803, "text": "\n* [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https://cloud.ibm.com/docs/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https://cloud.ibm.com/docs/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https://cloud.ibm.com/docs/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https://cloud.ibm.com/docs/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_sitemap"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00626-3414-5513", "score": 13.726952826307297, "text": "\nThe _replicator database is a special database within your account, where you can PUT or POST replication documents to specify the replications you want.\n\nBefore you start a replication, you must create the _replicator database. To create a database, send a PUT request to:\n\nhttps://$ACCOUNT.cloudant.com/_replicator\n\nFor more information, see [Databases](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-databases).\n\nTo cancel a replication, you DELETE the replication document. The fields that are supplied in the replication document are described in the [Create or modify a replication operation](https://cloud.ibm.com/apidocs/cloudantpostreplicate) description under Request information.\n\nAll design documents and _local documents that are added to the /_replicator database are ignored.\n\n\n\n\n\n Important notes \n\n\n\n* A new and more powerful [replication scheduler](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-advanced-replicationthe-replication-scheduler) changes the previous behavior of the IBM Cloudant replication mechanisms. Ensure that your applications are updated.\n* Replications can severely impact the performance of an IBM Cloudant instance. Performance testing helps you understand the impact on your environment under an increasing number of concurrent replications.\n* [Continuous replication](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-replication-apicontinuous-replication) can result in many internal calls. Requiring many calls might affect the costs for multi-tenant users of IBM Cloudant systems. By default, continuous replication is not enabled.\n* The target database must exist. It is not automatically created if it does not exist. Add \"create_target\":true to the JSON document that describes the replication if the target database does not exist before replication. For more information, see [Creating a target database during replication](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-replication-apicreating-a-target-database-during-replication).\n* Replicator databases must be maintained and looked after, just like any other valuable data store.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-replication-api"}, {"document_id": "ibmcld_13144-25047-26967", "score": 13.604555862971672, "text": "\nserviceClass: cloudantnosqldb\nplan: standard\n6. Click Create to create a IBM Cloudant database instance. Your context should be Operators > Installed Operators > IBM Cloud Operator in the Administrator perspective with Project: example-health in the Service panel.\n7. Click on the service just created, <your-initials>-cloudant-service and over time the state field will change from provisioning to Online meaning it is good to go.\n8. Create a Binding resource and a Secret resource for the cloudant Service resource just created. Navigate back to Operators > Installed Operators > IBM Cloud Operator > Binding tab. Open the Binding tab, click Create Binding and select YAML View. Create a cloudant-binding associated with the serviceName <your-initials>-cloudant-service, (this is the the name provided for the Service created earlier).\n\napiVersion: ibmcloud.ibm.com/v1\nkind: Binding\nmetadata:\nname: cloudant-binding\nnamespace: example-health\nspec:\nserviceName: <your-initials>-cloudant-service\n9. Optionally dig a little deeper to understand the relationship between the Red Hat OpenShift resources: Service, service Binding, binding Secret and the IBM Cloud resources: Service, service Instance and the instance's Service credentials. Using the cloud shell:\n\nibmcloud resource service-instances --service-name cloudantnosqldb\n\nYOURINITIALS=<your-initials>\n\nibmcloud resource service-instance $YOURINITIALS-cloudant-service\n\nibmcloud resource service-keys --instance-name $YOURINITIALS-cloudant-service --output json\n\nOutput looks something like this:\n\nyouyou@cloudshell:$ ibmcloud resource service-instances --service-name cloudantnosqldb\nRetrieving instances with type service_instance in all resource groups in all locations under ..\nOK\nName Location State Type\n<your-initials>-cloudant-service us-south active service_instance\nyouyou@cloudshell:$ ibmcloud resource service-instance <your-initials>-cloudant-service", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-openshift-microservices"}, {"document_id": "ibmcld_00626-5090-6346", "score": 13.518868802153753, "text": "\nAdd \"create_target\":true to the JSON document that describes the replication if the target database does not exist before replication. For more information, see [Creating a target database during replication](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-replication-apicreating-a-target-database-during-replication).\n* Replicator databases must be maintained and looked after, just like any other valuable data store. For more information, see [replication database maintenance](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-advanced-replicationreplication-database-maintenance).\n\n\n\nFor security purposes, the IBM Cloudant team recommends that you use IAM API keys or IBM Cloudant legacy authentication [API keys](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-work-with-your-accountapi-keys) rather than account-level credentials for replication jobs. For more information, see the [IAM guide](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudant) or the legacy [Authentication API document](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-work-with-your-accountauthentication) and the legacy [Authorization API document](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-work-with-your-accountauthorization).", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-replication-api"}, {"document_id": "ibmcld_00564-5557-7242", "score": 12.797439893007049, "text": "\nThe resulting compressed data stream is then redirected and written to a file called backup.gz.\n\nIf the database requires you to supply access credentials, use $SERVICE_URL with the form https://$USERNAME:$PASSWORD@$ACCOUNT, for example, https://myusername:mypassword@myhost.cloudant.com.\n\nIt's straightforward to extend the pipeline if you want to transform the data in other ways. For example, you might want to encrypt the data before it's written to disk. You might also want to write the data directly to an object store service by using their command-line tools.\n\n\n\n\n\n Hourly or daily backups that use cron \n\nThe cron scheduling tool can be set up to take snapshots of data at regular intervals.\n\nA useful starting point is to get couchbackup to write a single backup to a file, where the file name includes the current date and time, as shown in the following example:\n\ncouchbackup --url \"https://$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com\" --db \"animaldb\" > animaldb-backup-date -u \"+%Y-%m-%dT%H:%M:%SZ\".bak\n\nAfter you check the command to ensure it works correctly, it can be entered into a 'cron job':\n\n\n\n1. Install the CouchBackup tools on the server that you want to do the backups.\n2. Create a folder to store the backups.\n3. Create a 'cron entry' that describes the frequency of the backup.\n\n\n\nYou can create a cron entry by using the crontab -e command. See your system documentation for specific details on the 'cron' options.\n\nA cron entry that runs a daily backup looks similar to the following example:\n\n0 5 * * * couchbackup --url \"https://$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com\" --db \"animaldb\" > /path/to/folder/animaldb-backup-date -u \"+%Y-%m-%dT%H:%M:%SZ\".bak", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recovery"}, {"document_id": "ibmcld_00445-2996-3911", "score": 12.50200866277588, "text": "\n\"started_on\": 1363274083\n},\n{\n\"user\": \"acceptly\",\n\"updated_on\": 1363273779,\n\"type\": \"indexer\",\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"pid\": \"<0.20723.4070>\",\n\"changes_done\": 189,\n\"database\": \"shards/00000000-3fffffff/acceptly/acceptly_my_chances_logs_live.1321035717\",\n\"design_document\": \"_design/MyChancesLogCohortReport\",\n\"started_on\": 1363273094,\n\"total_changes\": 26389\n},\n{\n\"user\": \"username\",\n\"updated_on\": 1371118433,\n\"type\": \"search_indexer\",\n\"total_changes\": 5466,\n\"node\": \"dbcore@db7.meritage.cloudant.net\",\n\"pid\": \"<0.29569.7037>\",\n\"changes_done\": 4611,\n\"database\": \"shards/40000000-7fffffff/username/database_name\",\n\"design_document\": \"_design/lucene\",\n\"index\": \"search1\",\n\"started_on\": 1371118426\n},\n{\n\"view\": 1,\n\"user\": \"acceptly\",\n\"updated_on\": 1363273504,\n\"type\": \"view_compaction\",\n\"total_changes\": 26095,\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"pid\": \"<0.21218.4070>\",\n\"changes_done\": 20000,", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-active-tasks"}, {"document_id": "ibmcld_00445-2359-3178", "score": 12.188192877894053, "text": "\n\"checkpointed_source_seq\": \"403-g1AAAADfeJzLYWBgYMlgTmGQS0lKzi9KdUhJMjTRyyrNSS3QS87JL01JzCvRy0styQGqY0pkSLL___9_VmIymg5TXDqSHIBkUj1YUxyaJkNcmvJYgCRDA5AC6tuflZhGrPsgGg9ANAJtzMkCAPFSStc\",\n\"changes_pending\": 134,\n\"pid\": \"<0.1781.4101>\",\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"docs_written\": 0,\n\"missing_revisions_found\": 0,\n\"replication_id\": \"d0cdbfee50a80fd43e83a9f62ea650ad+continuous\",\n\"revisions_checked\": 0,\n\"source\": \"https://repl:@tsm.cloudant.com/tsm-admin/\",\n\"source_seq\": \"537-g1AAAADfeJzLYWBgYMlgTmGQS0lKzi9KdUhJMjTUyyrNSS3QS87JL01JzCvRy0styQGqY0pkSLL___9_VmI9mg4jXDqSHIBkUj1WTTityWMBkgwNQAqob39WYhextkE0HoBoBNo4MQsAFuVLVQ\",\n\"started_on\": 1363274083\n},\n{\n\"user\": \"acceptly\",\n\"updated_on\": 1363273779,\n\"type\": \"indexer\",\n\"node\": \"dbcore@db11.julep.cloudant.net\",\n\"pid\": \"<0.20723.4070>\",\n\"changes_done\": 189,", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-active-tasks"}, {"document_id": "ibmcld_00614-4378-5507", "score": 11.947580638286203, "text": "\ncurl \"https://$ACCOUNT.cloudant.com/_api/v2/monitoring/disk_use?cluster=myclustername&format=json\"\n\nSee an example result after you request disk use data in JSON format:\n\n[\n{\n\"target\": \"sumSeries(net.cloudant.mycustomer001.db.df.srv.used)\",\n\"datapoints\":\n523562172416.0, 1391019360],\n524413976576.0, 1391019420],\n519036682240.0, 1391019480],\n518762102784.0, 1391019540],\n523719393280.0, 1391019600]\n]\n},\n{\n\"target\": \"sumSeries(net.cloudant.mycustomer001.db.df.srv.free)\",\n\"datapoints\":\n6488926978048.0, 1391019360],\n6487768301568.0, 1391019420],\n6493145661440.0, 1391019480],\n6493420257280.0, 1391019540],\n4330660167680.0, 1391019600]\n]\n}\n]\nShow more\n\n\n\n\n\n With format=raw \n\nThe raw format data contains a series of text strings, identifying the name of the metric and associated values.\n\nThe text string (for example sumSeries(net.cloudant.mycustomer001.db.df.srv.used)) is the name of the metric. The next two numbers are the start and end times, expressed as UTC epoch seconds. The final number is the step size in seconds.\n\nThe numbers after the | character contain the metric data that is obtained from your chosen endpoint.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-monitoring-an-ibm-cloudant-cluster"}, {"document_id": "ibmcld_00580-24159-25838", "score": 11.83841959669563, "text": "\nCurl comes preinstalled on most Macs and Unix-like operating systems. If it's not present on your computer, Google curl and follow the installation instructions.\n\nLet's first use curl to fetch a web page - Google's home page.\n\n\n\n1. In a command-line terminal, type curl https://www.google.com.\n\nYou get a pageful of HTML in reply.\nIf this method works, then curl is installed, and you can proceed with the next tasks. Now, we don't want to type the URL of our IBM Cloudant service every time, so let's save the IBM Cloudant URL in an environment variable-called URL.\n2. Run the export URL command to create a variable that is called URL, which we can access later.\n\nexport URL=https://username:password@host\n3. Create an alias.\n\nalias acurl=\"curl -sgH 'Content-type: application/json'\"\n\nThis alias is a shortcut that is called acurl that saves us further typing. This acurl command is an alias for curl but with the JSON content-type header and a couple of useful command-line switches.\n4. Test the alias by fetching acurl $URL/. We get some JSON back from IBM Cloudant.\n\nYou completed your first IBM Cloudant API call. Now, our acurl alias is set up. We can start exploring the API. Let's start with the _all_dbs endpoint, which returns a list of databases.\n5. Type acurl $URL/_all_dbs to see an array of databases.\n\n\n\nA quick note here on formatting JSON on the command line. We can send the output of our acurl command to another tool, which formats the data nicely on the terminal. The following tools are available for your use:\n\n\n\n* Jq available from the URL on the page, which is more than just a JSON formatter - it allows JSON to be parsed, queried, and manipulated too.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_00540-1225-2251", "score": 11.792194486053821, "text": "\nFigure 1. Standard dashboard\n\nIf the Plan tab indicates that you're on the Standard plan, you don't need to read any further. You're already on a paid SLA-backed IBM Cloudant service. No further action is required.\n\n\n\n\n\n\n\n Step 2: Finding your legacy Enterprise plan \n\nYou can find your Enterprise plan in the IBM Cloudant Dashboard by following these steps.\n\n\n\n1. Open the IBM Cloudant Dashboard. For more information, see the [Getting started](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-navigate-the-dashboard) tutorial.\n2. If you're using a legacy Enterprise cloudant.com account, click Account.\n3. Review your cloudant.com Enterprise account on a dedicated cluster. The view doesn't include a Usage tab and looks like the following example:\n\nZoom\n\n![Review the information about the Enterprise plan in the IBM Cloudant Dashboard under Account.](https://cloud.ibm.com/docs-content/v1/content/522c6f62358b063f921283400a601c3f9bc66f08/Cloudant/images/cloudantcom_enterpriseplan_account.png)\n\nFigure 2. Enterprise plan", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan"}, {"document_id": "ibmcld_13159-1443-3030", "score": 11.623621416699017, "text": "\n[Architecture](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution64-serverless-webapp/architecture-serverless-api-webapp.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The user accesses the application hosted on the bucket in Object Storage\n2. The web application calls a backend API.\n3. The app with the backend API is deployed to Code Engine.\n4. The backend uses IBM Cloudant to store and retrieve guestbook entries.\n\n\n\n\n\n\n\n Step 1: Create the Guestbook database \n\nLet's start by creating a [IBM Cloudant](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudant) service instance. IBM Cloudant is a fully managed JSON document database. It is built upon and compatible with Apache CouchDB.\n\n\n\n1. In the [Catalog](https://cloud.ibm.com/catalog?category=databasesservices), under Services, go to the Databases category. Click on the IBM Cloudant tile. In the new dialog:\n\n\n\n1. Under Multitenant select a region.\n2. Under Configure Cloudant instance pick a unique name for the service, such as <yourinitials>-guestbook-db.\n3. Select a resource group.\n4. Select IAM as authentication method.\n5. Select the Lite plan. If you already have a Lite plan in your account, select another service plan.\n6. Click Create.\n\n\n\n2. Back in the [IBM Cloud Resource List](https://cloud.ibm.com/resources/), under Services, click on the IBM Cloudant instance you created to open the instance full details page. Note: You may be required to wait until the status of the service changes to Active.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-serverless-webapp"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10070-7-1616", "score": 30.374244389978898, "text": "\nCIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations.\n\nWhen a new Kubernetes version is released as part of a [supported Red Hat OpenShift version](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions), IBM engineers compare the default configuration of a cluster that runs that Kubernetes version against the benchmark and publishes the results in this documentation. You can review how specific versions of your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters meet the CIS Kubernetes Benchmark.\n\n\n\n Available benchmark versions \n\nUse the list to find CIS Kubernetes Benchmark results for available versions.\n\n\n\n* [Version 4.12](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-412)\n* [Version 4.11](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-411)\n* [Version 4.10](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-410)\n* [Version 4.9](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-49)\n* [Version 4.8](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-48)\n\n\n\n\n\n\n\n Using the benchmark \n\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark"}, {"document_id": "ibmcld_05608-7-1899", "score": 30.309894850921566, "text": "\nCIS Kubernetes Benchmark \n\nThe Center for Internet Security (CIS) publishes the [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/) as a framework of specific steps to configure Kubernetes more securely and with standards that are commensurate to various industry regulations.\n\nWhen a new [Kubernetes version](https://cloud.ibm.com/docs/containers?topic=containers-cs_versions) is released, IBM engineers compare the default configuration of a cluster that runs that Kubernetes version against the benchmark and publishes the results in this documentation. You can review how specific versions of your IBM Cloud\u00ae Kubernetes Service clusters meet the CIS Kubernetes Benchmark.\n\n\n\n Available benchmark versions \n\nUse the list to find CIS Kubernetes Benchmark results for available versions.\n\n\n\n* [Version 1.27](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-127)\n* [Version 1.26](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-126)\n* [Version 1.25](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-125)\n* [Version 1.24](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-124)\n* [Version 1.23](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123)\n\n\n\n\n\n\n\n Using the benchmark \n\nAs a security administrator or auditor, you might want to compare your company's internal standards and external regulatory requirements with the CIS Kubernetes Benchmark. The benchmark recommendations are provided by the Center for Internet Security, not by IBM. IBM might not configure default settings in a way that meets every recommendation, but documents whether the recommendation is met to help you in your review. For example, you might use the benchmark in an audit to confirm that basic security measures are in place, and to identify areas where you might enhance your security.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark"}, {"document_id": "ibmcld_05615-17992-19657", "score": 28.54767541425743, "text": "\n5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-124cis-benchmark-remediations-124) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces. Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker/default in your pod definitions. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-124cis-benchmark-remediations-124) Shared \n 5.6.3 Apply security context to your pods and containers. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-124cis-benchmark-remediations-124) Shared \n 5.6.4 The default namespace should not be used. Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-124cis-benchmark-remediations-124) Shared \n\n\n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/). \n 1.2.10 IBM Cloud Kubernetes Service does not enable the [EventRateLimit](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/eventratelimit) admission controller since it is a Kubernetes alpha feature.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-124"}, {"document_id": "ibmcld_05614-18132-19807", "score": 28.53111819093766, "text": "\n5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123cis-benchmark-remediations-123) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces. Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker/default in your pod definitions. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123cis-benchmark-remediations-123) Shared \n 5.6.3 Apply security context to your pods and containers. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123cis-benchmark-remediations-123) Shared \n 5.6.4 The default namespace should not be used. Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123cis-benchmark-remediations-123) Shared \n\n\n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/). \n 1.2.10 IBM Cloud Kubernetes Service does not enable the [EventRateLimit](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/eventratelimit) admission controller since it is a Kubernetes alpha feature.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-123"}, {"document_id": "ibmcld_05613-18132-19805", "score": 28.53111819093766, "text": "\n5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-122cis-benchmark-remediations-122) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces. Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker/default in your pod definitions. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-122cis-benchmark-remediations-122) Shared \n 5.6.3 Apply security context to your pods and containers. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-122cis-benchmark-remediations-122) Shared \n 5.6.4 The default namespace should not be used. Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-122cis-benchmark-remediations-122) Shared \n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/). \n 1.2.10 IBM Cloud Kubernetes Service does not enable the [EventRateLimit](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/eventratelimit) admission controller since it is a Kubernetes alpha feature.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-122"}, {"document_id": "ibmcld_10534-327288-328620", "score": 28.010019521668426, "text": "\n* [Clusters in Satellite locations without CoreOS enabled](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versionsos-satellite-without-coreos)\n\n\n\n* [Checking a cluster's Kubernetes server version](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versionsopenshift_server_version)\n* [Release lifecycle](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versionsrelease_lifecycle)\n* [Archive](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versionsversion-archive)\n\n\n\n[CIS Kubernetes Benchmark](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmarkcis-benchmark)\n\n\n\n* [Available benchmark versions](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmarkcis-benchmark-versions)\n* [Using the benchmark](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmarkcis-benchmark-use)\n\n\n\n* [What does the benchmark cover?](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmarkbenchmark-scope)\n* [What do the benchmark recommendations mean?](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmarkbenchmark-meaning)\n* [What parts of the benchmark am I responsible for?](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmarkbencmark-resp)\n* [What if some part of the service fails to comply with a recommendation?]", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_05616-18044-19639", "score": 27.955601993430406, "text": "\n5.5 Extensible admission control \n\n\n\nSection 5.5 Extensible admission control benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-125cis-benchmark-remediations-125) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored? Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces. Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker/default in your pod definitions. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-125cis-benchmark-remediations-125) Shared \n 5.6.3 Apply security context to your pods and containers. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-125cis-benchmark-remediations-125) Shared \n 5.6.4 The default namespace should not be used. Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-125cis-benchmark-remediations-125) Shared \n\n\n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-125"}, {"document_id": "ibmcld_05610-18106-19721", "score": 27.919725570419203, "text": "\n5.5 Extensible admission control \n\n\n\nSection 5.5 Extensible admission control benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-119cis-benchmark-remediations-119) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces. Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker/default in your pod definitions. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-119cis-benchmark-remediations-119) Shared \n 5.6.3 Apply security context to your pods and containers. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-119cis-benchmark-remediations-119) Shared \n 5.6.4 The default namespace should not be used. Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-119cis-benchmark-remediations-119) Shared \n\n\n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-119"}, {"document_id": "ibmcld_05612-18275-19890", "score": 27.919725570419203, "text": "\n5.5 Extensible admission control \n\n\n\nSection 5.5 Extensible admission control benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 5.5.1 Configure Image Provenance using ImagePolicyWebhook admission controller. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-121cis-benchmark-remediations-121) Shared \n\n\n\n\n\n\n\n 5.6 General policies \n\n\n\nSection 5.6 General policies benchmark results\n\n Section Recommendation Scored/Not Scored Level Result Responsibility \n\n 5.6.1 Create administrative boundaries between resources using namespaces. Not Scored 1 Pass Shared \n 5.6.2 Ensure that the seccomp profile is set to docker/default in your pod definitions. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-121cis-benchmark-remediations-121) Shared \n 5.6.3 Apply security context to your pods and containers. Not Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-121cis-benchmark-remediations-121) Shared \n 5.6.4 The default namespace should not be used. Scored 2 [Fail](https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-121cis-benchmark-remediations-121) Shared \n\n\n\n\n\n\n\n\n\n IBM remediations and explanations \n\nReview information from IBM on the CIS Benchmark results.\n\n\n\nExplanation and remediation\n\n Section Remediation/Explanation \n\n 1.2.1 IBM Cloud Kubernetes Service utilizes RBAC for cluster protection, but allows anonymous discovery, which is considered reasonable per [CIS Kubernetes Benchmark](https://www.cisecurity.org/benchmark/kubernetes/).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cis-benchmark-121"}, {"document_id": "ibmcld_10534-364509-365767", "score": 27.68676418237643, "text": "\n[Red Hat OpenShift on IBM Cloud version 4.10 CIS Kubernetes Benchmark](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-410cis-benchmark-410)\n\n\n\n* [1 Master node security configuration](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-410cis-benchmark-1-410)\n\n\n\n* [1.1 Master node configuration files](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-410cis-benchmark-11-410)\n* [1.2 API server](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-410cis-benchmark-12-410)\n* [1.3 Controller manager](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-410cis-benchmark-13-410)\n* [1.4 Scheduler](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-410cis-benchmark-14-410)\n\n\n\n* [2 Etcd node configuration](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-410cis-section-2-410)\n* [3 Control plane configuration](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-410cis-section-3-410)\n\n\n\n* [3.1 Authentication and authorization](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-410cis-benchmark-31-410)\n* [3.2 Logging](https://cloud.ibm.com/docs/openshift?topic=openshift-cis-benchmark-410cis-benchmark-32-410)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03113-4-2033", "score": 18.81436196328015, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Modifying a dialog using the API \n\nThe Watson Assistant REST API supports modifying your dialog programmatically, without using the Watson Assistant tool. You can use the /dialog_nodes API to create, delete, or modify dialog nodes.\n\nRemember that the dialog is a tree of interconnected nodes, and that it must conform to certain rules in order to be valid. This means that any change you make to a dialog node might have cascading effects on other nodes, or on the structure of your dialog. Before using the /dialog_nodes API to modify your dialog, make sure you understand how your changes will affect the rest of the dialog. You can make a backup copy of the current dialog by exporting the conversational skill in which it resides. See [Downloading a skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-tasksskill-tasks-download) for details.\n\nA valid dialog always satisfies the following criteria:\n\n\n\n* Each dialog node has a unique ID (the dialog_node property).\n* A child node is aware of its parent node (the parent property). However, a parent node is not aware of its children.\n* A node is aware of its immediate previous sibling, if any (the previous_sibling property). This means that all siblings that share the same parent form a linked list, with each node pointing to the previous node.\n* Only one child of a given parent can be the first sibling (meaning that its previous_sibling is null).\n* A node cannot point to a previous sibling that is a child of a different parent.\n* Two nodes cannot point to the same previous sibling.\n* A node can specify another node that is to be executed next (the next_step property).\n* A node cannot be its own parent or its own sibling.\n* A node must have a type property that contains one of the following values. If no type property is specified, then the type is standard.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-modify"}, {"document_id": "ibmcld_03270-3352-5135", "score": 18.34488343514625, "text": "\nAdd a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\nFor more information about different service desk solutions, see the following resources:\n\n\n\n* [Adding service desk support to the web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-haa)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-support"}, {"document_id": "ibmcld_03113-6206-7586", "score": 18.107529334163793, "text": "\n[Example dialog](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog_api_1.png)\n\nWe can create a new node by making a POST request to /dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n![Example dialog 2](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog_api_2.png)\n\nBecause node_8 was created without specifying a value for parent or previous_sibling, it is now the first node in the dialog. Note that in addition to creating node_8, the service also modified node_1 so that its previous_sibling property points to the new node.\n\nYou can create a node somewhere else in the dialog by specifying the parent and previous sibling:\n\n{\n\"dialog_node\": \"node_9\",\n\"parent\": \"node_2\",\n\"previous_sibling\": \"node_5\"\n}\n\nThe values you specify for parent and previous_node must be valid:\n\n\n\n* Both values must refer to existing nodes.\n* The specified parent must be the same as the parent of the previous sibling (or null, if the previous sibling has no parent).\n* The parent cannot be a node of type response_condition or event_handler.\n\n\n\nThe resulting dialog looks like this:\n\n![Example dialog 3](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog_api_3.png)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-modify"}, {"document_id": "ibmcld_03113-4996-6502", "score": 18.071851732991156, "text": "\n[UI location where the code that is triggered by named event handlers is authored](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/api-event-handlers.png)\n* A node of type event_handler with an event_name of generic can have a parent of type slot or frame.\n* A node of type event_handler with an event_name of focus, input, filled, or nomatch must have a parent of type slot.\n* If more than one event_handler with the same event_name is associated with the same parent node, then the order of the siblings reflects the order in which the event handlers will be executed.\n* For event_handler nodes with the same parent slot node, the order of execution is the same regardless of the placement of the node definitions. The events are triggered in this order by event_name:\n\n\n\n1. focus\n2. input\n3. filled\n4. generic*\n5. nomatch\n\n\n\n*If an event_handler with the event_name generic is defined for this slot or for the parent frame, then it is executed between the filled and nomatch event_handler nodes.\n\n\n\nThe following examples show how various modifications might cause cascading changes.\n\n\n\n Creating a node \n\nConsider the following simple dialog tree:\n\n![Example dialog](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dialog_api_1.png)\n\nWe can create a new node by making a POST request to /dialog_nodes with the following body:\n\n{\n\"dialog_node\": \"node_8\"\n}\n\nThe dialog now looks like this:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-dialog-modify"}, {"document_id": "ibmcld_02882-27313-29495", "score": 18.066167220506983, "text": "\nThis response type only returns a valid response if the assistant to which you added this dialog skill also has a search skill associated with it.\n\n\n\n2. Click Add response to add another response type to the current response.\n\nYou might want to add multiple response types to a single response to provide a richer answer to a user query. For example, if a user asks for store locations, you could show a map and display a button for each store location that the user can click to get address details. To build that type of response, you can use a combination of image, options, and text response types. Another example is using a text response type before a pause response type so you can warn users before pausing the dialog.\n\nYou cannot add more than 5 response types to a single response. Meaning, if you define three conditional responses for a dialog node, each conditional response can have no more than 5 response types added to it.\n\nA single dialog node cannot have more than one Connect to human agent or more than one Search skill response.\n3. If you added more than one response type, you can click the Move up or down arrows to arrange the response types in the order you want your assistant to process them.\n\n\n\n\n\n\n\n\n\n Conditional responses \n\nA single dialog node can provide different responses, each one triggered by a different condition. Use this approach to address multiple scenarios in a single node.\n\nThe node still has a main condition, which is the condition for using the node and processing the conditions and responses that it contains.\n\nIn this example, your assistant uses information that it collected earlier about the user's location to tailor its response, and provide information about the store nearest the user. See [Context variables](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables) for more information about how to store information collected from the user.\n\n![Shows a node that shows a user ask, Where are you located, and the dialog has three different responses depending on conditions that use info from the $state context variable to specify locations in those states.]", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overview"}, {"document_id": "ibmcld_02952-3289-5462", "score": 18.003059095490343, "text": "\nAdd meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.\n\n![Screen capture of the field in the node edit view where you add the node purpose summary.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/disambig-node-purpose.png)\n\nEvery dialog branch can be processed by the assistant while it chats with a customer, including branches with root nodes in folders.\n4. If a child node in any dialog branch conditions on a request or question that you do not want the assistant to handle, add a Connect to human agent response type to the child node.\n\nAt run time, if the conversation reaches this child node, the dialog is passed to a human agent at that point.\n\n\n\nYour dialog is now ready to support transfers from your assistant to a service desk agent.\n\n\n\n\n\n Measuring containment \n\nFrom the Analytics page, you can measure conversation containment. Containment is the rate at which your assistant is able to satisfy a customer's request without human intervention per conversation.\n\nTo measure containment accurately, the metric must be able to identify when a human intervention occurs. The metric primarily uses the Connect to human agent response type as an indicator. If a user conversation log includes a call to a Connect to human agent response type, then the conversation is considered to be not contained.\n\nHowever, not all human interventions are transacted by using a Connect to human agent response type. If you use an alternate method to deliver additional support, you must take additional steps to register the fact that the customer's need was not fulfilled by the assistant. For example, you might direct customers to your call center phone number or to an online support ticket form URL.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-support"}, {"document_id": "ibmcld_03273-11911-13556", "score": 17.98103100297602, "text": "\n[More icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png) icon on the folder, and then select Add node to folder.\n\nThe dialog node is added to the end of the dialog tree within the folder.\n\n\n\n\n\n\n\n\n\n Deleting a folder \n\nYou can delete either a folder alone or the folder and all of the dialog nodes in it.\n\nTo delete a folder, complete the following steps:\n\n\n\n1. From the tree view of the Dialog tab, find the folder that you want to delete.\n2. Click the More![More icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png) icon on the folder, and then select Delete.\n3. Do one of the following things:\n\n\n\n* To delete the folder only, and keep the dialog nodes that are in the folder, deselect the Delete the nodes inside the folder checkbox, and then click Yes, delete it.\n* To delete the folder and all of the dialog nodes in it, click Yes, delete it.\n\n\n\n\n\nIf you deleted the folder only, then the nodes that were in the folder are displayed in the dialog tree in the spot where the folder used to be.\n\n\n\n\n\n\n\n Dialog node limits \n\nThe number of dialog nodes you can create per skill depends on your plan type.\n\n\n\nPlan details\n\n Plan Dialog nodes per skill \n\n Enterprise 100,000 \n Premium (legacy) 100,000 \n Plus 100,000 \n Trial 25,000 \n Lite 25,000 \n\n\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\n\n\n\n\n Finding a dialog node by its node ID", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-tasks"}, {"document_id": "ibmcld_03188-1732-3801", "score": 17.93148026505072, "text": "\n* To add an entire dialog branch that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.chat, to the If assistant recognizes field of the dialog root node.\n* To add a single dialog node that is only processed by a specific integration type, add the appropriate integration type context variable, such as $integrations.zendesk, to the If assistant recognizes field of the dialog child node.\n* To add slightly different responses for a single dialog node based on the integration type, complete the following steps:\n\n\n\n* From the node's edit view, click Customize and then set the Multiple conditioned responses switch to On. Click Apply.\n* In the dialog node response section, add the appropriate condition and corresponding response for each custom response type.\n\n\n\nThe following examples show how to specify a hypertext link in the best format for the integration where the text response will be displayed. For the Web chat integration, which supports Markdown formatting, you can include a link label in the response text to make the response look nicer. For the SMS with Twilio integration, you can skip the formatting that makes sense in a web page, and add the straight URL.\n\n\n\nCustom conditioned responses\n\n Integration type Condition Sample text response \n\n SMS with Twilio `$integrations.text_messaging` `For more information, go to https://www.ibm.com.` \n Web chat `$integrations.chat` `For more information, go to [the ibm.com site](https://www.ibm.com).` \n Response to show if no other conditions are met. `true` `For more information, go to ibm.com.` \n\n\n\n\n\nThe rich response types often behave differently when they are displayed in different built-in integrations or in the assistant preview. For more information about these unique behaviors, see the following topics:\n\n\n\n* [Web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-dialog)\n\n\n\n\n\n* [Phone](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-dialog)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-integrations"}, {"document_id": "ibmcld_02952-1632-3754", "score": 17.825478301998388, "text": "\nCreate an intent that can recognize when a customer asks to speak to someone. After defining the intent, you can add a root-level dialog node that conditions on the intent. As the dialog node response, add a Connect to human agent response type. At run time, if the user asks to speak to someone, this node is triggered and a transfer is initiated on the user's behalf.\n* When the conversation broaches a topic that is sensitive in nature, you can start a transfer.\n\nFor example, an insurance company might want questions about bereavement benefits always to be handled by a person. Or, if a customer wants to close an account, you might want to transfer the conversation to a respresentative who is authorized to offer incentives to keep the customer's business.\n* When the assistant repeatedly fails to understand a customer's request. Instead of asking the customer to retry or rephrase the question over and over, your assistant can offer to transfer the customer to a human agent.\n\n\n\nTo design a dialog that can transfer the conversation, complete the following steps:\n\n\n\n1. Add an intent to your skill that can recognize a user's request to speak to a human.\n\nYou can create your own intent or add the prebuilt intent named General_Connect_to_Agent that is provided with the General content catalog.\n2. Add a root node to your dialog that conditions on the intent you created in the previous step. Choose Connect to human agent as the response type.\n\nFor more information, see [Adding a Connect to human agent response type](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. Add meaningful names to the dialog nodes in your dialog.\n\nWhen a conversation is transferred to an agent, the name of the most-recently processed dialog node is sent with it. To ensure that a useful summary is provided to service desk agents when a conversation is transferred to them, add short dialog node names that reflect the node's purpose. For example, Find a store.\n\nSome older skills specify the purpose of the node in the external node name field instead.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-support"}, {"document_id": "ibmcld_03054-27011-29125", "score": 17.805093531213984, "text": "\nFollow this procedure to make it less likely that the dialog will respond by resetting the confidence level threshold from the default setting of 0.2 to 0.5. Changing the confidence level threshold to 0.5 instructs your assistant to not respond with an answer from the dialog unless the assistant is more than 50% confident that the dialog can understand the user's intent and can address it.\n\n\n\n1. From the Dialog page of your dialog skill, make sure that the last node in the dialog tree has an anything_else condition with a search skill response type.\n\nWhenever this node is processed, the search skill is triggered.\n2. Add a folder to the dialog. Position the folder before the first dialog node that you want to de-emphasize. Add the following condition to the folder:\n\nintents[0].confidence > 0.5\n\nThis condition is applied to all of the nodes in the folder. The condition tells your assistant to process the nodes in the folder only if your assistant is at least 50% confident that it knows the user's intent.\n3. Move any dialog nodes that you do not want your assistant to process often into the folder.\n\n\n\nAfter changing the dialog, test the assistant to make sure the search skill is triggered as often as you want it to be.\n\nAn alternative approach is to teach the dialog about topics to ignore. To do so, you can add utterances that you want the assistant to send to the search skill immediately as test utterances in the dialog skill's Try it out pane. You can then select the Mark as irrevlant option within the Try it out pane to teach the dialog not to respond to this utterance or others like it.\n\n\n\n\n\n Disabling search \n\nYou can disable the search skill from being triggered.\n\nYou might want to do so temporarily, while you are setting up the integration. Or you might want to only ever trigger a search for specific user queries that you can identify within the dialog, and use a search skill response type to answer.\n\nTo prevent the search skill from being triggered, complete the following steps:\n\n\n\n1. From the Assistants page, click the menu for your assistant, and then choose Settings.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16258-1324-3123", "score": 21.069397697013066, "text": "\n[Time period](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_16258-7-1952", "score": 21.03209164481625, "text": "\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_02837-1397-3349", "score": 20.057416741156885, "text": "\n[Diagram of the components used by the assistant service](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/components.png)\n\nThe following sections provide more detail about each resource that is used by the system. The objective is to give you information that can help you to do initial resource planning and help you to manage changes in data needs over time.\n\n\n\n Microservices \n\nWatson Assistant consists of the following stateless microservices:\n\n\n\n* Analytics: Logs conversations that take place between the assistant and your customers. These user conversation logs are available from the Analytics page in the product and from the /logs API endpoint. Introduced with the 1.5.0 release. The Analytics feature relies on a microservice that is supported only on Red Hat OpenShift 4.5 and later.\n* CLU: A Conversational Language Understanding interface, also known as Natural Language Understanding (NLU), that is an entry point to the language understanding pipeline, which is where text is analyzed to find intent and entity mentions. The Store microservice uses the LiteLinks protocol to call this microservice to initiate machine learning training. The NLU microservice controls the lifecycle of the machine learning models. It maps the workspace ID that is used by the Store microservice to the machine language understanding pipeline's internal ID. The NLU microservice uploads the training data for machine learning models to the MinIO object storage. When a language model needs to be trained, such as after intents are edited, the NLU microservice calls the Master microservice. When the updated model is available, NLU calls the TAS microservice to analyze the user input that is provided by the customer. The workspace ID has a UUID format. The internal IDs of models in the language understanding pipeline typically follows the regular expression pattern, vn-[0-9a-f]-[0-9a-f].", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-architecture"}, {"document_id": "ibmcld_07578-84096-86060", "score": 20.002139950878846, "text": "\n[Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's Try it out pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tasks). \n Web chat An integration that you can use to embed your assistant in your company website. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat). \n Webhook A mechanism for calling out to an external program as part of the dialog. For example, if a customer asks the assistant to translate a string from English to French, the dialog can call an external language translation service to translate the phrase and return the translation to the customer in the course of the conversation. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-webhooks). \n\n\n\n* I don\u2019t see the Analytics page\n\nYou can only view the Analytics page if the system administrator enabled the feature in your deployment. A prerequisite service that is required by the feature is only available on OpenShift Red Hat 4.5; it is not available on 3.11.\n* Where can I find an example for creating my first assistant?\n\nFollow the steps in the [Getting started with Watson Assistant](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page. You can, however, use the /logs API to list events from the transcripts of conversations that occurred between your users and your assistant.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-84071-86035", "score": 20.002139950878846, "text": "\n[Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-system-entities). \n Try it out A chat window that you use to test as you build. For example, from the dialog skill's Try it out pane, you can mimic the behavior of a customer and enter a query to see how the assistant responds. You can test only the current skill; you cannot test your assistant and all attached skills from end to end. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tasks). \n Web chat An integration that you can use to embed your assistant in your company website. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat). \n Webhook A mechanism for calling out to an external program as part of the dialog. For example, if a customer asks the assistant to translate a string from English to French, the dialog can call an external language translation service to translate the phrase and return the translation to the customer in the course of the conversation. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-webhooks). \n\n\n\n* I don\u2019t see the Analytics page\n\nYou can only view the Analytics page if the system administrator enabled the feature in your deployment. A prerequisite service that is required by the feature is only available on OpenShift Red Hat 4.5; it is not available on 3.11.\n* Where can I find an example for creating my first assistant?\n\nFollow the steps in the [Getting started with Watson Assistant](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n* Can I export the user conversations from the Analytics page?\n\nYou cannot directly export conversations from the User conversation page. You can, however, use the /logs API to list events from the transcripts of conversations that occurred between your users and your assistant.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03162-10976-13038", "score": 19.977355351581583, "text": "\nThe routing rules identify the queue of agents to which messages from the assistant are transferred by default.\n\nThe code that you add to the setup page when you configure the service desk integration shares the following required information with Watson Assistant:\n\n\n\n* organization_id: Unique ID of the organization. A company can have more than one organization set up in Salesforce.\n* chat_api_endpoint: Salesforce API endpoint that is used by the integration to communicate with Salesforce.\n* deployment_id: Unique ID of the deployment. An organization can have multiple deployments.\n* button_id: Unique ID of a button, which defines the specific routing rules for incoming messages. Each deployment can have multiple buttons associated with it.\n\n\n\nTo override the default routing rules, you must specify a new value for the button_id. Before you perform this procedure, find out the ID of the Salesforce button implementation with the alternative routing rules that you want to use.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific group of Salesforce agents which is distinct from the default group.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Salesforce from the Service desk routing field.\n4. In the Button ID field, add the button_id value for the alternate routing destination that you want the assistant to use for conversations about only this topic. For example, 5733i0000008yGz.\n\nBe sure to specify the exact right syntax for the button_id value. The value is not validated by the service as you add it to your dialog.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-salesforce"}, {"document_id": "ibmcld_02844-1555-3643", "score": 19.837879836799498, "text": "\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-audit-events"}, {"document_id": "ibmcld_16262-6573-7996", "score": 19.74036270553597, "text": "\n{\n\"output\": {\n\"generic\": [!\n{\n\"response_type\": \"text\",\n\"text\": \"Welcome to the Watson Assistant example\"\n}\n],\n\"intents\": [\n{\n\"intent\": \"hello\",\n\"confidence\": 1\n}\n],\n\"entities\": []\n},\n\"user_id\": \"my_user_id\",\n\"context\": {\n\"global\": {\n\"system\": {\n\"turn_count\": 1,\n\"user_id\": \"my_user_id\"\n}\n},\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"account_number\": \"123456\"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n Restoring conversation state \n\nIn some situations, you might want the ability to restore a conversation to a previous state.\n\nYou can use the export option on stateful message requests to specify that you want the context object in the response to include complete session state data. If you specify true for this option, the returned skill context includes an encoded state property that represents the current conversation state.\n\nIf you are using the stateful message API, the service stores conversation state data only for the life of the session. However, if you save this context data (including state) and send it back to the service with a subsequent message request, you can restore the conversation to the same state, even if the original session expired or was deleted.\n\nIf you are using the stateless message API, the state property is always included in responses (along with the rest of context). Although stateless sessions do not expire, you can still use this state data to reset a conversation to a previous state.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-client-get-context"}, {"document_id": "ibmcld_03369-162577-164737", "score": 19.69462194135906, "text": "\nSee the [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support) topic for details.\n\n\n\n\n\n 16 June 2017 \n\nRecommendations (Beta - Premium users only)\n: The Improve panel also includes a Recommendations page that recommends ways to improve your system by analyzing the conversations that users have with your chatbot, and taking into account your system's current training data and response certainty.\n\n\n\n\n\n 14 June 2017 \n\nFuzzy matching for additional languages (Beta)\n: Fuzzy matching for entities is now available for additional languages, as noted in the [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support) topic. You can turn on fuzzy matching per entity to improve the ability of your assistant to recognize terms in user input with syntax that is similar to the entity, without requiring an exact match. The feature is able to map user input to the appropriate corresponding entity despite the presence of misspellings or slight syntactical differences. For example, if you define giraffe as a synonym for an animal entity, and the user input contains the terms giraffes or girafe, the fuzzy match is able to map the term to the animal entity correctly. See [Fuzzy matching](https://cloud.ibm.com/docs/assistant?topic=assistant-entitiesentities-fuzzy-matching) for details.\n\n\n\n\n\n 13 June 2017 \n\nUser conversations\n: The Improve panel now includes a User conversations page, which provides a list of user interactions with your chatbot that can be filtered by keyword, intent, entity, or number of days. You can open individual conversations to correct intents, or to add entity values or synonyms.\n\nRegex change\n: The regular expressions that are supported by SpEL functions like find, matches, extract, replaceFirst, replaceAll and split have changed. A group of regular expression constructs are no longer allowed, including look-ahead, look-behind, possessive repetition and backreference constructs. This change was necessary to avoid a security exposure in the original regular expression library.\n\n\n\n\n\n 12 June 2017 \n\nUpdates\n: This release includes the following updates:", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_02990-5902-7810", "score": 19.31217070774869, "text": "\n[Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tasks). \n Web chat An integration that you can use to embed your assistant in your company website. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat). \n Webhook A mechanism for calling out to an external program as part of the dialog. For example, if a customer asks the assistant to translate a string from English to French, the dialog can call an external language translation service to translate the phrase and return the translation to the customer in the course of the conversation. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-webhooks). \n\n\n\n\n\n\n\n I don\u2019t see the Analytics page \n\nYou can only view the Analytics page if the system administrator enabled the feature in your deployment. A prerequisite service that is required by the feature is only available on OpenShift Red Hat 4.5; it is not available on 3.11.\n\n\n\n\n\n Where can I find an example for creating my first assistant? \n\nFollow the steps in the [Getting started with Watson Assistant](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started) tutorial for a product introduction and to get help creating your first assistant.\n\n\n\n\n\n Can I export the user conversations from the Analytics page? \n\nYou cannot directly export conversations from the User conversation page. You can, however, use the /logs API to list events from the transcripts of conversations that occurred between your users and your assistant. For more information, see the [API reference](https://cloud.ibm.com/apidocs/assistant-data-v1listlogs) and the [Filter query reference](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-filter-reference).\n\n\n\n\n\n Can I export and import dialog nodes? \n\nNo, you cannot export and import dialog nodes from the product user interface.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-faqs"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08056-3796-5774", "score": 60.22457441187324, "text": "\nTo upgrade your support plan, contact a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative.\n\n\n\n\n\n How do I change my email preferences for notifications? \n\nYou can change which email notifications you receive for planned events, unplanned events, and announcements in your profile settings. To change your email preferences, choose one of the following options:\n\n\n\n* Go to [Notifications](https://cloud.ibm.com/user/notifications) in your profile settings.\n* For control.softlayer.com, you can change your email preferences by going to Account > Users > Email Preferences.\n\n\n\n\n\n\n\n How am I charged for support? \n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https://cloud.ibm.com/docs/account?topic=account-userroles).\n\n\n\n\n\n How can I upgrade my support plan? \n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n\n\n\n\n\n Why can't I see my support cases? \n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon !", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-get-supportfaq"}, {"document_id": "ibmcld_03729-7-2197", "score": 60.06106869374221, "text": "\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_08067-0-1736", "score": 59.965572483348076, "text": "\n\n\n\n\n\n\n  Viewing your support costs \n\nIf you have Advanced or Premium support, you can keep track of your monthly support costs from the Support costs page in the IBM Cloud\u00ae console.\n\n\n\n  How you're charged for support \n\nEach [IBM Cloud support plan](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans) has a minimum monthly price for providing support for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost. For details about your purchased support plan, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\n\n\n\n\n  Viewing support costs \n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https://cloud.ibm.com/docs/account?topic=account-userroles).\n\nIn the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. You can view your support plan and relevant cost details:\n\n\n\n*  If your support costs are billed monthly, you can view your costs for the current month. These costs include the starting price for the plan and any additional costs from your resource usage. After each billing cycle, these charges are added to your monthly invoice.\n*  If you have a support subscription, you can view the remaining credit in your active subscriptions and any overages for the current month. Overage is charged if you run out of credit in your active subscriptions. You can also view upcoming support subscriptions, which are subscriptions that you bought but are not yet valid.\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-support"}, {"document_id": "ibmcld_07578-1033424-1035350", "score": 59.5765689320682, "text": "\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https://cloud.ibm.com/docs/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https://cloud.ibm.com/icons/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https://cloud.ibm.com/docs/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1033295-1035221", "score": 59.5765689320682, "text": "\n* How am I charged for support?\n\nIf you have Advanced or Premium support, you can track your monthly support costs. In the IBM Cloud console, go to Manage > Billing and usage, and select Support costs. Each support plan has a minimum monthly support price for your cloud workload at the stated service level. Beyond this starting price, any additional costs for support are based on your resource usage. The higher your resource usage, the higher your total support cost.\n\nCharges for support of third-party services are not included in the Advanced or Premium Support charge calculations. These non-IBM programs are licensed directly by their providers.\n\nTo view your support costs, you need an access policy with the Administrator role on the Billing account management service. For more information about access roles, see [IAM access](https://cloud.ibm.com/docs/account?topic=account-userroles).\n* How can I upgrade my support plan?\n\nIf you want to upgrade your support plan, contact a [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative. For more information on the different support plans, see [Basic, Advanced, and Premium Support plans](https://cloud.ibm.com/docs/get-support?topic=get-support-support-plans).\n* Why can't I see my support cases?\n\nTo access your support cases, from the IBM Cloud console menu bar, click the Help icon ![Help icon](https://cloud.ibm.com/icons/help.svg) > Support center, and click Manage cases. If you're unable to view your cases, try clicking View classic infrastructure cases.\n\nIf you still can't view them, you might not have the required permission. Ask your account owner to add you to the support case access group. For more information, see [SoftLayer account permissions](https://cloud.ibm.com/docs/account?topic=account-migrated_permissions).\n* How do I get support for non-IBM Cloud products?\n\nSome cloud-based IBM products are not offered in IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03776-3313-5682", "score": 54.50458610997075, "text": "\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-overview"}, {"document_id": "ibmcld_08474-7-1664", "score": 53.11205277442632, "text": "\nFAQs: Pricing \n\nRead to get answers for questions about IBM Cloud\u00ae Hyper Protect Crypto Services pricing.\n\n\n\n How am I charged for my use of Hyper Protect Crypto Services standard plan? \n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. If you also enable [failover crypto units](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-understand-conceptscrypto-unit-concept), each failover crypto unit is also charged the same as the operational crypto unit.\n\nThe first 5 keystores, including KMS key rings and EP11 keystores, are free of charge. Each additional key ring or EP11 keystore is charged with a tiered pricing starting at $225 USD per month. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https://cloud.ibm.com/catalog/services/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-faq-pricing"}, {"document_id": "ibmcld_07578-1181831-1183629", "score": 52.58936745990907, "text": "\n* Can I add or remove crypto units after I provision a service instance?\n\nYes, you can request to add or remove crypto units by raising support tickets in the IBM Cloud\u00ae Support Center. For detailed instructions, see [Adding or removing crypto units](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-add-remove-crypto-units).\n* Is there a Service Level Agreement (SLA) specifically for Hyper Protect Crypto Services?\n\nYes, you can find the [SLA](https://www-03.ibm.com/software/sla/sladb.nsf/sla/bm-8506-01) for detailed terms.\n* How am I charged for my use of Hyper Protect Crypto Services standard plan?\n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. If you also enable [failover crypto units](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-understand-conceptscrypto-unit-concept), each failover crypto unit is also charged the same as the operational crypto unit.\n\nThe first 5 keystores, including KMS key rings and EP11 keystores, are free of charge. Each additional key ring or EP11 keystore is charged with a tiered pricing starting at $225 USD per month. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https://cloud.ibm.com/catalog/services/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours)", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1184464-1186262", "score": 52.58936745990907, "text": "\n* Can I add or remove crypto units after I provision a service instance?\n\nYes, you can request to add or remove crypto units by raising support tickets in the IBM Cloud\u00ae Support Center. For detailed instructions, see [Adding or removing crypto units](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-add-remove-crypto-units).\n* Is there a Service Level Agreement (SLA) specifically for Hyper Protect Crypto Services?\n\nYes, you can find the [SLA](https://www-03.ibm.com/software/sla/sladb.nsf/sla/bm-8506-01) for detailed terms.\n* How am I charged for my use of Hyper Protect Crypto Services standard plan?\n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. If you also enable [failover crypto units](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-understand-conceptscrypto-unit-concept), each failover crypto unit is also charged the same as the operational crypto unit.\n\nThe first 5 keystores, including KMS key rings and EP11 keystores, are free of charge. Each additional key ring or EP11 keystore is charged with a tiered pricing starting at $225 USD per month. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https://cloud.ibm.com/catalog/services/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours)", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03729-4932-7001", "score": 52.20371096762576, "text": "\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges\n: You select a plan and pay on a flat rate basis. For example, the Bare Metal Servers are charged at a flat-rate.\n\nMetered charges\n: You pay based on your runtime and service consumption. For example, with the Push service, any usage over the free monthly allowance is charged.\n\nReserved charges\n: As the account owner of a Pay As You Go account or a Subscription account, you can reserve a service instance, with a long-term commitment, for a discounted price. For example, you can reserve the standard large Db2 on Cloud offering for 12 months.\n: Some IBM Cloud services offer reserved plans. You can request a reserved plan from the IBM Cloud catalog by clicking the tile of the service. Then, select the service plan that best meets your needs. If a reserved plan is available, click Request, and follow the prompts to send your request. You receive an email that contains the price information of the reserved plan. An IBM Cloud sales representative also contacts you soon to complete the purchase.\n\nTiered charges\n: Similar to metered charges, you pay based on your runtime and service consumption. However, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10534-106135-107366", "score": 13.177713956640229, "text": "\n* [Run the installation command](https://cloud.ibm.com/docs/openshift?topic=openshift-cli-installcli-install-include-step1-install-idt)\n* [Verify the installation](https://cloud.ibm.com/docs/openshift?topic=openshift-cli-installcli-install-include-step2-verify-idt)\n* [Install CLI plug-ins and tools](https://cloud.ibm.com/docs/openshift?topic=openshift-cli-installcli-install-include-step3-install-idt-manually)\n* [Install the Red Hat OpenShift CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-cli-installinstall-kubectl-cli)\n\n\n\n[Updating the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-cli-updatecli-update)\n\n\n\n* [Updating the IBM Cloud CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-cli-updatecli-update-include-update-ibmcloud-cli)\n* [Updating installed plug-ins](https://cloud.ibm.com/docs/openshift?topic=openshift-cli-updatecli-update-include-cli-update-plugin)\n\n\n\n[Setting up the API](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_api_installcs_api_install)\n\n\n\n* [About the API](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_api_installapi_about)\n* [Automating cluster deployments with the API](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_api_installcs_api)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_14493-7568-8722", "score": 13.030386841103605, "text": "\nThese commands are used in the SSH session to the bastion node that has root privileges. Replace 4.x with the current Red Hat OpenShift version, for example, 4.7.\n\n Download unzip\nyum install -y wget unzip\n\n Create an installation directory and make it the working directory\nmkdir -p /opt/ocpinstall\ncd /opt/ocpinstall\n\n Download the OpenShift installer and client tools\nwget https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest-4.x/openshift-client-linux.tar.gz\nwget https://mirror.openshift.com/pub/openshift-v4/clients/ocp/latest-4.x/openshift-install-linux.tar.gz\n\n Extract the downloaded bundles\ntar -xvf openshift-client-linux.tar.gz\ntar -xvf openshift-install-linux.tar.gz\n\n Move commands to /usr/local/bin for ease of use\nmv kubectl oc openshift-install /usr/local/bin\nmv openshift-install /usr/local/bin\n\n Install git and clone the OpenShift installer\nyum install -y git\ngit clone -b release-4.x https://github.com/openshift/installer\n\n Download and extract terraform\nwget https://releases.hashicorp.com/terraform/0.11.13/terraform_0.11.13_linux_amd64.zip\nunzip terraform_0.11.13_linux_amd64.zip\nmv terraform /usr/local/bin\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-bastion-intro"}, {"document_id": "ibmcld_14493-6240-7938", "score": 13.014970620168818, "text": "\nAdd your SSH private key to the ssh-agent:\n\nssh-add /root/.ssh/id_rsa\n\n\n\n\n\n\n\n\n\n Downloading the installation tools \n\nFor more information about installing Red Hat OpenShift 4.7, see [Installing a cluster on vSphere with user-provisioned infrastructure](https://docs.openshift.com/container-platform/4.7/installing/installing_vsphere/installing-vsphere.html).\n\nFor more information about how to access the Red Hat OpenShift user provider infrastructure, see [Internet and Telemetry access for Red Hat OpenShift Container Platform](https://docs.openshift.com/container-platform/4.7/installing/installing_vsphere/installing-vsphere.htmlcluster-entitlements_installing-vsphere).\n\nBefore you install the Red Hat OpenShift Container Platform, you need to download a number of files onto the bastion node and then extract them. The following actions are completed:\n\n\n\n* Download unzip to extract the downloaded files.\n* Create an installation directory and make it the working directory.\n* Download the Red Hat OpenShift installation and client tools.\n* Extract the downloaded bundles.\n* Move commands to /usr/local/bin for ease of use.\n* Install Git to download the Red Hat OpenShift installer.\n* Clone the installer repository to the bastion node.\n* Download and extract Terraform to the /usr/local/bin directory for ease of use.\n\n\n\nThese commands are used in the SSH session to the bastion node that has root privileges. Replace 4.x with the current Red Hat OpenShift version, for example, 4.7.\n\n Download unzip\nyum install -y wget unzip\n\n Create an installation directory and make it the working directory\nmkdir -p /opt/ocpinstall\ncd /opt/ocpinstall\n\n Download the OpenShift installer and client tools", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-bastion-intro"}, {"document_id": "ibmcld_10534-105304-106400", "score": 12.99610587559972, "text": "\n* [Prerequisites](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorialvpc_rh_prereqs)\n* [Create a cluster in a VPC](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorialvpc_rh_create_vpc_cluster)\n* [Deploy an app to your cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorialvpc_rh_app)\n* [Set up a VPC load balancer to expose your app publicly](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorialvpc_rh_vpc_lb)\n* [What's next?](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorialvpc_rh_next)\n\n\n\n\n\n\n\n Installing the CLI and API \n\n[Installing the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-cli-installcli-install)\n\n\n\n* [Understanding the CLI tools](https://cloud.ibm.com/docs/openshift?topic=openshift-cli-installcli-understand)\n* [Run the installation command](https://cloud.ibm.com/docs/openshift?topic=openshift-cli-installcli-install-include-step1-install-idt)\n* [Verify the installation](https://cloud.ibm.com/docs/openshift?topic=openshift-cli-installcli-install-include-step2-verify-idt)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_10534-137076-138526", "score": 12.872984462430274, "text": "\n* [Setting up your location and cluster for autoscaling](https://cloud.ibm.com/docs/openshift?topic=openshift-prepare-autoscale-satsetup-location-cluster-scale-sat)\n\n\n\n[Enabling the cluster autoscaler add-on in your cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-install-addoncluster-scaling-install-addon)\n\n\n\n* [Enabling the cluster autoscaler add-on from the console](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-install-addonautoscaler-enable-console)\n* [Enabling the cluster autoscaler add-on from the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-install-addonautoscaler-enable-CLI)\n* [Updating the cluster autoscaler add-on](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-install-addoncluster-scaling-update-addon)\n* [Removing the cluster autoscaler add-on from the console](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-install-addonautoscaler-remove-console)\n* [Removing the cluster autoscaler add-on from the CLI](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-install-addonautoscaler-remove-cli)\n* [Cluster autoscaler add-on parameter reference](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-install-addonca_addon_ref)\n\n\n\n[Setting up autoscaling for your worker pools](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-enablecluster-scaling-enable)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_14496-7-1967", "score": 12.70735299493495, "text": "\nRed Hat OpenShift 4.7 user provider infrastructure installation \n\nRed Hat\u00ae OpenShift\u00ae 4 introduced the following concepts:\n\n\n\n* Installer Provisioned Infrastructure (IPI) - For use on supported platforms, only AWS currently. The installer provisions the underlying infrastructure for the cluster and it configures the cluster.\n* User Provisioned Infrastructure (UPI) - For use on bare metal, vSphere, and other clouds that do not support IPI. The user is required to provision the infrastructure; compute, network, storage that the Red Hat OpenShift cluster is hosted on. The installer configures only the cluster.\n\n\n\nThese instructions use the Red Hat OpenShift installer in the UPI mode. Terraform is used to provision the seven VMs for the bootstrap, control-plane, and compute nodes. The following process is completed:\n\n\n\n1. A yaml file is created that is processed by the Red Hat OpenShift installer.\n2. The installer is run and creates a number of files, including the Ignition files. The Ignition files are used to configure the bootstrap, control-plane, and compute nodes at the first start.\n3. The Ignition file for the bootstrap node is copied to the NGINX default directory on the bastion node so that the bootstrap node can fetch it on the first start.\n4. The Ignition Terraform file is updated with the DNS server.\n5. The terraform.tfvars file is created to hold the variables for the Terraform installation.\n6. Terraform is run, which provisions the VMs. The VMs are started, configured, and the Red Hat OpenShift cluster is created.\n\n\n\nFor more information about installing the Red Hat OpenShift user provider infrastructure, see [Installing a cluster on vSphere with user-provisioned infrastructure](https://docs.openshift.com/container-platform/4.7/installing/installing_vsphere/installing-vsphere.html).\n\n\n\n Creating the Red Hat OpenShift Installer yaml file \n\nUse the following table to document the parameters you need for your deployment.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-install-intro"}, {"document_id": "ibmcld_10391-1452-3086", "score": 12.622683832596461, "text": "\ncurl -fsSL https://clis.cloud.ibm.com/install/linux | sh\n\n\n\nFor more information about installing the Mac OS X M1/ARM or Linux 64-bit ARM versions of the CLI, see the IBM Cloud CLI [release notes](https://github.com/IBM-Cloud/ibm-cloud-cli-release/releases/). These versions are provided as-is and are not fully supported.\n\n\n\n\n\n Step 2: Verify the installation \n\nTo verify that the CLI was installed successfully, run the help command:\n\nibmcloud help\n\nThe output lists the usage instructions, the current version, and the supported commands.\n\n\n\n\n\n Step 3: Install CLI plug-ins and tools \n\nTo manually install the CLI plug-ins and tools, see [Extending IBM Cloud CLI with plug-ins](https://cloud.ibm.com/docs/cli?topic=cli-plug-ins).\n\nTo install the container-service or ks plugin, run the following command.\n\nibmcloud plugin install ks\n\n\n\n\n\n Step 4: Install the Red Hat OpenShift CLI \n\nYou can use the oc CLI to deploy and manage resources in your Red Hat OpenShift on IBM Cloud cluster.\n\nTo install the CLI, see the [Getting started with the OpenShift CLI](https://docs.openshift.com/container-platform/4.11/cli_reference/openshift_cli/getting-started-cli.html).\n\n\n\n* For a list of commands that are available to cluster administrators, see the [OpenShift CLI administrator command reference](https://docs.openshift.com/container-platform/4.11/cli_reference/openshift_cli/administrator-cli-commands.html).\n* For a list of commands that are available to cluster developers, see the [OpenShift CLI developer command reference](https://docs.openshift.com/container-platform/4.11/cli_reference/openshift_cli/developer-cli-commands.html).", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-cli"}, {"document_id": "ibmcld_13114-9694-10905", "score": 12.602716650786066, "text": "\nInstall Docker Engine - Community for Ubuntu following the instructions from [https://docs.docker.com/install/linux/docker-ce/ubuntu/](https://docs.docker.com/install/linux/docker-ce/ubuntu/).\n3. Verify the installation with:\n\ndocker --version\nsudo docker run hello-world\n\nTo run Docker under your own user instead of root, perfom the [post install](https://docs.docker.com/install/linux/linux-postinstall/) steps.\n\n\n\n\n\n\n\n kubectl \n\n\n\n1. Download kubectl from\n\n[https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-on-linux](https://kubernetes.io/docs/tasks/tools/install-kubectl/install-kubectl-on-linux).\n2. Make the kubectl binary executable.\n\nchmod +x ./kubectl\n3. Move the binary to your PATH.\n\nsudo mv ./kubectl /usr/local/bin/kubectl\n4. Verify the installation with:\n\nkubectl version --client=true\n\n\n\n\n\n\n\n oc \n\n\n\n1. Download the latest 4.x OpenShift CLI (oc) from [https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/](https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/).\n2. Extract openshift-client-linux.tar.gz:\n\ntar zxvf openshift-client-linux.tar.gz oc\n3. Move the oc binary to your PATH.\n\nsudo mv ./oc /usr/local/bin/oc\n4. Verify the installation with:", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials"}, {"document_id": "ibmcld_13168-9904-11115", "score": 12.602716650786066, "text": "\nInstall Docker Engine - Community for Ubuntu following the instructions from [https://docs.docker.com/install/linux/docker-ce/ubuntu/](https://docs.docker.com/install/linux/docker-ce/ubuntu/).\n3. Verify the installation with:\n\ndocker --version\nsudo docker run hello-world\n\nTo run Docker under your own user instead of root, perfom the [post install](https://docs.docker.com/install/linux/linux-postinstall/) steps.\n\n\n\n\n\n\n\n kubectl \n\n\n\n1. Download kubectl from\n\n[https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-on-linux](https://kubernetes.io/docs/tasks/tools/install-kubectl/install-kubectl-on-linux).\n2. Make the kubectl binary executable.\n\nchmod +x ./kubectl\n3. Move the binary to your PATH.\n\nsudo mv ./kubectl /usr/local/bin/kubectl\n4. Verify the installation with:\n\nkubectl version --client=true\n\n\n\n\n\n\n\n oc \n\n\n\n1. Download the latest 4.x OpenShift CLI (oc) from [https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/](https://mirror.openshift.com/pub/openshift-v4/clients/ocp/stable/).\n2. Extract openshift-client-linux.tar.gz:\n\ntar zxvf openshift-client-linux.tar.gz oc\n3. Move the oc binary to your PATH.\n\nsudo mv ./oc /usr/local/bin/oc\n4. Verify the installation with:", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-tutorials"}, {"document_id": "ibmcld_14497-12294-13464", "score": 12.592663845514318, "text": "\n* On the bastion node, the install-config.yaml file is populated with the required Red Hat OpenShift parameters and Red Hat OpenShift ignition is used to generate a number of files used for the installation of the bootstrap, control plane, and worker machines.\n* Terraform, on the bastion node, uses the files that are created by Ignition to create the Red Hat OpenShift VMs.\n\n\n\n* Phase 3 - Post deployment activities. Configure a persistent volume for use by the Red Hat OpenShift cluster. This step is described in [Red Hat OpenShift 4.7 additional configuration](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-config-intro).\n\n\n\n\n\n\n\n Related links \n\n\n\n* [What is Red Hat OpenShift?](https://www.ibm.com/cloud/blog/what-is-openshift)\n* [Red Hat OpenShift 4 Release Update](https://www.youtube.com/watch?v=YJvTu8jC6CU)\n* [Installing a cluster on vSphere with user-provisioned infrastructure](https://docs.openshift.com/container-platform/4.7/installing/installing_vsphere/installing-vsphere.html)\n* [Getting started with IBM Cloud Virtual Private Networking](https://cloud.ibm.com/docs/iaas-vpn?topic=iaas-vpn-getting-started)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01892-80168-82440", "score": 8.44446144938731, "text": "\nViewer As a viewer, you can view bare metal servers, but not modify them. \n\n\n\n\n\n\n\n Dedicated Host for VPC \n\nReview the available platform and service roles and the actions mapped to each to help you assign access. If you're using the CLI or API to assign access, use is.dedicated-host for the service name.\n\nPlatform roles\n\nActions\n\n\n\nTable 85. Platform roles - Dedicated Host for VPC\nUse the tab buttons to change the context of the table. This table has row and column headers. The row headers provide the platform role name and the column headers identify the specific information available about each role.\n\n Role Description \n\n Administrator As an administrator, you can perform all platform actions based on the resource this role is being assigned, including assigning access policies to other users. \n Editor As an editor, you can perform all platform actions except for managing the account and assigning access policies. \n Operator As an operator, you can perform platform actions required to configure and operate service instances, such as viewing a service's dashboard. \n Viewer As a viewer, you can view service instances, but you can't modify them. \n\n\n\n\n\n\n\n Virtual Private Endpoint for VPC \n\nReview the available platform and service roles and the actions mapped to each to help you assign access. If you're using the CLI or API to assign access, use is.endpoint-gateway for the service name.\n\nPlatform roles\n\nActions\n\n\n\nTable 86. Platform roles - Virtual Private Endpoint for VPC\nUse the tab buttons to change the context of the table. This table has row and column headers. The row headers provide the platform role name and the column headers identify the specific information available about each role.\n\n Role Description \n\n Administrator As an administrator you can create, delete, update and view endpoint gateway service instances, and assign access policies to other users. Administrators can also bind and unbind an endpoint gateway to a reserved IP address. \n Editor As an editor you can create, delete, update and view endpoint gateway service instance. Editors can also bind and unbind an endpoint gateway to a reserved IP address. \n Operator As an operator you can bind and unbind an endpoint gateway service instance to a reserved IP address.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-iam-service-roles-actions"}, {"document_id": "ibmcld_15130-10903-12609", "score": 7.500098739878805, "text": "\nThe following example CLI command creates a context-based restriction rule for all of the virtual server instances in the current account and restricts access to private endpoints:\n\nibmcloud cbr rule-create --context-attributes 'endpointType=private' --zone-id a7eeb5dd8e6bdce670eba1afce18e37f --description \"Test CBR for VSIs\" --service-name is --resource-attributes \"instanceId=\"\n\nThe following example CLI command creates a context-based restriction rule for all the virtual server instances in the resource group and restricts access to private endpoints:\n\nibmcloud cbr rule-create --context-attributes 'endpointType=private' --zone-id a7eeb5dd8e6bdce670eba1afce18e37f --description \"Test CBR for VSIs\" --service-name is --resource-attributes \"instanceId=\" --resource-group-id 1171749e3a8545069d04e6fca1ded18f\n\n\n\n\n\n Creating rules in the UI \n\n\n\n1. Go to Manage > Context-based restrictions in the IBM Cloud\u00ae console.\n2. Select Rules and click Create.\n3. Select VPC Infrastructure Services and click Next.\n4. Scope the rule to All resources or Specific resources. For more information, see [Protecting VPC Infrasturcture Services resources](https://cloud.ibm.com/docs/vpc?topic=vpc-cbr). Click Continue.\n5. Define the allowed endpoint types.\n\n\n\n* Keep the toggle set to No to allow all endpoint types.\n* Set the toggle to Yes to allow only specific endpoint types, then choose from the list.\n\n\n\n6. Select a network zone or zones that you have already created, or create a new network zone by clicking Create.\n\nContexts define the location from which your resources can be accessed, effectively linking your network zone to your rule.\n7. Click Add to add your configuration to the summary. Click Next.\n8.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-cbr&interface=cli"}, {"document_id": "ibmcld_15129-10875-12581", "score": 7.500098739878805, "text": "\nThe following example CLI command creates a context-based restriction rule for all of the virtual server instances in the current account and restricts access to private endpoints:\n\nibmcloud cbr rule-create --context-attributes 'endpointType=private' --zone-id a7eeb5dd8e6bdce670eba1afce18e37f --description \"Test CBR for VSIs\" --service-name is --resource-attributes \"instanceId=\"\n\nThe following example CLI command creates a context-based restriction rule for all the virtual server instances in the resource group and restricts access to private endpoints:\n\nibmcloud cbr rule-create --context-attributes 'endpointType=private' --zone-id a7eeb5dd8e6bdce670eba1afce18e37f --description \"Test CBR for VSIs\" --service-name is --resource-attributes \"instanceId=\" --resource-group-id 1171749e3a8545069d04e6fca1ded18f\n\n\n\n\n\n Creating rules in the UI \n\n\n\n1. Go to Manage > Context-based restrictions in the IBM Cloud\u00ae console.\n2. Select Rules and click Create.\n3. Select VPC Infrastructure Services and click Next.\n4. Scope the rule to All resources or Specific resources. For more information, see [Protecting VPC Infrasturcture Services resources](https://cloud.ibm.com/docs/vpc?topic=vpc-cbr). Click Continue.\n5. Define the allowed endpoint types.\n\n\n\n* Keep the toggle set to No to allow all endpoint types.\n* Set the toggle to Yes to allow only specific endpoint types, then choose from the list.\n\n\n\n6. Select a network zone or zones that you have already created, or create a new network zone by clicking Create.\n\nContexts define the location from which your resources can be accessed, effectively linking your network zone to your rule.\n7. Click Add to add your configuration to the summary. Click Next.\n8.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-cbr"}, {"document_id": "ibmcld_01892-96068-98396", "score": 7.4693207778020065, "text": "\nThe row headers provide the platform role name and the column headers identify the specific information available about each role.\n\n Role Description \n\n Administrator As a Virtual Network Interface administrator, you can Read, List, Attach, Detach, Create, Update, and Delete Virtual Network resources on the account and provide policies to other users on the account. \n Editor As a Virtual Network Interface editor, you can Read, List, Attach, Detach, Create, Update, and Delete Virtual Network resources. \n Operator As a Virtual Network Interface operator, you can Read, List, Attach, and Detach Virtual Network resources. \n Viewer As a Virtual Network Interface viewer, you can Read, and List Virtual Network resources. \n\n\n\n\n\n\n\n Block Storage for VPC \n\nReview the available platform and service roles and the actions mapped to each to help you assign access. If you're using the CLI or API to assign access, use is.volume for the service name.\n\nPlatform roles\n\nActions\n\n\n\nTable 101. Platform roles - Block Storage for VPC\nUse the tab buttons to change the context of the table. This table has row and column headers. The row headers provide the platform role name and the column headers identify the specific information available about each role.\n\n Role Description \n\n Administrator As an administrator, you can perform all platform actions based on the resource this role is being assigned, including assigning access policies to other users. \n Editor As an editor, you can perform all platform actions except for managing the account and assigning access policies. \n Operator As an operator, you can perform platform actions required to configure and operate service instances, such as viewing a service's dashboard. \n Viewer As a viewer, you can view service instances, but you can't modify them. \n\n\n\n\n\n\n\n Virtual Private Cloud \n\nReview the available platform and service roles and the actions mapped to each to help you assign access. If you're using the CLI or API to assign access, use is.vpc for the service name.\n\nPlatform roles\n\nActions\n\n\n\nTable 102. Platform roles - Virtual Private Cloud\nUse the tab buttons to change the context of the table. This table has row and column headers. The row headers provide the platform role name and the column headers identify the specific information available about each role.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-iam-service-roles-actions"}, {"document_id": "ibmcld_16094-8464-10265", "score": 7.421875905744971, "text": "\n1. Click Security groups under Network, then click Create.\n2. Enter vpc-secure-private-sg as name and select the VPC you created earlier.\n3. Click Create security group.\n\n\n\n\n\n\n\n Create a virtual server instance \n\nTo create a virtual server instance in the newly created subnet:\n\n\n\n1. Click on the subnet vpc-secure-private-subnet created earlier under Subnets.\n2. Click Attached resources, under Attached instances, click Create.\n3. To configure the instance:\n\n\n\n1. Enter a unique name, vpc-secure-private-vsi and resource group as earlier.\n2. Select the same Location already used by the bastion virtual server.\n3. Select Public type of virtual server.\n4. Set the Operating System to Ubuntu Linux. You can pick any version of the image.\n5. Select Compute (2 vCPUs and 4 GB RAM) as your profile. To check other available profiles, click View all profiles.\n6. For SSH keys pick the SSH key you created earlier for the bastion.\n\n\n\n4. Scroll to Networking and select the VPC your created.\n5. Under Network interfaces, click on the Edit icon\n\n\n\n* Select vpc-secure-private-subnet as the subnet.\n* Uncheck the default security and group and activate vpc-secure-private-sg.\n* Click Save.\n\n\n\n6. Click Create virtual server instance.\n\n\n\n\n\n\n\n Add virtual server instance(s) to the maintenance security group \n\nFor administrative work on the servers, you have to associate the specific virtual servers with the maintenance security group. In the following, you will enable maintenance, log into the private server, update the software package information, then disassociate the security group again.\n\nLet's enable the maintenance security group for the server.\n\n\n\n1. Navigate to Security groups and select vpc-secure-maintenance-sg security group.\n2. Click on theAttached resources tab, then Edit interfaces.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-secure-management-bastion-server"}, {"document_id": "ibmcld_13238-8347-10193", "score": 7.402298206852425, "text": "\nClick Create subnet to provision it.\n\n\n\n\n\n\n\n Create a security group \n\nTo create a new security group:\n\n\n\n1. Click Security groups under Network, then click Create.\n2. Enter vpc-secure-private-sg as name and select the VPC you created earlier.\n3. Click Create security group.\n\n\n\n\n\n\n\n Create a virtual server instance \n\nTo create a virtual server instance in the newly created subnet:\n\n\n\n1. Click on the subnet vpc-secure-private-subnet created earlier under Subnets.\n2. Click Attached resources, under Attached instances, click Create.\n3. To configure the instance:\n\n\n\n1. Enter a unique name, vpc-secure-private-vsi and resource group as earlier.\n2. Select the same Location already used by the bastion virtual server.\n3. Select Public type of virtual server.\n4. Set the Operating System to Ubuntu Linux. You can pick any version of the image.\n5. Select Compute (2 vCPUs and 4 GB RAM) as your profile. To check other available profiles, click View all profiles.\n6. For SSH keys pick the SSH key you created earlier for the bastion.\n\n\n\n4. Scroll to Networking and select the VPC your created.\n5. Under Network interfaces, click on the Edit icon\n\n\n\n* Select vpc-secure-private-subnet as the subnet.\n* Uncheck the default security and group and activate vpc-secure-private-sg.\n* Click Save.\n\n\n\n6. Click Create virtual server instance.\n\n\n\n\n\n\n\n Add virtual server instance(s) to the maintenance security group \n\nFor administrative work on the servers, you have to associate the specific virtual servers with the maintenance security group. In the following, you will enable maintenance, log into the private server, update the software package information, then disassociate the security group again.\n\nLet's enable the maintenance security group for the server.\n\n\n\n1. Navigate to Security groups and select vpc-secure-maintenance-sg security group.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-secure-management-bastion-server"}, {"document_id": "ibmcld_16729-313444-315292", "score": 6.967443064339906, "text": "\n[Onboarding a virtual server image for Power Systems Virtual Server](https://cloud.ibm.com/docs/account?topic=account-catalog-vsipower-tutorial)Onboarding a virtual server image for Power Systems Virtual Server\n\nThis tutorial walks you through how to onboard a sample virtual server image for Power Systems Virtual Server to your account. By completing this tutorial, you learn how to create a private catalog, import the sample, validate that it can be installed on a selected deployment target, and make the virtual server image available to users who have access to your account.\n\nObject Storage Virtual Private Cloud (VPC)\n\n+1\n\nManaging your account, resources, and access\n\n\n\n* 20 minutes\n* 2023-03-03\n\n\n\n[Onboarding a virtual server image for VPC](https://cloud.ibm.com/docs/account?topic=account-catalog-vsivpc-tutorial)Onboarding a virtual server image for VPC\n\nThis tutorial walks you through how to onboard a sample virtual server image for virtual private cloud (VPC) to your account. By completing this tutorial, you learn how to create a private catalog, import the image, validate that it can be installed on a selected deployment target, and make the virtual server image available to users who have access to your account. As you complete the tutorial, adapt each step to match your organization's goal.\n\nObject Storage Virtual Private Cloud (VPC)\n\n+1\n\nManaging your account, resources, and access\n\n\n\n* 20 minutes\n* 2022-08-25\n\n\n\n[Securing data using context-based restrictions](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-cos-tutorial-cbr)Securing data using context-based restrictions\n\nIn this tutorial, you will establish context-based restrictions that prevent any access to object storage data unless the request originates from a trusted network zone.\n\nObject Storage\n\n\n\n* 10 minutes\n* 2022-05-02", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_01892-83752-86071", "score": 6.851736450126344, "text": "\nImage Service for VPC \n\nReview the available platform and service roles and the actions mapped to each to help you assign access. If you're using the CLI or API to assign access, use is.image for the service name.\n\nPlatform roles\n\nService roles\n\nActions\n\n\n\nTable 89. Platform roles - Image Service for VPC\nUse the tab buttons to change the context of the table. This table has row and column headers. The row headers provide the platform role name and the column headers identify the specific information available about each role.\n\n Role Description \n\n Administrator As an administrator, you can perform all platform actions based on the resource this role is being assigned, including assigning access policies to other users. \n Editor As an editor, you can perform all platform actions except for managing the account and assigning access policies. \n Operator As an operator, you can perform platform actions required to configure and operate service instances, such as viewing a service's dashboard. \n Viewer As a viewer, you can view service instances, but you can't modify them. \n\n\n\n\n\n\n\n Virtual Server for VPC \n\nReview the available platform and service roles and the actions mapped to each to help you assign access. If you're using the CLI or API to assign access, use is.instance for the service name.\n\nPlatform roles\n\nService roles\n\nActions\n\n\n\nTable 90. Platform roles - Virtual Server for VPC\nUse the tab buttons to change the context of the table. This table has row and column headers. The row headers provide the platform role name and the column headers identify the specific information available about each role.\n\n Role Description \n\n Administrator As an administrator, you can perform all platform actions based on the resource this role is being assigned, including assigning access policies to other users. \n Editor As an editor, you can perform all platform actions except for managing the account and assigning access policies. \n Operator As an operator, you can perform platform actions required to configure and operate service instances, such as viewing a service's dashboard. \n Viewer As a viewer, you can view service instances, but you can't modify them. \n\n\n\n\n\n\n\n Auto Scale for VPC \n\nReview the available platform and service roles and the actions mapped to each to help you assign access.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-iam-service-roles-actions"}, {"document_id": "ibmcld_10067-8858-10062", "score": 6.799552707969109, "text": "\nGet the IDs of the zones you created in the previous step.\n\nibmcloud cbr zones\n\nExample output\n\nOK\nid name address_count\nc14c0839c13d8aa0afa8383e2be2e124 public-mgmt-zone 2\nf9676ca6ef37685315fa254b89d73159 public-cluster-zone 1\nc14c0839c13d8aa0afa8383e2be2e843 private-cluster-zone 1\nb53353de929de39ac2381f9b4cde8507 private-mgmt-zone 2\n3. Create a rule that protects access to the public and private cluster and management APIs by using the zones you created earlier.\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:management --context-attributes \"endpointType=public,networkZoneId=PUBLIC-MGMT-ZONE-ID\" --context-attributes \"endpointType=private,networkZoneId=PRIVATE-MGMT-ZONE-ID\" --description \"Separate private and public IPs for the management APIs\" --service-name containers-kubernetes\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --context-attributes \"endpointType=public,networkZoneId=PUBLIC-CLUSTER-ZONE-ID\" --context-attributes \"endpointType=private,networkZoneId=PRIVATE-CLUSTER-ZONE-ID\" --description \"Separate private and public IPs for cluster APIs\" --service-name containers-kubernetes", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cbr-tutorial"}, {"document_id": "ibmcld_05595-8921-10125", "score": 6.799552707969109, "text": "\nGet the IDs of the zones you created in the previous step.\n\nibmcloud cbr zones\n\nExample output\n\nOK\nid name address_count\nc14c0839c13d8aa0afa8383e2be2e124 public-mgmt-zone 2\nf9676ca6ef37685315fa254b89d73159 public-cluster-zone 1\nc14c0839c13d8aa0afa8383e2be2e843 private-cluster-zone 1\nb53353de929de39ac2381f9b4cde8507 private-mgmt-zone 2\n3. Create a rule that protects access to the public and private cluster and management APIs by using the zones you created earlier.\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:management --context-attributes \"endpointType=public,networkZoneId=PUBLIC-MGMT-ZONE-ID\" --context-attributes \"endpointType=private,networkZoneId=PRIVATE-MGMT-ZONE-ID\" --description \"Separate private and public IPs for the management APIs\" --service-name containers-kubernetes\n\nibmcloud cbr rule-create --api-types crn:v1:bluemix:public:containers-kubernetes::::api-type:cluster --context-attributes \"endpointType=public,networkZoneId=PUBLIC-CLUSTER-ZONE-ID\" --context-attributes \"endpointType=private,networkZoneId=PRIVATE-CLUSTER-ZONE-ID\" --description \"Separate private and public IPs for cluster APIs\" --service-name containers-kubernetes", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cbr-tutorial"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04866-1541-3629", "score": 43.51104892155038, "text": "\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https://cloud.ibm.com/docs/services/cloud-object-storage/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-1541-3629", "score": 43.51104892155038, "text": "\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy \n\nA retention policy is enabled at the IBM Cloud Object Storage bucket level. Minimum, maximum and default retention period are defined by this policy and apply to all objects in the bucket.\n\nMinimum retention period is the minimum duration of time an object must be kept unmodified in the bucket.\n\nMaximum retention period is the maximum duration of time an object can be kept unmodified in the bucket.\n\nIf an object is stored in the bucket without specifying a custom retention period, the default retention period is used. The minimum retention period must be less than or equal to the default retention period, which in turn must be less than or equal to the maximum retention period.\n\nA maximum retention period of 1000 years can be specified for the objects.\n\nTo create a retention policy on a bucket, you need Manager role. See [Bucket permissions](https://cloud.ibm.com/docs/services/cloud-object-storage/iam?topic=cloud-object-storage-iam-bucket-permissions) for more details.\n\n\n\n\n\n Legal hold \n\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-6428-8442", "score": 43.26193169422234, "text": "\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https://cloud.ibm.com/docs/images/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04831-50613-52356", "score": 43.09686422696378, "text": "\nX-Clv-Request-Id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\nServer: Cleversafe/3.14.9.53\nX-Clv-S3-Version: 2.5\nx-amz-request-id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\n\nThe server responds with 204 No Content.\n\n\n\n\n\n Add a retention policy on an existing bucket \n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. The service also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nFind out more about Immutable Object Storage in the [documentation](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable).\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nThis operation does not make use of extra query parameters. The required Content-MD5 header needs to be the binary representation of a base64-encoded MD5 hash. The following snippet shows one way to achieve the content for that particular header.\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nNot all operations are supported in Satellite environments.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/api-reference?topic=cloud-object-storage-compatibility-api-bucket-operations"}, {"document_id": "ibmcld_04991-50585-52328", "score": 43.09686422696378, "text": "\nX-Clv-Request-Id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\nServer: Cleversafe/3.14.9.53\nX-Clv-S3-Version: 2.5\nx-amz-request-id: 3e8bdf1e-b611-4b83-a404-e7d3e58e60b0\n\nThe server responds with 204 No Content.\n\n\n\n\n\n Add a retention policy on an existing bucket \n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. The service also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nFind out more about Immutable Object Storage in the [documentation](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable).\n\nThe minimum and maximum supported values for the retention period settings MinimumRetention, DefaultRetention, and MaximumRetention are a minimum of 0 days and a maximum of 365243 days (1000 years).\n\nThis operation does not make use of extra query parameters. The required Content-MD5 header needs to be the binary representation of a base64-encoded MD5 hash. The following snippet shows one way to achieve the content for that particular header.\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nNot all operations are supported in Satellite environments.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-compatibility-api-bucket-operations"}, {"document_id": "ibmcld_04866-6428-8391", "score": 42.2059239242449, "text": "\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https://cloud.ibm.com/docs/cloud-object-storage/images/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_06808-1384-2991", "score": 41.124623703324104, "text": "\n[Learn more](https://cloud.ibm.com/docs/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidencecd-devsecops-cos-bucket-resiliency).\n\n\n\n\n\n Naming your bucket \n\nCloud Object Storage object names consist of the following components:\n\n{NAMESPACE} / {PIPELINE_RUN_ID} / {TYPE} / {FILE_NAME} _ {HASH}\n\n\n\n Examples: \n\nci/48decaa9-9042-498f-b58d-3577e0ac0158/evidences/build-vulnerability-advisor.json_362c06afa88b3f304878f0d0979e834f\n\nci/48decaa9-9042-498f-b58d-3577e0ac0158/artifacts/app-image-va-report.json_b3f30487f0d0979e834f362c06afaaa8\n\nThe name component {NAMESPACE} / {PIPELINE_RUN_ID} / {TYPE} is useful as a prefix when you're looking for collected data from a certain pipeline run.\n\n\n\n\n\n Retention policy \n\nYou can set Cloud Object Storage buckets to enforce a retention policy or period for uploaded objects, otherwise known as [Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable). Immutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a Write-One-Read-Many (WORM), non-erasable, and non-rewritable manner. You cannot change or delete objects in protected buckets within the retention period, or delete protected buckets with objects themselves until the retention period is over. The policy is enforced until the end of a retention period and the removal of any legal holds.\n\nIt is recommended that teams set a retention policy for the buckets that are used as their evidence locker that stores every object for a minimum of 365 days.\n\n\n\n\n\n\n\n Audit event log", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidence"}, {"document_id": "ibmcld_04866-7-2136", "score": 40.5938692853166, "text": "\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-7-2136", "score": 40.5938692853166, "text": "\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04866-3142-5463", "score": 40.42994129270357, "text": "\nCertain objects might need to be prevented from modification after a retention period expires. An example is an incomplete legal review, where records might need to be accessible for an extended duration beyond the retention period originally set. A legal hold flag can then be applied at the object level. Legal holds can be applied to objects during initial uploads or after an object is written. Note: A maximum of 100 legal holds can be applied per object.\n\n\n\n\n\n Indefinite retention \n\nAllows the user to set the object to be stored indefinitely until a new retention period is applied. This is set at a per object level.\n\n\n\n\n\n Event-based retention \n\nImmutable Object Storage allows users to set indefinite retention on the object if they are unsure of the final duration of the retention period, or want to use event-based retention. Once set to indefinite, user applications can then can change the object retention to a finite value later. For example, a company has a policy of retaining employee records for three years after the employee leaves the company. When an employee joins the company, the records that are associated with that employee can be indefinitely retained. When the employee leaves the company, the indefinite retention is converted to a finite value of three years from the current time, as defined by company policy. The object is then protected for three years after the retention period change. A user or third-party application can change the retention period from indefinite to finite retention that uses an SDK or REST API.\n\n\n\n\n\n Permanent retention \n\nPermanent retention ensures that data can not be deleted, ever, by anyone. Read the documentation carefully and do not use permanent retention unless there is a compelling regulatory or compliance need for permanent data storage.\n\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16444-7-2064", "score": 34.62369969189609, "text": "\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available to you if you have created a machine learning model with Knowledge Studio already.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotation"}, {"document_id": "ibmcld_16464-4463-6317", "score": 32.58670269319441, "text": "\nOn the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\n> Note: In a realistic scenario, you would create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16507-1455-3632", "score": 31.736215313985653, "text": "\nThis choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes. Human annotators can specify entity subtypes for each pre-annotated mention by working on an [annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask) with the pre-annotated document.\n* Machine learning\n\nUses a machine learning model to automatically annotate documents. This option is only available if you have created a machine learning model with Knowledge Studio already. If you add a document set, you can run the machine learning annotator that you created previously to pre-annotate the new documents. If the new set of documents is similar to the documents that were used to train the machine learning annotator originally, then this is probably your best choice for pre-annotation.\n* Rule\n\nUses a rule-based model to automatically annotate documents. This option is only available if you have created a rule-based model with Knowledge Studio already. If your documents contain common patterns of tokens from which you can derive meaning, this model might be a good choice. It can incorporate some of the function of the dictionary pre-annotator if you enable it, by identifying class types for dictionary terms that it finds in the documents also.\n\n\n\nAlternatively, you can upload already-annotated documents, and use them to start training the machine learning model. You cannot run a pre-annotator on annotated documents that you upload or the existing annotations will be stripped from the documents and replaced with annotations produced by the pre-annotator only.\n\n\n\n\n\n Running multiple pre-annotators", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_16507-7-2044", "score": 31.298295734798582, "text": "\nBootstrapping annotation \n\nSimplify the job of the human annotator by pre-annotating the documents in a workspace. A pre-annotator is a Knowledge Studio dictionary, rule-based model, or machine learning model that you can run to find and annotate mentions automatically.\n\nPre-annotation makes the job of human annotators easier because it covers the straightforward annotations, and gets the job of annotating the documents underway.\n\nThe method that you use to pre-annotate documents in no way restricts the ways that you can use the resulting model. For example, just because you use the Natural Language Understanding service to pre-annotate documents does not mean you must deploy the final machine learning model that you build to the Natural Language Understanding service.\n\n\n\n Pre-annotation methods \n\nThe following pre-annotators are available:\n\n\n\n* Natural Language Understanding\n\nA pre-annotator that you can use to find mentions of entities in your documents automatically. If your source documents have general knowledge subject matter, then this pre-annotator is a good choice for you. If you are working with highly specialized documents that focus on a specific field, such as patent law research, for example, the dictionary pre-annotator or rule-based model might be a better choice.\n* Dictionary\n\nUses a dictionary of terms that you provide and associate with an entity type to find mentions of that entity type in the documents. This choice is best for fields with unique or specialized terminology because this pre-annotator does not analyze the context in which the term is used in the way a machine learning pre-annotator does; it instead relies on the term being distinct enough to have a decipherable meaning regardless of the context in which it is used. For example, it is easier to recognize asbestos as a mineral entity type than to determine the entity type of squash, which can refer to a vegetable, a sport, or a verb meaning to crush something.\n\nDictionary pre-annotators do not recognize entity subtypes.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-preannotation"}, {"document_id": "ibmcld_16447-1597-3270", "score": 31.079042022948382, "text": "\nIn large team settings, admins rarely participate in the model development process. \n Project manager Responsible for the overall organization of the workspace that she or he is assigned to. Tasks include creating the type system, managing assets, managing annotation work, evaluating the machine learning model, and deploying models. Users in this role need industry subject-matter expertise because they create the type system, teach the human annotators how to correctly apply the type system, and evaluate the model quality. \n Human annotator Performs the labeling of the entity mentions and relationship mentions in the training documents that he or she is assigned to. The work is assigned to human annotators and monitored by the project manager. Human annotators may not have industry subject-matter expertise, as long as they are taught by the project manager how to correctly apply the type system. \n\n\n\n\n\n\n\n Knowledge Studio role permissions \n\nTo compare the permissions of each role, see the following table. One permission is listed on each row. If a role has that permission, the role column is marked with a check mark (\u2713).\n\n\n\nTable 2. Role permissions\n\n Permission Admin Project manager Human annotator \n\n Manage user access and roles \u2713 \n Manage workspaces \u2713 \n Create the type system and annotation guidelines \u2713 \u2713 \n Upload training documents \u2713 \u2713 \n Manage rules \u2713 \u2713 \n Pre-annotate documents \u2713 \u2713 \n Manage annotation tasks \u2713 \u2713 \n Resolve annotation conflicts with human annotation (adjudication) \u2713 \u2713 \n Train and evaluate machine learning models \u2713 \u2713 \n Export models \u2713 \u2713 \n Annotate document sets directly \u2713 \u2713 \n Perform document annotation in annotation tasks \u2713 \u2713 \u2713", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles"}, {"document_id": "ibmcld_16464-3021-4769", "score": 30.975149075923685, "text": "\nYou can now divide the corpus into multiple document sets and assign the document sets to human annotators.\n\n\n\n\n\n\n\n Lesson 2: Pre-annotating with a dictionary-based annotator \n\nIn this lesson, you will learn how to use a dictionary-based annotator to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.\n\nFor more information about pre-annotation with dictionaries, see [Pre-annotating documents with a dictionary](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-preannotationwks_preannot).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Assets > Dictionaries.\n\nThe Test dictionary dictionary opens. The [Adding a dictionary](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintrowks_tutless4) lesson of the Getting started with Knowledge Studio tutorial shows how to create this dictionary.\n2. From the Entity type list, select the ORGANIZATION entity type to map it to the Test dictionary dictionary.\n\nThe [Creating a type system](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintrowks_tutless3) lesson of the Getting started with Knowledge Studio tutorial shows how to create the type system that contains the ORGANIZATION entity type.\n3. On the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16518-1687-3559", "score": 30.839976124468258, "text": "\nTable 1. Role descriptions\n\n Role Description \n\n Admin Responsible for administrative tasks, which include managing users, resource consumption, and monthly charges. In large team settings, admins rarely participate in the model development process. \n Project manager Responsible for the overall organization of the workspace that she or he is assigned to. Tasks include creating the type system, managing assets, managing annotation work, evaluating the machine learning model, and deploying models. Users in this role need industry subject-matter expertise because they create the type system, teach the human annotators how to correctly apply the type system, and evaluate the model quality. \n Human annotator Performs the labeling of the entity mentions and relationship mentions in the training documents that he or she is assigned to. The work is assigned to human annotators and monitored by the project manager. Human annotators may not have industry subject-matter expertise, as long as they are taught by the project manager how to correctly apply the type system. \n\n\n\n\n\n\n\n Knowledge Studio role permissions \n\nTo compare the permissions of each role, see the following table. One permission is listed on each row. If a role has that permission, the role column is marked with a check mark (\u2713).\n\n\n\nTable 2. Role permissions\n\n Permission Admin Project manager Human annotator \n\n Manage user access and roles \u2713 \n Manage workspaces \u2713 \n Create the type system and annotation guidelines \u2713 \u2713 \n Upload training documents \u2713 \u2713 \n Manage rules \u2713 \u2713 \n Pre-annotate documents \u2713 \u2713 \n Manage annotation tasks \u2713 \u2713 \n Resolve annotation conflicts with human annotation (adjudication) \u2713 \u2713 \n Train and evaluate machine learning models \u2713 \u2713 \n Deploy and undeploy models to runtime services \u2713 \u2713 \n Annotate document sets directly \u2713 \u2713 \n Perform document annotation in annotation tasks \u2713 \u2713 \u2713", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-roles"}, {"document_id": "ibmcld_16464-1626-3475", "score": 30.374435961351516, "text": "\nHowever, if you have access to only a single user ID, you can still simulate most parts of the process.\n\nFor information about user roles, see [User roles in Knowledge Studio](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles).\n\n\n\n\n\n\n\n Results \n\nAfter completing this tutorial, you will have a custom machine learning model that you can use with other Watson services.\n\n\n\n\n\n Lesson 1: Adding documents for annotation \n\nIn this lesson, you will learn how to add documents to a workspace in Knowledge Studio that can be annotated by human annotators.\n\n\n\n About this task \n\nFor more information about adding documents, see [Adding documents to a workspace](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotationwks_projadd).\n\n\n\n\n\n Procedure \n\n\n\n1. Download the [documents-new.csv![External link icon](https://cloud.ibm.com/docs-content/v1/content/icons/launch-glyph.svg)](https://watson-developer-cloud.github.io/doc-tutorial-downloads/knowledge-studio/documents-new.csv) file to your computer. This file contains example documents suitable for uploading.\n2. Within your workspace, click Assets > Documents.\n3. On the Documents page, click Upload Document Sets.\n4. Upload the documents-new.csv file from your computer. The uploaded file is displayed in the table.\n\n\n\n\n\n\n\n What to do next \n\nYou can now divide the corpus into multiple document sets and assign the document sets to human annotators.\n\n\n\n\n\n\n\n Lesson 2: Pre-annotating with a dictionary-based annotator \n\nIn this lesson, you will learn how to use a dictionary-based annotator to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nPre-annotating documents is an optional step. However, it is a worthwhile step because it makes the job of human annotators easier later.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16463-7-1870", "score": 30.371096249887454, "text": "\nPre-annotating documents \n\nThis tutorial helps you understand how to pre-annotate documents, which bootstraps the annotation process of human annotation.\n\n\n\n Learning objectives \n\nAfter you complete this tutorial, you will know how to pre-annotate documents with a machine learning model.\n\nThis tutorial should take approximately 5 minutes to finish. If you explore other concepts related to this tutorial, it could take longer to complete.\n\n\n\n\n\n Before you begin \n\n\n\n* You're using a supported browser. For information, see [Browser requirements](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-system-requirements).\n* You successfully completed [Getting started with Knowledge Studio](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintro), which covers creating a workspace, creating a type system, and adding a dictionary.\n* You successfully completed [Creating a machine learning model](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro).\n* You must have at least one user ID in either the Admin or Project Manager role. For information about user roles, see [User roles in Knowledge Studio](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles).\n\n\n\n\n\n\n\n Results \n\nAfter completing this tutorial, you will have a set of partially annotated documents. Then, you can assign the documents to human annotators to finish the annotation work.\n\n\n\n\n\n Lesson 1: Pre-annotating new documents with a machine learning model \n\nIn this lesson, you will learn how to use a machine learning model to pre-annotate documents in Knowledge Studio.\n\n\n\n About this task \n\nAfter you train a machine learning model, you can use it to pre-annotate new documents that you add to the corpus.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutboot_intro"}, {"document_id": "ibmcld_16563-4292-6145", "score": 30.31828791100914, "text": "\nSelect the document set that you created in [Lesson 1](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introtut_lessml1).\n6. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\nIn a realistic scenario, you create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3. Specify the details for the task:\n\n\n\n* In the Task name field, enter Test.\n* In the Deadline field, select a date in the future.\n\n\n\n4.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}]}
{"task_id": "674aa142d92a6b4262de254df0c3f7b2<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03330-3253-5192", "score": 37.11985594364167, "text": "\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.\n\n\n\n\n\nFor more information about the architecture, read the [How to Make Chatbot Orchestration Easier](https://medium.com/ibm-watson/how-to-make-chatbot-orchestration-easier-c8ed61620b8d) blog on Medium.com.\n\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https://www.ibm.com/blogs/watson/2020/03/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits/) blog on ibm.com.\n\nThis documentation describes managed instances of Watson Assistant that are offered in IBM Cloud or in Cloud Pak for Data as a Service. If you are interested in on-premises or installed deployments, see [this documentation](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-index).\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add)\n* [Adding skills to your assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-index"}, {"document_id": "ibmcld_16365-7-1700", "score": 32.116240823871856, "text": "\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_13160-14797-16607", "score": 31.717137679718835, "text": "\nEnd the action under And then.\n13. Create a new step with the condition for 8 Ran successfully being false. Use something like It seems there was a problem creating the new event record for the Assistant to say and end the action under And then. Save and close the action with the icons in the upper right.\n14. Test the new action by clicking on Preview on the left and using the webchat. Type add new event and submit. When prompted by the bot, enter my conference as name, home office as location, pick dates for begin and end, and use [http://localhost](http://localhost) as URL. Thereafter, confirm that the data is correct.\n\n\n\nWhen creating a chatbot, you may want to [publish a chatbot](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-publish). It is the controlled release of a version which allows rolling back changes and to continue with development without impacting the chatbot interacting with real customers.\n\n\n\n\n\n Step 6: Integrate with Slack \n\nNow, you will integrate the chatbot with Slack.\n\n\n\n1. On the lower left, click on Integrations.\n2. In the integrations overview, in the section Channels, locate Slack and click Add.\n3. Follow the step by step instructions to integrate the Draft environment of your chatbot with Slack. More information about it is available in the topic [Integrating with Slack](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-slack).\n4. Once done, open up your Slack workspace. Begin a direct chat with the bot and say show me event details. Then, similar to above, answer with Think when prompted for an event name.\n\n\n\nZoom\n\n![Slack with the eventbot](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution19/Slackbot_event.png)\n\nSlack with the eventbot", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"}, {"document_id": "ibmcld_07148-7-2060", "score": 31.225928756782928, "text": "\nUsing the COVID-19 kit \n\nThe COVID-19 kit is a special collection available in US instances of IBM Watson\u2122 Discovery. This pre-built collection includes more than 10 data sources you can use to fuel a dynamic chatbot built with IBM Watson\u2122 Assistant and Discovery to answer your customers' questions about COVID-19.\n\nFAQ extraction is a beta feature that was used to create question and answer pairs for the kit. The FAQ extraction beta feature is now deprecated and will stop being supported in v1 Discovery service instances on 1 March 2022. As a consequence, the COVID-19 kit data collection will stop being supported also.\n\nThe COVID-19 kit extracts answers from trusted sources and automatically updates your chatbot as the content from those sources are updated. It uses FAQ extraction machine learning models developed by IBM Research labs to extract question/answer pairs. The kit is pre-configured with web crawl seeds from trusted sources such as the CDC, Harvard, and the United States Department of Labor. An expanded stopwords list and query expansions are also included in this collection to improve search results. It is designed to be augmented with your own data and customized to your needs.\n\nFor more information about this kit, and how you can create a chatbot and connect it to a data source with the IBM Watson\u2122 Assistant search skill using IBM Watson\u2122 Assistant and Discovery, see [COVID-19 \u2014 Are Your Virtual Assistant\u2019s Answers Up-To-Date?](https://medium.com/ibm-watson/covid-19-are-your-virtual-assistants-answers-up-to-date-c9e1ba70eb65654b).\n\nTo learn how to create a search skill in Watson Assistant, see [Creating a search skill](https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add). (This feature is available only to Watson Assistant Plus or Premium plan users.)\n\nSee the following to learn more about working with Discovery:\n\n\n\n* To learn how to create a service instance, see [Getting started with the Discovery tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-getting-started).", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-covidkit"}, {"document_id": "ibmcld_09228-7-1878", "score": 31.214068870900714, "text": "\nSample apps \n\nIBM is announcing the deprecation of the IBM Watson\u00ae Language Translator service for IBM Cloud\u00ae in all regions. As of 10 June 2023, the Language Translator tile will be removed from the IBM Cloud Platform for new customers; only existing customers will be able to access the product. As of 10 June 2024, the service will reach its End of Support date. As of 10 December 2024, the service will be withdrawn entirely and will no longer be available to any customers.\n\nCheck out the following sample applications to see what you can build with Language Translator.\n\nThese systems are for demonstration purposes only and are not intended to process Personal Data. No Personal Data is to be entered into these systems as they may not have the necessary controls in place to meet the requirements of the General Data Protection Regulation (EU) 2016/679.\n\n\n\n Snap and translate text in images (Node.js) \n\nThis sample app explains how to create a hybrid mobile app that uses Watson Language Translator and Tesseract OCR. With this sample app you can capture an image, extract the text, and translate that text.\n\n\n\n* [Read the blog](https://developer.ibm.com/announcements/snap-translate-using-tesseract-ocr-watson-language-translator/)\n* [Code Pattern](https://developer.ibm.com/patterns/snap-translate-using-tesseract-ocr-watson-language-translator/)\n* [View on GitHub](https://github.com/IBM/snap-and-translate)\n\n\n\n\n\n\n\n Multilingual Chatbot (Node.js, Python) \n\nThis chatbot that is built with Watson Assistant and Cloud Functions adds support for multiple languages with Language Translator.\n\n\n\n* [View on GitHub](https://github.com/with-watson/multilingual-chatbot)\n* [Try the demo](https://multilingual-chatbot.mybluemix.net/)\n* [Read more](https://medium.com/ibm-watson/build-multilingual-chatbots-with-watson-language-translator-watson-assistant-8c38247e8af1)", "title": "", "source": "https://cloud.ibm.com/docs/language-translator?topic=language-translator-sample-apps"}, {"document_id": "ibmcld_09228-1610-2667", "score": 30.504192269963262, "text": "\n* [View on GitHub](https://github.com/with-watson/multilingual-chatbot)\n* [Try the demo](https://multilingual-chatbot.mybluemix.net/)\n* [Read more](https://medium.com/ibm-watson/build-multilingual-chatbots-with-watson-language-translator-watson-assistant-8c38247e8af1)\n\n\n\n\n\n\n\n Real-time translation (Node.js) \n\nBy using Node.js and React components, you can create a web app that can be your personal translator. The app uses Watson Speech to Text, Watson Language Translator, and Watson Text to Speech services to transcribe, translate, and synthesize from your microphone to your headphones.\n\n\n\n* [Code Pattern](https://developer.ibm.com/components/watson-apis/patterns/build-a-real-time-translation-service-with-watson-api-kit)\n* [View on GitHub](https://github.com/ibm/watson-speech-translator)\n\n\n\n\n\n\n\n Korean Character Recognition (TensorFlow, Android) \n\nThis mobile application uses TensorFlow and Language Translator to recognize and translate handwritten Korean characters.\n\n\n\n* [View on GitHub](https://github.com/IBM/tensorflow-hangul-recognition)", "title": "", "source": "https://cloud.ibm.com/docs/language-translator?topic=language-translator-sample-apps"}, {"document_id": "ibmcld_07223-2330-3654", "score": 30.472105321540297, "text": "\n* [Get the Code](https://github.com/IBM/watson-discovery-analyze-data-breaches?cm_sp=IBMCode-_-import-enrich-and-gain-insight-from-data-_-Get-the-Code)\n* [View the Demo](https://www.youtube.com/watch?v=zAu9tHefdDc&cm_sp=IBMCode-_-import-enrich-and-gain-insight-from-data-_-View-the-Demo)\n\n\n\n[Cognitive Retail Chatbot](https://developer.ibm.com/patterns/create-cognitive-retail-chatbot/?cm_sp=Developer-_-code-_-retail_chatbot) Create a chatbot dialog using Watson Assistant, a Cloudant NoSQL database, Watson Discovery, and a Slack group.\n\n\n\n* [Get the Code](https://github.com/IBM/watson-online-store/?cm_sp=IBMCode-_-create-cognitive-retail-chatbot-_-Get-the-Code)\n* [View the Demo](https://www.youtube.com/watch?v=b-94B3O1czU&cm_sp=IBMCode-_-create-cognitive-retail-chatbot-_-View-the-Demo)\n\n\n\n[Cognitive News Search App](https://developer.ibm.com/patterns/create-a-cognitive-news-search-app/?cm_sp=Developer-_-code-_-trending_news) Build your own news mining web application using JavaScript, Node.js, and the Watson Discovery service. Use the Watson Node.js SDK to build your news app to search the latest news, find trends, and even integrate it with other applications, such as Slack.\n\n\n\n* [Get the Code](https://github.com/IBM/watson-discovery-news/?cm_sp=IBMCode-_-create-a-cognitive-news-search-app-_-Get-the-Code)", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-sample-apps"}, {"document_id": "ibmcld_13160-7-1812", "score": 30.326121024842205, "text": "\nBuild a database-driven Slackbot \n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nIn this tutorial, you are going to build a Slackbot which allows to search and create entries in a backend Db2 on Cloud database. The Slackbot is backed by the IBM Watson\u00ae Assistant service. You will integrate Slack and IBM Watson\u00ae Assistant using an Assistant integration. Db2 on Cloud is made available to Watson Assistant as custom extension.\n\nThe Slack integration sends messages between Slack and Watson Assistant. A custom extension, written in Python and deployed as serverless Code Engine app, exposes a REST API against the database backend.\n\nThis tutorial uses the new experience of Watson Assistant and an action skill. A former version was based on the dialog skill and the database was integrated using IBM Cloud\u00ae Functions with code written in Node.js. You can find that version of the tutorial in the [cloud-functions branch of the related code repository](https://github.com/IBM-Cloud/slack-chatbot-database-watson/tree/cloud-functions).\n\n\n\n Objectives \n\n\n\n* Build a chatbot using Watson Assistant which interacts with a database backend\n* Connect Watson Assistant to Slack using an integration\n* Create and deploy a Python database app to Code Engine\n* Access a Db2 on Cloud database via a Watson Assistant custom extension\n\n\n\nZoom\n\n![Architecture](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution19/SlackbotArchitecture.svg)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The user interacts with [IBM Watson\u00ae Assistant](https://cloud.ibm.com/docs/watson-assistant), either through Slack or using a web chat client\n2.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"}, {"document_id": "ibmcld_16293-7-1797", "score": 29.587053544261636, "text": "\nIntegrating with Slack \n\nIBM Cloud\n\nSlack is a cloud-based messaging application that helps people collaborate with one another.\n\nAfter you create an action, you can integrate your assistant with Slack.\n\nWhen integrated, depending on the events that you configure the assistant to support, your assistant can respond to questions that are asked in direct messages or in channels where the assistant is directly mentioned.\n\nAn example and instructions on how to create a Slackbot using Watson Assistant, Slack, and Db2 are given in the solution tutorial, [Build a database-driven Slackbot](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson).\n\n\n\n Adding the Slack integration \n\n\n\n1. Go to the Integrations page by clicking the integrations icon (![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)) in the left menu.\n2. Click Add on the Slack tile.\n3. Click Confirm.\n4. You need to have a Slack app to connect to.\n\nIf you don\u2019t have a Slack app, create one now. See [Starting with Slack apps](https://api.slack.com/start).\n5. Go to the [Your Apps](https://api.slack.com/apps) page on the Slack website, and then click the app you want to use.\n\nOpen the Slack app in a new browser tab, so you can easily switch back and forth between the Slack app settings page and Watson Assistant Slack integration configuration page.\n6. From the settings page for your Slack app, open the App Home page.\n7. Add access scopes for your Slack app.\n\nThe button label might be Review Scopes to Add or Update scopes depending on whether you are creating a new app or editing an app that you created before February 2020.\n\nThe method for Slack access changed.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-slack"}, {"document_id": "ibmcld_16324-3229-5312", "score": 29.465143383214226, "text": "\nChoose a narrow set of user goals first. If you start small and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. After your assistant is live, the built-in metrics of active user conversations help you understand what your customers are asking about, how well your assistant is able to meet their needs, and what to focus on next.\n\n\n\n\n\n 3. Choose the tone and language of your assistant \n\nBefore you build your assistant, it can also be helpful to choose the tone with which your assistant communicates. Is your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Write conversations that reflect your assistant's personality. Don't overdo it by sacrificing usability for the sake of keeping your assistant in character. Strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe that the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chatbots to identify themselves as chatbots.\n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-support).\n\n\n\n\n\n 4. Connect to content sources \n\nThe answer to common questions might already be documented somewhere in your organization's technical information. Plan whether you want to connect the assistant to existing content sources by taking an inventory of relevant help content (for example, product information, knowledge articles, FAQs) available to your customers.\n\nYou can give your assistant access to this information by adding a [search integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-add) to your assistant. The search integration uses IBM Watson\u00ae Discovery to return smart answers to natural language questions.\n\n\n\n\n\n 5. Plan your handoff strategy", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-plan-assistant"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04149-3050-4970", "score": 45.285565270078784, "text": "\nSelect Let's get started from the welcome page to begin setting up CIS.\n\n\n\n\n\n\n\n Step 2. Add and configure your domain \n\nNext, begin protecting and improving the performance of your web service by entering your domain or a subdomain.\n\nSpecify DNS zones. You can configure the name servers for these domains or subdomains at the domain's registrar or DNS provider. Do not use CNAMEs.\n\nThe Overview screen shows your domain in Pending status and remains Pending until you complete configuring your name servers with the registrar or existing DNS provider, which is covered in Step 4.\n\nYou cannot delete the CIS instance after you add a domain. To delete the instance, delete the domain from the instance first.\n\n\n\n\n\n Step 3. Set up your DNS records (optional) \n\nBefore transitioning the traffic for your domain to CIS, it is recommended that you import or recreate your DNS records in CIS. You can choose to skip this step, but if your DNS records are not configured properly in CIS, it might leave parts of your website inaccessible.\n\nImport records by uploading your exported records from your current DNS, or manually create your DNS records. To import records, select Import records.\n\nWhen you are finished, or to skip this step, select Next step.\n\n\n\n\n\n Step 4. Configure your name servers with the registrar or existing DNS provider \n\nTo begin receiving the benefits of CIS, you must delegate your domain to CIS. To delegate a domain, create an NS record with the name servers provided by CIS at your domain's registrar or existing DNS provider. If you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https://whois.icann.org/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-getting-started"}, {"document_id": "ibmcld_04195-6086-8151", "score": 39.399306009094445, "text": "\nBecause CIS doesn't support email traffic by default, you must set the PTR record to the location of your email server. Contact your email provider for assistance.\n\n\n\n\n\n\n\n Updating DNS records \n\nIn each record row, you can click the Edit record option from the menu, which opens a dialog box that you can use to update the record.\n\nAfter you are finished making your changes, select Update record to save them, or Cancel to abort the changes.\n\n\n\n\n\n Deleting DNS records \n\nIn each record row, you can select the Delete record option from the menu, which opens a dialog box to confirm the delete process.\n\nYou can select the Delete button to confirm your delete action. Select Cancel if you don't want to delete.\n\n\n\n\n\n Importing and exporting DNS records \n\nDNS records can be imported into and exported from CIS. All files are imported and exported as .txt files in BIND format. Learn more about [BIND format](https://en.wikipedia.org/wiki/Zone_file). Click the overflow menu and select to import or export records.\n\nImport records - By default, a total of 3500 DNS records are allowed (imported and created on CIS). You can import multiple files, one at a time, as long as the total number of records is under the max limit. After importing, you are shown a summary with the number of records successfully added and the number that failed, along with the reason why each record failed.\n\nExport records - Use Export records to create a backup of your zone file, or export it to use with another DNS provider. When this menu option is clicked, the records are downloaded to the location specified by your browser settings (typically the Downloads folder). To select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-set-up-your-dns-for-cis"}, {"document_id": "ibmcld_04334-33215-34565", "score": 37.387211848268706, "text": "\nValid values are any, all.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nList all dns records in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records 31984fea73a15b45779fa0df4ef62f9b -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-import \n\nImport your BIND config.\n\nibmcloud cis dns-records-import DNS_DOMAIN_ID --file FILE [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: BIND config to import. Required.\n\n-i, --instance\n: Instance name or ID. If not set, the context instance specified by ibmcloud cis instance-set INSTANCE is used.\n\n--output\n: Specify output format, only JSON is supported.\n\n\n\n\n\n Examples \n\nImport BIND config in domain 31984fea73a15b45779fa0df4ef62f9b.\n\nibmcloud cis dns-records-import 31984fea73a15b45779fa0df4ef62f9b --file bind_config_file.txt -i \"cis-demo\"\n\n\n\n\n\n\n\n ibmcloud cis dns-records-export \n\nExport BIND config.\n\nibmcloud cis dns-records-export DNS_DOMAIN_ID [--file FILE] [-i, --instance INSTANCE]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required.\n\n--file\n: The BIND config file that saves exported DNS records.\n\n-i, --instance\n: Instance name or ID.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04110-7-2007", "score": 34.93258938314735, "text": "\nAuditing events for CIS \n\nAs a security officer, auditor, or manager, you can use the Activity Tracker service to track how users and applications interact with the CIS service in IBM Cloud\u00ae.\n\nIBM Cloud Activity Tracker records user-initiated activities that change the state of a service in IBM Cloud. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. In addition, you can be alerted about actions as they happen. The events that are collected comply with the Cloud Auditing Data Federation (CADF) standard. For more information, see the [getting started tutorial for IBM Cloud Activity Tracker](https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-getting-started).\n\nNames for auditing events changed on 1 July 2020. The change replaced all underscore (_) characters in the names with dash (-) characters.\n\n\n\n List of events: DNS domains \n\nThe following table lists the actions that are related to DNS domains and generate an event:\n\n\n\nTable 1. Actions that generate DNS domain events\n\n Action Description \n\n internet-svcs.zones.create Create a DNS domain. \n internet-svcs.zones.update Update a DNS domain. \n internet-svcs.zones.delete Delete a DNS domain. \n internet-svcs.zones-activation-check.update Perform activation check for a DNS domain. \n internet-svcs.dnssec.update Enable or disable DNSSEC for a DNS domain. \n\n\n\n\n\n\n\n List of events: DNS records \n\nThe following table lists the actions that are related to DNS records and generate an event:\n\n\n\nTable 2. Actions that generate DNS record events\n\n Action Description \n\n internet-svcs.dns-records.create Create a DNS record. \n internet-svcs.dns-records.update Update a DNS record. \n internet-svcs.dns-records.delete Delete a DNS record. \n internet-svcs.dns-records-bulk.create Import DNS records from zone file. \n\n\n\n\n\n\n\n List of events: Load balancers \n\nThe following table lists the actions that are related to load balancers and generate an event:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-at_events"}, {"document_id": "ibmcld_04195-7739-8817", "score": 34.17599367212573, "text": "\nTo select another folder location, change your browser's settings to prompt you for a location with each download.\n\n\n\n\n\n Configuring and managing your secure DNS \n\nDNSSec is a technology to digitally sign DNS data so you can be assured it is valid. To eliminate vulnerability from the internet, DNSSec must be deployed at each step in the lookup, from root zone to final domain name (for example, www.icann.org).\n\nDNSSec adds a layer of authentication to the internet's DNS infrastructure, which otherwise is not secure. Secure DNS guarantees that visitors are directed to your web server when they type your domain name into a web browser. All you need to do is enable DNSSec in your DNS page from your IBM CIS account and add the DS record to your registrar.\n\nYou can select View DS records to display the information needed to add the DS record to your registrar. You must copy parts of the DS record and paste them into your registrar\u2019s dashboard. Every registrar is different, and your registrar might only require you to enter information for some of the available fields.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-set-up-your-dns-for-cis"}, {"document_id": "ibmcld_04111-1094-2517", "score": 34.15432574390809, "text": "\nEnable / Disable DNSSEC PATCH /v1/{crn}/zones/{domain_id}/dnssec internet-svcs.reliability.update internet-svcs.dnssec.update \n\n\n\n\n\n\n\n DNS Records \n\n\n\nTable 3. DNS Records\n\n Action Method IAM ACTION AT ACTION \n\n Get DNS records GET /v1/{crn}/zones/{domain_id}/dns_records internet-svcs.reliability.read internet-svcs.dns-records.read \n Create a DNS record POST /v1/{crn}/zones/{domain_id}/dns_records internet-svcs.reliability.manage internet-svcs.dns-records.create \n Update a DNS record PUT /v1/{crn}/zones/{domain_id}/dns_records/{record_id} internet-svcs.reliability.update internet-svcs.dns-records.update \n Delete a DNS record DELETE /v1/{crn}/zones/{domain_id}/dns_records/{record_id} internet-svcs.reliability.manage internet-svcs.dns-records.delete \n Import DNS records from zone file GET /v1/{crn}/zones/{domain_id}/dns_records_bulk internet-svcs.reliability.read internet-svcs.dns-records-bulk.read \n Export DNS records to a zone file POST /v1/{crn}/zones/{domain_id}/dns_records_bulk internet-svcs.reliability.manage internet-svcs.dns-records-bulk.create \n\n\n\n\n\n\n\n GLB \n\n\n\nTable 4. GLB\n\n Action Method IAM ACTION AT ACTION \n\n Get global load balancers GET /v1/{crn}/zones/{domain_id}/load_balancers internet-svcs.reliability.read internet-svcs.load-balancers.read \n Create a global load balancer POST /v1/{crn}/zones/{domain_id}/load_balancers internet-svcs.reliability.manage internet-svcs.load-balancers.create", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-at_iam_CIS"}, {"document_id": "ibmcld_04149-4598-6150", "score": 32.866853358308, "text": "\nIf you are unsure of who the registrar is for your domain, you can look it up at [whois.icann.org](https://whois.icann.org/).\n\nIf you delegate a subdomain (for instance, subdomain.example.com) from another DNS provider, you must replace the existing name server (NS) records and replace them with a name server record for each of the name servers that are provided by CIS. See [Managing DNS records in Cloudflare](https://developers.cloudflare.com/dns/manage-dns-records/how-to/create-dns-records/) for detailed instructions by provider.\n\nAfter you configure your registrar or DNS provider, it can take up to 24 hours for the changes to take effect. When we verify that the specified name servers were configured correctly for your domain or subdomain, the domain's status changes from Pending to Active.\n\nYour domain must move to Active state within 60 days or your domain and any configuration data is removed.\n\n\n\n\n\n Step 5. Ensure that CIS is resolving the domain information for your application, hostname, or website \n\nTo proceed, select Reliability > DNS. Be sure to add the appropriate DNS records. Add the A Record and any AAAA or MX entries that are populated. If you forget to add these records before the registrar's delegation is complete, IBM Cloud Internet Services cannot resolve the domain information for your internet-facing applications.\n\n\n\n\n\n\n\n Next steps \n\nTo begin managing CIS functions and features, see [Managing your IBM Cloud Internet Services deployment](https://cloud.ibm.com/docs/cis?topic=cis-manage-your-cis-deployment).", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-getting-started"}, {"document_id": "ibmcld_04148-0-1895", "score": 32.2962732033643, "text": "\n\n\n\n\n\n\n  Getting CIS running with a new subdomain \n\nFollow these steps to practice using CIS with a subdomain or CNAME. This example uses the GoDaddy domain registrar. Your case might be different, depending on which registrar you use.\n\n\n\n1.  Deploy a CIS instance by using the IBM Cloud console or API.\n\nIt is recommended that you mirror the name of your CIS instance with the domain or subdomain.\n2.  Click Let\u2019s get started.\n3.  Enter the subdomain in the Domain name field and click Connect and continue.\n4.  For new subdomains click Next Step, for existing subdomains click Import records.\n5.  Make note the New NS records for entry into the GoDaddy DNS Management system.\n6.  Log in to GoDaddy domain Registrar.\n7.  Navigate to the DNS Management page for the candidate CIS domain. IBM Cloud\u00ae must be updated through the API.\n8.  Click ADD to create an NS Host record for each name server entry provided from CIS.\n9.  Set up a DNS record with the supplied CIS NS Records\n\n\n\n*  Type Nameserver\n*  Host subdomain (the name of the subdomain, for example, subdomain.example.com)\n*  Points to ns004.name.cloud.ibm.com\n*  TTL \u00bd hour\n\n\n\n10. The DNS Management page now reflects the two new NS records for the subdomain.\n11. Go back to the IBM Cloud Internet Services instance.\n12. After the NS Records are DNS propagated, it is reflected in the DNS tools, and you are ready to proceed.\n13. With completed NS propagation, click Check name servers.\n14. CIS starts checking NS configuration for the subdomain and might be in a Pending State.\n\nAny typographical errors in can produce a \"silent\" failure. If your subdomain is in the pending state for more than 30 minutes, you might have an error.\n\n\n\nUpon successful subdomain name server and NS record confirmation, the CIS instance reports Active. Customers are now ready to start configuring the service and routing traffic to their services.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-get-started-new-subdomain"}, {"document_id": "ibmcld_04160-1745-2938", "score": 32.185706328662974, "text": "\nIf a global load balancer is created with the name glbcust.ibmmo.com using the origin pool, then a client on the internet can execute the command:\n\n$ ping glbcust.ibmmo.com\nPING glbcust.ibmmo.com (169.61.244.18): 56 data bytes\n\nIn this example, CIS:\n\n\n\n* Created a DNS record named glbcust.ibmmo.com.\n* Used the global load balancer to resolve the DNS name to one of the IP addresses identified in the origin pool.\n\n\n\nNotice that the global load balancer does not terminate the TCP connection.\n\nSetting a DNS element or global load balancer to proxy changes the behavior. If, for example, you turn on proxy and Security > TLS > Mode to something besides Off, the CIS now terminates the TCP connection and establishes a second connection between CIS and the originator.\n\nIn this example, CIS:\n\n\n\n* Created a DNS record named: glbcust.ibmmo.com.\n* Used the global load balancer to resolve the DNS name to a CIS provided IP address.\n\n\n\nNow, connections to glbcust.ibmmo.com are terminated by CIS, and HTTPS certificates are hosted by CIS (which is required for TCP termination).\n\nAfter the client connects to the application the picture looks like this:\n\n[client]<--tls-->[cis]<-->[origin server]", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-global-load-balancer-glb-concepts"}, {"document_id": "ibmcld_07578-978380-979969", "score": 32.03634339588958, "text": "\nYou must re-import the certificate with a different CRN, and then update the VPN server with the new certificate CRN.\n* Can I use a customized hostname for the VPN server?\n\nYes, you can. You must create a CNAME DNS record and point it to the VPN server hostname in your DNS provider. After that, edit the client profile by replacing direct remote 445df6c234345.us-south.vpn-server.appdomain.cloud with remote your-customized-hostname.com.\n\n445df6c234345.us-south.vpn-server.appdomain.cloud is an example VPN server hostname.\n\nIf you are using [IBM Cloud Internet Services](https://cloud.ibm.com/docs/cis?topic=cis-getting-started) as your DNS provider, refer to [CNAME Type record](https://cloud.ibm.com/docs/cis?topic=cis-set-up-your-dns-for-ciscname-type-record) for information about how to add a CNAME DNS record.\n* What information should I provide in an IBM Support case if I need help?\n\nSupply the following content in your [IBM Support case](https://cloud.ibm.com/docs/get-support?topic=get-support-open-case):\n\n\n\n1. Your VPN server ID.\n2. Your VPN client and operating system version.\n3. The logs from your VPN client.\n4. The time range when you encountered the problem.\n5. If user-ID-based authentication is used, supply the username.\n6. If certificate-based authentication is used, supply the common name of your client certificate.\n\nTo view the common name of your client certificate, use the OpenSSL command openssl x509 -noout -text -in your_client_certificate_file in the subject section.\n\n\n\n* How do I assign the VPN client role using IAM access management tags in the API?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08435-1255-3053", "score": 37.035177221245874, "text": "\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_09061-2799-4588", "score": 36.47297892617239, "text": "\n[Log in to the IBM Cloud console](https://cloud.ibm.com/login/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.\n6. From the options menu, click Schedule key deletion and review the key's associated resources.\n7. Click the Next button, enter the key name, and click Schedule deletion.\n8. Contact another user to complete the deletion of the key.\n\n\n\nThe other user must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n\n\n Purging a key that holds dual authorization in the console \n\nFour hours after the other user with a Manager access policy has authorized the key for deletion, it can be purged by one of the users as long as they hold [the KeyPurge attribute](https://cloud.ibm.com/docs/key-protect?topic=key-protect-grant-access-keysgrant-access-keys-specific-functions).\n\nThis can be done by clicking the \u22ef icon to open a list of options for the key that you want to purge and then clicking Purge. If you cannot delete the key, make sure it has been at least four hours since the key was authorized for deleting by another user and that you hold the KeyPurge attribute.\n\n\n\n\n\n Authorize deletion for a key with the API \n\n[After you enable dual authorization for an instance or key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>/actions/setKeyForDeletion\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_09061-1334-3188", "score": 36.46026422656983, "text": "\nWhen the first user authorizes a key for deletion, it remains in the [Active state](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted. When you delete a key, it is \"soft deleted\", meaning that the key and its associated data will be restorable up to 30 days after deletion. You are able to still retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically [purged](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-key-purge), or hard deleted, and its associated data will be permanently removed from the Key Protect service.\n\n\n\n\n\n\n\n Authorize deletion for a key in the console \n\n[After you enable dual authorization for an instance or key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth), you can provide the first authorization to delete a key by using the Key Protect IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/login/).\n2. Go to Menu > Resource List to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Key Protect.\n4. On the application details page, use the Keys table to browse the keys in your service.\n5. Click the \u22ef icon to open a list of options for the key that you want to delete.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_08435-4-1684", "score": 34.5386281119087, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_09061-4-1966", "score": 33.56500214698501, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_08435-2509-4057", "score": 33.205195866448776, "text": "\nAfter you [enable dual authorization for an instance](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4. On the KMS keys page, use the Keys table to browse the keys in your service.\n5. Click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/action-menu-icon.svg) to open a list of options for the key that you want to delete.\n6. From the options menu, click Schedule key deletion and review the key's associated resources.\n7. Enter the name of the key that is to be deleted, and click Schedule key deletion.\n8. Contact the second approver to complete the deletion of the key.\n\n\n\n\n\n\n\n Step 2. Delete the key \n\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon !", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_09055-48796-50259", "score": 32.63601969270987, "text": "\n\"updatedBy\": \"user id ...<redacted>...\",\n\"rotation\": {\n\"interval_month\": 2\n}\n}\n]\n\n\n\n\n\n Required parameters \n\nKEY_ID\n: The ID of the key that you want to query. To retrieve a list of your available keys, run the [kp keys](#kp-keys) command.\n\n\n\n\n\n Optional parameters \n\n-d, --dual-auth\n: Show policies that have a dual-auth-delete policy.\n\n\n\n\n\n\n\n kp key policy-update dual-auth-delete \n\nYou can use Key Protect to safely delete encryption keys by using a dual authorization process. When you delete a key, you shred its contents and associated data. Any data that is encrypted by the key becomes inaccessible.\n\nDeleting a key that has a [dual authorization policy](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) requires an authorization from two users. With the Key Protect API, you can provide the first authorization by [setting the key for deletion](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the [GUI](https://cloud.ibm.com/login/) or [API](https://cloud.ibm.com/apidocs/key-protect) to delete the key.\n\nibmcloud kp key policy-update dual-auth-delete KEY_ID\n-i, --instance-id INSTANCE_ID\n-e, --enable\n[-o, --output OUTPUT]\n\n\n\n Example \n\nThis example enables the dual authorization delete policy.\n\n create a root key\n$ KEY_ID=$(ibmcloud kp key create my-root-key --output json | jq -r '.[\"id\"]')\n\n$ echo $KEY_ID", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-cli-reference-five-two"}, {"document_id": "ibmcld_08776-2908-4519", "score": 32.61250607286877, "text": "\nDual authorization enabled The status of a dual authorization policy on the key.<br><br><br><br> * True: Dual authorization is required to delete the key.<br> * False: No prior authorization is required to delete the key.<br><br><br> \n Set for deletion Indicates whether a delete authorization is issued for a key.<br><br><br><br> * True: An authorization to delete this key is issued by the first user. A second user with a Manager access policy can safely delete the key.<br> * False: The key is not set for deletion. No further action is needed.<br><br><br> \n Deletion expiration The date that an authorization for deletion expires for the key. If this date passes, the authorization is no longer valid. If False is the value for the Dual authorization enabled or Set for deletion column of the key, the Deletion expiration column is left empty. \n\n\n\nNot all key characteristics are displayed by default. To customize how the Keys table is to be presented, click the Settings icon![Settings icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/settings.svg) and check the columns to be displayed.\n\nNot seeing the full list of keys that are stored in your service instance? Verify with your administrator that you are assigned the correct role for the applicable service instance or individual key. For more information about roles, see [Roles and permissions](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-accessroles).\n\nYou can also search for a specific key by using the search bar, or filter keys based on your needs by clicking the Filter icon !", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-keys"}, {"document_id": "ibmcld_08695-1371-3050", "score": 30.829424381201076, "text": "\n* To resolve the error that is reported in error message 1, [review the resources](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key before you delete a key.\n\nYou can [force deletion on a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) that's protecting a cloud resource. However, the action won't succeed if the key's associated resource is nonerasable due to a retention policy. You can verify whether a key is associated with a nonerasable resource by [checking the registration details](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-protected-resourcesview-protected-resources-api) for the key. Then, you must contact an account owner to remove the retention policy on each resource that is associated with the key before you can delete the key.\n\nIf you don't need the resources that are associated with the key any more, you can also first delete the associated resources and then delete the key.\n* To resolve the error that is reported in error message 2, you need to assign two approvers to delete a key if you enable the dual authorization policy [for your instance](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy).\n\nThe first approver must have a Writer or Manager role to first schedule the key deletion and the second approver must have a Manager role to complete the deletion within 7 days. For more information, see [Deleting keys by using dual authorization](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys).", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys"}, {"document_id": "ibmcld_09061-6176-7874", "score": 30.664320946401425, "text": "\n<br> <br>For more information, see [Retrieving an access token](https://cloud.ibm.com/docs/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br>For more information, see [Retrieving an instance ID](https://cloud.ibm.com/docs/key-protect?topic=key-protect-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) by using the Key Protect GUI or API.\n\nIf you need to prevent the deletion of a key that's already authorized for deletion, you can remove the existing authorization by calling POST /api/v2/keys/<keyID_or_alias>/actions/unsetKeyForDeletion.\n\n\n\n Delete the key \n\nAfter you set a key for deletion, another user with a Manager access policy can safely delete the key by using the Key Protect GUI or API.\n\nKey Protect sets a seven-day authorization period that starts after you provide the first authorization to delete the key. During this seven-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-states) and all key operations are allowed on the key. If no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03120-3469-5331", "score": 61.25407849608816, "text": "\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_03353-6854-8737", "score": 56.37056496469897, "text": "\nSave the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:\n\n\n\n* GUI Direction: Specifies the layout direction of elements, such as buttons or menus, in the graphical user interface. Choose LTR (left-to-right) or RTL (right-to-left). If not specified, the tool follows the web browser GUI direction setting.\n* Text Direction: Specifies the direction of typed text. Choose LTR (left-to-right) or RTL (right-to-left), or select Auto which will automatically choose the text direction based on your system settings. The None option will display left-to-right text.\n* Numeric Shaping: Specifies which form of numerals to use when presenting regular digits. Choose from Nominal, Arabic-Indic, or Arabic-European. The None option will display Western numerals.\n* Calendar Type: Specifies how you choose filtering dates in the skill UI. Choose Islamic-Civil, Islamic-Tabular, Islamic-Umm al-Qura, or Gregorian.\n\n\n\nThis setting is not reflected in the \"Try it out\" panel.\n\n![Bidi options](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-language-support"}, {"document_id": "ibmcld_02839-3583-5403", "score": 54.648910907965515, "text": "\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_02839-1790-3940", "score": 54.083476765593936, "text": "\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_03027-6555-8367", "score": 52.08004080178002, "text": "\nThe language property is set to the original language of the skill. For example, the language property is en for an English skill.\n4. Change the value of this property to the language you want to use instead. For example, change it to fr for French or de for German.\n5. Save the changes to the JSON file, and then upload the edited file, overwriting the existing skill.\n\n\n\n\n\n\n\n Configuring bidirectional languages \n\nFor bidirectional languages, such as Arabic, you can change your skill preferences.\n\n\n\n1. From your skill tile, click the Actions drop-down menu, and then select Language Preferences.\n\nThis option is only available for skills that are configured to use a bidirectional language.\n2. Select from the following options for your skill:\n\n\n\n* GUI Direction: Specifies the layout direction of elements, such as buttons or menus, in the graphical user interface. Choose LTR (left-to-right) or RTL (right-to-left). If not specified, the tool follows the web browser GUI direction setting.\n* Text Direction: Specifies the direction of typed text. Choose LTR (left-to-right), RTL (right-to-left), or Auto (which automatically chooses the text direction based on your system settings). The None option displays left-to-right text.\n* Numeric Shaping: Specifies which form of numerals to use when presenting regular digits. Choose from Nominal, Arabic-Indic, or Arabic-European. The None option will display Western numerals.\n* Calendar Type: Specifies how you choose filtering dates in the skill UI. Choose Islamic-Civil, Islamic-Tabular, Islamic-Umm al-Qura, or Gregorian.\n\n\n\nThis setting is not reflected in the Try it out panel.\n\n![Bidi options](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/bidi-options.png)\n3. Click the X to close the page.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support"}, {"document_id": "ibmcld_03381-4-1869", "score": 46.852679268834486, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Adding a dialog skill \n\nThe natural-language processing for the Watson Assistant service is defined in a dialog skill, which is a container for all of the artifacts that define a conversation flow.\n\nYou can add one dialog skill to an assistant. See [Skill limits](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-addskill-add-limits) for information about limits per plan.\n\n\n\n Create the dialog skill \n\nYou can create a skill from scratch, use a sample skill that is provided by IBM, or upload a skill from a JSON file.\n\nTo add a skill, complete the following steps:\n\n\n\n1. From the assistant where you want to add the skill, click Add an actions or dialog skill.\n2. Do one of the following:\n\n\n\n* To create a new dialog skill, remain on the Create skill tab.\n* To add the dialog sample skill that is provided with the product as a starting point for your own skill or as an example to explore before you create one yourself, open the Use sample skill tab, and then click the sample labeled TYPE: Dialog. You can skip the remaining steps.\n* To add a skill that was downloaded previously, you can upload it as a JSON file. Open the Upload skill tab. Drag a file or click Drag and drop file here or click to select a file and select the JSON file you want to upload.\n\nThe uploaded JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10 MB. If you need to upload a larger skill, consider using the REST API. For more information, see the [API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v1?curl=createworkspace).\n\nClick Upload.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add"}, {"document_id": "ibmcld_03126-3707-6008", "score": 46.643573368404766, "text": "\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_03380-0-1070", "score": 45.903060591607804, "text": "\n\n\n\n\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n  Advanced skill development \n\nA developer can extend the capabilities of a skill.\n\nLearn more about what's possible in the following sections.\n\n\n\n  Dialog skill development \n\n\n\n*  [Adding custom dialog flow for integrations](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-integrations)\n*  [Defining responses using the JSON editor](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-responses-json)\n*  [Handling phone interactions](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions)\n*  [Handling SMS with Twilio interactions](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-sms-actions)\n*  [Making a programmatic call from dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-webhooks)\n*  [Requesting client actions](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-actions-client)\n\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-develop"}, {"document_id": "ibmcld_16364-62879-64703", "score": 45.40722516290004, "text": "\n* For dialog skills, the Try it out pane now uses the [React](https://reactjs.org/) UI framework similar to the rest of the Watson Assistant user interface. You shouldn't see any change in behavior or functionality. As a part of the update, dialog skill error handling has been improved within the \"Try it out\" pane. This update was enabled on these dates:\n\n\n\n* September 9, 2021 in the Tokyo and Seoul data centers\n* September 13, 2021 in the London, Sydney, and Washington, D.C. data centers\n* September 15, 2021 in the Dallas and Frankfurt data centers\n\n\n\n\n\n\n\n\n\n 13 September 2021 \n\nDialog skill \"Try it out\" improvements\n: For dialog skills, the Try it out pane now uses the [React](https://reactjs.org/) UI framework similar to the rest of the Watson Assistant user interface. You shouldn't see any change in behavior or functionality. As a part of the update, dialog skill error handling has been improved within the \"Try it out\" pane. This update was enabled on September 9, 2021 in the Tokyo and Seoul data centers. On September 13, 2021, the update was enabled in the London, Sydney, and Washington, D.C. data centers.\n\nDisambiguation feature updates\n: The dialog skill disambiguation feature now includes improved features:\n\n\n\n* Increased control: The frequency and depth of disambiguation can now be controlled by using the sensitivity parameter in the [workspace API](https://cloud.ibm.com/apidocs/assistant/assistant-v1updateworkspace). There are 5 levels of sensitivity:\n\n\n\n* high\n* medium_high\n* medium\n* medium_low\n* low\n\n\n\nThe default (auto) is medium_high if this option is not set.\n* More predictable: The new disambiguation feature is more stable and predictable. The choices shown may sometimes vary slightly to enable learning and analytics, but the order and depth of disambiguation is largely stable.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03166-12855-14852", "score": 45.262614062967714, "text": "\nThe settings include separate greeting messages for the desktop and mobile versions of the launcher.\n\nThe language of the default text shown within the launcher depends on the locale configured for the web chat. For more information, see [Languages](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslanguages). If you customize the greeting text, the text you provide is used regardless of the locale settings.\n\n\n\n\n\n Configuring the home screen \n\nBy default, the web chat window shows a home screen that can welcome users and tell them how to interact with the assistant. The home screen replaces any greeting that would otherwise be sent by a Welcome node in a dialog skill, or by the Greet customer system action in an actions skill. (If you prefer to use a Welcome node or a Greet customer system action instead of the home screen, you can disable the home screen on the Home screen tab.)\n\n![An example of the home screen](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/home-screen.png)\n\n\n\n1. Add a greeting that is engaging and invites the user to interact with your assistant. A greeting is required.\n2. Add three conversation starter messages.\n\nThese messages are displayed in the web chat as examples of the types of questions that customers can ask. Customers can click one of them to submit it to the assistant.\n\nYou must test each message that you add as a conversation starter. Use only questions that the assistant understands and knows how to answer well.\n\nIf your assistant has multiple skills attached to it, the dialog skill orchestrates the incoming messages. If you want an action that you created to respond to a conversation starter message, make sure your dialog is set up to call the action. For more information, see [Calling an actions skill from a dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-call-action).\n\nAll three conversation starters are required.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06968-15099-17180", "score": 36.012456399478275, "text": "\n[checkmark icon](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/icons/checkmark-icon.svg) \n\n\n\n\n\n* PDF files that are secured with a password or certificate are not supported. Vector objects, including SVG images and vectorized text, are not supported. Only images of the supported image file types that occur in the PDF are rendered.\n* Only single-page image files are supported.\n* Files within compressed archive files (ZIP, GZIP, TAR) are extracted. Discovery ingests the supported file types within the archive; it ignores all other file types. The file names must be encoded in UTF-8. Files with names that include Japanese characters, for example, must be renamed before they are added to the ZIP file.\n* Discovery supports MacOS ZIP files only if they are generated by using a command such as: zip -r my-folder.zip my-folder -x \".DS_Store\". ZIP files that are created by right-clicking a folder and clicking Compress are not supported.\n* PDF files that you upload as part of an archive file are not displayed in the advanced view for a query result that you open from the Improve and customize page. If you want the file to be viewable from the advanced view, reimport the PDF file separately from the archive file.\n\n\n\nWhen you add files to a Document Retrieval for Contracts project type, any file types that support SDU and OCR are processed with a pretrained Smart Document Understanding model and Optical Character Recognition automatically.\n\n\n\n\n\n Document limits \n\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collections"}, {"document_id": "ibmcld_00510-5537-7566", "score": 34.03274605253865, "text": "\nInstead, keep orders separate as their own document type, referencing the customer ID. Now the model is immutable. To add an order, I create a new order document in the database, which cannot generate conflicts.\n\nTo be able to retrieve all orders for a specific customer, we can employ a view, which we cover later.\n\nAvoid constructs that rely on updates to parts of existing documents, where possible. Bad data models are often hard to change after you\u2019re in production.\n\nThe previous pattern can be solved efficiently by using partitioned databases, which are covered in greater detailed later.\n\nFor more information, see the following documentation:\n\n\n\n* IBM Cloudant guide to [data modeling](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-five-tips-for-modeling-your-data-to-scale-faq)\n* [Database partitions](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-database-partitioning)\n\n\n\n\n\n\n\n Keep documents small \n\nIBM Cloudant imposes a max doc size of 1 MB. This limit does not mean that a close-to-1-MB document size is a good idea. On the contrary, if you find you are creating documents that exceed single-digit KB, you probably need to revisit your model. Several things in IBM Cloudant become less performant as documents grow. JSON decoding is costly, for example.\n\nLet's look at the following sections: Documents must group data that mostly changes together and Keep documents small. It\u2019s worth stressing that models that rely on updates have a maximum volume limit of 1 MB, the cut-off for document size. This size isn\u2019t what you want.\n\n\n\n\n\n Avoid using attachments \n\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-data-modeling"}, {"document_id": "ibmcld_16423-3286-5408", "score": 32.808019912342154, "text": "\nUpload one CSV file at a time. The first column in the CSV file specifies the file name of the document. The second column in the file contains the document text. For an example of the required format, see the [documents-new.csv](https://watson-developer-cloud.github.io/doc-tutorial-downloads/knowledge-studio/documents-new.csv) file in the tutorial sample files.\n\n\n\n\n\n PDF files \n\nText cannot be extracted from a PDF in some cases, depending on how the PDF was created. Typically, text can't be extracted from embedded fonts that don't map to unicode characters. If you are unsure whether text from a PDF can be extracted, you can try copying the text from the PDF and then pasting it into a text editor. If you do not see the same characters that are visible in the PDF itself, then the text extraction would likely fail.\n\n\n\n\n\n Formatted documents \n\nWhen formatted documents are converted to plain text, it's possible that losing the formatting could result in poor tokenization of words. For example, if a table row in a DOCX file contains cell values that do not end with a period, the values might be converted as one sentence. As another example, if a PDF document contains a very long word that is hyphenated at the end of a line, that word might be converted as two words. In cases like these, the documents might not be suitable for machine learning unless you pre-process the files to fix formatting limitations.\n\n\n\n\n\n Documents from another Watson Knowledge Studio workspace \n\nIf you previously downloaded documents from a Knowledge Studio workspace, you can upload the ZIP file that you downloaded. An option lets you specify whether you want the ground truth annotations to be included in the imported files.\n\nAfter documents are annotated, the annotated documents are stored in JSON format. The markup language in these files, which shows how the original document text was parsed and tokenized, includes elements for all of the annotations that a human annotator added. To improve model accuracy over time, you can upload these files into another workspace, thus preserving all of the existing annotations.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"}, {"document_id": "ibmcld_07140-2710-4310", "score": 32.697897319350695, "text": "\n* HTML files are converted to JSON using the html options, and the resulting JSON is converted using the json options.\n* JSON files are converted using the json options.\n\n\n\nIf you configure your collection using [Smart Document Understanding](https://cloud.ibm.com/docs/discovery?topic=discovery-sdu), the PDF and Word conversion settings listed are not used, so changing these conversion settings are ignored.\n\nThese options are described in the following sections. After conversion completes, [enrichment](https://cloud.ibm.com/docs/discovery?topic=discovery-configrefenrichment) and [normalization](https://cloud.ibm.com/docs/discovery?topic=discovery-configrefnormalization) are performed before the content is stored.\n\n\n\n PDF \n\nIf you configure your collection using [Smart Document Understanding](https://cloud.ibm.com/docs/discovery?topic=discovery-sdu), the PDF and Word conversion settings listed are not used, so changing these conversion settings are ignored.\n\nThe pdf conversion object defines the conversion from PDF to HTML and has the following structure:\n\n\"pdf\": {\n\"heading\": {\n\"fonts\": [\n{\n\"level\": 1,\n\"min_size\": 24,\n\"max_size\": 80,\n\"bold\": false,\n\"italic\": true,\n\"name\": \"arial\"\n},\n{\n\"level\": 2,\n\"min_size\": 18,\n\"max_size\": 24,\n\"bold\": true,\n\"italic\": false,\n\"name\": \"ariel\"\n}\n]\n}\n},\nShow more\n\nWhen converting PDF files, headings in those files can be identified and converted into an appropriate HTML \"h\" tag by identifying the size, font, and style of each heading level. Heading levels can be specified multiple times, if necessary, to correctly identify all relevant sections.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-configref"}, {"document_id": "ibmcld_00556-7-1696", "score": 31.58242360049144, "text": "\nHow to use attachments \n\nAnother way to store data is to use attachments. Attachments are Binary Large OBject ([BLOB](https://en.wikipedia.org/wiki/Binary_large_object)) files that are included within documents.\n\nIt's a good idea to keep attachments small in size and number because attachments can impact performance.\n\nThe BLOB is stored in the _attachments component of the document. The BLOB holds data that includes the following information:\n\n\n\n* The attachment name\n* The type of the attachment\n* The actual content\n\n\n\nExamples of BLOBs would be images and multimedia.\n\nIf you include the attachment as an [inline](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the overall JSON, the attachment content is represented by using BASE64 form.\n\nThe content type corresponds to a [MIME type](https://en.wikipedia.org/wiki/Internet_media_typeList_of_common_media_types). For example, if you want to attach a .jpg image file to a document, you specify the attachment MIME type as image/jpeg.\n\nAttachments aren't permitted on documents in [_replicator](https://cloud.ibm.com/apidocs/cloudantpostreplicate) or [_users](https://cloud.ibm.com/apidocs/cloudantputsecurity) databases.\n\n\n\n Create or update \n\nTo create a new attachment at the same time as creating a new document, include the attachment as an [inline](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-to-use-attachmentsinline) component of the JSON content.\n\nTo create a new attachment on an existing document, or to update an attachment on a document, make a PUT request with the document's most recent _rev to https://$ACCOUNT.cloudant.com/$DATABASE/$DOCUMENT_ID/$ATTACHMENT.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-how-to-use-attachments"}, {"document_id": "ibmcld_07117-1664-3943", "score": 29.40497230443807, "text": "\nIf you encounter this issue, open the file in a more recent version of Microsoft Office and convert the file to the DOCX, PPTX, or XLSX format respectively, and then upload the DOCX, PPTX, or XLSX file.\n\nLine breaks are inserted randomly\n: When some files in Microsoft Office format are added to a collection, line breaks are inserted seemingly at random to the text that is stored in the html field in the collection's index. The unexpected line breaks can impact the efficiency of enrichments, such as custom rule recognition.\n\nCause: As part of their ingestion into Discovery, such files are converted from Office format to PDF format. When the conversion happens, textual content is sometimes lost due to the nature of a PDF file. While the new lines appear to be added at random, they typically get inserted in areas where text wraps in the original document, such as in narrow text boxes or to accommodate other inline elements, such as images or diagrams.\n\nSolution: To avoid new line insertions, increase the width of text boxes in the original document. If the original document has a section where text wraps to accommodate an inline element, such as an image, move the image so that it is situated in its own section and the nearby text doesn't need to wrap around it. To test whether your fixes address the issue, you can convert the original file to a PDF file to check for unexpected carriage returns in the text.\n\nAfter applying a pretrained Smart Document Understanding model to a PPT file, table boundaries are not recognized properly\n: During the conversion process, text that is extracted from the table is confused with text that is outside the table in some PPT pages. This issue is more likely to occur in tables with a lot of text and that have footnotes displayed just outside the table border. If you encounter this issue, export the PPT file as a PDF file, and then upload the PDF file instead. Apply a user-trained Smart Document Understanding (SDU) model to the document, and then use the SDU tool to identify the tables in the document. The resulting model handles table boundaries properly and can extract text from the tables cleanly.\n\n\n\n\n\n PDF file troubleshooting tips \n\nFailed to parse document due to invalid encoding\n: Enable OCR for the file.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-troubleshoot-ingestion"}, {"document_id": "ibmcld_16358-1769-3890", "score": 28.635216506937166, "text": "\nYou can complete this tutorial at no cost by using a Plus plan, which offers a 30-day trial at no cost. However, to create a Plus plan instance of the service, you must have a paid account (where you provide credit card details). For more information about creating a paid account, see [Upgrading your account](https://cloud.ibm.com/docs/account?topic=account-upgrading-account).\n2. Create a Plus plan Discovery service instance.\n\nGo to the [Discovery](https://cloud.ibm.com/catalog/services/watson-discovery) resource page in the IBM Cloud catalog and create a Plus plan service instance.\n\nSpecify Dallas as the location.\n\nAs part of this tutorial, you will provision other services also. The services must be hosted in the same data location so that they can connect to one another. Because the NeuralSeek service is available only from Dallas, you will create all of the service instances in Dallas.\n\n\n\nIf you decide to stop using the Plus plan and don't want to pay for it, delete the Plus plan service instance before the 30-day trial period ends.\n\n\n\n\n\n\n\n Step 1: Get the product documentation \n\nTo use the Discovery product documentation as our knowledge base, we will download the product documentation as a PDF file.\n\n\n\n1. From a web browser, go to the product documentation site.\n\nhttps://cloud.ibm.com/docs/discovery-data\n2. From the table of contents panel, click the overflow menu icon in the Product guide section, and then choose View as PDF.\n3. Save the PDF file to your system by clicking the Save icon from the page header.\n4. Use a PDF file editor to split the PDF document into two separate PDF files of similar size.\n\nSplitting the PDF creates two smaller files that can be enriched faster in Discovery.\n\n\n\n\n\n\n\n Step 2: Create a Document Retrieval project \n\nNow that you have the latest copy of the product documentation, add it to a Discovery project as your data source.\n\nIn Discovery, you will create a Document Retrieval project type. Documents that you add to a project of this type are automatically enriched in the following ways:\n\n\n\n* Entities, such as proper nouns, are identified and tagged.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-tutorial-neuralseek"}, {"document_id": "ibmcld_00558-23465-25360", "score": 28.3590608717126, "text": "\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https://cloud.ibm.com/apidocs/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https://cloud.ibm.com/apidocs/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https://www.ibm.com/cloud/data-centers/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-public"}, {"document_id": "ibmcld_12904-23555-25450", "score": 28.3590608717126, "text": "\nIBM Cloudant JSON documents and requests have the following maximum size limits:\n\n\n\nTable 4. Maximum size limits for JSON documents and requests\n\n Limit Maximum Size \n\n Individual Document Size 1 MB \n Single Attachment Size 10 MB \n Request Body Size 11 MB \n\n\n\nIf you exceed these limits, a [413 response](https://cloud.ibm.com/apidocs/cloudantlist-of-http-codes) alerts you.\n\nThe IBM Cloudant team recommends that you store binary attachments, or large JSON blobs, in object storage and save a link to the location in an IBM Cloudant JSON document.\n\nWhen you replicate, documents or attachments that exceed these limits don't replicate to the target database. For more information about how to detect replication errors, see [Replication errors](https://cloud.ibm.com/apidocs/cloudantgetreplicationdocument).\n\n\n\n\n\n Locations and tenancy \n\nBy default, all Lite and Standard plans are deployed on multi-tenant environments. As part of your plan selection, you can choose from the following IBM Cloud locations.\n\n\n\n* Chennai (SZR)\n* Dallas\n* Frankfurt\u2021\n* London\n* Osaka\n* Sydney\n* Seoul (SZR)\n* Tokyo\n* Washington DC\n\n\n\nSingle-Zone Region (SZR) means that only one availability zone is available in that location. All other locations are Multi-Zone Regions (MZR) and leverage three separate availability zones for instances that are deployed in those locations. For more information, see the [High availability (HA), disaster recovery (DR), and backup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-disaster-recovery-and-backup) documentation.\n\nDedicated Hardware plan instances can be deployed in most [IBM data center locations](https://www.ibm.com/cloud/data-centers/). See the drop-down menu in the IBM Cloud catalog for an up-to-date list of available locations.\n\n\u2021All IBM Cloudant instances that are deployed from the IBM Cloud Frankfurt region are deployed into EU-managed environments.", "title": "", "source": "https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-ibm-cloud-public"}, {"document_id": "ibmcld_16423-1704-3666", "score": 28.282321728292203, "text": "\nA goal to aim for is to eventually have at least 50 annotations for each entity type and 50 for each relation type in the document collection.\n* Again, documents should represent the breadth of the subject matter that the application will cover, but in the case of skewed frequency-of-occurrence of entity types and relation types, try to get at least 50 exemplars of each type, more for entity types that have mentions which tend to be phrases.\n* The set that you create for training must contain at least 10 annotated documents.\n\n\n\nWhen you are ready to create and train the model, documents that you add to the workspace can be divided into sets that are used as training data, test data, and blind data. The separate data sets are important for assessing model performance.\n\nYou can add documents in the following ways. For information about the supported document types, size limits, and other information, see [Creating a workspace > Summary of inputs, outputs, and limitations](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-create-projectwks_formats).\n\n\n\n* A two-column CSV file in UTF-8 format\n* Text files in UTF-8 format\n* HTML files\n* PDF files (scanned and password-protected files are not supported)\n* Microsoft Word DOC or DOCX files (password-protected files are not supported)\n* A ZIP file that contains documents downloaded from a Knowledge Studio workspace\n* A ZIP file that contains files in UIMA CAS XMI format\n\n\n\n\n\n CSV files \n\nYou can upload a two-column CSV file that contains sample text from your local machine. Upload one CSV file at a time. The first column in the CSV file specifies the file name of the document. The second column in the file contains the document text. For an example of the required format, see the [documents-new.csv](https://watson-developer-cloud.github.io/doc-tutorial-downloads/knowledge-studio/documents-new.csv) file in the tutorial sample files.\n\n\n\n\n\n PDF files", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05598-81555-83001", "score": 29.663561017083275, "text": "\nChange log for master fix pack 1.19.6_1531, released 6 January 2021 \n\nThe following table shows the changes that are in the master fix pack patch update 1.19.6_1531. Master patch updates are applied automatically.\n\n\n\nChanges since version 1.19.5_1529\n\n Component Previous Current Description \n\n IBM Calico extension 538 556 Updated image to include the ip command. \n IBM Cloud Controller Manager v1.19.5-1 v1.19.6-1 Updated to support the Kubernetes 1.19.6 release and to use Go version 1.15.5. \n IBM Cloud File Storage for Classic plug-in N/A N/A Updated to run with a privileged security context. \n IBM Cloud RBAC Operator c148a8a f859228 Updated image for [CVE-2020-1971](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-1971) and [CVE-2020-24659](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-24659). \n Kubernetes v1.19.5 v1.19.6 See the [Kubernetes release notes](https://github.com/kubernetes/kubernetes/releases/tag/v1.19.6). \n Kubernetes NodeLocal DNS cache N/A N/A Updated to run with a least privileged security context. \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.19.5_1530, released 21 December 2020 \n\nThe following table shows the changes that are in the worker node fix pack 1.19.5_1530. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.19.5_1529\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-changelog_119"}, {"document_id": "ibmcld_05528-36924-38197", "score": 28.0551888297439, "text": "\nThe following table shows the changes that are in the master fix pack patch update 1.17.16_1550. Master patch updates are applied automatically.\n\n\n\nChanges since version 1.17.15_1548\n\n Component Previous Current Description \n\n IBM Calico extension 544 556 Updated image to include the ip command. \n IBM Cloud Controller Manager v1.17.15-1 v1.17.16-1 Updated to support the Kubernetes 1.17.16 release. \n IBM Cloud File Storage for Classic plug-in N/A N/A Updated to run with a privileged security context. \n Kubernetes v1.17.15 v1.17.16 See the [Kubernetes release notes](https://github.com/kubernetes/kubernetes/releases/tag/v1.17.16). \n Operator Lifecycle Manager 0.14.1-IKS-1 0.14.1-IKS-2 Updated image for [CVE-2020-1971](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-1971) and [CVE-2020-28928](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-28928). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.17.15_1549, released 21 December 2020 \n\nThe following table shows the changes that are in the worker node fix pack 1.17.15_1549. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.17.15_1548\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-117_changelog"}, {"document_id": "ibmcld_05529-53002-54422", "score": 27.633685916186504, "text": "\nKey Management Service provider v2.0.7 v2.2.2 Updated the key management service (KMS) provider support as follows.<br><br><br><br> * Updated to use Go version 1.15.2.<br> * Added support for [service-to-service authentication](https://cloud.ibm.com/docs/account?topic=account-serviceauth).<br> * Updated to use the KMS provider secret to identify when a [Key Protect](https://cloud.ibm.com/docs/containers?topic=containers-encryptionkeyprotect) key is enabled and disabled so that encryption and decryption requests are updated accordingly.<br><br><br> \n Kubernetes v1.18.13 v1.18.14 See the [Kubernetes release notes](https://github.com/kubernetes/kubernetes/releases/tag/v1.18.14). \n Kubernetes NodeLocal DNS cache N/A N/A Updated to run with a least privileged security context. \n Operator Lifecycle Manager 0.14.1-IKS-1 0.14.1-IKS-2 Updated image for [CVE-2020-1971](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-1971) and [CVE-2020-28928](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2020-28928). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.18.13_1536, released 21 December 2020 \n\nThe following table shows the changes that are in the worker node fix pack 1.18.13_1536. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.18.13_1535\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-118_changelog"}, {"document_id": "ibmcld_10642-7855-9754", "score": 27.432928142632278, "text": "\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.\n\n\n\nFor more information, see [Update types](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.\n\nIn addition, you can create a Kubernetes config map that specifies the maximum number of worker nodes that can be unavailable at a time, such as during an update. Worker nodes are identified by the worker node labels. You can use IBM-provided labels or custom labels that you added to the worker node.\n\nThe Kubernetes config map rules are used for updating worker nodes only.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-update"}, {"document_id": "ibmcld_06209-8154-10055", "score": 27.386934620947873, "text": "\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the classic worker node to the same patch by using the ibmcloud ks worker update command.\n\n\n\nFor more information, see [Update types](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_10068-139713-141302", "score": 27.288850769575895, "text": "\nRed Hat OpenShift on IBM Cloud toolkit 4.3.0+20201110 4.3.0+20210111 See the [Red Hat OpenShift on IBM Cloud toolkit release notes](https://github.com/openshift/ibm-roks-toolkit/releases/tag/v4.3.0+20210111). \n\n\n\n\n\n\n\n Change log for worker node fix pack 4.3.40_1551_openshift, released 18 January 2021 \n\nThe following table shows the changes that are in the worker node fix pack 4.3.40_1551_openshift. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 4.3.40_1549_openshift\n\n Component Previous Current Description \n\n RHEL 7 Packages N/A N/A Updated worker node image with package updates. \n\n\n\n\n\n\n\n Change log for master fix pack 4.3.40_1550_openshift, released 6 January 2021 \n\nThe following table shows the changes that are in the master fix pack patch update 4.3.40_1550_openshift. Master patch updates are applied automatically.\n\n\n\nChanges since version 4.3.40_1548_openshift\n\n Component Previous Current Description \n\n IBM Calico extension 538 556 Updated image to include the ip command. \n IBM Cloud Block Storage driver and plug-in 1.17.2 v2.0.0 Updated to use the universal base image (UBI), to use Go version 1.15.5, to run with a least privileged security context, and to improve logging. Updated image to implement additional IBM security controls. \n IBM Cloud Controller Manager v1.17.15-1 v1.17.16-1 Updated to support the Kubernetes 1.17.16 release. \n IBM Cloud File Storage for Classic plug-in N/A N/A Updated to run with a privileged security context.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-changelog_archive"}, {"document_id": "ibmcld_05603-16362-17269", "score": 27.288032306084844, "text": "\nKubernetes v1.24.12 v1.24.13 See the [Kubernetes release notes](https://github.com/kubernetes/kubernetes/releases/tag/v1.24.13). \n Kubernetes Metrics Server configuration N/A N/A Updated to use TLS version 1.3 ciphers. \n Load balancer and load balancer monitor for IBM Cloud Provider 2420 2486 Updated Go to version 1.19.7 and updated dependencies. \n Portieris admission controller v0.13.3 v0.13.4 See the [Portieris admission controller release notes](https://github.com/IBM/portieris/releases/tag/v0.13.4). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.24.13_1566, released 24 April 2023 \n\nThe following table shows the changes that are in the worker node fix pack 1.24.13_1566. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.24.12_1564\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-changelog_124"}, {"document_id": "ibmcld_05604-16199-17100", "score": 27.288032306084844, "text": "\nKubernetes v1.25.8 v1.25.9 See the [Kubernetes release notes](https://github.com/kubernetes/kubernetes/releases/tag/v1.25.9). \n Kubernetes Metrics Server configuration N/A N/A Updated to use TLS version 1.3 ciphers. \n Load balancer and load balancer monitor for IBM Cloud Provider 2420 2486 Updated Go to version 1.19.7 and updated dependencies. \n Portieris admission controller v0.13.3 v0.13.4 See the [Portieris admission controller release notes](https://github.com/IBM/portieris/releases/tag/v0.13.4). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.25.9_1543, released 24 April 2023 \n\nThe following table shows the changes that are in the worker node fix pack 1.25.9_1543. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.25.8_1541\n\n Component Previous Current Description", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-changelog_125"}, {"document_id": "ibmcld_05599-29878-31331", "score": 27.230793648462225, "text": "\nChange log for worker node fix pack 1.20.13_1564, released 6 December 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.20.13_1564. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.20.12_1562\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages 4.15.0-162 4.15.0-163 Updated worker node images and kernel with package updates. Contains fixes for [CVE-2021-43527](https://nvd.nist.gov/vuln/detail/CVE-2021-43527) \n Kubernetes 1.20.12 1.20.13 See the [change log](https://github.com/kubernetes/kubernetes/releases/tag/v1.20.13) \n Containerd v1.4.11 v1.4.12 See the [change log](https://github.com/containerd/containerd/releases/tag/v1.4.12) and the [security bulletin](https://www.ibm.com/support/pages/node/6524974). \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.20.12_1562, released 22 November 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.20.12_1562. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.20.11_1560\n\n Component Previous Current Description \n\n Kubernetes 1.20.11 1.20.12 For more information, see the [change log](https://github.com/kubernetes/kubernetes/releases/tag/v1.20.12).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-changelog_120"}, {"document_id": "ibmcld_05600-47544-48981", "score": 27.230793648462225, "text": "\nChange log for worker node fix pack 1.21.7_1542, released 6 December 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.21.7_1542. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.21.6_1540\n\n Component Previous Current Description \n\n Ubuntu 18.04 packages 4.15.0-162 4.15.0-163 Updated worker node images and kernel with package updates. Contains fixes for [CVE-2021-43527](https://nvd.nist.gov/vuln/detail/CVE-2021-43527) \n Kubernetes 1.21.6 1.21.7 See the [change log](https://github.com/kubernetes/kubernetes/releases/tag/v1.21.7) \n Containerd v1.5.7 v1.5.8 See the [change log](https://github.com/containerd/containerd/releases/tag/v1.5.8) and the [security bulletin](https://www.ibm.com/support/pages/node/6524974) \n\n\n\n\n\n\n\n Change log for worker node fix pack 1.21.6_1540, released 22 November 2021 \n\nThe following table shows the changes that are in the worker node fix pack patch update 1.21.6_1540. Worker node patch updates can be applied by updating, reloading (in classic infrastructure), or replacing (in VPC infrastructure) the worker node.\n\n\n\nChanges since version 1.21.5_1538\n\n Component Previous Current Description \n\n Kubernetes 1.21.5 1.21.6 For more information, see the [change log](https://github.com/kubernetes/kubernetes/releases/tag/v1.21.6).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-changelog_121"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16384-1889-3334", "score": 25.676784631262738, "text": "\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_16377-7-1723", "score": 24.917893172483524, "text": "\nTutorial: Displaying a pre-chat or post-chat form \n\nThis tutorial shows how you can display pre-chat form before the web chat opens, or a post-chat form that opens after the web chat closes.\n\nFor a complete, working version of the example described in this tutorial, see [Pre and post-chat forms for Watson Assistant web chat](https://github.com/watson-developer-cloud/assistant-toolkit/tree/master/integrations/webchat/examples/pre-post-chat-forms).\n\nIf you want to gather information from your customers before starting a chat session, you can display a pre-chat form before opening the web chat. Similarly, you might want to display a form after the web chat closes (for example, a customer satisfaction survey). You can use the same approach for either situation.\n\nWhen the web chat is opened or closed, it fires an [event](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-events) that you can subscribe to. In your event handler, you can use the [custom panels](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-rendercustompanel) feature to open a panel with custom content.\n\nBy returning a promise that is resolved when the custom panel closes, you can pause the process of opening or closing the web chat until after the customer completes the form.\n\nThis example shows how to create a pre-chat form. To create a post-chat form, follow the same steps, but subscribe to the window:pre:close event instead of the window:open event.\n\nTo display a pre-chat form, follow these steps:\n\n\n\n1. Create a handler for the [window:open](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-eventswindowpreopen) event, which is fired when the web chat opens.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-pre-chat"}, {"document_id": "ibmcld_16365-7-1700", "score": 24.910883837199595, "text": "\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_16366-2985-3766", "score": 24.800297942253287, "text": "\nFor more information, see [Configuring the home screen](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen).\n\nSuggestions\n: You can configure how and when the web chat offers offers suggestions to customers when the assistant isn't delivering what they expect. For more information, see [Configuring suggestions](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-suggestions).\n\nSecurity\n: You can protect your users' private information and prevent unauthorized messages to your assistant by enabling security on the Security tab. For more information about web chat security and how it works, see [Security](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture-security).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config"}, {"document_id": "ibmcld_16384-7-2422", "score": 24.680118015160122, "text": "\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_16334-23017-24816", "score": 24.49982033902, "text": "\n* Support for Carbon components: As part of the new styling support, you can now use [Carbon components](https://www.carbondesignsystem.com/components/overview/) in user-defined responses and web chat writeable elements. These components will inherit any theming customizations you have made to the web chat.\n* New embedded script: The embedded script you use to add the web chat to your website has been updated to avoid unexpected code changes when you lock on to a web chat version. (For more information about web chat versioning, see [Versioning](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-basicsweb-chat-basics-versions).) The previous version of the script will continue to work but is now deprecated. If you want to upgrade your existing web chat deployments to use the new script, copy the updated code snippet from the Embed tab of the web chat integration settings. (Remember to reapply any customizations you have made.)\n* Removal of deprecated methods and events:\n\n\n\n* The error event has been replaced by the onError method in the [configuration object](https://web-chat.global.assistant.watson.cloud.ibm.com/testfest.html?to=api-configurationconfigurationobject).\n* The getID method has been removed.\n\n\n\n* Microsoft Internet Explorer 11 is no longer a supported browser.\n\n\n\n\n\n\n\n 4.5.1 \n\nRelease date: 30 August 2021\n\n\n\n* Bug fixes for the interactive launcher beta feature. (For more information about this feature, see the launcherBeta configuration option at [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).)\n\n\n\n\n\n\n\n 4.5.0 \n\nRelease date: 29 July 2021\n\n\n\n* A new scrollToMessage method is available for scrolling the web chat view to a specified message in the chat history.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-release-notes-chat"}, {"document_id": "ibmcld_16380-7-2028", "score": 24.421777336343606, "text": "\nTutorial: Customizing the size and position of the web chat \n\nThis tutorial shows how you can change the size and position of the web chat by rendering it in a custom element.\n\nFor a complete, working version of the example described in this tutorial, see [Custom elements for Watson Assistant web chat](https://github.com/watson-developer-cloud/assistant-toolkit/tree/master/integrations/webchat/examples/custom-element).\n\nBy default, the web chat interface on your website is rendered in a host div element that is styled to appear in a fixed location on the page. If you want to change the size or position of the web chat, you can specify a custom element as the host location for the web chat. This host element is used as the location for both the main web chat interface and for the web chat launcher (unless you are using a custom launcher).\n\nWhen you use a custom element, you also take control of showing and hiding the web chat when it is opened or closed (such as when the customer clicks the launcher icon or the minimize button). This gives you the opportunity to apply additional effects, such as opening and closing animations. You can control showing and hiding the main window by using the [addClassName() and removeClassName()](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodselements-get-main-window) functions.\n\nTo use a custom element, follow these steps:\n\n\n\n1. In your website code, define the custom element where you want the web chat to be rendered. There are many ways of doing this, depending on the framework you are using. A simple example is to define an empty HTML element with an ID:\n\n<div id=\"WebChatContainer\"></div>\n2. Get a reference to your custom element so you can reference it in the web chat configuration. To get a reference, use whatever mechanism makes sense for the library you are using. For example, you can save the reference returned from document.createElement(), or you can use a query function to look up the element in the DOM.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-size-position"}, {"document_id": "ibmcld_16368-6482-8187", "score": 23.812331408315295, "text": "\n[development icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/development-icon.png)Example: For a working example that shows how to add custom elements to the home screen, see [Home screen custom elements for Watson Assistant web chat](https://github.com/watson-developer-cloud/assistant-toolkit/tree/master/integrations/webchat/examples/home-screen-custom-element).\n* To change the home screen style, use [CSS helper classes](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-renderhelper_classes).\n\n\n\nCustomizing strings\n: You can customize the strings that define the various labels and hardcoded phrases displayed by the web chat. To customize strings, use the [updateLanguagePack()](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdatelanguagepack) instance method to replace strings in the current language pack. For more information, see [Languages](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslanguages).\n\nSupporting global audiences\n: By default, the strings displayed by the web chat are in English. To change to a different language, use the [updateLanguagePack()](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsupdatelanguagepack) instance method to replace the current language pack with one of the available translated language packs. For more information, see [Supporting global audiences](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-global).\n\n\n\n\n\n Opening, closing, and rendering the web chat window \n\nReplacing the default launcher", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_16381-0-734", "score": 23.761641172284932, "text": "\n\n\n\n\n\n\n  Web chat development tutorials \n\nThe tutorials in this section provide detailed examples, including code snippets, showing customizations that you can implement using the web chat API.\n\nEach tutorial includes links to a [GitHub repository](https://github.com/watson-developer-cloud/assistant-toolkit/tree/master/integrations/webchat/examples/) where you can download complete working code for the example. You can run this code to see the customization in action, adapt it for your own web chat implementation, or use it as a guide for similar customizations of your own.\n\nThe GitHub repository also includes additional tutorials and examples that have not yet been added to this documentation, so feel free to browse.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-tutorials"}, {"document_id": "ibmcld_16365-10062-12114", "score": 23.517258348519977, "text": "\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\" />\n\n\n\n\n\n Accessibility \n\nIBM strives to provide products with usable access for everyone, regardless of age or ability.\n\nThe web chat integration complies with the [Web Content Accessibility 2.1 Level AA](https://www.w3.org/WAI/standards-guidelines/wcag/new-in-21/) standard. It is tested with both screen readers and automated tools on a continual basis.\n\n\n\n\n\n Language support \n\nBy default, the web chat displays hardcoded labels and messages in English, but support is built in for all of the languages supported by Watson Assistant. You can also choose from a wide selection of locales to customize the display of strings like dates and times for global audiences.\n\nIn whichever language you are using, you can also customize the text of any hardcoded strings.\n\nFor more information, see [Supporting global audiences](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-global).\n\n\n\n\n\n Security \n\nBy default, all messages that are sent between the web chat and the assistant are encrypted using Transport Layer Security (TLS). You can enable the web chat security feature if you need more robust protection.\n\nThe web chat embed script that you include on your website contains unique identifiers (such as the integration ID and service instance ID) that enable the web chat to connect with your assistant. These identifiers are not considered secret, and are visible to anyone who has access to your website. Anyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05838-12220-14151", "score": 15.592437318739094, "text": "\nYou can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_cluster_update).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-health-monitor"}, {"document_id": "ibmcld_10189-3187-5240", "score": 15.517964883710203, "text": "\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud oc cluster master update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud oc versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-debug_master"}, {"document_id": "ibmcld_05754-3185-5238", "score": 15.517964883710203, "text": "\nYou cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field. \n update_cancelled The master update is canceled because the cluster was not in a healthy state at the time of the update. Your master remains in this state until your cluster is healthy and you manually update the master. To update the master, use the ibmcloud ks cluster master update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_cluster_update). If you don't want to update the master to the default major.minor version during the update, include the --version option and specify the latest patch version that is available for the major.minor version that you want, such as 1.26. To list available versions, run ibmcloud ks versions. \n update_failed The master update failed. IBM Support is notified and works to resolve the issue. You can continue to monitor the health of the master until the master reaches a normal state. If the master remains in this state for more than 1 day, [open an IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help). IBM Support might identify other issues in your cluster that you must fix before the master can be updated. \n\n\n\n\n\n\n\n Understanding the impact of a master outage", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-debug_master"}, {"document_id": "ibmcld_10290-70537-72315", "score": 15.418601977474903, "text": "\nibmcloud oc cluster master refresh \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nApply configuration changes for the Kubernetes master that are requested with the ibmcloud oc cluster master commands. The highly available Kubernetes master components are restarted in a rolling restart. Your worker nodes, apps, and resources are not modified and continue to run.\n\nThe apiserver-refresh and cluster-refresh aliases for this command are deprecated.\n\nibmcloud oc cluster master refresh --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n\n\n ibmcloud oc cluster master update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite\n\nUpdate the Kubernetes master and API server. During the update, you can't access or change the cluster. Worker nodes, apps, and resources that were deployed are not modified and continue to run.\n\nYou might need to change your YAML files for future deployments. Review this [release note](https://cloud.ibm.com/docs/containers?topic=containers-cs_versions) for details.\n\nThe cluster-update alias for this command is deprecated.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n--version MAJOR.MINOR.PATCH\n: Optional: The Kubernetes version of the cluster. If you don't specify a version, the Kubernetes master is updated to the default API version.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-cli"}, {"document_id": "ibmcld_10642-1365-3347", "score": 15.414150194569897, "text": "\nThen, [update the worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-updateworker_node) in your cluster.\n\nWorker nodes can run later patch versions than the master, such as patch versions that are specific to worker nodes for security updates.\n\nHow are patch updates applied?\n: By default, patch updates for the master are applied automatically over the course of several days, so a master patch version might show up as available before it is applied to your master. The update automation also skips clusters that are in an unhealthy state or have operations currently in progress. Occasionally, IBM might disable automatic updates for a specific master fix pack, such as a patch that is only needed if a master is updated from one minor version to another. In any of these cases, you can [check the versions change log](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions) for any potential impact and choose to safely use the ibmcloud oc cluster master update[command](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_cluster_update) yourself without waiting for the update automation to apply.\n\nUnlike the master, you must update your workers for each patch version.\n\nWhat happens during the master update?\n: Your master is highly available with three replica master pods. The master pods have a rolling update, during which only one pod is unavailable at a time. Two instances are up and running so that you can access and change the cluster during the update. Your worker nodes, apps, and resources continue to run.\n\nCan I roll back the update?\n: No, you can't roll back a cluster to a previous version after the update process takes place. Be sure to use a test cluster and follow the instructions to address potential issues before you update your production master.\n\nWhat process can I follow to update the master?\n: The following diagram shows the process that you can take to update your master.\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-update"}, {"document_id": "ibmcld_10189-1607-3670", "score": 15.34967433166968, "text": "\nThe status includes a timestamp of how long the master has been in the same state, such as Ready (1 month ago). The Master State reflects the lifecycle of possible operations that can be performed on the master, such as deploying, updating, and deleting. Each state is described in the following table.\n\n\n\nMaster states\n\n Master state Description \n\n deployed The master is successfully deployed. Check the status to verify that the master is Ready or to see if an update is available. \n deploying The master is currently deploying. Wait for the state to become deployed before working with your cluster, such as adding worker nodes. \n deploy_failed The master failed to deploy. IBM Support is notified and works to resolve the issue. Check the Master Status field for more information, or wait for the state to become deployed. \n deleting The master is currently deleting because you deleted the cluster. You can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-debug_master"}, {"document_id": "ibmcld_05754-1605-3668", "score": 15.34967433166968, "text": "\nThe status includes a timestamp of how long the master has been in the same state, such as Ready (1 month ago). The Master State reflects the lifecycle of possible operations that can be performed on the master, such as deploying, updating, and deleting. Each state is described in the following table.\n\n\n\nMaster states\n\n Master state Description \n\n deployed The master is successfully deployed. Check the status to verify that the master is Ready or to see if an update is available. \n deploying The master is currently deploying. Wait for the state to become deployed before working with your cluster, such as adding worker nodes. \n deploy_failed The master failed to deploy. IBM Support is notified and works to resolve the issue. Check the Master Status field for more information, or wait for the state to become deployed. \n deleting The master is currently deleting because you deleted the cluster. You can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-debug_master"}, {"document_id": "ibmcld_05891-71325-73333", "score": 15.317560344903413, "text": "\nExample cluster master public-service-endpoint disable command \n\nibmcloud ks cluster master public-service-endpoint disable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master public-service-endpoint enable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nEnable the [public cloud service endpoint](https://cloud.ibm.com/docs/containers?topic=containers-plan_basicsworkeruser-master) to make your cluster master publicly accessible.\n\nAfter you run this command, you must refresh the API server to use the service endpoint by following the prompt in the CLI.\n\nibmcloud ks cluster master public-service-endpoint enable --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n-y\n: Optional: Refresh the cluster master with no user prompts.\n\n\n\n Example cluster master public-service-endpoint enable command \n\nibmcloud ks cluster master public-service-endpoint enable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master refresh \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nApply configuration changes for the Kubernetes master that are requested with the ibmcloud ks cluster master commands. The highly available Kubernetes master components are restarted in a rolling restart. Your worker nodes, apps, and resources are not modified and continue to run.\n\nThe apiserver-refresh and cluster-refresh aliases for this command are deprecated.\n\nibmcloud ks cluster master refresh --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n\n\n ibmcloud ks cluster master update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli"}, {"document_id": "ibmcld_04489-72055-74063", "score": 15.317560344903413, "text": "\nExample cluster master public-service-endpoint disable command \n\nibmcloud ks cluster master public-service-endpoint disable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master public-service-endpoint enable \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nEnable the [public cloud service endpoint](https://cloud.ibm.com/docs/containers?topic=containers-plan_basicsworkeruser-master) to make your cluster master publicly accessible.\n\nAfter you run this command, you must refresh the API server to use the service endpoint by following the prompt in the CLI.\n\nibmcloud ks cluster master public-service-endpoint enable --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Administrator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n-y\n: Optional: Refresh the cluster master with no user prompts.\n\n\n\n Example cluster master public-service-endpoint enable command \n\nibmcloud ks cluster master public-service-endpoint enable --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster master refresh \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nApply configuration changes for the Kubernetes master that are requested with the ibmcloud ks cluster master commands. The highly available Kubernetes master components are restarted in a rolling restart. Your worker nodes, apps, and resources are not modified and continue to run.\n\nThe apiserver-refresh and cluster-refresh aliases for this command are deprecated.\n\nibmcloud ks cluster master refresh --cluster CLUSTER [-q]\n\nMinimum required permissions\n: Operator platform access role for the cluster in IBM Cloud Kubernetes Service\n\nCommand options:\n\n-c, --cluster CLUSTER\n: Required: The name or ID of the cluster.\n\n-q\n: Optional: Do not show the message of the day or update reminders.\n\n\n\n\n\n ibmcloud ks cluster master update \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nSatellite", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-kubernetes-service-cli"}, {"document_id": "ibmcld_10246-14143-16190", "score": 15.316619099488197, "text": "\nCheck the status to verify that the master is Ready or to see if an update is available. \n deploying The master is currently deploying. Wait for the state to become deployed before working with your cluster, such as adding worker nodes. \n deploy_failed The master failed to deploy. IBM Support is notified and works to resolve the issue. Check the Master Status field for more information, or wait for the state to become deployed. \n deleting The master is currently deleting because you deleted the cluster. You can't undo a deletion. After the cluster is deleted, you can no longer check the master state because the cluster is completely removed. \n delete_failed The master failed to delete. IBM Support is notified and works to resolve the issue. You can't resolve the issue by trying to delete the cluster again. Instead, check the Master Status field for more information, or wait for the cluster to delete. You can also [open an IBM Cloud support case](https://cloud.ibm.com/docs/containers?topic=containers-get-help). \n scaled_down The master resources have been scaled down to zero replicas. This is a temporary state that occurs while etcd is being restored after a backup. You cannot interact with your cluster while it is in this state. Wait for the etcd restoration to complete and the master state to return to deployed. \n updating The master is updating its Kubernetes version. The update might be a patch update that is automatically applied, or a minor or major version that you applied by updating the cluster. During the update, your highly available master can continue processing requests, and your app workloads and worker nodes continue to run. After the master update is complete, you can [update your worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node). If the update is unsuccessful, the master returns to a deployed state and continues running the previous version. IBM Support is notified and works to resolve the issue. You can check if the update failed in the Master Status field.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-health-monitor"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06926-3212-5298", "score": 18.05681128543217, "text": "\n* The customer VRF is a connectivity service that provides isolation among tenants. Any additional controls that are needed within a tenancy must be provisioned separately by using a gateway, security groups, or host-based controls.\n\n\n\n\n\n\n\n Benefits of moving to VRF \n\nMoving to VRF includes the following primary benefits:\n\n\n\n* Industry-proven and widely accepted multiple isolation separation technologies. Many cloud customers find the Level-3 VPN approach more palatable than ACLs to their auditors and compliance officers.\n* IBM Cloud customers can extend or migrate the reach of their network significantly, due to addition of new sites or applications throughout the IBM network.\n* Tenant-specific routing tables narrow the aperture for IP address overlap, without the risk of overlap with other tenants' subnets or other parts of the network that are not applicable.\n\n\n\nCompared to the older ACL model, there are a few minor tradeoffs to take into account:\n\n\n\n* Converting to a customer VRF requires a maintenance window, which causes a brief disruption of backbone traffic flows.\n* Remote access by using the managed VPN services (SSL, IPsec) is limited to just SSL VPN into a data center; however, the shared ACL over the backbone allows global access from any entry point from either service.\n* VLAN spanning is a feature of the shared tenancy model and is not available in a VRF; this will be disabled upon conversion to the Customer VRF.\n* IPsec VPN managed service on IBM Cloud classic infrastructure remote access is not available.\n\n\n\nMany IBM Cloud customers currently operate with a shared tenancy model on the IBM Cloud network. During conversion, your shared tenancy is converted to use a customer VRF, most commonly with a new Direct Link subscription.\n\nFor specific information about how to initiate a VRF conversion for your account, refer to the conversion instructions for your IBM Cloud offering. For example:\n\n\n\n* [Direct Link conversion instructions](https://cloud.ibm.com/docs/direct-link?topic=direct-link-what-happens-during-the-account-conversion-process)", "title": "", "source": "https://cloud.ibm.com/docs/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud"}, {"document_id": "ibmcld_03180-11118-12801", "score": 17.49995781929554, "text": "\nIf the customer is on the Returns page, you might want to route the chat transfer to agents who know how to help customers return merchandise.\n\nFor more information, see [Web chat: Accessing browser information](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-integrationsdialog-integrations-chat-browser-info).\n\n\n\n\n\n Routing by topic \n\nYou can specify a routing preference for specific topics of conversation in your dialog. When specified, the chat is transferred to the department that you designate. You can choose a department that you know has agents who are best able to address the topic.\n\nBefore you perform this procedure, determine which department you want users to be routed to.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific Zendesk department.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Zendesk from the Service desk routing field.\n4. In the Department field, add the department to which you want the assistant to transfer customers who want to discuss this topic. For example, sales.\n\nBe sure to specify the exact right syntax for the department name. The value is not validated by the service as you add it to your dialog.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-zendesk"}, {"document_id": "ibmcld_03162-10976-13038", "score": 17.450223202103015, "text": "\nThe routing rules identify the queue of agents to which messages from the assistant are transferred by default.\n\nThe code that you add to the setup page when you configure the service desk integration shares the following required information with Watson Assistant:\n\n\n\n* organization_id: Unique ID of the organization. A company can have more than one organization set up in Salesforce.\n* chat_api_endpoint: Salesforce API endpoint that is used by the integration to communicate with Salesforce.\n* deployment_id: Unique ID of the deployment. An organization can have multiple deployments.\n* button_id: Unique ID of a button, which defines the specific routing rules for incoming messages. Each deployment can have multiple buttons associated with it.\n\n\n\nTo override the default routing rules, you must specify a new value for the button_id. Before you perform this procedure, find out the ID of the Salesforce button implementation with the alternative routing rules that you want to use.\n\nTo add custom routing logic, complete the following steps:\n\n\n\n1. From the Dialog page, find the root dialog node for the branch of the conversation that you want to route to a specific group of Salesforce agents which is distinct from the default group.\n2. Find the dialog node in the branch where you want the transfer to take place, and then add the Connect to human agent response type as the dialog node response type.\n\nFor more information, see [Adding a Connect to human agent response type](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-connect-to-human-agent).\n3. After you add the response type and customize the transfer messages, select Salesforce from the Service desk routing field.\n4. In the Button ID field, add the button_id value for the alternate routing destination that you want the assistant to use for conversations about only this topic. For example, 5733i0000008yGz.\n\nBe sure to specify the exact right syntax for the button_id value. The value is not validated by the service as you add it to your dialog.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-salesforce"}, {"document_id": "ibmcld_16258-7-1952", "score": 17.01262931019381, "text": "\nReview customer conversations \n\nThe Conversations page of Watson Assistant provides a history of conversations between users and a deployed assistant. You can use this history to improve how your assistants understand and respond to user requests.\n\nEach timestamp represents a single conversation. The Actions column shows you how many actions, search queries, or unrecognized requests are included in that conversation. The Requests column includes the questions or requests the user entered that initiated an action, started a search query, or weren't recognized.\n\nIf you have activated dialog in your assistant, the Actions column is replaced by a Topics column.\n\n![Conversations page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations.png)\n\n\n\n Choosing the environment and time period \n\nTo get started, choose the [environment](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-publish-overviewenvironments) and date range you want to analyze. All conversations reflect data based on the environment and the date range you select. When you change the environnment or the date range, the conversations on the page update to reflect the new date range. You can also use Refresh ensure the latest data is shown.\n\n![Time period](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_16258-1324-3123", "score": 17.00333833722928, "text": "\n[Time period](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-time-period.png)\n\n\n\n\n\n Filtering conversations \n\nYou can locate specific conversations by filtering the list of conversations. This lets you explore specific areas where your assistant might need improvement or updates to properly handle what your customers are asking about.\n\nYou can filter by:\n\n\n\n* Actions: Select specific actions. You can choose one or more actions to review.\n* Keyword: Search by session ID or for specific key terms, phrases, or words in the conversations. For more information about session IDs, see [session_id](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-managing-planadmin-managing-plan-no-userid).\n* Recognition: Choose between recognized or unrecognized user questions or requests.\n* Search: Choose between requests that initiated a search or requests that produced no search results.\n\n\n\nThe Actions and Keyword filters always appear at the top of the page. To show the Recognition and Search filters, click the Additional filters icon.\n\nIf you have activated dialog in your assistant, the Actions filter is replaced by a Topics filter.\n\n![Conversation filters](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/analytics-conversations-filters.png)\n\nIf you search for a specific session ID, enclose your search in quotation marks to ensure you receive an exact match on the full ID with its numbers and hyphen characters, for example: \"9015ab9a-2e13-4627-ae33-4179b1125cb5\".\n\n\n\n\n\n Exploring conversations in detail \n\nTo explore individual conversations in detail, you can click on any of the utterances or conversation time stamps.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-analytics-conversations"}, {"document_id": "ibmcld_02844-1555-3643", "score": 16.938558627959857, "text": "\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-audit-events"}, {"document_id": "ibmcld_16338-2788-4628", "score": 16.747838690092607, "text": "\n* [Confidence scores](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-reviewreview-debug-confidence)\n* [Step locator](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-reviewreview-debug-step-locator)\n* [Follow along](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-reviewreview-debug-follow-along)\n\n\n\n\n\n Start and end of an action \n\nThe assistant marks the spots in the conversation when a customer enters an input that fits within an action. The assistant also marks when an action completes, and how it completes.\n\nCompletion options include ending:\n\n\n\n* With an end step\n* Without an end step\n* With a human agent escalation\n* With a search to a knowledge base\n\n\n\n\n\n\n\n Action confidence score \n\nEvery input that you enter that can start a new topic shows a confidence score icon. Hover over this icon to see a list of actions with different confidence scores.\n\nThese scores represent the assistant\u2019s confidence that the sentence or phrase that you entered can be solved by the steps that are built into a specific action.\n\nZoom\n\n![Debug mode](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/rn-debug-confidence.png)\n\nDebug mode\n\nThe top score in green represents the action with the highest confidence and the one the assistant used.\n\nThe remaining two are actions that were considered because of their confidence score, but weren't used because thee confidence scores were lower.\n\nIf no action scores higher than 20% confidence, you see the built-in action No action matches.\n\n\n\n\n\n Step locator \n\nSometimes you might find an error in the middle of a test conversation, and need to find which step and action is involved. A locator icon next to each assistant response lets you find the associated steps in the editor.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-review"}, {"document_id": "ibmcld_16338-4145-6019", "score": 15.825638471615918, "text": "\nThe remaining two are actions that were considered because of their confidence score, but weren't used because thee confidence scores were lower.\n\nIf no action scores higher than 20% confidence, you see the built-in action No action matches.\n\n\n\n\n\n Step locator \n\nSometimes you might find an error in the middle of a test conversation, and need to find which step and action is involved. A locator icon next to each assistant response lets you find the associated steps in the editor.\n\nClick the icon, and the editor shows the corresponding step in the background.\n\nZoom\n\n![Step locator](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/review-step-locator.png)\n\nStep locator\n\n\n\n\n\n Follow along \n\nFollow along connects what you are seeing in Preview with what you built in the action. As you interact with your assistant, the debug mode automatically opens each step in the background. That means you can fix an error as soon as you see it, because the editor is already open to the corresponding step.\n\n\n\n\n\n\n\n Variable values in Preview \n\nAs you test your conversation in Preview, you can check that each variable is set correctly. Click Variable values to see the values stored in each variable during the conversation. The Variable values pane has two tabs, one for action variables and one for session variables. If you are using dialog, you can see session variables for both actions and dialog on the Session variables tab.\n\nZoom\n\n![Variable values](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/variable-values-preview.png)\n\nVariable values\n\nTo learn more about variables, see [Managing information during the conversation](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-manage-info).\n\n\n\n\n\n Extension inspector in Preview", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-review"}, {"document_id": "ibmcld_06926-4859-5591", "score": 15.807672820226209, "text": "\nDuring conversion, your shared tenancy is converted to use a customer VRF, most commonly with a new Direct Link subscription.\n\nFor specific information about how to initiate a VRF conversion for your account, refer to the conversion instructions for your IBM Cloud offering. For example:\n\n\n\n* [Direct Link conversion instructions](https://cloud.ibm.com/docs/direct-link?topic=direct-link-what-happens-during-the-account-conversion-process)\n* [VPC conversion instructions](https://cloud.ibm.com/docs/vpc?topic=vpc-setting-up-access-to-classic-infrastructure&interface=uihow-you-can-initiate-the-conversion)\n* [IBM Cloud service endpoints conversion instructions](https://cloud.ibm.com/docs/account?topic=account-vrf-service-endpoint)", "title": "", "source": "https://cloud.ibm.com/docs/direct-link?topic=direct-link-overview-of-virtual-routing-and-forwarding-vrf-on-ibm-cloud"}, {"document_id": "ibmcld_10143-7-2020", "score": 15.749176662071427, "text": "\nWhy can't I view or work with my cluster? \n\nVirtual Private Cloud\n\nClassic infrastructure\n\n What\u2019s happening \n\nYou are not able to find a cluster. When you run ibmcloud oc cluster ls, the cluster is not listed in the output.\n\nOr, you are not able to work with a cluster. When you run ibmcloud oc cluster config or other cluster-specific commands, the cluster is not found.\n\n Why it\u2019s happening \n\nIn IBM Cloud, each resource must be in a resource group. For example, cluster mycluster might exist in the default resource group.\n\nWhen the account owner gives you access to resources by assigning you an IBM Cloud IAM platform access role, the access can be to a specific resource or to the resource group. When you are given access to a specific resource, you don't have access to the resource group. In this case, you don't need to target a resource group to work with the clusters you have access to. If you target a different resource group than the group that the cluster is in, actions against that cluster can fail. Conversely, when you are given access to a resource as part of your access to a resource group, you must target a resource group to work with a cluster in that group. If you don't target your CLI session to the resource group that the cluster is in, actions against that cluster can fail.\n\nIf you can't find or work with a cluster, you might be experiencing one of the following issues:\n\n\n\n* You have access to the cluster and the resource group that the cluster is in, but your CLI session is not targeted to the resource group that the cluster is in.\n* You have access to the cluster, but not as part of the resource group that the cluster is in. Your CLI session is targeted to this or another resource group.\n* You don't have access to the cluster.\n\n\n\n How to fix it \n\nTo check your user access permissions:\n\n\n\n1. List all your user permissions.\n\nibmcloud iam user-policies <your_user_name>\n2. Check if you have access to the cluster and to the resource group that the cluster is in.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_cluster_access"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02988-8862-10727", "score": 14.116097196402938, "text": "\nThe confidence property is a decimal percentage that represents your assistant's confidence in the recognized intent.\n\nWhile testing your dialog, you can see details of the intents that are recognized in user input by specifying this expression in a dialog node response:\n\n<? intents ?>\n\nFor the user input, Hello now, your assistant finds an exact match with the #greeting intent. Therefore, it lists the #greeting intent object details first. The response also includes the 10 other intents that are defined in the skill regardless of their confidence score. (In this example, its confidence in the other intents is set to 0 because the first intent is an exact match.) The top 10 intents are returned because the Try it out pane sends the alternate_intents:true parameter with its request. If you are using the API directly and want to see the top 10 results, be sure to specify this parameter in your call. If alternate_intents is false, which is the default value, only intents with a confidence above 0.2 are returned in the array.\n\n[!{\"intent\":\"greeting\",\"confidence\":1},\n{\"intent\":\"yes\",\"confidence\":0},\n{\"intent\":\"pizza-order\",\"confidence\":0}]\n\nThe following examples show how to check for an intent value:\n\n\n\n* intents[0] == 'Help'\n* intent == 'Help'\n\n\n\nintent == 'help' differs from intents[0] == 'help' because intent == 'help' does not throw an exception if no intent is detected. It is evaluated as true only if the intent confidence exceeds a threshold. If you want to, you can specify a custom confidence level for a condition, for example, intents.size() > 0 && intents[0] == 'help' && intents[0].confidence > 0.1\n\n\n\n\n\n Accessing input \n\nThe input JSON object contains one property only: the text property. The text property represents the text of the user input.\n\n\n\n Input property usage examples \n\nThe following example shows how to access input:", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-expression-language"}, {"document_id": "ibmcld_03310-10261-12004", "score": 14.088086686910913, "text": "\nThe response also includes the top 10 other intents that are defined in the skill regardless of their confidence score. (In this example, its confidence in the other intents is set to 0 because the first intent is an exact match.) The top 10 intents are returned because the \"Try it out\" pane sends the alternate_intents:true parameter with its request. If you are using the API directly and want to see the top 10 results, be sure to specify this parameter in your call. If alternate_intents is false, which is the default value, only intents with a confidence above 0.2 are returned in the array.\n\n[!{\"intent\":\"greeting\",\"confidence\":1},\n{\"intent\":\"yes\",\"confidence\":0},\n{\"intent\":\"pizza-order\",\"confidence\":0}]\n\nIf you want to include text in the response, use the toJson() method in the expression to cast the returned intents list into a JSON object. For example:\n\nRecognized intents are: <? intents.toJson() ?>\n\nThe following examples show how to check for an intent value:\n\n\n\n* intents[0] == 'Help'\n* intent == 'Help'\n\n\n\nintent == 'help' differs from intents[0] == 'help' because intent == 'help' does not throw an exception if no intent is detected. It is evaluated as true only if the intent confidence exceeds a threshold. If you want to, you can specify a custom confidence level for a condition, for example, intents.size() > 0 && intents[0] == 'help' && intents[0].confidence > 0.1\n\n\n\n\n\n Accessing input \n\nThe input JSON object contains one property only: the text property. The text property represents the text of the user input.\n\n\n\n Input property usage examples \n\nThe following example shows how to access input:\n\n\n\n* To execute a node if the user input is \"Yes\", add this expression to the node condition: input.text == 'Yes'", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-expression-language"}, {"document_id": "ibmcld_03145-1287-2166", "score": 14.070015876837022, "text": "\nIntents that are added from a content catalog are distinguishable from other intents by their names. Each intent name is prepended with the content catalog name.\n3. Add a content catalog to your dialog skill by clicking the Add to skill button.\n4. Go to the Intents page to see the intents that you added from the catalog listed.\n\n\n\nYour skill trains itself on the new data.\n\nAfter you add a catalog to your skill, the intents become part of your training data. If IBM makes subsequent updates to a content catalog, the changes are not automatically applied to any intents you added from a catalog.\n\n\n\n\n\n Editing content catalog intents \n\nLike any other intent, after you add content catalog intents to your skill, you can make the following changes to them:\n\n\n\n* Rename intents\n* Delete intents\n* Add, edit, or delete intent user examples\n* Move an example to a different intent", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-catalog"}, {"document_id": "ibmcld_03334-20892-22106", "score": 14.030639672237555, "text": "\nRepeat the previous steps to resolve other intents with conflicts.\n\n\n\n\n\n\n\n Deleting intents \n\nYou can select a number of intents for deletion.\n\nIMPORTANT: By deleting intents that you are also deleting all associated examples, and these items cannot be retrieved later. All dialog nodes that reference these intents must be updated manually to no longer reference the deleted content.\n\n\n\n1. Go to the Intents page\n\n\n\n* To delete all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Delete all intents icon. ![Delete option](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/delete-c10.png)\n* To delete the intents that are listed on the current page only, select the checkbox in the header. This action selects all of the intents that are listed on the current page. Click Delete.\n* To delete one or more specific intents, select the intents that you want to delete, and then click Delete.\n\n![Shows that an intent was selected and the delete icon is in focus](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/intent-delete.png)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}, {"document_id": "ibmcld_03010-16826-18510", "score": 13.968334622241205, "text": "\n[Shows an intent with a user example list where one of the user examples has a Resolve conflicts button](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/intent-resolve-conflicts.png)\n3. Choose whether to delete the example from the intent or to move it to another intent.\n\n![Shows the intent conflict details page](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/intent-fix-conflict.png)\n\nSimilar user examples are displayed for each intent. These examples are not necessarily in conflict. They are shown to give you a quick view of the other types of user examples that are defined for each intent. It provides you with context that can help you make a more informed decision.\n\nKeep each intent as distinct and focused on one goal as possible. If you have two intents with multiple user examples that overlap, maybe you don't need two separate intents. You can move or delete user examples that don't directly overlap into one intent, and then delete the other.\n4. To move a user example, click Move, and then click the intent where you want to move the example.\n\n![Shows the Move menu with a list of one intent options](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/intent-move-conflict.png)\n\nWhen deciding where to put an example, look for the intent that has synonymous, or nearly synonymous, examples.\n\nIf the exact same example is used by the other intent already, the move action only removes the example from the current intent. It does not add the same example to the other intent twice.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents"}, {"document_id": "ibmcld_03334-19597-21305", "score": 13.931950402140586, "text": "\nIt provides you with context that can help you make a more informed decision.\n\nKeep each intent as distinct and focused on one goal as possible. If you have two intents with multiple user examples that overlap, maybe you don't need two separate intents. You can move or delete user examples that don't directly overlap into one intent, and then delete the other.\n4. To move a user example, click Move, and then click the intent where you want to move the example.\n\n![Shows the Move menu with a list of one intent options](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/intent-move-conflict.png)\n\nWhen deciding where to put an example, look for the intent that has synonymous, or nearly synonymous, examples.\n\nIf the exact same example is used by the other intent already, the move action only removes the example from the current intent. It does not add the same example to the other intent twice.\n5. After moving or deleting the example, click Submit to resolve the conflict.\n\n![Shows a resolved conflict](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/intent-submit-conflict.png)\n\nThe Reset reverts your changes. Click the x to close the page without submitting your changes.\n6. Repeat the previous steps to resolve other intents with conflicts.\n\n\n\n\n\n\n\n Deleting intents \n\nYou can select a number of intents for deletion.\n\nIMPORTANT: By deleting intents that you are also deleting all associated examples, and these items cannot be retrieved later. All dialog nodes that reference these intents must be updated manually to no longer reference the deleted content.\n\n\n\n1. Go to the Intents page", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}, {"document_id": "ibmcld_03010-13387-14939", "score": 13.925218915584374, "text": "\n[Shows the results from a search for intents](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/intent-search-results.png)\n\n\n\n\n\n\n\n Exporting intents \n\nYou can export a number of intents to a CSV file, so you can then import and reuse them for another Watson Assistant application.\n\n\n\n1. Go to the Intents page.\n\n\n\n* To export all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Export all intents icon. ![Export option](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/export-c10.png)\n* To export the intents that are listed on the current page only, select the checkbox in the header. This action selects all of the intents on the current page. Click Export.\n* To export one or more specific intents, select the intents that you want to export, and then click Export.\n\n![Shows that two intents are selected and the export icon is in focus](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/intent-export.png)\n\n\n\n2. Specify the name and location in which to store the CSV file that is generated.\n\n\n\n\n\n\n\n Importing intents and examples \n\nIf you have a large number of intents and examples, you might find it easier to import them from a comma-separated value (CSV) file than to define them one by one. Be sure to remove any personal data from the user examples that you include in the file.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents"}, {"document_id": "ibmcld_03010-18014-19579", "score": 13.925218915584374, "text": "\n[Shows the Move menu with a list of one intent options](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/intent-move-conflict.png)\n\nWhen deciding where to put an example, look for the intent that has synonymous, or nearly synonymous, examples.\n\nIf the exact same example is used by the other intent already, the move action only removes the example from the current intent. It does not add the same example to the other intent twice.\n5. After moving or deleting the example, click Submit to resolve the conflict.\n\n![Shows a resolved conflict](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/intent-submit-conflict.png)\n\nThe Reset reverts your changes. Click the x to close the page without submitting your changes.\n6. Repeat the previous steps to resolve other intents with conflicts.\n\n\n\n\n\n\n\n Deleting intents \n\nYou can select a number of intents for deletion.\n\nIMPORTANT: By deleting intents that you are also deleting all associated examples, and these items cannot be retrieved later. All dialog nodes that reference these intents must be updated manually to no longer reference the deleted content.\n\n\n\n1. Go to the Intents page\n\n\n\n* To delete all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Delete all intents icon. ![Delete option](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/delete-c10.png)", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents"}, {"document_id": "ibmcld_03010-11212-12967", "score": 13.900219124405538, "text": "\nIf the top intent has a low confidence score (less than 0.2), the top intent is included in the intents array that is returned by the API, but any nodes that condition on the intent are not triggered. If you want to detect the case when no intents with good confidence scores were detected, use the irrelevant special condition in your dialog node. See [Special conditions](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-special-conditions) for more information.\n\nAs intent confidence scores change, your dialogs might need restructuring. For example, if a dialog node uses an intent in its condition, and the intent's confidence score starts to consistently drop below 0.2, the dialog node stops being processed. If the confidence score changes, the behavior of the dialog can also change.\n\n\n\n\n\n Intent limits \n\n\n\nLimit details\n\n Intents per skill Examples per skill \n\n 2,000 25,000 \n\n\n\n\n\n\n\n Editing intents \n\nYou can click any intent in the list to open it for editing. You can make the following changes:\n\n\n\n* Rename the intent.\n* Delete the intent.\n* Add, edit, or delete examples.\n* Move an example to a different intent.\n\n\n\nYou can tab from the intent name to each example.\n\n\n\n1. To move or delete an example, click the checkbox that is associated with it, and then click Move or Delete.\n\n![Screen capture showing how to move or delete an example](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/move_example.png)\n\n\n\n\n\n\n\n Searching intents \n\nThe search capability was introduced with the 1.5.0 release.\n\nUse the Search feature to find user examples, intent names, and descriptions.\n\n\n\n1. From the Intents page header, click the Search icon !", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents"}, {"document_id": "ibmcld_03334-18585-20063", "score": 13.895274596311355, "text": "\n[Shows an intent list with a conflict](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/intent-conflicts.png)\n2. Click an intent with a conflict to open it. Find the user example that is causing the conflict, and then click Resolve conflicts.\n\n![Shows an intent with a user example list where one of the user examples has a Resolve conflicts button](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/intent-resolve-conflicts.png)\n3. Choose whether to delete the example from the intent or to move it to another intent.\n\n![Shows the intent conflict details page](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/intent-fix-conflict.png)\n\nSimilar user examples are displayed for each intent. These examples are not necessarily in conflict. They are shown to give you a quick view of the other types of user examples that are defined for each intent. It provides you with context that can help you make a more informed decision.\n\nKeep each intent as distinct and focused on one goal as possible. If you have two intents with multiple user examples that overlap, maybe you don't need two separate intents. You can move or delete user examples that don't directly overlap into one intent, and then delete the other.\n4. To move a user example, click Move, and then click the intent where you want to move the example.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03729-1672-3956", "score": 44.8767045322216, "text": "\nServices For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged. \n Tiered In this pricing model, you get a volumed-based discount according to your actual usage. Tiered pricing is typically used for charge metrics that are expected to have high quantities per month, such as API calls. Services might offer simple, graduated, or block tier pricing plans. Services For API Connect, one of the tiered plans charges $10,000 for the first 25 million monthly API calls and $40.00 USD per 100,000 API calls per month thereafter. \n Reserved Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment. Services Db2 on Cloud has reserved plans. \n\n\n\n\n\n Understanding monthly and hourly tags \n\nOn the usage dashboard, your products and resources can be labeled with Monthly, Hourly, or a combination of both tags to signify how often charges are updated.\n\nThe Monthly tag signifies that resources within your account have a fixed cost. These charge show up immediately after purchase and are prorated in proportion to how many days are left in the month. Any recurring monthly fixed costs are then shown at the first of every month.\n\nThe Hourly tag signifies that resources within your account have variable costs. These resources are updated daily.\n\n\n\n\n\n Lite plans \n\nLite plans are structured as a free quota. You can work on your projects worry free, without the risk of generating an accidental bill. The quota might operate for a specific time period, for example a month, or on a one-off usage basis. The following list provides some examples of Lite plan quotas:\n\n\n\n* Maximum number of registered devices\n* Maximum number of application bindings", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_03729-4932-7001", "score": 44.17431637355307, "text": "\nFor example, consider a runtime that costs $0.07 per GB-hour in two 512-MB instances, running for 30 days (720 hours). These resources would cost $50.4 USD, with the following calculations:\n\n2 instances x 0.5 GB x 720 hours = 720 GB-hours.\n720 GB-hours x $0.07 per GB-hour = $50.4\n\n\n\n\n\n Charges for services \n\nMany services include monthly free allowances. Usage of services that aren't included as part of the free allowance is charged in one of the following ways:\n\nFixed charges\n: You select a plan and pay on a flat rate basis. For example, the Bare Metal Servers are charged at a flat-rate.\n\nMetered charges\n: You pay based on your runtime and service consumption. For example, with the Push service, any usage over the free monthly allowance is charged.\n\nReserved charges\n: As the account owner of a Pay As You Go account or a Subscription account, you can reserve a service instance, with a long-term commitment, for a discounted price. For example, you can reserve the standard large Db2 on Cloud offering for 12 months.\n: Some IBM Cloud services offer reserved plans. You can request a reserved plan from the IBM Cloud catalog by clicking the tile of the service. Then, select the service plan that best meets your needs. If a reserved plan is available, click Request, and follow the prompts to send your request. You receive an email that contains the price information of the reserved plan. An IBM Cloud sales representative also contacts you soon to complete the purchase.\n\nTiered charges\n: Similar to metered charges, you pay based on your runtime and service consumption. However, tiered charges add more pricing tiers, often offering discounted charges in tiers with larger consumption. Tiered pricing is offered in simple, graduated, or block.\n\n\n\n Simple tier \n\nIn the simple tier model, the unit price is determined by the tier that the quantity of your usage falls into. The total price is your quantity that is multiplied by the unit price in that tier, for example:\n\n\n\nTable 2. Simple tier pricing table\n\n Quantity of Items Unit Price for All Items", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_14546-4405-6573", "score": 42.956082957704474, "text": "\nThis value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS/GB storage policy. The number of IOPS/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 3. VMware Shared Solutions Reserved billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_VCPU Monthly The peak vCPU allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest vCPU reservation value that is selected by the customer over a one month period. \n MAX_RAM_GB Monthly The peak memory allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest memory reservation value that is selected by the customer over a one month period. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of one month. This value includes the outbound traffic through the virtual data center NSX edge to the public internet. \n\n\n\n\n\n\n\n Private network endpoint billing plan \n\nPrivate network endpoint usage incurs charges as part of the on-demand or reserved virtual data center plan. On the VMware Shared order page, select the About tab to view the pricing plan details.\n\n\n\nTable 4. Billing plan for private network endpoints\n\n Metric Frequency Description \n\n MAX_PRIVATE_NETWORK_ONE_G_COST Monthly Charge for private network endpoint at 1 GB uplink over a period of one month. \n MAX_PRIVATE_NETWORK_TEN_G_COST Monthly Charge for private network endpoint at 10 GB uplink over a period of one month. \n\n\n\n\n\n\n\n Licenses and fees for Veeam Availability Suite and Zerto \n\nVeeam\u00ae and Zerto usage incurs the following on-demand charges.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-shared_pricing"}, {"document_id": "ibmcld_03776-5228-7163", "score": 41.83061452348745, "text": "\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https://myibm.ibm.com/billing/).", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-overview"}, {"document_id": "ibmcld_14546-7-1993", "score": 38.99151383993007, "text": "\nVMware Shared pricing \n\nIBM Cloud\u00ae for VMware Solutions Shared offers two pricing plans for creating VMware\u00ae virtual data centers. Virtual data centers incur charges for the following virtual data center resource usages:\n\n\n\n* Storage allocations with tiered pricing based on storage performance\n* Virtual CPU (vCPU) usage\n* Virtual memory usage\n* Egress on public networking\n* Commercial operating system licenses used\n* Third-party VMware services\n\n\n\n\n\nTable 1. Pricing plans\n\n Plans Description \n\n VMware Shared On-demand <br><br> * The vCPU and RAM virtual data center are allocated based on the demand. Resources are not preallocated. If you have a large regional demand, delays in availability can occur.<br> <br> <br> <br> <br> * The limits that are established for the amount of vCPU and RAM are maximums.<br> * vCPU and RAM resource limits can be increased and decreased later as required.<br> * The price is calculated hourly and it is based on the resource usage in the virtual data center.<br> * The amount of storage that can be allocated and used in the virtual data center is unlimited. Charges are hourly based on GB of allocated storage.<br> * The amount of inbound and outbound public networking is unlimited. Public outbound bandwidth is charged per GB.<br> <br> <br> <br> <br><br><br> \n VMware Shared Reserved <br><br> * The vCPU and RAM virtual data center reservations are pre-allocated and their availability is guaranteed.<br> <br> <br> <br> <br> * vCPU and RAM resources can be increased and decreased later as required.<br> * The amount of storage that can be allocated and used in the virtual data center is unlimited. Charges are hourly based on GB of allocated storage.<br> * The amount of inbound and outbound public networking is unlimited. Public outbound bandwidth is charged per GB.<br> <br> <br> <br> <br><br><br> \n\n\n\n\n\n Price breakdown \n\n\n\n Usage \n\nMetering is for the full potential size of the resource for the time period that the resource is used.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-shared_pricing"}, {"document_id": "ibmcld_03776-3313-5682", "score": 37.9579911545682, "text": "\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-overview"}, {"document_id": "ibmcld_14546-2844-4906", "score": 37.81883245378616, "text": "\nFor example, a single zone reserved virtual data center is created with 100 vCPU and 800 GB RAM. Later in the month, the data center is reduced to 50 vCPU and 400 GB RAM. The monthly peak usage is 100 vCPU and 800 GB RAM.\n\n\n\n\n\n Hourly peak metric usage \n\nThe maximum value of the metric used over an hour. For example, if 100 vCPU is used for a minute of the hour with 0 vCPU used for the other 59 mins, the hourly peak metric usage is 100 vCPU.\n\n\n\n\n\n\n\n VMware Shared on-demand billing plan \n\nVMware Shared on-demand virtual data center resources are allocated as needed. Pricing is hourly based on the resource usage in the virtual data center. The following metrics are part of this plan.\n\nThe standard storage policy pricing is the same as the 4-IOPS/GB storage policy. The number of IOPS/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 2. VMware Shared Solutions On-demand billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_BASE_COST Monthly Virtual data center price, which includes the edge gateway with five IP addresses. \n TOTAL_VCPU_HOURS Hourly The peak vCPU usage over the period of an hour. \n TOTAL_RAM_GB_HOURS Hourly The peak memory usage over the period of an hour. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of an hour. This value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS/GB storage policy. The number of IOPS/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-shared_pricing"}, {"document_id": "ibmcld_07578-508107-510221", "score": 37.700315520545054, "text": "\nIf the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID. You are not charged for entities that do not call App Configuration during the month. If your pricing plan includes a free allotment of Active Entity IDs, then you are not charged until the allotment is exceeded.\n\nActive Entity ID cost can be difficult to predict so you need to closely monitor your historical activity. See [How to view usage metrics for App Configuration?](https://cloud.ibm.com/docs/faqsfaq-ac-metrics) Rely on your own domain knowledge, business metrics, and usage forecasts to predict Active Entity ID cost.\n\nThe API Call cost is based on the number of API calls sent or received by App Configuration during the month over all your entities combined. Check section - [What are the charges to use App Configuration?](https://cloud.ibm.com/docs/faqsfaq-ac-charges) to determine what constitutes an API call.\n\nIf your pricing plan includes a free allotment of API calls, then you are not charged until the allotment is exceeded. Closely monitor your historical activity and check out [How to view usage metrics for App Configuration?](https://cloud.ibm.com/docs/faqsfaq-ac-metrics) Rely on your own domain knowledge, business metrics, and usage forecasts to predict cost.\n* Can you give some example pricing scenarios?\n\n\n\n Pricing Scenario 1: Mobile App with Feature Flags \n\nAssume you have a mobile app and you want feature flags and targeted segments to roll out features incrementally to different sets of users. Your historical metrics show 200,000 users but only about 50% are active in a month.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-508049-510175", "score": 37.59008977867224, "text": "\nIf the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID. You are not charged for entities that do not call App Configuration during the month. If your pricing plan includes a free allotment of Active Entity IDs, then you are not charged until the allotment is exceeded.\n\nActive Entity ID cost can be difficult to predict so you need to closely monitor your historical activity. See [How to view usage metrics for App Configuration?](https://cloud.ibm.com/docs?tab=faqsfaq-ac-metrics) Rely on your own domain knowledge, business metrics, and usage forecasts to predict Active Entity ID cost.\n\nThe API Call cost is based on the number of API calls sent or received by App Configuration during the month over all your entities combined. Check section - [What are the charges to use App Configuration?](https://cloud.ibm.com/docs?tab=faqsfaq-ac-charges) to determine what constitutes an API call.\n\nIf your pricing plan includes a free allotment of API calls, then you are not charged until the allotment is exceeded. Closely monitor your historical activity and check out [How to view usage metrics for App Configuration?](https://cloud.ibm.com/docs?tab=faqsfaq-ac-metrics) Rely on your own domain knowledge, business metrics, and usage forecasts to predict cost.\n* Can you give some example pricing scenarios?\n\n\n\n Pricing Scenario 1: Mobile App with Feature Flags \n\nAssume you have a mobile app and you want feature flags and targeted segments to roll out features incrementally to different sets of users. Your historical metrics show 200,000 users but only about 50% are active in a month.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_00536-0-2049", "score": 37.42713133326561, "text": "\n\n\n\n\n\n\n  Pricing FAQ \n\nIBM Cloudant pricing is based on the provisioned throughput capacity that you set for your instance, and the amount of data storage you use.\n\nWith IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae, you can increase or decrease your provisioned throughput capacity as needed, and pay pro-rated hourly. The provisioned throughput capacity is a reserved number of reads per second, writes per second, and global queries per second allocated to an instance. The throughput capacity setting is the maximum usage level for a given second.\n\nFor more information, see [IBM Cloudant Pricing](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-pricing).\n\n\n\n  Can I change my capacity setting? \n\nYou can change your provisioned throughput capacity and see your current capacity settings in the IBM Cloudant Dashboard. Launch IBM Cloudant Dashboard > Account > Capacity to view and change your provisioned throughput capacity and see the hourly and approximate monthly costs. You can also use the IBM Cloud\u00ae pricing calculator to see estimates in other currencies.\n\n\n\n\n\n  How do I know I exceeded the capacity limit that I set? \n\nThe Lite plan includes 1 GB of storage. If you exceed the limit, IBM Cloudant blocks your account from writing new data until you delete enough data to be under the 1-GB limit, or upgrade to a higher plan.\n\nThe first 20 GB of storage comes free with the Standard plan. You can store as much data as you want. Any storage over the 20 GB limit costs $0.0014 per GB per hour, which is approximately $1 per GB per month.\n\n\n\n\n\n  Where can I see my usage data? \n\nYou can see your current and historical usage bills in the IBM Cloud Dashboard. Go to Manage > Billing and usage > Usage. Here you can see the total charges and usage for the month by service, plan, or instance. Only the hourly costs that are accrued for the current month and time are available. At the end of the month, you can see the average provisioned throughput capacity for each field: LOOKUPS_PER_MONTH, WRITES_PER_MONTH, and QUERIES_PER_MONTH.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-pricing"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01062-5121-6350", "score": 18.50821011031839, "text": "\nDb2 Warehouse on Cloud plans Asia/Pacific Europe North/Central America South America \n\n Flex Tokyo Frankfurt Dallas (us-south) *NA \n Washington D.C. (us-east) \n Flex Performance Tokyo Frankfurt Dallas (us-south) *NA \n Washington D.C. (us-east) \n Flex One Tokyo Frankfurt Dallas (us-south) *NA \n London Toronto \n Washington D.C. (us-east) \n\n\n\n*NA = Not available at this time\n\nFor information on deploying your Db2 Warehouse on Cloud service in a network-isolated environment on the IBM Cloud, open a [support case](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n Availability of plans in Amazon Web Services data centers \n\nThe current generation of plans on AWS is available in N. Virginia and Frankfurt, with additional data centers coming soon.\n\nThe previous generation of plans on AWS is available in N. Virginia, Oregon, Frankfurt, London, Tokyo, Seoul, Singapore, and Sydney.\n\nIf you wish to provision a service instance in an AWS region not listed above, contact your local sales representative or open a [support case](https://cloud.ibm.com/unifiedsupport/supportcenter). You can also open a support case for information on deploying your Db2 Warehouse on Cloud service in a network-isolated environment on AWS.", "title": "", "source": "https://cloud.ibm.com/docs/Db2whc?topic=Db2whc-about"}, {"document_id": "ibmcld_14981-3774-5205", "score": 17.893879924602924, "text": "\n[AWS connection static routes](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/vpc/images/vpn-aws-connection-static-routes.png)\n\nFigure 3: AWS connection static routes\n5. Go to AWS Route tables in the Virtual private cloud section and find the route table that is associated with the VPC where the VPN was attached. Click Edit routes and add the same route to the route table.\n\nZoom\n\n![AWS route table](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/vpc/images/vpn-aws-route-table.png)\n\nFigure 4: AWS route table\n6. Verify the connection status on the Site-to-Site Connection page.\n7. Verify that the AWS ACL and security group rules are adjusted to allow the traffic you need.\n\n\n\n\n\n\n\n Configuring the IBM policy-based VPN \n\nTo configure an IBM policy-based VPN for an AWS peer, follow these steps:\n\n\n\n1. Create a new connection for one of the AWS tunnel IPs. Use a single CIDR for both Local Subnets and Peer Subnets.\n\nBecause AWS requires PFS to be enabled in Phase 2, you must create a custom IPsec policy to replace the default policy for the VPN in your VPC. For more information, see [Creating a custom IPsec policy in VPN for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-ipsec-policy).\n2. After the status for the connection is Active, verify the traffic between your subnets.\n\n\n\n\n\n\n\n\n\n Connecting an IBM route-based VPN to an AWS peer", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-aws-config"}, {"document_id": "ibmcld_14981-4773-6475", "score": 17.890306258342363, "text": "\nBecause AWS requires PFS to be enabled in Phase 2, you must create a custom IPsec policy to replace the default policy for the VPN in your VPC. For more information, see [Creating a custom IPsec policy in VPN for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-ipsec-policy).\n2. After the status for the connection is Active, verify the traffic between your subnets.\n\n\n\n\n\n\n\n\n\n Connecting an IBM route-based VPN to an AWS peer \n\nYou must have one IBM VPN gateway and two AWS VPN connections (a total of four tunnels) for this setup.\n\nZoom\n\n![Connecting an IBM route-based VPN to an AWS peer](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/vpc/images/vpn-interop-aws-diagram.png)\n\nFigure 5: Connecting an IBM route-based VPN to an AWS peer\n\n\n\n Configuring AWS \n\nTo configure an AWS peer, follow these steps:\n\n\n\n1. Create two AWS Customer Gateways using each of the IBM route-based VPN members IP addresses.\n2. Create an AWS Virtual Private Gateway and attach it to the AWS VPC that must send traffic to the IBM VPC.\n3. Create the first AWS site-to-site connection.\n\n\n\n* Set the Virtual Private Gateway to the gateway you created in Step 2.\n* Set the Customer Gateway to the first customer gateway you created in Step 1.\n* Set Routing Option to Static.\n* Divide the IBM VPC subnet into two smaller subnets and add them to Static IP Prefixes. This way, the first connection is preferred over the second connection.\n* Enter a pre-shared key for both tunnel1 and tunnel2\n* For both AWS tunnels, choose Edit Tunnel X Options and select the security parameters you need. You can choose multiple values for each parameter if they are also supported by the IBM VPN.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-aws-config"}, {"document_id": "ibmcld_01085-1492-2949", "score": 17.846394604427317, "text": "\nSee [Creating an Interface Endpoint](https://docs.aws.amazon.com/vpc/latest/userguide/vpce-interface.htmlcreate-interface-endpoint). Ensure that TCP traffic is allowed through ports 50001, 443, and 8443 on the VPC, and set rules to allow traffic from the CIDR range associated with the VPC.\n\n\n\n\n\n Considerations and limitations \n\n\n\n* AWS PrivateLink currently supports only TCP traffic. Tools that rely on UDP traffic are not supported by PrivateLink. To load data, load directly from Amazon S3 into Db2 Warehouse on Cloud. See [Loading data from Amazon S3](https://cloud.ibm.com/docs/Db2whc?topic=Db2whc-load_s3).\n\nExtra charges might apply when you transfer data by using the public endpoint.\n* You must create the Endpoint Service for accessing Db2 Warehouse on Cloud in the same AWS region where the Db2 Warehouse on Cloud instance is deployed. To access your instance from other AWS regions, you can use VPC Peering. See [Example: Services Using AWS PrivateLink and VPC Peering](https://docs.aws.amazon.com/vpc/latest/userguide/vpc-peer-region-example.html).\n* For the current generation of plans on AWS, connectivity to the web UI is available only over the public network, even if you have enabled PrivateLink. This restriction is temporary, and will be removed in an upcoming update.\n\n\n\nFor more information about AWS PrivateLink, see [Interface VPC Endpoints (AWS PrivateLink)](https://docs.aws.amazon.com/vpc/latest/userguide/vpce-interface.html).", "title": "", "source": "https://cloud.ibm.com/docs/Db2whc?topic=Db2whc-connect_options_aws"}, {"document_id": "ibmcld_14981-7-1838", "score": 17.784179718588433, "text": "\nConnecting to an AWS peer \n\nYou can use IBM Cloud VPN for VPC to securely connect your VPC to an on-prem network through a VPN tunnel. This topic provides guidance about how to configure your AWS VPN gateway to connect to VPN for VPC.\n\nBecause AWS requires PFS to be enabled in Phase 2, you must create a custom IPsec policy to replace the default policy for the VPN in your VPC. See [Creating an IPsec policy](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-ipsec-policy) for more details.\n\nWhen the AWS VPN receives a connection request from VPN for VPC, AWS VPN uses IPsec Phase 1 parameters to establish a secure connection and authenticate the VPN for VPC gateway. Then, if the security policy permits the connection, the AWS VPN establishes the tunnel by using IPsec Phase 2 parameters and applies the IPsec security policy. Key management, authentication, and security services are negotiated dynamically through the IKE protocol.\n\nReview the [VPN gateway limitations](https://cloud.ibm.com/docs/vpc?topic=vpc-vpn-limitations) before you connect to your on-prem peer.\n\nTo support these functions, you must perform the following general configuration steps on the AWS VPN:\n\n\n\n* Define the Phase 1 parameters that the AWS VPN requires to authenticate the remote peer and establish a secure connection.\n* Define the Phase 2 parameters that the AWS VPN requires to create a VPN tunnel with VPN for VPC.\n\n\n\n\n\n Connecting an IBM policy-based VPN to an AWS peer \n\nYou can use a VPN for VPC policy-based VPN to connect to an AWS route-based VPN. However, policy-based VPNs require separate Security Associations (SAs) for each subnet, while route-based VPNs use a single SA for all encrypted traffic. Therefore, a connection between a policy-based VPN to a route-based VPN is limited to one SA associated with a single CIDR range.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-aws-config"}, {"document_id": "ibmcld_01085-7-2015", "score": 17.668889476131042, "text": "\nConnectivity options on Amazon Web Services \n\nIBM\u00ae Db2\u00ae Warehouse on Cloud offers secure connectivity options for your application connection requirements.\n\nFor application connections, do not use IP addresses to connect to the Db2 Warehouse on Cloud instance, as the IP addresses resolved from the hostname may change. Use hostnames to reference your connection properties where it is available.\n\n\n\n Connecting to Db2 Warehouse on Cloud with Amazon Web Services PrivateLink \n\n[Amazon Web Services (AWS) PrivateLink](https://aws.amazon.com/privatelink/) gives you the ability to securely and privately connect to a Db2 Warehouse on Cloud instance that is deployed on AWS from your own AWS VPCs, services, and applications. With AWS PrivateLink, traffic between Db2 Warehouse on Cloud and your AWS VPCs, services, and applications does not traverse the public internet.\n\nIf you'd like to use AWS PrivateLink with Db2 Warehouse on Cloud, complete the following steps:\n\n\n\n1. Create an AWS principal to access Db2 Warehouse on Cloud. The AWS principal can be AWS accounts, IAM users, or IAM roles.\n2. Open a support ticket with IBM Cloud to enable AWS PrivateLink, and provide the Amazon Resource Name (ARN) of the AWS principal that was created in the previous step. The principal is granted permission to access your Db2 Warehouse on Cloud instance.\n3. After the principal is granted permission, create an interface endpoint on your VPC to connect to the Db2 Warehouse on Cloud service. See [Creating an Interface Endpoint](https://docs.aws.amazon.com/vpc/latest/userguide/vpce-interface.htmlcreate-interface-endpoint). Ensure that TCP traffic is allowed through ports 50001, 443, and 8443 on the VPC, and set rules to allow traffic from the CIDR range associated with the VPC.\n\n\n\n\n\n Considerations and limitations \n\n\n\n* AWS PrivateLink currently supports only TCP traffic. Tools that rely on UDP traffic are not supported by PrivateLink. To load data, load directly from Amazon S3 into Db2 Warehouse on Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/Db2whc?topic=Db2whc-connect_options_aws"}, {"document_id": "ibmcld_14981-7429-8713", "score": 17.6531700650266, "text": "\nThe following screens show that the network 10.248.0.0/24 is routed on both connections.\n\nZoom\n\n![AWS connection static routes](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/vpc/images/vpn-aws-connection-static-routes-route-based-one.png)\n\nFigure 7: AWS connection static routes\n\nZoom\n\n![AWS connection static routes](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/vpc/images/vpn-aws-connection-static-routes-route-based-two.png)\n\nFigure 8: AWS connection static routes\n6. Go to AWS Route Tables under VIRTUAL PRIVATE CLOUD and find the route table that is associated with the VPC where the VPN is attached. Click Edit Routes and add the same route to the route table.\n\nZoom\n\n![AWS route table](https://cloud.ibm.com/docs-content/v1/content/f02b9c9adcbb7328d95a45e105cec371d50f15eb/vpc/images/vpn-aws-route-table-route-based.png)\n\nFigure 9: AWS route table\n7. Verify the connection status on the Site-to-Site Connection page.\n8. Verify that the AWS ACL and security group rules are adjusted to allow the traffic you need.\n\n\n\n\n\n\n\n Configuring the IBM route-based VPN \n\nTo configure an IBM route-based VPN for an AWS peer, follow these steps:\n\n\n\n1. Create four new connections, one for each AWS tunnel IP.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-aws-config"}, {"document_id": "ibmcld_11713-22535-23710", "score": 17.632633178051663, "text": "\nsat-aws-block-silver gp3 ext4 ebs.csi.aws.com N/A 1 GiB - 16 TiB SSD True WaitforFirstConsumer Delete [Link](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.htmlsolid-state-drives) \n sat-aws-block-bronze st1 ext4 ebs.csi.aws.com N/A 125 GiB - 16 TiB HDD True WaitforFirstConsumer Delete [Link](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.htmlhard-disk-drives) \n sat-aws-block-bronze-metro st1 ext4 ebs.csi.aws.com N/A 125 GiB - 16 TiB HDD True WaitforFirstConsumer Delete [Link](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.htmlhard-disk-drives) \n sat-aws-block-silver-metro gp3 ext4 ebs.csi.aws.com 1 GiB - 16 TiB SSD True WaitforFirstConsumer Delete [Link](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.htmlsolid-state-drives) \n sat-aws-block-gold-metro io2 ext4 ebs.csi.aws.com 10 10 GiB - 6.25 TiB SSD True WaitforFirstConsumer Delete [Link](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.htmlsolid-state-drives) \n\n\n\n\n\n\n\n Getting help and support for AWS EBS \n\nWhen you use AWS EBS Storage, try the following resources before you open a support case.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-config-storage-ebs"}, {"document_id": "ibmcld_11895-22567-23742", "score": 17.632633178051663, "text": "\nsat-aws-block-silver gp3 ext4 ebs.csi.aws.com N/A 1 GiB - 16 TiB SSD True WaitforFirstConsumer Delete [Link](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.htmlsolid-state-drives) \n sat-aws-block-bronze st1 ext4 ebs.csi.aws.com N/A 125 GiB - 16 TiB HDD True WaitforFirstConsumer Delete [Link](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.htmlhard-disk-drives) \n sat-aws-block-bronze-metro st1 ext4 ebs.csi.aws.com N/A 125 GiB - 16 TiB HDD True WaitforFirstConsumer Delete [Link](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.htmlhard-disk-drives) \n sat-aws-block-silver-metro gp3 ext4 ebs.csi.aws.com 1 GiB - 16 TiB SSD True WaitforFirstConsumer Delete [Link](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.htmlsolid-state-drives) \n sat-aws-block-gold-metro io2 ext4 ebs.csi.aws.com 10 10 GiB - 6.25 TiB SSD True WaitforFirstConsumer Delete [Link](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.htmlsolid-state-drives) \n\n\n\n\n\n\n\n Getting help and support for AWS EBS \n\nWhen you use AWS EBS Storage, try the following resources before you open a support case.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-storage-aws-ebs-csi-driver"}, {"document_id": "ibmcld_11713-23359-24707", "score": 17.449865451367845, "text": "\nsat-aws-block-gold-metro io2 ext4 ebs.csi.aws.com 10 10 GiB - 6.25 TiB SSD True WaitforFirstConsumer Delete [Link](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-volume-types.htmlsolid-state-drives) \n\n\n\n\n\n\n\n Getting help and support for AWS EBS \n\nWhen you use AWS EBS Storage, try the following resources before you open a support case.\n\n\n\n1. Review the FAQs in the [AWS Knowledge Center](https://repost.aws/knowledge-center).\n2. Review the [troubleshooting documentation](https://cloud.ibm.com/docs/satellite?topic=satellite-storage-must-gather) to troubleshoot and resolve common issues.\n3. Check the status of the IBM Cloud platform and resources by going to the [Status page](https://cloud.ibm.com/status).\n4. Review [Stack Overflow](https://stackoverflow.com/questions/tagged/ibm-cloud) to see whether other users experienced the same problem. Tag any questions with ibm-cloud and AWS-EBS.\n5. The [AWS Support Center](https://signin.aws.amazon.com/signin?redirect_uri=https%3A%2F%2Fconsole.aws.amazon.com%2Fsupport%2Fhome%3Fstate%3DhashArgs%2523%252F%26isauthcode%3Dtrue&client_id=arn%3Aaws%3Aiam%3A%3A015428540659%3Auser%2Fsupportcenter&forceMobileApp=0&code_challenge=u3nT-WHT9gSG_PS93w4dwD6R_PWLj1eOU9GLUMEOkzo&code_challenge_method=SHA-256) is another resource available to AWS customers looking for more in-depth support options.", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-config-storage-ebs"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06341-2428-3641", "score": 42.49891908439999, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"}, {"document_id": "ibmcld_06499-2416-3629", "score": 42.49891908439999, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"}, {"document_id": "ibmcld_06443-2410-3623", "score": 42.49891908439999, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-etcd?topic=databases-for-etcd-deprovisioning"}, {"document_id": "ibmcld_06627-2422-3635", "score": 42.49891908439999, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"}, {"document_id": "ibmcld_06696-2412-3625", "score": 42.49891908439999, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-redis?topic=databases-for-redis-deprovisioning"}, {"document_id": "ibmcld_09551-2545-3629", "score": 41.205090855564634, "text": "\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"}, {"document_id": "ibmcld_06381-2433-3517", "score": 41.205090855564634, "text": "\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"}, {"document_id": "ibmcld_06564-2541-3625", "score": 41.205090855564634, "text": "\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-mysql?topic=databases-for-mysql-deprovisioning"}, {"document_id": "ibmcld_06381-1376-2975", "score": 40.5628616402165, "text": "\nDeleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https://dev.mysql.com/doc/refman/5.7/en/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https://dev.mysql.com/doc/refman/5.7/en/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"}, {"document_id": "ibmcld_09551-1435-3087", "score": 40.31369258579959, "text": "\nList of service instances on the Resource List\n\n\n\n\n\n Deleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https://dev.mysql.com/doc/refman/5.7/en/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https://dev.mysql.com/doc/refman/5.7/en/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00620-14227-15704", "score": 32.44179270718291, "text": "\nThe previous Go example requires the following import block: import (\n\"encoding/json\"\n\"fmt\"\n\"github.com/IBM/cloudant-go-sdk/cloudantv1\"\n\"github.com/IBM/go-sdk-core/core\"\nAll Go examples require the service object to be initialized. For more information, see the API documentation's Authentication section]] ! ! ! ! for examples.This option works, but you end up fetching n+1 documents when only n are required.<-- </section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --><-- <section \"id=\"section-option-2-the-u0000-trick\" \"> --> Option 2 - The \\u0000 trick If you're determined to fetch only n documents each time, then you need to calculate a value of startkey, which means the next ID after the last _id in the result set. For example, if the last document in the first page of results is \"example\", what must the startkey of the next call to _all_docs be? It can't be \"example\", otherwise you get the same document ID again. It turns out that you can append u0000 to the end of a key string to indicate the \"next key\" (u0000 is a Unicode null character, which can be placed in a URL as-is or with the percent code %00). ).See the following example of a first request:<-- <ul> --> * Curl * Java * Node * Python * Go<-- </ul> --> curl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL/orders/_all_docs?limit=5\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.DocsResultRow;", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-pagination-and-bookmarks"}, {"document_id": "ibmcld_00462-1307-2903", "score": 31.542515188288654, "text": "\nThe IBM Cloudant SDK for Python library is the official IBM Cloudant library for Python.\n\nInstall the [IBM Cloudant SDK for Python](https://pypi.org/project/ibmcloudant/) library by running pip or easy_install as shown in the following examples:\n\npip install --upgrade \"ibmcloudant>=0.0.27\"\n\nor\n\neasy_install --upgrade \"ibmcloudant>=0.0.27\"\n\nFor more information, see the [python.org](https://www.python.org/about/) website.\n\n\n\n Library for Python \n\n\n\n* [IBM Cloudant SDK for Python](https://github.com/IBM/cloudant-python-sdk)\n\n\n\n\n\n\n\n\n\n Go \n\nThe IBM Cloudant SDK for Go library is the official IBM Cloudant library for Go.\n\nInstall the [IBM Cloudant SDK for Go](https://pkg.go.dev/mod/github.com/IBM/cloudant-go-sdk) library by running the following command:\n\ngo get -u github.com/IBM/cloudant-go-sdk/cloudantv1\n\n\n\n Library for Go \n\n\n\n* [IBM Cloudant SDK for Go](https://github.com/ibm/cloudant-go-sdk)\n\n\n\n\n\n\n\n\n\n Useful tools \n\nYou can use the following tools with IBM Cloudant.\n\n\n\n Supported tools \n\nSupported tools are maintained and supported by IBM Cloudant.\n\n\n\n couchbackup \n\nA tool that you use from the command line to back up an IBM Cloudant or CouchDB database to a text file.\n\nTo install couchbackup, run the following command by using npm:\n\nnpm install -g @cloudant/couchbackup\n\nFor more information, see [couchbackup](https://github.com/cloudant/couchbackup).\n\n\n\n\n\n\n\n Unsupported tools \n\nUnsupported tools are not maintained or supported by IBM Cloudant.\n\n\n\n cURL \n\nA tool that you use from the command line to transfer data.\n\nFor more information, see [curl](https://curl.haxx.se/).", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-client-libraries"}, {"document_id": "ibmcld_00589-18424-20018", "score": 29.666432238693275, "text": "\n* [cloudant-java-sdk](https://github.com/IBM/cloudant-java-sdk/releases)\n\n\n\nFor an example that uses IBM Cloudant SDK for Java, see the [API and SDK documentation](https://cloud.ibm.com/apidocs/cloudant?code=javaauthentication).\n\n\n\n\n\n Node.js \n\nThe following link provides the latest supported version of the IBM Cloudant Node.js library:\n\n\n\n* [cloudant-node-sdk](https://github.com/IBM/cloudant-node-sdk/releases)\n\n\n\nFor an example that uses IBM Cloudant SDK for Node, see the [API and SDK documentation](https://cloud.ibm.com/apidocs/cloudant?code=nodeauthentication).\n\n\n\n\n\n Python \n\nThe following link provides the latest supported version of the IBM Cloudant Python library:\n\n\n\n* [cloudant-python-sdk](https://github.com/IBM/cloudant-python-sdk/releases)\n\n\n\nFor an example that uses IBM Cloudant SDK for Python, see the [API and SDK documentation](https://cloud.ibm.com/apidocs/cloudant?code=pythonauthentication).\n\n\n\n\n\n Go \n\nThe following link provides the latest supported version of the IBM Cloudant Go library:\n\n\n\n* [go-sdk](https://github.com/IBM/cloudant-go-sdk/releases)\n\n\n\nFor an example that uses IBM Cloudant SDK for Go, see the [API and SDK documentation](https://cloud.ibm.com/apidocs/cloudant?code=goauthentication).\n\n\n\n\n\n\n\n Access by using HTTP client \n\nIBM Cloud IAM requires that an IAM API key is exchanged for a time-limited access token before you make a request to a resource or service. The access token is then included in the Authorization HTTP header to the service. When the access token expires, the client must handle getting a new one from the IAM token service.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudant"}, {"document_id": "ibmcld_00462-7-1647", "score": 28.78106536582625, "text": "\nClient libraries \n\nClient libraries are the tools that you use to develop your own applications to work with IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae databases.\n\nThe following client libraries are formally supported by IBM Cloudant: Java\u2122, Node.js, Python, and Go.\n\nA supported library is one where you can contact IBM Cloudant if you come across a specific, reproducible problem in the current version of the library.\n\n\n\n Java \n\nThe IBM Cloudant SDK for Java\u2122 is the official IBM Cloudant library for Java\u2122.\n\nTo install the IBM Cloudant SDK for the Java\u2122 library, see [Installation](https://github.com/ibm/cloudant-java-sdkinstallation) about installing the library by adding it as a dependency to your Maven or Gradle builds. You can also see details and examples of how to use the library in the guide.\n\n\n\n Library for Java \n\n\n\n* [IBM Cloudant SDK for Java\u2122](https://github.com/ibm/cloudant-java-sdk)\n\n\n\n\n\n\n\n\n\n Node.js \n\nThe IBM Cloudant SDK for the Node.js library is the official IBM Cloudant library for Node.js.\n\nInstall the [IBM Cloudant SDK for Node.js](https://www.npmjs.com/package/@ibm-cloud/cloudant) library by running the following command:\n\nnpm install @ibm-cloud/cloudant\n\n\n\n Library for Node.js \n\n\n\n* [IBM Cloudant SDK for Node.js](https://github.com/ibm/cloudant-node-sdk)\n\n\n\n\n\n\n\n\n\n Python \n\nThe IBM Cloudant SDK for Python library is the official IBM Cloudant library for Python.\n\nInstall the [IBM Cloudant SDK for Python](https://pypi.org/project/ibmcloudant/) library by running pip or easy_install as shown in the following examples:\n\npip install --upgrade \"ibmcloudant>=0.0.27\"\n\nor\n\neasy_install --upgrade \"ibmcloudant>=0.0.27\"", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-client-libraries"}, {"document_id": "ibmcld_00510-7-1689", "score": 27.6454742302767, "text": "\nData modeling \n\nThe Data modeling document is the first best practice document in the series. It shows you the following best practices:\n\n\n\n* What you need to know about your APIs.\n* How to model your data.\n* What size documents you must use.\n* What to avoid.\n* How to configure your databases.\n\n\n\nFor more information, see [Indexing and querying](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-indexing-and-querying) or [IBM Cloudant in practice](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-cloudant-in-practice).\n\nThe content in this document was originally written by Stefan Kruger as a [Best and worst practice](https://blog.cloudant.com/2019/11/21/Best-and-Worst-Practices.html) blog post on 21 November 2019.\n\n\n\n Understand the API that you are targeting \n\nYou can use [Java\u2122](https://github.com/IBM/cloudant-java-sdk), [Python](https://github.com/IBM/cloudant-python-sdk), [Go](https://github.com/IBM/cloudant-go-sdk), or [Node.js](https://github.com/IBM/cloudant-node-sdk) or some other use-case-specific language or platform. One of these languages most likely comes with convenient client-side libraries that integrate IBM Cloudant access nicely, following the conventions that you expect for your tools. These languages are great for programmer efficiency, but they also hide the API from view.\n\nThis abstraction is what you want, the whole reason for using a client library is to save yourself repeated, tedious boiler-plating. However, you must understand the underlying API is vital when you troubleshoot and report problems. When you report a suspected problem to IBM Cloudant, it helps us help you if you can provide a way for us to reproduce the problem.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-data-modeling"}, {"document_id": "ibmcld_00620-8515-9974", "score": 27.47734832485351, "text": "\npanic(err)\n}\nb, _ := json.MarshalIndent(allDocsResult3, \"\", \" \")\nfmt.Println(string(b))\nThe previous Go example requires the following import block: import (\n\"encoding/json\"\n\"fmt\"\n\"github.com/IBM/cloudant-go-sdk/cloudantv1\"\n\"github.com/IBM/go-sdk-core/core\"\n)\nAll Go examples require the service object to be initialized. For more information, see the API documentation's Authentication section]] ! ! ! ! ! for examples.This practice means you define the size of the data set and the range of the _id field to return, but that isn't quite the same as pagination.The startkey/endkey values are in double quotation marks because they're expected to be JSON-encoded and JSON.stringify('order00077') === \"order00077\".<-- </section \"id=\"section-the-limit-startkey-endkey-parameters\" \"> --><-- <section \"id=\"section-pagination-options\" \"> --> Pagination options For performance reasons, if you are displaying large amounts of data, you must consider using pagination. In these examples, documents are fetched in blocks of five. However, in a real application, the page size might be different and depends on document size, latency demands, memory consumption, and other tradeoffs.You can use the options that are described in the following sections.<-- <section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --> Option 1 - Fetch one document too many Instead of fetching five documents (limit=5), fetch 5+1 (limit=6), but hide the sixth document from your users.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-pagination-and-bookmarks"}, {"document_id": "ibmcld_00512-21543-22914", "score": 27.382625492980765, "text": "\npostPartitionAllDocsOptions := service.NewPostPartitionAllDocsOptions(\n\"readings\",\n\"bridge-9876\",\n)\npostPartitionAllDocsOptions.SetIncludeDocs(true)\n\nallDocsResult, response, err := service.PostPartitionAllDocs(postPartitionAllDocsOptions)\nif err != nil {\npanic(err)\n}\n\nb, _ := json.MarshalIndent(allDocsResult, \"\", \" \")\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding/json\"\n\"fmt\"\n\"github.com/IBM/cloudant-go-sdk/cloudantv1\"\n)\n\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https://cloud.ibm.com/apidocs/cloudant?code=goauthentication-with-external-configuration) for examples.\n\n\n\n\n\n Finding recent readings for a piece of infrastructure \n\nThis query needs to use [the partitioned timestamped-readings index](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-database-partitioningcreating-a-paritioned-ibm-cloudant-query-index). You can issue a query to the partition to get the readings for today, assuming today is 13 December 2018.\n\nThe partition is embedded in the HTTP path when you issue the request to IBM Cloudant:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X POST \"$SERVICE_URL/readings/_partition/bridge-9876/_find\" -H 'Content-Type:\napplication/json' --data '{\n\"selector\": {\n\"ts\": { \"$gte\": \"20181213\"}\n}\n}'", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-database-partitioning"}, {"document_id": "ibmcld_00512-19432-20915", "score": 27.199637377312467, "text": "\nfmt.Println(string(b))\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding/json\"\n\"fmt\"\n\"github.com/IBM/cloudant-go-sdk/cloudantv1\"\n\"github.com/IBM/go-sdk-core/v5/core\"\n)\n\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https://cloud.ibm.com/apidocs/cloudant?code=goauthentication-with-external-configuration) for examples.\n\n\n\n\n\n\n\n\n\n Making queries \n\nOverall, you want to make four queries:\n\n\n\n1. Readings for all time for a piece of infrastructure.\n2. Readings for today for a piece of infrastructure.\n3. Readings for all time for a specific device.\n4. Readings for today for a specific device.\n\n\n\n\n\n Finding all readings for a piece of infrastructure \n\nThese partitions are infrastructure-based, so you can use _all_docs for a partition. For example, query all readings for the bridge-9876 infrastructure piece by using the following command.\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl -X POST \"$SERVICE_URL/readings/_partition/bridge-9876/_all_docs\" -H 'Content-Type:\napplication/json' --data '{\"include_docs\": true}'\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.PostPartitionAllDocsOptions;\nCloudant service = Cloudant.newInstance();\n\nPostPartitionAllDocsOptions allDocsOptions =\nnew PostPartitionAllDocsOptions.Builder()\n.db(\"readings\")\n.partitionKey(\"bridge-9876\")", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-database-partitioning"}, {"document_id": "ibmcld_00620-9537-11012", "score": 26.954610414940255, "text": "\nHowever, in a real application, the page size might be different and depends on document size, latency demands, memory consumption, and other tradeoffs.You can use the options that are described in the following sections.<-- <section \"id=\"section-option-1-fetch-one-doc-too-many\" \"> --> Option 1 - Fetch one document too many Instead of fetching five documents (limit=5), fetch 5+1 (limit=6), but hide the sixth document from your users. The _id of the sixth document becomes the startkey of your request for the next page of results.See the following example of a first request:<-- <ul> --> * Curl * Java * Node * Python * Go<-- </ul> --> curl -H \"Authorization: Bearer $API_BEARER_TOKEN\" \"$SERVICE_URL/orders/_all_docs?limit=6\"\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsResult;\nimport com.ibm.cloud.cloudant.v1.model.DocsResultRow;\nimport com.ibm.cloud.cloudant.v1.model.PostAllDocsOptions;\n\nCloudant service = Cloudant.newInstance();\n\nint pageSize = 5;\nPostAllDocsOptions.Builder docsOptionsBuilder =\nnew PostAllDocsOptions.Builder()\n.db(\"orders\")\n.limit(pageSize + 1); // Fetch pageSize + 1 documents\n\nAllDocsResult response =\nservice.postAllDocs(docsOptionsBuilder.build())\n.execute()\n.getResult();\n\nwhile (response.getRows().size() > 1) {\nList<DocsResultRow> responseDocuments = response.getRows();\n// on the last page, show all documents:\nif (responseDocuments.size() <= pageSize) {\nSystem.out.println(responseDocuments);", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-pagination-and-bookmarks"}, {"document_id": "ibmcld_10841-22000-23598", "score": 26.923593853613113, "text": "\n[CHANGELOG.md](https://github.com/ibm-functions/runtime-python/blob/master/python3.7/CHANGELOG.md). \n 3.6 Python 3.6 reached end of support on 2021/12/23. <br>See [end of life Python Releases](https://endoflife.date/python). \n 2.7 Python 2.7 reached end of support on 2020/01/01. <br>See [the Active Python Releases](https://www.python.org/downloads/). \n\n\n\n\n\n Migrating from Python 3.7 to Python 3.9, Python 3.11 \n\n\n\nTable 2. Migrating details from Python 3.7 to Python 3.9\n\n Package Details \n\n ibmcloudant The cloudant sdk has moved to the new ibmcloudant sdk. It includes a number of breaking changes. See [migration guide](https://github.com/cloudant/python-cloudant/blob/master/MIGRATION.md) for more information. \n ibm-watson The watson-developer-cloud sdk has renamed to the new ibm-watson sdk and includes breaking changes. See [pypi ibm-watson](https://pypi.org/project/ibm-watson/) and [github ibm-watson](https://github.com/watson-developer-cloud/python-sdk) for more information. \n\n\n\nFor more information about migrating to python:3.9, see [(Details on GitHub)](https://github.com/ibm-functions/runtime-python/blob/master/python3.9/CHANGELOG.md).\n\n\n\n\n\n Python packages \n\nEnsure that your action uses only the packages that are mentioned in the following table. \\n While other Python packages might be part of the runtime, they are included only as indirect dependencies of the other listed packages. These unlisted packages are candidates to be removed as soon as they are not required by the referring package.\n\nPython 3.11 packages\n\nPython 3.9 packages\n\nPython 3.7 packages\n\n\n\nTable 1.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-runtimes"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08867-20399-21926", "score": 22.730969713607763, "text": "\n+-------------------------------------------+\nSubscription Name: 30 Day Self-Supported Red Hat OpenShift Container Platform, 2-Core Evaluation\nProvides: Red Hat Ansible Engine\nRed Hat Software Collections (for RHEL Server for IBM Power LE)\nRed Hat OpenShift Enterprise Infrastructure\nRed Hat JBoss Core Services\nRed Hat Enterprise Linux Fast Data path\nRed Hat OpenShift Container Platform for Power\nJBoss Enterprise Application Platform\n:\nRed Hat OpenShift Container Platform Client Tools for Power\nRed Hat Enterprise Linux Fast Datapath (for RHEL Server for IBM Power LE)\nRed Hat OpenShift Enterprise JBoss EAP add-on\nRed Hat OpenShift Container Platform\nRed Hat Gluster Storage Management Console (for RHEL Server)\nRed Hat OpenShift Enterprise JBoss A-MQ add-on\nRed Hat Enterprise Linux for Power, little endian Beta\nRed Hat OpenShift Enterprise Client Tools\n:\nRed Hat OpenShift Enterprise Application Node\n:\nRed Hat OpenShift Service Mesh\n:\nRed Hat OpenShift Enterprise JBoss FUSE add-on\nSKU: SER0419\nContract: 123456789\nPool ID: 1a2345bcd6789098765abcde43219bc3\nProvides Management: Yes\nAvailable: 10\nSuggested: 1\nService Level: Self-Support\nService Type: L1-L3\nSubscription Type: Stackable\nStarts: 12/03/2018\nEnds: 01/02/2019\nSystem Type: Physical\n7. Exit the secure shell to return to your OpenShift installation directory inside your container.\n\nexit\n\nExample output:\n\nlogout\nConnection to 169.47.XXX.XX closed.\n/go/bin/terraform-ibm-openshift \n\n\n\n2. Finish setting up and registering the nodes with the Red Hat Network.", "title": "", "source": "https://cloud.ibm.com/docs/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-redhat"}, {"document_id": "ibmcld_14491-1340-3282", "score": 22.63335570090781, "text": "\nRed Hat OpenShift for VMware configuration \n\nWhen you order the service, you must provide a Red Hat\u00ae pull secret. This pull secret is used to associate the new Red Hat OpenShift cluster with your existing Red Hat account. You can obtain a copy of your pull secret by [logging in to your Red Hat account](https://cloud.redhat.com/openshift/install/vsphere/user-provisioned) and clicking Copy Pull Secret.\n\n\n\n\n\n Setting up DNS to access your Red Hat OpenShift console \n\nRed Hat OpenShift depends on DNS to function properly. The ocp wildcard zone in your VMware environment root zone resolves all names to the IP address of the Red Hat OpenShift cluster application. This way, all applications that run within Red Hat OpenShift are routed through the Load Balancer, as needed.\n\nBecause the Red Hat OpenShift web console runs as an application within Red Hat OpenShift, your system must properly resolve DNS names before you can connect to the Red Hat OpenShift web console. You must complete the following steps before you open the Red Hat OpenShift console:\n\n\n\n1. Ensure you are connected to your environment by using the IBM Cloud infrastructure VPN.\n2. Ensure the system that you use to connect to the Red Hat OpenShift web console can properly resolve hostnames in the DNS zone for your VMware environment. For an existing DNS infrastructure, configure the DNS delegation. Therefore, the queries for hostnames within the VMware instance's root zone are handled by the AD DNS server that is running within your VMware environment.\n\n\n\nAlternately, you can configure your local hosts file with the following entries so you can access the Red Hat OpenShift web console. Use the following details for the example.\n\n\n\n* Replace APPLICATION_IP with the Red Hat OpenShift application IP address shown in the Red Hat OpenShift service details page.\n* Replace ROOTDOMAIN with the root domain shown on the Summary page for the vCenter Server instance.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-ocp_ordering"}, {"document_id": "ibmcld_10422-7-1877", "score": 22.456798528201727, "text": "\nRed Hat OpenShift on IBM Cloud version information \n\nReview information about the supported Red Hat OpenShift versions for Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nView information of version changes for major, minor, and patch updates that are available for your Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters. Changes include updates to Red Hat OpenShift, Kubernetes, and IBM Cloud Provider components.\n\nUnless otherwise noted in the change logs, the IBM Cloud provider version enables Red Hat OpenShift APIs and features that are at beta. Red Hat OpenShift alpha features, which are subject to change, are disabled.\n\nCheck the [Security Bulletins on IBM Cloud Status](https://cloud.ibm.com/status?selected=security) for security vulnerabilities that affect Red Hat OpenShift on IBM Cloud. You can filter the results to view only Kubernetes Service security bulletins that are relevant to Red Hat OpenShift on IBM Cloud. Change log entries that address other security vulnerabilities but don't also refer to an IBM security bulletin are for vulnerabilities that are not known to affect Red Hat OpenShift on IBM Cloud in normal usage. If you run privileged containers, run commands on the workers, or execute untrusted code, then you might be at risk.\n\nMaster patch updates are applied automatically. Worker node patch updates can be applied by reloading or updating the worker nodes. For more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions).\n\nFor more details about the Red Hat OpenShift and Kubernetes project versions, review the Red Hat OpenShift release notes.\n\n\n\n* [Red Hat OpenShift 4.13 release notes overview](https://docs.openshift.com/container-platform/4.13/release_notes/ocp-4-13-release-notes.html)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions"}, {"document_id": "ibmcld_14492-10142-11408", "score": 22.402103251855216, "text": "\n* If you are using a vSAN datastore, delete any persistent volumes that you no longer need before you uninstall Red Hat OpenShift. Any volumes that are not deleted will remain in the vSAN storage after the Red Hat OpenShift uninstallation.\n* Before you delete the service, you must remove any personal VMs that were deployed with this service, from the storage. Red Hat OpenShift only orders personal VMs if it\u2019s not vSAN.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [vCenter Server and Red Hat OpenShift architecture overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* [VMware Solutions and Red Hat OpenShift overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro)\n* [Red Hat OpenShift Container Platform 4.7 documentation](https://docs.openshift.com/container-platform/4.7/welcome/index.html)\n* [Red Hat OpenShift Container Platform 4.7 release notes](https://docs.openshift.com/container-platform/4.7/release_notes/ocp-4-7-release-notes.html)\n* [What's new in Red Hat OpenShift](https://www.openshift.com/learn/whats-new)\n* [Succeeding with Red Hat OpenShift and VMware\u2019s Software-Defined Datacenter (SDDC)](https://blog.openshift.com/red-hat-openshift-and-vmware-better-together/)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-ocp_overview"}, {"document_id": "ibmcld_10702-7-1940", "score": 22.3294262729773, "text": "\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https://docs.openshift.com/container-platform/4.11/welcome/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorial"}, {"document_id": "ibmcld_10422-1393-2886", "score": 22.308741060383266, "text": "\nFor more information about major, minor, and patch versions and preparation actions between minor versions, see [Red Hat OpenShift versions](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions).\n\nFor more details about the Red Hat OpenShift and Kubernetes project versions, review the Red Hat OpenShift release notes.\n\n\n\n* [Red Hat OpenShift 4.13 release notes overview](https://docs.openshift.com/container-platform/4.13/release_notes/ocp-4-13-release-notes.html)\n* [Red Hat OpenShift 4.12 release notes overview](https://docs.openshift.com/container-platform/4.12/release_notes/ocp-4-12-release-notes.html)\n* [Red Hat OpenShift 4.11 release notes overview](https://docs.openshift.com/container-platform/4.11/release_notes/ocp-4-11-release-notes.html)\n* [Red Hat OpenShift 4.10 release notes overview](https://docs.openshift.com/container-platform/4.10/release_notes/ocp-4-10-release-notes.html)\n* [Red Hat OpenShift 4.9 release notes overview](https://docs.openshift.com/container-platform/4.9/release_notes/ocp-4-9-release-notes.html)\n* [Kubernetes change log](https://github.com/kubernetes/kubernetes/tree/master/CHANGELOG)\n\n\n\n\n\n Available Red Hat OpenShift versions \n\nRed Hat OpenShift on IBM Cloud supports the following versions of Red Hat OpenShift. Note that different Red Hat OpenShift versions might support different RHEL versions.\n\nDates that are marked with a dagger (\u2020) are tentative and subject to change.\n\nRHEL 7 is deprecated and becomes unsupported soon.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions"}, {"document_id": "ibmcld_07968-7-1612", "score": 22.271227789457676, "text": "\nWorking with Red Hat OpenShift on IBM Cloud \n\nIf you want to use containers in either either the VPC or Satellite reference architectures, you should use [Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-roks-overview). Red Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift on IBM Cloud cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps. Combined with an intuitive user experience, built-in security and isolation, and advanced tools to secure, manage, and monitor your cluster workloads, you can rapidly deliver highly available and secure containerized apps in the public cloud.\n\n\n\n Deploying Red Hat OpenShift on IBM Cloud \n\n\n\n1. Install the CLI plugins for Red Hat OpenShift on IBM Cloud. For more information, see [Installing the Red Hat OpenShift on IBM Cloud CLI](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-containers-openshift).\n2. Setup the API for Red Hat OpenShift on IBM Cloud. For more information, see [Setting up the API](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_api_install).\n3. Create your Red Hat OpenShift on IBM Cloud cluster. For more information, see [Creating a Red Hat OpenShift on IBM Cloud cluster in your VPC](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorial).\n4.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-containers-openshift"}, {"document_id": "ibmcld_14497-11060-12784", "score": 22.245314948778105, "text": "\nThe NSX DLR virtual machines are configured as an active - passive pair, and vSphere Distributed Resource Scheduler (DRS) anti-affinity rules are created to ensure that the DLR VMs do not run on the same host. This step is described in [Red Hat OpenShift NSX DLR configuration](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-nsxdlr-intro).\n* Update DNS - The infrastructure DNS, provisioned with the vCenter Server instance is updated with the names and IP addresses for the Red Hat OpenShift components by using a PowerShell script. This step is described in [VMware Solutions DNS configuration](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-dns-intro).\n\n\n\n* Phase 2 - Red Hat OpenShift installation. These steps are described in [Red Hat OpenShift 4.7 user provider infrastructure installation](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-install-intro).\n\n\n\n* A Red Hat virtual machine, the bastion node, is provisioned to run the Red Hat OpenShift installer and to host an HTTP Server. It is registered with Red Hat by using your subscription, and the Red Hat OpenShift installer is downloaded.\n* On the bastion node, the install-config.yaml file is populated with the required Red Hat OpenShift parameters and Red Hat OpenShift ignition is used to generate a number of files used for the installation of the bootstrap, control plane, and worker machines.\n* Terraform, on the bastion node, uses the files that are created by Ignition to create the Red Hat OpenShift VMs.\n\n\n\n* Phase 3 - Post deployment activities. Configure a persistent volume for use by the Red Hat OpenShift cluster.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"}, {"document_id": "ibmcld_14492-7-1792", "score": 22.23753195492817, "text": "\nRed Hat OpenShift for VMware overview \n\nThe Red Hat\u00ae OpenShift\u00ae for VMware\u00ae service deploys an Red Hat OpenShift cluster by using an automated deployment of the VMware SDDC (Software Defined Data Center) architecture. The Red Hat OpenShift components are deployed as virtual machines (VMs) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThe Red Hat OpenShift version available for deployment is 4.12.\n\nReview the following information before you install the Red Hat OpenShift for VMware service:\n\n\n\n* Red Hat OpenShift for VMware cannot be installed on multiple VMware vCenter Server\u00ae instances in a multisite configuration. Before you install Red Hat OpenShift for VMware on an instance, verify that the service is not installed on any other instances in the multisite configuration.\n* Red Hat OpenShift for VMware is supported for vCenter Server instances with VMware vSphere\u00ae 7.0 and VMware NSX-T\u2122 3.1 or later.\n* Red Hat OpenShift for VMware is not supported for new deployments or for ordering post-deployment for vCenter Server with NSX-V instances with vSphere 6.7.\n\n\n\nExisting installations of Red Hat OpenShift for VMware can be used or deleted for vSphere 6.7 instances.\n\nIBM Cloud\u00ae for VMware Solutions offers promotions for some services. Promotional pricing offers a number of months without charge for a service licenses, if the service has license charges. For more information, see [Promotions for VMware Solutions services](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_addingservicesvc_addingservices-service-promotions).\n\nThe cluster consists of the following components:\n\n\n\n* Three primary nodes\n* Three worker nodes, all running Red Hat\u00ae CoreOS\n* Two VMware NSX\u00ae VMs\n* A Red Hat CoreOS template\n* A bastion VM running CoreOS", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-ocp_overview"}, {"document_id": "ibmcld_10203-7-1859", "score": 22.224004917298913, "text": "\nDeploying apps in Red Hat OpenShift clusters \n\nWith Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters, you can deploy apps from a remote file or repository such as GitHub with a single command. Also, your clusters come with various built-in services that you can use to help operate your cluster.\n\n\n\n Moving your apps to Red Hat OpenShift \n\nTo create an app in your Red Hat OpenShift on IBM Cloud cluster, you can use the Red Hat OpenShift console or CLI.\n\nSeeing errors when you deploy your app? Red Hat OpenShift has different default settings than community Kubernetes, such as stricter security context constraints. Review the [common scenarios where you might need to modify your apps](https://cloud.ibm.com/docs/openshift?topic=openshift-plan_deployopenshift_move_apps_scenarios) so that you can deploy them on Red Hat OpenShift clusters.\n\n\n\n Deploying apps through the console \n\nYou can create apps through various methods in the Red Hat OpenShift console by using the Developer perspective. For more information, see the [Red Hat OpenShift documentation](https://docs.openshift.com/container-platform/4.11/applications/creating_applications/odc-creating-applications-using-developer-perspective.html).\n\n\n\n1. From the [Red Hat OpenShift clusters console](https://cloud.ibm.com/kubernetes/clusters?platformType=openshift), select your cluster.\n2. Click Red Hat OpenShift web console.\n3. From the perspective switcher, select Developer. The Red Hat OpenShift web console switches to the Developer perspective, and the menu now offers items such as +Add, Topology, and Builds.\n4. Click +Add.\n5. In the Add pane menu bar, select the Project that you want to create your app in from the drop-down list.\n6. Click the method that you want to use to add your app, and follow the instructions. For example, click From Git.\n\n\n\n\n\n\n\n Deploying apps through the CLI", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-deploy_app"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10203-2544-4340", "score": 15.078699630820314, "text": "\noc new-app --name <app_name> https://github.com/<path_to_app_repo> [--context-dir=<subdirectory>]\n\nWhat does the new-app command do?\n: The new-app command creates a build configuration and app image from the source code, a deployment configuration to deploy the container to pods in your cluster, and a service to expose the app within the cluster. For more information about the build process and other sources besides Git, see the [Red Hat OpenShift documentation](https://docs.openshift.com/container-platform/4.11/applications/creating_applications/odc-creating-applications-using-developer-perspective.html).\n\n\n\n\n\n\n\n Deploying apps to specific worker nodes by using labels \n\nWhen you deploy an app, the app pods indiscriminately deploy to various worker nodes in your cluster. Sometimes, you might want to restrict the worker nodes that the app pods to deploy to. For example, you might want app pods to deploy to only worker nodes in a certain worker pool because those worker nodes are on bare metal machines. To designate the worker nodes that app pods must deploy to, add an affinity rule to your app deployment.\n\nBefore you begin\n\n\n\n* [Access your Red Hat OpenShift cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-access_cluster).\n* Make sure that you are assigned a [service access role](https://cloud.ibm.com/docs/openshift?topic=openshift-userschecking-perms) that grants the appropriate Kubernetes RBAC role so that you can work with Kubernetes resources in the Red Hat OpenShift project.\n* Optional: [Set a label for the worker pool](https://cloud.ibm.com/docs/openshift?topic=openshift-add_workersworker_pool_labels) that you want to run the app on.\n\n\n\nTo deploy apps to specific worker nodes,\n\n\n\n1. Get the ID of the worker pool that you want to deploy app pods to.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-deploy_app"}, {"document_id": "ibmcld_03184-3236-4998", "score": 14.8993291823176, "text": "\nThe client application then stores the returned information in context variable specified in the action request ($weather_forecast).\n4. The client application sends another message to the service, including the updated context that contains the weather forecast information. From the dialog's perspective, this message is effectively the next round of user input, although the actual input text is blank.\n5. A child node of the #weather node is triggered by the presence of the $weather_forecast context variable. This node responds with text output that includes the weather forecast, which the client application displays to the user. (If the $weather_forecast variable is not set, another child node can handle this case and report an error.)\n\n\n\nIt is also possible to call an external Web service directly from a dialog node, without involving the client application, by defining a webhook. For more information about how to call an external service using a webhook, see [Making a programmatic call from a dialog node](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-webhooks).\n\n\n\n Procedure \n\nTo request a client action from a dialog node, complete the following steps:\n\n\n\n1. In the dialog node from which you want to request the client action, open the JSON editor for the node response.\n\n![Shows how to access the JSON editor associated with a standard noderesponse.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/contextvar-json-response.png)\n2. Use the following syntax to define the client action you want to request.\n\n{\n\"context\": {\n\"variable_name\" : \"variable_value\"\n},\n\"actions\": [\n{\n\"name\":\"<actionName>\",\n\"type\":\"client\",\n\"parameters\": {\n\"<parameter_name>\":\"<parameter_value>\",", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-actions-client"}, {"document_id": "ibmcld_03184-1586-3749", "score": 14.634918119943112, "text": "\nIt is the responsibility of the client application to carry out the requested action, store the result in the context, and send it back to the dialog with the next message.\n\nYou might call a client application to do the following types of things:\n\n\n\n* Validate information that you collected from the user.\n* Do calculations or string manipulations on user input that are too complex for supported SpEL expression methods to handle.\n* Get data from another application or service.\n\n\n\nThe following diagram illustrates how client actions work, using the example of an action to get a weather forecast.\n\n![Shows someone asking for a weather forecast and the dialog sending a request to a client app, which sends it to the external service and returns the result](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/forecast.png)\n\nThe flow of requests and responses follows this pattern:\n\n\n\n1. The client application sends a message containing user input that asks for a weather forecast (using the message or message_stateless method).\n2. The user input triggers a dialog node conditioned on a #weather intent. In its response to the client, this node specifies the get_weather client action, which is a name that the client application recognizes. (This is in addition to any text response, such as Checking the weather forecast....)\n3. When it receives this response, the client application recognizes that the get_weather action is being requested. It calls an external web service (/weather) to get the actual forecast information, passing any specified parameters (such as the user's location). The client application then stores the returned information in context variable specified in the action request ($weather_forecast).\n4. The client application sends another message to the service, including the updated context that contains the weather forecast information. From the dialog's perspective, this message is effectively the next round of user input, although the actual input text is blank.\n5. A child node of the #weather node is triggered by the presence of the $weather_forecast context variable.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-actions-client"}, {"document_id": "ibmcld_02872-10099-11736", "score": 14.340386360892307, "text": "\n\"result_variable\": \"context.my_forecast\"\n}\n]\n}\n\nNormally, the service only returns to the client from a POST /message request when new user input is required, such as after executing a parent and before executing one of its child nodes. However, if you add a client action to a node, then after evaluation, the service always returns to the client so that the result of the action call can be returned. To prevent waiting for user input when it should not, such as for a node that is configured to jump directly to a child node, the service adds the following value to the message context:\n\n{\n\"context\": {\n\"skip_user_input\": true\n}\n}\n\nIf you want the client to perform an action, but not get user input, then you can follow the same convention, and add the skip_user_input context variable to the parent node to communicate that to the client application.\n\nYour client application should always check for the skip_user_input variable on context. If present, then it knows not to request new input from the user, but instead execute the action, add its result into the message, and pass it back to the service. The new POST message request should include the message returned by the previous POST message response (namely, the context, input, intents, entities, and optionally the output section) and, instead of the JSON object that defines the programmatic call to make, it should include the result that was returned from the programmatic call.\n\nIn a child node that you jump to after this node, add the response to show the user:\n\n{\n\"output\": {\n\"text\": {\n\"values\": [\n\"It will be $my_forecast $date.literal in $location.literal.\"\n]\n}\n}", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-actions-client"}, {"document_id": "ibmcld_02953-3805-5544", "score": 14.019556213021337, "text": "\n* To find and resubmit a test utterance, you can press the Up key to cycle through your recent inputs.\n* To remove prior test utterances from the chat pane and start over, click the Clear link. Not only are the test utterances and responses removed, but this action also clears the values of any context variables that were set as a result of your interactions with the dialog. Context variable values that you explicitly set or change are not cleared.\n\n\n\n\n\n\n\n What to do next \n\nIf you determine that the wrong intents or entities are being recognized, you might need to modify your intent or entity definitions.\n\nIf the correct intents and entities are being recognized, but the wrong nodes are being triggered in your dialog, make sure your conditions are written properly.\n\nIf you are ready to put the conversation to work helping your users, call the assistant from a client application. See [Building a client application](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-api-client).\n\n\n\n\n\n\n\n Searching your dialog \n\nThe search capability was introduced with the 1.5.0 release.\n\nYou can search the dialog to find one or more dialog nodes that mention a given word or phrase.\n\n\n\n1. From the Dialog page header, click the Search icon ![Search icon in the Intents page header](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/search_icon.png).\n2. Enter a search term or phrase.\n\nThe first time you search, an index is created. You might be asked to wait for the text in your dialog nodes to be indexed and then resubmit your request.\n\n\n\nDialog nodes that contain your search term, with corresponding examples, are shown. Select a result to open it for editing.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tasks"}, {"document_id": "ibmcld_05838-25355-26994", "score": 13.763093305135119, "text": "\nThe Autorecovery system uses various checks to query worker node health status. If Autorecovery detects an unhealthy worker node based on the configured checks, Autorecovery triggers a corrective action like rebooting a VPC worker node or reloading the operating system in a classic worker node. Only one worker node undergoes a corrective action at a time. The worker node must complete the corrective action before any other worker node undergoes a corrective action. For more information, see this [Autorecovery blog post](https://www.ibm.com/cloud/blog/autorecovery-utilizes-consistent-hashing-high-availability).\n\nAutorecovery requires at least one healthy worker node to function properly. Configure Autorecovery with active checks only in clusters with two or more worker nodes.\n\nBefore you begin:\n\n\n\n* Ensure that you have the following [IBM Cloud IAM roles](https://cloud.ibm.com/docs/containers?topic=containers-userschecking-perms):\n\n\n\n* Administrator platform access role for the cluster\n* Writer or Manager service access role for the kube-system namespace\n\n\n\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\n\n\nTo configure Autorecovery:\n\n\n\n1. [Follow the instructions](https://cloud.ibm.com/docs/containers?topic=containers-helminstall_v3) to install the Helm version 3 client on your local machine.\n2. Create a configuration map file that defines your checks in JSON format. For example, the following YAML file defines three checks: an HTTP check and two Kubernetes API server checks.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-health-monitor"}, {"document_id": "ibmcld_03184-7285-9367", "score": 13.59384637357918, "text": "\nIf multiple actions in a single JSON action array add the result of their programmatic call to the same context variable, then the order in which the context is updated matters. Per action type, the order in which the actions are defined in the array determines the order in which the context variable's value is set. The context variable value returned by the last action in the array overwrites the values calculated by any other actions.\n\nThe result_variable property is required. If the client action does not return any result, specify null as the value.\n\n\n\n\n\n\n\n\n\n Client action example \n\nThe following example shows what a request for a call to an external weather service might look like. It is added to the JSON editor that is associated with the node response. By the time the node-level response is triggered, slots have collected and stored the date and location information from the user. This example assumes that the client action is named weather_forecast, that it takes a location parameter, and that the results are to be stored in the weather_forecast context variable.\n\n{\n\"actions\": [\n{\n\"name\": \"get_weather\",\n\"type\": \"client\",\n\"parameters\": {\n\"location\": \"$location\"\n},\n\"result_variable\": \"weather_forecast\"\n}\n]\n}\n\nThe client application must check for the presence of any client actions in the responses to messages it sends to the assistant. When it recognizes a request for the get_weather action, it executes the action (calling the external weather service), and it stores the result in the specified context variable (weather_forecast). It then sends a message to the service, including the updated context.\n\nTo handle this message in your dialog, create a child node following the node that requested the action. You can condition this child node on the special condition true to ensure that it is always triggered by the message that the client sends after completing the requested action. In this child node, add the response to show the user, reading the stored action result from the $my_forecast context variable:\n\n{\n\"output\": {\n\"text\": {\n\"values\": [", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-actions-client"}, {"document_id": "ibmcld_06209-36554-38368", "score": 13.447341448214189, "text": "\nYou can use worker pools to spread worker nodes evenly across zones and build a balanced cluster. Balanced clusters are more available and resilient to failures. If a worker node is removed from a zone, you can rebalance the worker pool and automatically provision new worker nodes to that zone. Worker pools are also used to install Kubernetes version updates to all your worker nodes.\n\nIf you created clusters before multizone clusters became available, your worker nodes are still stand-alone and not automatically grouped into worker pools. You must update these clusters to use worker pools. If not updated, you can't change your single zone cluster to a multizone cluster.\n\nReview the following image to see how your cluster setup changes when you move from stand-alone worker nodes to worker pools.\n\nZoom\n\n![Update your cluster from stand-alone worker nodes to worker pools](https://cloud.ibm.com/docs-content/v1/content/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7/containers/images/cs_cluster_migrate.png)\n\nFigure 1. Update your cluster from stand-alone worker nodes to worker pools\n\nBefore you begin:\n\n\n\n* Ensure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https://cloud.ibm.com/docs/containers?topic=containers-userschecking-perms) for the cluster.\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\n\n\nTo update stand-alone worker nodes to worker pools:\n\n\n\n1. List existing stand-alone worker nodes in your cluster and note the ID, the Machine Type, and Private IP.\n\nibmcloud ks worker ls --cluster <cluster_name_or_ID>\n2. Create a worker pool and decide on the flavor and the number of worker nodes that you want to add to the pool.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_03112-3236-4753", "score": 13.121190007531677, "text": "\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"my_context_var\": \"this is the value\"\n}\n}\n}\n}\n\nFor detailed information about how to access context variables using the API, see the [v2 API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v2).\n\n\n\n Example \n\nThe following example shows a stateful /message request that includes both global and skill-specific context variables; it also uses the options.return_context property to request that the context be returned with the response. Note that this option is applicable only if you are using the stateful message method, because the stateless message method always returns the context.\n\n\n\n* Java\n* Python\n* Node\n\n\n\nMessageInputOptions inputOptions = new MessageInputOptions.Builder()\n.returnContext(true)\n.build();\n\nMessageInput input = new MessageInput.Builder()\n.messageType(\"text\")\n.text(\"Hello\")\n.options(inputOptions)\n.build();\n\n// create global context with user ID\nMessageContextGlobalSystem system = new MessageContextGlobalSystem.Builder()\n.userId(\"my_user_id\")\n.build();\nMessageContextGlobal globalContext = new MessageContextGlobal.Builder()\n.system(system)\n.build();\n\n// build user-defined context variables, put in skill-specific context for main skill\nMap<String, Object> userDefinedContext = new HashMap<>();\nuserDefinedContext.put(\"account_number\",\"123456\");\nMessageContextSkill mainSkillContext = new MessageContextSkill.Builder()\n.userDefined(userDefinedContext)\n.build();\nMap<String, MessageContextSkill> skillsContext = new HashMap<>();", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-client-get-context"}, {"document_id": "ibmcld_16262-3184-4712", "score": 13.054565991260555, "text": "\nThe following example shows a stateful /message request that includes both global and skill-specific context variables; it also uses the options.return_context property to request that the context is returned with the response. This option is applicable only if you are using the stateful message method because the stateless message method always returns the context.\n\n\n\n* Java\n* Python\n* Node\n\n\n\nMessageInputOptions inputOptions = new MessageInputOptions.Builder()\n.returnContext(true)\n.build();\n\nMessageInput input = new MessageInput.Builder()\n.messageType(\"text\")\n.text(\"Hello\")\n.options(inputOptions)\n.build();\n\n// create global context with user ID\nMessageContextGlobalSystem system = new MessageContextGlobalSystem.Builder()\n.userId(\"my_user_id\")\n.build();\nMessageContextGlobal globalContext = new MessageContextGlobal.Builder()\n.system(system)\n.build();\n\n// build user-defined context variables, put in skill-specific context for main skill\nMap<String, Object> userDefinedContext = new HashMap<>();\nuserDefinedContext.put(\"account_number\",\"123456\");\nMessageContextSkill mainSkillContext = new MessageContextSkill.Builder()\n.userDefined(userDefinedContext)\n.build();\nMap<String, MessageContextSkill> skillsContext = new HashMap<>();\nskillsContext.put(\"main skill\", mainSkillContext);\n\nMessageContext context = new MessageContext.Builder()\n.global(globalContext)\n.skills(skillsContext)\n.build();\n\nMessageOptions options = new MessageOptions.Builder()\n.assistantId(\"{assistant_id}\")\n.sessionId(\"{session_id}\")\n.input(input)", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-client-get-context"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04170-7-2189", "score": 30.87203645392696, "text": "\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https://research.google/pubs/pub45581/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with /cdn-cgi/challenge-platform/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_04105-5067-6335", "score": 28.68390403512752, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-3403-5572", "score": 28.079952510830093, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04168-6066-7283", "score": 26.439882992663186, "text": "\n* [Querying Edge Functions metrics with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https://cloud.ibm.com/docs/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https://cloud.ibm.com/docs/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https://cloud.ibm.com/docs/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https://cloud.ibm.com/docs/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https://cloud.ibm.com/docs/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https://cloud.ibm.com/docs/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https://cloud.ibm.com/docs/cis?topic=cis-at_events)", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-http-concepts"}, {"document_id": "ibmcld_04334-39121-41053", "score": 23.680382780085303, "text": "\nValid values for group are all, domain, reliability, performance, security. This option is mutually exclusive with -f, --feature.\n\n-f, --feature\n: Feature of domain settings to check. This option is mutually exclusive with g, --group. Valid values are as follow:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination in the BoringSSL format. This command only lists ciphers specifically whitelisted by customers. If no ciphers are whitelisted, the list is empty and the default ciphers are used. See [TLS Options](/docs/cis? topic=cis-cis-tls-options#cipher-suites) for the list of default ciphers.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP/2.\n* http3: Accelerate your website with HTTP/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_04113-1734-4014", "score": 23.57273533692618, "text": "\nIBM CIS usually accelerates API traffic by removing connection overhead. However, the default security stance can interfere with many API calls. It is recommended that you take a few actions to prevent interference with your API traffic after proxying is active.\n\n\n\n* Turn security features off selectively, using the Page Rules features.\n\n\n\n* Create a Page Rule with the URL pattern of your API, such as api.example.com\n* Add the following rule behaviors:\n\n\n\n* Select Security Level to Essentially off\n* Select TLS to Off\n* Select Browser Integrity Check to Off\n\n\n\n* Select Provision Resource\n\n\n\n* Alternatively, you can turn off Web Application Firewall globally from the Security page.\n\n\n\n\n\n What does the Browser Integrity Check do? \n\nThe browser integrity check looks for HTTP headers that are commonly abused by spammers. It denies traffic with those headers access to your page. It also blocks visitors that do not have a user agent, or who add a non-standard user agent (this tactic is commonly used by abuse bots, crawlers, or APIs).\n\n\n\n\n\n\n\n Best practice 4: Configure your security settings as strictly as possible \n\nCIS provides some options for encrypting your traffic. As a reverse proxy the TLS connection is terminated at Cloudflare and a new TLS connection is opened to your origin servers. For your termination with CIS, you can upload a custom certificate from your account, you can use a wildcard certificate provisioned for you by CIS, or both.\n\n\n\n Upload a custom certificate \n\nYou can upload your public and private key when you create an Enterprise domain. If you upload your own certificate, you gain immediate compatibility with encrypted traffic, and you maintain control over your certificate (for example, an Extended Validation (EV) certificate). Remember that you'll be responsible for managing your certificate if you upload a custom certificate. For example, IBM CIS won't track the certificate expiration dates.\n\n\n\n\n\n Alternatively, use a certificate provisioned by CIS \n\nIBM CIS has partnered with several Certificate Authorities (CAs) to provide domain wildcard certificates for our customers, by default. Manual verification could be required for setting up these certificates, and your support team can help you perform these additional steps.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-best-practices-for-cis-setup"}, {"document_id": "ibmcld_04172-7-2047", "score": 23.038805876661975, "text": "\nAccessing log fields \n\nIf fields are not specified in the request, a limited set of default fields are returned. Find the full list of all available fields using the following request.\n\nibmcloud cis logpull DNS_DOMAIN_ID --available-fields\n\nFields are passed as a comma-separated list. For example, to have \"ZoneID\" and \"RayID\", use:\n\nibmcloud cis logpull DNS_DOMAIN_ID --start 2019-01-02T01:00:00+00:00 --end 2019-01-02T01:00:00+00:00 --fields ZoneId,RayID\n\n\n\n Available Fields \n\nThe following tables describe the fields available by log category.\n\n\n\n HTTP requests \n\nThis table contains the fields available for HTTP requests.\n\n\n\nTable 1. HTTP events\n\n Field Value Type \n\n BotScore Cloudflare Bot Score (available for Bot Management customers; please contact your account team to enable) int \n BotScoreSrc Underlying detection engine or source on where a Bot Score is calculated. Possible values are Not ComputedHeuristicsMachine LearningBehavioral AnalysisVerified Bot string \n CacheCacheStatus unknownmissexpiredupdatingstalehitignoredbypassrevalidated string \n CacheResponseBytes Number of bytes returned by the cache int \n CacheResponseStatus HTTP status code returned by the cache to the edge; all requests (including non-cacheable ones) go through the cache; also see CacheStatus field int \n CacheTieredFill Tiered Cache was used to serve this request bool \n ClientASN Client AS number int \n ClientCountry Country of the client IP address string \n ClientDeviceType Client device type string \n ClientIP IP address of the client string \n ClientIPClass unknowncleanbadHostsearchEnginewhitelistgreylistmonitoringServicesecurityScannernoRecordscanbackupServicemobilePlatformtor string \n ClientRequestBytes Number of bytes in the client request int \n ClientRequestHost Host requested by the client string \n ClientRequestMethod HTTP method of client request string \n ClientRequestPath URI path requested by the client string \n ClientRequestProtocol HTTP protocol of client request string \n ClientRequestReferer HTTP request referrer string", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-log-fields"}, {"document_id": "ibmcld_04334-43529-45385", "score": 22.81961236686035, "text": "\nUpdate a feature for the domain.\n\nibmcloud cis domain-settings-update DNS_DOMAIN_ID (-f, --feature FEATURE) (-v, --value VALUE) [-i, --instance INSTANCE] [--output FORMAT]\n\n\n\n Command options \n\nDNS_DOMAIN_ID\n: The ID of DNS domain. Required. -f, --feature value\n: Feature of domain settings to update. Required. Valid values:\n\n\n\n* always_use_https: Redirect all requests with scheme http to https. This applies to all http requests to the domain.\n* automatic_https_rewrites: Help fix mixed content by changing http to https for all resources or links on your web site that can be served with HTTPS.\n* brotli: When the client requesting an asset supports the brotli compression algorithm, CIS will serve a brotli compressed version of the asset.\n* browser_check: Evaluate HTTP headers from your visitors browser for threats. If a threat is found a block page will be delivered.\n* challenge_ttl: Specify how long a visitor with a bad IP reputation is allowed access to your website after completing a challenge.\n* ciphers: A whitelist of ciphers for TLS termination. These ciphers must be in the BoringSSL format.\n* cname_flattening: Follow a CNAME to where it points and return that IP address instead of the CNAME record. By default, only flatten the CNAME at the root of your domain.\n* email_obfuscation: Encrypt email addresses on your web page from bots while keeping them visible to humans.\n* opportunistic_onion: Allow legitimate users of Tor Browser to access your websites.\n* hotlink_protection: Protect your images from off-site linking.\n* http2: Accelerate your website with HTTP/2.\n* http3: Accelerate your website with HTTP/3.\n* image_load_optimization: Improve load time for pages that include images on mobile devices with slow network connections.\n* image_size_optimization: Improve image load time by optimizing images hosted on your domain.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cis-cli"}, {"document_id": "ibmcld_16286-2915-4657", "score": 22.381059839116535, "text": "\n6. On the Connect to channels page, click Configure Microsoft Teams channel in the Add a featured channel section.\n7. On the Configure Microsoft Teams page, specify options in the Messaging, Calling, and Publish tabs that fit your bot needs, and then click Save.\n8. In your Watson Assistant Microsoft Teams integration, click Next to create your Teams app.\n\n\n\n\n\n\n\n Create your Teams app \n\n\n\n1. Go to the [Microsoft Teams Developer Portal](https://dev.teams.microsoft.com/home), and log in with your admin credentials.\n2. On the Apps tab, click New App.\n3. Enter a name, and click Add.\n4. On the Basic information page, enter app names, app ID, descriptions, developer information, and app URLs, and then copy and paste your app ID into Application (client) ID. Click Save.\n5. In the Configure section, select App features, and then Bot.\n6. On the Identify your bot page, select your bot.\n7. In the Select the scope in which people can use this command section, select Personal, Team, and Group Chat.\n8. Click Save, but keep the window open.\n9. In your Watson Assistant Microsoft Teams integration, click Finish.\n10. Click Publish to publish your bot.\n\n\n\n\n\n\n\n\n\n Publishing your Teams app \n\n\n\n1. In the Microsoft Teams Developer Portal window where you created and saved your Teams app, click Publish to publish your bot.\n2. Click Download the app package.\n3. Go to [Microsoft Teams](https://teams.microsoft.com), and log in with your admin credentials.\n4. Click Apps in the sidebar menu, and then click Manage your apps and Upload an app.\n5. Select Upload a custom app and specify the app package .zip file you downloaded.\n6. Click Add to finish.\n7. Test your actions and responses in the Chat section of your Teams app.\n\n\n\n\n\n\n\n Response types", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-microsoft-teams"}, {"document_id": "ibmcld_04175-0-1274", "score": 22.04968131295568, "text": "\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16365-12876-14604", "score": 37.85027852723348, "text": "\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https://web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https://integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https://cloud.ibm.com/docs/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_16388-7-1918", "score": 37.09485023693624, "text": "\nEncrypting sensitive data \n\nBy using the public key that is provided by IBM, you can add another level of encryption to hide sensitive data you send from the web chat.\n\nTo use this method for encrypting data, you must first enable the web chat security feature. For more information, see [Enabling web chat security](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security-enable).\n\nUse this method to send sensitive information in messages that come from your website, such as information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from actions. Information passed to your assistant in this way is stored in a private context variable. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for a standard customer. You do not want non-VIPs to know that they are categorized as such, but you must pass this information to your action so it can change the flow of the conversation. To do this, you can pass the customer MVP status as an encrypted variable. This private context variable is available for use by the action, but not by anything else.\n\n![development icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/development-icon.png)Tutorial: For a tutorial that shows an example of using web chat security to authenticate users and protect sensitive data, see [Tutorial: Authenticating a user in the middle of a session](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop-security).\n\nTo encrypt sensitive data:\n\n\n\n1. On the Security tab of the web chat integration settings, click the Generate key button.\n2. Copy the public key that displays in the IBM-provided public key field.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security-encrypt"}, {"document_id": "ibmcld_02855-27616-29462", "score": 36.36293933751701, "text": "\nreturn new Promise(function(resolve, reject) {\n// And then pass the new JWT into the callback and the service will resume processing messages.\nevent.identityToken = 'YOUR NEW JWT';\nresolve();\n});\n}});\ninstance.render();\n}\n};\nsetTimeout(function(){\nconst t=document.createElement('script');\nt.src=\"https://web-chat.global.assistant.watson.appdomain.cloud/loadWatsonAssistantChat.js\";\ndocument.head.appendChild(t);\n});\n</script>\nShow more\n\n\n\n\n\n\n\n Passing sensitive data \n\nYou can optionally copy the public key that is provided by IBM, and use it to add an additional level of encryption to support passing sensitive data from the web chat.\n\nUse this method to send sensitive information in messages that come from your website, such as a information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from your dialog. Information that is passed to your assistant in this way is stored in a private variable in your assistant. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for less important customers. You likely do not want non-VIPs to know that they are categorized as such. But you must pass this informataion to your dialog because it changes the route of the conversation. You can pass the customer MVP status as an encrypted variable. This private context variable will be available for use by the dialog, but not by anything else.\n\n\n\n1. From the web chat configuration page, copy the public key from the IBM provided public key field.\n2. From your website, write a function that signs a JSON Web Token.\n\nFor example, the following NodeJS code snippet shows a function that accepts a userID and payload content and sends it to the web chat.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_03422-6821-8665", "score": 36.36293933751701, "text": "\nreturn new Promise(function(resolve, reject) {\n// And then pass the new JWT into the callback and the service will resume processing messages.\nevent.identityToken = 'YOUR NEW JWT';\nresolve();\n});\n}});\ninstance.render();\n}\n};\nsetTimeout(function(){\nconst t=document.createElement('script');\nt.src=\"https://web-chat.global.assistant.watson.appdomain.cloud/loadWatsonAssistantChat.js\";\ndocument.head.appendChild(t);\n});\n</script>\nShow more\n\n\n\n\n\n Passing sensitive data \n\nYou can optionally copy the public key that is provided by IBM, and use it to add an additional level of encryption to support passing sensitive data from the web chat.\n\nUse this method to send sensitive information in messages that come from your website, such as a information about a customer's loyalty level, a user ID, or security tokens to use in webhooks that you call from your dialog. Information that is passed to your assistant in this way is stored in a private variable in your assistant. Private variables cannot be seen by customers and are never sent back to the web chat.\n\nFor example, you might start a business process for a VIP customer that is different from the process you start for less important customers. You likely do not want non-VIPs to know that they are categorized as such. But you must pass this informataion to your dialog because it changes the route of the conversation. You can pass the customer MVP status as an encrypted variable. This private context variable will be available for use by the dialog, but not by anything else.\n\n\n\n1. From the web chat configuration page, copy the public key from the IBM provided public key field.\n2. From your website, write a function that signs a JSON Web Token.\n\nFor example, the following NodeJS code snippet shows a function that accepts a userID and payload content and sends it to the web chat.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-security"}, {"document_id": "ibmcld_03180-5630-7213", "score": 36.27030191513466, "text": "\nEnabling visitor authentication also enables support for cross-domain traffic and cross-browser identification. For more information, see the [Zendesk documentation](https://support.zendesk.com/hc/en-us/articles/360022185314-Enabling-authenticated-visitors-in-the-Chat-widget).\n\nBefore you can secure the Zendesk connection, complete the following required tasks:\n\n\n\n1. Secure the web chat. For more information see [Securing the web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-security).\n2. Encrypt sensitive information that you pass to the web chat.\n\nWhen you enable security in Zendesk, you must provide the name and email address of the current user with each request. Configure the web chat to pass this information in the payload.\n\nSpecify the information by using the following syntax. Use the exact names (name and email) for the two name and value pairs.\n\n{\nuser_payload : {\nname: '{customerName}',\nemail: '{customerEmail}'\n}\n}\n\nFor more information, see [Passing sensitive data](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-securityweb-chat-security-encrypt).\n\nZendesk also expects iat and external_id name and value pairs. However, there's no need for you to provide this information. IBM automatically provides a JWT that contains these values.\n\nFor example:\n\nconst userPayload = {\n\"name\" : \"Cade Jones\",\n\"email\" : \"cade@example.com\",\n}\n\n// Sample NodeJS code on your server.\nconst jwt = require('jsonwebtoken');\nconst RSA = require('node-rsa');\n\nconst rsaKey = new RSA(process.env.PUBLIC_IBM_RSA_KEY);\n\n/\n* Returns a signed JWT.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-zendesk"}, {"document_id": "ibmcld_03080-1529-3357", "score": 35.92378294492732, "text": "\nFor a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill. For examples of how to complete common tasks, see [Passing values](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-context).\n* Change the language that is used by the web chat.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-config"}, {"document_id": "ibmcld_03080-7-1901", "score": 35.56036341219553, "text": "\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-config"}, {"document_id": "ibmcld_16364-119531-121469", "score": 35.371131427677575, "text": "\nYou can [search your dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-tasksdialog-tasks-search) to find out where you are currently using the entity, and remove it. Consider using a contextual entity to identify references to locations and people instead. After removing the entity from your dialog, disable the entity from the System entities page.\n\n\n\n\n\n 13 May 2020 \n\nStateless v2 message API\n: The v2 runtime API now supports a new stateless message method. If you have a client application that manages its own state, you can use this new method to take advantage of [many of the benefits](https://medium.com/ibm-watson/the-new-watson-assistant-v2-stateless-api-unlock-enterprise-features-today-2c02a4bbdef5) of the v2 API without the overhead of creating sessions. For more information, see the [API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v2message-stateless).\n\n\n\n\n\n 30 April 2020 \n\nWeb chat is generally available!\n: Add your assistant to your company website as a web chat widget that can help your customers with common questions and tasks. Service desk transfer support continues to be a beta feature. For more information, see [Integrating with your own website](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat).\n\nSecure your web chat\n: Enable the beta security feature of web chat so that you can verify that messages sent to your assistant come from only your customers and can pass sensitive information to your assistant.\n\n\n\n\n\n 27 April 2020 \n\nAdd personality to your assistant in web chat\n: You can add an assistant image to the web chat header to brand the window. You can add an avatar image that represents your assistant or a brand logo, for example. For more information, see [Integrating with your own web site](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat).\n\nKnow your plan\n: Now your service plan is displayed in the page header.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_16365-11574-13329", "score": 35.297863460795, "text": "\nAnyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website. For more information, see [Web chat security](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n Updating site security policies \n\nIf your website uses a Content Security Policy (CSP), you must update it to grant permission to the web chat.\n\nThe following table lists the values to add to your CSP.\n\n\n\nCSP properties\n\n Property Additional values \n\n default-src 'self' *.watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline' \n connect-src *.watson.appdomain.cloud \n\n\n\nThe following example shows a complete CSP metadata tag:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline';connect-src .watson.appdomain.cloud\" />\n\n\n\n Allowing elements \n\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_16326-1697-3495", "score": 35.01902222086184, "text": "\nFor more information, see [Changing background website](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-preview-share"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13790-1284-2889", "score": 17.585696969623786, "text": "\n* For more information about obtaining word timings, see [Generating word timings](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https://tools.ietf.org/html/rfc6455).\n\n\n\n Open a connection \n\nYou call the /v1/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss://api.{location}.text-to-speech.watson.cloud.ibm.com/instances/{instance_id}/v1/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss://api.{location}.text-to-speech.watson.cloud.ibm.com/instances/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}/v1/synthesize.\n\nA WebSocket client calls the /v1/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocket"}, {"document_id": "ibmcld_13790-7-1700", "score": 17.428573684960686, "text": "\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its /v1/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST /v1/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocket"}, {"document_id": "ibmcld_13455-7-1568", "score": 17.184616264717317, "text": "\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the /v1/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https://cloud.ibm.com/apidocs/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}, {"document_id": "ibmcld_10833-0-1231", "score": 16.440628006422482, "text": "\n\n\n\n\n\n\n  WebSocket \n\nThe preinstalled /whisk.system/websocket package for IBM Cloud\u00ae Functions offers a convenient way to post messages to a WebSocket.\n\nThe package includes the following actions.\n\n\n\nTable 1. WebSocket package entities\n\n Entity                          Type     Parameters        Description                                 \n\n /whisk.system/websocket         Package  uri               Utilities for communicating with WebSockets \n /whisk.system/websocket/send    Action   uri, payload      Send the payload to the WebSocket URI.      \n\n\n\nIf you plan to send many messages to the same WebSocket URI, creating a package binding with the uri value is suggested. With binding, you don't need to specify the value each time that you use the send action.\n\n\n\n  Send a message to a WebSocket \n\nThe /whisk.system/websocket/send action sends a payload to a WebSocket URI. The parameters are as follows.\n\n\n\nTable 2. WebSocket send action parameters\n\n Parameter  Description                                                                \n\n uri        The URI of the WebSocket server. For example, ws://mywebsockethost:80.     \n payload    The message to send to the WebSocket.                                      \n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_websocket"}, {"document_id": "ibmcld_10852-48513-49624", "score": 16.299111414060405, "text": "\n* [Reading an object with the CLI](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_read_cli)\n* [Reference for Object Storage and Cloud Functions](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_actions)\n\n\n\n\n\n[Slack](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_slackpkg_slack)\n\n\n\n* [Posting a message to a Slack channel](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_slackpkg_slack_post)\n* [Using the Slack token-based API](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_slackpkg_slack_api)\n\n\n\n[Utilities](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_utilspkg_utils)\n\n[WebSocket](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_websocketpkg_websocket)\n\n\n\n* [Send a message to a WebSocket](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_websocketsend-websocket)\n\n\n\n[Creating custom event provider feeds](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-feeds_customfeeds_custom)\n\n\n\n* [Feed architecture](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-feeds_customfeeds_arch)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_13429-163247-165127", "score": 15.878039587638945, "text": "\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https://cloud.ibm.com/apidocs/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https://github.com/watson-developer-cloud/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-release-notes"}, {"document_id": "ibmcld_13455-26115-26611", "score": 15.829116326429716, "text": "\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https://tools.ietf.org/html/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes. For more information, see the [API & SDK reference](https://cloud.ibm.com/apidocs/speech-to-text).", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}, {"document_id": "ibmcld_13741-1529-3393", "score": 15.589440467087673, "text": "\nSynthesizing speech with the service \n\nThe Text to Speech service offers an HTTP Representational State Transfer (REST) interface and a WebSocket interface:\n\n\n\n* [The HTTP interface](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingHTTP) provides both GET and POST versions of the service's /v1/synthesize method. The two versions of the method offer generally equivalent functionality. You pass the text that is to be synthesized as a query parameter with the GET method and as the body of the request with the POST method.\n* [The WebSocket interface](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocket) provides a /v1/synthesize method. You pass the text that is to be synthesized over an established WebSocket connection.\n\n\n\nWith both the HTTP and WebSocket interfaces, you specify the language and voice that are to be used, and the format for the audio that is to be returned.\n\n\n\n* For an overview of the features that are available for speech synthesis, see [Using speech synthesis features](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-service-featuresfeatures-synthesis).\n* For detailed descriptions and examples of the speech synthesis methods, see the [API & SDK reference](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\n\n\n Data limits \n\nThe interfaces accept the following maximum amounts of text with a single request:\n\n\n\n* The HTTP GET /v1/synthesize method accepts a maximum of 8 KB of input, which includes the input text and the URL and headers.\n* The HTTP POST /v1/synthesize method accepts a maximum of 8 KB for the URL and headers, and a maximum of 5 KB for the input text that is sent in the body of the request.\n* The WebSocket /v1/synthesize method accepts a maximum of 5 KB of input text.\n\n\n\nThese limits include all characters of the input, including whitespace.\n\nIBM Cloud", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-service-features"}, {"document_id": "ibmcld_13455-1311-2796", "score": 15.278615537176227, "text": "\n4. [End a recognition request](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-more)\n6. [Keep a connection alive](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-keep)\n7. [Close a connection](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-close)\n\n\n\nWhen the client sends data to the service, it must pass all JSON messages as text messages and all audio data as binary messages.\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https://tools.ietf.org/html/rfc6455).\n\n\n\n Open a connection \n\nThe Speech to Text service uses the WebSocket Secure (WSS) protocol to make the /v1/recognize method available at the following endpoint:\n\nwss://api.{location}.speech-to-text.watson.cloud.ibm.com/instances/{instance_id}/v1/recognize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of your service instance.\n\nThe examples in the documentation abbreviate wss://api.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}, {"document_id": "ibmcld_03285-5746-7932", "score": 14.9932768550599, "text": "\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https://cloud.ibm.com/apidocs/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-112910-114676", "score": 19.7137466740746, "text": "\nFor details, see [Configuring and viewing logs](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n* How can I track actions performed by users on a serverless Spark instance?\n\nYou can use the Activity Tracker service to track how users and applications interact with IBM Analytics Engine in IBM Cloud\u00ae. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. In addition, you can be alerted about actions as they happen. The events that are collected comply with the Cloud Auditing Data Federation (CADF) standard. See [Auditing events for IBM Analytics Engine serverless instances](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-at_events-serverless).\n\n\n\nNetezza\n\n\n\n* How do I sign up for Netezza Performance Server?\n\n[Create a free IBM Cloud account](https://cloud.ibm.com/registration?target=%2Fcatalog%2Fservices%2Fdb2-warehouse). When you have the account, you can provision a Netezza Performance Server instance directly through the IBM Cloud\u00ae catalog.\nFor more information, see [Getting started with Netezza Performance Server](https://cloud.ibm.com/docs/netezza?topic=netezza-getstarted).\n* How do I generate or view credentials for my Netezza Performance Server instance?\n\nTo generate credentials, follow the steps:\n\n\n\n1. Log in to [IBM Cloud](https://cloud.ibm.com/) account.\n2. Go to Resource list > Services and Software > Databases.\n3. Click on your Netezza Performance Server instance.\nYou are now on the Service instance details page.\n4. Go to the Service Credentials tab.\n5. Click New Credentials.\n6. Type a name to assing to your credentials.\n7. Select the IAM role that was assigned to you to manage the instance.\n8. Click Add.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-112889-114655", "score": 19.7137466740746, "text": "\nFor details, see [Configuring and viewing logs](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-viewing-logs).\n* How can I track actions performed by users on a serverless Spark instance?\n\nYou can use the Activity Tracker service to track how users and applications interact with IBM Analytics Engine in IBM Cloud\u00ae. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. In addition, you can be alerted about actions as they happen. The events that are collected comply with the Cloud Auditing Data Federation (CADF) standard. See [Auditing events for IBM Analytics Engine serverless instances](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-at_events-serverless).\n\n\n\nNetezza\n\n\n\n* How do I sign up for Netezza Performance Server?\n\n[Create a free IBM Cloud account](https://cloud.ibm.com/registration?target=%2Fcatalog%2Fservices%2Fdb2-warehouse). When you have the account, you can provision a Netezza Performance Server instance directly through the IBM Cloud\u00ae catalog.\nFor more information, see [Getting started with Netezza Performance Server](https://cloud.ibm.com/docs/netezza?topic=netezza-getstarted).\n* How do I generate or view credentials for my Netezza Performance Server instance?\n\nTo generate credentials, follow the steps:\n\n\n\n1. Log in to [IBM Cloud](https://cloud.ibm.com/) account.\n2. Go to Resource list > Services and Software > Databases.\n3. Click on your Netezza Performance Server instance.\nYou are now on the Service instance details page.\n4. Go to the Service Credentials tab.\n5. Click New Credentials.\n6. Type a name to assing to your credentials.\n7. Select the IAM role that was assigned to you to manage the instance.\n8. Click Add.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_05567-7-1922", "score": 19.369947834993745, "text": "\nIAM and Activity Tracker action by API method \n\nWhen you use IBM Cloud\u00ae Kubernetes Service such as through the command line or console, the service calls application programming interface (API) methods to complete your requests. In IBM Cloud IAM, each API operation is associated with an IAM action that the user must have an access role to use the API operation. You can keep track of the requests that you make with an IBM Cloud Activity Tracker instance.\n\nReview the following list of IBM Cloud Identity and Access Management (IAM) actions and IBM Cloud Activity Tracker events that correspond to each API method in IBM Cloud Kubernetes Service.\n\nFor more information, see the following topics.\n\n\n\n* [IBM Cloud Kubernetes Service API docs](https://containers.cloud.ibm.com/global/swagger-global-api//)\n* [User access permissions](https://cloud.ibm.com/docs/containers?topic=containers-access_reference)\n* [IBM Cloud Activity Tracker events](https://cloud.ibm.com/docs/containers?topic=containers-at_events).\n\n\n\n\n\n Account \n\nReview the following account API methods, their corresponding actions in IBM Cloud IAM, and the events that are sent to IBM Cloud Activity Tracker for IBM Cloud Kubernetes Service.\n\n\n\nAccount API methods, IAM actions, and Activity Tracker events.\n\n API Method Description IAM action for the API Event sent to Activity Tracker \n\n DELETE/v1/credentials Remove IBM Cloud infrastructure account credentials from your IBM Cloud Kubernetes Service account. containers-kubernetes.cluster.create containers-kubernetes.account.delete \n GET/v1/addons List available add-ons that you can enable in a cluster. N/A N/A \n GET/v1/config List configuration values for your IBM Cloud account. containers-kubernetes.cluster.read N/A \n GET/v1/credentials View the IBM Cloud infrastructure account credentials that are set for your IBM Cloud Kubernetes Service account. containers-kubernetes.cluster.read N/A", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-api-at-iam"}, {"document_id": "ibmcld_10041-7-1932", "score": 19.219565157326624, "text": "\nIAM and Activity Tracker action by API method \n\nWhen you use Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae such as through the command line or console, the service calls application programming interface (API) methods to complete your requests. In IBM Cloud IAM, each API operation is associated with an IAM action that the user must have an access role to use the API operation. You can keep track of the requests that you make with an IBM Cloud Activity Tracker instance.\n\nReview the following list of IBM Cloud Identity and Access Management (IAM) actions and IBM Cloud Activity Tracker events that correspond to each API method in Red Hat OpenShift on IBM Cloud.\n\nFor more information, see the following topics.\n\n\n\n* [Red Hat OpenShift on IBM Cloud API docs](https://containers.cloud.ibm.com/global/swagger-global-api//)\n* [User access permissions](https://cloud.ibm.com/docs/openshift?topic=openshift-access_reference)\n* [IBM Cloud Activity Tracker events](https://cloud.ibm.com/docs/openshift?topic=openshift-at_events).\n\n\n\n\n\n Account \n\nReview the following account API methods, their corresponding actions in IBM Cloud IAM, and the events that are sent to IBM Cloud Activity Tracker for Red Hat OpenShift on IBM Cloud.\n\n\n\nAccount API methods, IAM actions, and Activity Tracker events.\n\n API Method Description IAM action for the API Event sent to Activity Tracker \n\n DELETE/v1/credentials Remove IBM Cloud infrastructure account credentials from your Red Hat OpenShift on IBM Cloud account. containers-kubernetes.cluster.create containers-kubernetes.account.delete \n GET/v1/addons List available add-ons that you can enable in a cluster. N/A N/A \n GET/v1/config List configuration values for your IBM Cloud account. containers-kubernetes.cluster.read N/A \n GET/v1/credentials View the IBM Cloud infrastructure account credentials that are set for your Red Hat OpenShift on IBM Cloud account. containers-kubernetes.cluster.read N/A", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-api-at-iam"}, {"document_id": "ibmcld_13877-10119-11951", "score": 19.19950790049733, "text": "\nSet the name to a unique value, such as <your-initials>-secure-file-upload.\n2. Set Resiliency to Regional.\n3. Set Location to the same location where you created the Key Protect service instance.\n4. Set Storage class to Standard\n\n\n\n3. Under Service integrations (optional) / Encryption, enable Key management\n\n\n\n1. Select the Key Protect service instance created earlier by clicking on Use existing instance\n2. Select secure-file-storage-root-enckey as the key and click Associate key.\n\n\n\n4. Under Service integrations (optional) / Monitoring & Activity tracking, enable Activity tracking to have events recording in Activity Tracker.\n\n\n\n1. After clicking the checkmark the service information for the Activity Tracker instance in the region should be shown.\n2. Now, enable Track Data events and select read & write as Data Events.\n\n\n\n5. Click Create bucket.\n\n\n\n\n\n\n\n\n\n A database map relationships between users and their files \n\nThe IBM Cloudant database will contain metadata for all files uploaded from the application.\n\n\n\n1. Create an instance of [IBM Cloudant](https://cloud.ibm.com/catalog/services/cloudant) service.\n\n\n\n1. Select Cloudant as the offering.\n2. Select a Multitenant environment and a region same as the previous services.\n3. Set the name to secure-file-storage-cloudant.\n4. Use the same resource group as for the previous services.\n5. Set Authentication method to IAM.\n6. Click Create.\n\n\n\n2. Back to the Resource List, locate the newly created service and click on it. Note: You will need to wait until the status changes to Active.\n\n\n\n1. Under Service credentials, create New credential.\n2. Set the name to secure-file-storage-cloudant-acckey.\n3. Set Role to Manager.\n4. Keep the default values for the the remaining fields.\n5. Click Add.\n\n\n\n3. Expand the newly created credentials and make note of the values.", "title": "", "source": "https://cloud.ibm.com/docs/tutorials?topic=solution-tutorials-cloud-e2e-security"}, {"document_id": "ibmcld_12385-3409-5426", "score": 18.70556709030813, "text": "\nIf you accidentally assign a secret to the wrong secret group, or if you don't want a secret to belong to the default secret group, delete the secret and create a new one.\n2. Optionally, use secret groups to allow privileged access to specific resources in your account.\n\nSecret groups can be used to grant direct access to resources that otherwise wouldn't be possible through IAM. For example, assume that User A has no access to Service A in IAM. If you create an IAM access policy that assigns User A to Secret Group A, and Secret Group A contains an [IAM credential](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) with a service ID that gives access to Service A, then you grant User A access to Service A. In this scenario, Secret Group A becomes a gateway to Service A, even if a restriction exists in IAM. Keep in mind that with this scenario it is possible to grant access to a resource unintentionally. Review your configuration carefully to ensure that your secret group assignments do not override your IAM access policies accidentally.\n3. Audit your secret groups regularly and remove them when they're no longer needed.\n\nGrant only the minimum access that is required, and delete a secret group when it is no longer needed.\n\nTo delete a secret group, it must be empty. If you need to remove a secret group that contains secrets, you must first [delete the secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-delete-secrets) that are part of the group.\n\n\n\n\n\n\n\n Track your related secrets by adding labels \n\nAdd labels so that you can further search by and categorize the secrets in your instance. When you use a consistent labeling schema, you can easily group similar secrets together.\n\n\n\n1. Label your secrets by using a consistent schema, such as creating labels to differentiate which secrets are used for a specific purpose. To add labels by using the Secrets Manager UI, go to the Secrets page, and then select a secret to edits its details.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets"}, {"document_id": "ibmcld_12613-7-2387", "score": 18.605920439562826, "text": "\nIBM Cloud IAM roles \n\nAll services that are organized in a resource group in your account are managed by using IBM Cloud Identity and Access Management (IAM). Account owners are automatically assigned the account administrator role. As the account administrator, you can assign and manage access for users, create resource groups, create access groups, create trusted profiles, view billing details and track usage, and create service instances. You provide access for users, service IDs, access groups, and trusted profiles by creating policies that set a target for the subject of the policy to access and a role that defines what type of access that is allowed.\n\n\n\n IAM roles \n\nYou can manage and define access based on specific roles for users and resources in your account.\n\n\n\n* Platform management roles cover a range of actions, including the ability to create and delete instances, manage aliases, bindings, and credentials, and manage access. The platform roles are administrator, editor, operator, viewer. Platform management roles also apply to [account management services](https://cloud.ibm.com/docs/account?topic=account-account-servicesaccount-management-actions-roles) that enable users to invite users, manage service IDs, access policies, catalog entries, and track billing and usage depending on their assigned role on an account management service.\n* Service access roles define a user or service\u2019s ability to perform actions on a service instance, such as accessing the console or performing API calls. The most common service access roles are manager, writer, and reader. Each service maps particular actions for working with the service to each of these roles.\n\nYou might not see all of the roles that are listed here as options when you assign policies in the UI because only the roles available for the service that you chose are displayed. For more information on what roles are enabled and what actions each access role allows for each service, see the documentation for that service.\n* Custom roles for a service can be created on the IAM Roles page by the account owner or a user assigned the administrator role on the role management service.\n\nYou can review the available roles and associated actions for a particular service by going to the [Roles](https://cloud.ibm.com/iam/roles) page, and selecting the service that you want to learn more about.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-userroles"}, {"document_id": "ibmcld_09185-0-1954", "score": 18.10518030884498, "text": "\n\n\n\n\n\n\n  Setting up the API \n\nIBM\u00ae Key Protect for IBM Cloud\u00ae provides a REST API that can be used with any programming language to store, retrieve, and generate encryption keys.\n\n\n\n  Retrieving your IBM Cloud credentials \n\nTo work with the API, you need to generate your service and authentication credentials.\n\nTo gather your credentials:\n\n\n\n1.  [Generate an IBM Cloud IAM access token](https://cloud.ibm.com/docs/key-protect?topic=key-protect-retrieve-access-token).\n2.  [Retrieve the instance ID that uniquely identifies your Key Protect instance](https://cloud.ibm.com/docs/key-protect?topic=key-protect-retrieve-instance-ID).\n\n\n\n\n\n\n\n  Forming your API request \n\nWhen you make an API call to the service, structure your API request according to how you initially provisioned your instance of Key Protect.\n\nTo build your request, pair a [service endpoint](https://cloud.ibm.com/docs/key-protect?topic=key-protect-regionsservice-endpoints) with the appropriate authentication credentials. For example, if you created a Key Protect instance for the us-south region, use the following endpoint and API headers to browse keys in your service:\n\n$ curl -X GET     \"https://us-south.kms.cloud.ibm.com/api/v2/keys\"     -H \"accept: application/vnd.ibm.collection+json\"     -H \"authorization: Bearer <IAM_token>\"     -H \"bluemix-instance: <instance_ID>\"\n\nReplace <access_token> and <instance_ID> with your retrieved service and authentication credentials.\n\nWant to track your API requests in case something goes wrong? When you include the -v flag as part of curl request, you get a correlation-id value in the response headers. You can use this value to correlate and track the request for debugging purposes.\n\n\n\n\n\n  What's next \n\nYou're all set to start managing your encryption keys in Key Protect. To find out more about programmatically managing your keys, [check out the Key Protect API reference doc](https://cloud.ibm.com/apidocs/key-protect).\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-set-up-api"}, {"document_id": "ibmcld_00891-3543-5656", "score": 18.023642593625397, "text": "\nManage access to toolchains in resource groups and their associated IBM-hosted tools, except for Git Repos and Issue Tracking. N/A Grant, revoke, and manage access to toolchains by using IBM Cloud Identity and Access Management (IAM). For more information about access management, see [Managing user access to toolchains in resource groups](https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-toolchains-iam-security). \n Manage the Continuous Delivery service's access to third-party tools that are integrated into toolchains. N/A Add, update, or delete third-party tool integration configurations (including access credentials for tool integrations) in toolchains. For more information about working with tool integrations, see [Configuring tool integrations](https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-integrations). \n Manage access to repos in Git Repos and Issue Tracking. N/A From the Settings > Members page in the Git Repos and Issue Tracking dashboard, manage project members and role permissions. \n Manage all other access to third-party tools that are integrated with Continuous Delivery. N/A Manage access by using the capabilities that are provided by the third-party tools. \n\n\n\n\n\n\n\n Security and regulation compliance \n\nSecurity and regulation compliance includes tasks such as security controls implementation and compliance certification.\n\n\n\nTable 4. Responsibilities for security and regulation compliance\n\n Task IBM responsibilities Your responsibilities \n\n Meet security and compliance objectives Provide a secure Continuous Delivery service that complies with key standards. For more information about data security, see [How do I know that my data is safe?](https://cloud.ibm.com/docs/overview/terms-of-use?topic=overview-security) Secure your workloads and data. Integrate tools into your toolchains that satisfy your security and compliance requirements. To learn more about securing your cloud apps, see [Security to safeguard and monitor your cloud apps](https://www.ibm.com/cloud/garage/architectures/securityArchitecture).", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-responsibilities-cd"}, {"document_id": "ibmcld_12518-7-1970", "score": 17.925986669793996, "text": "\nAuditing events for account, IAM, catalog management \n\nAs a security officer, auditor, or manager, you can use the IBM Cloud\u00ae Activity Tracker service to track how users and applications interact with an IBM Cloud\u00ae account, the IBM Cloud catalog, private catalogs, and with IBM Cloud Identity and Access Management (IAM).\n\nTo get started with monitoring your user's actions, see [Activity Tracker](https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-getting-startedgetting-started).\n\n\n\n Account management events \n\nYou can track the following events:\n\n\n\n* Managing an account by creating an account, updating information, activating an account, or creating a Subscription account\n* Adding or removing users\n* Creating organizations\n\n\n\n\n\n\n\n IAM events \n\nYou must create an instance of the Activity Tracker service in the Frankfurt (eu-de) region to start tracking IAM events. When you create the instance, you can track the following events:\n\n\n\n* Managing access groups by creating and deleting groups or adding and removing users\n* Creating, updating, or deleting service IDs\n* Creating, updating, or deleting API keys\n* Creating, updating, or deleting access policies\n* Creating, updating, or deleting trusted profiles\n* Logging in to IBM Cloud by using an API key, authorization code, passcode, password, or an API key associated with a service ID\n* Logging in to IBM Cloud by using a trusted profile. For more information, see [Monitoring login sessions for trusted profiles](https://cloud.ibm.com/docs/account?topic=account-trusted-profile-monitor).\n\n\n\nFor more information, see [IAM events](https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-at_events_iam).\n\n\n\n\n\n Catalog management events \n\nYou can track the following events:\n\n\n\n* Viewing or updating account settings\n* Viewing or updating a catalog\n* Listing all products in a catalog\n* Listing all products in an account\n* Creating, updating, viewing, or deleting a product", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-acct_iam_tracking"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10817-7-1802", "score": 61.486500260060666, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10852-43319-44485", "score": 49.975394735860014, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10817-1342-3184", "score": 48.08954199129251, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-7-1743", "score": 46.31133471483602, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_02772-4213-5899", "score": 45.149794226698226, "text": "\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}, {"document_id": "ibmcld_04518-1426-3052", "score": 34.30227374338302, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10852-44214-45420", "score": 32.48804611831317, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_12332-1034-2510", "score": 30.209369788369937, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}, {"document_id": "ibmcld_10817-2884-4620", "score": 29.092765550689734, "text": "\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in /Library/Developer/Xcode/DerivedData/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_02772-1628-3402", "score": 27.932225993556177, "text": "\nFollowing registration, your users authenticate by using either the OAuth2 authorization code or resource owner password[authorization grant](https://datatracker.ietf.org/doc/html/rfc6749section-1.3) flows to authenticate users.\n\n\n\n\n\n Dynamic client registration \n\n\n\n1. A user triggers a request by the client application to the App ID SDK.\n2. If your app is not registered as a mobile client yet, the SDK initiates a dynamic registration flow.\n3. On a successful registration, App ID returns your installation-specific client ID.\n\n\n\n\n\n\n\n Authorization flow \n\nZoom\n\n![App ID mobile request flow](https://cloud.ibm.com/docs-content/v1/content/27ecaa7a29890634603881a8e64789974a29916b/appid/images/mobile-flow.svg)\n\nFigure 1. App ID mobile request flow\n\n\n\n1. The App ID SDK starts the authorization process by using the App ID /authorization endpoint.\n2. The login widget is displayed to the user.\n3. The user authenticates by using one of the configured identity providers.\n4. App ID returns an authorization grant.\n5. The authorization grant is exchanged for access, identity, and refresh tokens from the App ID /token endpoint.\n\n\n\n\n\n\n\n\n\n Configuring your mobile app with the App ID SDKs \n\nGet started with the App ID SDKs.\n\n\n\n Before you begin \n\nYou need the following information:\n\n\n\n* An App ID instance\n* Your instance's tenant ID. This can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07037-6201-7365", "score": 29.550279277570418, "text": "\nFrom the web browser location field, scroll to the end of the URL. Look for the collections/ section, and then copy the ID that is displayed after it. For example, in the URL /collections/5a525eb7-b175-3820-0000-017d00f0fcd1/activity, the collection ID is 5a525eb7-b175-3820-0000-017d00f0fcd1.)\n\n\n\n* If the problem has to do with documents failing to load, provide the following information if known:\n\n\n\n* What kind of documents are being uploaded (such as PDF, Json, CSV). Was optical character recognition (OCR) enabled for the collection?\n* How were the documents loaded into the collection? (using the API, from the product UI, data source connector)\n* Did you identify fields in the collection by using Smart Document Understanding? If so, what type of SDU model was applied to the collection (user-trained or pretrained)?\n* What enrichments were applied to the collection?\n\n\n\n* If the problem is related to a particular document (of a small set of documents), provide the document_id of the document, if known. You can share example documents if they might be helpful.\n* If the problem is related to querying documents, describe the kind of query being used.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-get-help"}, {"document_id": "ibmcld_07569-8576-9701", "score": 28.687729943013217, "text": "\nevent-notifications.00003E ERROR Notification dispatch failed due to the authentication error for device id <device_id> and platform <platform_name>. \n event-notifications.00004E ERROR Slack returned with an error response: <error_message> with the status code: 401 \n event-notifications.00005E ERROR Notification dispatch failed due to the <'BadDeviceToken'> error for device id <device_id> and platform <platform_name>. \n event-notifications.00006E ERROR Microsoft teams API returned with an error response: Unauthorised with the status code: 401 \n\n\n\n\n\n\n\n Analyzing logs \n\n\n\n List logs generated by a service \n\nIf you want to view all the logs thar are being generated for a particular source, get the sourceID from the Event Notifications service dashboard and use the following query in Log Analysis:\n\nsourceID:<source_crn>\n\n\n\n\n\n List logs for a notification request \n\nIf you know the notification ID that is generated for a request from a service or source to the Event Notifications service, use the following query in Log Analysis to list all logs for that particular notification ID:\n\nnotificationID:<notification Id>", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-logging"}, {"document_id": "ibmcld_00460-11932-13842", "score": 28.48226487755294, "text": "\nMultiple queries\n: The ability to submit multiple queries against a view by using the POST to /{db}/_design/{ddoc}/_view/{view} with the ?queries option was replaced by the new queries endpoint. The same is true of the _all_docs and _design_docs endpoints. Specify a keys object when you POST to these endpoints.\n\ndisk_size and data_size fields\n: The disk_size and data_size fields were retired from the database information object that is returned by GET /{db}.\n\n/{db}/_changes feed\n: The /{db}/_changes feed immediately returns headers now, even when no changes are available. This process prevents client's from becoming blocked.\n\nNegative and noninteger heartbeat values\n: Negative and noninteger heartbeat values now return a 400 Bad Request response status code.\n\nSeparate proxies\n: Allow specifying separate proxies for both the source and target in a replication by using source_proxy and target_proxy keys.\n\nPOST view function\n: The POST view function now supports identical parameters and behavior as specified in the /{db}/_design/{ddoc}/_view/{view}, /{db}/_all_docs, and /{db}/_design_docs endpoints. You can supply query string parameters as keys in a JSON object in the body of the POST request.\n\nReplication errors\n: Replication \"info\" errors are now JSON objects. Previously, they were strings.\n\nReplication support\n: A compatibility change was made to support replication with future databases that contain per-document access control fields.\n\nWarning message\n: Add a warning to the _find endpoint if multiple document scans were required to generate a result.\n\n_find endpoint error\n: Fix a bug in the _find endpoint whereby an error would be returned if a document matched by a text index was deleted while the query was being processed.\n\n\n\n\n\n\n\n January 2020 \n\n\n\n 15 January 2020 \n\nThe following changes were made in build 8126:\n\nImprovements\n: Internal bug fixes.\n\nReplication error reports", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-classic-release-notes"}, {"document_id": "ibmcld_07098-22545-24101", "score": 28.32499616254065, "text": "\nYou can increase the maximum number of passages to return per document by specifying a higher number in the passages.max_per_document parameter.<-- </section \"id=\"section-passages_max-per-doc\" \"> --><-- </section \"id=\"section-passages\" \"> --><-- <section \"id=\"section-similar\" \"> --> similar Finds documents that are similar to documents that you identify as being of interest to you. To find similar documents, Discovery identifies the 25 most relevant terms from the original document and then searches for documents with similar relevant terms.If similar.enabled is true, you must specify the similar.document_ids field to include a comma-separated list of the documents of interest.In installed deployments, support for this parameter was added with the 4.6.0 release.<-- </section \"id=\"section-similar\" \"> --><-- <section \"id=\"section-table_retrieval\" \"> --> table retrieval If Table understanding]] is enabled in your collection, a natural_language_query finds tables with content or context that match a search query.Example query: curl -H \"Authorization: Bearer {token}\" 'https://{hostname}/{instance_name}/v2/projects/{project_id}/collections/{collection_id}/query?version=2019-11-29&natural_language_query=interest%20appraised&table_results=true'\nThe JSON that is returned from the query has the following format: {\n\"matching_results\": 1,\n\"session_token\": \"1_FDjAVkn9SW6oH9y5_9Ek3KsNFG\",\n\"results\":\n{}\n]\n{\n\"table_results\":\n{\n\"table_id\": \"e883d3df1d45251121cd3d5aef86e4edc9658b21\",\n\"source_document_id\": \"c774c3df0c90255191cc0d4bb8b5e8edc6638d96\",", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-parameters"}, {"document_id": "ibmcld_00539-4998-6652", "score": 26.748285525616705, "text": "\nWhen you execute a query, passing execution_stats: true as an extra parameter forces IBM Cloudant to enumerate the number of documents it scanned in performing the query, for example:\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"sort\": [\"date\"],\n\"limit\": 10,\n\"execution_stats\": true\n}\n\nThe returned data now includes an extra JSON object:\n\n{\n...\n\"execution_stats\": {\n\"total_keys_examined\": 0,\n\"total_docs_examined\": 1000000,\n\"total_quorum_docs_examined\": 0,\n\"results_returned\": 2,\n\"execution_time_ms\": 4400.699\n}\n}\n\nThe ratio between total_docs_examined and results_returned is key here: a high value indicates that too many documents are being scanned per document that is returned.\n\nFor more information, see [Blog post on Optimizing IBM Cloudant Queries](https://blog.cloudant.com/2020/04/24/Optimising-Cloudant-Queries.html).\n\n\n\n\n\n Which IBM Cloudant Query operators defeat the use of an index? \n\nAny of the [combination operators](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-queryoperators) other than $and can make a query do a full database scan without the help of a secondary index. For example, if an $or operator is used, then no secondary index can be used to assist the query. If in doubt, use the [POST /{db}/_explain](https://cloud.ibm.com/apidocs/cloudant?code=javapostexplain) endpoint to check that an index is used, and the execution_stats: true parameter to measure the efficiency of each query.\n\nFor a type=json index to be used to support a query, it must match the fields that are used in the selector and sort parameters. Comparison operators might be used on the last element to perform range queries.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-using-cloudant-query"}, {"document_id": "ibmcld_16273-10724-12629", "score": 25.484590187683274, "text": "\nTo create an step condition based on the HTTP status code, follow these steps:\n\n\n\n1. For the value you want to test, click Expression.\n2. In the expression field, type a dollar sign ($) to show the list of available variables.\n3. Select any variable that is a response value from the extension. (It doesn't matter which variable you select, as long as it is an extension response variable).\n\nThe expression is automatically updated to show a reference to the variable you selected, in the format ${step_xxx_result_y.body.variablename}. For example, if you selected a response variable called body.id, the reference might be ${step_596_result_1.body.id}.\n4. Inside the curly braces, ({}), edit this reference to remove .body.variablename. You should be left with something like ${step_596_result_1}.\n5. After the closing curly brace (}), add .status. The resulting reference identifies the status code returned from the call to the extension (for example, ${step_596_result_1}.status).\n\nFor more information about writing expressions, see [Writing expressions](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-expressions).\n6. Complete the expression by adding an operator and a comparison value, so the expression evaluates to a Boolean (true/false) value. For example, the following expression tests for HTTP status 408, which indicates a timeout error:\n\n${step_549_result_1}.status==408\n\n\n\n\n\n\n\n Debugging failures \n\nIf your calls to an extension are failing, you might want to debug the problem by seeing detailed information about what is being sent to and returned from the external API. To do this, you can use the extension inspector in the Preview pane:\n\n\n\n1. On the Actions page, or in the action editor, click Preview to open the Preview pane.\n\nYou cannot access the extension inspector from the assistant preview on the Preview page, which shows only what a customer would see.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-call-extension"}, {"document_id": "ibmcld_16304-7-2130", "score": 24.737447473254225, "text": "\nDynamic options \n\nAn options response presents customers with a list of choices to select from. You can use the dynamic setting to generate the list from options that might be different each time.\n\nDynamic options are generated based on the data stored in a variable, which must be available to the step asking the question. The source variable must contain an array of values, each of which represents one of the options that will be presented to the customer. The items in the array can be simple values such as strings or numbers (for example, [ \"Raleigh\", \"Boston\", \"New York\" ]) or compound JSON objects.\n\nA common scenario for dynamic options is when an array is returned from an external API that you call using a custom extension. For example, you might use a custom extension to retrieve a list of credit cards associated with a customer's account. You can then use dynamic options to ask the customer which card to use during the conversation. (For more information about custom extensions, see [Calling a custom extension](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-call-extension).)\n\nYour actions might also populate the source variable using expressions. For example, you might use a session variable to build a shopping cart containing items the customer has decided to purchase. An action for removing an item from the cart could then use dynamic options to show the items in the cart so the customer can select which one to remove. (For more information about using expressions for variable values, see [Using an expression to assign a value to a session variable](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-expressionsexpression-variable).)\n\n\n\n Defining dynamic options \n\nTo define a dynamic options customer response:\n\n\n\n1. In a step, click Define customer response.\n2. Choose the Options response type.\n3. Click the Dynamic toggle.\n4. In the Source variable field, choose the variable that contains the array that defines the dynamic options (for example, the variable containing the response from a custom extension that you called in a previous step).\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-dynamic-options"}, {"document_id": "ibmcld_15559-7-1698", "score": 24.635233865660922, "text": "\nInstance metadata API error codes \n\nAs covered in [Error handling](https://cloud.ibm.com/apidocs/vpc-metadataerror-handling), the VPC Instance Metadata API uses standard HTTP response codes to indicate the outcome of a request. For example, a 4xx-series response indicates a failure that the client must resolve. A 5xx-series response indicates a service failure.\n\nAdditionally, all 4xx and 5xx responses include a JSON error response object that provides additional information about the problem. This information includes a trace property whose value might be requested by IBM support when they troubleshoot the failure, and an errors array property that contains one or more specific errors that are related to the problem. Each item in the errors array uses the following JSON schema:\n\n\n\n* code - Error code string, such as invalid_value\n* message - Text string that describes the error message, for example, \"The value provided for the expires_in field must be between 5 and 3600.\"\n* more_info - If present, a link to the documentation about this error\n* target - For errors that return a target property in the response, review the subproperties for clues:\n\n\n\n* name of the problematic field, query parameter, or header\n* type of input where the problem was found, such as a field\n* value (if present) the problematic value within the field, query parameter, or header\n\n\n\n\n\nExample 400 JSON error response object:\n\n{\n\"errors\": [\n{\n\"code\": \"invalid_value\",\n\"message\": \"The expires_in field must not exceed 3600.\",\n\"more_info\": \"https://cloud.ibm.com/docs/vpc?topic=vpc-imd-configure-service\",\n\"target\": {\n\"name\": \"expires_in\",\n\"type\": \"field\",\n\"value\": \"7200\"\n}\n}\n],\n\"status_code\": 400,", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-instance-metadata-error-codes"}, {"document_id": "ibmcld_07037-3003-4984", "score": 24.595181635821575, "text": "\nFor example, in the URL /collections/5a525eb7-b175-3820-0000-017d00f0fcd1/activity, the collection ID is 5a525eb7-b175-3820-0000-017d00f0fcd1.)\n\n\n\n* If the problem has to do with documents failing to load, provide the following information if known:\n\n\n\n* What kind of documents are being uploaded (such as PDF, Json, CSV). Was optical character recognition (OCR) enabled for the collection?\n* How were the documents loaded into the collection? (using the API, from the product UI, data source connector)\n* Did you identify fields in the collection by using Smart Document Understanding? If so, what type of SDU model was applied to the collection (user-trained or pretrained)?\n* What enrichments were applied to the collection?\n\n\n\n* If the problem is related to a particular document (of a small set of documents), provide the document_id of the document, if known. You can share example documents if they might be helpful.\n* If the problem is related to querying documents, describe the kind of query being used.\n\n\n\n\n\n\n\n\n\n IBM Cloud Pak for Data Contacting IBM Support for installed deployments \n\nInstalled deployments are deployment that you provision on IBM Cloud Pak for Data.\n\nYou can get help by opening a case from IBM Support from [IBM Support](https://www.ibm.com/mysupport/s/topic/0TO50000000IYkUGAW/cloud-pak-for-data).\n\nBe ready to share the following information with IBM Support:\n\n\n\n Account information \n\n\n\n* Account name or customer name.\n* Business impact so IBM Support understands the urgency of the issue and can prioritize it.\n* Case information for any related cases or a parent case.\n* Software versions of both the Discovery service version and IBM Cloud Pak for Data version.\n* Relevant details about configuration choices that were made during installation and deployment.\n\n\n\n\n\n\n\n Problem description \n\n\n\n* What outcome were you expecting and what happened?\n* Message text that is displayed when the error occurs, especially the document ID, if specified.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-get-help"}, {"document_id": "ibmcld_00518-6367-8480", "score": 24.475464040164404, "text": "\n\"language\": \"javascript\"\n}\n\nWhen this design document is saved, IBM Cloudant completely invalidates the old index and begins building the new index from scratch, iterating over every document in turn. As with the original build, the time that it takes depends on how many documents are in the database. The build also blocks incoming queries on that view until it's complete.\n\nBut there's a problem...\n\nIf you have an application that is accessing this view in real time, then you might experience a deployment dilemma:\n\n\n\n* Version 1 of the code, which relied on the original design document, might no longer work because the old view is invalidated.\n* Version 2 of the code uses the new design document. This version can't be released immediately because the new view isn't finished building yet. Remember the build process takes longer if the database includes many documents.\n* A more subtle problem that affects the code is that versions 1 and 2 expect different result data from the view: Version 1 expects a list of matching documents, while version 2 expects a 'reduced' count of results.\n\n\n\n\n\n\n\n Coordinating changes to design documents \n\nYou can deal with this change control problem in two ways.\n\n\n\n Versioned design documents \n\nOne solution is to use versioned design document names:\n\n\n\n* The code is initially written to use a view called _design/fetchv1.\n* When you release a new version, you create a new view that is called _design/fetchv2, and query the view to ensure that it builds.\n* IBM Cloudant polls _active_tasks until the work of building the new index is complete.\n* Now, you're ready to release the code that depends on the second view.\n* Delete _design/fetchv1 when we're sure it's no longer needed.\n\n\n\nUsing versioned design documents is a simple way to manage change control in your design documents, but you must remember to remove the older versions later.\n\n\n\n\n\n Move and switch design documents \n\nAnother approach relies on the fact that IBM Cloudant recognizes when it has two identical design documents, and doesn't waste time and resources to rebuild views that it already has.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-design-document-management"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00028-7-1916", "score": 18.393770513477175, "text": "\nCreating a library set for other packages or file download \n\nIf you want to customize your instance by adding libraries to a library set that you fetch from sources other than through the conda or pip repositories, you should use script based customization.\n\nIf you are only using a set of JAR files or PY files, you should use the \"application_details\" > \"conf\" > \"spark.submit.pyFiles\" or \"application_details\" > \"jars\" arguments in your Spark application submission payload and only create a library set if this method doesn't work for you. For more information, see [Submitting a Spark application](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-spark-app-rest-apispark-submit-app)\n\nWith script based customization, you create a Python script using the module naming convention expected by IBM Analytics Engine. Also, you need to implement a Python function that acts as the executable entry point to your script. In this script, you can add your own logic for downloading the libraries and placing them in a predesignated directory, which is /home/spark/shared/user-libs/<libraryset_name>/custom/<subdir_if_applicable>, so that they become part of the library set and get stored for later consumption in your application.\n\n\n\n Creating a library set using script based customization \n\nPerform these steps to create a library set using script based customization:\n\n\n\n1. Create a Python file named customization_script.py. Analytics Engine's customization component looks for a Python module with this name.\n2. In your customization_script.py, implement a function called customize(<install_path>, <params>), where <install_path> is the predesignated location where the libraries are downloaded to, namely /home/spark/shared/user-libs/<libraryset_name>/custom/<subdir_if_applicable>. You can't change this path. <params> is a list of the parameters required by the customization script.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-cust-script"}, {"document_id": "ibmcld_06726-8970-10659", "score": 17.828385878174366, "text": "\n[The Truck Tracker Zoom View](https://cloud.ibm.com/docs-content/v1/content/c1b02d6157702384a9668d8c58bb951e69117793/databases-for-redis/includes/cloud-databases/includes/cloud-databases/images/trucktrackerzoom.png)\n\nFigure 4. Single-Truck View\n\n\n\n\n\n\n\n What you just did \n\n\n\n The build.sh script \n\nThe build.sh script does a number of things:\n\n\n\n1. It builds a docker image for each of the services you need. The producer, consumers and web application are all in different folders. Each folder has its own simple Dockerfile file that is used by the script to create a container image, which is then uploaded to the IBM Container Registry.\n2. It creates a bunch of kubernetes secrets with all the credentials that are going to be needed to access the different IBM services (IBM Cloudant, Redis and Event Streams).\n3. It deploys the application code (and the secretes) to the Red Hat OpenShift on IBM Cloud cluster using the instructions contained in the deployment.yml script.\n\n\n\n\n\n\n\n The deployment.yml script \n\nThis script tells Openshift what to deploy to the machines in the Openshift cluster. In our case this is:\n\n\n\n1. Data producers (trucktrackerproducer).\n2. Data consumers (trucktrackerredisconsumer and trucktrackercloudantconsumer)\n3. Web application (trucktrackerweb)\n\n\n\nIn all cases, they pull an image from the container registry and get fed some environment variables with the credentials they require to access external services.\n\n\n\n\n\n The Truck Tracker system \n\nThe Truck Tracker system is a set of simple Node.js scripts that use four main packages:\n\n\n\n1. [@ibm-cloud/cloudant](https://github.com/IBM/cloudant-node-sdk) to connect to IBM Cloudant and read/write data.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-redis?topic=databases-for-redis-truck-tracker-ibmcloud"}, {"document_id": "ibmcld_06532-8974-10665", "score": 17.828385878174366, "text": "\n[The Truck Tracker Zoom View](https://cloud.ibm.com/docs-content/v1/content/ec83e0c9f915f4acf715222aaa5b8387c028200c/databases-for-mongodb/includes/cloud-databases/includes/cloud-databases/images/trucktrackerzoom.png)\n\nFigure 4. Single-Truck View\n\n\n\n\n\n\n\n What you just did \n\n\n\n The build.sh script \n\nThe build.sh script does a number of things:\n\n\n\n1. It builds a docker image for each of the services you need. The producer, consumers and web application are all in different folders. Each folder has its own simple Dockerfile file that is used by the script to create a container image, which is then uploaded to the IBM Container Registry.\n2. It creates a bunch of kubernetes secrets with all the credentials that are going to be needed to access the different IBM services (IBM Cloudant, Redis and Event Streams).\n3. It deploys the application code (and the secretes) to the Red Hat OpenShift on IBM Cloud cluster using the instructions contained in the deployment.yml script.\n\n\n\n\n\n\n\n The deployment.yml script \n\nThis script tells Openshift what to deploy to the machines in the Openshift cluster. In our case this is:\n\n\n\n1. Data producers (trucktrackerproducer).\n2. Data consumers (trucktrackerredisconsumer and trucktrackercloudantconsumer)\n3. Web application (trucktrackerweb)\n\n\n\nIn all cases, they pull an image from the container registry and get fed some environment variables with the credentials they require to access external services.\n\n\n\n\n\n The Truck Tracker system \n\nThe Truck Tracker system is a set of simple Node.js scripts that use four main packages:\n\n\n\n1. [@ibm-cloud/cloudant](https://github.com/IBM/cloudant-node-sdk) to connect to IBM Cloudant and read/write data.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-mongodb?topic=databases-for-mongodb-truck-tracker-ibmcloud"}, {"document_id": "ibmcld_16729-139037-140928", "score": 17.733028363743003, "text": "\nIn this tutorial, you learn how to create and deploy a scalable Java Spring application. This scalable web app offers a one-click option to create an IBM Cloud\u00ae Schematics workspace with your choice of preconfigured Terraform templates. The Terraform templates deploy your app to IBM Cloud with options for the deployment target (Kubernetes or Red Hat\u00ae OpenShift\u00ae) and the DevOps toolchain pipeline structure.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 45 minutes\n* 2023-03-09\n\n\n\n[Creating an IBM Cloud Satellite environment on AWS by using scripts](https://cloud.ibm.com/docs/apps?topic=apps-tutorial-trysat)Creating an IBM Cloud Satellite environment on AWS by using scripts\n\nThis tutorial and set of scripts provide a mostly automated way to set up an IBM Cloud Satellite location and Red Hat OpenShift cluster on Amazon Web Services (AWS). This is not a production-ready solution, but it provides a useful tool for proof-of-concepts, learning, and experimenting.\n\nSchematics Red Hat OpenShift on IBM Cloud\n\n+4\n\nRed Hat OpenShift on IBM Cloud,Kubernetes service,Continuous Delivery,Creating apps\n\n\n\n* 1.5 hours\n* 2022-02-23\n\n\n\n[Part 4: Set up a Continuous Compliance (CC) toolchain](https://cloud.ibm.com/docs/devsecops?topic=devsecops-tutorial-cc-toolchain)Part 4: Set up a Continuous Compliance (CC) toolchain\n\nThis tutorial is part 4 of a 4-part tutorial series where you learn IBM Cloud\u00ae DevSecOps best practices by using a complete reference implementation that is available as a service and powered by IBM Cloud\u00ae Continuous Delivery. In part 4 of this tutorial series, you use the toolchain template for continuous compliance (CC) to ensure that your deployed artifacts and their source repositories are always compliant.\n\nKubernetes service Continuous Delivery\n\n+1\n\nDevSecOps\n\n\n\n* 1 hour", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_06472-9194-10955", "score": 17.607623112220036, "text": "\nSingle-Truck View\n\n\n\n\n\n\n\n What you just did \n\n\n\n The build.sh script \n\nThe build.sh script does a number of things:\n\n\n\n1. It builds a docker image for each of the services you need. The producer, consumers and web application are all in different folders. Each folder has its own simple Dockerfile file that is used by the script to create a container image, which is then uploaded to the IBM Container Registry.\n2. It creates a bunch of kubernetes secrets with all the credentials that are going to be needed to access the different IBM services (IBM Cloudant, Redis and Event Streams).\n3. It deploys the application code (and the secretes) to the Red Hat OpenShift on IBM Cloud cluster using the instructions contained in the deployment.yml script.\n\n\n\n\n\n\n\n The deployment.yml script \n\nThis script tells Openshift what to deploy to the machines in the Openshift cluster. In our case this is:\n\n\n\n1. Data producers (trucktrackerproducer).\n2. Data consumers (trucktrackerredisconsumer and trucktrackercloudantconsumer)\n3. Web application (trucktrackerweb)\n\n\n\nIn all cases, they pull an image from the container registry and get fed some environment variables with the credentials they require to access external services.\n\n\n\n\n\n The Truck Tracker system \n\nThe Truck Tracker system is a set of simple Node.js scripts that use four main packages:\n\n\n\n1. [@ibm-cloud/cloudant](https://github.com/IBM/cloudant-node-sdk) to connect to IBM Cloudant and read/write data.\n2. [Redis](https://www.npmjs.com/package/redis) to connect to the Redis instance and read/write data.\n3. [kafkajs](https://www.npmjs.com/package/kafkajs) to connect to the Event Streams instance.\n4. [Express](https://expressjs.com/) to enable a simple web server that allows interaction with the data.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-etcd?topic=databases-for-etcd-truck-tracker-ibmcloud"}, {"document_id": "ibmcld_06667-9212-10973", "score": 17.607623112220036, "text": "\nSingle-Truck View\n\n\n\n\n\n\n\n What you just did \n\n\n\n The build.sh script \n\nThe build.sh script does a number of things:\n\n\n\n1. It builds a docker image for each of the services you need. The producer, consumers and web application are all in different folders. Each folder has its own simple Dockerfile file that is used by the script to create a container image, which is then uploaded to the IBM Container Registry.\n2. It creates a bunch of kubernetes secrets with all the credentials that are going to be needed to access the different IBM services (IBM Cloudant, Redis and Event Streams).\n3. It deploys the application code (and the secretes) to the Red Hat OpenShift on IBM Cloud cluster using the instructions contained in the deployment.yml script.\n\n\n\n\n\n\n\n The deployment.yml script \n\nThis script tells Openshift what to deploy to the machines in the Openshift cluster. In our case this is:\n\n\n\n1. Data producers (trucktrackerproducer).\n2. Data consumers (trucktrackerredisconsumer and trucktrackercloudantconsumer)\n3. Web application (trucktrackerweb)\n\n\n\nIn all cases, they pull an image from the container registry and get fed some environment variables with the credentials they require to access external services.\n\n\n\n\n\n The Truck Tracker system \n\nThe Truck Tracker system is a set of simple Node.js scripts that use four main packages:\n\n\n\n1. [@ibm-cloud/cloudant](https://github.com/IBM/cloudant-node-sdk) to connect to IBM Cloudant and read/write data.\n2. [Redis](https://www.npmjs.com/package/redis) to connect to the Redis instance and read/write data.\n3. [kafkajs](https://www.npmjs.com/package/kafkajs) to connect to the Event Streams instance.\n4. [Express](https://expressjs.com/) to enable a simple web server that allows interaction with the data.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-truck-tracker-ibmcloud"}, {"document_id": "ibmcld_09500-1577-3261", "score": 17.467993378871306, "text": "\nPlease see [Running SQL Scripts in Production](https://cloud.ibm.com/docs/mas-ms?topic=mas-ms-supportrunning-sql-scripts) for details.\n\n\n\n\n\n\n\n Manage Application \n\nNo Java extensions are supported. It is assumed the Manage auomation scripting capability will be used for these types of extensions. Existing Maximo customers who have Java extensions will need to move these functions into automation scripts within the application. See link above for further details\n\n\n\n\n\n LA Fixes \n\nLA (Limited Availability) aka \"one off\" or \"hot\" fixes are the customer's responsibility to manage. Please see [Maintenance](https://cloud.ibm.com/docs/mas-ms?topic=mas-ms-maintenancelafixes) section for details.\n\n\n\n\n\n 3rd Party Applications \n\nMaximo Application Suite Dedicated will not host or support any 3rd party applications. 3rd Party applications hosted outside the MAS-Dedicated environment can be integrated to applications with the Suite provided they follow standard integration protocols.\n\n\n\n\n\n Access \n\nClients will not have access to the operating system, file system or overall system administration of the Suite. DBAdmin access or direct updating of the database is not allowed.\n\n\n\n\n\n MAS Administrator Functions \n\nDirect access to the clusters is not available. Changes required must be submitted using an IBM support case system and the IBM SRE team will execute.\n\n\n\n\n\n AppConnect \n\nAppConnect is included as an entitlement with the Maximo Application Suite, but the Dedicated Service does not implement or support this within the MAS-Dedicated environment. The client is responsible for implementing AppConnect or beginning with version MAS v8.7, AppConnect SaaS will be supported.", "title": "", "source": "https://cloud.ibm.com/docs/mas-ms?topic=mas-ms-limitations-exclusions"}, {"document_id": "ibmcld_09583-9325-11065", "score": 17.137291341643948, "text": "\nIt builds a docker image for each of the services you need. The producer, consumers and web application are all in different folders. Each folder has its own simple Dockerfile file that is used by the script to create a container image, which is then uploaded to the IBM Container Registry.\n2. It creates a bunch of kubernetes secrets with all the credentials that are going to be needed to access the different IBM services (IBM Cloudant, Redis and Event Streams).\n3. It deploys the application code (and the secretes) to the Red Hat OpenShift on IBM Cloud cluster using the instructions contained in the deployment.yml script.\n\n\n\n\n\n\n\n The deployment.yml script \n\nThis script tells Openshift what to deploy to the machines in the Openshift cluster. In our case this is:\n\n\n\n1. Data producers (trucktrackerproducer).\n2. Data consumers (trucktrackerredisconsumer and trucktrackercloudantconsumer)\n3. Web application (trucktrackerweb)\n\n\n\nIn all cases, they pull an image from the container registry and get fed some environment variables with the credentials they require to access external services.\n\n\n\n\n\n The Truck Tracker system \n\nThe Truck Tracker system is a set of simple Node.js scripts that use four main packages:\n\n\n\n1. [@ibm-cloud/cloudant](https://github.com/IBM/cloudant-node-sdk) to connect to IBM Cloudant and read/write data.\n2. [Redis](https://www.npmjs.com/package/redis) to connect to the Redis instance and read/write data.\n3. [kafkajs](https://www.npmjs.com/package/kafkajs) to connect to the Event Streams instance.\n4. [Express](https://expressjs.com/) to enable a simple web server that allows interaction with the data.\n\n\n\nThere are five main files:\n\n\n\n1. server.js: This runs the web server and communicates with Redis.", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-truck-tracker-ibmcloud"}, {"document_id": "ibmcld_06600-9319-11059", "score": 17.137291341643948, "text": "\nIt builds a docker image for each of the services you need. The producer, consumers and web application are all in different folders. Each folder has its own simple Dockerfile file that is used by the script to create a container image, which is then uploaded to the IBM Container Registry.\n2. It creates a bunch of kubernetes secrets with all the credentials that are going to be needed to access the different IBM services (IBM Cloudant, Redis and Event Streams).\n3. It deploys the application code (and the secretes) to the Red Hat OpenShift on IBM Cloud cluster using the instructions contained in the deployment.yml script.\n\n\n\n\n\n\n\n The deployment.yml script \n\nThis script tells Openshift what to deploy to the machines in the Openshift cluster. In our case this is:\n\n\n\n1. Data producers (trucktrackerproducer).\n2. Data consumers (trucktrackerredisconsumer and trucktrackercloudantconsumer)\n3. Web application (trucktrackerweb)\n\n\n\nIn all cases, they pull an image from the container registry and get fed some environment variables with the credentials they require to access external services.\n\n\n\n\n\n The Truck Tracker system \n\nThe Truck Tracker system is a set of simple Node.js scripts that use four main packages:\n\n\n\n1. [@ibm-cloud/cloudant](https://github.com/IBM/cloudant-node-sdk) to connect to IBM Cloudant and read/write data.\n2. [Redis](https://www.npmjs.com/package/redis) to connect to the Redis instance and read/write data.\n3. [kafkajs](https://www.npmjs.com/package/kafkajs) to connect to the Event Streams instance.\n4. [Express](https://expressjs.com/) to enable a simple web server that allows interaction with the data.\n\n\n\nThere are five main files:\n\n\n\n1. server.js: This runs the web server and communicates with Redis.", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-mysql?topic=databases-for-mysql-truck-tracker-ibmcloud"}, {"document_id": "ibmcld_06856-4326-6064", "score": 16.943338882987263, "text": "\nIterates through the list that is generated in Step 2 to remove the corresponding files from the repository in Step 3, and updates the Pull Request from Step 4.\n6. Generates a summary of the activities, including a link to the pull request.\n\n\n\n5. Review and merge the pull request\n\nWhen the pull request is generated for the evidence repository, you can review and merge it. The following is an example of how a sample pull request after the completion of the evidence pruner pipeline.\n\nZoom\n\n![Merge Pull Request](https://cloud.ibm.com/docs-content/v1/content/5eb88a2575e30e316dbb83829c7f4c8b1ddbc67c/devsecops/images/devsecops-triggers-evidence-pruner-2.png)\n\nFigure 4. Merge Pull Request\n\n\n\n\n\n Customizing the trigger \n\nThe evidence pruning tool is implemented by using [Custom tasks](https://cloud.ibm.com/docs/devsecops?topic=devsecops-custom-scripts) in DevSecOps pipelines. You must use the default implementation. However, you can also extend or replace the default implementation with a custom implementation. Customize the default by introducing a stage definition in .pipeline-config.yaml, which instructs the pipeline to override the default stage definition.\n\nThe following code snippet starts the default implementation of the evidence pruning script that is located at /opt/commons/prune-evidence/run.sh within the compliance-baseimage Docker image. If you want to customize the default implementation, substitute this snippet with your own implementations.\n\nprune-evidence:\nimage: icr.io/continuous-delivery/pipeline/pipeline-base-ubi:3.18\ndind: false\nabort_on_failure: stopAndFail\nimage_pull_policy: IfNotPresent\nscript: \n!/bin/sh\n\n\"/opt/commons/prune-evidence/run.sh\"\n\n\n\n\n\n Configuring the listener for the timed trigger", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-devsecops-prune-evidence"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03786-7-2105", "score": 23.66806929771421, "text": "\nApplying subscription codes \n\nAfter you buy a subscription for platform or support credit, you must add the credit to your account by applying a subscription code to an existing account or a new account when you register. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nIf you set up your first subscription through the [Subscriptions page](https://cloud.ibm.com/billing/subscriptions), the credit for this subscription is automatically added to your account - no code required.\n\nAfter IBM Cloud Sales places the order, an email with the subscription code for each subscription and support line item is sent to the appropriate contact.\n\nOnly the account owner, enterprise account owner, or a user with the Editor or Administrator role on the Billing account management service can apply the subscription code. If you don't have access to apply subscription codes, the account owner or administrator can provide access. For more information, see [Assigning access to account management services](https://cloud.ibm.com/docs/account?topic=account-account-services). Applying the subscription code through the IBM Cloud\u00ae console is essential to ensure that your account is migrated appropriately.\n\n\n\n1. Open the email with the subscription code.\n\nIf you bought a subscription and didn't receive your subscription code, [contact us](https://www.ibm.com/cloud?contactmodule) or email Sales at [CloudDigitalSales@us.ibm.com](mailto:CloudDigitalSales@us.ibm.com) to request for it to be sent again.\n2. Click Add subscription to add it to an existing account.\n3. Sign in to the console with your IBMid and password.\n4. From the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code"}, {"document_id": "ibmcld_12597-0-804", "score": 23.66115702510281, "text": "\n\n\n\n\n\n\n  Why can't I apply a subscription code to my account in an enterprise? \n\nA subscription code can't be added to the account because of specific access that is required.\n\n  What\u2019s happening \n\nYou can't add a subscription code to your IBM Cloud\u00ae account because you don't have the correct access.\n\n  Why it\u2019s happening \n\nBecause your account is a child account on the enterprise, you can't apply subscription codes. Subscription codes must be applied at the enterprise level.\n\n  How to fix it \n\nContact the owner or the administrator of the enterprise to add the subscription code. When the subscription code is added, it applies to all accounts in the enterprise. For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-troubleshoot-promo-enterprise"}, {"document_id": "ibmcld_03786-1684-3421", "score": 23.567636225288474, "text": "\nFrom the modal, choose the account you'd like to add the subscription to, select I understand, and then click Add.\n\n\n\nTo manually apply the subscription code to an existing account, complete the following steps:\n\n\n\n1. In the IBM Cloud\u00ae console, go to Manage > Account, and select Account settings.\n2. Click Apply code.\n\nEach code can be redeemed only one time, and the codes must be redeemed before their expiration date. Ensure that you add the code to the correct account because the subscription credits can't be removed after the code is applied. After you add the subscription code, you might see that the status of the subscription as IN_PROCESS. Contact IBM Cloud Sales to review the account.\n3. Enter the subscription code, and click Apply.\n\nIf you have separate codes for platform and support credit, apply the platform subscription code first, then apply the support subscription code.\n\n\n\nTo manually apply the subscription code to a new account, complete the following steps:\n\n\n\n1. Go [create an IBM Cloud account](https://cloud.ibm.com/registration), and enter the required information.\n2. Click Register with a code instead of entering your credit card information.\n3. Click Create account.\n\n\n\nIf you don't know your seller, the codes are applied in the wrong order, or you experience issues with applying the codes, [contact IBM Cloud Support](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar).\n\nFor information about other codes and credits that can be applied to different account types, see [Applying feature codes to a Lite account](https://cloud.ibm.com/docs/account?topic=account-codes) or [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code"}, {"document_id": "ibmcld_03785-7-2010", "score": 23.410308981028567, "text": "\nFAQs for subscription accounts \n\nFAQs for subscription accounts include entries about subscription credit, subscription terms, and other subscription-related self-help information.\n\n\n\n How do I add subscription credit to my account? \n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https://cloud.ibm.com/account/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration). For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n\n\n\n\n\n What does the IN_PROGRESS status mean when I apply a subscription code? \n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n\n\n\n\n\n Can I pay the total spending commitment up-front or quarterly? \n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\n\n\n\n\n Can I spend more or less than my monthly commitment? \n\nYes, what you spend monthly is up to you! You can spend any amount of the total commitment each month.\n\n\n\n\n\n What happens if I spend my entire subscription amount before my term ends? \n\nYou're required to continue paying your monthly charges until the end of your term.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription-account"}, {"document_id": "ibmcld_16727-1068047-1069909", "score": 22.970342589380333, "text": "\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https://www.ibm.com/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https://cloud.ibm.com/account/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration). For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes! By default, you're billed monthly for your subscriptions. If you'd like to pay up-front or quarterly, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n* Can I spend more or less than my monthly commitment?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1065299-1067188", "score": 22.878994099820133, "text": "\n* What are the adjustments that are shown on my invoice?\n\nThe adjustments section of your current invoice includes charges or credits from previous billing periods that weren't included on your previous invoice.\n* How do I know if my invoice is paid?\n\nIf you manage your invoices through the IBM Console, you can see the invoice status by clicking Manage > Billing and usage, and selecting Invoices. When the invoice is paid, the status is Closed. If your invoices are managed through the [IBM Invoices website](https://www.ibm.com/invoices), it's paid when the status is Settled.\n* How do I add subscription credit to my account?\n\nAfter you purchase a subscription, you'll receive an email with a subscription code that adds the credit to your account. To apply the subscription code, go to [Account settings](https://cloud.ibm.com/account/settings), and click Apply code. You can also apply your code to a new account by clicking Register with a code when you [sign up for a new account](https://cloud.ibm.com/registration). For more information, see [Managing subscriptions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions).\n\nYou might be looking for information about promo codes and feature codes. For more information, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes) and [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes).\n* What does the IN_PROGRESS status mean when I apply a subscription code?\n\nWhen you apply a subscription code to a Pay-As-You-Go account, the status of the subscription might be IN_PROGRESS. This status indicates that your account must be reviewed to complete your order. When you see this status, contact the IBM Cloud Sales representative who helped you with the order.\n* Can I pay the total spending commitment up-front or quarterly?\n\nYes!", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_03710-0-838", "score": 22.637636829215317, "text": "\n\n\n\n\n\n\n  Why can't I apply a subscription code? \n\nTo successfully apply a subscription code, make sure the code is valid and you have the required access.\n\n  What\u2019s happening \n\nWhen you try to apply a subscription code, you see an error that states that the code cannot be applied.\n\n  Why it\u2019s happening \n\nYou might see this error if you don't have the required access in the account or the code expired.\n\n  How to fix it \n\nUse the following options:\n\n\n\n*  Verify that you have access to apply the code. To apply any code, you must have an Editor role or higher on all account management services. To view or change roles, see [Assigning access to account management services](https://cloud.ibm.com/docs/account?topic=account-account-services).\n*  Contact the person who provided the code for help with reissuing an expired code.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cannot-apply-subscription-code"}, {"document_id": "ibmcld_03787-5002-7004", "score": 22.083483078848026, "text": "\nA subscription is inactive if its term expires or all of its credit is spent.\n\n\n\nYou can use the spending and usage information on the Subscriptions page to evaluate whether your subscriptions suit your usage needs. For example, if you consistently have overages, you might increase your monthly spending commitment to save money on that usage. To buy new subscriptions or change future subscription amounts, contact [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule).\n\n\n\n\n\n Support subscriptions \n\nTo view support subscription usage, in the console, go to Manage > Billing and usage, and select Support costs. You can view the remaining credit in your active support subscriptions and any upcoming subscriptions that aren't yet valid. For more information, see [Viewing your support costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-support).\n\n\n\n\n\n\n\n Subscription credit \n\nAfter you buy a subscription for platform or support credit, you add the credit to your account by applying a subscription code. Applying the code ensures that the credit is added to your account and you don't have unexpected overage charges.\n\nFor more information, see [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n\n\n\n\n\n Expiring subscriptions \n\nYou are notified by email 60, 30, 14, and 1 day before the expiration date of the last subscription on the account. After the subscription expires, your account is converted to a Pay-As-You Go account, which means you pay only for billable services that you use with no contracts or commitments. The discounts that are associated with the subscription account won't apply to the Pay-As-You-Go account. The IBM Sales team is happy to help extend your subscription before you reach its expiration date. If you extend your subscription within 30 days from the expiration date, you won't get charged at the Pay-As-You-Go account rate. After 30 days, you are invoiced as a Pay-As-You-Go account.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscriptions"}, {"document_id": "ibmcld_03704-8977-10890", "score": 21.13638498040437, "text": "\nTo apply your promo code, go to the [Promotions](https://cloud.ibm.com/billing/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes) and [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n\n\n\n\n\n Why did I get invoiced when I have remaining promotion credits? \n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_07578-1050413-1052321", "score": 21.13638498040437, "text": "\nTo apply your promo code, go to the [Promotions](https://cloud.ibm.com/billing/promotions) page in the console, enter your promo code, and click Apply. For more information, see [Applying promo codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nYou might be looking for information on feature codes and subscription codes. For more information, see [Applying feature codes](https://cloud.ibm.com/docs/account?topic=account-codes) and [Applying subscription codes](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-subscription_code).\n\nIf you can't apply a promo code that you received from IBM Cloud Sales or an educational provider, contact sales or the provider for additional help.\n* Why did I get invoiced when I have remaining promotion credits?\n\nIf you think your invoice didn't include your promotion credits, first determine that the credits are still active on your account by using the following steps:\n\n\n\n1. In the IBM Cloud console, go to Manage > Billing and usage, and select Promotions and credits.\n2. Click a promotion to expand the table and view the amount of each promotion, the duration of each promotion and the product it applies to.\n3. Check the following to make sure that your promo code is still applicable:\n\n\n\n* Verify the maximum value of the promo code per month. Some monthly recurring promo codes have a monthly limit. If your usage exceeded that limit, you're billed for the remaining amount.\n* Compare the date of your invoice to the start and end dates of the promo code. If you applied the promo code after the invoice was issued, it was not applied to that month's invoice.\n* If you didn't use the products that are impacted by the promo code before it expired, you don't receive the promotion credits.\n\n\n\n\n\nAfter you complete these steps, if you still believe that the invoice amount is an error, create a support case.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01533-4546-6910", "score": 41.88071148844089, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4585-6962", "score": 41.82922399064323, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01533-6329-8623", "score": 38.3053829876066, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-6381-8675", "score": 38.3053829876066, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_07578-365833-367834", "score": 37.88754203308693, "text": "\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-365807-367808", "score": 37.88754203308693, "text": "\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_01415-6473-8616", "score": 37.46018291042721, "text": "\nFor more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_faq&interface=ui"}, {"document_id": "ibmcld_00882-2700-4149", "score": 36.41299843139626, "text": "\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \"./Report-final.xml\" --type staticsecurityscan\n\nChange the type to dynamicsecurityscan if the report is from a dynamic scan.\n\n\n\n\n\n Uploading SonarQube results \n\nTo upload data from SonarQube, you must provide the SonarQube server token by using --token. Your SonarQube server is required to be accessible from your CI/CD tool.\n\nAfter you run a scan by using SonarQube, you can upload SonarQube results by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"$MY_APP_NAME\" --buildnumber \"$MY_BUILD_NUMBER\" --filelocation \".scannerwork/report-task.txt\" --type=sonarqube --token=$SONARQUBE_TOKEN\n\nreport-task.txt is a file that is generated during the SonarQube scan.\n\n\n\n\n\n Uploading IBM Vulnerability Advisor results \n\nTo get the result of the vulnerability advisor scan from the CLI, use the following command:\n\nibmcloud cr va ${PIPELINE_IMAGE_URL} -o json > vulnerability_advisor.json\n\nYou can get your image's repository and tag from the Vulnerability Advisor UI or in the CLI by using ibmcloud cr image-list. DevOps Insights accepts only the JSON output. You can upload Vulnerability Advisor output file to DevOps Insights by running this command.\n\nibmcloud doi testrecord-publish --logicalappname \"${APP_NAME}\" --buildnumber \"${BUILD_NUMBER}\" --filelocation \"vulnerability_advisor.json\" --type vulnerabilityadvisor", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-publishing-test-data"}, {"document_id": "ibmcld_07971-2155-4528", "score": 36.40779894457682, "text": "\n* Document and evidence the execution of the system/service and security testing/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https://github.com/IBM/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overview)", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-development-processes"}, {"document_id": "ibmcld_01533-4-2366", "score": 35.74146097124232, "text": "\n* UI\n* CLI\n\n\n\n\n\n\n\n Managing image security with Vulnerability Advisor \n\nVulnerability Advisor is provided as part of IBM Cloud\u00ae Container Registry. Vulnerability Advisor checks the security status of container images that are provided by IBM, third parties, or added to your organization's registry namespace.\n\nVulnerability Advisor provides security management for [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-getting-startedgetting-started). Vulnerability Advisor generates a security status report that includes suggested fixes and best practices. Vulnerability Advisor is available in two versions: version 3 and version 4. Version 4 uses new architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nWhen you add an image to a namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nYou can use IBM Cloud Security and Compliance Center to monitor vulnerabilities that are detected by Vulnerability Advisor. For more information, see [Getting started with Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\nUsing Portieris to block the deployment of images with issues that are found by Vulnerability Advisor is deprecated.\n\n\n\n About Vulnerability Advisor \n\nVulnerability Advisor provides functions to help you to secure your images.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-1076793-1078629", "score": 28.558469399675687, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1079289-1081125", "score": 28.558469399675687, "text": "\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n* How many apps can I build?\n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n* What happens when my Lite plan instance reaches the monthly quota?\n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n* How many resource groups, orgs, or spaces can I create?\n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n* Can I change which notifications I receive?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_01660-7085-8964", "score": 28.328553434112287, "text": "\nAfter your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https://cloud.ibm.com/account/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n\n\n\n\n Can I log in to the console with my SoftLayer ID? \n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https://cloud.ibm.com/login), and click Log in with SoftLayer ID.\n\n\n\n\n\n What's a Lite pricing plan for services? \n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_07578-1075256-1077185", "score": 27.270744914526656, "text": "\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel/close/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https://cloud.ibm.com/account/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https://cloud.ibm.com/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1077752-1079681", "score": 27.270744914526656, "text": "\n* To close a Pay-As-You-Go or Subscription account, go to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter), and click Create a case in the Contact Support center. Click Account, and select the Cancel/close/suspend subtopic. A support case is required for account security and documentation purposes. After your account is closed, all usage is stopped across all services running in your account, and the usage that is accrued in the current billing period is sent in one final invoice at the close of the billing period. Closing your account can't be undone and your data is unrecoverable.\n* To close a Lite account, go to the [Account settings](https://cloud.ibm.com/account/settings) page, and click Close account. You can reactivate your account if you upgrade to a Pay-As-You-Go or Subscription account. After an account is closed for 30 days, all data is deleted and all services are removed.\n* You might receive a final invoice after you close your account due to incurred charges from the month before the account was closed.\n* Before you request to close an account, cancel all services and resources within the account. Make sure to state that you want all services and data to be deleted immediately and that you understand all services and data are unrecoverable within the account closure case.\n\n\n\n* Can I log in to the console with my SoftLayer ID?\n\nYes, you can use your SoftLayer ID to log in to the console. Go to the [login page](https://cloud.ibm.com/login), and click Log in with SoftLayer ID.\n* What's a Lite pricing plan for services?\n\nA Lite plan is a free quota-based service plan. You can use a service's Lite plan to build an app without incurring any charges. A Lite plan might be offered on a monthly cycle that is renewed each month or on a one-off usage basis. Lite pricing plans are available with all account types. You can have one instance of a Lite plan for each service.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_04488-133306-134586", "score": 26.760210516478136, "text": "\ncreate a Cloud Object Storage (COS) instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\nCreating service instance my-cos-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-cos-1 was created.\nName: my-cos-1\nID: crn:v1:bluemix:public:cloud-object-storage:global:a/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8::\nGUID: 4b636e74-f3ca-40bb-80b8-3bd21801ccb8\nLocation: global\nState: active\nType: service_instance\nSub Type:\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation: Status create succeeded Message Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\nCreating service instance my-kms-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-kms-1 was created.\nName: my-kms-1", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-key-protect-cli-reference"}, {"document_id": "ibmcld_09055-96989-98298", "score": 25.8003317382759, "text": "\nThe ibmcloud resource service-instance-create command requires a service plan name and a location, which is in the catalog. show the catalog offerings for cloud object storage (COS) and Key Protect\n$ ibmcloud catalog service cloud-object-storage\n\n$ ibmcloud catalog service kms\n create a Cloud Object Storage (COS) instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\nCreating service instance my-cos-1 in resource group Default of account <account name> as <email address>...\nOK\nService instance my-cos-1 was created.\nName: my-cos-1\nID: crn:v1:bluemix:public:cloud-object-storage:global:a/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8::\nGUID: 4b636e74-f3ca-40bb-80b8-3bd21801ccb8\nLocation: global\nState: active\nType: service_instance\nSub Type:\nAllow Cleanup: false\nLocked: false\nCreated at: 2020-06-15T16:03:39Z\nUpdated at: 2020-06-15T16:03:39Z\nLast Operation:\nStatus create succeeded\nMessage Completed create instance operation\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=4b636e74-f3ca-40bb-80b8-3bd21801ccb8\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-cli-reference-five-two"}, {"document_id": "ibmcld_01660-8584-10307", "score": 25.315112451592665, "text": "\nLite pricing plans are available with all account types. You can have one instance of a Lite plan for each service. For more information about Lite accounts, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accountsliteaccount).\n\n\n\n\n\n How many apps can I build? \n\nThere's no limit to the number of apps you can build in a Pay-As-You-Go or Subscription account.\n\nIf you created a Lite account before 12 August 2021, you can build and deploy apps with 256 MB of instantaneous runtime memory. To get 512 MB of free instantaneous runtime memory, upgrade to a Pay-As-You-Go or Subscription account and pay only for what you use over that limit.\n\n\n\n\n\n What happens when my Lite plan instance reaches the monthly quota? \n\nReaching any quota limit for Lite plan instances suspends the service for that month. Quota limits are per org, not instance. New instances that you create in the same org reflect any usage from previous instances. The quota limits reset on the first of every month.\n\nYou can check your usage by going to Manage > Billing and usage in the IBM Cloud console, and selecting Usage. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).\n\n\n\n\n\n How many resource groups, orgs, or spaces can I create? \n\nIf you have a Pay-As-You-Go or Subscription account, there's no limit to the number of resource groups, orgs, or spaces that you can create. However, if you have a Lite account, you're limited to one org and one resource group.\n\n\n\n\n\n Can I change which notifications I receive? \n\nYes, you can update your email preferences for receiving notifications from the Email preferences page in the console. Click the Avatar icon !", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_09055-104201-105670", "score": 25.17258545912451, "text": "\nService instance my-cos-1 with ID crn:v1:bluemix:public:cloud-object-storage:global:a/ea998d3389c3473aa0987652b46fb146:4b636e74-f3ca-40bb-80b8-3bd21801ccb8:: is deleted successfully\n\n view resources (COS and KMS should no longer exist)\n$ ibmcloud resource service-instances\n\nRetrieving instances with type service_instance in resource group Default in all locations under account <account name> as <email address>...\nOK\nNo service instance found.\n<-- </section \"id=\"section-kp-registrations-example-2\" \"> --><-- <section \"id=\"section-kp-registrations-example-3\" \"> --> Example 3 This example shows what happens when one of the following occurs between COS and Key Protect (KP) - COS is not able to access the Key Protect root key.<-- <ul> --> * Delete the KP root key * Remove the CMS/KP authorization policy<-- </ul> -->This example does not show command output except when relevant. create a Cloud Object Storage (COS) service instance\n \"lite\" is the pricing plan and \"global\" is the region\n$ COS_NAME=my-cos-1\n\n$ ibmcloud resource service-instance-create $COS_NAME cloud-object-storage lite global\n\n capture the COS instance id (GUID)\n$ COS_INSTANCE_ID=c488e11a-c8a0-4688-b002-9327266ea55f\n\n create a Key Management Service (KMS) service instance\n \"tiered-pricing\" is the pricing plan and \"us-south\" is the region\n$ KMS_NAME=my-kms-1\n\n$ ibmcloud resource service-instance-create $KMS_NAME kms tiered-pricing us-south\n\n capture the Key Protect (KP) instance id (GUID)", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-cli-reference-five-two"}, {"document_id": "ibmcld_00558-2925-4840", "score": 25.167484481222115, "text": "\nIf you want to store more than one GB of data, or be able to scale provisioned throughput capacity, move to the [Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-publicstandard-plan).\n\nYou're limited to one IBM Cloudant Lite plan instance per IBM Cloud account. If you already have one Lite plan instance, you can't create a second Lite plan instance, or change a Standard plan instance to a Lite plan. If you try, you see the following message. You can have only one instance of a Lite plan per service. To create a new instance, either delete your existing Lite plan instance or select a paid plan.\n\n\n\n\n\n Standard plan \n\nThe IBM Cloudant Standard plan is available to all paid IBM Cloud\u00ae accounts, either as pay-as-you-go or subscription, and scales to meet the needs of your application. The Standard plan is priced based on two factors: the provisioned throughput capacity that is allocated, and the amount of data that is stored in the instance.\n\nPricing is pro-rated hourly with a starting provisioned throughput capacity of 100 reads per second, 50 writes per second, and 5 global queries per second. This rate is equal to a starting cost of USD $0.105 per hour. You can toggle the provisioned throughput capacity up or down by using the user interface or API. Toggle in increments of 100 reads per second, 50 writes per second, and 5 global queries per second. Costs are calculated for the provisioned throughput capacity that is allocated and not on the metered volume of requests. The Standard plan includes 20 GB of data storage. If you store more than 20 GB, you're charged a defined cost per GB per hour.\n\nRefer to the IBM Cloud Pricing Calculator in the dashboard for pricing at different capacities and currencies, and the [pricing](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-pricingpricing) information for examples to estimate costs.\n\n\n\n\n\n Dedicated Hardware plan", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloud-public"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>12", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03713-3269-5168", "score": 65.54488537052927, "text": "\nProblem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card not authorized to place an order? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is IBM Cloud unable to process my order request? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected. Please contact Cloud Trust Enablement at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n Why it\u2019s happening \n\nIBM Cloud\u00ae was unable to process your transaction.\n\n How to fix it \n\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-1710-3705", "score": 65.25486635771449, "text": "\nWhy do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the update wasn't successful.\n\n How to fix it \n\nGo to the [Support Center](https://cloud.ibm.com/unifiedsupport/supportcenter) and click Create a case.\n\n\n\n\n\n Why was there a general decline of my credit card? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is my credit card inactive or not authorized? \n\n What\u2019s happening \n\nYou tried to make a payment or place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Could not place order. Problem authorizing the credit card. We're afraid this transaction has been rejected. Inactive card or card not authorized for card-not-present transactions.\n\n Why it\u2019s happening \n\nSome credit card issuers don't allow transactions when it is being initiated by using a credit card on file. You might see this error message if your credit card has been deactivated.\n\n How to fix it \n\nContact your credit card issuer for more information.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-7-2194", "score": 62.665148478837445, "text": "\nCredit Card error messages \n\nAn issue might occur when you try to update, add, or remove a credit card. Review the following credit card error messages for detailed self-help information.\n\n\n\n Why was my credit card transaction rejected? \n\nProtecting your identity is a priority and IBM Cloud takes credit card verification seriously.\n\n What\u2019s happening \n\nAn issue occurred that caused the transaction to fail. For example, the name and address on file with IBM Cloud doesn't match the information on file with the company that issued your credit card. This error might prompt the following message:\n\n> Error: Could not place order. Problem authorizing the credit card. We are unable to process your request: Transaction Rejected\n\n Why it\u2019s happening \n\nSomething went wrong when verifying your credit card, and the transaction wasn't successful.\n\n How to fix it \n\nTo ensure that your credit card verification is successful, complete the following steps:\n\n\n\n1. Verify that the name and address for your IBM Cloud account matches the name and address on file with your credit card issuer.\n2. Verify that the country associated with a VAT or tax identification number matches the country in your IBM Cloud account. For example, a VAT ID registered in France can't be associated with an IBM Cloud account that is registered in Finland.\n3. Verify that you are creating a business account and not a personal account if you are specifying a VAT ID or tax identification number.\n4. Review the error message that was displayed. If your transaction was rejected and an email address was not provided, contact your credit card issuer.\n5. Contact us by calling 1-866-325-0045 and selecting the third option.\n\n\n\n\n\n\n\n Why do I get an error when I try to update my credit card? \n\nYou tried to change your payment method by adding a new credit card in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments).\n\n What\u2019s happening \n\nAfter you entered your credit card information and saved it, the following message displayed:\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-4689-6647", "score": 46.971631363623466, "text": "\nContact the Cloud Trust and Enablement team by email at [verify@us.ibm.com](mailto:verify@us.ibm.com).\n\n\n\n\n\n Why was my change request rejected? \n\n What\u2019s happening \n\nYou tried to place an order in the IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get one of the following error messages:\n\n> Failed to complete the Change Request process due to the following error: We're afraid this transaction has been rejected. Invalid account number.\n\nor\n\n> Failed to complete the Change Request process due to the following error: We are unable to process your request: Transaction Rejected.\n\n Why it\u2019s happening \n\nYour credit card number was not recognized by your credit card issuer.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why was my change request rejected because of a VAT ID? \n\n What\u2019s happening \n\nYou tried to complete a change request IBM Cloud console [Payments page](https://cloud.ibm.com/billing/payments), but you get the following error message:\n\n> Failed to complete the Change Request process due to the following error: VAT ID is a required field for ...\n\n Why it\u2019s happening \n\nYour VAT ID, CST or other tax identification number cannot be validated.\n\n How to fix it \n\n\n\n1. Verify that tax identification number is valid.\n2. Verify that the tax identification number is associated with the same country as the physical country of residence in your IBM Cloud profile.\n3. Verify whether a VAT ID is required to create an IBM Cloud account in your country of residence. For more information, see [Personal use availability](https://cloud.ibm.com/docs/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-6236-8279", "score": 44.68985053181524, "text": "\nFor more information, see [Personal use availability](https://cloud.ibm.com/docs/account?topic=account-account-getting-startedsignup-personalaccts).\n4. Verify that you are creating the correct account type: personal or business.\n\n\n\n\n\n\n\n Why was there an error in the payment process? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> There was an error in the payment process: We're afraid this transaction has been rejected. General decline of the card. No other information provided by the issuing bank.\n\n Why it\u2019s happening \n\nYour credit card issuer has declined the transaction.\n\n How to fix it \n\nContact your credit card issuer for more information.\n\n\n\n\n\n Why is the transaction already processed? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Transaction already processed.\n\n Why it\u2019s happening \n\nOur payment system has detected multiple similar payments within a short period of time. IBM Cloud is attempting to avoid unintentional duplicate payments.\n\n How to fix it \n\nWait 3-4 hours for the manual payment to be processed and posted to your IBM Cloud} account. Verify your account balance on the [Payments page](https://cloud.ibm.com/billing/payments).\n\n\n\n\n\n Why can't I upgrade my account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your account couldn't be upgraded. Click Upgrade account to try again.\n\n Why it\u2019s happening \n\nIBM Cloud} was unable to process your transaction.\n\n How to fix it \n\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03713-7896-8949", "score": 42.12431085468739, "text": "\nSubmit your account upgrade information again. If the error continues to occur, you can contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\n\n\n\n\n Why can't I save my credit card to the account? \n\n What\u2019s happening \n\nAn issue occurred that caused the payment process to fail. This error might prompt the following message:\n\n> Your card could not be saved. Please try another card.\n\n Why it\u2019s happening \n\nYour card information was incorrect.\n\n How to fix it \n\nUse a different credit card to process your transaction.\n\n\n\n\n\n Why was my credit card declined? \n\n What\u2019s happening \n\nAn issue occurred that caused your credit card to decline. This error might prompt the following message:\n\n> Your payment was declined for invoice number\u2026\n\n Why it\u2019s happening \n\nYou have a credit card on file and it was declined.\n\n How to fix it \n\nUpdate your credit card information on the [Payments page](https://cloud.ibm.com/billing/payments). Credit card transactions are automatically retried within 24 hours after you update the information.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages"}, {"document_id": "ibmcld_03782-0-720", "score": 39.87044309601806, "text": "\n\n\n\n\n\n\n  Why do I get a section error when I try to provide credit card information? \n\nYou are unable to complete the registration of a new account or to update the credit card information on an existing account because the Credit Card information section can\u2019t be loaded.\n\n  What\u2019s happening \n\nThe following error appears in the Credit Card information section of the form:\n\n> This section can\u2019t be loaded.\n\n  Why it\u2019s happening \n\nA network issue might affect the loading of this section of the form.\n\n  How to fix it \n\nYou can troubleshoot potential network problems by using a private or incognito window, by trying without a VPN or with a different VPN, or by using a browser on a different computer or device.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-section-error"}, {"document_id": "ibmcld_03794-0-812", "score": 37.880430692767334, "text": "\n\n\n\n\n\n\n  Why am I getting a charge limit error when I try to make a payment? \n\nYou can't make a full payment on your invoice because of a charge limit.\n\n  What\u2019s happening \n\nYou try to make a payment on an invoice that is over $1,000.00 USD, but you get the following error message:\n\n> Manual payment request cannot be processed. Payment amount is higher than the limit allowed.\n\n  Why it\u2019s happening \n\nBy default, credit card payments in US Dollars cannot exceed $1,000.00 USD, which might cause you to make multiple payments to pay your invoice.\n\n  How to fix it \n\nYou can contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter) to request an increase in this maximum credit card payment limit. All requests are considered based on the payment and invoice history of the account.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-ts-charge-limit"}, {"document_id": "ibmcld_03793-7-1857", "score": 33.90372417356006, "text": "\nHow do I add a credit card when the option isn't available through the console? \n\nIf your payments are managed outside of the console, you can't use [Billing and usage](https://cloud.ibm.com/billing) to add a credit card.\n\n What\u2019s happening \n\nYou want to enter a credit card to pay for IBM Cloud services, but the option doesn't appear.\n\nWhen you try to enter your credit card information, you see the following message:\n\nYour payments are managed through IBM.com. To view your payments and maintain your billing, you can visit the IBM.com portal which contains everything for your IBMid account.\n\nYou click Explore to access the ibm.com website, but you don't see a location to enter your credit card information.\n\n Why it\u2019s happening \n\nCredit card transactions are securely processed through the IBM Cloud console. However, in some countries, extra steps are taken to ensure the integrity of the credit card data. Those credit card requests are completed through the IBM.com website. Both methods ensure that your credit card information is securely processed.\n\n How to fix it \n\nTo provide your credit card information for payment, complete the following steps:\n\n\n\n1. Go to [IBM.com](http://www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2. Click the Avatar icon ![Avatar icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/i-avatar-icon.svg), and select Billing.\n3. Click Manage payment method.\n4. Enter your credit card information, and click Register.\n\n\n\nThe information is verified and added to your IBM Cloud account as your payment method for any charges.\n\nTo replace an existing credit card, complete the following steps:\n\n\n\n1. Go to [ibm.com](http://www.ibm.com) and log in with the same IBMid and password that you use to log in to IBM Cloud.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-ts-ccibm"}, {"document_id": "ibmcld_07578-1068305-1070191", "score": 33.38009101372776, "text": "\nYou can request to cancel your subscription before the end of the term, but whether the subscription can be canceled is at the discretion of IBM. Any remaining credit on your subscription might be forfeited. For more information, contact [Support](https://cloud.ibm.com/unifiedsupport/supportcenter). Make sure that you provide details about why you need to cancel your subscription.\n\nTo close a Pay-As-You-Go account or a Lite account, see [Can I cancel my account?](https://cloud.ibm.com/docs/account?topic=account-accountfaqscancelaccount).\n\n\n\nManaging your account, resources, and access\n\n\n\n* How do I create an IBM Cloud account?\n\nYou can create an account by [registering](https://cloud.ibm.com/registration) your email address. For identity verification, a credit card is required when you create a new account. New accounts are created as Pay-As-You-Go accounts, except purchased subscriptions. For more information, see [Account types](https://cloud.ibm.com/docs/account?topic=account-accounts).\n\nFeature codes aren't supported in some countries. For more information, see [personal use availability](https://cloud.ibm.com/docs/account?topic=account-account-getting-startedsignup-personalaccts).\n* How is my credit card authorized?\n\nA credit card is required to create a new IBM Cloud account unless you have a subscription or feature code. As part of the authorization process, you might see a temporary hold on your credit card for verification and security when creating an account. This credit card hold is reversed within 24 to 72 hours. In many cases, a credit card isn't accepted because your credit card issuer didn't authorize it. For more information about issues with credit card authorization, see [Credit Card error messages](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cc-error-messages).\n* How do I get help with issues with creating an account?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13480-1642-3813", "score": 41.45214106294349, "text": "\nSo, if you are either familiar with the schema, or want to repetitively use the data for queries, create a table in the catalog. Such a table improves performance for repeated query executions.\n\nAnother advantage of creating a table in the catalog is that the table name serves as an alias and is decoupled from the data location. Hence, you can separate the tasks of data engineers and SQL authors. Data engineers deal with the data location and publish registered tables in the catalog by using descriptive table names. Hence, SQL authors are able to compose queries without having to know the exact location and format of data on Object Storage. If the data location changes, only the table in the catalog must be updated, but the table name remains unchanged. Updates of the physical data structure are simplified and the robustness of SQL statements and applications is increased.\n\n\n\n\n\n Usage \n\nYou manage the database catalog in Data Engine with Database Definition Language (DDL) statements that you submit just like any other SQL query statement. The catalog is stored independently of Object Storage: No data is written to Object Storage when you create or change table definitions, and no data is deleted from Object Storage when you drop a table definition. To call the catalog management statements, you need the Manager user role assigned.\n\nTo register a new table in the catalog, use the CREATE TABLE statement, as in the following example:\n\nCREATE TABLE employees\nUSING PARQUET\nLOCATION cos://us-geo/sql/employees.parquet\n\nThe statement automatically detects the schema of the data at the location that is indicated. See the [SQL reference](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencecreateTable) for options that can be set on the table.\n\nUse the DESCRIBE TABLE statement to verify the detected table schema:\n\nDESCRIBE TABLE employees\n\nIf the DESCRIBE TABLE output shows partition information, you must run an ALTER TABLE ... RECOVER PARTITIONS statement to attach the partitions. For more information, see the section on [partitioned tables](https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalogpartitioned).", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalog"}, {"document_id": "ibmcld_13498-39344-41146", "score": 38.48815457159398, "text": "\nWith this function, you can write results, for example, into Parquet, without the need to provide column by column alias names in your SQL when your input data has columns with these characters. A typical situation is the existence of space () in input columns.\n\nFor example, you can use SELECT * FROM CLEANCOLS(cos://us-geo/sql/iotmessages STORED AS JSON) INTO cos://us-geo/mybucket/myprefix STORED AS PARQUET to produce a result set that can be stored as is into Parquet target format.\n\nIf you wrap your external table definition with the DESCRIBE table transformer, the table does not show its actual content but the schema that is inferred from the objects in IBM Cloud\u00ae Object Storage instead. With this function, you can explore the schema before you author your actual SQL statements against it.\n\nWhen you use the DESCRIBE table transformer in your SQL statement, the default output format is JSON instead of CSV.\n\nYou can also wrap DESCRIBE around the other table transformers to explore the transformed table schema. However, you cannot wrap other table transformers around the DESCRIBE transformer.\n\n\n\n\n\n tableValuedFunction \n\nA table-valued function returns a relation, which is a set of rows. An example of a table-valued function is range(). For more information, see [SQL functions](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sqlfunctionssqlfunctions).\n\n\n\n\n\n More topics - relation clause \n\nFor more information about the clauses that are used in relation clauses, see the following topics:\n\n\n\n* [booleanExpression](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencebooleanExpression)\n* [COSURI](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referenceCOSURI)\n* [expression](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referenceexpression)", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference"}, {"document_id": "ibmcld_13480-7832-9910", "score": 37.69386807434336, "text": "\nSELECT * FROM cos://us-geo/sql/customers.csv\nINTO cos://us-geo/mybucket/customers_partitioned.csv\nPARTITIONED BY (country)\n\n\n\n\n\n Step 2: Attach table partitions \n\nAfter you defined a partitioned table, it is initially empty and you must attach the partitions to it explicitly. A convenient way to add all partitions that exist on Object Storage, is to use the following RECOVER PARTITIONS clause.\n\nALTER TABLE customers RECOVER PARTITIONS\n\nThis clause overwrites the current partition definitions for the table with the structure that is detected from Object Storage data by using the location prefix that is specified for the table. You can also update partition definitions selectively with the ADD PARTITION and DROP PARTITION clauses of the ALTER TABLE statement, for example, to attach more data to a table that was uploaded recently.\n\nWhen you added all partitions, the partitioned table is set up to be queried. You get all the German customers, if you submit the following query:\n\nSELECT customerID FROM customers WHERE country = 'Germany'\n\nThe query execution reads the objects only under the cos://us-geo/sql/customers_partitioned.csv/country=Germany/ prefix because the partition definitions are used by the query optimizer to minimize the necessary data transfer.\n\n\n\n\n\n\n\n Limitations \n\n\n\n* With the Standard plan, you can create up to 100 tables with up to 20,000 partitions per table.\n* If you use the Lite plan, the catalog management features, such as CREATE TABLE, are not allowed.\n* The ADD PARTITION option of the ALTER TABLE statement may not correctly locate partitions if the value for a partition column contains special characters, such as the colon : that can appear as a timestamp separator.\n\nWhen the location is inferred from one or more partition values, some special characters in the values are URL escaped when you construct the Object Storage location. For example, the statement ALTER TABLE mytable ADD PARTITION ( startTime = '2020-01-01 12:00:00' ) constructs a partition with an Object Storage location .../startTime=2020-01-01 12%3A00%3A00/.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalog"}, {"document_id": "ibmcld_13498-7-2240", "score": 36.71204277739709, "text": "\nSQL reference \n\n\n\n Introduction \n\nWith IBM Cloud\u00ae Data Engine, you can analyze and transform open data with SQL. It supports the various types of SELECT statements from the ANSI SQL standard.\n\nThe SELECT statement (or query statement) is used to read object data from IBM Cloud\u00ae Object Storage (COS), process the data, and store it back on Cloud Object Storage eventually.\n\nYou can use Data Engine as a data transformation service, as it always writes the results of a query to a specified location in either Object Storage or Db2 tables. Data Engine provides extended SQL syntax inside a special INTO clause to control how the result data is stored physically. This extended SQL syntax includes control over data location, format, layout, and partitioning.\n\nA query statement can be submitted through Data Engine's web UI or programmatically, either by using the service's REST API, or by using the Python or Node.JS SDK. You can also use IBM Watson\u00ae Studio and the Python SDK to use Data Engine interactively with Jupyter Notebooks. In addition, you can submit SQL queries that use IBM Cloud\u00ae Functions.\n\nIn addition to the ad hoc usage of data in IBM Cloud\u00ae Object Storage, you can also register and manage your data in a catalog as tables, consisting of columns and partitions.\n\nSeveral benefits to cataloging your data exist:\n\n\n\n* It simplifies SQL SELECT statements because the SQL author does not need not know and specify exactly where and how the data is stored.\n* The SQL execution can skip the inference of schema and partitioning because this information is available in the metastore. Thus, cataloging improves your query performance, especially for text-based data formats, such as CSV and JSON, where the schema inference requires a full scan of the data before the actual query execution.\n\n\n\n\n\n\n\n Select \n\nSee the following examples for an outline of the general syntax of an SQL query statement that uses the query clause and the namedQuery clause.\n\n\n\n query \n\n\n\n\n\n namedQuery \n\n\n\n\n\n intoClause \n\nThe query statement supports common table expressions. A common table expression permits defining a result table with a table name that can be specified as a table name in any FROM clause of the fullselect that follows.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference"}, {"document_id": "ibmcld_05152-1176-2997", "score": 36.640846094177675, "text": "\nFigure 3 shows the panel that opens when the card is selected. This panel give you control over the location and costs regarding your new instance of IBM Cloud Data Engine. Select the region appropriate for your buckets and the plan suitable for your projects. If you want more information you can use the documentation to [get started](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overview).\n\nZoom\n\n![Create SQL Instance](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/create-sql-instance-cos.jpg)\n\nFigure 3. Fill out form fields to configure your instance\n\n\n\n Querying Object Storage with SQL Query \n\nYou can use SQL Query to create SELECT statements only; actions such as CREATE, DELETE, INSERT, and UPDATE are not possible.\n\nInput data for your queries are read from ORC, CSV, JSON, or Parquet files located in one or more IBM Cloud Object Storage instances. Each query result is written by default to a CSV file in a Cloud Object Storage instance where you created the integration. But you can freely override and customise the format and Object Storage location as part of the SQL statement that you run.\n\nYou can use a custom INTO clause of a SELECT statement to control where and how result data from a SELECT statement is written to IBM Cloud Object Storage.\n\nGetting started using SQL Query SELECT statements from inside your instance is as easy as creating an integration. Objects of queryable data formats, as well as folders with multiple objects of a consistent queryable format (when shown in the \"folders\" view) are labeled as shown in Figure 4.\n\nZoom\n\n![Object with SQL label](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/accessible-using-sql.jpg)\n\nFigure 4.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-sql-query"}, {"document_id": "ibmcld_13480-6528-8270", "score": 35.2652039875351, "text": "\ncustomers_partitioned.csv/country=USA/cust-1.csv\ncustomers_partitioned.csv/country=USA/cust-2.csv\ncustomers_partitioned.csv/country=USA/cust-3.csv\ncustomers_partitioned.csv/country=Sweden/cust-1.csv\n\nTo query partitioned tables, you must perform two mandatory steps:\n\n\n\n Step 1: Register the table \n\nThis data partitioning is reflected in the PARTITIONED BY clause of the following CREATE TABLE statement:\n\nCREATE TABLE customers (\ncustomerID string,\ncompanyName string,\ncontactName string,\ncontactTitle string,\naddress string,\nregion string,\npostalCode string,\ncountry string,\nphone string,\nfax string\n)\nUSING CSV\nPARTITIONED BY (country)\nLOCATION cos://us-geo/sql/customers_partitioned.csv\n\nAutomatic schema detection also recognizes partitioned tables from the structure of the object names, so the same table definition is created from the following statement:\n\nCREATE TABLE customers\nUSING CSV\nLOCATION cos://us-geo/sql/customers_partitioned.csv\n\nIf your data on Object Storage does not adhere to this naming convention, you can convert it to a Hive-partitioned layout by using Data Engine in a data preparation step. Use SELECT * to copy the data to a new location and specify [PARTITION BY](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencepartitionedClause) in the INTO clause:\n\nSELECT * FROM cos://us-geo/sql/customers.csv\nINTO cos://us-geo/mybucket/customers_partitioned.csv\nPARTITIONED BY (country)\n\n\n\n\n\n Step 2: Attach table partitions \n\nAfter you defined a partitioned table, it is initially empty and you must attach the partitions to it explicitly. A convenient way to add all partitions that exist on Object Storage, is to use the following RECOVER PARTITIONS clause.\n\nALTER TABLE customers RECOVER PARTITIONS", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalog"}, {"document_id": "ibmcld_13498-100465-102250", "score": 35.230211861545904, "text": "\nCAST(2018-10-31 23:55:00 AS TIMESTAMP) CAST(2018-2-28 23:55:00 AS DATE) CAST(HELLO AS TIMESTAMP) \n\n 2018-10-31 23:55:00.0 2018-02-28 null \n\n\n\n\n\n\n\n Boolean type \n\nThe BOOLEAN type represents a domain with two values, true or false. Any numeric value that represents zero, for example, 0, 0.0, or 0.0E10, can be cast to false. Numeric values that represent a nonzero value, for example, 1, 1.0, 1.0E10, or 21474.83648 can be cast to true. The string value '0' can be cast to false and '1' can be cast to true. Any other string value is cast to false.\n\n\n\n\n\n Binary type \n\nA BINARY type represents an array of byte values. Thus, string values can be cast to type BINARY.\n\n\n\n\n\n Related references - dataType \n\nA dataType is referenced by the following clauses:\n\n\n\n* [castExpression](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencecastExpression)\n* [createTable](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencecreateTable)\n\n\n\n\n\n\n\n\n\n Catalog management \n\nThe following commands allow users to store table metadata catalog in the Data Engine catalog. By defining the tables, columns, and partitions in the catalog, you can use short table names in the SQL SELECT statements. Each instance of Data Engine has its own catalog, and table definitions are not visible from other instances. For more information, see [catalog management](https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalog).\n\n\n\n Create table \n\n\n\n createTable \n\n\n\n\n\n columnDefinition \n\nCreate a table definition in the catalog based on the objects in the specified Object Storage location. The LOCATION option is mandatory. If a table or view with the same name exists in the same Data Engine instance, you receive an error, unless the IF NOT EXISTS clause is specified.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference"}, {"document_id": "ibmcld_05152-4777-6005", "score": 35.08239935167094, "text": "\n[SQL Query Window](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/select-with-sql.jpg)\n\nFigure 7. Access with SQL query window\n\nThe entry representing the job of the SELECT statement run previously is shown in Figure 8. There are two tabs, \"Results\" and \"Details,\" at the top of the list that allow you to switch between seeing the results and more detailed information.\n\nZoom\n\n![SQL Query Results](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/results-from-sql.jpg)\n\nFigure 8. Access with SQL query jobs\n\nThe entry representing the details of running the SELECT statement run previously is shown in Figure 9.\n\nZoom\n\n![SQL Query Details](https://cloud.ibm.com/docs-content/v1/content/63322f2f3a72050206eb05ba7f590fdcb741105c/cloud-object-storage/images/details-from-sql.jpg)\n\nFigure 9. Access with SQL query jobs\n\n\n\n\n\n Next Steps \n\nFor more information on using Data Engine see the [Data Engine documentation](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overview) and [Analyzing Data with IBM Cloud SQL Query](https://www.ibm.com/cloud/blog/analyzing-data-with-ibm-cloud-sql-query).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-sql-query"}, {"document_id": "ibmcld_13498-37842-39831", "score": 35.04624802912383, "text": "\nFROM cos://us-geo/sql/temperature_humidity.csv\nUSING TIME_SERIES_FORMAT(timetick=\"timestamp\", value=\"humidity\")\n\n\n\n\n\n tableTransformer \n\nA table transformer is a function that is applied to the input data set before it is sent to the actual SQL query compilation and execution.\n\nYou can wrap your external table definition optionally with the FLATTEN table transformation function. It preprocesses your input table before query compilation to a fully flat column schema. This table transformation function can be useful when you have hierarchical input data as it is often found in JSON documents. By using FLATTEN, you do not need to dereference all nested columns explicitly in your SQL statement.\n\nFor example, you can run a simple SELECT * FROM FLATTEN(cos://us-geo/sql/iotmessages STORED AS JSON) on a flattened JSON input and use CSV output to easily browse a sample of your JSON input data.\n\nThe FLATTEN table transformation function creates a flat list of columns by concatenating all nested column names with _. You can optionally also combine FLATTEN with CLEANCOLS.\n\nYou can wrap your external table definition optionally with the CLEANCOLS table transformation function. It preprocesses your input table before query compilation by renaming all columns that have characters that are NOT supported by certain target formats, such as Parquet. These characters are ,, ;, ,,,, =, (, ), {, and }. They are replaced by the corresponding URL-encoded representation, for example, %20 for space (). With this function, you can write results, for example, into Parquet, without the need to provide column by column alias names in your SQL when your input data has columns with these characters. A typical situation is the existence of space () in input columns.\n\nFor example, you can use SELECT * FROM CLEANCOLS(cos://us-geo/sql/iotmessages STORED AS JSON) INTO cos://us-geo/mybucket/myprefix STORED AS PARQUET to produce a result set that can be stored as is into Parquet target format.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-reference"}, {"document_id": "ibmcld_16662-0-1981", "score": 34.560480856896916, "text": "\n\n\n\n\n\n\n  Running SQL queries \n\nSQL is a standardized language for defining and manipulating data in a relational database. You can use the Query workspace interface in IBM\u00ae watsonx.data to run SQL queries and scripts against your data.\n\nThe Query workspace has the following components:\n\n\n\n*  Data objects: To view the engines, catalogs, schemas, tables, and columns.\n*  Engine: To select an engine and view the associated catalogs.\n*  Saved queries: To view the saved queries.\n*  Worksheet: To write SQL queries.\n\n\n\nThe Query workspace page provides basic options to undo, redo, cut, copy, paste, save, clear, and delete.\n\nFormat selection option is enabled only when an SQL statement in a query worksheet is selected. The Format worksheet option formats all the content in the worksheet. Comment selection is used to explain sections of SQL statements.\n\nThe Delete option is enabled only after an SQL query is saved.\n\nTo run the SQL queries, do the following steps:\n\n\n\n1.  Log in to the watsonx.data console.\n2.  From the navigation menu, select SQL. The Query workspace page opens.\n3.  Select an engine from the Engine drop-down.\n4.  Select the catalog, schema, table, or column in which you want to run the query.\n5.  Click the overflow menu and select the required query.\n\n\n\n*  For a catalog and schema, you can run the Generate Path query.\n*  For a table, you can run the Generate path, Generate SELECT, Generate ALTER, and Generate DROP query.\n*  For a column, you can run the Generate path, Generate SELECT, and Generate DROP query.\n\n\n\n6.  Click the Save icon to save the query. A Save query confirmation dialog appears.\n7.  Click Save.\n8.  Click the Run button to run the query.\n9.  Select Result set or Details tab to view the results.\n10. Click Saved queries to view the saved queries.\n11. Click [Explain](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-explain_sql_query) to view the logical or distributed plan of execution for a specified SQL query.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-run_sql"}]}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16446-7-1856", "score": 16.817714015594316, "text": "\nRelease notes \n\nThe following new features and changes to IBM Watson\u2122 Knowledge Studio for IBM Cloud Pak\u00ae for Data are available.\n\nFor details about what's new, see the IBM Cloud Pak for Data documentation.\n\n\n\n* [4.5.x](https://www.ibm.com/docs/SSQNUZ_4.5.x/fixlist/wks-fixlist.html)\n\n\n\n\n\n Version 1.2.0 (9 December 2020) \n\n\n\n* Security and stability fixes\n\n\n\n* Several security fixes and stability enhancements have been introduced.\n\n\n\n\n\n\n\n\n\n Version 1.1.3 (31 August 2020) \n\n\n\n* Security and stability fixes\n\n\n\n* Several security fixes and stability enhancements have been introduced.\n\n\n\n\n\n\n\n\n\n Version 1.1.2 (19 June 2020) \n\n\n\n* Enhanced pre-annotation workflow.\n\n\n\n* Run multiple pre-annotators at once and configure the order of pre-annotators to resolve annotation conflicts between them. Existing pre-annotator results are preserved unless you remove them with the Wipe option.\n* Human annotations are preserved when running pre-annotators, even when using the Wipe option.\n\n\n\n\n\n\n\n\n\n Version 1.1.1 (28 February 2020) \n\n\n\n* New advanced rules tokenizer Advanced rules has introduced a new tokenizer which is not compatible with the previous one. The following extractor categories are affected:\n\n\n\n* Parts of Speech extractor names are renamed automatically\n* Cardinal is renamed to Numeral\n* Preposition is renamed to Adposition\n* Machine Data Analytics Splitter extractors have been removed and will disappear from the canvas. There is no substitute for these extractors that is provided by the new tokenizer.\n* Generic Splitters:\n\n\n\n* Date Time Splitter\n* Day First Splitter\n* Month First Splitter\n* Year First Splitter\n\n\n\n* Syslog Splitter:\n\n\n\n* Date Time Splitter\n\n\n\n\n\n* Cross-sentence relations (Experimental): English entities and relations workspaces can now support annotating relations between entities within spans of six sentences.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-release-notes"}, {"document_id": "ibmcld_16034-7-1778", "score": 16.815648009083905, "text": "\nVPC CLI release notes \n\nThe following release notes are for the IBM Cloud\u00ae Virtual Private Cloud (VPC) command line interface (CLI).\n\n\n\n v6.15.0 \n\nVersion 6.15.0 was released on 2023-07-11.\n\n\n\n New commands \n\n\n\n* New commands image-obsolete and image-deprecate are introduced to support image lifecycle management.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for image lifecycle management in image-create, image-update, and images commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.14.1 \n\nVersion 6.14.1 was released on 2023-06-30.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed issue with using the SSH key generated from UI in CLI.\n\n\n\n\n\n\n\n\n\n v6.14.0 \n\nVersion 6.14.0 was released on 2023-06-23.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for more algorithms in the SSH key key-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.13.0 \n\nVersion 6.13.0 was released on 2023-06-22.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for snapshot and backup cross region copy in snaphot-create, snapshots, backup-policy-plan-create and backup-policy-plan-update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.12.0 \n\nVersion 6.12.0 was released on 2023-06-01.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for fileshare mount targets in share commands (Beta).\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed bare-metal-server-network-interfaces, bare-metal-server-profiles and bare-metal-servers commands to print correct response values.\n\n\n\n\n\n\n\n\n\n v6.11.1 \n\nVersion 6.11.1 was released on 2023-05-03.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-cli-rn"}, {"document_id": "ibmcld_14851-9765-11592", "score": 16.57564543168323, "text": "\n* If introducing new hosts, ensure that they are of the same initial version and upgrade them along with the rest of the cluster.\n* If you are adding or replacing disks during an upgrade, ensure that they are formatted with the appropriate legacy on-disk format version, if applicable.\n* Therefore, certain vSAN behavior changes are controlled by the on-disk format it is important that newer on-disk format versions are not introduced into a mixed-version cluster.\n\n\n\n\n\n\n\n\n\n Upgrade the vCenter Server Appliance \n\nFor more information, see [VCSA update and SSO-linked vCenters](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vum-updating-vcsa).\n\n\n\n\n\n Upgrade the vSphere ESXi hosts \n\nFor more information, see [Creating baselines and attaching to inventory objects](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vum-baselines).\n\n\n\n\n\n Upgrade the vSAN disk format \n\nRuby vSphere Console (RVC) is a Ruby-based command-line interface for vSphere and can be used to manage VMware vSphere ESXi and vCenter. The vSphere inventory is presented in a tree structure, that allows you to navigate and run commands against vCenter objects.\n\nMany basic administrative tasks can be done much more efficiently than clicking through the vSphere Client. RVC is fully implemented in the VCSA and is accused by an SSH connection to the appliance.\n\n\n\n1. SSH to the VCSA and login by using root and the password that is provided on the ICVS Console.\n2. At the prompt, type: rvc Administrator@vsphere.local@localhost and press Enter.\n3. Enter the Administrator\u2019s password provided on the ICVS Console. You are now at the root of the virtual file system, type ls and then press Enter. The output is: 0 / 1 localhost/\n4. Type cd 1, enter and then ls and press Enter. The output is: 0 / datacenter1 (datacenter)\n5.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vum-updating-vsan"}, {"document_id": "ibmcld_16516-6223-8371", "score": 16.280746615137943, "text": "\n: Admins and Project Managers can annotate document sets directly from the Ground Truth tab on the Annotations page.\n: Annotation tasks are still available. You can manage them from the Annotation Tasks tab on the Annotations page.\n: Annotations applied directly to ground truth are not applied to related active annotation tasks. It is recommended that you annotate document sets directly only when they are not associated with any active annotation tasks.\n: The Annotation Sets tab has been removed from the Documents page. You can manage annotation sets from the Annotation Tasks tab of the Annotations page.\n\n- To create new annotation sets, click Add task. Then, click Create Annotation Sets.\n- To manage existing annotation sets, click an existing annotation task, then click Edit.\n\n\n\n\n\n\n\n March 2019 \n\n\n\n New features and changes \n\nCustom categories workspace (Experimental)\n: Introduced an experimental custom categories workspace for Knowledge Studio service instances on Lite and Standard plans that are hosted in the Dallas location. With the new workspace, you can deploy your own custom text categorization model to Natural Language Understanding or Discovery.\n\n\n\n\n\n\n\n January 2019 \n\nMigrating Cloud Foundry service instances\n: You can now migrate Knowledge Studio Cloud Foundry service instances to a resource group.\n\n\n\n\n\n December 2018 \n\n\n\n New features and changes \n\nSupport to deploy same model to multiple instances\n: Introduced support to deploy the same machine learning model version to multiple service instances and general improvements to the Version History and Deployment page. For more information about deploying multiple instances of the same model version see [Deploying the same model version to multiple services](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-publish-mlwks_secdep)\n\nAdded models method\n: Added the models method to the Natural Language Understanding service allowing users to list deployed Knowledge Studio models.\n\n\n\n\n\n\n\n September 2018 \n\n\n\n New features and changes \n\nSupport for additional document types\n: Introduced support for HTML, DOC, DOCX, and PDF files.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-release-notes"}, {"document_id": "ibmcld_12270-37028-38802", "score": 16.153289299842754, "text": "\nTerraform v0.14 introduced new sensitive attribute in the variable metadata configuration. Schematics do not detect this sensitive attribute. Users should continue to use the sensitive checkbox in the IBM Cloud Schematics console, and use secure flag in the API payload. Schematics already supports masking the sensitive updated values. Terraform v0.14 introduced a lock file for versions with the name .terraform.lock.hcl. This file is created during terraform init. If you use .terraform.lock.hcl file in the Terraform commands, the versions stored in .terraform.lock.hcl file are used. Schematics doesn't support this feature. Schematics will not store this file for subsequent actions.\n\n\n\n\n\n\n\n February 2021 \n\nReview the release notes for February 2021.\n\n\n\n 25 February 2021 \n\nSchematics supports the ability to store the user-defined file\n: IBM Cloud Schematics supports the ability to store the user-defined file for running the subsequent Terraform commands. For more information, see [store user-defined files in Schematics](https://cloud.ibm.com/docs/schematics?topic=schematics-general-faqpersist-file).\n\nAllowed file extensions in Schematics\n: Allowed and blocked file extensions support during cloning. For more information, see [allowed and blocked file extensions](https://cloud.ibm.com/docs/schematics?topic=schematics-workspaces-faqclone-file-extension).\n\nSchematics CLI plug-in and commands support in CLI documentation\n: IBM Cloud Schematics [command-line plug-in to install](https://cloud.ibm.com/docs/cli?topic=schematics-cli-plugin-schematics-cli-reference), and [view command-line commands](https://cloud.ibm.com/docs/cli?topic=schematics-cli-plugin-schematics-cli-reference) in the CLI documentation.\n\n\n\n\n\n 12 February 2021 \n\nAnsible open beta release", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-schematics-relnotes&interface=cli"}, {"document_id": "ibmcld_10140-2632-4302", "score": 16.070597560641616, "text": "\nVersion 1.0.480 of the CLI was released on 14 December 2022.\n: Adjusted ibmcloud oc flavor get and ibmcloud oc flavor ls commands to show secondary storage details.\n: Introduced Secondary Storage Configuration for worker-pool get.\n: Added Ignored Errors to ingress status-report.\n\n\n\n\n\n Version 1.0.471 \n\nVersion 1.0.471 of the CLI was released on 1 December 2022.\n: Adds new endpoint type vpe(Virtual Private Endpoint) for cluster config command.\n: Updates the cluster get command to show VPE url.\n: Adds infrastructureTopology field to cluster response.\n: Adds JSON output to Satellite get host command.\n\n\n\n\n\n Version 1.0.459 \n\nVersion 1.0.459 of the CLI was released on 21 October 2022.\n: Adds the --infrastructure-topology option for the ibmcloud oc cluster create satellite command.\n: Adds new ibmcloud oc flavor get and ibmcloud oc flavor ls commands.\n\n\n\n\n\n Version 1.0.454 \n\nVersion 1.0.454 of the CLI was released on 3 October 2022.\n: Adds new [Ingress status](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clialb-commands) commands.\n: Adds the --operating-system option for the cluster create commands.\n\n\n\n\n\n Version 1.0.452 \n\nVersion 1.0.452 of the CLI was released on 21 September 2022.\n: Updates the help text in various languages.\n\n\n\n\n\n Version 1.0.446 \n\nVersion 1.0.446 of the CLI was released on 12 September 2022.\n: Adds --pod-network-interface-selection option to location create flow.\n\n\n\n\n\n Version 1.0.444 \n\nVersion 1.0.444 of the CLI was released on 8 September 2022.\n: Adds Secrets Manager registration to cluster create flow.\n: Adds worker-pool OS support.\n: Removes Ingress migration command support.\n\n\n\n\n\n Version 1.0.439", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_cli_changelog"}, {"document_id": "ibmcld_14851-8096-10277", "score": 16.04149776533904, "text": "\nThis can be verified with the vSAN Health Service by clicking Home > Hosts and Clusters, then select the vSAN Cluster. Click the Monitor tab, vSAN and then click Health. Review the Test Results.\n* No active resync at the start of the upgrade process by clicking Home > Hosts and Clusters, then select the vSAN Cluster and click the vSAN tab and then click Resync Components. The Resync components count should be 0. Some resync activity is expected during the upgrade process, as data needs to be synchronized following host restarts.\n\n\n\n* vSphere ESXi host preparation - When you move a host into maintenance mode in a vSAN cluster, you have three options to choose:\n\n\n\n* No data migration - If you select this option, vSAN does not evacuate any data from this host. If you power off or remove the host from the cluster, some virtual machines (VMs) might become inaccessible.\n* Ensure availability - If you select this option, vSAN allows you to move the host into maintenance mode faster than Full data migration and allows access to the VMs in the environment.\n* Full data migration\n\n\n\n* Exit maintenance mode and resync - When the vSphere ESXi host is upgraded and moved out of maintenance mode, a resync occurs. You can see this through the VMware vSphere Web Client. Ensure this is complete before you move onto the next host. A resync is occurring as the host that is updated can now contribute to the vSAN datastore again. It is vital to wait until this resync is complete to ensure that there is no data loss.\n* After starting a vSAN Cluster upgrade:\n\n\n\n* Do not attempt to upgrade a cluster by introducing new versions to the cluster and migrating workloads.\n* If introducing new hosts, ensure that they are of the same initial version and upgrade them along with the rest of the cluster.\n* If you are adding or replacing disks during an upgrade, ensure that they are formatted with the appropriate legacy on-disk format version, if applicable.\n* Therefore, certain vSAN behavior changes are controlled by the on-disk format it is important that newer on-disk format versions are not introduced into a mixed-version cluster.\n\n\n\n\n\n\n\n\n\n Upgrade the vCenter Server Appliance", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vum-updating-vsan"}, {"document_id": "ibmcld_05684-2632-4362", "score": 15.926222646334663, "text": "\nVersion 1.0.480 of the CLI was released on 14 December 2022.\n: Adjusted ibmcloud ks flavor get and ibmcloud ks flavor ls commands to show secondary storage details.\n: Introduced Secondary Storage Configuration for worker-pool get.\n: Added Ignored Errors to ingress status-report.\n\n\n\n\n\n Version 1.0.471 \n\nVersion 1.0.471 of the CLI was released on 1 December 2022.\n: Adds new endpoint type vpe(Virtual Private Endpoint) for cluster config command.\n: Updates the cluster get command to show VPE url.\n: Adds infrastructureTopology field to cluster response.\n: Adds JSON output to Satellite get host command.\n\n\n\n\n\n Version 1.0.459 \n\nVersion 1.0.459 of the CLI was released on 21 October 2022.\n: Adds the --infrastructure-topology option for the ibmcloud ks cluster create satellite command.\n: Adds new ibmcloud ks flavor get and ibmcloud ks flavor ls commands.\n\n\n\n\n\n Version 1.0.454 \n\nVersion 1.0.454 of the CLI was released on 3 October 2022.\n: Adds new [Ingress status](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clialb-commands) commands.\n: Adds the --operating-system option for the cluster create commands.\n\n\n\n\n\n Version 1.0.452 \n\nVersion 1.0.452 of the CLI was released on 21 September 2022.\n: Updates the help text in various languages.\n\n\n\n\n\n Version 1.0.446 \n\nVersion 1.0.446 of the CLI was released on 12 September 2022.\n: Adds --pod-network-interface-selection option to location create flow.\n\n\n\n\n\n Version 1.0.444 \n\nVersion 1.0.444 of the CLI was released on 8 September 2022.\n: Adds Secrets Manager registration to cluster create flow.\n: Adds worker-pool OS support.\n: Removes Ingress migration command support.\n\n\n\n\n\n Version 1.0.439 \n\nVersion 1.0.439 of the CLI was released on 26 Aug 2022.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_cli_changelog"}, {"document_id": "ibmcld_12725-0-1775", "score": 15.879810124670666, "text": "\n\n\n\n\n\n\n  Change log: IBM Cloud Kubernetes Service Benchmark \n\nIn this change log, you can learn about the latest changes, improvements, and updates for the IBM Cloud Kubernetes Service profile. The change log lists changes that were made, ordered by the version number.\n\nTo work with this profile, you must connect an instance of [Workload Protection](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance=setup-workload-protection).\n\n\n\n  Profile versioning \n\nWhen specifications or controls are edited, removed from, or added to a profile in a way that is not compatible with the current version, a new version is released. To take advantage of the changes in a new version, update your attachments to use the newest profile version.\n\nThis profile is consistently updated and is not an exhaustive list of all the controls that might be required for every organization. Be sure to validate the available controls to determine where you might need to supplement your workloads with other security measures.\n\n\n\n  Active versions \n\nThe following table shows the service behavior changes for each version date. Switching to a later version date activates all changes that are introduced in earlier versions.\n\n\n\nTable. Active versions of the IBM Cloud Kubernetes Service Benchmark\n\n Version number   Release date \n\n Version 1.0.0    2023-07-12   \n\n\n\n\n\n\n\n\n\n  Version 1.0.0 \n\nNow available\n:   Released today, 12 July 2023, the IBM Cloud Kubernetes Service Benchmark is a collection of controls designed to validate the configuration of your Kubernetes Service clusters. This profile introduces the concept of wp-rule assessments. These are assessments that are defined by the Workload Protection service and imported into Security and Compliance Center.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-iks-profile"}, {"document_id": "ibmcld_02114-36409-38347", "score": 15.39843975558384, "text": "\nFor more information, see [ibmcloud catalog offering version cra](https://cloud.ibm.com/docs/account?topic=account-manage-catalogs-pluginversion-cra) and [ibmcloud catalog offering version scc](https://cloud.ibm.com/docs/account?topic=account-manage-catalogs-pluginversion-scc).\n\nibmcloud catalog offering get-scan-results [--version-locator LOCATOR]\n\n\n\n Command options \n\n--version-locator LOCATOR\n: To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you want to use.\n\n\n\n\n\n\n\n ibmcloud catalog offering version create-draft \n\nRun the following command to create a draft of an existing version. This command is useful for changing an existing version that you want to publish without introducing a new version. Some changes, like changing the source file, require you to revalidate the product.\n\nibmcloud catalog offering version create-draft --version-locator VERSION_NUMBER [--output FORMAT]\n\n\n\n Command options \n\n--version-locator VERSION_NUMBER\n: To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you want to use.\n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n\n\n ibmcloud catalog offering version delete-version \n\nRun the following command to delete a version of a product.\n\nibmcloud catalog offering version delete-version --version-locator VERSION_NUMBER [--output FORMAT]\n\n\n\n Command options \n\n--version-locator VERSION_NUMBER\n: To get the version locator for the product, run the ibmcloud catalog offering list command and locate the specified product or version you want to use.\n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-manage-catalogs-plugin"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_11192-0-1195", "score": 22.464905838467544, "text": "\n\n\n\n\n\n\n  Exploring scorecards \n\nYou can use different approaches to add data to your metrics cube.\n\nScorecards reflect the strategic goals of an organization. Using scorecards, you can identify how well objectives are being met by comparing targets to actual results. Visual status indicators such as traffic lights, trend icons, and colors are used to help you to quickly evaluate performance.\n\nIn Planning Analytics with Watson, you can add existing scorecards to your books, and analyze data by selecting different time periods, metrics, and dimensions. You can also create visualizations from scorecards, such as impact diagrams and strategy maps.\n\nYou can explore scorecards in Planning Analytics with Watson with the GO_Scorecards sample.\n\n\n\n*  [Scorecards](https://www.ibm.com/docs/planning-analytics/2.0.0?topic=es-scorecards)\n\n\n\nA scorecard is a collection of performance metrics that are designed to reflect the strategic goals of your business unit or organization.\n\n\n\n*  [Metrics cubes](https://www.ibm.com/docs/planning-analytics/2.0.0?topic=es-metrics-cubes)\n\n\n\nA metrics cube is a special type of cube that provides the basis for scorecard solutions and scorecard diagrams.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/planning-analytics?topic=planning-analytics-exploring-scorecards"}, {"document_id": "ibmcld_09615-10623-12269", "score": 20.2249512156819, "text": "\n\"containers-kubernetes\"\n]\n},\n{\n\"operand\": \"location\",\n\"operator\": \"in\",\n\"values\":\n\"us-south\",\n\"eu-de\"\n]\n}\n]\n}]\nShow more\n\nWhere:\n\naction\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-cloud-services-mr)", "title": "", "source": "https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-metrics-router-cli"}, {"document_id": "ibmcld_09615-4729-6393", "score": 20.174480510985987, "text": "\n{\n\"operand\": \"location\",\n\"operator\": \"in\",\n\"values\":\n\"us-south\",\n\"eu-de\"\n]\n}\n]\n}]\nShow more\n\nWhere:\n\naction\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource", "title": "", "source": "https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-metrics-router-cli"}, {"document_id": "ibmcld_09615-2350-4116", "score": 20.086129004820897, "text": "\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-cloud-services-mr)\n\n--rules RULES", "title": "", "source": "https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-metrics-router-cli"}, {"document_id": "ibmcld_09615-8271-10037", "score": 20.086129004820897, "text": "\n: Action defines whether IBM Cloud\u00ae Metrics Routing includes or excludes metrics on the route. Two actions are supported: send and drop. If not specified, the default action is to send the metrics.\n\nsend\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalues\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, values must include a single string. When the inoperator is used, values can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-cloud-services-mr)\n\n--rules RULES", "title": "", "source": "https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-metrics-router-cli"}, {"document_id": "ibmcld_09628-1427-3147", "score": 20.04610022970025, "text": "\n: Metrics are sent, based on the routing rule, on the defined route.\n\ndrop\n: Metrics are excluded, based on the routing rule, when metrics are sent on the defined route.\n\n\n\n\n\n Inclusion filters \n\nInclusion filters define the conditions that are used to determine which metrics are routed to the targets specified in the rule.\n\nTo route all metrics, exclude the inclusion_filters definition when you configure a route.\n\nInclusion filters are composed of an operand, operator, and value:\n\noperand\n: Operand is the name of the property in the target that is used to filter data. The following operands are supported: location, service_name, service_instance, resource_type, and resource. The value is extracted from the target CRN.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string. When the inoperator is used, value can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource", "title": "", "source": "https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-route_rules_definitions"}, {"document_id": "ibmcld_09623-1182-2897", "score": 20.00148247485529, "text": "\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string. When the inoperator is used, value can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-cloud-services-mr)\n\nFor example, to define an inclusion filter that defines the condition where only metrics that are generated in the us-south region are routed, looks as follows:\n\n{\"operand\": \"location\",\"operator\": \"is\",\"values\": \"us-south\"}\n\n\n\n\n\n Configure the route \n\nRun the following command to exclude all metrics received by IBM Cloud Metrics Routing from the us-south region.\n\nibmcloud metrics-router route create --name drop-route --rules '[{\"action\": \"drop\", \"inclusion_filters\":{\"operand\": \"location\",\"operator\": \"is\",\"values\": \"us-south\"}]}]'\n\nWhere inclusion_filters specifies the filters.", "title": "", "source": "https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-route-drop"}, {"document_id": "ibmcld_09623-4-1600", "score": 19.87935378234638, "text": "\n* CLI\n\n\n\n\n\n\n\n Excluding metrics by using the drop action \n\nYou can configure IBM Cloud\u00ae Metrics Routing to exclude (drop) metrics based on a configured rule. Dropped metrics are not sent on to a target.\n\n\n\n Prereqs \n\n\n\n1. [Install the IBM Cloud CLI](https://cloud.ibm.com/docs/cli?topic=cli-install-ibmcloud-cli).\n2. [Install the IBM Cloud Metrics Routing CLI](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-metrics-router-cli-config).\n3. Ensure you have the [correct IAM permissions to configure IBM Cloud Metrics Routing routes.](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-iam)\n4. Log in to IBM Cloud. Run the following command: [ibmcloud login](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_cliibmcloud_login).\n\n\n\n\n\n\n\n Define the inclusion filter \n\nInclusion filters determine which metrics are routed to the targets.\n\nInclusion filters are comprised of an operand, operator, and values:\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location, service_name, service_instance, resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string.", "title": "", "source": "https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-route-drop"}, {"document_id": "ibmcld_09625-1179-2989", "score": 19.798337253705732, "text": "\nStep 2: Define the inclusion filter \n\nInclusion filters determine which metrics are routed to the targets.\n\nInclusion filters are comprised of an operand, operator, and values:\n\noperand\n: Operand is the name of the property on which the operator test is run. The following operands are supported: location,service_name,service_instance,resource_type, and resource.\n\noperator\n: Two operators are supported: in and is.\n\nin\n: The value of the operand property is compared to a list of values.\n\nYou can define up to 20 values.\n\nis\n: The value of the operand property is compared to a single value.\n\nWhen using is, only 1 value can be specified.\n\nvalue\n: A string, or an array of strings, to be compared with the operand property to determine whether the metric is routed or not. When the isoperator is used, value must include a single string. When the inoperator is used, value can include multiple strings in an array.\n\nValid values depend on the operand.\n\nlocation\n: Any location where [IBM Cloud Metrics Routing is available.](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-regions)\n\nservice_name\n: The CRN service name of an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-cloud-services-mr)\n\nservice_instance, resource_type, and resource\n: Values appropriate to an [IBM Cloud service that generates metrics managed through [IBM Cloud Metrics Routing](https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-cloud-services-mr)\n\nFor example, to define an inclusion filter that defines the condition where only metrics that are generated in the us-south region are routed, looks as follows:\n\n{\"operand\": \"location\",\"operator\": \"is\",\"values\": \"us-south\"}\n\n\n\n\n\n Step 3: Configure the route", "title": "", "source": "https://cloud.ibm.com/docs/metrics-router?topic=metrics-router-route-from-1-location"}, {"document_id": "ibmcld_04612-2600-4714", "score": 19.22550283383868, "text": "\nThe CPU utilization can be affected by the total workload of the hosting hardware and other factors.\n* Responsetime is the average amount of time that the app takes to respond to a request. Responsetime is specified in ms (milliseconds).\n* Throughput is the total number of the requests that are processed in a time period. Throughput is specified in rps (requests per second).\n* Custom_metric is your own custom metric. The Custom_metric name can be any alphanumeric value. Autoscaling is triggered when the corresponding metric is emitted to the App Autoscaler. For more information, see the [custom metric usage guide](https://github.com/cloudfoundry/app-autoscaler/tree/develop/docsauto-scale-your-application-with-custom-metrics).\n\n\n\nIn addition to specifying the metric type, specify an operator, threshold, breach duration, adjustment, and cooldown period values.\n\nWhen the threshold is continuously breached during the breach duration period, and beyond the cooldown period, the App AutoScaler triggers the defined autoscaling action. The number or percentage of app instances is adjusted.\n\n\n\n* The operator can be >=, >, <=, or <.\n* The threshold must be a numeric value.\n* The breach duration is defined in seconds. The default value is 120 seconds.\n* The adjustment value specifies how the number of app instances change in each scaling action. You can specify an absolute number or a percentage of instances to add or remove.\n* The cooldown period specifies the time to wait before the taking the next autoscaling action. A cooldown period ensures that your app does not launch new instances or stop existing instances before your app is stable. The cooldown period is specified in seconds. The default cooldown period is 300 seconds.\n\n\n\n4. (Optional) Define Schedules to scale your app during a set time period.\n\nYou can define specific time periods when you know that your app requires different numbers of instances to handle peak loads. The schedule policy overwrites the default instance limits and sets the number of instances to the Initial Minimum Instance Count value for the scheduled period.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-autoscale_cloud_foundry_apps"}]}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07126-7-2254", "score": 12.872183685955527, "text": "\nGetting the most from Discovery \n\nDiscovery was redesigned to introduce new features and a simpler way to build solutions.\n\nThe redesigned product is referred to as Discovery v2. When you create an instance on IBM Cloud or install and provision an instance on IBM Cloud Pak for Data, you get the new and improved version of Discovery.\n\n\n\n Advantages of using the latest version \n\nDiscovery v2 offers the following features and enhancements:\n\n\n\n* A project-based experience that supports many different use cases within a single environment.\n* Built-in customization tools for adding dictionaries, patterns, and classifiers to help business users build projects that understand the language of their domain.\n* Connectors to popular data sources that can quickly access valuable data where it resides.\n* Smart Document Understanding that learns from the structure of human-readable documents, such as PDFs.\n* Natural language query support across all document types, optimized with machine learning to find targeted answers.\n* Advanced search capabilities, such as answer finding, curations, and table retrieval.\n* An out-of-the-box contract understanding function that helps you search and interpret legal contracts.\n* A full-featured Content Mining application that you can use to conduct in-depth analysis of unstructured text.\n* Customizable user interface components that help you to deploy custom applications.\n\n\n\nFor more information, see [Migrating to Discovery v2](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-migrate-to-v2).\n\n\n\n\n\n Comparing v1 and v2 features \n\nIf you are already familiar with Discovery v1, learn more about how Discovery v2 compares.\n\nDiscovery v2 has new features that were previously unavailable. The following table describes feature support in both versions.\n\n\n\nFeature support details\nThis table has row and column headers. The row headers identify features. The column headers identify the different versions of the product. To understand which features are supported by a product version, go to the row that describes the feature, and find the column for the product version that you are interested in.\n\n Feature Product redesign (v2) Earlier version (v1) \n\n Use projects to organize your work !", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-version-choose"}, {"document_id": "ibmcld_01718-1246-2892", "score": 12.235087801859425, "text": "\nActive version \n\nThe following table shows the behavior changes for each version.\n\n\n\nTable 1. IAM Policy Management API versions\n\n Version Summary of changes \n\n v2 New schema to support conditions and advanced operators dealing with date and time \n v1 Initial version of IAM Policy Management API \n\n\n\nThe v1 API is not forwards compatible with the v2 API. You can't add conditions to a policy that is created with the v1 API. To add conditions, you must delete the v1 policy and replace it with a new access policy that includes conditions.\n\n\n\n\n\n\n\n 25 January 2023 \n\nThis change log introduces a new version (v1 -> v2) of the IAM Policy Management API. This version adds a new JSON schema to support a conditional policy construct and several time-based comparison operators. These operators provide the capability to restrict access based on time and date. With time-based access control, customers can establish granular policy enforcement based on a specified time period.\n\nTo get started, see [Limiting access with time-based conditions](https://cloud.ibm.com/docs/account?topic=account-iam-time-based&interface=ui).\n\nFor detailed operator descriptions and examples, see: [Conditions in v2 access policies](https://cloud.ibm.com/docs/account?topic=account-iam-condition-propertiespolicy-condition-properties)\n\nThe new v2/polices schema provides backwards functional compatibility and allows for more complex comparisons and operators. The v1/polices schema remains supported and available. For more information, see [Comparing /v1/policies and /v2/policies syntax](https://cloud.ibm.com/docs/account?topic=account-known-issuescompare-syntax).", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-api-change-log"}, {"document_id": "ibmcld_03369-3070-5241", "score": 12.092814914090537, "text": "\nIt includes a new foundation model that is trained using a transformer architecture to improve intent detection and action matching for English.\n\nImprovements include:\n\n\n\n* Improved robustness to variations in user inputs such as typos and different inflection forms\n* Less training data required to reach the same level of performance compared to previous algorithms\n\n\n\nFor more information, see [Algorithm version and training](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-algorithm-version).\n\n\n\n\n\n 16 April 2023 \n\nAutolearning beta for dialog skills removed\n: As of this release, the autolearning beta has been removed from the Analytics section in dialog skills. In the new experience, you can test a new and improved autolearning beta. For more information, see [Using autolearning to improve assistant responses](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-autolearn).\n\n\n\n\n\n 16 March 2023 \n\nNew algorithm version Latest (20 Dec 2022) provides improved irrelevance detection\n: A new algorithm version is available. The Latest (20 Dec 2022) version includes a new irrelevance detection implementation to improve off-topic detection accuracy.\n\nImprovements include:\n\n\n\n* Relevant user inputs are expected to get higher confidence, so they are less likely to be considered irrelevant or require clarification\n* Irrelevance detection is improved in the presence of direct entity references\n* Irrelevance detection is more stable across small changes to input\n* Intent detection is more stable regarding occurrence of numerics, such as postal codes\n* For German-language assistants, intent detection is more robust in the presence of umlauts\n\n\n\nThis algorithm was first introduced as the Beta version in June 2022. Since then, support for more languages has been added. This algorithm version was stabilized in December 2022 with minor enhancements since that time.\n\nWith this new release, the June 1, 2022 version is now labeled as Previous (01 Jun 2022). The oldest release labeled as 01 Jan 2022 is no longer available for training. As of now, the new Beta version has the same behavior as the Latest (20 Dec 2022) version.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_16364-9056-11175", "score": 10.912657942522992, "text": "\n15 May 2023 \n\nChange to dialog skill context variables named request\n: If your dialog skill used a context variable that is named request, it was removed from the response payload of any /message calls in the V1 or V2 API, or through the Watson Assistant user interface. After 15 May 2023, this behavior changes. Watson Assistant doesn't remove context variables that are named request from the response payload anymore.\n\n\n\n\n\n 5 May 2023 \n\nNew validation choices for date, time, and numeric customer responses\n: For Number, Date, Time, Currency, and Percentage customer responses, you can now customize the validation to check for a specific answer, such as a range of dates or a limited currency amount. For more information, see [Customizing validation for a response](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errorscustomize-validation).\n\n\n\n\n\n 3 May 2023 \n\nAlgorithm version Beta provides improved intent detection and action matching\n: The algorithm version Beta now provides improved intent detection and action matching. It includes a new foundation model that is trained using a transformer architecture to improve intent detection and action matching for English.\n\nImprovements include:\n\n\n\n* Improved robustness to variations in user inputs such as typos and different inflection forms\n* Less training data required to reach the same level of performance compared to previous algorithms\n\n\n\nFor more information, see [Algorithm version and training](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-algorithm-version).\n\n\n\n\n\n 24 April 2023 \n\nResponse modes randomization behavior\n: The response modes beta now uses the same randomization behavior during clarification that your actions have without response modes enabled. Previous to this change, when response modes were enabled, the clarification feature no longer periodically modified the options for clarification. Randomizing the clarification helps prevent bias that can be introduced by a percentage of people who always pick the first option without carefully reviewing all of their choices beforehand.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_08733-2552-4062", "score": 10.839329490114416, "text": "\nNot all PKCS #11 functions are implemented by IBM Cloud\u00ae Hyper Protect Crypto Services. For the implemented PKCS #11 functions, see\n\n[Supported PKCS #11 functions](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-pkcs11-api-refpkcs11_function_list).\n\nTo review the PKCS #11 standard documentation, see:\n\n\n\n* [Cryptographic Token Interface Usage Guide Version 2.40](http://docs.oasis-open.org/pkcs11/pkcs11-ug/v2.40/pkcs11-ug-v2.40.html)\n* [Cryptographic Token Interface Base Specification Version 2.40 Plus Errata 01](http://docs.oasis-open.org/pkcs11/pkcs11-base/v2.40/pkcs11-base-v2.40.html)\n* [Cryptographic Token Interface Current Mechanisms Specification Version 2.40 Plus Errata 01](http://docs.oasis-open.org/pkcs11/pkcs11-curr/v2.40/pkcs11-curr-v2.40.html)\n\n\n\n\n\n PKCS 11 implementation components \n\nTo connect and use the PKCS #11 API, you need to understand the PKCS #11 API that is implemented by Hyper Protect Crypto Services and the relationship with the GREP11 API. For more information, see\n\n[Comparing the PKCS #11 API with the GREP11 API](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-uko-introduce-cloud-hsmuko-compare-grep11-pkcs11). With the support of the PKCS 11 API, you don't need to change your existing applications that use the PKCS 11 standard. Hyper Protect Crypto Services also provides the isolated keystores to store cryptographic keys generated by the PKCS 11 functions. These keys are protected by the master key and the applications never see the key files locally.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-uko-pkcs11-intro"}, {"document_id": "ibmcld_16034-7-1778", "score": 10.621763349678288, "text": "\nVPC CLI release notes \n\nThe following release notes are for the IBM Cloud\u00ae Virtual Private Cloud (VPC) command line interface (CLI).\n\n\n\n v6.15.0 \n\nVersion 6.15.0 was released on 2023-07-11.\n\n\n\n New commands \n\n\n\n* New commands image-obsolete and image-deprecate are introduced to support image lifecycle management.\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for image lifecycle management in image-create, image-update, and images commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.14.1 \n\nVersion 6.14.1 was released on 2023-06-30.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed issue with using the SSH key generated from UI in CLI.\n\n\n\n\n\n\n\n\n\n v6.14.0 \n\nVersion 6.14.0 was released on 2023-06-23.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for more algorithms in the SSH key key-create command.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.13.0 \n\nVersion 6.13.0 was released on 2023-06-22.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for snapshot and backup cross region copy in snaphot-create, snapshots, backup-policy-plan-create and backup-policy-plan-update commands.\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n\n\n v6.12.0 \n\nVersion 6.12.0 was released on 2023-06-01.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands \n\n\n\n* Added support for fileshare mount targets in share commands (Beta).\n\n\n\n\n\n\n\n Removed commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Notes \n\n\n\n* Fixed bare-metal-server-network-interfaces, bare-metal-server-profiles and bare-metal-servers commands to print correct response values.\n\n\n\n\n\n\n\n\n\n v6.11.1 \n\nVersion 6.11.1 was released on 2023-05-03.\n\n\n\n New commands \n\n\n\n* N/A\n\n\n\n\n\n\n\n Updated commands", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-cli-rn"}, {"document_id": "ibmcld_16446-7-1856", "score": 10.497411781252769, "text": "\nRelease notes \n\nThe following new features and changes to IBM Watson\u2122 Knowledge Studio for IBM Cloud Pak\u00ae for Data are available.\n\nFor details about what's new, see the IBM Cloud Pak for Data documentation.\n\n\n\n* [4.5.x](https://www.ibm.com/docs/SSQNUZ_4.5.x/fixlist/wks-fixlist.html)\n\n\n\n\n\n Version 1.2.0 (9 December 2020) \n\n\n\n* Security and stability fixes\n\n\n\n* Several security fixes and stability enhancements have been introduced.\n\n\n\n\n\n\n\n\n\n Version 1.1.3 (31 August 2020) \n\n\n\n* Security and stability fixes\n\n\n\n* Several security fixes and stability enhancements have been introduced.\n\n\n\n\n\n\n\n\n\n Version 1.1.2 (19 June 2020) \n\n\n\n* Enhanced pre-annotation workflow.\n\n\n\n* Run multiple pre-annotators at once and configure the order of pre-annotators to resolve annotation conflicts between them. Existing pre-annotator results are preserved unless you remove them with the Wipe option.\n* Human annotations are preserved when running pre-annotators, even when using the Wipe option.\n\n\n\n\n\n\n\n\n\n Version 1.1.1 (28 February 2020) \n\n\n\n* New advanced rules tokenizer Advanced rules has introduced a new tokenizer which is not compatible with the previous one. The following extractor categories are affected:\n\n\n\n* Parts of Speech extractor names are renamed automatically\n* Cardinal is renamed to Numeral\n* Preposition is renamed to Adposition\n* Machine Data Analytics Splitter extractors have been removed and will disappear from the canvas. There is no substitute for these extractors that is provided by the new tokenizer.\n* Generic Splitters:\n\n\n\n* Date Time Splitter\n* Day First Splitter\n* Month First Splitter\n* Year First Splitter\n\n\n\n* Syslog Splitter:\n\n\n\n* Date Time Splitter\n\n\n\n\n\n* Cross-sentence relations (Experimental): English entities and relations workspaces can now support annotating relations between entities within spans of six sentences.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-release-notes"}, {"document_id": "ibmcld_10140-2632-4302", "score": 10.428044346276025, "text": "\nVersion 1.0.480 of the CLI was released on 14 December 2022.\n: Adjusted ibmcloud oc flavor get and ibmcloud oc flavor ls commands to show secondary storage details.\n: Introduced Secondary Storage Configuration for worker-pool get.\n: Added Ignored Errors to ingress status-report.\n\n\n\n\n\n Version 1.0.471 \n\nVersion 1.0.471 of the CLI was released on 1 December 2022.\n: Adds new endpoint type vpe(Virtual Private Endpoint) for cluster config command.\n: Updates the cluster get command to show VPE url.\n: Adds infrastructureTopology field to cluster response.\n: Adds JSON output to Satellite get host command.\n\n\n\n\n\n Version 1.0.459 \n\nVersion 1.0.459 of the CLI was released on 21 October 2022.\n: Adds the --infrastructure-topology option for the ibmcloud oc cluster create satellite command.\n: Adds new ibmcloud oc flavor get and ibmcloud oc flavor ls commands.\n\n\n\n\n\n Version 1.0.454 \n\nVersion 1.0.454 of the CLI was released on 3 October 2022.\n: Adds new [Ingress status](https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-clialb-commands) commands.\n: Adds the --operating-system option for the cluster create commands.\n\n\n\n\n\n Version 1.0.452 \n\nVersion 1.0.452 of the CLI was released on 21 September 2022.\n: Updates the help text in various languages.\n\n\n\n\n\n Version 1.0.446 \n\nVersion 1.0.446 of the CLI was released on 12 September 2022.\n: Adds --pod-network-interface-selection option to location create flow.\n\n\n\n\n\n Version 1.0.444 \n\nVersion 1.0.444 of the CLI was released on 8 September 2022.\n: Adds Secrets Manager registration to cluster create flow.\n: Adds worker-pool OS support.\n: Removes Ingress migration command support.\n\n\n\n\n\n Version 1.0.439", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_cli_changelog"}, {"document_id": "ibmcld_14851-9765-11592", "score": 10.39255992025474, "text": "\n* If introducing new hosts, ensure that they are of the same initial version and upgrade them along with the rest of the cluster.\n* If you are adding or replacing disks during an upgrade, ensure that they are formatted with the appropriate legacy on-disk format version, if applicable.\n* Therefore, certain vSAN behavior changes are controlled by the on-disk format it is important that newer on-disk format versions are not introduced into a mixed-version cluster.\n\n\n\n\n\n\n\n\n\n Upgrade the vCenter Server Appliance \n\nFor more information, see [VCSA update and SSO-linked vCenters](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vum-updating-vcsa).\n\n\n\n\n\n Upgrade the vSphere ESXi hosts \n\nFor more information, see [Creating baselines and attaching to inventory objects](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vum-baselines).\n\n\n\n\n\n Upgrade the vSAN disk format \n\nRuby vSphere Console (RVC) is a Ruby-based command-line interface for vSphere and can be used to manage VMware vSphere ESXi and vCenter. The vSphere inventory is presented in a tree structure, that allows you to navigate and run commands against vCenter objects.\n\nMany basic administrative tasks can be done much more efficiently than clicking through the vSphere Client. RVC is fully implemented in the VCSA and is accused by an SSH connection to the appliance.\n\n\n\n1. SSH to the VCSA and login by using root and the password that is provided on the ICVS Console.\n2. At the prompt, type: rvc Administrator@vsphere.local@localhost and press Enter.\n3. Enter the Administrator\u2019s password provided on the ICVS Console. You are now at the root of the virtual file system, type ls and then press Enter. The output is: 0 / 1 localhost/\n4. Type cd 1, enter and then ls and press Enter. The output is: 0 / datacenter1 (datacenter)\n5.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vum-updating-vsan"}, {"document_id": "ibmcld_12725-0-1775", "score": 10.363070661346377, "text": "\n\n\n\n\n\n\n  Change log: IBM Cloud Kubernetes Service Benchmark \n\nIn this change log, you can learn about the latest changes, improvements, and updates for the IBM Cloud Kubernetes Service profile. The change log lists changes that were made, ordered by the version number.\n\nTo work with this profile, you must connect an instance of [Workload Protection](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance=setup-workload-protection).\n\n\n\n  Profile versioning \n\nWhen specifications or controls are edited, removed from, or added to a profile in a way that is not compatible with the current version, a new version is released. To take advantage of the changes in a new version, update your attachments to use the newest profile version.\n\nThis profile is consistently updated and is not an exhaustive list of all the controls that might be required for every organization. Be sure to validate the available controls to determine where you might need to supplement your workloads with other security measures.\n\n\n\n  Active versions \n\nThe following table shows the service behavior changes for each version date. Switching to a later version date activates all changes that are introduced in earlier versions.\n\n\n\nTable. Active versions of the IBM Cloud Kubernetes Service Benchmark\n\n Version number   Release date \n\n Version 1.0.0    2023-07-12   \n\n\n\n\n\n\n\n\n\n  Version 1.0.0 \n\nNow available\n:   Released today, 12 July 2023, the IBM Cloud Kubernetes Service Benchmark is a collection of controls designed to validate the configuration of your Kubernetes Service clusters. This profile introduces the concept of wp-rule assessments. These are assessments that are defined by the Workload Protection service and imported into Security and Compliance Center.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-iks-profile"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07108-2897-3942", "score": 20.80234005445844, "text": "\nYou can use the [expansions.json](https://watson-developer-cloud.github.io/doc-tutorial-downloads/discovery/expansions.json) file as a starting point when you build a query expansion list.\n2. From the navigation pane, open the Improve and customize page.\n3. Expand Improve relevance from the Improvement tools pane.\n4. Click Synonyms, and then click Upload synonyms for the collection.\n\nDo not upload a synonyms file while documents are being added to your collection. The ingestion processing that occurs when documents are added can cause the index to be unavailable.\n\nOnly one synonyms list can be uploaded per collection. If a second expansion list is uploaded, the second list replaces the first.\n5. Run a test query to verify that the query expansion is working as expected.\n\nQuery expansions are applied at query time, not during indexing, so you can add synonyms without reprocessing your collection.\n\n\n\nTo disable query expansion, delete the synonyms file. However, do not delete a synonyms file while new documents are being processed.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-search-settings"}, {"document_id": "ibmcld_07115-7009-9068", "score": 20.381921389401597, "text": "\n* The rating that you apply to the result that indicates whether the result is relevant or not relevant\n\n\n\nTo apply relevancy training to a project, complete the following steps:\n\n\n\n1. Go to the Improve and customize page. On the Improvement tools panel, select Improve relevance, then Relevancy training.\n2. Enter a natural language query in the Enter a question to train field.\n\nDo not include a question mark in your query. Use the same wording as your users. For example, IBM Watson in healthcare. Write queries that include some of the terms that are mentioned in the target answer. Term overlap improves the initial results when the natural language query is evaluated.\n3. Click Add+.\n4. Click Rate results.\n5. After the results are displayed, assess each result, and then select Relevant or Not relevant, whichever option applies given the quality of the result.\n\nWhen you select Relevant, you apply a score of 10 to the result. Not relevant applies a score of 0. You can use a different scoring scale if you use the API to rate results, but you can't mix scoring scales within the same project.\n\nIf the result shows the message, \u201cNo content preview available for this document\u201d, it means that the document that was returned does not contain a text field or that its text field is empty. If none of the documents in your collection have a text field, use the API to train the project instead of training it from the product user interface.\n6. When you are finished, click Back to queries.\n7. Continue adding queries and rating them.\n\nAs you rate results, your progress is shown. Check your progress to see when enough rating information is available to meet the training threshold needs. Your progress is broken into the following tasks:\n\n\n\n* Add more queries\n* Rate more results\n* Add more variety to your ratings\n\n\n\nYou must evaluate at least 50 unique queries, maybe more, depending on the complexity of your data. You cannot add more than 10,000 training queries.\n8. You can continue adding queries and rating results after you reach the threshold.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-train"}, {"document_id": "ibmcld_07214-65893-68177", "score": 19.590035298479236, "text": "\n: The new version string enables enrichments in German (de) or Spanish (es) if the language of a collection is set to one of those languages. Previously, all enrichments were performed in English regardless of a collection's language setting. : If you do not use enrichments in non-English languages, you can continue to use the 2016-12-01 version string. However, to avoid potential future conflicts, it is recommended that you update the version string as soon as possible.\n\nNew anomaly detection availability : Anomaly detection is now available as part of timeslice aggregations as a GA capability.\n\nNew beta improvement to relevancy tooling : Added the beta ability to improve the relevancy of query results using the Discovery tooling (relevancy tooling). See [Improving the relevance of your query results with the Discovery tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n 19 June 2017 \n\nNew select language of documents : Added option to specify the language of the documents in a new collection as English, Spanish, or German. To use it, choose Select the language of your documents on the Name your new collection dialog.\n\nAdded a Summary tab to the Build queries screen : The Summary tab displays an overview of the full query results provided in the existing JSON tab. The Summary display varies, based on your query and enrichments. Information that might be displayed includes: document name or ID, aggregation statistics, document passages in order of relevance, and results by enrichment.\n\nAdded a Natural Language Query option to the Build queries screen : To use it, click Ask a question in plain language in the Search for documents section, and a field displays where you can enter your question. You can now access the original query field, formerly titled Enter a query or keyword, by clicking the Use the Discovery Query Language button.\n\nThe Build queries screen was redesigned, but all fields and options remain. : Following are the old and new names for the fields.\n\n Old field name New field or section name \n\n Write and run a query Search for documents \n Narrow your query results (Filter) Limit which documents you query \n Group query results (Aggregation) Include analysis of your results", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-release-notes"}, {"document_id": "ibmcld_07150-7-2267", "score": 19.346170671722895, "text": "\nContinuous Relevancy Training \n\nDiscovery Continuous Relevancy Training can learn from user behavior automatically, significantly reducing the effort required to improve the relevancy ranking of results. It uses interactions from users to learn how to surface the most relevant results. It can learn from interactions like clicks to determine which results are most valuable for users and uncover the most important signals for future queries. Continuous Relevancy Training reranks documents to surface the most relevant information at the top of the results. You can also use it for the following purposes:\n\n\n\n* Help improve the relevance of results for support agents, based on the results they click on\n* Display more relevant results in a customer chatbot based on the long-tail results selected\n* Provide experts with more relevant responses, based on the results they explore\n\n\n\nTo setup Continuous Relevancy Training:\n\n\n\n* Continuous Relevancy Training can only be enabled at the environment level. Queries must use either the /api/v1/environment/{environment_id}/query and /api/v1/environments/{environment_id}/query endpoints to query one or more collections.\n* Because Discovery events (clicks) are used to create the training data needed, first integrate event tracking. See [Usage monitoring](https://cloud.ibm.com/docs/discovery?topic=discovery-usage) for details.\n* A minimum of 1000 natural language queries with an associated click event are required for Continuous Relevancy Training to start. Events and logs are retained for 30 days across your instance so the 1000 clicks must be collected during that time period.\n* Continuous Relevancy Training is available for Advanced plans size Small or larger, and Premium plans. It is not available for Lite plans.\n* The number of collections for Continuous Relevancy Training is limited to 5. Because Continuous Relevancy Training works across multiple collections, both query and training times might be extended.\n* Continuous Relevancy Training only occurs on top-level fields, and there are limits to how many fields can be used in the training process. In cases where there are more than 10 top level fields, training is more likely to encounter errors.\n\n\n\nTo use Continuous Relevancy Training:", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-crt"}, {"document_id": "ibmcld_07214-74576-76512", "score": 18.864544664515424, "text": "\nNew support for 'sort' parameter in the query API : The query API (GET /v1/environments/{environment_id}/collections/{collection_id}/query) now supports the sort parameter, which enables you to specify a comma-separated list of fields in the document to sort on. See the [Query your collection](https://cloud.ibm.com/apidocs/discoveryquery-your-collection) method in the API reference for information.\n\nImproved handling by 'timeslice' parameter : The timeslice parameter for query aggregations now correctly handles dates in UNIX epoch format. See [Query reference](https://cloud.ibm.com/docs/discovery?topic=discovery-query-referenceaggregations) for information about aggregations and the timeslice parameter.\n\nUpdate to JavaSDK : The Discovery Java SDK has been updated. See the [API Reference](https://cloud.ibm.com/apidocs/discovery?language=java) for details.\n\nFixed known issues with wildcard limitations in queries : Only one wildcard worked in any given query. For example, query-month:ctober worked, but query-month:ctobe generated a parsing error. This is resolved. : Wildcards did not work with queries that contained capital letters. For example, given the key/field pair {\"borrower\": \"GOVERNMENT OF INDIA\"}, query-borrower:ndia returned results but query-borrower:NDIA did not. This is resolved. : Wildcards are not necessary within phrases in queries. For example, given the key/field pair {\"borrower\": \"GOVERNMENT OF TIMOR\"}, query-borrower:\"GOVERNMENT OF TIMOR\" returns results, but query-borrower:\"GOVERNMENT OF TIOR\" does not. Using a wildcard is not applicable within phrases because all of the characters within the quotation marks (\") of a phrase are escaped.\n\n\n\n\n\n 24 March 2017 \n\nNew feature for My data insights : Added filtering to the \"My data insights\" screen in the Discovery tooling.\n\n\n\n\n\n 15 March 2017 \n\nKnown issues : All fields that are ingested from HTML, PDF, and Word documents are typed as string.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-release-notes"}, {"document_id": "ibmcld_00460-32793-34849", "score": 18.806179907644214, "text": "\nPrefer: return=minimal header\n: Added the header Prefer: return=minimal to return only essential headers. This header reduces the size of the request, which gives a performance improvement to nonbrowser clients.\n\nDisabled JavaScript constructors\n: If a user calls the disabled JavaScript constructors, eval() or Function(), an error message similar to this one is returned, Call to eval() was blocked by CSP. You can fix the problem by replacing eval() calls with the calls from the [expr-eval library](https://github.com/silentmatt/expr-eval).\n\n\n\n\n\n 4 December 2017 \n\nRemoved support for virtual hosts\n: IBM Cloudant disabled the virtual host functionality on 4 December 2017. Support for insecure HTTP connections was replaced by HTTPS only. After you turn off HTTP support, the virtual hosts feature is no longer available since use of virtual hosts precludes secure HTTPS connections. Previous users of the virtual host feature need to make alternative arrangements to present a chosen hostname to your clients from your application and use HTTPS connections only.\n\n\n\n\n\n\n\n November 2017 \n\n\n\n 7 November 2017 \n\nIncompatibility between CouchDB version 1.6 and IBM Cloudant version 2.0.0\n: An incompatibility exists between the most recent version of IBM Cloudant and CouchDB 1.6-based codebase. In the older version of IBM Cloudant, if you add a query parameter (\"reduce=false\") to the request body, the parameter in the request body is ignored. However, the parameter in the request URL is respected. In recent versions of IBM Cloudant, the query parameter (\"reduce=false\") in the request body isn't ignored.\n\n\n\n\n\n\n\n October 2017 \n\n\n\n 17 October 2017 \n\nQuery (_find endpoint) improved\n: IBM Cloudant Query now uses a new method to select an index. Learn more about [IBM Cloudant Query index selection](https://www.ibm.com/support/pages/improving-cloudant-query-index-selection).\n\nIndex validation\n: The logic for determining whether a specific index is valid for a query that changed, addressing a bug that might lead to incorrect results.\n\nText indexes", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-classic-release-notes"}, {"document_id": "ibmcld_13075-3392-5440", "score": 18.624512384995263, "text": "\nYou are prompted to choose a collection to train.\n\n\n\n2. On the Train Watson screen, click Add a natural language query, for example: \"IBM Watson in healthcare\", and add it. Make sure your queries are written the way your users would ask them. Also, it is recommended that training queries be written with some term overlap between the query and the desired answer. This overlap improves initial results, when the natural language query is run. Relevance training only uses natural language queries, so do not enter queries written in the Discovery Query Language.\n3. To view the results of your query, click the Rate Results button next to it. If you don't think there are enough results, you could try rewriting the query, or adding more documents to this collection via the Manage data screen.\n4. Begin rating results as either Relevant or Not relevant. When you are done, click Back to queries. In the Discovery tooling, Relevant has a score of 10 and Not relevanthas a score of 0. If you already started rating results for this collection, using the API, and used a different scoring scale, a warning is displayed, with options to fix the issue. At the top of the screen, Watson tracks the training status and provides tips about what you can do to improve results. \"Add more variety to your ratings\" means that you might want to use both the Relevant and Not relevant ratings. After you meet the requirements, training starts updating periodically. Most training takes less than 30 minutes to complete, but you can continue working while training is underway.\n5. Continue adding queries and rating results.\n\n\n\nTo return to the main Build queries screen at any time, click Build queries on the upper left. To return to the Manage data screen, click the name of the collection on the upper right.\n\nIf you would like to delete all of the training data in your collection at one time, you must do so via the API. See [Delete all training data for a collection](https://cloud.ibm.com/apidocs/discoverydelete-all-training-data) for more information.", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-improving-result-relevance-with-the-tooling"}, {"document_id": "ibmcld_00460-28506-30205", "score": 18.59874735815484, "text": "\nThe parameter was replaced with the endpoint POST /{db}/_design/{ddoc}/_view/{view}/queries and is supplied as a queries request body parameter. You can also make multiple queries with the following new endpoints:\n\n\n\n* POST /{db}/_all_docs/queries\n* POST /{db}/_design_docs/queries\n\n\n\nSending several queries to a view\n: Sending multiple queries to a view that uses a POST request to /$DATABASE/_design/$DDOC/_view/$VIEWNAME is deprecated with [multi-querying a MapReduce view](https://cloud.ibm.com/apidocs/cloudantpostviewqueries). For more information, see the previous deprecation note about replacing the queries parameter.\n\n\n\n\n\n 4 April 2018 \n\nThe following changes were made in build 6875:\n\nNew! Audit facility\n: Internal audit facility is added to the platform.\n\nIBM Cloudant Query error messages\n: Improve error messages for IBM Cloudant Query.\n\n\n\n\n\n\n\n March 2018 \n\n\n\n 30 March 2018 \n\nThe following changes were made in build 6870:\n\nkill command\n: Fix how the kill command works when you terminate an operating system process.\n\n_changes endpoint\n: Fix _changes endpoint shard substitution.\n\nCompaction resumption\n: Fix compaction resumption for terminated compactions.\n\n\n\n\n\n 13 March 2018 \n\nThe following changes were made in build 6761:\n\nNew! _dbs_info endpoint\n: Introduce new _dbs_info endpoint to get information from a list of databases. See [Get a list of all databases in the instance](https://cloud.ibm.com/apidocs/cloudantgetalldbs).\n\nNew! Pluggable storage engine\n: Add a pluggable storage engine.\n\nImprovement\n: Update MochiWeb to version 2.17.\n\nAttachments\n: Ensure deterministic revisions for attachments. See [COUCHDB-3255](https://issues.apache.org/jira/browse/COUCHDB-3255).", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-classic-release-notes"}, {"document_id": "ibmcld_00460-34449-36370", "score": 18.438701941692347, "text": "\nQuery (_find endpoint) improved\n: IBM Cloudant Query now uses a new method to select an index. Learn more about [IBM Cloudant Query index selection](https://www.ibm.com/support/pages/improving-cloudant-query-index-selection).\n\nIndex validation\n: The logic for determining whether a specific index is valid for a query that changed, addressing a bug that might lead to incorrect results.\n\nText indexes\n: Queries that use text indexes no longer fail when $exists: false is used.\n\nPartial indexes\n: Partial indexes are now supported for both JSON and text indexes. For more information, see [Creating a partial index](https://cloud.ibm.com/apidocs/cloudantpostindex) to learn about the partial_filter_selector parameter.\n\nExecution statistics\n: Execution statistics about a query can now be generated. These statistics are enabled by using the execution_stats=true parameter. For more information, see [querying an index by using selector syntax](https://cloud.ibm.com/apidocs/cloudantpostfind) to learn more about execution_stats=true parameter.\n\nPagination\n: [Pagination](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-pagination-and-bookmarks) is supported by using the bookmark field. Bookmarks are enabled for all index types.\n\nuse_index field invalid\n: _find now falls back to any valid index if the value specified in the use_index field is invalid for the current query. When find falls back, the warning field is populated in the query response.\n\n\n\n\n\n 9 October 2017 \n\nError handling\n: If you rely on 500 replies for your application, you might have issues. To fix the problem, update your application to rely on 400 responses.\n: If you don't take care of reduce overflow errors as part of a row in the response body, issues occur. To fix this problem, change the application to handle the errors from view requests.\n\n\n\n\n\n\n\n August 2017 \n\n\n\n 17 August 2017 \n\nThe following changes were made in build 6365:\n\nNew!", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-classic-release-notes"}, {"document_id": "ibmcld_07214-69430-71715", "score": 18.400399066525235, "text": "\nAny fields used in aggregations are also highlighted in the query results, but only the first aggregation operation is highlighted.\n\n\n\n\n\n 10 May 2017 \n\nNew support for 'highlight' parameter : The query and notices methods now support the highlight parameter. The parameter is a boolean. When you run a query and specified highlight as true, the service returns output that includes a new highlight field in which words that match the query are wrapped in HTML * (emphasis) tags. See the [Query parameters](https://cloud.ibm.com/docs/discovery?topic=discovery-query-parametershighlight) for details.\n\nKnown issue when deleting an environment : It is possible for the deletion of an environment to complete only partially, resulting in a situation in which a new environment cannot be created because only a single environment per service instance is permitted. If you attempt to delete and then create an environment but see either operation stuck in the pending state, it is likely that you encountered this problem. To work around it, re-run the deletion operation to complete it, then create the new environment.\n\n\n\n\n\n 8 May 2017 \n\nImproved precision for emotion analysis and training dataset : Updated the emotion tone score model to improve precision on emotion analysis (docEmotion) enrichments. The training dataset was expanded and feature engineering was altered and as a result, the model has higher precision on the benchmark dataset.\n\n\n\n\n\n 5 May 2017 \n\nNew beta support for entity normalization : Entity normalization is now available for use with the Discovery service that use a custom model generated by Watson Knowledge Studio. Entity normalization inserts normalized (canonical) names for different references to the same person or object in the source document. : Entity normalization is currently supported only as a beta capability. : [Resolved](https://cloud.ibm.com/docs/discovery?topic=discovery-release-notesdiscovery-30june2017)\n\nImproved tooling error log : The Tooling error log is no longer limited to a maximum of eight (8) pages of results. The error log still displays the document ID if the document name is not available.\n\nUpdate to configuration names : Configuration names are limited to 50 characters and must consist of the characters [a-zA-Z0-9-_].", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-release-notes"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10154-7-1896", "score": 33.89122986321482, "text": "\nBenefits and service offerings \n\n[Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae](https://www.ibm.com/products/openshift) is an IBM Cloud service, where IBM sets up and helps you manage a cluster of worker nodes that come installed with the OpenShift Container Platform container orchestration software.\n\nTo see a list of the cluster operators that are supported by default, you can run the oc get co command.\n\n\n\n Benefits of using the service \n\nWith Red Hat OpenShift on IBM Cloud, your developers have a fast and secure way to containerize and deploy enterprise workloads in Kubernetes clusters. Red Hat OpenShift clusters build on Kubernetes container orchestration that offers consistency and flexibility for your development lifecycle operations.\n\nYour Red Hat OpenShift workloads can scale across IBM\u2019s global footprint of data centers and multizone regions. At the same time, you\u2019re able to uniformly monitor, log, and secure apps. Because IBM manages the service, you can focus on innovating with high-value IBM Cloud services and middleware, such as AI and analytics. You also have access to Red Hat packaged open-source tools, including your favorite app runtimes, frameworks, databases, and more.\n\nReady to get started? Try out the [creating a Red Hat OpenShift on IBM Cloud cluster tutorial](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial).\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}, {"document_id": "ibmcld_07578-394005-396150", "score": 30.885751314156384, "text": "\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-393979-396124", "score": 30.885751314156384, "text": "\nYour worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov).\n* Why should I use Red Hat OpenShift on IBM Cloud?\n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits).\n* What container platforms are available for my cluster?\n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_10170-14072-16125", "score": 30.743558024999984, "text": "\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure tunnel to on-premises systems that host the benefits systems.\n* Combination of on-premises data and Red Hat OpenShift on IBM Cloud lets them access sensitive data while they adhere to regulations.\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization \n\nWatson Assistant provides tools to quickly scaffold a chatbot that can provide the correct benefits information to users.\n\n\n\n\n\n Step 4: Deliver continuously across the globe \n\n\n\n* IBM Cloud\u00ae Continuous Delivery helps Developers to quickly provision an integrated toolchain, by using customizable, shareable templates with tools from IBM, third parties, and open source. Automate builds and tests, controlling quality with analytics.\n* After Developers build and test the apps in their Development and Test clusters, they use the IBM CI/CD toolchains to deploy apps into Production clusters across the globe.\n* Red Hat OpenShift on IBM Cloud provides easy rollout and roll-back of apps. Tailored apps are deployed to meet regional requirements through the intelligent routing and load balancing of Istio.\n* Built-in HA tools in Red Hat OpenShift on IBM Cloud balance the workload within each geographic region, including self-healing and load balancing.\n\n\n\n\n\n\n\n\n\n Results \n\n\n\n* With tools like the chatbot, the HR team proved to their workforce that innovation was part of the corporate culture, not just buzz words.\n* Authenticity with personalization in the site addressed the changing expectations of the airline\u2019s workforce today.\n* Last-minute updates to the HR site, including ones that driven by the employees chatbot conversations, went live quickly because Developers were pushing changes at least 10 times daily.\n* With infrastructure management taken care of by IBM, the Development team was freed up to deliver the site in only 3 weeks.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_transport"}, {"document_id": "ibmcld_10170-12206-14575", "score": 30.073914292846872, "text": "\nDevelopers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.\n\nRed Hat OpenShift on IBM Cloud provides scalable compute resources and the associated DevOps dashboards to create, scale, and tear down apps and services as needed. Using industry-standard containers technology apps can be quickly developed and shared across multiple Development, Test, and Production environments. This setup provides the immediate benefit of scalability. Using Kubernetes rich set of deployment and runtime objects, the HR team can monitor and manage upgrades to apps reliably. They can also replicate and scale the apps, by using defined rules and the automated Kubernetes orchestrator.\n\n\n\n Step 1: Containers, microservices, and the Garage Method \n\n\n\n* Apps are built in a set of cooperative microservices that run in Red Hat OpenShift on IBM Cloud. The architecture represents the functional areas of the app with the most quality problems.\n* Deploy apps to container in Red Hat OpenShift on IBM Cloud, continuously scanned with IBM Vulnerability Advisor.\n* Provide standardized DevOps dashboards through Kubernetes.\n* Adopt the essential agile and iterative development practices within the IBM Garage Method to enable frequent releases of new functions, patches, and fixes without downtime.\n\n\n\n\n\n\n\n Step 2: Connections to existing benefits back-end \n\n\n\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae is used to create a secure tunnel to on-premises systems that host the benefits systems.\n* Combination of on-premises data and Red Hat OpenShift on IBM Cloud lets them access sensitive data while they adhere to regulations.\n* Chatbot conversations fed back into HR policies, allowing the benefits site to reflect which benefits were most and least popular, including targeted improvements to poorly performing initiatives.\n\n\n\n\n\n\n\n Step 3: Chatbot and personalization", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_transport"}, {"document_id": "ibmcld_10534-1033-2260", "score": 30.035111240713935, "text": "\n[Understanding Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewoverview)\n\n\n\n* [What is Red Hat OpenShift on IBM Cloud and how does it work?](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewwhat-is-overview)\n* [What is Kubernetes?](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewwhat-is-kube-overview)\n* [What are containers?](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewwhat-are-containers-overview)\n* [What is Red Hat OpenShift?](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewwhat-is-openshift-overview)\n* [What compute host infrastructure does the service offer?](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewwhat-compute-infra-is-offered)\n* [Related resources](https://cloud.ibm.com/docs/openshift?topic=openshift-overviewkubernetes-resources)\n\n\n\n[Benefits and service offerings](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovcs_ov)\n\n\n\n* [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits)\n* [Comparison between Red Hat OpenShift and community Kubernetes clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes)", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-sitemap"}, {"document_id": "ibmcld_10116-3182-5089", "score": 29.97257965457901, "text": "\n* 291 - 540 hours\n* 541+ hours\n\n\n\n\n\nPhysical machines, or bare metal, (not available for VPC clusters) yield high-performance benefits for workloads such as data, GPU, and AI. Additionally, all the hardware resources are dedicated to your workloads, so you don't have \"noisy neighbors\". Keep in mind these factors that impact your bare metal costs.\n\n\n\n* Monthly billing only: All bare metals are charged monthly.\n* Longer ordering process: After you order or cancel a bare metal server, the process is completed manually in your IBM Cloud infrastructure account. Therefore, it can take more than one business day to complete.\n\nVPC Generation 2 only: Prices vary by region where the underlying worker node infrastructure resides, and you can get sustained usage discounts. For more information, see [What are the regional uplift charges and sustained usage discounts for VPC worker nodes?](https://cloud.ibm.com/docs/openshift?topic=openshift-costscharges_vpc_gen2).\n\n\n\nFor more information about worker node specifications, see [Available hardware for worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesplanning_worker_nodes).\n\n\n\n\n\n Compute licenses \n\nIn Red Hat OpenShift on IBM Cloud, worker nodes require OpenShift Container Platform licenses to cover the use of Red Hat OpenShift Container Platform and Red Hat Enterprise Linux. OpenShift Container Platform licenses can be supplied by an [existing IBM Cloud Pak entitlement](https://cloud.ibm.com/docs/openshift?topic=openshift-costslicenses-cloud-pak) or [by Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-costslicenses-on-demand).\n\n\n\n OCP licenses from Red Hat OpenShift on IBM Cloud \n\nWhen you create worker nodes by adding a worker pool or cluster, Red Hat OpenShift on IBM Cloud helps you include the purchase of OpenShift Container Platform licenses for the worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-costs"}, {"document_id": "ibmcld_10214-7-1980", "score": 29.85287405612193, "text": "\nFAQs \n\nReview frequently asked questions (FAQs) for using Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae.\n\n\n\n How does Red Hat OpenShift on IBM Cloud work? \n\nWith Red Hat OpenShift on IBM Cloud, you can create your own Red Hat OpenShift cluster to deploy and manage containerized apps on IBM Cloud. Your containerized apps are hosted on IBM Cloud infrastructure compute hosts that are called worker nodes. You can choose to provision your compute hosts as [virtual machines](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesvm) with shared or dedicated resources, or as [bare metal machines](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesbm) that can be optimized for GPU and software-defined storage (SDS) usage. Your worker nodes are controlled by a highly available Red Hat OpenShift master that is configured, monitored, and managed by IBM. You can use the IBM Cloud Kubernetes Service API or CLI to work with your cluster infrastructure resources and the Kubernetes API or CLI to manage your deployments and services.\n\nFor more information about how your cluster resources are set up, see the [Service architecture](https://cloud.ibm.com/docs/containers?topic=containers-service-arch). To find a list of capabilities and benefits, see [Benefits and service offerings](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov).\n\n\n\n\n\n Why should I use Red Hat OpenShift on IBM Cloud? \n\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-faqs"}, {"document_id": "ibmcld_10170-10609-12793", "score": 28.955073143098193, "text": "\nThus, the annual rollout of benefits is a key aspect of fostering an employee-centered culture.\n\nThey need a solution that helps the Developers and their users.\n\n\n\n* FRONT-END TO EXISTING BENEFITS: insurance, educational offerings, wellness, and more\n* REGION-SPECIFIC FEATURES: each country has unique HR policies so that the overall site might look similar but show region-specific benefits\n* DEVELOPER-FRIENDLY TOOLS that accelerate rollout of features and bug fixes\n* CHATBOT to provide authentic conversations about benefits and resolve users requests and questions efficiently.\n\n\n\nTechnical solution:\n\n\n\n* Red Hat OpenShift on IBM Cloud\n* IBM Cloud\u00ae Continuous Delivery\n* IBM Logging and Monitoring\n* IBM\u00ae Secure Gateway for IBM Cloud\u00ae\n* IBM Cloud App ID\n\n\n\nAccelerated development is a key win for the HR Exec. The team gets started by containerizing their apps and putting them in the cloud. With the use of modern containers, Developers can experiment easily with Node.js SDK and push changes to Development and Test systems, which are scaled out on separate clusters. Those pushes were automated with open toolchains and IBM Cloud\u00ae Continuous Delivery. No longer were updates to the HR site languishing in slow, error-prone build processes. They can deliver incremental updates to their site, daily or even more frequently. Moreover, logging and monitoring for the HR site is rapidly integrated, especially for how the site pulls personalized data from back-end benefit systems. Developers don\u2019t waste time building complex logging systems, just to be able to troubleshoot live systems. Developers don't need to become experts in cloud security, they can enforce policy driven authentication easily by using IBM Cloud App ID.\n\nWith Red Hat OpenShift on IBM Cloud, they went from over-built hardware in a private data center to customizable compute that reduces IT operations, maintenance, and energy. To host the HR site, they could easily design Kubernetes clusters to fit their CPU, RAM, and storage needs. Another factor for less personnel costs is that IBM manages Kubernetes, so the Developers can focus on delivering better employee experience for benefits enrollment.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_transport"}, {"document_id": "ibmcld_10214-1438-3413", "score": 28.602042529915956, "text": "\nRed Hat OpenShift on IBM Cloud is a managed Red Hat OpenShift offering that delivers powerful tools, an intuitive user experience, and built-in security for rapid delivery of apps that you can bind to cloud services that are related to IBM Watson\u00ae, AI, IoT, DevOps, security, and data analytics. As a certified Kubernetes provider, Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management. The service also has advanced capabilities around simplified cluster management, container security and isolation policies, the ability to design your own cluster, and integrated operational tools for consistency in deployment.\n\nFor a detailed overview of capabilities and benefits, see [Benefits of using the service](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovbenefits).\n\n\n\n\n\n What container platforms are available for my cluster? \n\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform. If you want to use multiple container platforms, create a separate cluster for each.\n\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https://kubernetes.io/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-faqs"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03771-1594-3365", "score": 43.08178713347584, "text": "\nThe charges on your invoice are consistent with the usage dashboard. On the Invoices page in the console, click View usage to be directed to your usage dashboard. From there, you can select a timeframe and view billing and usage information that aligns directly with the details in your invoice.\n\n\n\n Checking your invoice status \n\nYou can check the status of your invoice on the [Invoices page](https://cloud.ibm.com/billing/invoices):\n\n\n\n* Invoiced: You received the latest invoice from IBM Cloud.\n* Paid: Your payment for the charges on your latest invoice was received.\n* Unpaid: The charges on your latest invoice have not been paid.\n* Pending: Your payment for your latest charges has not been applied due to a payment processing error. In this case, you can contact IBM Cloud Support for more details about the error.\n\n\n\nTurning a resource \"off\" doesn't cancel the resource in your account. You will receive invoices for resources in your account until you cancel them. For more information, see [Cancelling your billing items](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cancel-billing-items).\n\n\n\n\n\n Viewing and downloading your invoice \n\nView and download your invoice from the IBM console by clicking the Download icon ![Download icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/download.svg)> PDF invoice next to each invoice. For some accounts, invoices are available through the [Invoices@IBM](http://ibm.com/invoices) website. See the [Viewing and downloading invoices for all other accounts](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoices"}, {"document_id": "ibmcld_03776-6753-8705", "score": 39.118619870052356, "text": "\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https://myibm.ibm.com/billing/).\n\nFor more information about how to manage your payments, see [Managing your payment method](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusageprereqs-payments).\n\n\n\n\n\n Tracking your usage \n\nTo view usage data for resources, you must be assigned the correct access. Access can be assigned at the account level or to individual resource groups and Cloud Foundry orgs.\n\n\n\n* To view usage for all resources in the account, you need an access policy with the Administrator role on the Billing account management service.\n* To view usage only for specific IBM Cloud Identity and Access Management (IAM) resources, you need the Viewer role or higher on the resource group.\n* To view usage for only specific Cloud Foundry services, the Billing manager role must be applied at the org level. Billing managers can see the details for only the organizations in which they are assigned the Billing manager role.\n\n\n\nYou can limit the access to view the usage for a specific resource group by assigning the viewer role or higher on all Identity and Access enabled services within that resource group.\n\n\n\n\n\n Managing your invoices \n\nIf you have a Pay-As-You-Go account that's billed in US dollars, you can view your invoice in the IBM Cloud console by going to Manage > Billing and usage, > and clicking Invoices.\n\nIf you own one of the following accounts, you can view your invoice on the [IBM Invoices](http://ibm.com/invoices) website, which is linked from the [Invoices page](https://cloud.ibm.com/billing/invoices) in the console.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-overview"}, {"document_id": "ibmcld_03704-4411-6289", "score": 36.67840798152092, "text": "\nYou might manage your payment method on a separate billing platform, [IBM Billing](https://myibm.ibm.com/billing/). For more information about that process, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n Can I check the status of my account's updated payment method? \n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https://cloud.ibm.com/unifiedsupport/cases) page in the IBM Cloud console to view the status of your request.\n\n\n\n\n\n Can I delete my credit card? \n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https://cloud.ibm.com/billing/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https://myibm.ibm.com/billing/). For more information, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) for more information.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_07578-1045891-1047755", "score": 36.67840798152092, "text": "\nYou might manage your payment method on a separate billing platform, [IBM Billing](https://myibm.ibm.com/billing/). For more information about that process, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https://cloud.ibm.com/unifiedsupport/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https://cloud.ibm.com/billing/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https://myibm.ibm.com/billing/). For more information, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) for more information.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1045762-1047626", "score": 36.67840798152092, "text": "\nYou might manage your payment method on a separate billing platform, [IBM Billing](https://myibm.ibm.com/billing/). For more information about that process, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n* Can I check the status of my account's updated payment method?\n\nYes, you can. When you request to change your payment method, a support case is created automatically. Go to the [Manage cases](https://cloud.ibm.com/unifiedsupport/cases) page in the IBM Cloud console to view the status of your request.\n* Can I delete my credit card?\n\nFor Pay-As-you-Go accounts, you must have an active credit card on file. You can replace an existing credit card with a new one.\n\n\n\n* If you're using a new US-based Pay-As-You-Go account with credit card billing, you can add a new credit card in the Monthly Payment Method form on the [Payments](https://cloud.ibm.com/billing/payments) page.\n* For all other accounts, you can remove a credit card and switch to a different payment method by clicking Pay with Other > Submit change request. To complete the change, review and update the support case that is created for you.\n* If you manage your payment method on a separate billing platform, you can remove your credit card by going to [IBM Billing](https://myibm.ibm.com/billing/). For more information, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) for more information.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03794-0-812", "score": 36.33734243398908, "text": "\n\n\n\n\n\n\n  Why am I getting a charge limit error when I try to make a payment? \n\nYou can't make a full payment on your invoice because of a charge limit.\n\n  What\u2019s happening \n\nYou try to make a payment on an invoice that is over $1,000.00 USD, but you get the following error message:\n\n> Manual payment request cannot be processed. Payment amount is higher than the limit allowed.\n\n  Why it\u2019s happening \n\nBy default, credit card payments in US Dollars cannot exceed $1,000.00 USD, which might cause you to make multiple payments to pay your invoice.\n\n  How to fix it \n\nYou can contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter) to request an increase in this maximum credit card payment limit. All requests are considered based on the payment and invoice history of the account.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-ts-charge-limit"}, {"document_id": "ibmcld_01623-6277-8255", "score": 33.901945655157455, "text": "\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https://cloud.ibm.com/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https://myibm.ibm.com/billing/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-account-getting-started"}, {"document_id": "ibmcld_03771-2998-4769", "score": 32.787372673467374, "text": "\nFor some accounts, invoices are available through the [Invoices@IBM](http://ibm.com/invoices) website. See the [Viewing and downloading invoices for all other accounts](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoicesviewing-external-invoices) section for more information.\n\n\n\n\n\n\n\n Viewing and downloading invoices for all other accounts \n\nIf you own one of the following accounts, you can view your invoice on the [Invoices@IBM](http://ibm.com/invoices) website, which is linked from the [Invoices page](https://cloud.ibm.com/billing/invoices) in the IBM console.\n\n\n\n* New and existing Pay-As-You-Go accounts that are based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nTo save a copy of your invoice, click the PDF icon in the Invoice Number column. Then, click the Download icon ![Download icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/download.svg).\n\n\n\n Getting access to Invoices@IBM \n\nIf you are attempting to access the [Invoices@IBM](http://ibm.com/invoices) website for the first time, you can sign up with your IBMid, complete your profile, and provide your IBM customer number to access your account. Your IBM customer number is used for identification purposes during your registration process with the IBM Invoices page and during other interactions with [IBM Support](https://www.ibm.com/support/home/).\n\nTo ensure that access is granted to the correct individuals, you must register using an email address that includes your company's domain, such as ibm.com. Requests using personal, non-company-specific email addresses might not be approved.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoices"}, {"document_id": "ibmcld_03776-5228-7163", "score": 30.788941069082615, "text": "\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.\n* Reserved: Reserved pricing is based on a long-term commitment for a service, so you can get a discounted price. With a reserved plan, you get a dedicated service instance that is easy to set up, deploy, and deliver in the public IBM Cloud environment.\n\n\n\n\n\n\n\n Managing your payments \n\nIf you're a new Pay-As-You-Go account owner that is located in the US and you are paying with a credit card, you can replace your current card with a new one or edit the details of an existing card. In either case, you manage your credit card from the [Payments](https://cloud.ibm.com/billing/payments) page in the IBM Cloud console.\n\nIf you own one of the following accounts, in the IBM Cloud\u00ae console, you can go to Manage > Billing and usage to make a one-time payment, change your credit card details, view your billing items, and manage your invoices.\n\n\n\n* New and existing Pay-As-You-Go accounts based in the US with any payment method other than a credit card\n* New and existing Pay-As-You-Go accounts not based in the US\n* New and existing Subscription accounts worldwide\n\n\n\nThe process for updating a credit card requires a manual review that might take a few days to process. To view your open change request cases, go to [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n\nYou might manage your payment method on a separate billing platform. You can easily register, update, or delete a payment method by going to [IBM Billing](https://myibm.ibm.com/billing/).", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-overview"}, {"document_id": "ibmcld_12544-10042-12276", "score": 30.75656015377311, "text": "\nYou can view usage from the Usage page in the console, from the CLI, or from the Enterprise Usage Reports API. For more information, see [Viewing usage in an enterprise](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Invoicing and payments \n\nUsage in the enterprise is invoiced through the enterprise account. As with all billable accounts, usage is invoiced monthly, and the invoice is due on the billing date for your account. During each billing cycle, a single invoice with the usage costs from all accounts is made available in the enterprise account. The invoice contains costs for all platform and infrastructure usage as a single-line item in your invoice. If all of the credit in the credit pool is used, the invoice contains a line item for any overage charges.\n\nBecause all usage is invoiced through the enterprise account, child accounts within the enterprise don't receive separate invoices.\n\nYou can analyze usage costs for each account or account group on the Usage page in the enterprise account. For details, see [Viewing usage in an enterprise](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-enterprise-usage).\n\n\n\n\n\n Access management for enterprise billing and usage \n\nAs with other enterprise management roles, access to enterprise billing and usage is managed through the enterprise account. Users must be invited to the enterprise account and assigned an access policy with a role on the relevant service.\n\nIn an enterprise, billing access and usage access are assigned separately.\n\n\n\n* Billing access is provided by assigning enterprise users a role on the Billing account management service. For example, you can assign the Viewer role to an enterprise user so that they can view the amount of available subscription credit in the credit pool. If you would like an enterprise user to be able to add new subscriptions or manage payment methods, you can assign the Editor or Administrator role to them.\n* Usage access is provided by assigning enterprise users the Usage Reports Viewer, Editor, or Administrator role on the Enterprise account management service. You can assign this access for the entire enterprise or for specific account groups and accounts.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-enterprise"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07549-19143-21543", "score": 13.713261187456204, "text": "\nThe information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.If you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information. But this requirement does not apply if neither you nor any third party retains the ability to install modified object code on the User Product (for example, the work has been installed in ROM).The requirement to provide Installation Information does not include a requirement to continue to provide support service, warranty, or updates for a work that has been modified or installed by the recipient, or for the User Product in which it has been modified or installed. Access to a network may be denied when the modification itself materially and adversely affects the operation of the network or violates the rules and protocols for communication across the network.Corresponding Source conveyed, and Installation Information provided, in accord with this section must be in a format that is publicly documented (and with an implementation available to the public in source code form), and must require no special password or key for unpacking, reading or copying.<-- </section \"id=\"section-en-notice-non-source\" \"> --><-- <section \"id=\"section-en-notice-add-term\" \"> --> 7. Additional Terms \"Additional permissions\" are terms that supplement the terms of this License by making exceptions from one or more of its conditions. Additional permissions that are applicable to the entire Program shall be treated as though they were included in this License, to the extent that they are valid under applicable law. If additional permissions apply only to part of the Program, that part may be used separately under those permissions, but the entire Program remains governed by this License without regard to the additional permissions.When you convey a copy of a covered work, you may at your option remove any additional permissions from that copy, or from any part of it.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-notices"}, {"document_id": "ibmcld_07863-0-2804", "score": 12.298894832182956, "text": "\n\n\n\n\n\n\n  SA-5 - Information System Documentation \n\n\n\n  Control requirements \n\nThe organization:\n\nSA-5 (a)\n:   Obtains administrator documentation for the information system, system component, or information system service that describes:\n\n\n\n1.  Secure configuration, installation, and operation of the system, component, or service;\n2.  Effective use and maintenance of security functions/mechanisms; and\n3.  Known vulnerabilities regarding configuration and use of administrative (i.e., privileged) functions;\n\n\n\nSA-5 (b)\n:   Obtains user documentation for the information system, system component, or information system service that describes:\n\n\n\n1.  User-accessible security functions/mechanisms and how to effectively use those security functions/mechanisms;\n2.  Methods for user interaction, which enables individuals to use the system, component, or service in a more secure manner; and\n3.  User responsibilities in maintaining the security of the system, component, or service;\n\n\n\nSA-5 (c)\n:   Documents attempts to obtain information system, system component, or information system service documentation when such documentation is either unavailable or nonexistent and takes [Assignment: organization-defined actions] in response;\n\nSA-5 (d)\n:   Protects documentation as required, in accordance with the risk management strategy; and\n\nSA-5 (e)\n:   Distributes documentation to [Assignment: organization-defined personnel or roles].\n\n\n\n\n\n  NIST supplemental guidance \n\nThis control helps organizational personnel understand the implementation and operation of security controls associated with information systems, system components, and information system services. Organizations consider establishing specific measures to determine the quality/completeness of the content provided. The inability to obtain needed documentation may occur, for example, due to the age of the information system/component or lack of support from developers and contractors. In those situations, organizations may need to recreate selected documentation if such documentation is essential to the effective implementation or operation of security controls. The level of protection provided for selected information system, component, or service documentation is commensurate with the security category or classification of the system. For example, documentation associated with a key DoD weapons system or command and control system would typically require a higher level of protection than a routine administrative system. Documentation that addresses information system vulnerabilities may also require an increased level of protection. Secure operation of the information system, includes, for example, initially starting the system and resuming secure system operation after any lapse in system operation.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-sa-5"}, {"document_id": "ibmcld_07549-17189-19772", "score": 11.242198129469173, "text": "\nIf the place to copy the object code is a network server, the Corresponding Source may be on a different server (operated by you or a third party) that supports equivalent copying facilities, provided you maintain clear directions next to the object code saying where to find the Corresponding Source. Regardless of what server hosts the Corresponding Source, you remain obligated to ensure that it is available for as long as needed to satisfy these requirements.e) Convey the object code using peer-to-peer transmission, provided you inform other peers where the object code and Corresponding Source of the work are being offered to the general public at no charge under subsection 6d. A separable portion of the object code, whose source code is excluded from the Corresponding Source as a System Library, need not be included in conveying the object code work.A \"User Product\" is either (1) a \"consumer product\", which means any tangible personal property which is normally used for personal, family, or household purposes, or (2) anything designed or sold for incorporation into a dwelling. In determining whether a product is a consumer product, doubtful cases shall be resolved in favor of coverage. For a particular product received by a particular user, \"normally used\" refers to a typical or common use of that class of product, regardless of the status of the particular user or of the way in which the particular user actually uses, or expects or is expected to use, the product. A product is a consumer product regardless of whether the product has substantial commercial, industrial or non-consumer uses, unless such uses represent the only significant mode of use of the product.\"Installation Information\" for a User Product means any methods, procedures, authorization keys, or other information required to install and execute modified versions of a covered work in that User Product from a modified version of its Corresponding Source. The information must suffice to ensure that the continued functioning of the modified object code is in no case prevented or interfered with solely because modification has been made.If you convey an object code work under this section in, or with, or specifically for use in, a User Product, and the conveying occurs as part of a transaction in which the right of possession and use of the User Product is transferred to the recipient in perpetuity or for a fixed term (regardless of how the transaction is characterized), the Corresponding Source conveyed under this section must be accompanied by the Installation Information.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-notices"}, {"document_id": "ibmcld_07902-1732-3843", "score": 11.032297233149595, "text": "\nInformation system entry and exit points include, for example, firewalls, electronic mail servers, web servers, proxy servers, remote-access servers, workstations, notebook computers, and mobile devices. Malicious code includes, for example, viruses, worms, Trojan horses, and spyware. Malicious code can also be encoded in various formats (e.g., UUENCODE, Unicode), contained within compressed or hidden files, or hidden in files using steganography. Malicious code can be transported by different means including, for example, web accesses, electronic mail, electronic mail attachments, and portable storage devices. Malicious code insertions occur through the exploitation of information system vulnerabilities. Malicious code protection mechanisms include, for example, anti-virus signature definitions and reputation-based technologies. A variety of technologies and methods exist to limit or eliminate the effects of malicious code. Pervasive configuration management and comprehensive software integrity controls may be effective in preventing execution of unauthorized code. In addition to commercial off-the-shelf software, malicious code may also be present in custom-built software. This could include, for example, logic bombs, back doors, and other types of cyber attacks that could affect organizational missions/business functions. Traditional malicious code protection mechanisms cannot always detect such code. In these situations, organizations rely instead on other safeguards including, for example, secure coding practices, configuration management and control, trusted procurement processes, and monitoring practices to help ensure that software does not perform functions other than the functions intended. Organizations may determine that in response to the detection of malicious code, different actions may be warranted. For example, organizations can define actions in response to malicious code detection during periodic scans, actions in response to detection of malicious downloads, and/or actions in response to detection of maliciousness when attempting to open or execute files.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-si-3"}, {"document_id": "ibmcld_00500-13090-15172", "score": 10.556103930008085, "text": "\nDue to sharding, IBM Cloudant offers no guarantees that the output of any two specific map functions passes to the same instance of a reduce call. You must not rely on any ordering. The reduce function that you use must consider all the values that are passed to it and return the correct answer irrespective of ordering. IBM Cloudant is also guaranteed to call your reduce function with rereduce=true at query time even if it didn't need to do so when it built the index. It's essential that your functions work correctly in that case (rereduce=true means that the keys parameter is null and the values array is filled with results from previous reduce function calls).\n\n\n\n\n\n Reduced value size \n\nIBM Cloudant computes view indexes and the corresponding reduce values then caches these values inside each of the B-tree node pointers. Now, IBM Cloudant can reuse reduced values when it updates the B-tree. You must pay attention to the amount of data that is returned from reduce functions.\n\nIt's best that the size of your returned data set stays small and grows no faster than log(num_rows_processed). If you ignore this restriction, IBM Cloudant does not automatically throw an error, but B-tree performance degrades dramatically. If your view works correctly with small data sets but quits working when more data is added, your view might violate the growth rate characteristic restriction.\n\n\n\n\n\n Execution environment \n\nYour indexing functions work in a memory-constrained environment where the document forms part of the memory used in the environment. Your code's stack and document must fit within the memory. We limit documents to a maximum size of 64 MB.\n\n\n\n\n\n No JavaScript reducers when options.partitioned is true \n\nDesign documents with options.partitioned set to true can't contain JavaScript reduce functions, only built-ins Erlang reducers such as _stats.\n\n\n\n\n\n\n\n Storing the view definition \n\nEach view is a JavaScript function. Views are stored in design documents. So, to store a view, IBM Cloudant simply stores the function definition within a design document.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-views-mapreduce"}, {"document_id": "ibmcld_07717-7794-9268", "score": 10.530537750593341, "text": "\nNIST supplemental guidance \n\nInformation systems can provide a wide variety of functions and services. Some of the functions and services, provided by default, may not be necessary to support essential organizational operations (e.g., key missions, functions). Additionally, it is sometimes convenient to provide multiple services from single information system components, but doing so increases risk over limiting the services provided by any one component. Where feasible, organizations limit component functionality to a single function per device (e.g., email servers or web servers, but not both). Organizations review functions and services provided by information systems or individual components of information systems, to determine which functions and services are candidates for elimination (e.g., Voice Over Internet Protocol, Instant Messaging, auto-execute, and file sharing). Organizations consider disabling unused or unnecessary physical and logical ports/protocols (e.g., Universal Serial Bus, File Transfer Protocol, and Hyper Text Transfer Protocol) on information systems to prevent unauthorized connection of devices, unauthorized transfer of information, or unauthorized tunneling. Organizations can utilize network scanning tools, intrusion detection and prevention systems, and end-point protections such as firewalls and host-based intrusion detection systems to identify and prevent the use of prohibited functions, ports, protocols, and services.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-cm-7"}, {"document_id": "ibmcld_10858-1526-3046", "score": 10.504749167582444, "text": "\n...some synchronous code...\n} catch(e) {\n...log error...\nreject(e); // <-- this also terminates the execution, but reports the failure back to the runtime\n}\n});\n}\n\nasync function main() {\n...some synchronous code...\nawait doGet(....) // <-- function continues synchronous execution, once this async call returned\n...some synchronous code...\n}\nShow more\n\nNote that a function declared as async automatically returns a promise, so you don't have to explicitly return one.\n\nThe following example does not necessarily work as expected, but might work intermittently, depending on the runtime of asynchronous code. Do not use this type of pattern.\n\nfunction main() {\n...some synchronous code...\ndoGet(callback => {\n...log result... // <-- this line is never reached, if the doGet is not complete before the action container gets stopped\n});\n...some synchronous code... // <-- this code is usually executed BEFORE the doGet callback got processed. Make sure that this is what you expect to happen!\n}\n\nInstead, either use promises as part of the function or use async/await.\n\nThe following example performs the same type of function as in the previous example, but instead uses async/await. This type of function code runs reliably.\n\nasync function main() {\n...some synchronous code...\nawait doGet(callback => {\n...log result... // <-- this line gets now executed BEFORE the below synchronous code block is reached\n});\n...some synchronous code... // <-- the whole function now behaves as if it was only using synchronous code\n}", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-ts_action_nodejs_fails"}, {"document_id": "ibmcld_10817-6582-8092", "score": 10.379708796624078, "text": "\n} else {\nvar result = reply[\"result\"]\nprint(\"Got result (result)\")\n}\n})\n} catch {\nprint(\"Error (error)\")\n}\n\nBy default, the SDK returns only the activation ID and any result that is produced by the invoked action. To get metadata of the entire response object, which includes the HTTP response status code, use the following setting:\n\nwhisk.verboseReplies = true\n\n\n\n\n\n Configuring the mobile SDK \n\nYou can configure the SDK to work with different installations of Cloud Functions by using the baseURL parameter. For instance:\n\nwhisk.baseURL = \"http://localhost:8080\"\n\nIn this example, you use an installation that is running at http://localhost:8080. If you do not specify the baseURL, the mobile SDK uses the instance that is running at [https://us-south.functions.cloud.ibm.com](https://us-south.functions.cloud.ibm.com).\n\nYou can pass in a custom NSURLSession in case you require special network handling. For example, you might have your own Cloud Functions installation that uses self-signed certificates:\n\n// create a network delegate that trusts everything\nclass NetworkUtilsDelegate: NSObject, NSURLSessionDelegate {\nfunc URLSession(session: NSURLSession, didReceiveChallenge challenge: NSURLAuthenticationChallenge, completionHandler: (NSURLSessionAuthChallengeDisposition, NSURLCredential?) -> Void) {\ncompletionHandler(NSURLSessionAuthChallengeDisposition.UseCredential, NSURLCredential(forTrust: challenge.protectionSpace.serverTrust!))\n}\n}\n// create an NSURLSession that uses the trusting delegate", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10762-1269-2843", "score": 10.34636155948779, "text": "\ndefault a8a12accd63b437bbd6d58fb8b462ca7 true ACTIVE\ntest a8a12abbbd63b437cca6d58fb8b462ca7 false ACTIVE\n6. Target a resource group by running the following command.\n\nibmcloud target -g <resource_group>\n\nExample output\n\nTargeted resource group default\n\n\n\n\n\n\n\n Setting up the Cloud Functions CLI plug-in \n\nTo work with Cloud Functions, download and install the CLI plug-in.\n\nYou can use the Cloud Functions CLI plug-in to perform the following tasks.\n\n\n\n* Run your code snippets, or actions, on Cloud Functions. See [Creating and invoking actions](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-actions).\n* Create triggers and rules to enable your actions to respond to events. See [Creating triggers and rules](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-triggers).\n* Bundle actions and configure external events sources. See [Create and use packages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_ov).\n* Explore the catalog of packages and enhance your applications with external services. See [Adding IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-services).\n\n\n\nComplete the following steps to install the Cloud Functions CLI plug-in\n\n\n\n1. Install the Cloud Functions plug-in.\n\nibmcloud plugin install cloud-functions\n2. Verify that the plug-in is installed.\n\nibmcloud plugin list\n\nExample Output\n\nPlugin Name Version\ncloud-functions/wsk/functions/fn 1.0.32\n3. All Cloud Functions commands begin with ibmcloud fn. To see everything that you can do with the Cloud Functions plug-in, run ibmcloud fn with no arguments.\n\nibmcloud fn", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-cli_install"}, {"document_id": "ibmcld_03160-4262-5873", "score": 10.293622339188692, "text": "\nIf this test did not work as expected, double check your phone number configuration to make sure its attached to your flow.\n\n\n\n\n\n\n\n Creating a Twilio function to handle incoming calls \n\nNow we need to configure the call flow to direct inbound calls to the assistant using a Twilio function. Follow these steps:\n\n\n\n1. In the navigation menu, click the All Products & Services icon.\n2. Click Services.\n3. Click Create Service. Specify a service name and then click Next.\n4. Click Add > Add Function to add a new function to your service. Name the new function /receive-call.\n5. Replace the template in your /receive-call function with the following code:\n\nexports.handler = function(context, event, callback) {\nconst VoiceResponse = require('twilio').twiml.VoiceResponse;\nconst response = new VoiceResponse();\nconst dial = response.dial({\nanswerOnBridge: \"true\",\nreferUrl: \"/refer-handler\"\n});\nconst calledPhoneNumber = event.Called;\ndial.sip(sip:${calledPhoneNumber}@{sip_uri_hostname};secure=true);\nreturn callback(null, response);\n}\n\n\n\n* Replace {sip_uri_hostname} with the hostname portion of your assistant's phone integration SIP URI (everything that comes after sips:).. Note that Twilio does not support SIPS URIs, but does support secure SIP trunking by appending ;secure=true to the SIP URI.\n\n\n\n6. Click Save.\n7. Click Deploy All.\n\n\n\n\n\n\n\n Redirecting to the incoming call handler \n\nIn this section you will use a TwiML Redirect** widget in your Studio Flow editor to call out to the /call-recieve function created in the previous section.\n\n\n\n1. Add a TwiML Redirect widget to your Studio Flow canvas.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone-flex"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10817-7-1802", "score": 54.62493392726993, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10852-43319-44485", "score": 49.975394735860014, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_04518-7-1743", "score": 44.75333946664987, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_02772-4213-5899", "score": 44.20998500336549, "text": "\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}, {"document_id": "ibmcld_10817-1342-3184", "score": 41.52882402843565, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-1426-3052", "score": 32.6694530681322, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10852-44214-45420", "score": 32.48804611831317, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_12332-1034-2510", "score": 28.760026659370958, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}, {"document_id": "ibmcld_10817-2884-4620", "score": 28.160095710940347, "text": "\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in /Library/Developer/Xcode/DerivedData/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_02772-1628-3402", "score": 26.546499031544805, "text": "\nFollowing registration, your users authenticate by using either the OAuth2 authorization code or resource owner password[authorization grant](https://datatracker.ietf.org/doc/html/rfc6749section-1.3) flows to authenticate users.\n\n\n\n\n\n Dynamic client registration \n\n\n\n1. A user triggers a request by the client application to the App ID SDK.\n2. If your app is not registered as a mobile client yet, the SDK initiates a dynamic registration flow.\n3. On a successful registration, App ID returns your installation-specific client ID.\n\n\n\n\n\n\n\n Authorization flow \n\nZoom\n\n![App ID mobile request flow](https://cloud.ibm.com/docs-content/v1/content/27ecaa7a29890634603881a8e64789974a29916b/appid/images/mobile-flow.svg)\n\nFigure 1. App ID mobile request flow\n\n\n\n1. The App ID SDK starts the authorization process by using the App ID /authorization endpoint.\n2. The login widget is displayed to the user.\n3. The user authenticates by using one of the configured identity providers.\n4. App ID returns an authorization grant.\n5. The authorization grant is exchanged for access, identity, and refresh tokens from the App ID /token endpoint.\n\n\n\n\n\n\n\n\n\n Configuring your mobile app with the App ID SDKs \n\nGet started with the App ID SDKs.\n\n\n\n Before you begin \n\nYou need the following information:\n\n\n\n* An App ID instance\n* Your instance's tenant ID. This can be found in the Service Credentials tab of your service dashboard.\n* Your instance's deployment IBM Cloud region. You can find your region by looking at the console.\n\n\n\nTable 1. IBM Cloud regions and corresponding SDK values\n\n IBM Cloud Region SDK value \n\n US South AppID.REGION_US_SOUTH \n Sydney AppID.REGION_SYDNEY \n United Kingdom AppID.REGION_UK \n Germany AppID.REGION_GERMANY \n\n\n\n\n\n\n\n\n\n\n\n Authenticating with the Android SDK", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04105-3403-5572", "score": 34.343980804124286, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-1672-3877", "score": 29.346151168430463, "text": "\nThe tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots. Like any tool that can be used for good, bots can be used for malicious behavior, too.\n\n\n\n\n\n Differences between good bots and bad bots \n\nIt is estimated that up to half of all internet traffic is bot traffic. Some bots are malicious, and some are \"good.\"\n\nBots that misuse online products or services can be considered \"bad.\" Bad bots range from malicious to simply annoying; for instance, breaking into user accounts to steal data or buying concert tickets online to assist scalpers.\n\nA bot that performs a helpful service can be considered \"good.\" For example, customer service chatbots, search engine crawlers, and performance monitoring bots are generally good bots. Good bots look for and abide by the rules outlined in a website's robots.txt file.\n\n\n\n\n\n The robots.txt file \n\nRobots.txt is a file that outlines the rules for bots accessing properties on a web server, though the file itself does not enforce these rules. Anyone programming a bot is expected to follow an honor system and make sure that their bot checks a website's robots.txt file before accessing the website. Malicious bots don't follow this system, which generates the need for bot management.\n\n\n\n\n\n How bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-7-2225", "score": 26.564201466718966, "text": "\nAbout bot management \n\nBot management blocks undesired or malicious internet bot traffic while allowing useful bots to access web properties. Bot management detects bot activity, discerns between desirable and undesirable bot behavior, and identifies the sources of the undesirable activity.\n\nUnmanaged bots can cause serious issues for web properties. Excessive bot traffic can put a heavy load on web servers, slowing or denying service to legitimate users (for example, DDoS attacks). Malicious bots can perform cyber attacks such as scraping content from websites, stealing user credentials, and spreading spam content.\n\n\n\n What bot managers do \n\nA bot manager is any software product that manages bots. Bot managers should be able to block some bots and allow others through, instead of simply blocking all non-human traffic. If all bots are blocked and Google bots aren't able to index a page, for instance, then that page can't show up in Google search results, resulting in greatly reduced organic traffic to the website.\n\nAn effective bot manager accomplishes the following goals:\n\n\n\n* Distinguishes bots from human visitors\n* Identifies bot reputation\n* Identifies bot origin IP addresses and block based on IP reputation\n* Analyzes bot behavior\n* Adds \"good\" bots to allowlists\n* Challenges potential bots with a CAPTCHA test, JavaScript injection, or other methods\n* Rate limits any potential bot that is over-using a service\n* Denies access to certain content or resources for \"bad\" bots\n* Serves alternative content to bots\n\n\n\n\n\n\n\n What are bots and what do they do? \n\nA bot is a computer program that automatically does certain actions on a network. The tasks a bot is programmed to do are fairly simple, but the bot can do these tasks repeatedly at a much faster rate than a human can.\n\nBots don't access the internet using a traditional web browser or a mouse to interact with visual content. Bots are software programs that typically use a \"headless browser\" to make HTTP requests and other activities.\n\nBots can do almost any repetitive, non-creative task that can be automated, including filling out forms, reading and downloading content, and even hold basic conversations with humans as chatbots.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04105-5067-6335", "score": 25.53121915120552, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04170-7-2189", "score": 25.18483465050702, "text": "\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https://research.google/pubs/pub45581/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with /cdn-cgi/challenge-platform/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_04168-6066-7283", "score": 22.221740082294858, "text": "\n* [Querying Edge Functions metrics with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https://cloud.ibm.com/docs/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https://cloud.ibm.com/docs/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https://cloud.ibm.com/docs/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https://cloud.ibm.com/docs/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https://cloud.ibm.com/docs/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https://cloud.ibm.com/docs/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https://cloud.ibm.com/docs/cis?topic=cis-at_events)", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-http-concepts"}, {"document_id": "ibmcld_04146-2946-5057", "score": 22.13859669881625, "text": "\nAvailable Cloudflare fields\n\n Field name Type Example value Notes \n\n cf.client.bot Boolean true This field indicates whether the request is coming from a known bot or crawler, regardless of good or bad intent. \n cf.threat_score Number A 0-100 value This field represents a risk score, 0 indicates low risk as determined by Cloudflare. Values above 10 can represent spammers or bots, and values above 40 point to bad actors on the internet. It is rare to see values above 60, so tune your firewall rules to challenge those above 10, and to block those above 50. \n\n\n\n\n\n\n\n\n\n Functions \n\nThe firewall rules language has a number of functions to convert fields.\n\nThese are not currently supported in the CIS UI Visual Expression Builder.\n\n\n\nTable 3. Firewall rules functions\n\n Function name Argument types Return type Usage example Notes \n\n lower String String lower(http.host) == \"www.example.com\" Converts a string field to lowercase. Only uppercase ASCII bytes are being converted, every other bytes are left as-is. \n upper String String upper(http.host) == \"www.example.com\" Converts a string field to uppercase. Only lowercase ASCII bytes are being converted, every other bytes are left as-is. \n\n\n\n\n\n\n\n Expressions \n\nAn expression returns true or false based on a match against incoming traffic. For example:\n\nhttp.host eq \"www.example.com\" and ip.src in 92.182.212.0/24\n\nIn this example, two single expressions comprise a compound expression. Think of each single expression as a condition. Each condition is evaluated individually before applying and logic to determine the final result of the compound expression.\n\nLooking at the first single expression, you can see that it contains:\n\n\n\n* a field - http.host\n* a comparison operator - eq\n* a value - \"www.example.com\"\n\n\n\nNot all conditions have the same structure. Additional examples using different structures are discussed in the next section.\n\n\n\n Comparison operators \n\nThe following comparison operators are available for use in expressions:\n\n\n\nTable 4. Comparison operators for expressions\n\n English C-like Description \n\n eq == Equal \n ne != Not equal", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-fields-and-expressions"}, {"document_id": "ibmcld_04111-35313-36062", "score": 21.549123733273813, "text": "\nGet Bot Management settings. GET /v1/{crn}/zones/{domain_id}/bot_management} internet-svcs.reliability.read internet-svcs.bot-management.read \n Update Bot Management settings. PUT /v1/{crn}/zones/{domain_id}/bot_management} internet-svcs.reliability.update internet-svcs.bot-management.update \n Get Bot Analytics Score Source. GET /v1/{crn}/zones/{domain_id}/bot_analytics/score_source} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Timeseries. GET /v1/{crn}/zones/{domain_id}/bot_analytics/timeseries} internet-svcs.security.read internet-svcs.bot-analytics.read \n Get Bot Analytics Top Attributes. GET /v1/{crn}/zones/{domain_id}/bot_analytics/top_ns} internet-svcs.security.read internet-svcs.bot-analytics.read", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-at_iam_CIS"}, {"document_id": "ibmcld_04172-7-2047", "score": 21.50036385301345, "text": "\nAccessing log fields \n\nIf fields are not specified in the request, a limited set of default fields are returned. Find the full list of all available fields using the following request.\n\nibmcloud cis logpull DNS_DOMAIN_ID --available-fields\n\nFields are passed as a comma-separated list. For example, to have \"ZoneID\" and \"RayID\", use:\n\nibmcloud cis logpull DNS_DOMAIN_ID --start 2019-01-02T01:00:00+00:00 --end 2019-01-02T01:00:00+00:00 --fields ZoneId,RayID\n\n\n\n Available Fields \n\nThe following tables describe the fields available by log category.\n\n\n\n HTTP requests \n\nThis table contains the fields available for HTTP requests.\n\n\n\nTable 1. HTTP events\n\n Field Value Type \n\n BotScore Cloudflare Bot Score (available for Bot Management customers; please contact your account team to enable) int \n BotScoreSrc Underlying detection engine or source on where a Bot Score is calculated. Possible values are Not ComputedHeuristicsMachine LearningBehavioral AnalysisVerified Bot string \n CacheCacheStatus unknownmissexpiredupdatingstalehitignoredbypassrevalidated string \n CacheResponseBytes Number of bytes returned by the cache int \n CacheResponseStatus HTTP status code returned by the cache to the edge; all requests (including non-cacheable ones) go through the cache; also see CacheStatus field int \n CacheTieredFill Tiered Cache was used to serve this request bool \n ClientASN Client AS number int \n ClientCountry Country of the client IP address string \n ClientDeviceType Client device type string \n ClientIP IP address of the client string \n ClientIPClass unknowncleanbadHostsearchEnginewhitelistgreylistmonitoringServicesecurityScannernoRecordscanbackupServicemobilePlatformtor string \n ClientRequestBytes Number of bytes in the client request int \n ClientRequestHost Host requested by the client string \n ClientRequestMethod HTTP method of client request string \n ClientRequestPath URI path requested by the client string \n ClientRequestProtocol HTTP protocol of client request string \n ClientRequestReferer HTTP request referrer string", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-log-fields"}, {"document_id": "ibmcld_04175-0-1274", "score": 20.0294732537988, "text": "\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13790-1284-2889", "score": 17.585696969623786, "text": "\n* For more information about obtaining word timings, see [Generating word timings](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https://tools.ietf.org/html/rfc6455).\n\n\n\n Open a connection \n\nYou call the /v1/synthesize method over the WebSocket Secure (WSS) protocol to open a connection to the service. The method is available at the following endpoint:\n\nwss://api.{location}.text-to-speech.watson.cloud.ibm.com/instances/{instance_id}/v1/synthesize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of the service instance.\n\nThe examples in the documentation abbreviate wss://api.{location}.text-to-speech.watson.cloud.ibm.com/instances/{instance_id} to {ws_url}. So all WebSocket examples call the method as {ws_url}/v1/synthesize.\n\nA WebSocket client calls the /v1/synthesize method with the following query parameters to establish an authenticated connection with the service:\n\naccess_token (required string)\n: Pass a valid access token to authenticate with the service.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocket"}, {"document_id": "ibmcld_13384-7-1898", "score": 17.558904122728514, "text": "\nUsing a custom language model for speech recognition \n\nOnce you create and train your custom language model, you can use it in speech recognition requests by using the language_customization_id query parameter. By default, no custom language model is used with a request. You can create multiple custom language models for the same or different domains. But you can specify only one custom language model at a time for a speech recognition request. You must issue the request with credentials for the instance of the service that owns the custom model.\n\nA custom model can be used only with the base model for which it is created. If your custom model is based on a model other than the default, you must also specify that base model with the model query parameter. For more information, see [Using the default model](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-models-usemodels-use-default).\n\nFor information about telling the service how much weight to give to words from a custom model, see [Using customization weight](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-languageUseweight). For examples that use a grammar with a custom language model, see [Using a grammar for speech recognition](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-grammarUse).\n\n\n\n Examples of using a custom language model \n\nThe following examples show the use of a custom language model with each speech recognition interface. In this case, the custom model that is used is based on the next-generation model en-US_Telephony.\n\n\n\n* For the [WebSocket interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets), use the /v1/recognize method. The specified custom model is used for all requests that are sent over the connection.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}/v1/recognize'\n+ '?access_token=' + access_token", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-languageUse"}, {"document_id": "ibmcld_13790-7-1700", "score": 17.428573684960686, "text": "\nThe WebSocket interface \n\nTo synthesize text to speech with the WebSocket interface of the IBM Watson\u00ae Text to Speech service, you first establish a connection with the service by calling its /v1/synthesize method. You then send the text to be synthesized to the service as a JSON text message over the connection. The service automatically closes the WebSocket connection when it finishes processing the request.\n\nThe synthesize request and response cycle includes the following steps:\n\n\n\n1. [Open a connection](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocketWSopen).\n2. [Send input text](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocketWSsend).\n3. [Receive a response](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocketWSreceive).\n\n\n\nThe WebSocket interface accepts identical input and produces identical results as the GET and POST /v1/synthesize methods of the HTTP interface. In addition, the WebSocket interface also supports use of the SSML <mark> element to identify the location of user-specified markers in the audio. It can also return timing information for all strings of the input text. (The <mark> element and word timings are available only with the WebSocket interface.)\n\n\n\n* For more information about obtaining word timings, see [Generating word timings](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-timing).\n* For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocket"}, {"document_id": "ibmcld_13455-7-1568", "score": 17.184616264717317, "text": "\nThe WebSocket interface \n\nThe WebSocket interface of the IBM Watson\u00ae Speech to Text service is the most natural way for a client to interact with the service. To use the WebSocket interface for speech recognition, you first use the /v1/recognize method to establish a persistent connection with the service. You then send text and binary messages over the connection to initiate and manage recognition requests.\n\nBecause of their advantages, WebSockets are the preferred mechanism for speech recognition. For more information, see [Advantages of the WebSocket interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-service-featuresfeatures-websocket-advantages). For more information about the WebSocket interface and its parameters, see the [API & SDK reference](https://cloud.ibm.com/apidocs/speech-to-text).\n\n\n\n Managing a WebSocket connection \n\nThe WebSocket recognition request and response cycle has the following steps:\n\n\n\n1. [Open a connection](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-open)\n2. [Initiate a recognition request](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-start)\n3. [Send audio and receive recognition results](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-audio)\n4. [End a recognition request](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-more)\n6.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}, {"document_id": "ibmcld_10833-0-1231", "score": 16.440628006422482, "text": "\n\n\n\n\n\n\n  WebSocket \n\nThe preinstalled /whisk.system/websocket package for IBM Cloud\u00ae Functions offers a convenient way to post messages to a WebSocket.\n\nThe package includes the following actions.\n\n\n\nTable 1. WebSocket package entities\n\n Entity                          Type     Parameters        Description                                 \n\n /whisk.system/websocket         Package  uri               Utilities for communicating with WebSockets \n /whisk.system/websocket/send    Action   uri, payload      Send the payload to the WebSocket URI.      \n\n\n\nIf you plan to send many messages to the same WebSocket URI, creating a package binding with the uri value is suggested. With binding, you don't need to specify the value each time that you use the send action.\n\n\n\n  Send a message to a WebSocket \n\nThe /whisk.system/websocket/send action sends a payload to a WebSocket URI. The parameters are as follows.\n\n\n\nTable 2. WebSocket send action parameters\n\n Parameter  Description                                                                \n\n uri        The URI of the WebSocket server. For example, ws://mywebsockethost:80.     \n payload    The message to send to the WebSocket.                                      \n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_websocket"}, {"document_id": "ibmcld_10852-48513-49624", "score": 16.299111414060405, "text": "\n* [Reading an object with the CLI](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_read_cli)\n* [Reference for Object Storage and Cloud Functions](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_actions)\n\n\n\n\n\n[Slack](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_slackpkg_slack)\n\n\n\n* [Posting a message to a Slack channel](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_slackpkg_slack_post)\n* [Using the Slack token-based API](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_slackpkg_slack_api)\n\n\n\n[Utilities](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_utilspkg_utils)\n\n[WebSocket](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_websocketpkg_websocket)\n\n\n\n* [Send a message to a WebSocket](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_websocketsend-websocket)\n\n\n\n[Creating custom event provider feeds](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-feeds_customfeeds_custom)\n\n\n\n* [Feed architecture](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-feeds_customfeeds_arch)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_13429-163247-165127", "score": 15.878039587638945, "text": "\nThe WebSocket section also discusses the maximum frame or message size of 4 MB enforced by the WebSocket interface.\n\nHTTP and WebSocket interfaces can now return warnings\n: The JSON response for a recognition request can now include an array of warning messages for invalid query parameters or JSON fields that are included with a request. Each element of the array is a string that describes the nature of the warning followed by an array of invalid argument strings. For example, \"warnings\": [ \"Unknown arguments: u'{invalid_arg_1}', u'{invalid_arg_2}'].\" ]. For more information, see the [API & SDK reference](https://cloud.ibm.com/apidocs/speech-to-text).\n\nBeta Apple iOS SDK is deprecated\n: The beta Watson Speech Software Development Kit (SDK) for the Apple\u00ae iOS operating system is deprecated. Use the Watson SDK for the Apple\u00ae iOS operating system instead. The new SDK is available from the [ios-sdk repository](https://github.com/watson-developer-cloud/ios-sdk) in the watson-developer-cloud namespace on GitHub.\n\nWebSocket interface can produce delayed results\n: The WebSocket interface can take minutes to produce final results for a recognition request for an especially long audio file. For the WebSocket interface, the underlying TCP connection remains idle while the service prepares the response. Therefore, the connection can close due to a timeout. To avoid the timeout with the WebSocket interface, request interim results (\"interim_results\": \"true\") in the JSON for the start message to initiate the request. You can discard the interim results if you do not need them. This issue will be resolved in a future update.\n\n\n\n\n\n 19 January 2016 \n\nNew profanity filtering feature\n: The service was updated to include a new profanity filtering feature on January 19, 2016. By default, the service censors profanity from its transcription results for US English audio.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-release-notes"}, {"document_id": "ibmcld_13455-26115-26611", "score": 15.829116326429716, "text": "\nIf the socket closes with an error, the client receives an informative message of the form {\"error\":\"{message}\"} before the socket closes. Use the onerror event handler to respond appropriately. For more information about WebSocket return codes, see [IETF RFC 6455](https://tools.ietf.org/html/rfc6455).\n\nThe WebSocket implementations of the SDKs can return different or additional response codes. For more information, see the [API & SDK reference](https://cloud.ibm.com/apidocs/speech-to-text).", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}, {"document_id": "ibmcld_13741-1529-3393", "score": 15.589440467087673, "text": "\nSynthesizing speech with the service \n\nThe Text to Speech service offers an HTTP Representational State Transfer (REST) interface and a WebSocket interface:\n\n\n\n* [The HTTP interface](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingHTTP) provides both GET and POST versions of the service's /v1/synthesize method. The two versions of the method offer generally equivalent functionality. You pass the text that is to be synthesized as a query parameter with the GET method and as the body of the request with the POST method.\n* [The WebSocket interface](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocket) provides a /v1/synthesize method. You pass the text that is to be synthesized over an established WebSocket connection.\n\n\n\nWith both the HTTP and WebSocket interfaces, you specify the language and voice that are to be used, and the format for the audio that is to be returned.\n\n\n\n* For an overview of the features that are available for speech synthesis, see [Using speech synthesis features](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-service-featuresfeatures-synthesis).\n* For detailed descriptions and examples of the speech synthesis methods, see the [API & SDK reference](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\n\n\n Data limits \n\nThe interfaces accept the following maximum amounts of text with a single request:\n\n\n\n* The HTTP GET /v1/synthesize method accepts a maximum of 8 KB of input, which includes the input text and the URL and headers.\n* The HTTP POST /v1/synthesize method accepts a maximum of 8 KB for the URL and headers, and a maximum of 5 KB for the input text that is sent in the body of the request.\n* The WebSocket /v1/synthesize method accepts a maximum of 5 KB of input text.\n\n\n\nThese limits include all characters of the input, including whitespace.\n\nIBM Cloud", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-service-features"}, {"document_id": "ibmcld_13455-1311-2796", "score": 15.278615537176227, "text": "\n4. [End a recognition request](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-stop)\n5. [Send additional requests and modify request parameters](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-more)\n6. [Keep a connection alive](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-keep)\n7. [Close a connection](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websocketsws-close)\n\n\n\nWhen the client sends data to the service, it must pass all JSON messages as text messages and all audio data as binary messages.\n\nThe snippets of example code that follow are written in JavaScript and are based on the HTML5 WebSocket API. For more information about the WebSocket protocol, see the Internet Engineering Task Force (IETF) [Request for Comment (RFC) 6455](https://tools.ietf.org/html/rfc6455).\n\n\n\n Open a connection \n\nThe Speech to Text service uses the WebSocket Secure (WSS) protocol to make the /v1/recognize method available at the following endpoint:\n\nwss://api.{location}.speech-to-text.watson.cloud.ibm.com/instances/{instance_id}/v1/recognize\n\nwhere {location} indicates where your application is hosted:\n\n\n\n* us-south for Dallas\n* us-east for Washington, DC\n* eu-de for Frankfurt\n* au-syd for Sydney\n* jp-tok for Tokyo\n* eu-gb for London\n* kr-seo for Seoul\n\n\n\nAnd {instance_id} is the unique identifier of your service instance.\n\nThe examples in the documentation abbreviate wss://api.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03080-7-1901", "score": 70.26850839195868, "text": "\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-config"}, {"document_id": "ibmcld_03421-4-1877", "score": 70.02073289660642, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_16368-7-2072", "score": 66.15233013942549, "text": "\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_16365-1312-3051", "score": 59.94255678332679, "text": "\nFor more information, see [Configuring the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n![An example of the initial launcher](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-icon.png)\n\nAfter 15 seconds, the launcher expands to show a greeting message to the user. In this expanded state, a customer can still click the launcher to open the web chat. (If the customer reloads the page or navigates to a different page before the launcher has expanded, the 15-second timer restarts.)\n\nThe appearance of this expanded state differs slightly depending on whether the customer is using a desktop browser or a mobile browser:\n\n\n\n* For desktop browsers, the expanded launcher shows two primary buttons the customer can click to open the web chat, and a Close button that closes the launcher.\n\n![An example of the desktop launcher](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/desktop-launcher.png)\n\nThe expanded launcher remains in its expanded state even if the customer reloads the page or navigates to a different page. It stays in its expanded state until the customer either opens it by clicking on either of the two primary buttons, or closes it, at which point it returns to its initial small state for the rest of the session.\n* For mobile browsers, the launcher shows only a single primary button.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_03166-9980-11726", "score": 58.16739708997608, "text": "\nThis means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nA developer can use APIs to apply more advanced customizations to the style of the web chat. For more information, see [Applying advanced customizations](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config).\n\n\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n![An example of the initial launcher](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/web-chat-icon.png)\n\nAfter 15 seconds, the launcher expands to show a greeting message to the user. In this expanded state, a customer can still click the launcher to open the web chat. (If the customer reloads the page or navigates to a different page before the launcher has expanded, the 15-second timer restarts.) There are two slightly different appearances for this expanded state, depending on whether the user is using a desktop browser or a mobile browser.\n\n\n\n* For desktop browsers, the expanded launcher shows two primary buttons the customer can click to open the web chat, and a Close button that closes the launcher:\n\n![An example of the desktop launcher](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/desktop-launcher.png)\n\nThe expanded launcher remains in its expanded state even if the customer reloads the page or navigates to a different page.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}, {"document_id": "ibmcld_16366-1573-3444", "score": 56.59949633174645, "text": "\nOn the ![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)Integrations page, find the Web chat tile and click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\n\n\n\n\n Setup tasks \n\nYou can configure the web chat in the following ways:\n\nStyle and appearance\n: You can configure the overall appearance of the web chat widget, including the assistant name, the colors of various elements, and the avatar image. For more information, see [Configuring style and appearance](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-style).\n\nLauncher\n: You can change the greeting text that is shown by the launcher that invites users to open the web chat. On the Launcher tab, you can specify separate greeting messages for the desktop launcher and the mobile launcher.\n\nThe message you specify is immediately reflected by the launcher preview that is shown on the page. However, no configuration changes are applied to the environment until you click Save and exit.\n\nHome screen\n: You can configure the contents of the home screen that greets customers and helps them start the conversation. For more information, see [Configuring the home screen](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen).\n\nSuggestions\n: You can configure how and when the web chat offers offers suggestions to customers when the assistant isn't delivering what they expect. For more information, see [Configuring suggestions](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-suggestions).\n\nSecurity", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config"}, {"document_id": "ibmcld_16365-7-1700", "score": 55.082470836042205, "text": "\nHow the web chat works \n\nThe web chat provides an easy-to-use chatbot interface that you can add to your website without writing any code.\n\nAfter you add the web chat script to your website, your customers will see a launcher icon that they can click to open the chat window and start a conversation with the assistant. The appearance of the launcher icon adapts to desktop and mobile browsers.\n\n![web chat launcher in desktop browser](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-desktop-highlighted.png)\n\nWhen a customer clicks the launcher, the web chat window opens, initially displaying the home screen. The home screen displays a greeting and an optional set of suggested conversation starters for common questions and problems. The customer can either click a conversation starter or type a message in the input field to start the conversation with the assistant.\n\n![web chat example home screen](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/web-chat-home-screen-lendyr.png)\n\nThe appearance and behavior of the launcher icon, the home screen, and most other aspects of the web chat can be configured and customized to match your website style and branding. For more information, see [Configuring the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n Launcher appearance and behavior \n\nThe web chat launcher welcomes and engages customers so they know where to find help if they need it. By default, the web chat launcher appears in a small initial state as a circle in the bottom right corner:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_16366-7-1826", "score": 54.24907328327637, "text": "\nWeb chat setup overview \n\nYou can modify the web chat integration settings to configure the styling and appearance of the web chat.\n\nYou can quickly deploy and test the web chat integration using the default settings. However, before you go to production with your chatbot, you will need to configure the web chat to integrate with your website and better serve the needs of your customers.\n\nAt a minimum, you should update the following basic settings for your assistant:\n\n\n\n* The [assistant name](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-style) that you want to show to your customers\n* The contents of the [home screen](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen)\n* The [suggestions](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-suggestions) your assistant will offer if customers get stuck\n\n\n\nYou might also want to make additional configurations, such as changing the web chat colors to match your branding, changing the launcher greeting, or enabling encryption.\n\nIf you are a developer, you can customize the web chat by using the web chat API. With the API, you can customize the styling, change the behavior of the web chat widget and launcher, customize strings, modify message content, and more. For more information about using the web chat API, see [Web chat development overview](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop).\n\nTo change the web chat configuration, follow these steps:\n\n\n\n1. On the ![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)Integrations page, find the Web chat tile and click Open. The Open web chat window opens.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config"}, {"document_id": "ibmcld_03421-1518-3290", "score": 53.18530879605271, "text": "\nIf you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size. For a tutorial that shows you how, see [Render to a custom element](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-example-element).\n* Hide the launcher icon entirely and automatically start the web widget in open state, at its full length. For more information, see the [openChatByDefault method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n* Hide the close button so users cannnot close the web chat widget. For more information, see the [hideCloseButton method](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject).\n\n\n\n\n\n\n\n Change the conversation \n\nThe core of the conversation is defined in your skill. If you use more than one integration type, focus on defining an engaging conversation in the underlying skill. The same skill is used for all integrations. To customize the conversation for the web chat only, you can take the following actions:\n\n\n\n* Update the text of a message before it is sent or after it is received, such as to hide personally-identifiable information.\n* Pass contextual information, such as the customer's name, from the web chat to the underlying skill.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_03166-8640-10452", "score": 51.67339003367487, "text": "\nFor more information, see [Applying advanced customizations](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config).\n4. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/web-chat-window.png)\n5. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere where you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n6. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf the Connect to agent button is displayed and you don't have human agent support configured, you can hide it by changing the Suggestions configuration. For more information, see [Showing more suggestions](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate).\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.\n\n\n\nA developer can use APIs to apply more advanced customizations to the style of the web chat. For more information, see [Applying advanced customizations](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config).\n\n\n\n\n\n Launcher appearance and behavior", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-417176-418645", "score": 14.279030040423343, "text": "\n: Description of IAM API key.\n\niam_apikey_name\n: ID of IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of service ID.\n\nurl\n: IBM Cloudant service URL.\n\nusername\n: The internal IBM Cloudant account name.\n\nFor more information, see [IBM Cloud API keys and Use only IAM](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudantibm-cloudant-api-keys-and-use-only-iam_ai).\n\n\n\n\n\nIn most cases, rotating credentials is a straight-forward process:\n\n\n\n1. Generate a replacement service credential. For more information, see [How can I generate service credentials?](https://cloud.ibm.com/docs/faqsfind-service-credentials-iam).\n2. Replace the current credential with the newly generated credential.\n3. Delete the no-longer-used service credential.\n\n\n\nHowever, when you rotate the credentials for a replication, if you are using legacy credentials in the replication document, the replication starts from the beginning. To ensure that changes arrive in a timely manner, we advise you to create a new replication once it catches up with deleting the previous replication and the associated service credential. The process is described in the following steps:\n\n\n\n1. Generate a replacement service credential. For more information, see [How can I generate service credentials?](https://cloud.ibm.com/docs/faqsfind-service-credentials-iam).\n2. Create a replication with the same settings but new credentials.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_00589-5073-6581", "score": 14.271632920720716, "text": "\nTo provision an instance as Use both legacy credentials and IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" cloudantnosqldb Standard us-south -p {\"legacyCredentials\": true}\n\n\n\n\n\n Service credential JSON examples for each option \n\nThe choice between Use only IAM and Use both legacy credentials and IAM access control affects how credentials are delivered to your application when you bind and generate service credentials. When you generate credentials within the primary IBM Cloud IAM interface, API keys are shown in that interface when generated.\n\nYou can also generate credentials from the Service Credentials section of a service instance. Generating service credentials this way creates a service credentials JSON blob that can be pasted into applications with all the details that are needed to access the service instance.\n\nNext, you can see what the service credential JSON looks like and what each value means.\n\nWhen you select Use only IAM, the service credentials that are generated contain only IAM values, and look like the following example.\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",\n\"iam_apikey_description\": \"Auto generated apikey during resource-key [...]\",\n\"iam_apikey_name\": \"auto-generated-apikey-050d21b5-5f[...]\",\n\"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Manager\",\n\"iam_serviceid_crn\": \"crn:v1:staging:public:iam-identity::[...]\",\n\"url\": \"https://76838001-b883-444d-90d0-46f89e942a15-bluemix.cloudant.com\",", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudant"}, {"document_id": "ibmcld_16727-417150-418627", "score": 14.26761201142838, "text": "\n: Description of IAM API key.\n\niam_apikey_name\n: ID of IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of service ID.\n\nurl\n: IBM Cloudant service URL.\n\nusername\n: The internal IBM Cloudant account name.\n\nFor more information, see [IBM Cloud API keys and Use only IAM](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudantibm-cloudant-api-keys-and-use-only-iam_ai).\n\n\n\n\n\nIn most cases, rotating credentials is a straight-forward process:\n\n\n\n1. Generate a replacement service credential. For more information, see [How can I generate service credentials?](https://cloud.ibm.com/docs?tab=faqsfind-service-credentials-iam).\n2. Replace the current credential with the newly generated credential.\n3. Delete the no-longer-used service credential.\n\n\n\nHowever, when you rotate the credentials for a replication, if you are using legacy credentials in the replication document, the replication starts from the beginning. To ensure that changes arrive in a timely manner, we advise you to create a new replication once it catches up with deleting the previous replication and the associated service credential. The process is described in the following steps:\n\n\n\n1. Generate a replacement service credential. For more information, see [How can I generate service credentials?](https://cloud.ibm.com/docs?tab=faqsfind-service-credentials-iam).\n2. Create a replication with the same settings but new credentials.\n3.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_00483-3212-4996", "score": 14.237579773270614, "text": "\n: The legacy credentials password that is required for applications to access the service instance. This field displays only if the Use both legacy credentials and IAM option is chosen.\n\nhost\n: The hostname that is used by applications to locate the service instance. This field displays only if the Use both legacy credentials and IAM option is chosen.\n\nport\n: The HTTPS port number for accessing the service instance on the host. It's 443 as only HTTPS access is allowed by IBM Cloudant. This field displays only if the Use both legacy credentials and IAM option is chosen.\n\nurl\n: The HTTPS URL to access the IBM Cloudant instance. If the Use both legacy credentials and IAM option is chosen, it also includes the embedded legacy username and password.\n\napikey\n: The IAM API key.\n\niam_apikey_description\n: Description of the IAM API key.\n\niam_apikey_name\n: ID of the IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of the service ID.\n\n\n\n\n\n Authentication \n\nIBM Cloudant has two authentication methods available at provisioning time, either Use only IAM or Use both legacy credentials and IAM. You can see the details about your legacy credentials in the service credentials only if the Use both legacy credentials and IAM authentication method is chosen. The credentials display on the Service credentials tab for your instance. For more information, see the [IAM guide](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudant) and [legacy authentication](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-work-with-your-accountauthentication) document for details about using either style of authentication.\n\nThe IBM Cloudant team recommends you use IAM access controls for authentication whenever possible.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-connecting"}, {"document_id": "ibmcld_12422-16914-18005", "score": 14.20232376596697, "text": "\nYou must add a depends_on Terraform meta-argument and refer it to your IAM configuration resource. The depends_on meta-argument instructs Terraform to complete all actions on the IAM configuration before you perform actions on the IAM credentials secrets.\n\nThe following example shows a configuration that you can use to create IAM credentials.\n\nresource \"ibm_sm_iam_credentials_secret\" \"test_iam_credentials_secret\" {\ninstance_id = local.instance_id\nregion = local.region\nservice_id = \"ServiceId-f4b2deac-fbb5-4bf7-85de-88426701db97\"\nttl = \"1800\"\nname = \"test-iam-credentials-secret\"\nreuse_api_key = true\nsecret_group_id = ibm_sm_secret_group.sm_secret_group_test.secret_group_id\ndepends_on = [\nibm_sm_iam_credentials_configuration.iam_credentials_configuration\n]\n}\n\n\n\n\n\n Deleting IAM credentials \n\nIf you have a service ID or API key that was generated by the IAM credentials secret engine and delete your instance of Secrets Manager, you must also delete the secret from IAM. For more information, see [Managing user API keys](https://cloud.ibm.com/docs/account?topic=account-userapikey).", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials"}, {"document_id": "ibmcld_12428-16940-18031", "score": 14.20232376596697, "text": "\nYou must add a depends_on Terraform meta-argument and refer it to your IAM configuration resource. The depends_on meta-argument instructs Terraform to complete all actions on the IAM configuration before you perform actions on the IAM credentials secrets.\n\nThe following example shows a configuration that you can use to create IAM credentials.\n\nresource \"ibm_sm_iam_credentials_secret\" \"test_iam_credentials_secret\" {\ninstance_id = local.instance_id\nregion = local.region\nservice_id = \"ServiceId-f4b2deac-fbb5-4bf7-85de-88426701db97\"\nttl = \"1800\"\nname = \"test-iam-credentials-secret\"\nreuse_api_key = true\nsecret_group_id = ibm_sm_secret_group.sm_secret_group_test.secret_group_id\ndepends_on = [\nibm_sm_iam_credentials_configuration.iam_credentials_configuration\n]\n}\n\n\n\n\n\n Deleting IAM credentials \n\nIf you have a service ID or API key that was generated by the IAM credentials secret engine and delete your instance of Secrets Manager, you must also delete the secret from IAM. For more information, see [Managing user API keys](https://cloud.ibm.com/docs/account?topic=account-userapikey).", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials&interface=ui"}, {"document_id": "ibmcld_00583-2378-4437", "score": 14.172203903931258, "text": "\nIf anyone or any application has access to the credentials, they can effectively do whatever they want with the service instance. For example, they might create spurious data, or delete valuable information. Protect these credentials carefully.\n\nIBM Cloudant has two authentication methods available at provisioning time, either Use only IAM or Use both legacy credentials and IAM. You can see the details about your legacy credentials only if the Use both legacy credentials and IAM authentication method is chosen. The credentials display on the Service credentials tab for your instance. For more information, see the [IAM guide](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudant) and [legacy authentication](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudant) document for details about using either style of authentication.\n\nThe service credentials include the following fields, as well as designating the fields that are only shown if you select the Use both legacy credentials and IAM option:\n\n\n\nTable 1. Service credential fields\n\n Field Purpose Legacy-auth enabled \n\n username The username that is required for applications to access the service instance. \n password The legacy credentials password that is required for applications to access the service instance. X \n host The hostname that is used by applications to locate the service instance. X \n port The HTTPS port number for accessing the service instance on the host. It's 443 as only HTTPS access is allowed by IBM Cloudant. X \n url The HTTPS URL to access the IBM Cloudant instance. X (If the Use both legacy credentials and IAM option is chosen, it also includes the embedded legacy username and password.) \n apikey The IAM API key. \n iam_apikey_description Description of the IAM API key. \n iam_apikey_name ID of the IAM API key. \n iam_role_crn The IAM role that the IAM API key has. \n iam_serviceid_crn The CRN of the service ID. X \n\n\n\nTo create an application that can access your service instance, you need these credentials.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-locating-your-service-credentials"}, {"document_id": "ibmcld_00610-7-2079", "score": 14.170991864707352, "text": "\nMigrating an instance with legacy credentials and IAM Authentication to IAM Only Authentication \n\nWhen you create a new service credential by using the IBM Cloud Dashboard or the IBM Cloud CLI, it always produces a new username and password combination. This method applies to legacy credentials as well as a new IAM API key. This tutorial guides you through migrating your instance from generating new legacy credentials and IAM API keys to generating new IAM API keys only.\n\nThis tutorial is only applicable to IBM Cloudant instances within resource groups with legacy credentials that are enabled.\n\nSee the effects of this tutorial on existing legacy credentials:\n\n\n\n* New format legacy credentials (usernames that start with apikey-v2-) continue to function until the service credential is deleted.\n* URL style legacy credentials if still active are revoked. If you would like to revoke them separately, follow the [Revoking credential that is tied to your instance URL](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-revoke-instance-url-style-credential) steps before you complete this tutorial.\n\n\n\n\n\n Objectives \n\n\n\n1. Update your applications to use IAM credentials instead of legacy credentials.\n2. Disable creation of new legacy credentials.\n\n\n\n\n\n\n\n Step 1: Generating new IBM Cloudant IAM Credentials \n\n\n\n1. Use the IBM Cloud Dashboard or the IBM Cloud CLI to [generate new service credentials](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-started-with-cloudantcreating-service-credentials) for your IBM Cloudant instance. For more information, see [Creating service credentials](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-to-iam-onlycreating-service-credentials) for further instructions.\n\n\n\n\n\n\n\n Step 2: Updating applications \n\n\n\n1. Update all applications to use IAM access tokens when you authenticate with the IBM Cloudant instance.\n\n\n\n\n\n\n\n Step 3: Migrating to IAM only \n\nThis operation cannot be undone. Make sure all applications that access the instance are using IAM to authenticate before you start this step.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-to-iam-only"}, {"document_id": "ibmcld_12404-7597-8376", "score": 14.168710914936348, "text": "\nYou can configure a secrets engine programmatically by using Terraform for Secrets Manager.\n\nThe following example shows a configuration that you can use to configure the IAM credentials engine.\n\nresource \"ibm_sm_iam_credentials_configuration\" \"iam_credentials_configuration\" {\ninstance_id = local.instance_id\nregion = local.region\nname = \"iam_credentials_config\"\napi_key = var.ibmcloud_api_key\n}\n\n\n\n\n\n Next steps \n\nNow you can use Secrets Manager to dynamically generate IAM credentials for your apps. In the Secrets Manager UI, click Secrets > Add > IAM credentials to start creating secrets.\n\n\n\n* [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials)\n\n\n\nThe metadata update operation uses a secret ID as part of the path.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-configure-iam-engine"}, {"document_id": "ibmcld_00583-1311-2968", "score": 14.138846946521848, "text": "\n(https://cloud.ibm.com/docs-content/v1/content/522c6f62358b063f921283400a601c3f9bc66f08/Cloudant/tutorials/images/img0052.png)\n\nFigure 2. Viewing the IBM Cloudant service credentials\n\nNow, you can see the service credentials:\n\nZoom\n\n![The service credentials in this image are surrounded by a red box. The credentials include apikey, host, iam_apikey_description, iam_apikey_name, iam_role_crn, iam_serviceid_crn, url, and username.](https://cloud.ibm.com/docs-content/v1/content/522c6f62358b063f921283400a601c3f9bc66f08/Cloudant/tutorials/images/img0009.png)\n\nFigure 3. The IBM Cloudant service credentials\n\nThe service credentials in these examples were defined when a demonstration IBM Cloudant service was created on IBM Cloudant. The credentials are reproduced here to show how they would appear in the dashboard. However, the demonstration IBM Cloudant service was removed, so these credentials are no longer valid. You must supply and use your own service credentials.\n\n\n\n\n\n\n\n Step 2: Understanding your service credentials \n\nService credentials are valuable. If anyone or any application has access to the credentials, they can effectively do whatever they want with the service instance. For example, they might create spurious data, or delete valuable information. Protect these credentials carefully.\n\nIBM Cloudant has two authentication methods available at provisioning time, either Use only IAM or Use both legacy credentials and IAM. You can see the details about your legacy credentials only if the Use both legacy credentials and IAM authentication method is chosen. The credentials display on the Service credentials tab for your instance.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-locating-your-service-credentials"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06251-22863-24659", "score": 16.43078742783907, "text": "\nThe instructions in this topic are available for VPC worker nodes only. If you want to attach raw, unformatted block storage to a classic worker node, you must install the [IBM Cloud Block Storage attacher plug-in](https://cloud.ibm.com/docs/containers?topic=containers-utilitiesblock_storage_attacher).\n\nBefore you begin:\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\n\n\n1. List your storage volumes and note the ID of the volume that you want to attach.\n\nibmcloud is vols\n2. List the worker nodes in your cluster and note the ID of the worker node where you want to attach your volume.\n\nibmcloud ks worker ls -c <cluster_name_or_ID>\n3. Attach your Block Storage for Classic to your VPC worker node.\n\nibmcloud ks storage attachment create --cluster <cluster_name_or_ID> --volume <volume> --worker <worker_ID>\n\n\n\n\n\n Removing raw Block Storage for VPC from VPC worker nodes by using the CLI \n\nYou can remove storage from your worker node by using the ibmcloud ks storage attachment rm command.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\n\n\n1. List your storage volumes and note the ID of the volume that you want to remove.\n\nibmcloud is vols\n2. Get the details of your volume such as the worker-id where the volume is attached. The worker-id is listed as the Instance name in the Volume Attachment Instance Reference section of the command output.\n\nibmcloud is vol <volume-ID>\n\nExample output\n\nVolume Attachment Instance Reference Attachment type Instance ID Instance name Auto delete Attachment ID Attachment name", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-utilities"}, {"document_id": "ibmcld_10203-2544-4340", "score": 16.411372590388673, "text": "\noc new-app --name <app_name> https://github.com/<path_to_app_repo> [--context-dir=<subdirectory>]\n\nWhat does the new-app command do?\n: The new-app command creates a build configuration and app image from the source code, a deployment configuration to deploy the container to pods in your cluster, and a service to expose the app within the cluster. For more information about the build process and other sources besides Git, see the [Red Hat OpenShift documentation](https://docs.openshift.com/container-platform/4.11/applications/creating_applications/odc-creating-applications-using-developer-perspective.html).\n\n\n\n\n\n\n\n Deploying apps to specific worker nodes by using labels \n\nWhen you deploy an app, the app pods indiscriminately deploy to various worker nodes in your cluster. Sometimes, you might want to restrict the worker nodes that the app pods to deploy to. For example, you might want app pods to deploy to only worker nodes in a certain worker pool because those worker nodes are on bare metal machines. To designate the worker nodes that app pods must deploy to, add an affinity rule to your app deployment.\n\nBefore you begin\n\n\n\n* [Access your Red Hat OpenShift cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-access_cluster).\n* Make sure that you are assigned a [service access role](https://cloud.ibm.com/docs/openshift?topic=openshift-userschecking-perms) that grants the appropriate Kubernetes RBAC role so that you can work with Kubernetes resources in the Red Hat OpenShift project.\n* Optional: [Set a label for the worker pool](https://cloud.ibm.com/docs/openshift?topic=openshift-add_workersworker_pool_labels) that you want to run the app on.\n\n\n\nTo deploy apps to specific worker nodes,\n\n\n\n1. Get the ID of the worker pool that you want to deploy app pods to.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-deploy_app"}, {"document_id": "ibmcld_05838-25355-26994", "score": 16.367014984158146, "text": "\nThe Autorecovery system uses various checks to query worker node health status. If Autorecovery detects an unhealthy worker node based on the configured checks, Autorecovery triggers a corrective action like rebooting a VPC worker node or reloading the operating system in a classic worker node. Only one worker node undergoes a corrective action at a time. The worker node must complete the corrective action before any other worker node undergoes a corrective action. For more information, see this [Autorecovery blog post](https://www.ibm.com/cloud/blog/autorecovery-utilizes-consistent-hashing-high-availability).\n\nAutorecovery requires at least one healthy worker node to function properly. Configure Autorecovery with active checks only in clusters with two or more worker nodes.\n\nBefore you begin:\n\n\n\n* Ensure that you have the following [IBM Cloud IAM roles](https://cloud.ibm.com/docs/containers?topic=containers-userschecking-perms):\n\n\n\n* Administrator platform access role for the cluster\n* Writer or Manager service access role for the kube-system namespace\n\n\n\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\n\n\nTo configure Autorecovery:\n\n\n\n1. [Follow the instructions](https://cloud.ibm.com/docs/containers?topic=containers-helminstall_v3) to install the Helm version 3 client on your local machine.\n2. Create a configuration map file that defines your checks in JSON format. For example, the following YAML file defines three checks: an HTTP check and two Kubernetes API server checks.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-health-monitor"}, {"document_id": "ibmcld_06209-36554-38368", "score": 15.766108657739814, "text": "\nYou can use worker pools to spread worker nodes evenly across zones and build a balanced cluster. Balanced clusters are more available and resilient to failures. If a worker node is removed from a zone, you can rebalance the worker pool and automatically provision new worker nodes to that zone. Worker pools are also used to install Kubernetes version updates to all your worker nodes.\n\nIf you created clusters before multizone clusters became available, your worker nodes are still stand-alone and not automatically grouped into worker pools. You must update these clusters to use worker pools. If not updated, you can't change your single zone cluster to a multizone cluster.\n\nReview the following image to see how your cluster setup changes when you move from stand-alone worker nodes to worker pools.\n\nZoom\n\n![Update your cluster from stand-alone worker nodes to worker pools](https://cloud.ibm.com/docs-content/v1/content/4d497aff9e27b92fbbc2ee4e343a9ec4549cb1d7/containers/images/cs_cluster_migrate.png)\n\nFigure 1. Update your cluster from stand-alone worker nodes to worker pools\n\nBefore you begin:\n\n\n\n* Ensure that you have the [Operator or Administrator IBM Cloud IAM platform access role](https://cloud.ibm.com/docs/containers?topic=containers-userschecking-perms) for the cluster.\n* [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\n\n\nTo update stand-alone worker nodes to worker pools:\n\n\n\n1. List existing stand-alone worker nodes in your cluster and note the ID, the Machine Type, and Private IP.\n\nibmcloud ks worker ls --cluster <cluster_name_or_ID>\n2. Create a worker pool and decide on the flavor and the number of worker nodes that you want to add to the pool.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_06251-14621-16000", "score": 15.463146728397867, "text": "\nIf you want to attach raw, unformatted block storage to a classic worker node, you must install the [IBM Cloud Block Storage attacher plug-in](https://cloud.ibm.com/docs/containers?topic=containers-utilitiesblock_storage_attacher).\n\nBefore you begin:\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\n\n\n1. Check which region and zone your VPC worker node is in.\n\nibmcloud ks worker ls -c <cluster_name>\n2. Decide on the [Block Storage for Classic profile](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-profiles) that best meets the capacity and performance requirements that you have.\n3. [Provision a Block Storage for Classic volume](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-block-storage). The volume that you provision must be in the same resource group, region, and zone as the worker node.\n4. Retrieve your IAM token.\n\nibmcloud iam oauth-tokens\n5. Retrieve the ID of the worker node that you want to attach to the Block Storage for Classic instance. Make sure to select a worker node that is located in the same zone as your Block Storage for Classic volume.\n\nibmcloud ks worker ls --cluster <cluster_name_or_ID>\n6. Use a POST request to attach your Block Storage for Classic volume to the worker node.\n\nExample request", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-utilities"}, {"document_id": "ibmcld_10665-22516-24332", "score": 15.170496528545838, "text": "\nMake sure that the volume is in the same zone as the worker node for the attachment to succeed.\n\nThe instructions in this topic are available for VPC worker nodes only. If you want to attach raw, unformatted block storage to a classic worker node, you must install the [IBM Cloud Block Storage attacher plug-in](https://cloud.ibm.com/docs/openshift?topic=openshift-utilitiesblock_storage_attacher).\n\nBefore you begin:\n\n[Access your Red Hat OpenShift cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-access_cluster).\n\n\n\n1. List your storage volumes and note the ID of the volume that you want to attach.\n\nibmcloud is vols\n2. List the worker nodes in your cluster and note the ID of the worker node where you want to attach your volume.\n\nibmcloud oc worker ls -c <cluster_name_or_ID>\n3. Attach your Block Storage for Classic to your VPC worker node.\n\nibmcloud oc storage attachment create --cluster <cluster_name_or_ID> --volume <volume> --worker <worker_ID>\n\n\n\n\n\n Removing raw Block Storage for VPC from VPC worker nodes by using the CLI \n\nYou can remove storage from your worker node by using the ibmcloud oc storage attachment rm command.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\n\n\n1. List your storage volumes and note the ID of the volume that you want to remove.\n\nibmcloud is vols\n2. Get the details of your volume such as the worker-id where the volume is attached. The worker-id is listed as the Instance name in the Volume Attachment Instance Reference section of the command output.\n\nibmcloud is vol <volume-ID>\n\nExample output\n\nVolume Attachment Instance Reference Attachment type Instance ID Instance name Auto delete Attachment ID Attachment name", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-utilities"}, {"document_id": "ibmcld_06260-8470-9978", "score": 14.952823366884783, "text": "\nIf you want to permit egress from your allowlist-protected services to your cluster, you must add your worker nodes' private IP addresses or your cluster's VPC subnet CIDRs in your service's allowlist. Note that because worker nodes in VPC clusters have only private IP addresses, connections into the VPC cluster worker nodes can only originate from systems that are connected to your IBM Cloud private network.\n\nBefore you begin\n\n\n\n1. [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n2. Install the infrastructure-service CLI plug-in. The prefix for running VPC infrastructure commands is ibmcloud is.\n\nibmcloud plugin install infrastructure-service\n\n\n\n\n\n Allowing ingress from a cluster to another service \n\nTo permit ingress from your cluster to another service, modify that service's allowlist or your on-premises allowlist.\n\n\n\n1. Get the Worker Zones and VPCs that your cluster is created in.\n\nibmcloud ks cluster get -c <cluster>\n\nExample output\n\n...\nWorker Zones: us-south-1, us-south-2, us-south-3\nIngress Subdomain: vpc-prod.us-south.containers.appdomain.cloud\nIngress Secret: vpc-prod\nCreator: -\nPublic Service Endpoint URL: https://c2.us-south.containers.cloud.ibm.com:20267\nPrivate Service Endpoint URL: https://c2.private.us-south.containers.cloud.ibm.com:20267\nPull Secrets: enabled in the default namespace\nVPCs: ff537d43-a5a4-4b65-9627-17eddfa5237b\n...\n2.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc-firewall"}, {"document_id": "ibmcld_10395-7-1827", "score": 14.932888610975485, "text": "\nUpdating VPC worker nodes that use OpenShift Data Foundation \n\nVirtual Private Cloud\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-vpc"}, {"document_id": "ibmcld_06251-13150-15063", "score": 14.913663170472912, "text": "\nDetached volumes are still authorized to be accessed by a specific worker node and are attached again when you create a new PV with the IBM Cloud Block Volume Attacher storage class to attach a different volume to the same worker node. To avoid attaching the old detached volume again, unauthorize the worker node to access the detached volume by using the ibmcloud sl block access-revoke command. Detaching the volume does not remove the volume from your IBM Cloud infrastructure account. To cancel the billing for your volume, you must manually [remove the storage from your IBM Cloud infrastructure account](https://cloud.ibm.com/docs/containers?topic=containers-block_storagecleanup_block).\n\n\n\n\n\n VPC: Adding raw Block Storage for VPC to VPC worker nodes by using the API \n\nYou can use the Kubernetes Service API to attach and detach raw, unformatted [Block Storage for Classic](https://containers.cloud.ibm.com/global/swagger-global-api//storage/GetClassicVolume) to a worker node in your VPC cluster.\n\nYou can attach a volume to one worker node only. Make sure that the volume is in the same zone as the worker node for the attachment to succeed.\n\nYou can also attach, detach, and list the volume attachments of your worker nodes by using the CLI. For more information, see the [storage CLI reference](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_storage).\n\nThe instructions in this topic are available for VPC worker nodes only. If you want to attach raw, unformatted block storage to a classic worker node, you must install the [IBM Cloud Block Storage attacher plug-in](https://cloud.ibm.com/docs/containers?topic=containers-utilitiesblock_storage_attacher).\n\nBefore you begin:\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-utilities"}, {"document_id": "ibmcld_10444-5383-7233", "score": 14.911230294686668, "text": "\nFor more information, see [worker node resource reserves](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesresource_limit_node).\n\nWant to be sure that you always have enough worker nodes to cover your workload? Try out [the cluster autoscaler](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-scaling-classic-vpc).\n\n\n\n\n\n Why do my worker nodes have the master role? \n\nWhen you run oc get nodes or oc describe node <worker_node>, you might see that the worker nodes have master,worker roles. In OpenShift Container Platform clusters, operators use the master role as a nodeSelector so that OCP can deploy default components that are controlled by operators, such as the internal registry, in your cluster. No master node processes, such as the API server or Kubernetes scheduler, run on your worker nodes. For more information about master and worker node components, see [Red Hat OpenShift architecture](https://cloud.ibm.com/docs/openshift?topic=openshift-service-architectureservice-architecture-4).\n\n\n\n\n\n How can I check the operating system that my worker nodes run? \n\nWhen you create a worker pool, you choose the flavor, which describes the operating system along with the compute resources of the worker nodes. Supported operating systems are RHEL 7.\n\nYou can also log in to your cluster to check the operating system of the worker nodes.\n\n\n\n1. [Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n2. List your worker nodes.\n\noc get nodes\n3. Describe your worker node and check for the operating system label that IBM applies, or the OS Image and Operating System fields in the System Info section.\n\noc describe node <node>\n\nExample output\n\nNAME: 10.xxx.xx.xxx\nRoles: <none>", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodes"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00535-0-1738", "score": 27.795184570077282, "text": "\n\n\n\n\n\n\n  Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\n  Which plans can I migrate? \n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n*  IBM Cloudant Enterprise\n*  Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\n  Can I back up my data before I migrate? \n\nThe IBM Cloudant team advises that you use the [couchbackup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https://www.ibm.com/cloud/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\n  Can I keep my username.cloudant.com domain and redirect it to the new service on IBM Cloudant? \n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\n  Who do I contact if I have questions? \n\nGo to the [IBM Cloud Support portal](https://www.ibm.com/cloud/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-migration"}, {"document_id": "ibmcld_07578-447531-449109", "score": 25.00386978026273, "text": "\n[Upload](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https://www.ibm.com/cloud/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-447513-449091", "score": 25.00386978026273, "text": "\n[Upload](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-document-versioning-and-mvccupload-the-new-revision-mvcc) the new revision.\n4. [Delete](https://cloud.ibm.com/docs/services/Cloudant?topic=Cloudant-document-versioning-and-mvccdelete-old-revisions-mvcc) old revisions.\n\n\n\n* Migration FAQ\n\n Migration FAQ \n\nMigrate your plan to an IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Lite or Standard plan instance.\n\n\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n\n\n\n\n\nThe IBM Cloudant team advises that you use the [couchbackup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https://www.ibm.com/cloud/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-448564-450242", "score": 24.757579543542768, "text": "\nThe IBM Cloudant team advises that you use the [couchbackup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https://www.ibm.com/cloud/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https://www.ibm.com/cloud/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-448546-450224", "score": 24.757579543542768, "text": "\nThe IBM Cloudant team advises that you use the [couchbackup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk. Or use [IBM Cloud Object Storage](https://www.ibm.com/cloud/object-storage), which is an inexpensive, scalable solution for storing the exported files.\n\n\n\n\n\nNo, it's not possible to keep your domain. You must plan to update your applications to use the new account URL and credentials that are generated for the IBM Cloudant instances.\n\n\n\n\n\nGo to the [IBM Cloud Support portal](https://www.ibm.com/cloud/support), or open a ticket from within the IBM Cloudant Dashboard if you have any questions about migration. IBM Cloudant support is happy to provide more details.\n\n\n\n* Which plans can I migrate?\n\nYou can migrate to a Lite or Standard plan from one of the following plans:\n\n\n\n* IBM Cloudant Enterprise\n* Apache CouchDB\n\n\n\nFor more information, see [Migrating an Enterprise plan to a Lite or Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan).\n\nOr you can migrate from the Lite plan to a Standard plan, which is just upgrading from the Lite plan to the Standard plan. For more information, see [Migrating from a Lite plan to a Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan).\n* Can I back up my data before I migrate?\n\nThe IBM Cloudant team advises that you use the [couchbackup](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-ibm-cloudant-backup-and-recoveryibm-cloudant-backup-and-recovery) utility to export data to disk.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_13336-1484-3613", "score": 23.596636501833324, "text": "\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:\n\n\n\n* Users who recognize 1 to 999,999 minutes of audio in a given month pay $0.02 (USD) per minute of audio for that month.\n* Users who recognize at least 1,000,000 minutes of audio in a given month pay $0.01 (USD) per minute of audio for that month.\n\n\n\nThe Plus plan is intended for small businesses. It is also a good choice for large enterprises that want to develop and test larger applications before considering moving to a Premium plan. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text).\n\n\n\n\n\n Can I continue to use the Speech to Text Standard plan? \n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https://cloud.ibm.com/catalog/speech-to-text). They will continue to have access to all of their settings and custom models after upgrading. And, if they find that the Plus plan does not meet their needs for any reason, they can always downgrade back to their Standard plan.\n\n\n\n\n\n What pricing plan do I need to use the service's customization interface? \n\nYou must have a paid plan (Plus, Standard, or Premium) to use language model or acoustic model customization. Users of the Lite plan cannot use customization. To use customization, users of the Lite plan must upgrade to a paid plan such as the Plus plan.\n\n\n\n\n\n How do I upgrade from the Lite plan to the Plus plan?", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-faq-pricing"}, {"document_id": "ibmcld_07578-45764-47767", "score": 23.40339057089192, "text": "\nYou must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.\n* What is the price for using the Speech to Text Plus plan?\n\nThe Plus plan provides access to all of the service's features:\n\n\n\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:\n\n\n\n* Users who recognize 1 to 999,999 minutes of audio in a given month pay $0.02 (USD) per minute of audio for that month.\n* Users who recognize at least 1,000,000 minutes of audio in a given month pay $0.01 (USD) per minute of audio for that month.\n\n\n\nThe Plus plan is intended for small businesses. It is also a good choice for large enterprises that want to develop and test larger applications before considering moving to a Premium plan. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text).\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text).", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-45749-47752", "score": 23.40339057089192, "text": "\nYou must use a paid plan to use customization.\n\nThe Lite plan is intended for any user who wants to try out the service before committing to a purchase. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text). Services that are created with the Lite plan are deleted after 30 days of inactivity.\n* What is the price for using the Speech to Text Plus plan?\n\nThe Plus plan provides access to all of the service's features:\n\n\n\n* Use of all available models (same as the Lite plan).\n* Unlimited creation and use of custom language and custom acoustic models at no extra charge.\n* A maximum of one hundred concurrent transcription requests from all interfaces, WebSocket and HTTP, combined.\n\n\n\nThe plan uses a simple tiered pricing model to give high-volume users further discounts as they use the service more heavily. Pricing is based on the aggregate number of minutes of audio that you recognize per month:\n\n\n\n* Users who recognize 1 to 999,999 minutes of audio in a given month pay $0.02 (USD) per minute of audio for that month.\n* Users who recognize at least 1,000,000 minutes of audio in a given month pay $0.01 (USD) per minute of audio for that month.\n\n\n\nThe Plus plan is intended for small businesses. It is also a good choice for large enterprises that want to develop and test larger applications before considering moving to a Premium plan. For more information, see the Speech to Text service in the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text).\n* Can I continue to use the Speech to Text Standard plan?\n\nThe Standard plan is no longer available for purchase by new users. But existing users of the Standard plan can continue to use the plan indefinitely with no change in their pricing. Their API settings and custom models remain unaffected.\n\nExisting users can also choose to upgrade to the new Plus plan by visiting the [IBM Cloud\u00ae Catalog](https://%7BDomainName%7D/catalog/speech-to-text).", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_16729-112397-114109", "score": 21.852094964463877, "text": "\n[Migrating an Enterprise plan to a Lite or Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-an-enterprise-plan-to-a-lite-or-standard-plan)Migrating an Enterprise plan to a Lite or Standard plan\n\nMigration from the Enterprise plans to IBM Cloudant Lite or Standard plans includes these tasks, which are described in the following steps.\n\nCloudant\n\n\n\n* 30 minutes\n* 2023-04-06\n\n\n\n[Migrating from a Lite plan to a Standard plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-migrating-from-a-lite-plan-to-a-standard-plan)Migrating from a Lite plan to a Standard plan\n\nMigrating from the free Lite plan to the Standard plan by completing the following tasks.\n\nCloudant\n\n\n\n* 15 minutes\n* 2023-04-06\n\n\n\n[Finding your IBM Cloudant plan](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-find-your-ibm-cloudant-plan)Finding your IBM Cloudant plan\n\nYou can subscribe to different IBM Cloudant plans, including the Lite, Standard, or Enterprise plans.\n\nCloudant\n\n\n\n* 20 minutes\n* 2023-03-30\n\n\n\n[Combining IBM Cloudant with other IBM services](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-combine-ibm-services)Combining IBM Cloudant with other IBM services\n\nEach database technology has its own strengths and weaknesses. Some are built for high availability and data durability (at the expense of more hardware and extra cost). Others favor speed and can churn out blazingly fast queries (but might lose data in a sudden power failure).\n\nCloudant\n\n\n\n* 2023-03-30\n\n\n\n[Enhance cloud security by applying context-based restrictions](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_00479-7-2264", "score": 21.641412227153584, "text": "\nLearning about IBM Cloudant architecture and workload isolation \n\nReview the following sample architecture for IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae, and learn more about different isolation levels. After that, you can choose the solution that best meets the requirements of the workloads that you want to run in the cloud.\n\n\n\n IBM Cloudant isolation models and architecture \n\nIBM Cloudant is a multi-tenant-capable database system with mechanisms in place to distribute any shared resources like CPU or I/O fairly among the active tenants. IBM Cloudant implements isolation in the database layer itself, and not by relying on containers. Instances are isolated from each other for access control, meaning that it is not possible to read or write data in one instance from another.\n\nWorkload isolation is an important consideration for many customers. To select the best IBM Cloudant plan choice for your workload isolation requirements, see the following architectural information:\n\n\n\n1. Standard and Lite plans on Multi-Tenant Hardware, which offer excellent isolation.\n2. Standard plan provisioned on a Dedicated Hardware plan instance, which offers improved isolation over Standard on Multi-Tenant Hardware.\n\n\n\n\n\n Standard and Lite \n\nStandard and Lite plans are provisioned onto large, shared IBM Cloudant database deployments where customers share compute and storage resource. Standard and Lite plans apply provisioned throughput rate-limiting, along with other resource and access isolation mechanisms within the database layer itself. Together, these provide strong security guarantees alongside robust resource separation within the shared environment.\n\nZoom\n\n![Diagram about how to isolate data with the IBM Cloudant Standard plan for two customers.](https://cloud.ibm.com/docs-content/v1/content/522c6f62358b063f921283400a601c3f9bc66f08/Cloudant/images/Isolation-Standard.svg)\n\nFigure 1. Data isolation on IBM Cloudant Standard plan\n\nDisk encryption is used to provide encryption at rest by using an IBM owned and managed encryption key. Customer data resides in different files on disk.\n\n\n\n\n\n Standard on Dedicated Hardware \n\nA Dedicated Hardware instance offers improved storage and compute isolation for your most valuable data, including use of BYOK.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-compute-isolation"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_14913-0-1238", "score": 17.71701646861897, "text": "\n\n\n\n\n\n\n  About virtual network functions over VPC \n\nNetwork Function Virtualization (NFV) is the network infrastructure behind virtualizing network services (such as routers, firewalls, and load balancers) that were traditionally run on proprietary hardware. These services, called Virtual Network Functions (VNFs), are packaged as virtual machines (VMs) on commodity hardware, which allows service providers to run their networks on standard servers instead of proprietary ones. This third-party software interacts with the IBM Software-Defined Networking (SDN) controller to offer easy configuration, centralized management, and lower operational costs.\n\nWorking along with IBM Cloud\u00ae Schematics (Infrastructure as Code) and the IBM Content catalog, customers are able to instantiate best-in-network solutions to manage their workload.\n\nBenefits include:\n\n\n\n*  Instantiating virtual network services and modifying configurations without the need to deploy new network hardware.\n*  Rapid service delivery with the agility to scale well above physical hardware.\n*  Centralized policy control.\n*  Using the same routers, firewalls, load balancers, and VPNs in IBM Cloud that were used in physical hardware or other cloud providers.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-about-vnf"}, {"document_id": "ibmcld_16030-7-2126", "score": 17.354973425989584, "text": "\nVPC behind the curtain \n\nThe following information presents a detailed conceptual picture of what's happening \"behind the curtain\" in VPC networking. Learn about network isolation, address prefixes, Cloud Service Endpoint source addresses, data packet flows, external IP address lifecycle, and Classic infrastructure access. Readers are expected to have some networking background.\n\n\n\n Network isolation \n\nVPC network isolation takes place at three levels:\n\n\n\n* Hypervisor - The virtual server instances are isolated by the hypervisor. A virtual server instance can't directly reach other virtual server instances that are hosted by the same hypervisor if they are not in the same VPC.\n* Network - Isolation occurs at the network level by using virtual network identifiers (VNIs). These identifiers are assigned to each subnet and scoped to a single zone. A VNI is added to all data packets that enter any zone of the VPC: entering either from the hypervisor, when sent by a virtual server instance, or entering the zone from the cloud, when sent by the implicit routing function.\n\nA packet that leaves a zone has the VNI stripped off. When the packet reaches its destination zone, entering through the implicit routing function, the implicit router always adds the proper VNI for that zone.\n* Router - The implicit router function provides isolation to each VPC by providing a virtual routing function (VRF) and a VPN with MPLS (multi-protocol label switching) in the cloud backbone. Each VPC's VRF has a unique identifier, and this isolation allows each VPC to have access to its own copy of the IPv4 address space. The MPLS VPN allows for federating all edges of the cloud: Classic Infrastructure, Direct Link, and VPC.\n\n\n\n\n\n\n\n Address prefixes \n\nAddress prefixes are the summary information that is used by a VPC's implicit routing function to locate a destination virtual server instance, regardless of the availability zone in which the destination virtual server instance is located. The primary function of address prefixes is to optimize routing over the MPLS VPN, while pathological routing cases are avoided.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-behind-the-curtain"}, {"document_id": "ibmcld_16026-0-358", "score": 16.479052726526444, "text": "\n\n\n\n\n\n\n  VNF limitations \n\nHigh Availability (HA) Virtual Network Function (VNF) deployments have the following known limitations.\n\n\n\n*  The Virtual Network Function (VNF) must share one subnet with the Network Load Balancer (NLB).\n*  Routing public internet \"ingress\" traffic to a VNF is not supported.\n*  Auto-scaling with the VNF is not supported.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vnf-limitations"}, {"document_id": "ibmcld_07953-7-2429", "score": 15.706912046680525, "text": "\nEnsuring isolation between Satellite management functions and workload functions \n\nA key aspect of the IBM Cloud Framework for Financial Services is to separate user workloads from system management functions and isolate security functions from nonsecurity functions. The network infrastructure of the Satellite location can be used to provide physical and logical separation between the Satellite management control plane and your workloads.\n\nNetwork flow rule design should follow the IBM Cloud Framework for Financial Services's [information flow guidelines](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-best-practicesbest-practices-boundary-protection) by using a \"deny by default\" approach.\n\n\n\n Before you begin \n\n\n\n1. Complete the work for [account setup and management](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-satellite-architecture-account-setup).\n2. Complete [Satellite location setup](https://cloud.ibm.com/docs/satellite?topic=satellite-locations).\n\n\n\n\n\n\n\n Identify network areas for control plane hosts and workload hosts \n\n\n\n1. Place control plane hosts into a separate network segment. Control plane hosts support various management and security-related components of the Satellite location. To facilitate effective network flow restrictions within the Satellite location, it is recommended to place control plane hosts into a separate network segment (whether physical or virtual) that can enable clear identification of source or destination of the network flows related to control plane functionality. The control plane hosts can be deployed to different physical locations, but the address space they are assigned to should provide an easy way to identify this group of hosts (for example, CIDR blocks).\n2. Designate a separate network segment for each group of Satellite hosts assigned to Red Hat OpenShift on IBM Cloud workload clusters. Satellite hosts that are assigned to Red Hat OpenShift on IBM Cloud workload clusters (workload hosts) should use their own network segments that would enable network flow control and monitoring between workload hosts, control plane, and other components outside of the Satellite location. It is recommended to designate a separate network segment (virtual subnet, VLAN, or a similar entity) for each group of Satellite hosts assigned to the same workload cluster.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-satellite-architecture-connectivity-management-isolation"}, {"document_id": "ibmcld_16030-4758-6868", "score": 15.683874973851204, "text": "\nInter-subnet, inter-zone data flows - For these flows, the implicit router function removes the VNI and forwards the packet in the VPC's MPLS VPN for transit across the cloud backbone. At the destination zone, the implicit router function tags the data packet with the appropriate VNI. Then, the packet is forwarded to the destination hypervisor, where the VNI is stripped off again so that the data packet can be forwarded to the destination virtual server instance.\n\nExtra-vpc service data flows - Packets that are destined for IaaS or IBM Cloud Service Endpoint (CSE) services use the VPC's implicit router function. They also use a network address translation (NAT) function. The translation function replaces the virtual server instance address with an IPv4 address that identifies the VPC to the IaaS or CSE service that is requested.\n\nExtra-vpc internet data flows - Packets that are destined for the internet are the most complex. In addition to using the VPC's implicit router function, each of these flows also rely on one of the implicit router's two network address translation (NAT) functions.\n\n\n\n* An explicit one-to-many NAT through a public gateway function that serves all subnets that are connected to it.\n* One-to-one NAT assigned to individual virtual server instances.\n\n\n\nAfter NAT translation, the implicit router forwards these internet-destined packets to the internet, by using the cloud backbone.\n\n\n\n\n\n Life cycle of external IP addresses that are associated with public gateway functions \n\nAs both external IP addresses and PGWs are bound to an availability zone. A public gateway function can have only a single external IP. This external IP has the following lifecycle:\n\n\n\n* The external IP is allocated when the public gateway is created.\n* The external IP is released when the public gateway is deleted.\n\n\n\n\n\n\n\n Classic access \n\nThe [classic access](https://cloud.ibm.com/docs/vpc?topic=vpc-setting-up-access-to-classic-infrastructure) feature for VPC is accomplished by reusing the VRF identifier from the IBM Cloud\u00ae classic infrastructure account as the VRF identifier for VPC.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-behind-the-curtain"}, {"document_id": "ibmcld_04709-1717-3966", "score": 15.568898780713283, "text": "\nPricing Hourly and monthly billing, plus suspend billing features Hourly, suspend billing, and sustained usage discount \n Virtual server families Public, dedicated, transient, reserved Public, dedicated \n Profiles All profiles, including the GPU profiles Balanced, compute, memory profiles with higher RAM and vCPU options \n Supported images Full set of pre-stock images, plus custom images Limited set of pre-stock images, plus the ability to import a custom image \n Platform integration IAM and resource group integration for a unified experience \n\n\n\nSuspend billing supports only hourly, SAN instances that are provisioned with a public profile from one of the Balanced, Compute, Memory, or Variable compute families.\n\n\n\n\n\n Network differentiators \n\nSee the following table for the networking differences between classic and VPC.\n\n\n\nTable 2. Network comparison\nThis table has row and column headers. The row headers identify possible features. The column headers identify the differentiators between classic infrastructure and VPC infrastructure. To understand the differences between environments, navigate to the row and find the details for the feature that you're interested in.\n\n Category Classic infrastructure VPC infrastructure \n\n Location construct Data centers and PODs <br>(Might require VLAN spanning to connect two different pods or data centers, and purchasing gateways to control and route traffic) Regional model that abstracts infrastructure so you don't need to worry about pod locations. \n Network functions and services Physical and virtual appliances from multiple vendors Cloud-native network functions (VPNs, LBaaS) <br>(VPC isolation, dedicated resources carved out of public cloud, with more options for VPNs, LBaaS, multiple vNIC instances, and larger subnet sizes) \n IP addresses IPv6 addresses supported IPv4 addresses only \n Gateway routing Use a virtual or physical network appliance (Virtual Router Appliance, Vyatta, Juniper vSRX, Fortinet FSA) Traffic routing is handled by public gateway and floating IP services \n Network address translation (NAT) Use a virtual or physical network appliance (Virtual Router Appliance, Vyatta, Juniper vSRX, Fortinet FSA) Supported by the Bring-your-own-IP (BYOIP) functionality", "title": "", "source": "https://cloud.ibm.com/docs/cloud-infrastructure?topic=cloud-infrastructure-compare-infrastructure"}, {"document_id": "ibmcld_07877-0-2001", "score": 15.529071354278557, "text": "\n\n\n\n\n\n\n  SC-2 - Application Partitioning \n\n\n\n  Control requirements \n\nSC-2 - 0\n:   The information system separates user functionality (including user interface services) from information system management functionality.\n\n\n\n\n\n  Implementation guidance \n\nSee the resources that follow to learn more about how to implement this control.\n\n\n\n*  [Creating and connecting the management and workload VPCs](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-vpc-architecture-connectivity-create-vpcs)\n\n\n\n\n\n\n\n  IBM Cloud for Financial Services profile \n\nThe rules related to this control that follow are part of the IBM Cloud for Financial Services v1.2.0 profile in [IBM Cloud\u00ae Security and Compliance Center](https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-getting-started).\n\n\n\n*  Check whether at least # Virtual Private Cloud (VPC)s have been created\n*  Check whether at least # instances of Transit Gateway have been created\n\n\n\n\n\n\n\n  NIST supplemental guidance \n\nInformation system management functionality includes, for example, functions necessary to administer databases, network components, workstations, or servers, and typically requires privileged user access. The separation of user functionality from information system management functionality is either physical or logical. Organizations implement separation of system management-related functionality from user functionality by using different computers, different central processing units, different instances of operating systems, different network addresses, virtualization techniques, or combinations of these or other methods, as appropriate. This type of separation includes, for example, web administrative interfaces that use separate authentication methods for users of any other information system resources. Separation of system and user functionality may include isolating administrative interfaces on different domains and with additional access controls.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-sc-2"}, {"document_id": "ibmcld_15810-70646-72492", "score": 15.341770159522166, "text": "\nApplication Load Balancer (ALB) for VPC\n: Application load balancers now support HTTP/HTTPS compression, which you use to compress data that is transmitted to your users. For more information, see [Compression (HTTP/HTTPS only)](https://cloud.ibm.com/docs/vpc?topic=vpc-advanced-traffic-managementcompression).\n\nHigh Availability (HA) Virtual Network Function (VNF) support\n: Support for a highly available, highly resilient virtual network functions can be achieved by using the \"routing mode\" feature of the IBM Cloud Network Load Balancer (NLB) for VPC. For more information, see [About virtual network functions over VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vnf) and [About HA VNF deployments](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vnf-ha).\n\nUpdates to Getting started with IBM Cloud VPC button\n: The \"Getting started with IBM Cloud VPC\" button now includes access to tours that are specific to what you are doing on the IBM console. If a tour is not available, the button takes you to the VPC List view.\n\n\n\n\n\n 06 January 2022 \n\nUI update when you create a virtual server\n: When you create a virtual server, the UI is updated to include a link in the Operating system section that opens a panel that contains information about the image lifecycle.\n\n\n\n\n\n\n\n December 2021 \n\n\n\n 16 December 2021 \n\nFile Storage for VPC (LA)\n: IBM Cloud\u00ae File Storage for VPC is now available for customers with special approval to preview this service in the Washington, Dallas, Frankfurt, London, Sydney, and Tokyo regions.\n: For more information about this service, see [About File Storage for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-file-storage-vpc-about).\n\n\n\n\n\n 09 December 2021 \n\nSecurity updates\n: The following stock images were refreshed with the most recent fixes and security updates.\n\n\n\n* Debian version 10\n* CentOS version 7", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-release-notes"}, {"document_id": "ibmcld_07717-6101-8054", "score": 15.096283920032445, "text": "\nin deployed artifacts<br> * Check whether Virtual Private Cloud (VPC) has no rules in the default security group<br> * Check whether App ID Cloud Directory users aren't able to self-sign up to applications<br> * Check whether all network interfaces of a virtual server instance have at least one Virtual Private Cloud (VPC) security group attached<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether Virtual Servers for VPC instance has the minimum # interfaces<br> * Check whether App ID redirect URIs are using HTTPS only<br> * Check whether Cloud Internet Services (CIS) has TLS mode set to End-to-End CA signed<br> * Check whether Application Load Balancer for VPC pool uses the HTTPS protocol for HTTPS listeners<br> * Check whether Application Load Balancer for VPC uses HTTPS (SSL & TLS) instead of HTTP<br> * Check whether Cloud Object Storage public access is disabled in IAM settings (not applicable to ACLs managed using S3 APIs)<br> * Check whether App ID anonymous authentication is disabled<br> * Check whether App ID avoid password reuse policy is enabled<br> * Check whether App ID user profile updates from client apps is disabled<br> * Check whether Virtual Private Cloud (VPC) network access control lists don't allow ingress from 0.0.0.0/0 to RDP port<br> * Check whether App ID redirect URIs are not using localhost or 127.0.0.1<br> * Check whether Virtual Private Cloud (VPC) network access control lists don't allow ingress from 0.0.0.0/0 to SSH port<br> * Check whether Virtual Private Cloud (VPC) network access control lists don't allow egress from 0.0.0.0/0 to any port<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nInformation systems can provide a wide variety of functions and services. Some of the functions and services, provided by default, may not be necessary to support essential organizational operations (e.g., key missions, functions).", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-cm-7"}, {"document_id": "ibmcld_14128-0-2207", "score": 14.639992305929102, "text": "\n\n\n\n\n\n\n  Overview of Parallels Server 4 bare metal server \n\nParallels Server Bare Metal is a virtualization solution that provides hardware virtualization along side the software virtualization of Virtuozzo, providing technology for both virtual machines and containers*.\n\nCommand line interface\n\nAlong with the usual Virtuozzo commands, other commands are available: pctl, pmigrate, pstat, and prl_disk_tool.\n\nMigration\n\nYou can now migrate Virtuozzo Containers to virtual machines, physical servers to Virtuozzo Containers, and physical servers to virtual machines to allow for consolidation of services. This functionality also allows for one to migrate containers or VMs between bare metal servers, convert VMs that were created on different virtualized environments (V2V), and change Windows SIDs when you clone or deploy a Windows VM from a template.\n\nIP address usage and VLANs\n\nYou can assign VMs to an IP from the physical server by using Parallels Tools that are in the VM. Additionally, PSBM allows for virtual switches and VLANs to be created within the VMs to better secure intra-VM network traffic.\n\nExecuting commands\n\nYou can run raw commands from the physical server directly within the Virtuozzo Containers and now within VMs (when parallels tools are installed within the VM), including user password resets.\n\nProcess accounting\n\nYou use Parallels Server Bare Metal to increase and reduce the priority of resources that are allocated (CPU, Disk I/O Priority) to a VM quickly.\n\nBackup\n\nParallels Server Bare Metal provides the functionality to back up and restore VMs and containers on either the local bare metal server or a remote bare metal server to include full, and incremental backups.\n\nNetwork accounting\n\nYou use Parallels Server Bare Metal to easily view and locate VMs or Containers based on current and historical network throughput.\n\nNetwork\n\nParallels Server Bare Metal uses Portable IP addresses, while Virtuozzo uses either Portable or Static IP addresses (depending on the configuration).\n\n* IBM Cloud\u00ae licenses only hardware virtual machines on Parallels Server 4 Bare Metal, unless otherwise indicated on the order form. VM = virtual machine. V = VPS or Container.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/virtualization?topic=virtualization-overview-of-parallels-server-4-bare-metal"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06381-1376-2975", "score": 42.76390883353503, "text": "\nDeleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https://dev.mysql.com/doc/refman/5.7/en/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https://dev.mysql.com/doc/refman/5.7/en/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"}, {"document_id": "ibmcld_06341-2428-3641", "score": 42.49891908439999, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-elasticsearch?topic=databases-for-elasticsearch-deprovisioning"}, {"document_id": "ibmcld_06499-2416-3629", "score": 42.49891908439999, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-mongodb?topic=databases-for-mongodb-deprovisioning"}, {"document_id": "ibmcld_06443-2410-3623", "score": 42.49891908439999, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-etcd?topic=databases-for-etcd-deprovisioning"}, {"document_id": "ibmcld_06627-2422-3635", "score": 42.49891908439999, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-deprovisioning"}, {"document_id": "ibmcld_06696-2412-3625", "score": 42.49891908439999, "text": "\nLaunch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-redis?topic=databases-for-redis-deprovisioning"}, {"document_id": "ibmcld_09551-1435-3087", "score": 42.488087034391384, "text": "\nList of service instances on the Resource List\n\n\n\n\n\n Deleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https://dev.mysql.com/doc/refman/5.7/en/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https://dev.mysql.com/doc/refman/5.7/en/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"}, {"document_id": "ibmcld_06564-1431-3083", "score": 42.488087034391384, "text": "\nList of service instances on the Resource List\n\n\n\n\n\n Deleting your Deployment by using the CLI \n\nBy using the CLI, you can delete your existing IBM Cloud\u00ae Databases instance with the [ibmcloud resource service-instance-delete](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_service_instance_delete) command:\n\nibmcloud resource service-instance-delete my-service-instance\n\nUsing the command ibmcloud resource reclamation-delete deletes a reclaimed resource so that the resource can no longer be restored.\n\n\n\n\n\n Deleting your database by using DROP DATABASE Statement \n\n[DROP DATABASE](https://dev.mysql.com/doc/refman/5.7/en/drop-database.html) drops all tables in the database and deletes the database.\n\nDROP {DATABASE | SCHEMA} [IF EXISTS] db_name\n\n\n\n\n\n Deleting your database by using mysqladmin \n\nYou can also drop databases with [mysqladmin, a MySQL Server Administration Program](https://dev.mysql.com/doc/refman/5.7/en/mysqladmin.html). Launch mysqladmin like this:\n\nmysqladmin [options] command [command-arg] [command command-arg]] ...\n\n\n\n\n\n Cryptoshredding keys \n\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-mysql?topic=databases-for-mysql-deprovisioning"}, {"document_id": "ibmcld_09551-2545-3629", "score": 41.205090855564634, "text": "\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-deprovisioning"}, {"document_id": "ibmcld_06381-2433-3517", "score": 41.205090855564634, "text": "\nKey Protect provides for a [force delete](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) of a key that is in use by IBM Cloud\u00ae services, including your Cloud Databases deployments. This action is called cryptoshredding.\n\nCryptoshredding is a destructive action. When the key is deleted, your data is unrecoverable even from a soft delete state.\n\n\n\n\n\n Backups Removal \n\nBackups cannot be manually deleted. However, if you delete your deployment, its backups are deleted automatically.\n\n\n\n\n\n Reenabling from a soft delete \n\nYou are able to discover available soft-deleted instances by using the IBM Cloud CLI [ibmcloud resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations) command.\n\nYou can then \"undelete\", recover, or reclaim an available soft-deleted instance by using the IBM Cloud CLI [ibmcloud resource reclamation-restore](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamation_restore) command:\n\nibmcloud resource reclamation-restore resource_ID", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-enterprisedb?topic=cloud-databases-deprovisioning"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00589-8040-10059", "score": 29.212329978858474, "text": "\niam_apikey_description\n: Description of IAM API key.\n\niam_apikey_name\n: ID of IAM API key.\n\niam_role_crn\n: The IAM role that the IAM API key has.\n\niam_serviceid_crn\n: The CRN of service ID.\n\npassword\n: The IBM Cloudant legacy credential password.\n\nport\n: IBM Cloudant service port.\n\nurl\n: IBM Cloudant service URL, including embedded IBM Cloudant legacy credentials.\n\nusername\n: The IBM Cloudant legacy credential username.\n\nNote the included username and password are always equivalent to IAM's Manager credentials. Therefore, the use of Use both legacy credentials and IAM is insecure when used with Reader, Writer, Monitor, or Checkpointer IAM roles.\n\n\n\n\n\n\n\n Must I use Use only IAM or Use both legacy credentials and IAM? \n\nIf possible, Use only IAM is preferred. The major advantages for using IBM Cloud IAM are shown in the following list:\n\n\n\n* Management of access to IBM Cloudant with the standard tools of IBM Cloud rather than a combination of IBM Cloud and IBM Cloudant-specific credential management.\n* Credentials can be easily revoked and rotated when you use IBM Cloud IAM.\n\n\n\nFurther description of the advantages and disadvantages of each approach follows.\n\nWhen you use IAM roles other than Manager, such as Reader, Writer, Monitor, or Checkpointer, you must use Use only IAM to avoid supplying users with legacy credentials that include greater access permissions.\n\n\n\n Advantages and disadvantages of the two access control mechanisms \n\nOverall, IBM Cloud IAM is the recommended authentication model. However, the primary disadvantages to the approach are if you have an existing application or are unable to use an IBM Cloudant-supported client library.\n\n\n\n Advantages of IAM mode \n\n\n\n* Manage access for many services by using one interface.\n* Revoke access to a user globally.\n* Account-level API keys that use service IDs.\n* Easy-to-rotate credentials.\n* Activity Tracker logs capture individual humans and services.\n* IAM federates with other identity systems, like enterprise LDAP repositories.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudant"}, {"document_id": "ibmcld_07578-414710-416563", "score": 29.212154520246216, "text": "\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n\n\n\n\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",\n\"host\": \"2922d728-27c0-4c7f-aa80-1e59fbeb04d0-bluemix.cloudant.com\",", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-414684-416537", "score": 29.212154520246216, "text": "\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n\n\n\n\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",\n\"host\": \"2922d728-27c0-4c7f-aa80-1e59fbeb04d0-bluemix.cloudant.com\",", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-419683-421572", "score": 29.061458292866707, "text": "\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-419665-421554", "score": 29.061458292866707, "text": "\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n* Why is the Use only IAM mode preferred?\n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n* How can I create an instance by using the command line?\n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" \ncloudantnosqldb Standard us-south \n-p '{\"legacyCredentials\": false}'\n\nIf you don't use Use only IAM mode when you use the IAM Reader and Writer roles, you might grant users legacy credentials with more access permissions than you intended.\n* How can I generate service credentials?\n\nYou can generate service credentials in the primary IBM Cloud IAM interface. When you select Use only IAM, service credentials include only IAM values. The service credential JSON looks like the following example:\n\n{\n\"apikey\": \"MxVp86XHkU82Wc97tdvDF8qM8B0Xdit2RqR1mGfVXPWz\",", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_00531-7-2145", "score": 27.909642442862165, "text": "\nAuthenticating with IBM Cloudant FAQ \n\nIBM Cloud\u00ae Identity and Access Management (IAM) combines managing user identities, services, and access control into one approach. IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae integrates with IBM Cloud Identity and Access Management.\n\n\n\n What is the difference between IBM Cloudant legacy and IAM access controls? \n\n\n\n IBM Cloud IAM \n\n\n\n* Centrally managed access management across IBM Cloud.\n* Allows a user or service to access many different resources by using the same set of credentials (for example, same username and password or IAM API key).\n* IAM API keys can be granted access to account management functions, like creating new databases.\n\n\n\n\n\n\n\n IBM Cloudant legacy \n\n\n\n* Unique to IBM Cloudant.\n* Access to each service instance requires its own set of credentials.\n* Uses HTTP basic authentication with credentials that aren't bound to an individual user or service.\n\n\n\n\n\n\n\n\n\n Why is the Use only IAM mode preferred? \n\nThe Use only IAM mode means that only IAM credentials are provided through service binding and credential generation. You gain the following advantages when you use IBM Cloud IAM:\n\n\n\n* Managing access to IBM Cloudant with the standard tooling of IBM Cloud.\n* Using credentials that you can easily revoke and rotate when you use IBM Cloud IAM.\n\n\n\nFor more information about the advantages and disadvantages between these modes, see [Advantages and disadvantages of the two access control mechanisms](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudantadvantages-and-disadvantages-of-the-two-access-control-mechanisms-ai).\n\n\n\n\n\n How can I create an instance by using the command line? \n\nWhen you create a new IBM Cloudant instance from the command line, you must include the ibmcloud tool by using the -p parameter. This parameter enables or disables legacy credentials for an account by passing the option in JSON format. The option is called legacyCredentials.\n\nTo create an instance as Use only IAM, run the following command:\n\nibmcloud resource service-instance-create \"Instance Name\" cloudantnosqldb Standard us-south -p '{\"legacyCredentials\": false}'", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-authenticating-cloudant"}, {"document_id": "ibmcld_00579-7-1988", "score": 27.385260757296372, "text": "\nIndexing and querying \n\nThe Index and querying document is the second best practice document in the series. It shows you the following best practices:\n\n\n\n* How to understand the different results between emitting data into a view or not.\n* Why you must never rely on IBM Cloudant Query's ability to query without creating explicit indexes.\n* Why you must limit the number of fields with IBM Cloudant Search (or IBM Cloudant Query indexes of type text).\n* How to manage design documents.\n* Why partitioned queries are faster and cheaper.\n* How to use the primary index as a free search index.\n\n\n\nFor more information, see [Data modeling](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-data-modeling) or [IBM Cloudant in practice](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-cloudant-in-practice).\n\nThe content in this document was originally written by Stefan Kruger as a [Best and worst practice](https://blog.cloudant.com/2019/11/21/Best-and-Worst-Practices.html) blog post on 21 November 2019.\n\n\n\n Understand the tradeoffs in emitting data or not into a view \n\nAs the document that is referenced by a view is always available by using include_docs=true, it is possible to do something like the following example to allow lookups on indexed_field:\n\nemit(doc.indexed_field, null);\n\nThis example has the following advantages and disadvantages:\n\n\n\n* The index is compact. This index size is good, since index size contributes to storage costs.\n* The index is robust. Since the index does not store the document, you can access any field without thinking ahead about what to store in the index.\n* The disadvantage is that getting the document back is more costly than the alternative of emitting data into the index itself. First, the database has to look up the requested key in the index and then read the associated document. Also, if you\u2019re reading the whole document, but need only a single field, you\u2019re making the database read and transmit data that you don\u2019t need.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-indexing-and-querying"}, {"document_id": "ibmcld_00589-9560-11733", "score": 26.70362610656195, "text": "\nHowever, the primary disadvantages to the approach are if you have an existing application or are unable to use an IBM Cloudant-supported client library.\n\n\n\n Advantages of IAM mode \n\n\n\n* Manage access for many services by using one interface.\n* Revoke access to a user globally.\n* Account-level API keys that use service IDs.\n* Easy-to-rotate credentials.\n* Activity Tracker logs capture individual humans and services.\n* IAM federates with other identity systems, like enterprise LDAP repositories.\n* Fine-grained permissions (for example, Reader, Writer, Monitor, or Checkpointer).\n\n\n\n\n\n\n\n Disadvantages of IAM mode \n\n\n\n* If you are not using the supported libraries from IBM Cloudant, application changes are likely to be required to use IAM's API keys and access tokens.\n* No database-level permissions (yet).\n* Some endpoints are not available. For more information, see [unavailable endpoints](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudantunavailable-endpoints).\n* No way to specify a database as \"public\", that is, not requiring an authorized user to access.\n\n\n\n\n\n\n\n Advantages of legacy mode \n\n\n\n* No need to change existing applications or client library dependencies.\n* Database-level permissions.\n\n\n\n\n\n\n\n Disadvantages of legacy mode \n\n\n\n* Separate management of IBM Cloudant credentials, so unable to get full overview of all access within centralized interface.\n\n\n\n\n\n\n\n\n\n\n\n Create a replication job by using IAM credentials only \n\nFollow these instructions to generate IAM API keys, generate the bearer token, create the _replicator database, and create the replication job.\n\n\n\n Generating IAM API keys for Source and Target and one for IBM Cloudant API access \n\nIn this exercise, the first two API keys are created so that the two instances can talk to each other during the replication process. The third API key is for the user to access the IBM Cloudant API, create the _replicator database, and then add the replication document to it.\n\nFollow these steps to generate IAM API keys and API access for IBM Cloudant. You must write down the credentials that are requested in the following steps to continue with the example.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-managing-access-for-cloudant"}, {"document_id": "ibmcld_03630-7-2200", "score": 21.895260154334856, "text": "\nAbout RAID \n\nRAID (Redundant Array of Independent Disks) creates a single usable data disk, where several physical disks are combined into an array for better speed and fault tolerance. Following are the three key concepts in RAID:\n\n\n\n* Mirroring: copying data to more than one disk\n* Striping: splitting data across more than one disk\n* Error correction (fault tolerance): redundant data is stored to allow problems to be detected and possibly fixed.\n\n\n\nAlthough many different levels of RAID exist, IBM chooses to support the most common RAID types: 0, 1, 5, 6, and 10. The different RAID levels use one or more of the following techniques, depending on the system requirements. The main purpose of using RAID is to improve reliability by using either 3Ware 9550SX Raid SATA or an Adaptec SA-SCSI RAID controller for all RAID solutions deployed.\n\nRAID is not a backup solution. Rather, RAID creates a single usable data disk, where several physical disks are combined into an array for better speed and fault tolerance.\n\nRAID 0 (Striped set without parity / Non-Redundant Array) Implements data striping, where file blocks are written across multiple disks in fragments that require a minimum of two disks. The advantage of a RAID 0 is that the read/write speed is dramatically increased. The more disks that are in the array, the greater the bandwidth. The disadvantage to a RAID 0 is that it has no fault tolerance. If a single drive fails, the array is broken. Also, RAID 0 does not implement error checking. So, any error is also unrecoverable. A common solution for fault tolerance is to have a drive outside of the array that is used as backup storage in a hardware failure.\n\nRAID 1 (Mirrored set without parity) Implements data mirroring. Data is duplicated on 2 or 4 disks through a hardware raid controller and provides some fault tolerance. The array is recoverable if at least one drive does not fail. It provides faster read performance than a single drive and provides drive redundancy if a drive failure occurs. Write speed is slightly reduced.\n\nRAID 5 (Striped set with dual distributed parity) Implements data striping at a block level and distributes parity among the disks.", "title": "", "source": "https://cloud.ibm.com/docs/bare-metal?topic=bare-metal-bm-raid-levels"}, {"document_id": "ibmcld_05138-7979-9034", "score": 21.25385124092189, "text": "\nAfter your bucket is created with Activity Tracker and Monitoring, it may take a few minutes for the rules to take effect.\n\nYou are now ready to store data in a secure content store with encryption, monitoring, and audit observability!\n\n\n\n\n\n Get started by uploading data \n\n\n\n* See [uploading data](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-upload) for more information.\n\n\n\n\n\n\n\n Add capabilities \n\nAdd capabilities to protect objects from ransomware and accidental deletion such as [versioning](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-versioning) and [immutable retention polices](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-ol-overview) for supporting immutable storage, and immutable backup and archive data.\n\n\n\n\n\n Library of Object Storage tutorials \n\nCheck out the IBM Cloud Tutorials library for more tutorials when deploying solutions with [Cloud Object Storage](https://cloud.ibm.com/docs?tab=tutorials&page=1&pageSize=20&tags=cloud-object-storage).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-secure-content-store"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-122722-124676", "score": 13.595327336941576, "text": "\nAfter you understand how many CAs, peers, and ordering nodes are required, you can examine the default resource allocations table for your [nodes](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-allocate-resources) to get an approximate estimate of the CPUs (VPCs) required for your network. If you are purchasing IBM Blockchain Platform on IBM Cloud, you can estimate your cost through this method, but you also have the ability to scale dynamically if more sources are needed.\n* How does pricing work on the IBM Blockchain Platform for IBM Cloud?\n\nIBM Blockchain Platform for IBM Cloud is priced based on the VPCs that you allocate to your blockchain nodes on the IBM Kubernetes Service. For more information, see [Pricing for IBM Blockchain Platform for IBM Cloud](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing).\n* What are the limitations of the free IBM Blockchain Platform using the IBM Cloud Kubernetes Service free cluster?\n\n\n\n* Preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.\n* Only one blockchain console can be connected to a free cluster at a time.\n* You cannot migrate any nodes or data from a free cluster to a paid cluster.\n\n\n\nThe following capabilities are only available on a paid cluster:\n\n\n\n* Customizing resource allocation for a node during or after deployment.\n* Using a Hardware Security Module (HSM) to secure the private key for a node.\n* Configuring a Certificate Authority (CA) for high availability by using a PostgreSQL database and replica sets.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_07578-149603-151557", "score": 13.595327336941576, "text": "\nAfter you understand how many CAs, peers, and ordering nodes are required, you can examine the default resource allocations table for your [nodes](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-allocate-resources) to get an approximate estimate of the CPUs (VPCs) required for your network. If you are purchasing IBM Blockchain Platform on IBM Cloud, you can estimate your cost through this method, but you also have the ability to scale dynamically if more sources are needed.\n* How does pricing work on the IBM Blockchain Platform for IBM Cloud?\n\nIBM Blockchain Platform for IBM Cloud is priced based on the VPCs that you allocate to your blockchain nodes on the IBM Kubernetes Service. For more information, see [Pricing for IBM Blockchain Platform for IBM Cloud](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing).\n* What are the limitations of the free IBM Blockchain Platform using the IBM Cloud Kubernetes Service free cluster?\n\n\n\n* Preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.\n* Only one blockchain console can be connected to a free cluster at a time.\n* You cannot migrate any nodes or data from a free cluster to a paid cluster.\n\n\n\nThe following capabilities are only available on a paid cluster:\n\n\n\n* Customizing resource allocation for a node during or after deployment.\n* Using a Hardware Security Module (HSM) to secure the private key for a node.\n* Configuring a Certificate Authority (CA) for high availability by using a PostgreSQL database and replica sets.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-149577-151531", "score": 13.595327336941576, "text": "\nAfter you understand how many CAs, peers, and ordering nodes are required, you can examine the default resource allocations table for your [nodes](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-allocate-resources) to get an approximate estimate of the CPUs (VPCs) required for your network. If you are purchasing IBM Blockchain Platform on IBM Cloud, you can estimate your cost through this method, but you also have the ability to scale dynamically if more sources are needed.\n* How does pricing work on the IBM Blockchain Platform for IBM Cloud?\n\nIBM Blockchain Platform for IBM Cloud is priced based on the VPCs that you allocate to your blockchain nodes on the IBM Kubernetes Service. For more information, see [Pricing for IBM Blockchain Platform for IBM Cloud](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing).\n* What are the limitations of the free IBM Blockchain Platform using the IBM Cloud Kubernetes Service free cluster?\n\n\n\n* Preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.\n* Only one blockchain console can be connected to a free cluster at a time.\n* You cannot migrate any nodes or data from a free cluster to a paid cluster.\n\n\n\nThe following capabilities are only available on a paid cluster:\n\n\n\n* Customizing resource allocation for a node during or after deployment.\n* Using a Hardware Security Module (HSM) to secure the private key for a node.\n* Configuring a Certificate Authority (CA) for high availability by using a PostgreSQL database and replica sets.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_16727-122701-124655", "score": 13.595327336941576, "text": "\nAfter you understand how many CAs, peers, and ordering nodes are required, you can examine the default resource allocations table for your [nodes](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-adv-deploymentibp-console-adv-deployment-allocate-resources) to get an approximate estimate of the CPUs (VPCs) required for your network. If you are purchasing IBM Blockchain Platform on IBM Cloud, you can estimate your cost through this method, but you also have the ability to scale dynamically if more sources are needed.\n* How does pricing work on the IBM Blockchain Platform for IBM Cloud?\n\nIBM Blockchain Platform for IBM Cloud is priced based on the VPCs that you allocate to your blockchain nodes on the IBM Kubernetes Service. For more information, see [Pricing for IBM Blockchain Platform for IBM Cloud](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing).\n* What are the limitations of the free IBM Blockchain Platform using the IBM Cloud Kubernetes Service free cluster?\n\n\n\n* Preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.\n* Only one blockchain console can be connected to a free cluster at a time.\n* You cannot migrate any nodes or data from a free cluster to a paid cluster.\n\n\n\nThe following capabilities are only available on a paid cluster:\n\n\n\n* Customizing resource allocation for a node during or after deployment.\n* Using a Hardware Security Module (HSM) to secure the private key for a node.\n* Configuring a Certificate Authority (CA) for high availability by using a PostgreSQL database and replica sets.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_05707-4888-6797", "score": 13.532081779267838, "text": "\nIBM Cloud Kubernetes Service on IBM Cloud Public delivers powerful tools by combining Docker containers, the Kubernetes technology, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts For more information, see [IBM Cloud Kubernetes Service technology](https://cloud.ibm.com/docs/containers?topic=containers-service-arch).\n: You can also create your cluster in a Virtual Private Cloud (VPC), which gives you the security of a private cloud environment with isolated networking features along with the dynamic scalability of the public cloud. For more information, see [Overview of Classic and VPC infrastructure providers](https://cloud.ibm.com/docs/containers?topic=containers-infrastructure_providers).\n\nIBM Cloud Private, on-premises\n: IBM Cloud Private is an application platform that can be installed locally on your own machines. You might choose to use Kubernetes in IBM Cloud Private when you need to develop and manage on-premises, containerized apps in your own controlled environment behind a firewall. For more information, see the [IBM Cloud Private product documentation](https://www.ibm.com/docs/en/cloud-private/3.2.x).\n\n\n\n\n\n Comparison of free and standard clusters \n\nReview the following table for a comparison of free and standard clusters.\n\nThe free cluster option is deprecated and will be unsupported on 25 July 2023. Existing free tier clusters will be allowed to finish their 30-day trial window. If you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https://www.ibm.com/account/reg/us-en/signup?formid=MAIL-wcp).\n\nFree clusters are automatically deleted after 30 days.\n\nIf you have a free cluster and want to upgrade to a standard cluster, you can [create a standard cluster](https://cloud.ibm.com/docs/containers?topic=containers-clusters).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_ov"}, {"document_id": "ibmcld_04082-13243-15143", "score": 13.457096855130958, "text": "\nHow does pricing work on the IBM Blockchain Platform for IBM Cloud? \n\nIBM Blockchain Platform for IBM Cloud is priced based on the VPCs that you allocate to your blockchain nodes on the IBM Kubernetes Service. For more information, see [Pricing for IBM Blockchain Platform for IBM Cloud](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing).\n\n\n\n\n\n What are the limitations of the free IBM Blockchain Platform using the IBM Cloud Kubernetes Service free cluster? \n\n\n\n* Preview the IBM Blockchain Platform at no charge for 30 days when you link your IBM Blockchain Platform service instance to an IBM Cloud Kubernetes free cluster.\n* Performance will be limited by throughput, storage, and functionality. Read more about the [limitations of free clusters](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovcluster_types).\n* IBM Cloud will delete your Kubernetes cluster after 30 days.\n* Only one blockchain console can be connected to a free cluster at a time.\n* You cannot migrate any nodes or data from a free cluster to a paid cluster.\n\n\n\nThe following capabilities are only available on a paid cluster:\n\n\n\n* Customizing resource allocation for a node during or after deployment.\n* Using a Hardware Security Module (HSM) to secure the private key for a node.\n* Configuring a Certificate Authority (CA) for high availability by using a PostgreSQL database and replica sets.\n* Selecting a specific Kubernetes zone when deploying a node.\n* Overriding node configuration during or after deployment by using the console or APIs.\n* Adding or removing ordering nodes to an ordering service. The free offering only supports a single node Raft ordering service.\n\n\n\nSee [Find out how to preview the platform free for 30 days](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-saas-pricingibp-saas-pricing-free) for more information on how to get started.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-v2-faq"}, {"document_id": "ibmcld_04489-25567-27336", "score": 13.179975121266983, "text": "\nibmcloud ks cluster config --cluster my_cluster\n\n\n\n\n\n\n\n ibmcloud ks cluster create classic \n\nClassic infrastructure\n\nCreate a cluster with worker nodes on classic infrastructure. For free clusters, you specify the cluster name; everything else is set to a default value. A free cluster is automatically deleted after 30 days. You can have one free cluster at a time. To take advantage of the full capabilities of Kubernetes, create a standard cluster.\n\nibmcloud ks cluster create classic [--hardware HARDWARE] --zone ZONE --flavor FLAVOR --name NAME [--operating-system UBUNTU_20_64|UBUNTU_18_64] [--version MAJOR.MINOR.PATCH] [--no-subnet] [--sm-group GROUP] [--sm-instance INSTANCE] [--private-vlan PRIVATE_VLAN] [--public-vlan PUBLIC_VLAN] [--private-only] [--gateway-enabled] [--private-service-endpoint] [--public-service-endpoint] [--workers WORKER] [--disable-disk-encrypt] [--pod-subnet SUBNET] [--service-subnet SUBNET] [--skip-advance-permissions-check] [-q]\n\nTo create a VPC cluster, use the [ibmcloud ks cluster create vpc-gen2 command](https://cloud.ibm.com/docs/cli?topic=cli-kubernetes-service-clicli_cluster-create-vpc-gen2) instead.\n\nMinimum required permissions\n: Administrator platform access role for IBM Cloud Kubernetes Service at the account level\n: Administrator platform access role for IBM Cloud Container Registry at the account level\n: Super User role for IBM Cloud infrastructure\n\nCommand options:\n\n--hardware HARDWARE\n: The level of hardware isolation for your worker node. Use dedicated so that available physical resources are dedicated to you only, or shared to allow physical resources to be shared with other IBM customers. The default is shared. This value is optional for VM standard clusters and is not available for free clusters.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-kubernetes-service-cli"}, {"document_id": "ibmcld_16729-266570-268549", "score": 13.160697940094405, "text": "\n[Deploying server pools and origins in a single MZR](https://cloud.ibm.com/docs/ha-infrastructure?topic=ha-infrastructure-ha-pools-origins)Deploying server pools and origins in a single MZR\n\nUse this tutorial to deploy availability pools in a VPC for a single MZR. Creating server pools with origins provides your DevOps team with a staging environment so they can validate near-production ready code in parallel with an existing production environment.\n\nVirtual Servers for Classic Virtual Private Cloud (VPC)\n\n+3\n\nIBM Cloud Load Balancer,Cloud Internet Services (CIS),High availability and resiliency for infrastructure\n\n\n\n* 2021-06-10\n\n\n\n[Deploying critical applications with IBM Cloud MZR](https://cloud.ibm.com/docs/ha-infrastructure?topic=ha-infrastructure-multi-zone-resiliency)Deploying critical applications with IBM Cloud MZR\n\nThis tutorial walks you through setting up a resilient environment for an n-tier application in an IBM Cloud\u00ae MZR. In this tutorial, you create your own VPC in region 1, then create subnets in two different zones of region 1, then you provision the virtual server instances. You create two availability zones and virtual server instances in each availability zone for UI, application, and db.\n\nVirtual Servers for Classic Virtual Private Cloud (VPC)\n\n+2\n\nIBM Cloud Load Balancer,High availability and resiliency for infrastructure\n\n\n\n* 45 minutes\n* 2021-09-03\n\n\n\n[Try out IBM Cloud, for free](https://cloud.ibm.com/docs/overview?topic=overview-tutorial-try-for-free)Try out IBM Cloud, for free\n\nLooking to try out IBM Cloud\u00ae? Create an account and start building proof of concepts (POCs) with the many components available in IBM Cloud. You can try Lite and Free service plans to explore IBM Cloud at no cost while learning how to work in the cloud, use Watson, and more. This quick start guide is intended to help you get up and running on IBM Cloud without having to think about costs until you're ready.\n\nIBM Cloud overview\n\n\n\n* 10 minutes", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_10444-1564-3232", "score": 13.100718068929254, "text": "\n[Hardware options for worker nodes in a standard cluster](https://cloud.ibm.com/docs-content/v1/content/bce0f0917a9eea684d1b4b704ac6343a1f65f446/openshift/images/cs_clusters_hardware.png)\n\nFigure 1. Hardware options for worker nodes in a standard cluster\n\n\n\n What flavors are available to me? \n\nClassic standard clusters can be created on [virtual](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesvm) and [bare metal](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesbm) worker nodes. If you require additional local disks, you can also choose one of the bare metal flavors that are designed for [software-defined storage](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodessds) solutions, such as Portworx. Depending on the level of hardware isolation that you need, virtual worker nodes can be set up as shared or dedicated nodes, whereas bare metal machines are always set up as dedicated nodes. If you create a free classic cluster, your cluster is provisioned with the smallest virtual worker node flavor on shared infrastructure.\n\nVPC clusters can be provisioned as standard clusters on shared [virtual](https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodesvm) worker nodes only, and must be created in one of the supported [multizone locations](https://cloud.ibm.com/docs/openshift?topic=openshift-regions-and-zoneszones-vpc). Free VPC clusters are not supported.\n\nVPC clusters can be provisioned using virtual worker nodes on standard infrastructure or dedicated hosts. Free VPC clusters are not supported.\n\n\n\n\n\n Can I combine different flavors in a cluster? \n\nYes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-planning_worker_nodes"}, {"document_id": "ibmcld_05707-6437-8139", "score": 12.97215211874688, "text": "\nIf you want to try IBM Cloud Kubernetes Service, [contact IBM Sales](https://www.ibm.com/account/reg/us-en/signup?formid=MAIL-wcp).\n\nFree clusters are automatically deleted after 30 days.\n\nIf you have a free cluster and want to upgrade to a standard cluster, you can [create a standard cluster](https://cloud.ibm.com/docs/containers?topic=containers-clusters). Then, [copy your deployment configuration files](https://cloud.ibm.com/docs/containers?topic=containers-update_appcopy_apps_cluster) from your free cluster into the standard cluster.\n\n\n\nCharacteristics of free and standard clusters\n\n Characteristics Free clusters Standard clusters \n\n [In-cluster networking](https://cloud.ibm.com/docs/containers?topic=containers-securitynetwork) Yes Yes \n [Public network app access by a NodePort service to a non-stable IP address](https://cloud.ibm.com/docs/containers?topic=containers-nodeport) Yes Yes \n [User access management](https://cloud.ibm.com/docs/containers?topic=containers-access-overviewaccess_policies) Yes Yes \n [IBM Cloud service access from the cluster and apps](https://cloud.ibm.com/docs/containers?topic=containers-service-bindingbind-services) Yes Yes \n [Disk space on worker node for non-persistent storage](https://cloud.ibm.com/docs/containers?topic=containers-storage-plan) Yes Yes \n [Provision Red Hat OpenShift clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-getting-started) Yes \n [Create clusters in a Virtual Private Cloud (VPC)](https://cloud.ibm.com/docs/containers?topic=containers-vpc_ks_tutorial) Yes \n [Ability to create cluster in every IBM Cloud Kubernetes Service region](https://cloud.ibm.com/docs/containers?topic=containers-regions-and-zones) Yes", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_ov"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05666-7-2151", "score": 30.692621831649454, "text": "\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like IBM Cloud\u00ae Kubernetes Service, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith IBM Cloud Kubernetes Service clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-costs"}, {"document_id": "ibmcld_10116-7-2157", "score": 30.604859304193056, "text": "\nUnderstanding costs for your clusters \n\nWith IBM Cloud\u00ae, you can plan for, estimate, review, and modify your cluster environment to control costs. Just by using a managed service like Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae, you are saving many expenses that are associated with managing, updating, and maintaining an infrastructure environment.\n\n\n\n Understanding costs by component \n\nWith Red Hat OpenShift on IBM Cloud clusters, you can use IBM Cloud infrastructure compute, networking, and storage resources with platform services such as Watson AI or Compose Database-as-a-Service. Each resource might entail its own charges that can be [fixed, metered, tiered, or reserved](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-chargescharges) and billed by various incremental rates such as monthly or hourly.\n\nMonthly resources are billed based on the first of the month for usage in the preceding month. If you order a monthly resource in the middle of the month, you are charged a prorated amount for that month. However, if you cancel a resource in the middle of the month, you are still charged the full amount for the monthly resource.\n\n\n\n Worker nodes \n\nClusters can have two main types of worker nodes: virtual or physical (bare metal) machines. Flavor (machine type) availability and pricing varies by the zone that you deploy your cluster to.\n\nWhen do worker nodes begin to incur charges?**\n: Worker nodes begin to incur charges after they complete the provisioning state and continue until you delete the worker nodes and they complete the deleting state. For more information, see [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-health-monitorstates).\n\n\n\n\n\n What is the difference between virtual and physical machines? \n\nVirtual machines feature greater flexibility, quicker provisioning times, and more automatic scalability features than bare metal, at a more cost-effective price than bare-metal. However, VMs have a performance tradeoff when compared to bare metal specs, such as networking Gbps, RAM and memory thresholds, and storage options. Keep in mind these factors that impact your VM costs.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-costs"}, {"document_id": "ibmcld_03798-0-2240", "score": 30.458986214004998, "text": "\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https://cloud.ibm.com/billing/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http://ibm.com/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https://cloud.ibm.com/billing/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https://cloud.ibm.com/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-understand-invoices"}, {"document_id": "ibmcld_14007-0-1917", "score": 29.601475645533036, "text": "\n\n\n\n\n\n\n  FAQs: Reserved capacity and instances \n\n\n\n  Which virtual server instance types can be reserved? \n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n\n\n\n\n\n  Can I combine different CPUxRAM sizes or change the sizes later? \n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n\n\n\n\n\n  Is my payment upfront or monthly? \n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n\n\n\n\n\n  What happens at the end of my contract? \n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https://www.ibm.com/cloud/virtual-servers).\n\n\n\n\n\n  What happens if I don't need my reserved virtual server instances anymore? \n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n\n\n\n\n\n  Does the reservation include everything that I configured into my virtual server instance? \n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n\n\n\n\n\n  Why do I need to choose hourly or monthly billing on the virtual server instance? \n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/virtual-servers?topic=virtual-servers-faqs-reserved-capacity-and-instances"}, {"document_id": "ibmcld_07578-335595-337885", "score": 29.02650198411018, "text": "\nEach device has a unique SSH key, so the key for the newly provisioned or reloaded device is different from the image. However, SSH keys that are associated with either a Flex Image or a standard image templates are associated with the device when it is provisioned or reloaded. You can also add keys during the setup process.\n* Which virtual server instance types can be reserved?\n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n* Can I combine different CPUxRAM sizes or change the sizes later?\n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n* Is my payment upfront or monthly?\n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n* What happens at the end of my contract?\n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https://www.ibm.com/cloud/virtual-servers).\n* What happens if I don't need my reserved virtual server instances anymore?\n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n* Does the reservation include everything that I configured into my virtual server instance?\n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n* Why do I need to choose hourly or monthly billing on the virtual server instance?\n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n* What types of virtual servers are available for use?\n\nIBM Cloud\u00ae offers a couple types of virtual servers within its Classic Infrastructure.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-335569-337859", "score": 29.02650198411018, "text": "\nEach device has a unique SSH key, so the key for the newly provisioned or reloaded device is different from the image. However, SSH keys that are associated with either a Flex Image or a standard image templates are associated with the device when it is provisioned or reloaded. You can also add keys during the setup process.\n* Which virtual server instance types can be reserved?\n\nOnly SAN-backed balanced, memory, and compute family sizes can be reserved.\n* Can I combine different CPUxRAM sizes or change the sizes later?\n\nYou cannot combine different CPUxRAM sizes or change the sizes later. The set of virtual server instances that you provision to your reserved capacity must be the same size as your reservation.\n* Is my payment upfront or monthly?\n\nReserved capacity and instances are purchased for a 1 or 3-year term. After that point, you're committed to a monthly payment.\n* What happens at the end of my contract?\n\nDepending on whether you choose hourly or monthly billing, the billing price for the CPU and RAM converts to the current list price, with any account discounts applied. Contact your sales representative, who in turn works with your global sales manager to determine end-of-contract options such as renewal or restructuring of your contract provisions. For more information about pricing, see [Build your virtual server](https://www.ibm.com/cloud/virtual-servers).\n* What happens if I don't need my reserved virtual server instances anymore?\n\nYou can reclaim reserved virtual server instances, but you cannot cancel reserved capacity.\n* Does the reservation include everything that I configured into my virtual server instance?\n\nOnly CPU and RAM are included in your reservation. Primary disk and no-additional charge network or storage products are not included in your reservation. More network bandwidth, storage capacity, OS, and third-party software are charged on an hourly or monthly basis, which depends on the instance type.\n* Why do I need to choose hourly or monthly billing on the virtual server instance?\n\nYour additional software, storage, and network selections need to be billed either hourly or monthly.\n* What types of virtual servers are available for use?\n\nIBM Cloud\u00ae offers a couple types of virtual servers within its Classic Infrastructure.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_14546-4405-6573", "score": 27.481832155046753, "text": "\nThis value includes public outbound traffic. \n\n\n\n\n\n\n\n VMware Shared Solutions Reserved billing plan \n\nVMware Shared Solutions Reserved virtual data center resources are preallocated and guaranteed. Pricing is monthly based on the allocation size of the virtual data center.\n\nThe standard storage policy pricing is the same as the 4-IOPS/GB storage policy. The number of IOPS/GB for the standard storage policy is not guaranteed.\n\nStorage policy availability can vary by region and deployment topology. On the VMware Shared order page, select the About tab to view available storage policy offerings.\n\nGeneral metrics\n\nStorage metrics\n\nOperating system metrics\n\n\n\nTable 3. VMware Shared Solutions Reserved billing plan - General metrics\n\n Metric Frequency Description \n\n MAX_VCPU Monthly The peak vCPU allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest vCPU reservation value that is selected by the customer over a one month period. \n MAX_RAM_GB Monthly The peak memory allocation for the virtual data center over the period of one month. The peak vCPU metric is determined by the largest memory reservation value that is selected by the customer over a one month period. \n TOTAL_EGRESS_GB Usage The total outbound public traffic is charged per GB transferred over the period of one month. This value includes the outbound traffic through the virtual data center NSX edge to the public internet. \n\n\n\n\n\n\n\n Private network endpoint billing plan \n\nPrivate network endpoint usage incurs charges as part of the on-demand or reserved virtual data center plan. On the VMware Shared order page, select the About tab to view the pricing plan details.\n\n\n\nTable 4. Billing plan for private network endpoints\n\n Metric Frequency Description \n\n MAX_PRIVATE_NETWORK_ONE_G_COST Monthly Charge for private network endpoint at 1 GB uplink over a period of one month. \n MAX_PRIVATE_NETWORK_TEN_G_COST Monthly Charge for private network endpoint at 10 GB uplink over a period of one month. \n\n\n\n\n\n\n\n Licenses and fees for Veeam Availability Suite and Zerto \n\nVeeam\u00ae and Zerto usage incurs the following on-demand charges.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-shared_pricing"}, {"document_id": "ibmcld_03704-5798-7955", "score": 25.65844742705683, "text": "\nFor more information, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n\n\n\n\n How do I change the invoice currency from US Dollars to my local currency? \n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) for more information.\n\nAn account that is invoiced in a currency other than US Dollars can't be converted to US Dollar invoicing.\n\n\n\n\n\n What is Business Continuity Insurance? \n\nBusiness Continuity Insurance is insurance that protects you from illegitimate charges against your servers. You can request this insurance through [IBM Cloud Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) to avoid overage charges if a documented network attack occurs against a covered server. IBM Cloud credits back any overages incurred on the affected server.\n\nTo receive the credits for illegitimate charges against your servers, contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter) and open a support case.\n\n\n\n\n\n What is the Service: Support and Services charge on my invoice? \n\nIf you create a VMWare cluster on your IBM Cloud account, you are charged for VMWare Level 2 Support for each cluster instance. This charge is in addition to any IBM Cloud Support charges for Premium or Advanced Support.\n\n\n\n\n\n What's the difference between promo codes and feature codes? \n\nPromo codes are for Pay-As-You-Go and Subscription accounts and give you limited-time credits toward your account and IBM Cloud products. The codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-billusagefaqs"}, {"document_id": "ibmcld_07578-1047268-1049406", "score": 25.65844742705683, "text": "\nFor more information, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) for more information.\n\nAn account that is invoiced in a currency other than US Dollars can't be converted to US Dollar invoicing.\n* What is Business Continuity Insurance?\n\nBusiness Continuity Insurance is insurance that protects you from illegitimate charges against your servers. You can request this insurance through [IBM Cloud Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) to avoid overage charges if a documented network attack occurs against a covered server. IBM Cloud credits back any overages incurred on the affected server.\n\nTo receive the credits for illegitimate charges against your servers, contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter) and open a support case.\n* What is the Service: Support and Services charge on my invoice?\n\nIf you create a VMWare cluster on your IBM Cloud account, you are charged for VMWare Level 2 Support for each cluster instance. This charge is in addition to any IBM Cloud Support charges for Premium or Advanced Support.\n* What's the difference between promo codes and feature codes?\n\nPromo codes are for Pay-As-You-Go and Subscription accounts and give you limited-time credits toward your account and IBM Cloud products. The codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1047139-1049277", "score": 25.65844742705683, "text": "\nFor more information, see [Managing your payment method outside of the console](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-linkedusagepayment-method-ibm).\n\n\n\n* How do I change the invoice currency from US Dollars to my local currency?\n\nInvoicing in your local currency might be possible if you have a subscription or IBM Cloud Cloud Enterprise Savings Plan account type. Contact [IBM Cloud Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) for more information.\n\nAn account that is invoiced in a currency other than US Dollars can't be converted to US Dollar invoicing.\n* What is Business Continuity Insurance?\n\nBusiness Continuity Insurance is insurance that protects you from illegitimate charges against your servers. You can request this insurance through [IBM Cloud Cloud Sales](https://cloud.ibm.com/catalog?contactmodule) to avoid overage charges if a documented network attack occurs against a covered server. IBM Cloud credits back any overages incurred on the affected server.\n\nTo receive the credits for illegitimate charges against your servers, contact [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter) and open a support case.\n* What is the Service: Support and Services charge on my invoice?\n\nIf you create a VMWare cluster on your IBM Cloud account, you are charged for VMWare Level 2 Support for each cluster instance. This charge is in addition to any IBM Cloud Support charges for Premium or Advanced Support.\n* What's the difference between promo codes and feature codes?\n\nPromo codes are for Pay-As-You-Go and Subscription accounts and give you limited-time credits toward your account and IBM Cloud products. The codes are typically short phrases, like PROMO200. For more information about promo codes, see [Managing promotions](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-applying-promo-codes).\n\nFeature codes provide enhancements for an account, such as an unlimited number of organizations or creating a trial account. Feature codes are typically provided for online courses and certain events, such as educational sessions or conference workshops.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03403-1720-3144", "score": 14.300145446495229, "text": "\nStep 2: Answer questions about the restaurant \n\nAdd an intent that recognizes when customers ask for details about the restaurant itself. An intent is the purpose or goal expressed in user input. The General_About_You intent that is provided with the General content catalog serves a similar function, but its user examples are designed to focus on queries about the assistant as opposed to the business that is using the assistant to help its customers. So, you will add your own intent.\n\n\n\n Add the about_restaurant intent \n\n\n\n1. From the Intents tab, click Create intent.\n\n![Shows the the Create intent button on the Intents page.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-ass-intent-add.png)\n2. Enter about_restaurant in the Intent name field, and then click Create intent.\n\n![Shows the #about_restaurant intent being added.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-ass-add-intent.png)\n3. Add the following user examples:\n\nTell me about the restaurant\ni want to know about you\nwho are the restaurant owners and what is their philosophy?\nWhat's your story?\nWhere do you source your produce from?\nWho is your head chef and what is the chef's background?\nHow many locations do you have?\ndo you cater or host functions on site?\nDo you deliver?\nAre you open for breakfast?\n4. Click the Close!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial"}, {"document_id": "ibmcld_03069-1750-3289", "score": 14.287790176747857, "text": "\nThe General_About_You intent that is provided with the General content catalog serves a similar function, but its user examples are designed to focus on queries about the assistant as opposed to the business that is using the assistant to help its customers. So, you will add your own intent.\n\n\n\n Add the about_restaurant intent \n\n\n\n1. From the Intents tab, click Create intent.\n\n![Shows the the Create intent button on the Intents page.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-ass-intent-add.png)\n2. Enter about_restaurant in the Intent name field, and then click Create intent.\n\n![Shows the #about_restaurant intent being added.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/gs-ass-add-intent.png)\n3. Add the following user examples:\n\nTell me about the restaurant\ni want to know about you\nwho are the restaurant owners and what is their philosophy?\nWhat's your story?\nWhere do you source your produce from?\nWho is your head chef and what is the chef's background?\nHow many locations do you have?\ndo you cater or host functions on site?\nDo you deliver?\nAre you open for breakfast?\n4. Click the Close![Close arrow](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/close_arrow.png) icon to finish adding the about_restaurant intent.\n\n\n\nYou added an intent and provided examples of utterances that real users might enter to trigger this intent.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial"}, {"document_id": "ibmcld_03010-1770-3351", "score": 14.266112816802728, "text": "\nSelect Create intent.\n3. In the Intent name field, type a name for the intent.\n\n\n\n* The intent name can contain letters (in Unicode), numbers, underscores, hyphens, and periods.\n* The name cannot consist of .. or any other string of only periods.\n* Intent names cannot contain spaces and must not exceed 128 characters. The following are examples of intent names:\n\n\n\n* weather_conditions\n* pay_bill\n* escalate_to_agent\n\n\n\n\n\nA number sign is prepended to the intent name automatically to help identify the term as an intent. You do not need to add it.\n\nOptionally add a description of the intent in the Description field.\n4. Select Create intent to save your intent name.\n\n![Screen capture that shows new intent definition](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/intent-create.png)\n5. In the User example field, type the text of a user example for the intent. An example can be any string up to 1,024 characters in length. The following utterances might be examples for the pay_bill intent:\n\n\n\n* I need to pay my bill.\n* Pay my account balance\n* make a payment\n\n\n\nTo learn about the impact of including references to entities in your user examples, see [How entity references are treated](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intentsintents-entity-references).\n\nIntent names and example text can be exposed in URLs when an application interacts with Watson Assistant. Do not include sensitive or personal information in these artifacts.\n6. Click Add example to save the user example.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents"}, {"document_id": "ibmcld_03010-7-2157", "score": 14.266064493445223, "text": "\nDefining intents \n\nIntents are purposes or goals that are expressed in a customer's input, such as answering a question or processing a bill payment. By recognizing the intent expressed in a customer's input, the Watson Assistant service can choose the correct dialog flow for responding to it.\n\n\n\n Intent creation overview \n\n\n\n* Plan the intents for your application.\n\nConsider what your customers might want to do, and what you want your application to be able to handle on their behalf. For example, you might want your application to help your customers make a purchase. If so, you can add a buy_something intent. (The that is added as a prefix to the intent name helps to clearly identify it as an intent.)\n* Teach Watson about your intents.\n\nAfter you decide which business requests that you want your application to handle for your customers, you must teach Watson about them. For each business goal (such as buy_something), you must provide at least 5 examples of utterances that your customers typically use to indicate their goal. For example, I want to make a purchase.\n\nIdeally, find real-world user utterance examples that you can extract from existing business processes. The user examples should be tailored to your specific business. For example, if you are an insurance company, a user example might look more like this, I want to buy a new XYZ insurance plan.\n\nThe examples that you provide are used by your assistant to build a machine learning model that can recognize the same and similar types of utterances and map them to the appropriate intent.\n\n\n\nStart with a few intents, and test them as you iteratively expand the scope of the application.\n\n\n\n\n\n Creating intents \n\n\n\n1. Open your dialog skill. The skill opens to the Intents page.\n2. Select Create intent.\n3. In the Intent name field, type a name for the intent.\n\n\n\n* The intent name can contain letters (in Unicode), numbers, underscores, hyphens, and periods.\n* The name cannot consist of .. or any other string of only periods.\n* Intent names cannot contain spaces and must not exceed 128 characters. The following are examples of intent names:\n\n\n\n* weather_conditions", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents"}, {"document_id": "ibmcld_10832-2167-3643", "score": 14.251057586364634, "text": "\nupdate-workspace Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, workspace_id, name, description, language, intents, entities, dialog_nodes, counterexamples, metadata, learning_opt_out, append Update a workspace. \n create-intent Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, workspace_id, intent, description, examples Create an intent. \n delete-intent Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, workspace_id, intent Delete an intent. \n get-intent Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, workspace_id, intent, export, include_audit Get information about an intent. \n list-intents Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, workspace_id, export, page_limit, include_count, sort, cursor, include_audit List intents. \n update-intent Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, workspace_id, intent, new_intent, new_description, new_examples Update an intent. \n create-example Action username, password, iam_access_token, iam_apikey, iam_url, headers, headers[X-Watson-Learning-Opt-Out], url, workspace_id, intent, text Create a user input example.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_watson_assistant"}, {"document_id": "ibmcld_03334-1458-3293", "score": 14.20053291329311, "text": "\nThe user examples should be tailored to your specific business. For example, if you are an insurance company, a user example might look more like this, I want to buy a new XYZ insurance plan.\n\nThe examples that you provide are used by your assistant to build a machine learning model that can recognize the same and similar types of utterances and map them to the appropriate intent.\n\n\n\nStart with a few intents, and test them as you iteratively expand the scope of the application.\n\n![Plus or higher plans only](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/plus.png) If you already have chat transcripts from a call center or customer inquiries that you collected from an online application, put that data to work for you. Share the real customer utterances with Watson and let Watson recommend the best intents and intent user examples for your needs. See [Get help defining intents](https://cloud.ibm.com/docs/assistant?topic=assistant-intent-recommendations) for more details.\n\n\n\n\n\n Creating intents \n\n\n\n1. Open your dialog skill. The skill opens to the Intents page.\n2. Select Create intent.\n3. In the Intent name field, type a name for the intent.\n\n\n\n* The intent name can contain letters (in Unicode), numbers, underscores, hyphens, and periods.\n* The name cannot consist of .. or any other string of only periods.\n* Intent names cannot contain spaces and must not exceed 128 characters. The following are examples of intent names:\n\n\n\n* weather_conditions\n* pay_bill\n* escalate_to_agent\n\n\n\n\n\nA number sign is prepended to the intent name automatically to help identify the term as an intent. You do not need to add it.\n\nKeep the name as short as possible. It's easier to read in the \"Try it out\" pane and conversation logs if you keep the intent name short and concise.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}, {"document_id": "ibmcld_03334-12430-14290", "score": 14.163675317347433, "text": "\nIf the top intent has a low confidence score (less than 0.2), the top intent is included in the intents array that is returned by the API, but any nodes that condition on the intent are not triggered. If you want to detect the case when no intents with good confidence scores were detected, use the irrelevant special condition in your dialog node. See [Special conditions](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-special-conditions) for more information.\n\nAs intent confidence scores change, your dialogs might need restructuring. For example, if a dialog node uses an intent in its condition, and the intent's confidence score starts to consistently drop below 0.2, the dialog node stops being processed. If the confidence score changes, the behavior of the dialog can also change.\n\n\n\n\n\n Intent limits \n\nThe number of intents and examples you can create depends on your Watson Assistant plan type:\n\n\n\nPlan details\n\n Plan Intents per skill Examples per skill \n\n Enterprise 2,000 25,000 \n Premium (legacy) 2,000 25,000 \n Plus 2,000 25,000 \n Lite, Trial 100 25,000 \n\n\n\n\n\n\n\n Editing intents \n\nYou can click any intent in the list to open it for editing. You can make the following changes:\n\n\n\n* Rename the intent.\n* Delete the intent.\n* Add, edit, or delete examples.\n* Move an example to a different intent.\n\n\n\nYou can tab from the intent name to each example.\n\n\n\n1. To move or delete an example, click the checkbox that is associated with it, and then click Move or Delete.\n\n![Screen capture showing how to move or delete an example](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/move_example.png)\n\n\n\n\n\n\n\n Searching intents \n\nUse the Search feature to find user examples, intent names, and descriptions.\n\n\n\n1. From the Intents page, click the Search icon.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}, {"document_id": "ibmcld_03405-4-2057", "score": 14.15090915139426, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Adding a node with slots to a dialog \n\nIn this tutorial, you will add slots to a dialog node to collect multiple pieces of information from a user within a single node. The node you create will collect the information that is needed to make a restaurant reservation.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Define the intents and entities that are needed by your dialog\n* Add slots to a dialog node\n* Test the node with slots\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 30 minutes to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https://cloud.ibm.com/docs/assistant?topic=assistant-getting-started). You will use the Watson Assistant tutorial skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\nYou can also start with a new dialog skill if you want. Just be sure to create the skill before you begin this tutorial.\n\n\n\n\n\n\n\n Step 1: Add intents and examples \n\nAdd an intent on the Intents tab. An intent is the purpose or goal that is expressed in user input. You will add a #reservation intent that recognizes user input that indicates that the user wants to make a restaurant reservation.\n\n\n\n1. From the Intents page of the tutorial skill, click Add intent.\n2. Add the following intent name, and then click Create intent:\n\nreservation\n\nThe #reservation intent is added. A number sign () is prepended to the intent name to label it as an intent. This naming convention helps you and others recognize the intent as an intent. It has no example user utterances associated with it yet.\n3. In the Add user examples field, type the following utterance, and then click Add example:\n\ni'd like to make a reservation\n4. Add these additional examples to help Watson recognize the reservation intent.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial-slots"}, {"document_id": "ibmcld_03071-7-2056", "score": 14.146089035406895, "text": "\nTutorial: Adding a node with slots to a dialog \n\nIn this tutorial, you will add slots to a dialog node to collect multiple pieces of information from a user within a single node. The node you create will collect the information that is needed to make a restaurant reservation.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Define the intents and entities that are needed by your dialog\n* Add slots to a dialog node\n* Test the node with slots\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 30 minutes to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started). You will use the Watson Assistant tutorial skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\nYou can also start with a new dialog skill if you want. Just be sure to create the skill before you begin this tutorial.\n\n\n\n\n\n\n\n Step 1: Add intents and examples \n\nAdd an intent on the Intents tab. An intent is the purpose or goal that is expressed in user input. You will add a #reservation intent that recognizes user input that indicates that the user wants to make a restaurant reservation.\n\n\n\n1. From the Intents page of the tutorial skill, click Add intent.\n2. Add the following intent name, and then click Create intent:\n\nreservation\n\nThe #reservation intent is added. A number sign () is prepended to the intent name to label it as an intent. This naming convention helps you and others recognize the intent as an intent. It has no example user utterances associated with it yet.\n3. In the Add user examples field, type the following utterance, and then click Add example:\n\ni'd like to make a reservation\n4. Add these additional examples to help Watson recognize the reservation intent.\n\nI want to reserve a table for dinner\nCan 3 of us get a table for lunch?\ndo you have openings for next Wednesday at 7?\nIs there availability for 4 on Tuesday night?", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial-slots"}, {"document_id": "ibmcld_03403-9884-11324", "score": 14.145414705225866, "text": "\n(https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-ass-entity-added.png)\n\n\n\n\n\n\n\n Add a cancel order intent \n\n\n\n1. Click the Intents tab.\n2. Click Create intent.\n3. Enter cancel_order in the Intent name field, and then click Create intent.\n4. Add the following user examples:\n\nI want to cancel my cake order\nI need to cancel an order I just placed\nCan I cancel my cake order?\nI'd like to cancel my order\nThere's been a change. I need to cancel my bakery order.\nplease cancel the birthday cake order I placed last week\nThe party theme changed; we don't need a cake anymore\nthat order i placed, i need to cancel it.\n\n![Shows that the #cancel_order intent was added.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-ass-cancel-order-intent-added.png)\n5. Click the Close![Close arrow](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/close_arrow.png) icon to finish adding the cancel_order intent.\n\n\n\n\n\n\n\n Add a yes intent \n\nBefore you perform an action on the user's behalf, you must get confirmation that you are taking the proper action. Add a #yes intent to the dialog that can recognize when a user agrees with what your assistant is proposing.\n\n\n\n1. Click the Intents tab.\n2. Click Create intent.\n3. Enter yes in the Intent name field, and then click Create intent.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13481-5443-6857", "score": 61.55140075497474, "text": "\n.config(\"spark.hive.metastore.uris\", \"thrift://catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\") \n.config(\"spark.hive.metastore.client.plain.username\", '<YourDataengineCRN>') \n.config(\"spark.hive.metastore.client.plain.password\", '<YourAPIkey>') \n.config(\"spark.hive.execution.engine\", \"spark\") \n.config(\"spark.hive.stats.autogather\", \"false\") \n.config(\"spark.sql.warehouse.dir\", \"file:///tmp\") \n only spark is allowed as the default catalog\n.config(\"metastore.catalog.default\", \"spark\") \n.enableHiveSupport() \n.getOrCreate()\nShow more\n\n\n\n\n\n Apache Hive metastore version 3.1.2 compatible client \n\nDownload the [Hive-compatible client](https://us.sql-query.cloud.ibm.com/download/catalog/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in /tmp/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_00029-8568-9861", "score": 60.06384074286919, "text": "\n\"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3\n\"spark.hive.metastore.truststore.path\":\"/opt/ibm/jdk/lib/security/cacerts\",\n for spark 3.1, spark 3.2\n\"spark.hive.metastore.truststore.path\":\"file:///opt/ibm/jdk/jre/lib/security/cacerts\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.jars\":\"/opt/ibm/connectors/data-engine/hms-client/\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.hive.metastore.version\":\"3.0\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.warehouse.dir\":\"file:///tmp\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.sql.catalogImplementation\":\"hive\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hadoop.metastore.catalog.default\":\"spark\"\n},\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\"application\": \"cos://mybucket.ALIAS NAME/select_query_data_engine.py\"\n\u00a0\u00a0\u00a0 }\n}\nShow more\n\nParameter values:\n\n\n\n* ALIAS NAME: specify the data engine endpoint for your region. For more information on the currently supported data engine endpoints, see [Data engine endpoints](https://cloud.ibm.com/docs/sql-query?topic=sql-query-overviewendpoints).\n* THRIFT URL: specify the region-specific thrift URL. For example, thrift://catalog.us.dataengine.cloud.ibm.com:9083.", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"}, {"document_id": "ibmcld_16641-6629-7897", "score": 59.64412000795579, "text": "\n\"spark.sql.catalog.lakehouse.type\": \"hive\",\n\"spark.sql.catalog.lakehouse.uri\": \"<hms-thrift-endpoint-from-watsonx.data> for example (thrift://81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683) \",\n\"spark.hive.metastore.client.auth.mode\": \"PLAIN\",\n\"spark.hive.metastore.client.plain.username\": \"<hms-user-from-watsonx.data> (for example, ibmlhapikey)\",\n\"spark.hive.metastore.client.plain.password\": \"<hms-password-from-watsonx.data>\",\n\"spark.hive.metastore.use.SSL\": \"true\",\n\"spark.hive.metastore.truststore.type\": \"JKS\",\n\"spark.hive.metastore.truststore.path\": \"file:///opt/ibm/jdk/lib/security/cacerts\",\n\"spark.hive.metastore.truststore.password\": \"changeit\"\n}\nShow more\n* INSTANCE_ID: The Analytics Engine instance ID. For more information about how to retrieve an instance ID, see [Obtaining the service endpoints](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli)\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data. For more information on getting the HMS credentials, see [Getting (Hive metastore) HMS Credentials](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-hms).\n* Hms-user-from-watsonx.Data: The watsonx.data username.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-lh-config-ae"}, {"document_id": "ibmcld_00029-7452-8829", "score": 59.02466967298581, "text": "\ntablesDF=spark.sql(\"SHOW TABLES\")\ntablesDF.show()\nstatesDF=spark.sql(\"SELECT * from COUNTRIESCAPITALS\");\nstatesDF.show()\n\ndef main():\nspark,sc = init_spark()\nselect_query_data_engine(spark,sc)\n\nif __name__ == '__main__':\nmain()\nShow more\n\nNote that for the SELECT command to work, you must pass the IBM Cloud Object Storage identifiers as one of the standard Data Engine aliases, in this example, we have used ALIAS NAME. If you do not pass the expected ones, you might see the following error: Configuration parse exception: Access KEY is empty. Please provide valid access key.\n\nselect_query_data_engine_payload.json:\n\n{\n\"application_details\": {\n\"conf\": {\n\"spark.hadoop.fs.cos.ALIAS NAME.endpoint\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.access.key\": \"CHANGEME\",\n\"spark.hadoop.fs.cos.ALIAS NAME.secret.key\": \"CHANGEME\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.truststore.password\" : \"changeit\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.execution.engine\":\"spark\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.password\":\"APIKEY-WITH-ACCESS-TO-DATA-ENGINE-INSTANCE\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.uris\":\"THRIFT URL\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.auth.mode\":\"PLAIN\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.use.SSL\":\"true\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.stats.autogather\":\"false\",\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 \"spark.hive.metastore.client.plain.username\":\"<CHANGEME-CRN-DATA-ENGINE-INSTANCE>\",\n for spark 3.3", "title": "", "source": "https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-data-engine-external-metastore"}, {"document_id": "ibmcld_16641-4554-5850", "score": 58.864443648163196, "text": "\n\"spark.sql.catalog.lakehouse.type\": \"hive\",\n\"spark.sql.catalog.lakehouse.uri\": \"<hms-thrift-endpoint-from-watsonx.data> for example (thrift://81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683) \",\n\"spark.hive.metastore.client.auth.mode\": \"PLAIN\",\n\"spark.hive.metastore.client.plain.username\": \"<hms-user-from-watsonx.data> (for example, ibmlhapikey)\",\n\"spark.hive.metastore.client.plain.password\": \"<hms-password-from-watsonx.data>\",\n\"spark.hive.metastore.use.SSL\": \"true\",\n\"spark.hive.metastore.truststore.type\": \"JKS\",\n\"spark.hive.metastore.truststore.path\": \"file:///opt/ibm/jdk/lib/security/cacerts\",\n\"spark.hive.metastore.truststore.password\": \"changeit\"\n}\nShow more\n* BASE_URL: The Analytics Engine URL for the region where you provisioned the instance. For example, api.region.ae.ibmcloud.com.\n* INSTANCE_ID: The Analytics Engine instance ID. For more information about how to retrieve an instance ID, see [Obtaining the service endpoints](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli).\n* hms-thrift-endpoint-from-watsonx.data: Specify the credentials for watsonx.data.\n* hms-user-from-watsonx.data: The watsonx.data username.\n* hms-password-from-watsonx.data: The watsonx.data password.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-lh-config-ae"}, {"document_id": "ibmcld_13481-4684-5710", "score": 58.18922293067736, "text": "\n.config(\"fs.cos.impl\", \"com.ibm.stocator.fs.ObjectStoreFileSystem\") \n.config(\"fs.stocator.scheme.list\", \"cos\") \n.config(\"fs.stocator.cos.impl\", \"com.ibm.stocator.fs.cos.COSAPIClient\") \n.config(\"fs.stocator.cos.scheme\", \"cos\") \n register the required Cloud Object Storage path used in our application, add endpoints for all buckets\n.config(\"spark.hadoop.fs.cos.us-geo.endpoint\", \"https://s3.us.cloud-object-storage.appdomain.cloud\") \n.config(\"spark.hadoop.fs.cos.us-geo.iam.endpoint\", \"https://iam.cloud.ibm.com/identity/token\") \n.config(\"spark.hadoop.fs.cos.us-geo.iam.api.key\", '<YourAPIkey>') \n.config(\"spark.sql.hive.metastore.version\", \"3.0\") \n directory where the Hive client has been placed\n.config(\"spark.sql.hive.metastore.jars\", \"/tmp/dataengine/\") \n.config(\"spark.hive.metastore.uris\", \"thrift://catalog.<region>.sql-query.cloud.ibm.com:9083\") \n.config(\"spark.hive.metastore.use.SSL\", \"true\") \n.config(\"spark.hive.metastore.truststore.password\", \"changeit\") \n.config(\"spark.hive.metastore.client.auth.mode\", \"PLAIN\")", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_16641-2355-3755", "score": 57.689952922437655, "text": "\nspark.sql.catalog.lakehouse.uri = <hms-thrift-endpoint-from-watsonx.data> for example (thrift://81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683)\nspark.hive.metastore.client.auth.mode = PLAIN\nspark.hive.metastore.client.plain.username = <hms-user-from-watsonx.data> (for example, ibmlhapikey)\nspark.hive.metastore.client.plain.password = <hms-password-from-watsonx.data>\nspark.hive.metastore.use.SSL = true\nspark.hive.metastore.truststore.type = JKS\nspark.hive.metastore.truststore.path = file:///opt/ibm/jdk/lib/security/cacerts\nspark.hive.metastore.truststore.password = changeit\nShow more\n\n\n\nParameter value:\n\n\n\n* Hms-thrift-endpoint-from-watsonx.Data: Specify the credentials for watsonx.data.\n* Hms-user-from-watsonx.Data: The watsonx.data username.\n* Hms-password-from-watsonx.Data: The watsonx.data password.\n\n\n\n\n\n\n\n Configuring Analytics Engine instance by using Analytics Engine API \n\nTo configure your IBM Analytics Engine instance from the Analytics Engine API, complete the following steps:\n\n\n\n1. Generate an IAM token to connect to the IBM Analytics Engine API. For more information about how to generate an IAM token, see [IAM token](https://cloud.ibm.com/docs/AnalyticsEngine?topic=AnalyticsEngine-retrieve-endpoints-serverlessendpoints-cli).\n2. Run the following API command to invoke the Analytics Engine API by using the generated IAM token.", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-lh-config-ae"}, {"document_id": "ibmcld_13481-7-1988", "score": 55.10943301466189, "text": "\nConnecting Apache Spark with Data Engine \n\nIBM Cloud\u00ae Data Engine catalog provides an interface that is compatible with Apache Hive metastore. This unified metadata repository enables any Big Data engine, such as Apache Spark, to use Data Engine as metastore. The same definition for tables and views can be created once and used from any connected engine. Each instance of Data Engine exports its catalog as a database called default.\n\n\n\n Catalog usage within Data Engine \n\nThe Catalog can be used in Data Engine in read and write mode. Seamless access is configured without any configuration steps needed.\n\n\n\n\n\n Connecting Apache Spark with Data Engine \n\nWhen you use the Hive metastore compatible interface, access is limited to read only operations. Thus, existing tables and views can be used, but not modified.\n\nDepending from where you want to connect to your catalog, the steps may vary.\n\n\n\n Usage within Watson Studio Notebooks \n\nWatson Studio has the compatible Hive metastore client already included. It also includes a convenience library to configure the connection to the Hive metastore. Set the required variables (CRN and apikey) and call the helper function to connect to the Hive metastore:\n\n change the CRN and the APIkey according to your instance\ncrn='yourDataengineCRN'\napikey='yourAPIkey'\n\nfrom dataengine import SparkSessionWithDataengine\n\n call the helper function to create a session builder equipped with the correct config\nsession_builder = SparkSessionWithDataengine.enableDataengine(crn, apikey, \"public\")\nspark = session_builder.appName(\"Spark DataEngine integration test\").getOrCreate()\n\nDisplay your tables and run an SQL statement:\n\nspark.sql('show tables').show(truncate=False)\n\n replace yourTable with a valid table. Do not use the sample tables as you do not have access to the data!\nspark.sql('select * from yourTable').show()\n\n\n\n\n\n Usage with IBM Analytics Engine \n\nThe Hive metastore client is also already included in IBM\u00ae Analytics Engine.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_13481-6212-7871", "score": 54.49408097516069, "text": "\nDownload the [Hive-compatible client](https://us.sql-query.cloud.ibm.com/download/catalog/hive-metastore-standalone-client-3.1.2-sqlquery-1.0.13.jar) and place it in a directory of your Apache Spark cluster that is not on the classpath. This step is necessary, as the client is loaded into an isolated classloader to avoid version conflicts. Note that in the examples the files are placed in /tmp/dataengine, when you use a different folder, adjust the example accordingly.\n\nThe client differs from the Hive version 3.1.2 release by more enhancements that add support for TLS and authentication through IBM Cloud\u00ae Identity and Access Management. For user, specify the CRN and for password a valid API key with access to your Data Engine. Find the endpoint to use in the following table.\n\n\n\nTable 1. Region endpoints\n\n Region Endpoint \n\n us-south thrift://catalog.us.dataengine.cloud.ibm.com:9083 \n eu-de thrift://catalog.eu-de.dataengine.cloud.ibm.com:9083 \n\n\n\n\n\n\n\n Convenience libraries to configure Spark \n\nWhile the Data Engine catalog is compatible with the Hive metastore and can be used as any other external Hive metastore server, an SDK is provided to minimize the steps that are needed to configure Apache Spark. The SDK simplifies connecting to the Hive metastore and IBM Cloud Object Storage buckets referenced by tables or views.\n\nIn case of using Python download both, the Scala and the Python SDK, and place them in a folder that is in the classpath of your Apache Spark cluster. When using Scala, the Scala SDK is enough.\n\n\n\n* [spark-dataengine-scala](https://us.sql-query.cloud.ibm.com/download/catalog/dataengine-spark-integration-1.4.51.jar)", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-hive_metastore"}, {"document_id": "ibmcld_16641-1211-2688", "score": 52.960590174766274, "text": "\nFor more information on getting the HMS credentials, see [Getting (Hive metastore) HMS Credentials](https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-hms).\n\n\n\n\n\n\n\n Configuring Analytics Engine instance by using IBM Cloud\u00ae console \n\nTo configure your Analytics Engine instance from the IBM Cloud\u00ae Resource list, complete the following steps:\n\n\n\n1. Log in to your IBM Cloud\u00ae account.\n2. Access the [IBM Cloud\u00ae Resource list](https://test.cloud.ibm.com/resources).\n3. Search your Analytics Engine instance and click the instance to see the details.\n4. Click Manage > Configuration to view the configuration.\n5. In the Default Spark configuration section, click Edit.\n6. Add the following configuration to the Default Spark configuration section.\n\nspark.sql.catalogImplementation = hive\nspark.driver.extraClassPath = /opt/ibm/connectors/iceberg-lakehouse/iceberg-3.3.2-1.2.1-hms-4.0.0-shaded.jar\nspark.sql.extensions = org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\nspark.sql.iceberg.vectorization.enabled = false\nspark.sql.catalog.lakehouse = org.apache.iceberg.spark.SparkCatalog\nspark.sql.catalog.lakehouse.type = hive\nspark.sql.catalog.lakehouse.uri = <hms-thrift-endpoint-from-watsonx.data> for example (thrift://81823aaf-8a88-4bee-a0a1-6e76a42dc833.cfjag3sf0s5o87astjo0.databases.appdomain.cloud:32683)\nspark.hive.metastore.client.auth.mode = PLAIN\nspark.hive.metastore.client.plain.username = <hms-user-from-watsonx.data> (for example, ibmlhapikey)", "title": "", "source": "https://cloud.ibm.com/docs/watsonxdata?topic=watsonxdata-lh-config-ae"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06968-15099-17180", "score": 43.86403114318861, "text": "\n[checkmark icon](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/icons/checkmark-icon.svg) \n\n\n\n\n\n* PDF files that are secured with a password or certificate are not supported. Vector objects, including SVG images and vectorized text, are not supported. Only images of the supported image file types that occur in the PDF are rendered.\n* Only single-page image files are supported.\n* Files within compressed archive files (ZIP, GZIP, TAR) are extracted. Discovery ingests the supported file types within the archive; it ignores all other file types. The file names must be encoded in UTF-8. Files with names that include Japanese characters, for example, must be renamed before they are added to the ZIP file.\n* Discovery supports MacOS ZIP files only if they are generated by using a command such as: zip -r my-folder.zip my-folder -x \".DS_Store\". ZIP files that are created by right-clicking a folder and clicking Compress are not supported.\n* PDF files that you upload as part of an archive file are not displayed in the advanced view for a query result that you open from the Improve and customize page. If you want the file to be viewable from the advanced view, reimport the PDF file separately from the archive file.\n\n\n\nWhen you add files to a Document Retrieval for Contracts project type, any file types that support SDU and OCR are processed with a pretrained Smart Document Understanding model and Optical Character Recognition automatically.\n\n\n\n\n\n Document limits \n\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collections"}, {"document_id": "ibmcld_06968-16615-18789", "score": 37.50454484170314, "text": "\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row\n* Each object that is defined in an array in a JSON file results in a separate document\n\n\n\n\n\nNumber of documents per service instance\n\n Plan Documents per service instance \n\n Cloud Pak for Data Unlimited \n Premium Unlimited \n Enterprise Unlimited \n Plus (includes Trial) 500,000 \n\n\n\nThe maximum allowed number can vary slightly depending on the size of the documents. Use these values as a general guideline.\n\n\n\n\n\n File size limits \n\n\n\n Crawled documents \n\nThe maximum size of each file that you can crawl by using a connector differs by deployment type.\n\nIBM Cloud\n\nManaged deployments on IBM Cloud\n\n\n\n* Premium plans only:\n\n\n\n* Box: 50 MB\n* IBM Cloud Object Store: 50 MB\n* Salesforce Files objects: 50 MB\n* All other data sources: 10 MB\n\n\n\n* All other plans: 10 MB\n\n\n\nIBM Cloud Pak for Data\n\nInstalled deployments on IBM Cloud Pak for Data\n\n\n\n* All data sources: 32 MB\n\n\n\n\n\n\n\n Uploaded documents \n\nThe size of each file that you can upload depends on your Discovery plan type. See the *Maximum document size table for details.\n\n\n\nMaximum document size\n\n Plan File size per document \n\n Cloud Pak for Data 50 MB \n Premium 50 MB \n Enterprise 10 MB \n Plus (includes Trial) 10 MB \n\n\n\n\n\n\n\n\n\n Field limits \n\nWhen a document is added to a collection, content from the document is evaluated and added to the appropriate fields in an internal index.\n\nFor structured data, such as uploaded CSV or JSON files, or data from crawled databases, each column or object is stored as a root-level field. For example, if you add a CSV file to collection, each column in the CSV file is stored as a separate field in the index.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collections"}, {"document_id": "ibmcld_16423-3286-5408", "score": 37.10319744359081, "text": "\nUpload one CSV file at a time. The first column in the CSV file specifies the file name of the document. The second column in the file contains the document text. For an example of the required format, see the [documents-new.csv](https://watson-developer-cloud.github.io/doc-tutorial-downloads/knowledge-studio/documents-new.csv) file in the tutorial sample files.\n\n\n\n\n\n PDF files \n\nText cannot be extracted from a PDF in some cases, depending on how the PDF was created. Typically, text can't be extracted from embedded fonts that don't map to unicode characters. If you are unsure whether text from a PDF can be extracted, you can try copying the text from the PDF and then pasting it into a text editor. If you do not see the same characters that are visible in the PDF itself, then the text extraction would likely fail.\n\n\n\n\n\n Formatted documents \n\nWhen formatted documents are converted to plain text, it's possible that losing the formatting could result in poor tokenization of words. For example, if a table row in a DOCX file contains cell values that do not end with a period, the values might be converted as one sentence. As another example, if a PDF document contains a very long word that is hyphenated at the end of a line, that word might be converted as two words. In cases like these, the documents might not be suitable for machine learning unless you pre-process the files to fix formatting limitations.\n\n\n\n\n\n Documents from another Watson Knowledge Studio workspace \n\nIf you previously downloaded documents from a Knowledge Studio workspace, you can upload the ZIP file that you downloaded. An option lets you specify whether you want the ground truth annotations to be included in the imported files.\n\nAfter documents are annotated, the annotated documents are stored in JSON format. The markup language in these files, which shows how the original document text was parsed and tokenized, includes elements for all of the annotations that a human annotator added. To improve model accuracy over time, you can upload these files into another workspace, thus preserving all of the existing annotations.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"}, {"document_id": "ibmcld_06968-18330-20453", "score": 36.62298843278439, "text": "\nPlus (includes Trial) 10 MB \n\n\n\n\n\n\n\n\n\n Field limits \n\nWhen a document is added to a collection, content from the document is evaluated and added to the appropriate fields in an internal index.\n\nFor structured data, such as uploaded CSV or JSON files, or data from crawled databases, each column or object is stored as a root-level field. For example, if you add a CSV file to collection, each column in the CSV file is stored as a separate field in the index.\n\nA maximum of 1,000 fields can be added to the index.\n\nYou cannot assign the data type, such as Date or String, of a field. The data type is detected automatically and assigned to the field during document ingestion. The assignment is based on the data type that is detected from the first document that is indexed. Ingestion errors can occur in subsequent documents if a different data type is detected for the value in the same field. Therefore, if your documents have a mix of data types in a single field, first ingest the document that has a value with the most flexible data type, such as String, in the field.\n\nWhen you crawl a website or upload an HTML file, the HTML content is added to the collection and indexed in an html field.\n\nThe following table shows the maximum size limit for fields per document.\n\n\n\nMaximum field sizes\n\n Field type Maximum allowed size per document \n\n html field 5 MB \n Sum of all other fields 1 MB \n\n\n\nIf the maximum size of the fields in the document exceeds the allowed limits, they are treated as follows:\n\n\n\n* For a document with an oversized html field, all of the fields in the document are indexed except the html field.\n\nFor IBM Cloud Pak for Data version 4.0 and earlier, the entire document is not indexed.\n* For a document with oversized non-HTML fields, the document is not indexed.\n\n\n\nIf you are uploading a Microsoft Excel file and a message is displayed that indicates that the non-HTML field size limit is exceeded, consider converting the XLS file into a CSV file. When you upload a comma-separated value (CSV) file, each row is indexed as a separate document. As a result, no field size limits are exceeded.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collections"}, {"document_id": "ibmcld_00546-2347-3956", "score": 36.59132793326536, "text": "\ndisk_size Size in bytes of the data as stored on the disk. Views indexes aren't included in the calculation. \n doc_count A count of the documents in the specified database. \n doc_del_count Number of deleted documents. \n instance_start_time Always 0. \n other JSON object that contains a data_size field. \n purge_seq The number of purge operations on the database. \n sizes A JSON object, containing file, external, and active sizes. active is the size in bytes of data that is stored internally (excluding old revisions). external is the size in bytes of decompressed user data. This value is the billable data size. The other/data_size field is an alias for the external field. file is the size in bytes of data that is stored on the disk. Indexes aren't included in the calculation. The disk_size field is an alias for the file field. This size includes data that is waiting for compaction. \n update_seq An opaque string that describes the state of the database. Don't rely on this string for counting the number of updates. \n partitioned_indexes A JSON object that appears only if the database is partitioned. count is the number of partitioned indexes. indexes list the type of partitioned indexes, and limit shows the maximum number of allowed partitioned indexes. \n\n\n\nSee the following example (abbreviated) response that contains database details:\n\n{\n\"update_seq\": \"982...uUQ\",\n\"db_name\": \"db\",\n\"sizes\": {\n\"file\": 46114703224,\n\"external\": 193164408719,\n\"active\": 34961621142\n},\n\"purge_seq\": 0,\n\"other\": {\n\"data_size\": 193164408719\n},\n\"doc_del_count\": 5564,\n\"doc_count\": 9818541,\n\"disk_size\": 46114703224,", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-database-details"}, {"document_id": "ibmcld_00510-5537-7566", "score": 35.545271019862994, "text": "\nInstead, keep orders separate as their own document type, referencing the customer ID. Now the model is immutable. To add an order, I create a new order document in the database, which cannot generate conflicts.\n\nTo be able to retrieve all orders for a specific customer, we can employ a view, which we cover later.\n\nAvoid constructs that rely on updates to parts of existing documents, where possible. Bad data models are often hard to change after you\u2019re in production.\n\nThe previous pattern can be solved efficiently by using partitioned databases, which are covered in greater detailed later.\n\nFor more information, see the following documentation:\n\n\n\n* IBM Cloudant guide to [data modeling](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-five-tips-for-modeling-your-data-to-scale-faq)\n* [Database partitions](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-database-partitioning)\n\n\n\n\n\n\n\n Keep documents small \n\nIBM Cloudant imposes a max doc size of 1 MB. This limit does not mean that a close-to-1-MB document size is a good idea. On the contrary, if you find you are creating documents that exceed single-digit KB, you probably need to revisit your model. Several things in IBM Cloudant become less performant as documents grow. JSON decoding is costly, for example.\n\nLet's look at the following sections: Documents must group data that mostly changes together and Keep documents small. It\u2019s worth stressing that models that rely on updates have a maximum volume limit of 1 MB, the cut-off for document size. This size isn\u2019t what you want.\n\n\n\n\n\n Avoid using attachments \n\nIBM Cloudant has support for storing attachments alongside documents, a long-standing feature it inherits from CouchDB. If you use IBM Cloudant as a backend for a web application, you can also store small icons and other static assets such as CSS and JavaScript files with the data.\n\nYou must consider a few things before you use attachments in IBM Cloudant today, especially if you\u2019re looking at larger assets such as images and videos:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-data-modeling"}, {"document_id": "ibmcld_07117-1664-3943", "score": 35.29050530232332, "text": "\nIf you encounter this issue, open the file in a more recent version of Microsoft Office and convert the file to the DOCX, PPTX, or XLSX format respectively, and then upload the DOCX, PPTX, or XLSX file.\n\nLine breaks are inserted randomly\n: When some files in Microsoft Office format are added to a collection, line breaks are inserted seemingly at random to the text that is stored in the html field in the collection's index. The unexpected line breaks can impact the efficiency of enrichments, such as custom rule recognition.\n\nCause: As part of their ingestion into Discovery, such files are converted from Office format to PDF format. When the conversion happens, textual content is sometimes lost due to the nature of a PDF file. While the new lines appear to be added at random, they typically get inserted in areas where text wraps in the original document, such as in narrow text boxes or to accommodate other inline elements, such as images or diagrams.\n\nSolution: To avoid new line insertions, increase the width of text boxes in the original document. If the original document has a section where text wraps to accommodate an inline element, such as an image, move the image so that it is situated in its own section and the nearby text doesn't need to wrap around it. To test whether your fixes address the issue, you can convert the original file to a PDF file to check for unexpected carriage returns in the text.\n\nAfter applying a pretrained Smart Document Understanding model to a PPT file, table boundaries are not recognized properly\n: During the conversion process, text that is extracted from the table is confused with text that is outside the table in some PPT pages. This issue is more likely to occur in tables with a lot of text and that have footnotes displayed just outside the table border. If you encounter this issue, export the PPT file as a PDF file, and then upload the PDF file instead. Apply a user-trained Smart Document Understanding (SDU) model to the document, and then use the SDU tool to identify the tables in the document. The resulting model handles table boundaries properly and can extract text from the tables cleanly.\n\n\n\n\n\n PDF file troubleshooting tips \n\nFailed to parse document due to invalid encoding\n: Enable OCR for the file.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-troubleshoot-ingestion"}, {"document_id": "ibmcld_07140-2710-4310", "score": 34.35153847504846, "text": "\n* HTML files are converted to JSON using the html options, and the resulting JSON is converted using the json options.\n* JSON files are converted using the json options.\n\n\n\nIf you configure your collection using [Smart Document Understanding](https://cloud.ibm.com/docs/discovery?topic=discovery-sdu), the PDF and Word conversion settings listed are not used, so changing these conversion settings are ignored.\n\nThese options are described in the following sections. After conversion completes, [enrichment](https://cloud.ibm.com/docs/discovery?topic=discovery-configrefenrichment) and [normalization](https://cloud.ibm.com/docs/discovery?topic=discovery-configrefnormalization) are performed before the content is stored.\n\n\n\n PDF \n\nIf you configure your collection using [Smart Document Understanding](https://cloud.ibm.com/docs/discovery?topic=discovery-sdu), the PDF and Word conversion settings listed are not used, so changing these conversion settings are ignored.\n\nThe pdf conversion object defines the conversion from PDF to HTML and has the following structure:\n\n\"pdf\": {\n\"heading\": {\n\"fonts\": [\n{\n\"level\": 1,\n\"min_size\": 24,\n\"max_size\": 80,\n\"bold\": false,\n\"italic\": true,\n\"name\": \"arial\"\n},\n{\n\"level\": 2,\n\"min_size\": 18,\n\"max_size\": 24,\n\"bold\": true,\n\"italic\": false,\n\"name\": \"ariel\"\n}\n]\n}\n},\nShow more\n\nWhen converting PDF files, headings in those files can be identified and converted into an appropriate HTML \"h\" tag by identifying the size, font, and style of each heading level. Heading levels can be specified multiple times, if necessary, to correctly identify all relevant sections.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-configref"}, {"document_id": "ibmcld_16423-1704-3666", "score": 32.99530805128716, "text": "\nA goal to aim for is to eventually have at least 50 annotations for each entity type and 50 for each relation type in the document collection.\n* Again, documents should represent the breadth of the subject matter that the application will cover, but in the case of skewed frequency-of-occurrence of entity types and relation types, try to get at least 50 exemplars of each type, more for entity types that have mentions which tend to be phrases.\n* The set that you create for training must contain at least 10 annotated documents.\n\n\n\nWhen you are ready to create and train the model, documents that you add to the workspace can be divided into sets that are used as training data, test data, and blind data. The separate data sets are important for assessing model performance.\n\nYou can add documents in the following ways. For information about the supported document types, size limits, and other information, see [Creating a workspace > Summary of inputs, outputs, and limitations](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-create-projectwks_formats).\n\n\n\n* A two-column CSV file in UTF-8 format\n* Text files in UTF-8 format\n* HTML files\n* PDF files (scanned and password-protected files are not supported)\n* Microsoft Word DOC or DOCX files (password-protected files are not supported)\n* A ZIP file that contains documents downloaded from a Knowledge Studio workspace\n* A ZIP file that contains files in UIMA CAS XMI format\n\n\n\n\n\n CSV files \n\nYou can upload a two-column CSV file that contains sample text from your local machine. Upload one CSV file at a time. The first column in the CSV file specifies the file name of the document. The second column in the file contains the document text. For an example of the required format, see the [documents-new.csv](https://watson-developer-cloud.github.io/doc-tutorial-downloads/knowledge-studio/documents-new.csv) file in the tutorial sample files.\n\n\n\n\n\n PDF files", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"}, {"document_id": "ibmcld_16487-3110-5017", "score": 32.18491363888447, "text": "\n* A .zip file that contains files in UIMA CAS XMI format\n\n\n\n\n\n CSV files \n\nYou can upload a two-column CSV file that contains sample text from your local machine. Upload one CSV file at a time. The first column in the CSV file specifies the file name of the document. The second column in the file contains the document text. For an example of the required format, see the [documents-new.csv![External link icon](https://cloud.ibm.com/docs-content/v1/content/50eddb8fd81f33092880335ff107a78ff5cd0f65/icons/launch-glyph.svg)](https://watson-developer-cloud.github.io/doc-tutorial-downloads/knowledge-studio/documents-new.csv) file in the tutorial sample files.\n\n\n\n\n\n PDF files \n\nText cannot be extracted from a PDF in some cases, depending on how the PDF was created. Typically, text can't be extracted from embedded fonts that don't map to unicode characters. If you are unsure whether text from a PDF can be extracted, you can try copying the text from the PDF and then pasting it into a text editor. If you do not see the same characters that are visible in the PDF itself, then the text extraction would likely fail.\n\n\n\n\n\n Formatted documents \n\nWhen formatted documents are converted to plain text, it's possible that losing the formatting could result in poor tokenization of words. For example, if a table row in a DOCX file contains cell values that do not end with a period, the values might be converted as one sentence. As another example, if a PDF document contains a very long word that is hyphenated at the end of a line, that word might be converted as two words. In cases like these, the documents might not be suitable for machine learning unless you pre-process the files to fix formatting limitations.\n\n\n\n\n\n Documents from another Watson Knowledge Studio workspace \n\nIf you previously downloaded documents from a Knowledge Studio workspace, you can upload the .zip file that you downloaded.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-documents-for-annotation"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10596-9883-11854", "score": 32.967642554819456, "text": "\nIf they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_06160-10037-11653", "score": 32.45926099783268, "text": "\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see whether the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_03970-6841-9069", "score": 29.12139169921774, "text": "\nIf you import a bulk data transfer of nodes and do not also import identities, you will have to perform the separate step of associating identities with the nodes. There are a few ways to procure an identity that can operate a node. For more information about, see [Gathering certificates or credentials](https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-import-nodesibp-console-import-start-here). Regardless of the process used to acquire the identity, after the bulk import has been completed you will need to click on each imported node. For peers and ordering nodes, a box on the left of the screen will say Identity not associated with (peer or ordering node), depending on the node in question. After clicking on this box, you will be able to associate the relevant identity by selecting it from your Wallet. Note that this process is distinctly different than the process for importing individual nodes, where you will be asked to associate an identity as part of the import process.\n\nYou will also need to associate an admin identity for the CA. This process is similar to the peer and ordering node process except that after you click on the imported CA you will see a separate screen asking you to associate an identity rather than a box on the left.\n\nFor cases where bulk data transfers are impractical or inadvisable, you can follow the steps below to export and import components and identities one at a time.\n\n\n\n\n\n Gathering certificates or credentials \n\nBecause identities contain private keys, be careful when exporting them to ensure they are handled securely. If a private key is compromised, it can be used to perform malicious actions.\n\nEach IBM Blockchain Platform component is deployed with the signing certificate of an administrator inside. When actions requiring the permission level of an admin are performed against the component, the signing certificate of the entity attempting the action is checked against the signing certificate inside the node. If they don't match, the action is denied. In this way, these certificates, which are also known as \"keys\", allow the administrator to operate their components.\n\nIf you intend to operate an imported node, you have two options:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-import-nodes"}, {"document_id": "ibmcld_06160-8533-10577", "score": 28.777127621882528, "text": "\n* Check any Calico or Kubernetes network policies that are applied to the cluster and make sure that they do not block traffic from the worker node to the cluster apiservice, container registry, or other critical services.\n\n\n\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see if the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. Check the status of your worker nodes. If they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n6. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states \n\nIf your worker nodes switch between a Normal and Critical or NotReady state, check the following components for any issues or recent changes that may disrupt your worker nodes.\n\n\n\n1. For classic clusters, check your firewalls or gateways. If there is a bandwidth limit or any type of malfunction, resolve the issue. Then, check your worker nodes again.\n2. Check if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_10596-8503-10370", "score": 28.077801021725577, "text": "\nCheck if the applications, security, or monitoring components in your cluster are overloading the cluster apiserver with requests, which may cause disruptions for your worker nodes.\n3. If you recently added any components to your cluster, remove them. If you made changes to any existing components in your cluster, revert the changes. Then, check the status of your worker nodes to see if the new components or changes were causing the issue.\n4. Check for changes on any cluster webhooks, which can disrupt apiserver requests or block a worker node's ability to connect with the apiserver. [Remove all webhooks](https://cloud.ibm.com/docs/containers?topic=containers-ts-delete-webhooks) that were added to the cluster after it was created.\n5. Remove and regenerate any custom Docker pull secrets, which, if misconfigured, can prevent worker nodes from pulling images from Docker registries.\n\n\n\n1. Run the ibmcloud oc delete secret -n openshift pull-secret and ibmcloud oc delete secret -n openshift-config pull-secret commands to delete the custom Docker pull secrets.\n\nibmcloud oc delete secret -n openshift pull-secret\n\nibmcloud oc delete secret -n openshift-config pull-secret\n2. Wait for the cluster to regenerate the custom Docker pull secrets. Any misconfigured components are no longer present in the regenerated pull secrets.\n\n\n\n6. Check the status of your worker nodes. If they are in a Normal state, add back any deleted components and re-create any reverted changes, one by one, until you can determine which configuration or component caused the worker node disruption.\n7. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n If worker nodes switch between normal and critical states", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_06160-11142-12906", "score": 27.626511715950414, "text": "\nIf the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\nkubectl top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%\n2.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_10596-11475-13230", "score": 27.626511715950414, "text": "\n5. If the issue is still not resolved, follow the steps to [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n\n\n\n\n Gathering data for a support case \n\nIf you are unable to resolve the issue with the troubleshooting steps, gather information about your worker nodes. Then, [open a support ticket](https://cloud.ibm.com/unifiedsupport/cases/form) and include the worker node information you gathered.\n\nBefore you open a support ticket, review the information and follow any troubleshooting steps in [Debugging worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-debug_worker_nodes), [Worker node states](https://cloud.ibm.com/docs/containers?topic=containers-worker-node-state-reference), and [Troubleshooting worker nodes in Critical or NotReady state](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready).\n\nIf all worker nodes in a cluster, or in a single zone, subnet, or VLAN are affected, you can open an initial support ticket without gathering data. However, you might later be asked to gather the relevant data. If only one or some of your worker nodes are affected, you must gather the relevant data to include in your support ticket.\n\n\n\n Before you begin \n\nCheck the conditions of your worker nodes and cluster before you gather data.\n\n\n\n1. Check the CPU and memory level of your nodes. If any node is over 80% in either CPU or memory usage, consider provisioning more nodes or reducing your workload.\n\noc top node\n\nExample output.\n\nNAME CPU(cores) CPU% MEMORY(bytes) MEMORY%\n10.001.1.01 640m 16% 6194Mi 47%\n10.002.2.02 2686m 68% 4024Mi 30%\n10.003.3.03 2088m 53% 10735Mi 81%", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_10596-5350-7330", "score": 27.498376033816346, "text": "\nIf the previous steps do not solve the issue, [reload](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.\n\n\n\n1. Check if there were any recent changes to your cluster, environment, or account that might impact your worker nodes. If so, revert the changes and then check the worker node status to determine if the changes caused the issue.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-ts-critical-notready"}, {"document_id": "ibmcld_06160-5357-7356", "score": 27.30022763731949, "text": "\nIf the previous steps do not solve the issue, [reload](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uics_worker_reload) or [replace](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-cli&interface=uicli_worker_replace) the affected workers one at a time.\n\n\n\nIf some, but not all, of your worker nodes frequently enter a Critical or NotReady state, consider enabling [worker autorecovery](https://cloud.ibm.com/docs/containers?topic=containers-health-monitorautorecovery) to automate these recovery steps.\n\n\n\n\n\n If all worker nodes in a single zone, subnet, or VLAN are affected \n\nIf all worker nodes in a single zone, subnet, or VLAN are in a Critical or NotReady state, but all other worker nodes in the cluster are functioning normally, there might be an issue with a networking component. Follow the steps in [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all), especially to the steps regarding any networking components that may affect the zone, subnet or VLAN, such as firewall or gateway rules, ACLs or custom routes, or Calico and Kubernetes network policies.\n\nIf you checked your networking components and still cannot resolve the issue, [gather your worker node data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather) and open a support ticket.\n\n\n\n\n\n If all worker nodes in a cluster are affected \n\nIf all the worker nodes in your cluster show Criticalor NotReady at the same time, there might be a problem with either the cluster apiserver or the networking path between the workers and the apiserver. Follow these troubleshooting steps to determine the cause and resolve the issue.\n\nSome steps are specific to a specialized area, such as networking or automation. Consult with the relevant administrator or team in your organization before completing these steps.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notready"}, {"document_id": "ibmcld_05713-581893-583377", "score": 25.703018260643706, "text": "\n* [If all worker nodes in a cluster are affected](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-all)\n* [If worker nodes switch between normal and critical states](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-steps-switch)\n\n\n\n* [Gathering data for a support case](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather)\n\n\n\n* [Before you begin](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-before)\n* [Gathering data](https://cloud.ibm.com/docs/containers?topic=containers-ts-critical-notreadyts-critical-notready-gather-steps)\n\n\n\n\n\n[VPC: Why can't I create worker nodes on dedicated hosts?](https://cloud.ibm.com/docs/containers?topic=containers-ts-worker-dedicatedts-worker-dedicated)\n\n[Why doesn't replacing a worker node create a worker node?](https://cloud.ibm.com/docs/containers?topic=containers-auto-rebalance-offauto-rebalance-off)\n\n[Classic: Why is the bare metal instance ID inconsistent with worker records?](https://cloud.ibm.com/docs/containers?topic=containers-bm_machine_idbm_machine_id)\n\n[After deleting all worker nodes, why don't my pods start on new worker nodes?](https://cloud.ibm.com/docs/containers?topic=containers-zero_nodes_calico_failurezero_nodes_calico_failure)\n\n[After a worker node updates or reloads, why do duplicate nodes and pods appear?]", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_sitemap"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03120-3469-5331", "score": 29.565251192326862, "text": "\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Choose to create either a dialog or actions skill, and then click Next.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).\n3. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n4. Create the skill.\n5. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. For an actions skill, add actions.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language"}, {"document_id": "ibmcld_02839-3583-5403", "score": 26.33097766312298, "text": "\nIf your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences. Click the Enable bidirectional capabilities switch. Specify any settings that you want to configure.\n\nFor more information, see [Configuring bidirectional languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-supportlanguage-support-configure-bidirectional).\n\n\n\nNext, start building your conversation.\n\nAs you follow the normal steps to design a conversational flow, you teach the universal language model about the language you want your skill to support. It is by adding training data that is written in the target language that the universal model is constructed. Add intents, intent user examples, and entities. The universal language model adapts to understand and support your language of choice.\n\n\n\n\n\n Integration considerations \n\nWhen your skill is ready, you can add it to an assistant and deploy it. Keep these tips in mind:\n\n\n\n* Search skill: If you build an assistant that specializes in a single language, be sure to connect it to data collections that are written in that language. For more information about the languages that are supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n* Web chat: Web chat has some hardcoded strings that you can customize to reflect your target language. For more information, see [Global audience support](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-basicsweb-chat-basics-global).", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_03369-36856-39124", "score": 25.716144393460823, "text": "\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests.\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:\n\n\n\n* New assistants can use up to two skills, either actions and search or dialog and search. Previously, new assistants could use up to three skills: actions, dialog, and search.\n* Existing assistants that already use an actions skill and a dialog skill together can continue to use both.\n* The ability to use actions and dialog skills together in a new assistant is planned for 2H 2021.\n\n\n\n\n\n\n\n 20 May 2021", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_03126-3707-6008", "score": 24.95817376342451, "text": "\nUnderstanding where you will deploy the assistant before you begin can help you author the right types of answers for a given channel or platform.\n\n\n\n\n\n What languages does your assistant speak? \n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language).\n\n\n\n\n\n Does your assistant see the glass as half full? \n\nIs your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Choose a personality for your assistant, and then write conversations that reflect that personality. Don't overdo it. Don't sacrifice usability for the sake of keeping your assistant in character. But strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chat bots to identify themselves as chat bots.\n\n\n\n\n\n Who will build your assistant? \n\nAssemble a team with people who understand your customers and their needs, people who know how to interact with customers to reach the best outcomes. These subject matter experts can focus on designing an engaging conversational flow. In fact, the actions skill is designed with this type of expert in mind. The team can simultaneously build a conversational flow by defining discrete actions.\n\nIf you have data scientists or team members with programming skills, you can take advantage of some advanced capabilities that require varying levels of development expertise. This set of users might prefer to build the conversational flow with a dialog skill because there is greater visibility into the individual components that make up the training data.\n\nSo, which conversational skill type should you use?\n\nUse both. Leverage advanced capabilities that are available from a dialog skill and build individual actions to perform finite tasks that you want to support. You can call the actions in your actions skill from your dialog skill.\n\nFor more information, see [Choosing a conversational skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skills-choose).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-assistants"}, {"document_id": "ibmcld_02839-1790-3940", "score": 24.76868214535353, "text": "\nTo deploy, attach each language skill to its own assistant that you can deploy in a way that optimizes its use by your target audience.\n\n\n\n\n\n Understanding the universal language model \n\nA skill that uses the universal language model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from the training data that you add to it.\n\nThe universal language classifier can adapt to a single language per skill. It cannot be used to support multiple languages within a single skill. However, you can use the universal language model in one skill to support one language, such as Russian, and in another skill to support another language, such as Hindi. The key is to add enough training examples or intent user examples in your target language to teach the model about the unique syntactic and grammatical rules of the language.\n\nUse the universal language model when you want to create a conversation in a language for which no dedicated language model is available, and which is unique enough that an existing model is insufficient.\n\nFor more information about feature support in the universal language model, see [Supported languages](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support).\n\n\n\n\n\n Creating a skill that uses the universal language model \n\nTo create a skill that uses the universal language model, complete the following steps:\n\n\n\n1. From the Skills page, click Create skill.\n2. Name your skill, and optionally add a description. From the Language field, choose Another language.\n\nRemember, if the language you want to support is listed individually, choose it instead of using the universal model. The built-in language models provide optimal language support.\n3. Create the skill.\n4. If your skill will support a language with right-to-left directional text, such as Hebrew, configure the bidirectional capabilities.\n\nClick the options icon from the skill tile ![Skill options icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kebab.png), and then select Language preferences.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language"}, {"document_id": "ibmcld_03043-7-2031", "score": 24.076183515496023, "text": "\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-add"}, {"document_id": "ibmcld_16364-72601-74697", "score": 24.058035180279443, "text": "\nFor more information, see [Actions skill overview](https://cloud.ibm.com/docs/assistant?topic=assistant-actions-overview).\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests. For more information, see [Response types](https://cloud.ibm.com/docs/assistant?topic=assistant-actionsactions-response-types).\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nFor more information, see [Adding and referencing variables](https://cloud.ibm.com/docs/assistant?topic=assistant-actionsactions-variables).\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03369-66296-68553", "score": 23.896452938418896, "text": "\nVisit the learning center!\n: Click the Learning center link that is displayed in the header of the skill pages to find helpful product tours. The tours guide you through the steps to follow to complete a range of tasks, from adding your first intent to a dialog skill to enhancing the conversation in an actions skill. The Additional resources page has links to relevant documentation topics and how-to videos. You can search the resource link titles to find what you're looking for quickly.\n\n\n\n\n\n 29 October 2020 \n\nSystem entity support changes\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_03329-1102-2607", "score": 23.794340579024635, "text": "\n[Finish creating the new assistant](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-create-assistant-done.png)\n3. Click Create assistant.\n\n\n\n\n\n\n\n Step 2: Create a dialog skill \n\nA dialog skill is a container for the artifacts that define the flow of a conversation that your assistant can have with your customers.\n\n\n\n1. Click Add an actions or dialog skill.\n\n![Add actions or dialog skill button](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-addskill.png)\n2. Give your skill the name My first skill.\n3. Optional. If the dialog you plan to build will use a language other than English, then choose the appropriate language from the list.\n4. For skill type, choose Dialog.\n\n![Finish creating the skill](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/gs-add-skill-done.png)\n5. Click Create skill.\n\nThe skill is created and appears in your assistant.\n\n\n\n\n\n\n\n Step 3: Add intents from a content catalog \n\nThe Intents page is where you start to train your assistant. In this tutorial, you will add training data that was built by IBM to your skill. Prebuilt intents are available from the content catalog. You will give your assistant access to the General content catalog so your dialog can greet users, and end conversations with them.\n\n\n\n1. Make sure your My first skill is open.\n2. Click Content Catalog from the Skills menu.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-gs-dialog"}, {"document_id": "ibmcld_16364-103662-105841", "score": 23.666897418917316, "text": "\n: For English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills only the new system entities API version is supported. For backward compatibility, both the interpretation and metadata attributes are included with the recognized entity object. The new system entity version is enabled automatically for dialog skills in the Arabic, Chinese, Korean, and Japanese languages. You can choose to use the legacy version of the system entities API by switching to it from the Options>System Entities page. This settings page is not displayed in English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills because use of the legacy version of the API is no longer supported for those languages. For more information about the new system entities, see [System entities](https://cloud.ibm.com/docs/assistant?topic=assistant-system-entities).\n\n\n\n\n\n 28 October 2020 \n\nIntroducing the actions skill!\n: The actions skill is the latest step in the continuing evolution of Watson Assistant as a software as a service application. The actions skill is designed to make it simple enough for anyone to build a virtual assistant. We've removed the need to navigate between intents, entities, and dialog to create conversational flows. Building can all now be done in one simple and intuitive interface.\n\nThe actions skill is available as a beta feature. For more information, see [Adding an actions skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-actions-add).\n\nWeb chat integration is created automatically\n: When you create a new assistant, a web chat integration is created for you automatically (in addition to the preview link integration, which was created previously). These integrations are added also to the assistant that is auto-generated (named My first assistant) when you create a new service instance. For more information, see [Integrating the web chat with your website](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat).\n\nText messaging integration was renamed\n: The Twilio messaging integration was renamed to SMS with Twilio.\n\n\n\n\n\n 9 October 2020 \n\nSearch skill update", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04111-12664-14293", "score": 33.00361066364631, "text": "\nUpdate universal SSL setting PATCH /v1/{crn}/zones/{domain_id}/ssl/universal/settings internet-svcs.security.update internet-svcs.universal-ssl-setting.update \n Get edge certificates ordered from CIS GET /v1/{crn}/zones/{domain_id}/ssl/certificate_packs internet-svcs.security.read internet-svcs.certificate-packs.read \n Order an edge certificate POST /v1/{crn}/zones/{domain_id}/ssl/certificate_packs internet-svcs.security.manage internet-svcs.certificate-packs.create \n Delete an edge certificate DELETE /v1/{crn}/zones/{domain_id}/ssl/certificate_packs/{cert_id} internet-svcs.security.manage internet-svcs.certificate-packs.delete \n Get uploaded certificates GET /v1/{crn}/zones/{domain_id}/custom_certificates internet-svcs.security.read internet-svcs.custom-certificates.read \n Upload a certificate to CIS edge POST /v1/{crn}/zones/{domain_id}/custom_certificates internet-svcs.security.manage internet-svcs.custom-certificates.create \n Update the certificate uploaded to CIS edge PATCH /v1/{crn}/zones/{domain_id}/custom_certificates/{cert_id} internet-svcs.security.update internet-svcs.custom-certificates.update \n Delete a certificate uploaded to CIS edge DELETE /v1/{crn}/zones/{domain_id}/custom_certificates/{cert_id} internet-svcs.security.manage internet-svcs.custom-certificates.delete \n Get origin certificate issued by CIS GET /v1/{crn}/zones/{domain_id}/origin_certificates internet-svcs.security.read internet-svcs.origin-certificates.read \n Create an origin certificate issued by CIS POST /v1/{crn}/zones/{domain_id}/origin_certificates internet-svcs.security.manage internet-svcs.origin-certificates.create", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-at_iam_CIS"}, {"document_id": "ibmcld_04111-13789-15438", "score": 29.913574806401964, "text": "\nDelete a certificate uploaded to CIS edge DELETE /v1/{crn}/zones/{domain_id}/custom_certificates/{cert_id} internet-svcs.security.manage internet-svcs.custom-certificates.delete \n Get origin certificate issued by CIS GET /v1/{crn}/zones/{domain_id}/origin_certificates internet-svcs.security.read internet-svcs.origin-certificates.read \n Create an origin certificate issued by CIS POST /v1/{crn}/zones/{domain_id}/origin_certificates internet-svcs.security.manage internet-svcs.origin-certificates.create \n Revoke an origin certificate issued by CIS DELETE /v1/{crn}/zones/{domain_id}/origin_certificates/{cert_id} internet-svcs.security.manage internet-svcs.origin-certificates.delete \n\n\n\n\n\n\n\n Edge Functions \n\n\n\nTable 15. Edge Functions\n\n Action Method IAM ACTION AT ACTION \n\n Get edge function scripts GET /v1/{crn}/workers/scripts internet-svcs.performance.read internet-svcs.edge-functions-scripts.read \n Create edge function script POST /v1/{crn}/workers/scripts internet-svcs.performance.manage internet-svcs.edge-functions-scripts.create \n Update edge function script PUT /v1/{crn}/workers/scripts/{script_name} internet-svcs.performance.update internet-svcs.edge-functions-scripts.update \n Delete edge function script DELETE /v1/{crn}/workers/scripts/{script_name} internet-svcs.performance.manage internet-svcs.edge-functions-scripts.delete \n Get edge function routes GET /v1/{crn}/zones/{domain_id}/workers/routes internet-svcs.performance.read internet-svcs.edge-functions-routes.read \n Create edge function route POST /v1/{crn}/zones/{domain_id}/workers/routes internet-svcs.performance.manage internet-svcs.edge-functions-routes.create", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-at_iam_CIS"}, {"document_id": "ibmcld_05440-4287-5611", "score": 28.510534281944253, "text": "\nIn Code Engine, [create a custom domain mapping](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappings) for your app.\n3. Set up an instance of [Cloud Internet Services (CIS)](https://cloud.ibm.com/catalog/services/internet-services) to manage your custom domain.\n4. [Add the custom domain to the CIS instance](https://cloud.ibm.com/docs/cis?topic=cis-multi-domain-support).\n5. [Configure a global load balancer](https://cloud.ibm.com/docs/cis?topic=cis-configure-glb) in CIS.\n6. [Enable the HTTP proxy mode for the load balancer](https://cloud.ibm.com/docs/cis?topic=cis-proxy-modes) in CIS. This activates DDoS protection on Layer 7 and other CIS security features.\n7. In Code Engine, turn off the public system provided domain mappings of your application. Go to your application, from the Domain mapping tab for your app, select No external system domain mapping.\n8. Click Create to save the application revision.\n\n\n\nFor more information about DDoS in CIS, see [Dealing with Distributed Denial of Service attacks in CIS](https://cloud.ibm.com/docs/cis?topic=cis-distributed-denial-of-service-ddos-attack-concepts). For more ways to address Layer 7 attacks, see [Mitigating Layer 7 attacks in CIS](https://cloud.ibm.com/docs/cis?topic=cis-about-ibm-cloud-internet-services-ciscis-mitigate-layer7-attacks).", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-secure"}, {"document_id": "ibmcld_05353-18865-20445", "score": 28.48674428452326, "text": "\nTo obtain the CNAME record with the CLI, use the [ibmcloud ce domainmapping get](https://cloud.ibm.com/docs/codeengine?topic=codeengine-clicli-domainmapping-get) command. For example,\n\nibmcloud ce domainmapping get --domain-name www.example.com\n\nExample output\n\nGetting domain mapping 'www.example.com'...\nOK\n\nDomain Name: www.example.com\nCNAME: custom.abcdabcdabc.us-south.codeengine.appdomain.cloud\nTarget Name: myapp\nTarget Type: app\nTLS Secret: mytlssecret\nStatus: ready\n\nAfter you have the CNAME target, you are ready to add the CNAME record entry to the DNS settings of your custom domain. Note that publishing of the CNAME record with the domain registrar can take some time to populate the DNS changes in the internet.\n\n\n\n\n\n How can I use Cloud Internet Services (CIS) with custom domain mapping? \n\nYou cannot use the CIS TLS encryption mode of End-to-End flexible with Code Engine custom domain mappings because this mode uses self-signed certificates that are not allowed. Instead, you can use the default TLS encryption mode of [End-to-End CA signed](https://cloud.ibm.com/docs/cis?topic=cis-cis-tls-optionstls-encryption-modes-end-to-end-ca-signed). If you use the CIS TLS mode of End-to-End-flexible, you can switch to use the CIS TLS End-to-End CA signed mode, and obtain a CA signed certificate that is created outside of Cloud Internet Services (CIS).\n\n\n\n1. Create the TLS/SSL certificate outside of CIS. See [How can I obtain a certificate for my custom domain?](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappingsprepare-custom-domain-cert)\n2.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappings"}, {"document_id": "ibmcld_05440-3062-4677", "score": 27.74812043929156, "text": "\nUse secrets to store sensitive information You can store information, such as passwords and SSH keys in a secret. For more information, see [Working with secrets](https://cloud.ibm.com/docs/codeengine?topic=codeengine-secret). \n\n\n\n\n\n Supported TLS versions and cipher suites \n\nThe Code Engine API and application endpoints support transport layer security (TLS) 1.2 (or higher) and the following cipher suites.\n\n\n\n TLS cipher suites \n\n\n\n* ECDHE-ECDSA-AES128-GCM-SHA256\n* ECDHE-ECDSA-AES256-GCM-SHA384\n* ECDHE-RSA-AES128-GCM-SHA256\n* ECDHE-RSA-AES256-GCM-SHA384\n* ECDHE-ECDSA-CHACHA20-POLY1305\n* ECDHE-RSA-CHACHA20-POLY1305\n\n\n\n\n\n\n\n\n\n DDoS protection \n\nCode Engine provides out-of-the-box DDoS protection for your application. Code Engine's DDoS protection is provided by Cloud Internet Services (CIS) at no additional cost to you.\n\nDDoS protection covers System Interconnection (OSI) Layer 3 and Layer 4 (TCP/IP) protocol attacks, but not Layer 7 (HTTP) attacks.\n\nTo address Layer 7 attacks, you can take the following steps so that your traffic runs through a secure route using your custom domain and is no longer available to the public internet through the Code Engine provided domain.\n\n\n\n1. Obtain your custom domain.\n2. In Code Engine, [create a custom domain mapping](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappings) for your app.\n3. Set up an instance of [Cloud Internet Services (CIS)](https://cloud.ibm.com/catalog/services/internet-services) to manage your custom domain.\n4. [Add the custom domain to the CIS instance](https://cloud.ibm.com/docs/cis?topic=cis-multi-domain-support).", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-secure"}, {"document_id": "ibmcld_04186-9163-11063", "score": 27.387734129078908, "text": "\n* [Configure the Ingress for the DNS subdomain](https://cloud.ibm.com/docs/cis?topic=cis-multi-region-k8s-cismulti-region-k8s-cis-ingress)\n\n\n\n\n\n\n\n Step 3: Configure multi-location load-balancing \n\nYour application is now running in two clusters but it is missing one component for the users to access either clusters transparently from a single entry point.\n\nIn this section, you will configure IBM Cloud Internet Services (CIS) to distribute the load between the two clusters. CIS is a one stop-shop service providing Global Load Balancer (GLB), Caching, Web Application Firewall (WAF) and Page rule to secure your applications while ensuring the reliability and performance for your Cloud applications.\n\nTo configure a global load balancer, you will need:\n\n\n\n* to point a custom domain to CIS name servers,\n* to retrieve the Ingress Subdomain of the Kubernetes clusters,\n* to configure health checks to validate the availability of your application,\n* and to define origin pools pointing to the clusters.\n\n\n\n\n\n Register a custom domain with IBM Cloud Internet Services \n\nThe first step is to create an instance of CIS and to point your custom domain to CIS name servers.\n\n\n\n1. If you do not own a domain, you can buy one from a registrar.\n2. Navigate to [IBM Cloud Internet Services](https://cloud.ibm.com/catalog/services/internet-services) in the IBM Cloud catalog.\n3. Set the service name, and click Create to create an instance of the service.\n4. When the service instance is provisioned, click on Add domain.\n5. Enter your domain name and click Next.\n6. Setup your DNS records is an optional step and can be skipped for this tutorial. click on Next\n7. When the name servers are assigned, configure your registrar or domain name provider to use the name servers listed.\n8. After you've configured your registrar or the DNS provider, it may require up to 24 hours for the changes to take effect.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-multi-region-k8s-cis"}, {"document_id": "ibmcld_05351-7020-8692", "score": 27.072848767711413, "text": "\nSet the Monitor type to HTTPS and the Port to 443.\n5. Accept the defaults for the rest of the options. Note that if you are using an app other than codeengine/helloworld app, adjust any options that your app requires.\n6. Click Create.\n\n\n\nFor more information, see [Setting up health checks](https://cloud.ibm.com/docs/cis?topic=cis-glb-features-healthchecks).\n\n\n\n\n\n Step 7: Configure the Cloud Internet Services (CIS) load-balancer \n\nAfter your custom domain mappings are in a Ready state, configure the Cloud Internet Services (CIS) load-balancer for your application global endpoint. For more information, see [Configuring a global load balancer](https://cloud.ibm.com/docs/cis?topic=cis-configure-glb).\n\n\n\n1. Go to the Reliability page in the Cloud Internet Services (CIS) console.\n2. Select Origin pools and click Create.\n\n\n\n1. Name your pool global-app-au-syd.\n2. Set the Origin address to the CNAME target of your domain name mapping.\n3. Set the Host header to your domain name.\n4. From the Health check, select Existing health check and then select global-app.\n5. Click Save.\n6. Repeat these steps for each region that contains your deployed app. Change the name to reflect the region that you are targeting. For example, global-app-de-eu and global-app-br-sao.\n\n\n\n3. Select Load balancers and click Create.\n\n\n\n1. Name your load balancer. Note that this name appears in your custom domain URL. For example, if your custom domain is global-app.example.com and you name your load balancer global-app, your URL is global-app.example.com.\n2. Set Traffic steering to Geo.\n3. Add your Geo routes. You can choose to create a route for all CIS regions or only some regions.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-deploy-multiple-regions"}, {"document_id": "ibmcld_05351-7-1916", "score": 27.01183423323585, "text": "\nConfiguring a highly available application \n\nYou can deploy your IBM Cloud\u00ae Code Engine application across multiple regions to make it resilient to regional failures. Note that this example uses [IBM Cloud Internet Services](https://cloud.ibm.com/docs/cis?topic=cis-getting-started), but you can use alternate providers. This example also uses a custom domain.\n\n\n\n Prerequisites \n\n\n\n* You must have a custom domain name for your application, such as example.com. This domain name is used by your Code Engine application.\n* Set up an instance of [Cloud Internet Services (CIS)](https://cloud.ibm.com/catalog/services/internet-services).\n* [Add your domain name to Cloud Internet Services (CIS)](https://cloud.ibm.com/docs/cis?topic=cis-getting-startedadd-configure-your-domain). When you register your domain name with Cloud Internet Services (CIS), you are delegating control of your domain name to Cloud Internet Services (CIS). Note that this step can take a while to complete.\n\n\n\n\n\n\n\n Step 1: Create projects in different regions \n\nCreate a Code Engine project in three different regions. You can use a common naming pattern and a shared tag.\n\nFor example, create a project called global-app-project in the au-syd, eu-de, and br-sao regions with either the CLI or from the console.\n\n\n\nTable 1. Projects in multiple regions\n\n Name Status Tag Location Resource group Created \n\n global-app-project Ready global-app Sydney (au-syd) default \n global-app-project Ready global-app Frankfurt (eu-de) default 2 min \n global-app-project Ready global-app Sao Paulo (br-sao) default 3 min \n\n\n\nFor more information, see [Managing projects](https://cloud.ibm.com/docs/codeengine?topic=codeengine-manage-project).\n\n\n\n\n\n Step 2: Deploy your apps in multiple regions \n\nNow that your projects are created in multiple regions, deploy your application in each project.\n\nFor example, deploy the codeengine/helloworld app.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-deploy-multiple-regions"}, {"document_id": "ibmcld_13234-11167-13184", "score": 26.920198771536505, "text": "\nCIS provides Global Load Balancer (GLB), Caching, Web Application Firewall (WAF) and Page rule to secure your applications while ensuring the reliability and performance for your cloud applications.\n\nTo configure a global load balancer, you will need:\n\n\n\n* to point a custom domain to CIS name servers,\n* to retrieve the IP addresses or hostnames of the VPC load balancers,\n* to configure health checks to validate the availability of your application,\n* and to define origin pools pointing to the VPC load balancers.\n\n\n\n\n\n Add a custom domain to IBM Cloud Internet Services \n\nThe first step is to create an instance of CIS and to point your custom domain to CIS name servers.\n\n\n\n1. If you do not own a domain, you can buy one from a registrar.\n2. Navigate to [IBM Cloud Internet Services](https://cloud.ibm.com/catalog/services/internet-services) in the IBM Cloud catalog.\n3. Set the service name, and click Create to create an instance of the service.\n4. When the service instance is provisioned, click on Add domain.\n5. Enter your domain name and click Next.\n6. Setup your DNS records is an optional step and can be skipped for this tutorial. click on Next.\n7. When the name servers are assigned, configure your registrar or domain name provider to use the name servers listed.\n8. At this point you can click on Cancel to get back to the main page, after you've configured your registrar or the DNS provider, it may require up to 24 hours for the changes to take effect.\n\nWhen the domain's status on the Overview page changes from Pending to Active, you can use the dig <your_domain_name> ns command to verify that the new name servers have taken effect.\n\n\n\n\n\n\n\n Configure Health Check for the Global Load Balancer \n\nA health check helps gain insight into the availability of pools so that traffic can be routed to the healthy ones. These checks periodically send HTTP/HTTPS requests and monitor the responses.\n\n\n\n1. In the IBM Cloud Internet Services dashboard, navigate to Reliability > Global Load Balancers.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-vpc-multi-region"}, {"document_id": "ibmcld_16079-11208-13225", "score": 26.920198771536505, "text": "\nCIS provides Global Load Balancer (GLB), Caching, Web Application Firewall (WAF) and Page rule to secure your applications while ensuring the reliability and performance for your cloud applications.\n\nTo configure a global load balancer, you will need:\n\n\n\n* to point a custom domain to CIS name servers,\n* to retrieve the IP addresses or hostnames of the VPC load balancers,\n* to configure health checks to validate the availability of your application,\n* and to define origin pools pointing to the VPC load balancers.\n\n\n\n\n\n Add a custom domain to IBM Cloud Internet Services \n\nThe first step is to create an instance of CIS and to point your custom domain to CIS name servers.\n\n\n\n1. If you do not own a domain, you can buy one from a registrar.\n2. Navigate to [IBM Cloud Internet Services](https://cloud.ibm.com/catalog/services/internet-services) in the IBM Cloud catalog.\n3. Set the service name, and click Create to create an instance of the service.\n4. When the service instance is provisioned, click on Add domain.\n5. Enter your domain name and click Next.\n6. Setup your DNS records is an optional step and can be skipped for this tutorial. click on Next.\n7. When the name servers are assigned, configure your registrar or domain name provider to use the name servers listed.\n8. At this point you can click on Cancel to get back to the main page, after you've configured your registrar or the DNS provider, it may require up to 24 hours for the changes to take effect.\n\nWhen the domain's status on the Overview page changes from Pending to Active, you can use the dig <your_domain_name> ns command to verify that the new name servers have taken effect.\n\n\n\n\n\n\n\n Configure Health Check for the Global Load Balancer \n\nA health check helps gain insight into the availability of pools so that traffic can be routed to the healthy ones. These checks periodically send HTTP/HTTPS requests and monitor the responses.\n\n\n\n1. In the IBM Cloud Internet Services dashboard, navigate to Reliability > Global Load Balancers.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-multi-region"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08435-1255-3053", "score": 42.83291273917013, "text": "\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_08435-8253-9823", "score": 40.10450402812201, "text": "\nDuring this 7-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>/actions/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_08211-1158-3123", "score": 39.3623363395985, "text": "\nibmcloud hpvs instance-delete CRN --force\n\n\n\nWhere CRN is Cloud resource name of the server you want to delete. Use --force to force the deletion of the Hyper Protect Virtual Servers instance without showing a confirmation prompt.\n\nYou can find more information and example output [here](https://cloud.ibm.com/docs/hpvs-cli-pluginhpvs-instance-delete).\n\n\n\n\n\n What happens during the reclamation period \n\nWhen you delete a virtual server from the resource list, the server isn't deleted immediately, it's stopped and marked for deletion, and a reclamation period of seven days starts. The server is deleted after the reclamation period ends. During this seven-day reclamation period, you can restore the virtual server, or manually trigger a deletion from [resource reclamations](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_commands_resourceibmcloud_resource_reclamations). Resource reclamations lists the Hyper Protect Virtual Servers that are marked for deletion together with the time (Target time) when the actual deletion is triggered.\n\n\n\n\n\n Deleting servers that belong to the free plan \n\nThe free plan servers expire 30 days after they are created. When a server expires, it's immediately deleted at the backend. The server is also deleted at the backend if it expires during the seven-day reclamation period. Even though the server is deleted at the backend, it's still displayed in the resource list or in the resource reclamations as if it still exists.\n\nIf the server has expired, you can remove the entry from the resource list and either:\n\n\n\n* Wait for the target time to trigger deletion for you, or\n* Manually trigger the deletion from the resource reclamations.\n\n\n\nIf an expired server is restored, only the entry within the resource list is restored, not the server itself.\n\n\n\n\n\n Restoring servers that belong to paid plans \n\nServers that belong to a paid plans do not expire, and that's why they can be restored during the reclamation period.", "title": "", "source": "https://cloud.ibm.com/docs/hp-virtual-servers?topic=hp-virtual-servers-remove_vs"}, {"document_id": "ibmcld_08435-6973-8664", "score": 37.13399108314764, "text": "\nYour IBM Cloud access token. Include the full contents of the IAM token, including the Bearer value, in the cURL request. For more information, see [Retrieving an access token](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Hyper Protect Crypto Services instance. For more information, see [Retrieving an instance ID](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys) by using the IBM Cloud console or key management service API.\n\nIf you need to prevent the deletion of a key that is already authorized for deletion, you can remove the existing authorization by calling POST /api/v2/keys/<key_ID>/actions/unsetKeyForDeletion.\n\n\n\n\n\n\n\n Step 2. Delete the key \n\nAfter you set a key for deletion, a second user with a Manager access policy can safely delete the key.\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_12448-7795-9977", "score": 36.33082341420328, "text": "\nAfter it is restored, you must upgrade your plan within 1 hour or it will be deleted again.\n\nThe Secrets Manager data retention policy describes how long your data is stored after you delete the service. The data retention policy is included in the Secrets Manager service description, which you can find in the [IBM Cloud Terms and Notices](https://cloud.ibm.com/docs/overview?topic=overview-terms).\n\n\n\n Deleting a Secrets Manager instance \n\nIf you no longer need an instance of Secrets Manager, you can delete the service instance and any data that is stored. Your instance enters a disabled state, and after 7 days its data is permanently deleted. You can also choose to delete your service instance by using the console.\n\nDuring the 7-day reclamation period, do not delete authorizations between Secrets Manager and other integrated services, such as Key Protect. Secrets Manager uses the authorization to unregister your instance from any associated resources in those services. After the instance is permanently deleted, the authorization is also deleted by IAM.\n\n\n\n1. Delete the service and place it in a reclamation period of 7 days.\n\nibmcloud resource service-instance-delete \"<instance_name>\"\n\nReplace <instance_name> with the name of the Secrets Manager instance that you want to delete.\n2. Optional: To permanently delete your instance, get the reclamation ID.\n\nibmcloud resource reclamations --resource-instance-id <instance_ID>\n\nReplace <instance_ID> with your Secrets Manager instance ID.\n\nIf you choose to permanently delete the instance by deleting its reclamation, you cannot restore your data.\n3. Optional: Permanently delete the reclamation instance.\n\nibmcloud resource reclamation-delete <reclamation_ID>\n\nReplace <reclamation_ID> with the value that you retrieved in the previous step.\n\n\n\n\n\n\n\n Restoring a deleted service instance \n\nIf you haven't permanently deleted your instance, you can restore it during the 7-day reclamation period.\n\n\n\n1. View which service instances are available for restoration.\n\nibmcloud resource reclamations\n\nFrom the list of available instances, copy the reclamation ID of the Secrets Manager instance that you want to restore.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-mng-data"}, {"document_id": "ibmcld_08435-3634-5079", "score": 35.5728669154276, "text": "\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_09061-12083-13778", "score": 33.864001648405036, "text": "\nFor more information about deleting and purging keys, check out [About deleting and purging keys](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keys).\n\nThe following table lists which APIs you can use to retrieve data related to a deleted key.\n\n\n\nTable 4. Lists the API that users can use to view details about a key and its registrations.\n\n API Description \n\n [Get key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-retrieve-key) Retrieve key details \n [Get key metadata](https://cloud.ibm.com/docs/key-protect?topic=key-protect-retrieve-key-metadata) Retrieve key metadata \n [Get registrations](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) Retrieve a list of registrations associated with the key \n\n\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the seven-day authorization period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>/actions/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/key-protect?topic=key-protect-set-up-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Key Protect service actions, check out [Service access roles](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-accessmanage-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_08435-4-1684", "score": 33.65749455528067, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_09061-6176-7874", "score": 33.55360756902776, "text": "\n<br> <br>For more information, see [Retrieving an access token](https://cloud.ibm.com/docs/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br>For more information, see [Retrieving an instance ID](https://cloud.ibm.com/docs/key-protect?topic=key-protect-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) by using the Key Protect GUI or API.\n\nIf you need to prevent the deletion of a key that's already authorized for deletion, you can remove the existing authorization by calling POST /api/v2/keys/<keyID_or_alias>/actions/unsetKeyForDeletion.\n\n\n\n Delete the key \n\nAfter you set a key for deletion, another user with a Manager access policy can safely delete the key by using the Key Protect GUI or API.\n\nKey Protect sets a seven-day authorization period that starts after you provide the first authorization to delete the key. During this seven-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-states) and all key operations are allowed on the key. If no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_12566-4-1791", "score": 31.37078037543425, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Auditing access policies \n\nTo reduce the number of policies in the account and keep only the minimum access that is necessary for each user, you can identify the infrequently used access policies. You can determine whether to remove them, or in some cases, you might expect an infrequently used policy.\n\nIAM captures authorization information for each policy. This information includes the last time that the policy was used to grant a permit and a running count of its use.\n\n\n\n Managing inactive policies in the console \n\nThe inactive policies report shows policies that haven't permitted access in the last 30 days or longer. Policies that have never permitted access are not included.\n\nTo view inactive policies, you need the Editor role or higher on the AM Insight service, the IAM Access Management service, or on All Account Management services.\n\nTo manage inactive policies in the console, complete the following steps:\n\n\n\n1. In the IBM Cloud console, click Manage > Access (IAM), and select Inactive policies.\n2. Determine whether you can remove the inactive policies in the report.\n3. To delete inactive policies, click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/d4595e5202a9a27767cf034e81b038cdf772e0d5/secure-enterprise/includes/account/includes/icons/action-menu-icon.svg) > Remove.\n\n\n\nWhen you delete a policy, it's no longer included for authorization evaluations. IAM keeps a copy of all deleted policies for 10 days. During this time period, you can list and restore them at any time. To restore a deleted policy, see [Restoring deleted policies by using the API](https://cloud.ibm.com/docs/account?topic=account-iam-audit-policies&interface=apiiam-audit-policies-restore).\n\n\n\n\n\n Exporting user access policy reports", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-iam-audit-policies"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16464-4463-6317", "score": 43.706510465332805, "text": "\nOn the Machine Learning Model > Pre-annotation > Dictionaries tab, click Apply This Pre-annotator.\n4. Select the document set that you created in [Lesson 1](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introtut_lessml1).\n5. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\n> Note: In a realistic scenario, you would create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16563-4292-6145", "score": 41.34707676366025, "text": "\nSelect the document set that you created in [Lesson 1](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_introtut_lessml1).\n6. Click Run.\n\n\n\n\n\n\n\n Results \n\nThe documents in the selected sets are pre-annotated by using the dictionary that you created. If you like, you can use the dictionary to pre-annotate document sets or annotation sets that you add later.\n\n\n\n\n\n\n\n Lesson 3: Creating an annotation task \n\nIn this lesson, you will learn how to create annotation sets and use annotation tasks to track the work of human annotators in Knowledge Studio.\n\n\n\n About this task \n\nAn annotation set is a subset of documents from an uploaded document set that you assign to a human annotator. The human annotator annotates the documents in the annotation set. To later use inter-annotator scores to compare the annotations that are added by each human annotator, you must assign at least two human annotators to different annotation sets. You must also specify that some percentage of documents overlap between the sets.\n\nIn a realistic scenario, you create as many annotation sets as needed, based on the number of human annotators who are working in the workspace. In this tutorial, you will create two annotation sets. If you do not have access to multiple user IDs, you can assign both annotation sets to the same user.\n\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3. Specify the details for the task:\n\n\n\n* In the Task name field, enter Test.\n* In the Deadline field, select a date in the future.\n\n\n\n4.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}, {"document_id": "ibmcld_16410-5205-7359", "score": 40.20486336101095, "text": "\nAdjustments can be made repeatedly to improve performance until a satisfactory level of accuracy is achieved.\n\n\n\n\n\n Model deployment \n\nThis stage refers to exporting components that enable the model to run in machine learning runtime environments and making the model accessible to other Watson cognitive applications. For example, you can export the machine learning model for use by IBM Watson\u2122 Natural Language Understanding for IBM Cloud Pak\u00ae for Data or IBM Watson\u2122 Discovery for IBM Cloud Pak\u00ae for Data\n\n\n\n\n\n\n\n Creating an annotation task \n\nBefore human annotators begin adding annotations to documents, the annotation process manager can optionally create an annotation task.\n\nAdmins and project managers can annotate ground truth document sets directly. See [Annotating document sets directly](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotating-document-sets-directly).\n\n\n\n About this task \n\nThe annotation task specifies which documents are to be annotated. To compare how well the human annotators perform, and to see how consistently they apply the annotation guidelines, you must include at least two human annotators in the task. In addition, some percentage of documents must occur in all of the annotation sets that you add to the task (you specify the overlap percentage when you create the annotation sets).\n\n\n\n Important \n\n\n\n* An annotation task is a temporal concept that exists to allow human annotators to annotate text in isolated spaces. It also ensures that annotations must be approved before they are promoted to ground truth.\n* An annotation set can be included in one active task at a time. To add an annotation set in one task to a different task, you must first delete the task where the annotation set is active.\n* If you delete a human annotator's user account, it affects their annotations too. Any annotations in documents that were assigned to that user but were not promoted to ground truth are deleted.\n* If the type system or ground truth editor settings change after you create a human annotation task, you must decide whether to propagate the changes to the task.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"}, {"document_id": "ibmcld_16410-8324-10312", "score": 39.27476189812386, "text": "\nInter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set.\n\nYou cannot change the annotation set name after the set is created.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.\n* Open a task to add annotation sets to it. Ensure that the annotation sets that you add include documents that overlap with documents in the original annotation sets.\n\n\n\nFrom the Settings tab of the main navigation, you can specify the following information:\n\n\n\n* Specify preferences for using colors and keyboard shortcuts in the ground truth editor.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documents"}, {"document_id": "ibmcld_16468-8522-10510", "score": 39.11496038814089, "text": "\nIf no annotation sets are available, click Create Annotation Sets.\n\n\n\n1. For the base set, select the document set or annotation set that you want to divide into annotation sets.\n2. For the overlap value, specify the percentage of documents that you want to include in each annotation set. Inter-annotator agreement scores cannot be calculated unless two or more human annotators annotate the same documents. For example, if you specify a 20% overlap value for a corpus that contains 30 documents, and you divide the corpus into 3 document sets, 6 documents (20%) will be annotated by all human annotators. The remaining 24 documents will be divided among the 3 human annotators (8 each). Thus, each annotator receives 14 documents to annotate (6+8).\n\n\n\nAn annotation set that you plan to use to train a machine learning model must contain at least 10 annotated documents.\n\n\n\n1. Select a user name from the list of human annotators.\n2. Name the annotation set.\n\nAs a good practice for evaluating a human annotator's work as the workspace progresses, you might want to create annotation set names that identify the human annotator assigned to the set. You cannot change the annotation set name after the set is created.\n\nThe maximum size of the annotation set name is 256 characters.\n3. Click Generate.\n\n\n\n6. A list of available annotation sets is displayed under Available Sets, along with the names of the human annotators assigned to them. To add available sets to your annotation task, click Add to task.\n7. Make sure that all of the annotation sets that you want to include in the task appear under Selected Sets, then click Save to create the task.\n\n\n\n\n\n\n\n What to do next \n\nAfter the task is created, you can return to the Annotation Tasks tab on the Machine Learning Model > Annotations page to view the progress of each human annotator. Also, you can complete the following tasks:\n\n\n\n* Check approved documents that overlap between annotation sets to resolve annotation conflicts.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-annotate-documents"}, {"document_id": "ibmcld_16464-8477-10131", "score": 38.22073373659213, "text": "\nLog in to Knowledge Studio as a user who is assigned to the annotation task that you created in [Lesson 3](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introwks_tutless_ml2).\n\n> Note: If you have access only to a single administrator ID for this tutorial, you can use that ID to perform human annotation. However, remember that in a realistic scenario, human annotation is performed by different users with the Human Annotator role.\n2. Open the My workspace workspace and click Machine Learning Model > Annotations.\n3. Click the Annotation Tasks tab, then open the Test annotation task you created in [Lesson 3](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introwks_tutless_ml2).\n4. Click Annotate for one of the assigned annotation sets.\n\nDepending on how you set up the annotation tasks, you could have one or more annotation tasks assigned to the user ID you logged in with.\n5. From the list of documents, find the Technology - gmanews.tv document and open it.\n\nNotice that the term IBM was already annotated with the ORGANIZATION entity type. This annotation was added by the dictionary pre-annotator that was applied in [Lesson 2](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_introwks_tutless_ml3). This pre-annotation is correct, so it does not need to be modified.\n\n![This screen capture shows an open document with an existing pre-annotation for \"IBM\".](images/wks_tut_preannotation.png \"This screen capture shows an open document with an existing pre-annotation for \"IBM\".\")\n6.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16464-5948-7556", "score": 38.101223433205774, "text": "\nFor more information about annotation sets and annotation tasks, see [Creating an annotation task](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-annotate-documentswks_hatask).\n\n\n\n\n\n Procedure \n\n\n\n1. Within your workspace, click Machine Learning Model > Annotations.\n2. Click the Annotation Tasks tab, then click Add Task.\n3. Specify the details for the task:\n\n\n\n* In the Task name field, enter Test.\n* In the Deadline field, select a date in the future.\n\n\n\n4. Click Create Annotation Sets.\n\nThe Create Annotation Sets window opens. By default, this window shows the base set, which contains all documents, and fields where you can specify the information for a new annotation set.\n5. Click Add another set and human annotator to add fields for an additional annotation set. You can click to add as many annotation sets as you want to create. For this tutorial, you need only two annotation sets.\n\n![A screen capture of the Create Annotation Sets page.](https://cloud.ibm.com/docs-content/v1/content/148d3bd95f946aa1bb53ea1540475f522e6b61c9/watson-knowledge-studio-data/images/wks_tutdocset2.png)\n6. In the Overlap field, specify 100. This value specifies that you want 100 percent of the documents in the base set to be included in all the new annotation sets so they can be annotated by all human annotators.\n7. For each new annotation set, specify the required information.\n\n\n\n* In the Annotator field, select a human annotator user ID to assign to the new annotation set. In a realistic scenario, each annotation set is assigned to a different human annotator.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16456-14956-16896", "score": 37.66738935137736, "text": "\nTo annotate repeating mentions:\n\n\n\n1. Log in as a human annotator (or as an administrator or project manager who was assigned documents to annotate). Workspaces that contain tasks that are assigned to you are displayed.\n2. Open a workspace, and then click Machine Learning Model > Annotations. Click the Annotation Tasks tab. The annotation tasks that are assigned to you are displayed.\n3. Open the annotation task that you want to work on. The annotation sets that are assigned to you are displayed.\n4. Click Annotate to open the annotation set you want to work on. The documents in the annotation set are displayed.\n5. Open the document that you want to annotate. By default, the document opens in Mention mode, which is the mode you use to annotate entity mentions.\n6. If you have not added any annotations yet, add at least one annotation. Select a word or word phrase that represents a mention of an entity type from your type system, and assign the appropriate type to it. Click Save to save your annotation.\n7. Select a single occurrence of repeating text that you want to annotate, and then click Concordance.\n8. Select the documents that you want to apply the selected entity type to. You can create the annotations in all documents that you have been assigned to annotate, all documents that you have begun annotating, or all documents that you have not yet started to annotate.\n9. Click Preview to see the annotations that will be added.\n\nIf you want to view the annotations in greater context, click the icons to preview the document content or open the document in a new window.\n10. Click Apply & Review to apply the selected entity types to mentions in the selected documents. You still have a chance to review the annotations that will be added. If an annotation is inaccurate in a particular context, you can remove that occurrence by clicking the Edit icon, and then removing the entity type assignment for the mention.\n11.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide"}, {"document_id": "ibmcld_16530-14956-16896", "score": 37.66738935137736, "text": "\nTo annotate repeating mentions:\n\n\n\n1. Log in as a human annotator (or as an administrator or project manager who was assigned documents to annotate). Workspaces that contain tasks that are assigned to you are displayed.\n2. Open a workspace, and then click Machine Learning Model > Annotations. Click the Annotation Tasks tab. The annotation tasks that are assigned to you are displayed.\n3. Open the annotation task that you want to work on. The annotation sets that are assigned to you are displayed.\n4. Click Annotate to open the annotation set you want to work on. The documents in the annotation set are displayed.\n5. Open the document that you want to annotate. By default, the document opens in Mention mode, which is the mode you use to annotate entity mentions.\n6. If you have not added any annotations yet, add at least one annotation. Select a word or word phrase that represents a mention of an entity type from your type system, and assign the appropriate type to it. Click Save to save your annotation.\n7. Select a single occurrence of repeating text that you want to annotate, and then click Concordance.\n8. Select the documents that you want to apply the selected entity type to. You can create the annotations in all documents that you have been assigned to annotate, all documents that you have begun annotating, or all documents that you have not yet started to annotate.\n9. Click Preview to see the annotations that will be added.\n\nIf you want to view the annotations in greater context, click the icons to preview the document content or open the document in a new window.\n10. Click Apply & Review to apply the selected entity types to mentions in the selected documents. You still have a chance to review the annotations that will be added. If an annotation is inaccurate in a particular context, you can remove that occurrence by clicking the Edit icon, and then removing the entity type assignment for the mention.\n11.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-user-guide"}, {"document_id": "ibmcld_16464-7-2089", "score": 37.50157252812847, "text": "\nCreating a machine learning model \n\nThis tutorial helps you understand the process for building a machine learning model that you can deploy and use with other Watson services.\n\n\n\n Learning objectives \n\nAfter you complete the lessons in this tutorial, you will know how to perform the following tasks:\n\n\n\n* Create document sets\n* Pre-annotate documents\n* Create tasks for human annotators\n* Analyze inter-annotator agreement and adjudicate conflicts in annotated documents\n* Create machine learning models\n\n\n\nThis tutorial takes approximately 60 minutes to finish. If you explore other concepts that are related to this tutorial, it might take longer to complete.\n\n\n\n\n\n Before you begin \n\n\n\n* You're using a supported browser. See [Browser requirements](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-system-requirements).\n* You successfully completed [Getting started with Knowledge Studio](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutintro), which covers creating a workspace, creating a type system, and adding a dictionary.\n* You must have at least one user ID in either the Admin or Project Manager role.\n\n> Note: If possible, use multiple user IDs for the machine learning model tasks in this tutorial (one Admin or Project Manager user ID, and at least two Human Annotator user IDs). Using multiple user IDs provides the most realistic simulation of an actual IBM Watson\u2122 Knowledge Studio workspace, where a project manager must coordinate and adjudicate annotation that is performed by multiple human annotators. However, if you have access to only a single user ID, you can still simulate most parts of the process.\n\nFor information about user roles, see [User roles in Knowledge Studio](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-roles).\n\n\n\n\n\n\n\n Results \n\nAfter completing this tutorial, you will have a custom machine learning model that you can use with other Watson services.\n\n\n\n\n\n Lesson 1: Adding documents for annotation", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}]}
{"task_id": "674aa142d92a6b4262de254df0c3f7b2<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_09118-10321-12086", "score": 46.550960802425664, "text": "\n[View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Natural Language Understanding](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-getting-startedgetting-started) You can use IBM Watson\u00ae Natural Language Understanding to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Personality Insights](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-about) You can use IBM Watson\u00ae Personality Insights to analyze semantic features of text input, including categories, concepts, emotion, entities, keywords, metadata, relations, semantic roles, and sentiment. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n\n\n\n\n\n\n\n Container service integrations \n\nYou can integrate Key Protect with the following container services.\n\n\n\nTable 4. Supported container services.\n\n Service Description Integration docs \n\n [IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-getting-started) You can use the IBM Cloud Kubernetes Service service to deploy highly available apps in Docker containers that run in Kubernetes clusters. [View docs](https://cloud.ibm.com/docs/containers?topic=containers-encryptionkeyprotect)", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-integrate-services"}, {"document_id": "ibmcld_09118-9294-10691", "score": 40.64698025146758, "text": "\n[Text to Speech](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-gettingStarted) You can use Text to Speech's speech-synthesis capabilities to convert written text into natural-sounding speech. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [Tone Analyzer](https://cloud.ibm.com/docs/tone-analyzer?topic=tone-analyzer-gettingStarted) You can use Tone Analyzer to detect emotional and language tones in your written texts. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [Knowledge Studio](https://cloud.ibm.com/docs/tone-analyzer?topic=tone-analyzer-gettingStarted) You can use Knowledge Studio to understand the linguistic nuances, meaning, and relationships specific to your industry. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [Watson OpenScale](https://dataplatform.cloud.ibm.com/docs/content/wsj/model/getting-started.html) You can use Watson OpenScale to automate and maintain the AI lifecycle in your business applications. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice) \n [IBM Watson\u00ae Assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-getting-startedgetting-started) You can use IBM Watson\u00ae Assistant to to build your own branded live chatbot into any device, application, or channel. [View docs](https://cloud.ibm.com/docs/watson?topic=watson-keyservice)", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-integrate-services"}, {"document_id": "ibmcld_09920-5038-6185", "score": 35.5652179439114, "text": "\nCreate a Banking Chatbot \n\nUse Node.js and Watson to detect emotion, identify entities, and discover answers.\n\n\n\n* [Learn more ![External link icon](https://cloud.ibm.com/docs-content/v1/content/icons/launch-glyph.svg)](https://developer.ibm.com/patterns/create-cognitive-banking-chatbot/)\n* [Get the Code ![External link icon](https://cloud.ibm.com/docs-content/v1/content/icons/launch-glyph.svg)](https://github.com/IBM/watson-banking-chatbot?cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-Get-the-Code)\n* [View the Demo ![External link icon](https://cloud.ibm.com/docs-content/v1/content/icons/launch-glyph.svg)](https://www.youtube.com/watch?v=Jxi7U7VOMYg&cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-View-the-Demo)\n* [Build from a Starter Kit ![External link icon](https://cloud.ibm.com/docs-content/v1/content/icons/launch-glyph.svg)](https://console.bluemix.net/developer/watson/create-project?starterKit=a5819b41-0f6f-34cb-9067-47fd16835d04&cm_sp=dw-bluemix-_-code-_-devcenter)\n\n\n\n\n\n\n\n Enrich multimedia files using Watson services \n\nBuild an app that enriches audio and visual files using IBM Watson services.\n\n\n\n* [Learn more !", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-sample-apps"}, {"document_id": "ibmcld_09920-3951-5345", "score": 34.10017502583719, "text": "\n[External link icon](https://cloud.ibm.com/docs-content/v1/content/icons/launch-glyph.svg)](https://developer.ibm.com/patterns/snap-translate-using-tesseract-ocr-watson-language-translator/)\n* [Get the Code ![External link icon](https://cloud.ibm.com/docs-content/v1/content/icons/launch-glyph.svg)](https://github.com/IBM/snap-and-translate)\n\n\n\n\n\n\n\n Analyze product reviews and generate a shopping guide \n\nCreate a Node.js app to make cognitive decisions using product reviews evaluated by Watson Natural Language Understanding.\n\n\n\n* [Learn more ![External link icon](https://cloud.ibm.com/docs-content/v1/content/icons/launch-glyph.svg)](https://developer.ibm.com/patterns/analyze-product-reviews-and-generate-a-shopping-guide/)\n* [Get the Code ![External link icon](https://cloud.ibm.com/docs-content/v1/content/icons/launch-glyph.svg)](https://github.com/IBM/watson-second-opinion?cm_sp=Developer-_-slug-_-Get-the-Code)\n* [View the Demo ![External link icon](https://cloud.ibm.com/docs-content/v1/content/icons/launch-glyph.svg)](https://www.youtube.com/watch?v=wwNAEvbxd54)\n\n\n\n\n\n\n\n Create a Banking Chatbot \n\nUse Node.js and Watson to detect emotion, identify entities, and discover answers.\n\n\n\n* [Learn more ![External link icon](https://cloud.ibm.com/docs-content/v1/content/icons/launch-glyph.svg)](https://developer.ibm.com/patterns/create-cognitive-banking-chatbot/)\n* [Get the Code !", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-sample-apps"}, {"document_id": "ibmcld_16324-3229-5312", "score": 33.87512438578662, "text": "\nChoose a narrow set of user goals first. If you start small and choose the goals with the highest impact first, you'll have room and time to grow the expertise of your assistant. After your assistant is live, the built-in metrics of active user conversations help you understand what your customers are asking about, how well your assistant is able to meet their needs, and what to focus on next.\n\n\n\n\n\n 3. Choose the tone and language of your assistant \n\nBefore you build your assistant, it can also be helpful to choose the tone with which your assistant communicates. Is your assistant an optimist or a pessimist, a shy intellectual type, or an upbeat sidekick? Write conversations that reflect your assistant's personality. Don't overdo it by sacrificing usability for the sake of keeping your assistant in character. Strive to present a consistent tone and attitude.\n\nNever misrepresent the assistant as being a human. If users believe that the assistant is a person, then find out it's not, they are likely to distrust it. In fact, some US states have laws that require chatbots to identify themselves as chatbots.\n\nDecide whether and how you want to handle more than one spoken language. For more information about ways to approach language support, see [Adding support for global audiences](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-support).\n\n\n\n\n\n 4. Connect to content sources \n\nThe answer to common questions might already be documented somewhere in your organization's technical information. Plan whether you want to connect the assistant to existing content sources by taking an inventory of relevant help content (for example, product information, knowledge articles, FAQs) available to your customers.\n\nYou can give your assistant access to this information by adding a [search integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-add) to your assistant. The search integration uses IBM Watson\u00ae Discovery to return smart answers to natural language questions.\n\n\n\n\n\n 5. Plan your handoff strategy", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-plan-assistant"}, {"document_id": "ibmcld_03330-4-2191", "score": 33.03148096992666, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-index"}, {"document_id": "ibmcld_16233-7-2298", "score": 32.6429782278517, "text": "\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-about"}, {"document_id": "ibmcld_13160-14797-16607", "score": 31.717137679718835, "text": "\nEnd the action under And then.\n13. Create a new step with the condition for 8 Ran successfully being false. Use something like It seems there was a problem creating the new event record for the Assistant to say and end the action under And then. Save and close the action with the icons in the upper right.\n14. Test the new action by clicking on Preview on the left and using the webchat. Type add new event and submit. When prompted by the bot, enter my conference as name, home office as location, pick dates for begin and end, and use [http://localhost](http://localhost) as URL. Thereafter, confirm that the data is correct.\n\n\n\nWhen creating a chatbot, you may want to [publish a chatbot](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-publish). It is the controlled release of a version which allows rolling back changes and to continue with development without impacting the chatbot interacting with real customers.\n\n\n\n\n\n Step 6: Integrate with Slack \n\nNow, you will integrate the chatbot with Slack.\n\n\n\n1. On the lower left, click on Integrations.\n2. In the integrations overview, in the section Channels, locate Slack and click Add.\n3. Follow the step by step instructions to integrate the Draft environment of your chatbot with Slack. More information about it is available in the topic [Integrating with Slack](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-slack).\n4. Once done, open up your Slack workspace. Begin a direct chat with the bot and say show me event details. Then, similar to above, answer with Think when prompted for an event name.\n\n\n\nZoom\n\n![Slack with the eventbot](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution19/Slackbot_event.png)\n\nSlack with the eventbot", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson"}, {"document_id": "ibmcld_07223-4208-5090", "score": 30.616086690480856, "text": "\n* [View the Demo](https://www.youtube.com/watch?v=uigisF50F8s&feature=youtu.be)\n\n\n\n[Cognitive Banking Chatbot](https://developer.ibm.com/patterns/create-cognitive-banking-chatbot/?cm_sp=Developer-_-code-_-banking_chatbot) Create a web UI chatbot using the IBM Watson Node.js SDK to include conversation interaction, anger detection, natural language understanding, and answer discovery. Answers are discovered from a collection of FAQ documents. Built as a fictional financial institution, this app calls out to simple banking services code as an example of how to include external business data in a conversation response.\n\n\n\n* [Get the Code](https://github.com/IBM/watson-banking-chatbot?cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-Get-the-Code)\n* [View the Demo](https://www.youtube.com/watch?v=Jxi7U7VOMYg&cm_sp=IBMCode-_-create-cognitive-banking-chatbot-_-View-the-Demo)", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-sample-apps"}, {"document_id": "ibmcld_07148-7-2060", "score": 30.510618017750815, "text": "\nUsing the COVID-19 kit \n\nThe COVID-19 kit is a special collection available in US instances of IBM Watson\u2122 Discovery. This pre-built collection includes more than 10 data sources you can use to fuel a dynamic chatbot built with IBM Watson\u2122 Assistant and Discovery to answer your customers' questions about COVID-19.\n\nFAQ extraction is a beta feature that was used to create question and answer pairs for the kit. The FAQ extraction beta feature is now deprecated and will stop being supported in v1 Discovery service instances on 1 March 2022. As a consequence, the COVID-19 kit data collection will stop being supported also.\n\nThe COVID-19 kit extracts answers from trusted sources and automatically updates your chatbot as the content from those sources are updated. It uses FAQ extraction machine learning models developed by IBM Research labs to extract question/answer pairs. The kit is pre-configured with web crawl seeds from trusted sources such as the CDC, Harvard, and the United States Department of Labor. An expanded stopwords list and query expansions are also included in this collection to improve search results. It is designed to be augmented with your own data and customized to your needs.\n\nFor more information about this kit, and how you can create a chatbot and connect it to a data source with the IBM Watson\u2122 Assistant search skill using IBM Watson\u2122 Assistant and Discovery, see [COVID-19 \u2014 Are Your Virtual Assistant\u2019s Answers Up-To-Date?](https://medium.com/ibm-watson/covid-19-are-your-virtual-assistants-answers-up-to-date-c9e1ba70eb65654b).\n\nTo learn how to create a search skill in Watson Assistant, see [Creating a search skill](https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add). (This feature is available only to Watson Assistant Plus or Premium plan users.)\n\nSee the following to learn more about working with Discovery:\n\n\n\n* To learn how to create a service instance, see [Getting started with the Discovery tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-getting-started).", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-covidkit"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06282-17354-19397", "score": 9.57472497069661, "text": "\nWhen you create your VPC cluster, you can also attach additional security groups alongside, or instead of, the default VPC security groups. The security groups applied to the workers in the cluster are a combination of the security groups applied when you create the cluster and [when you create the worker pool](https://cloud.ibm.com/docs/containers?topic=containers-vpc-security-groupvpc-sg-worker-pool). A total of five security groups can be applied to workers, including the default security groups and any security groups applied to the worker pool. Note that these security group options are only available in the CLI.\n\nThe security groups applied to a cluster cannot be changed once the cluster is created. You can [change the rules of the security groups](https://cloud.ibm.com/docs/containers?topic=containers-vpc-security-groupvpc-sg-create-rules) that are applied to the cluster, but you cannot add or remove security groups at the cluster level. If you apply the incorrect security groups at cluster create time, you must delete the cluster and create a new one.\n\n\n\n If you only want the default VPC and cluster security groups and no additional security groups \n\nVPC security group\n\nCluster security group\n\nNote that this is the default behavior at cluster create time.\n\nWhen you create your cluster, do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the default VPC and kube-<cluster-id> cluster security groups:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id>\n\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc-security-group"}, {"document_id": "ibmcld_06284-17445-19501", "score": 9.569364147594921, "text": "\nWhen you create your VPC cluster, you can also attach additional security groups alongside, or instead of, the default VPC security groups. The security groups applied to the workers in the cluster are a combination of the security groups applied when you create the cluster and [when you create the worker pool](https://cloud.ibm.com/docs/containers?topic=containers-vpc-security-group&interface=uivpc-sg-worker-pool). A total of five security groups can be applied to workers, including the default security groups and any security groups applied to the worker pool. Note that these security group options are only available in the CLI.\n\nThe security groups applied to a cluster cannot be changed once the cluster is created. You can [change the rules of the security groups](https://cloud.ibm.com/docs/containers?topic=containers-vpc-security-groupvpc-sg-create-rules) that are applied to the cluster, but you cannot add or remove security groups at the cluster level. If you apply the incorrect security groups at cluster create time, you must delete the cluster and create a new one.\n\n\n\n If you only want the default VPC and cluster security groups and no additional security groups \n\nVPC security group\n\nCluster security group\n\nNote that this is the default behavior at cluster create time.\n\nWhen you create your cluster, do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the default VPC and kube-<cluster-id> cluster security groups:\n\nibmcloud ks cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id>\n\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc-security-group&interface=ui"}, {"document_id": "ibmcld_06294-2598-4239", "score": 9.540057142711422, "text": "\nThis tutorial creates a cluster that runs version 1.26.\n\n\n\n\n\n\n\n Step 1: Create a cluster in VPC \n\nCreate an IBM Cloud Kubernetes Service cluster in your IBM Cloud Virtual Private Cloud (VPC) environment. For more information about VPC, see [Getting Started with Virtual Private Cloud](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-started).\n\n\n\n1. Log in to the account, resource group, and IBM Cloud region where you want to create your VPC environment. The VPC must be set up in the same multizone metro location where you want to create your cluster. In this tutorial you create a VPC in us-south. For other supported regions, see [Multizone metros for VPC clusters](https://cloud.ibm.com/docs/containers?topic=containers-regions-and-zoneszones-vpc). If you have a federated ID, include the --sso option.\n\nibmcloud login -r us-south [-g <resource_group>] [--sso]\n2. Create a VPC for your cluster. For more information, see the docs for creating a VPC in the [console](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-a-vpc-using-the-ibm-cloud-console) or [CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-vpc-resources-with-cli-and-api&interface=clicreate-a-vpc-cli).\n\n\n\n1. Create a VPC called myvpc and note the ID in the output. VPCs provide an isolated environment for your workloads to run within the public cloud. You can use the same VPC for multiple clusters, such as if you plan to have different clusters host separate microservices that need to communicate with each other. If you want to separate your clusters, such as for different departments, you can create a VPC for each cluster.\n\nibmcloud is vpc-create myvpc\n2.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc_ks_tutorial"}, {"document_id": "ibmcld_16098-2598-4239", "score": 9.540057142711422, "text": "\nThis tutorial creates a cluster that runs version 1.26.\n\n\n\n\n\n\n\n Step 1: Create a cluster in VPC \n\nCreate an IBM Cloud Kubernetes Service cluster in your IBM Cloud Virtual Private Cloud (VPC) environment. For more information about VPC, see [Getting Started with Virtual Private Cloud](https://cloud.ibm.com/docs/vpc?topic=vpc-getting-started).\n\n\n\n1. Log in to the account, resource group, and IBM Cloud region where you want to create your VPC environment. The VPC must be set up in the same multizone metro location where you want to create your cluster. In this tutorial you create a VPC in us-south. For other supported regions, see [Multizone metros for VPC clusters](https://cloud.ibm.com/docs/containers?topic=containers-regions-and-zoneszones-vpc). If you have a federated ID, include the --sso option.\n\nibmcloud login -r us-south [-g <resource_group>] [--sso]\n2. Create a VPC for your cluster. For more information, see the docs for creating a VPC in the [console](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-a-vpc-using-the-ibm-cloud-console) or [CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-vpc-resources-with-cli-and-api&interface=clicreate-a-vpc-cli).\n\n\n\n1. Create a VPC called myvpc and note the ID in the output. VPCs provide an isolated environment for your workloads to run within the public cloud. You can use the same VPC for multiple clusters, such as if you plan to have different clusters host separate microservices that need to communicate with each other. If you want to separate your clusters, such as for different departments, you can create a VPC for each cluster.\n\nibmcloud is vpc-create myvpc\n2.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-vpc_ks_tutorial"}, {"document_id": "ibmcld_10689-18215-20114", "score": 9.524967482196985, "text": "\nThe security groups applied to the workers in the cluster are a combination of the security groups applied when you create the cluster and [when you create the worker pool](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-security-groupvpc-sg-worker-pool). A total of five security groups can be applied to workers, including the default security groups and any security groups applied to the worker pool. Note that these security group options are only available in the CLI.\n\nThe security groups applied to a cluster cannot be changed once the cluster is created. You can [change the rules of the security groups](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-security-groupvpc-sg-create-rules) that are applied to the cluster, but you cannot add or remove security groups at the cluster level. If you apply the incorrect security groups at cluster create time, you must delete the cluster and create a new one.\n\n\n\n If you only want the default VPC and cluster security groups and no additional security groups \n\nVPC security group\n\nCluster security group\n\nNote that this is the default behavior at cluster create time.\n\nWhen you create your cluster, do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the default VPC and kube-<cluster-id> cluster security groups:\n\nibmcloud oc cluster create vpc-gen2 --name <cluster-name> --zone <zone> --vpc-id <vpc-id> --subnet-id <subnet-id>\n\nThe following security groups are applied:\n\n\n\n* Default VPC security group (randomly generated name)\n* kube-<cluster-id>\n\n\n\n\n\n\n\n If you only want the cluster security group and not the default VPC security group \n\nCluster security group\n\nWhen you create the cluster specify --cluster-security-group cluster. Do not specify any additional security groups.\n\nExample command to create a VPC cluster with only the kube-<cluster-id> cluster security group:", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-security-group"}, {"document_id": "ibmcld_06282-2925-4793", "score": 9.490867771135642, "text": "\nAutomatically attached to each worker node in a cluster created in the VPC.<br> * Allows all outbound traffic by default.<br><br><br> \n VPC cluster security group kube-<cluster-ID> <br><br> * Automatically created when the VPC cluster is created. Automatically attached to each worker node in a cluster created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n Security groups applied to VPE gateways and VPC ALBs \n\nDo not modify the rules in the kube-<vpc-id> security group as doing so might cause disruptions in network connectivity between the workers of the cluster and the control cluster. However, you can [remove the default security group from the VPC ALB](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-referencesecurity-group-target-remove) and [replace it with a security group](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-referencesecurity-group-target-add) that you create and manage.\n\n\n\nTable 1. VPC security groups\nThe table shows the three types of security groups that are automatically created for VPCs. The first column includes the type of security group. The second column includes the naming format of the security group. The third column includes details on when and where the security group is created and what type of traffic it allows.\n\n Security group type Name Details \n\n Kubernetes Service security group kube-<vpc-id> <br><br> * Automatically created and attached to any cluster-related VPE gateways in the VPC.<br> * Automatically created and attached to each VPC ALB that is created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n\n\n Viewing VPC security groups in the CLI \n\nFollow the steps to view details about the VPC security groups.\n\n\n\n1. List your clusters and note the ID of the cluster that you are working in.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc-security-group"}, {"document_id": "ibmcld_06284-2951-4819", "score": 9.490867771135642, "text": "\nAutomatically attached to each worker node in a cluster created in the VPC.<br> * Allows all outbound traffic by default.<br><br><br> \n VPC cluster security group kube-<cluster-ID> <br><br> * Automatically created when the VPC cluster is created. Automatically attached to each worker node in a cluster created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n Security groups applied to VPE gateways and VPC ALBs \n\nDo not modify the rules in the kube-<vpc-id> security group as doing so might cause disruptions in network connectivity between the workers of the cluster and the control cluster. However, you can [remove the default security group from the VPC ALB](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-referencesecurity-group-target-remove) and [replace it with a security group](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-referencesecurity-group-target-add) that you create and manage.\n\n\n\nTable 1. VPC security groups\nThe table shows the three types of security groups that are automatically created for VPCs. The first column includes the type of security group. The second column includes the naming format of the security group. The third column includes details on when and where the security group is created and what type of traffic it allows.\n\n Security group type Name Details \n\n Kubernetes Service security group kube-<vpc-id> <br><br> * Automatically created and attached to any cluster-related VPE gateways in the VPC.<br> * Automatically created and attached to each VPC ALB that is created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n\n\n Viewing VPC security groups in the CLI \n\nFollow the steps to view details about the VPC security groups.\n\n\n\n1. List your clusters and note the ID of the cluster that you are working in.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-vpc-security-group&interface=ui"}, {"document_id": "ibmcld_10229-10270-11735", "score": 9.482238053528834, "text": "\nibmcloud oc zone add classic --zone <zone> --cluster <cluster_name_or_ID> --worker-pool <pool_name> --private-vlan <private_VLAN_ID> --public-vlan <public_VLAN_ID>\n\n\n\n\n\n Creating VPC clusters in the CLI \n\nReview the sample commands for creating classic clusters in the CLI. For more detailed steps and information about creating clusters, see [Creating VPC clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2&interface=clicluster_create_vpc). For information about planning your cluster set up, see [Preparing to create clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-clusters&interface=cli).\n\nCreate a VPC cluster with three worker nodes.\n\nibmcloud oc cluster create vpc-gen2 --name my_cluster --version 4.11_openshift --zone us-east-1 --vpc-id <VPC_ID> --subnet-id <VPC_SUBNET_ID> --cos-instance <COS_CRN>--flavor bx2.4x16 --workers 3\n\nFor a VPC multizone cluster, after you created the cluster in a [multizone metro](https://cloud.ibm.com/docs/openshift?topic=openshift-regions-and-zoneszones-vpc), [add zones](https://cloud.ibm.com/docs/openshift?topic=openshift-add_workersvpc_add_zone).\n\nibmcloud oc zone add vpc-gen2 --zone <zone> --cluster <cluster_name_or_ID> --worker-pool <pool_name> --subnet-id <VPC_SUBNET_ID>\n\n\n\n\n\n Deploying an app with the Red Hat OpenShift service catalog \n\nFrom the Red Hat OpenShift console, you can deploy one of the built-in service catalog apps and expose the app with a route.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-getting-started&interface=ui"}, {"document_id": "ibmcld_10228-10244-11709", "score": 9.482238053528834, "text": "\nibmcloud oc zone add classic --zone <zone> --cluster <cluster_name_or_ID> --worker-pool <pool_name> --private-vlan <private_VLAN_ID> --public-vlan <public_VLAN_ID>\n\n\n\n\n\n Creating VPC clusters in the CLI \n\nReview the sample commands for creating classic clusters in the CLI. For more detailed steps and information about creating clusters, see [Creating VPC clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cluster-create-vpc-gen2&interface=clicluster_create_vpc). For information about planning your cluster set up, see [Preparing to create clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-clusters&interface=cli).\n\nCreate a VPC cluster with three worker nodes.\n\nibmcloud oc cluster create vpc-gen2 --name my_cluster --version 4.11_openshift --zone us-east-1 --vpc-id <VPC_ID> --subnet-id <VPC_SUBNET_ID> --cos-instance <COS_CRN>--flavor bx2.4x16 --workers 3\n\nFor a VPC multizone cluster, after you created the cluster in a [multizone metro](https://cloud.ibm.com/docs/openshift?topic=openshift-regions-and-zoneszones-vpc), [add zones](https://cloud.ibm.com/docs/openshift?topic=openshift-add_workersvpc_add_zone).\n\nibmcloud oc zone add vpc-gen2 --zone <zone> --cluster <cluster_name_or_ID> --worker-pool <pool_name> --subnet-id <VPC_SUBNET_ID>\n\n\n\n\n\n Deploying an app with the Red Hat OpenShift service catalog \n\nFrom the Red Hat OpenShift console, you can deploy one of the built-in service catalog apps and expose the app with a route.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-getting-started"}, {"document_id": "ibmcld_10689-2901-4781", "score": 9.481391884772634, "text": "\nAutomatically attached to each worker node in a cluster created in the VPC.<br> * Allows all outbound traffic by default.<br><br><br> \n VPC cluster security group kube-<cluster-ID> <br><br> * Automatically created when the VPC cluster is created. Automatically attached to each worker node in a cluster created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n Security groups applied to VPE gateways and VPC ALBs \n\nDo not modify the rules in the kube-<vpc-id> security group as doing so might cause disruptions in network connectivity between the workers of the cluster and the control cluster. However, you can [remove the default security group from the VPC ALB](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-referencesecurity-group-target-remove) and [replace it with a security group](https://cloud.ibm.com/docs/vpc?topic=vpc-vpc-referencesecurity-group-target-add) that you create and manage.\n\n\n\nTable 1. VPC security groups\nThe table shows the three types of security groups that are automatically created for VPCs. The first column includes the type of security group. The second column includes the naming format of the security group. The third column includes details on when and where the security group is created and what type of traffic it allows.\n\n Security group type Name Details \n\n Red Hat OpenShift on IBM Cloud security group kube-<vpc-id> <br><br> * Automatically created and attached to any cluster-related VPE gateways in the VPC.<br> * Automatically created and attached to each VPC ALB that is created in the VPC.<br> * Allows traffic necessary for the cluster infrastructure to function.<br><br><br> \n\n\n\n\n\n\n\n\n\n Viewing VPC security groups in the CLI \n\nFollow the steps to view details about the VPC security groups.\n\n\n\n1. List your clusters and note the ID of the cluster that you are working in.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-security-group"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04175-0-1274", "score": 52.40274276856783, "text": "\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models"}, {"document_id": "ibmcld_04105-5067-6335", "score": 49.72118007420493, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04168-6066-7283", "score": 47.17694404582127, "text": "\n* [Querying Edge Functions metrics with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https://cloud.ibm.com/docs/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https://cloud.ibm.com/docs/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https://cloud.ibm.com/docs/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https://cloud.ibm.com/docs/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https://cloud.ibm.com/docs/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https://cloud.ibm.com/docs/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https://cloud.ibm.com/docs/cis?topic=cis-at_events)", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-http-concepts"}, {"document_id": "ibmcld_04105-3403-5572", "score": 37.92367445098527, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04170-7-2189", "score": 33.40706669540404, "text": "\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https://research.google/pubs/pub45581/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with /cdn-cgi/challenge-platform/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_04136-7-2226", "score": 29.01836531022354, "text": "\nDealing with Distributed Denial of Service attacks \n\nDistributed Denial of Service (DDoS) attacks are among the most common types of internet attacks that your website or host can encounter.\n\n\n\n What is a DDoS attack? \n\nA distributed denial of service (DDoS) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. DDoS attacks achieve effectiveness by utilizing many compromised computer systems as sources of attack traffic. Exploited machines can include computers and other networked resources such as IoT devices. From a high level, a DDoS attack is like a traffic jam clogging up a highway, preventing regular traffic from arriving at its destination.\n\n\n\n\n\n How DDoS attacks work \n\nAn attacker gains control of a network of online machines to carry out a DDoS attack. Computers and other machines (such as IoT devices) are infected with malware, turning each one into a bot (or zombie). The attacker controls the group of bots, which is called a botnet.\n\nAfter establishing a botnet, the attacker directs the machines by sending updated instructions to each bot using remote control. A targeted IP address can receive requests from a multitude of bots, causing the targeted server or network to overflow capacity. This creates a denial-of-service to normal traffic. Because each bot is a legitimate internet device, separating the attack traffic from normal traffic can be difficult.\n\n\n\n\n\n Common types of DDoS attacks \n\nDDoS attack vectors target varying components of a network connection. While nearly all DDoS attacks involve overwhelming a target device or network with traffic, attacks can be divided into three categories. An attacker can use one or multiple attack vectors, and might even cycle through these attack vectors based on countermeasures taken by the target.\n\nCommon types are:\n\n\n\n* Application layer attacks (Layer 7)\n* Protocol attacks (Layer 3 and Layer 4)\n* Volumetric attacks (amplification attacks)\n\n\n\n\n\n Application layer attacks \n\nAn application layer attack is sometimes referred to as a Layer-7 DDoS attack (in reference to the 7th layer of the OSI model).", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-distributed-denial-of-service-ddos-attack-concepts"}, {"document_id": "ibmcld_16729-323776-325852", "score": 27.83425245610389, "text": "\nA script and tool will assist you to simulate the transmission of web server log messages from a static file to Event Streams.\n\nObject Storage Event Streams\n\n+3\n\nAnalytics Engine,Data Engine,Key Protect\n\n\n\n* 3 hours\n* 2023-05-05\n\n\n\n[Enhance cloud security by applying context-based restrictions](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions\n\nThis tutorial walks you through the process of implementing context-based restrictions (CBRs) in your IBM Cloud account. CBRs help you to secure the cloud environment further and move towards a zero trust security model.\n\nKubernetes service Object Storage\n\n+7\n\nActivity Tracker hosted event search,Container Registry,Secrets Manager,App ID,Cloudant,Key Protect,Log Analysis\n\n\n\n* 2 hours\n* 2023-06-28\n\n\n\n[Apply end to end security to a cloud application](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-cloud-e2e-security)Apply end to end security to a cloud application\n\nThis tutorial walks you through key security services available in the IBM Cloud\u00ae catalog and how to use them together. An application that provides file sharing will put security concepts into practice.\n\nKubernetes service Object Storage\n\n+8\n\nActivity Tracker hosted event search,Container Registry,Secrets Manager,App ID,Cloudant,Key Protect,Log Analysis,Cloud Internet Services (CIS)\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Build, deploy, test and monitor a predictive machine learning model](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model)Build, deploy, test and monitor a predictive machine learning model\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\nObject Storage", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_16516-12409-14637", "score": 27.15090005022258, "text": "\nAnnotation tasks Assets & Tools > Documents > Tasks Machine Learning Model > Annotation Tasks \n Coreferences tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Dictionaries page (management) Assets & Tools > Pre-annotators > Manage Dictionaries Assets \n Dictionaries tab (mapping to classes for rule-based model) Document Annotation Rule-based Model > Rules \n Documents page Assets & Tools Assets \n Entity Types page Assets & Tools Assets \n Mentions tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Performance page Model Management Machine Learning Model \n Pre-annotators page Assets & Tools Machine Learning Model > Pre-annotation \n Regex tab Document Annotation Rule-based Model > Rules \n Relation Types page Assets & Tools Assets \n Relations tab Document Annotation Machine Learning Model > Annotation Tasks > task > annotation set > document \n Rules tab Document Annotation Rule-based Model \n Tasks tab Assets & Tools > Documents Machine Learning Model > Annotation Tasks \n Versions page (machine learning model) Model Management Machine Learning Model \n Versions page (rule-based model) Model Management Rule-based Model \n\n\n\n\n\n\n\n\n\n May 2018 \n\n\n\n New features and changes \n\nConfiguration issue fixed\n: A configuration issue was fixed that caused service instances in Sydney region to not appear in US South region.\n\nDeploy Model window support changes\n: In the Deploy Model window, if the region you're deploying to supports both IBM Cloud\u00ae Identity and Access Management resource groups and Cloud Foundry spaces, to see the list, you will need to choose the method of access management that your service instance uses.\n\nData collection setting added\n: Added the data collection setting on the Service Details page. For more information about data collection, see [Troubleshooting, support, and FAQs](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-troubleshootingcontent)\n\nSupport for Chinese (Traditional)\n: Added Chinese (traditional) language support.\n\nAdministrators can see number of workspaces\n: Users who have the Admin role can now see the number of workspaces that are used.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-release-notes"}, {"document_id": "ibmcld_16524-7-2263", "score": 26.844427808597686, "text": "\nTraining the machine learning model \n\nIn IBM Watson\u00ae Knowledge Studio , the creation of the machine learning model involves training the machine learning model and evaluating how well the model performed when annotating test data and blind data.\n\n\n\n Creating a machine learning model \n\nWhen you create a machine learning model, you select the document sets that you want to use to train the model and specify the percentage of documents that are to be used as training data, test data, and blind data.\n\n\n\n About this task \n\nBy exploring the performance metrics, you can identify ways to improve the model's accuracy.\n\n> Restriction: Only three machine learning models can be trained at a time per Knowledge Studio instance. If your instance contains multiple workspaces and the number of machine learning models that are being trained in other workspaces totals 3 already, then your request to train the machine learning model in your workspace will be queued until the other training processes are done.\n\n\n\n\n\n Procedure \n\nTo create a machine learning model:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. Verify that all of the document sets have been approved and that all annotation conflicts have been resolved through adjudication. Only documents that have become ground truth through adjudication or approval can be used to train the model.\n4. Click Train and evaluate.\n5. Optional: To specify how you want to allocate documents from your document sets to be used by the system-level training, test, or blind sets, click Edit settings.\n\nSee [Document set management](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-improve-mlwks_mamanagedata) for help determining which ratios to apply.\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\n> Important: Training a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-train-ml"}, {"document_id": "ibmcld_16451-7-2278", "score": 26.82144508384809, "text": "\nTraining the machine learning model \n\nIn IBM Watson\u2122 Knowledge Studio for IBM Cloud Pak for Data, the creation of the machine learning model involves training the machine learning model and evaluating how well the model performed when annotating test data and blind data.\n\n\n\n Creating a machine learning model \n\nWhen you create a machine learning model, you select the document sets that you want to use to train the model and specify the percentage of documents that are to be used as training data, test data, and blind data.\n\n\n\n About this task \n\nBy exploring the performance metrics, you can identify ways to improve the model's accuracy.\n\nOnly three machine learning models can be trained at a time per Knowledge Studio instance. If your instance contains multiple workspaces and the number of machine learning models that are being trained in other workspaces totals 3 already, then your request to train the machine learning model in your workspace will be queued until the other training processes are done.\n\n\n\n\n\n Procedure \n\nTo create a machine learning model:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. Verify that all of the document sets have been approved and that all annotation conflicts have been resolved through adjudication. Only documents that have become ground truth through adjudication or approval can be used to train the model.\n4. Click Train and evaluate.\n5. Optional: To specify how you want to allocate documents from your document sets to be used by the system-level training, test, or blind sets, click Edit settings.\n\nFor more information about which ratios to apply, see [Document set management](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-mlwks_mamanagedata).\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\nTraining a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-train-ml"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12498-8087-10171", "score": 16.891608638240143, "text": "\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_12498-9696-11699", "score": 15.791398823325672, "text": "\n[IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource. \n [SSL/TLS certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificates) imported_cert <br>public_cert* <br>private_cert* Static A type of digital certificate that can be used to establish communication privacy between a server and a client. In Secrets Manager, you can store the following types of certificates.<br><br><br><br> * Imported certificates: Certificates that you import to the service.<br> * Public certificates: Certificates that you order from a third-party certificate authority, for example Let's Encrypt.<br> * Private certificates: Certificates that you generate by using a private certificate authority that you manage in Secrets Manager.<br><br><br> \n [User credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials) username_password Static Username and password values that you can use to log in or access an application or resource. \n\n\n\n* Requires an [engine configuration](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-secrets-engines) before secrets can be created in the service.\n\n\n\n Supported features by secret type \n\nThe following table compares and contrasts some common characteristics between the secret types.\n\n\n\nTable 2. Feature comparison between secret types\n\n Arbitrary secrets IAM credentials User credentials Key-value secrets Imported certificates Public certificates Private certificates \n\n [Automatic rotation](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-automatic-rotation) !", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_12415-7-1973", "score": 14.917907074356522, "text": "\nFAQs for Secrets Manager \n\nFAQs for IBM Cloud\u00ae Secrets Manager might include questions about secrets or credentials. To find all FAQs for IBM Cloud, see the [FAQ library](https://cloud.ibm.com/docs/faqs).\n\n\n\n What is a secret? \n\nA secret is a piece of sensitive information. For example, a secret might be a username and password combination or an API key that you use while you develop your applications. To keep your applications secure, it is important to regulate which secrets can access what and who has access to them.\n\nIn addition to the static secrets described, there are other types of secrets that you might work with in the Secrets Manager service. To learn more about secret types, check out [Types of secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secretsecret-types).\n\n\n\n\n\n What is a secret group? \n\nA secret group is a means to organize and control access to the secrets that you store within Secrets Manager. There are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n\n\n\n\n\n What is an IAM credential? \n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials).\n\n\n\n\n\n What happens when I rotate my secret? \n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-faqs"}, {"document_id": "ibmcld_00894-7096-9156", "score": 13.548148667795129, "text": "\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox. Also, specify a lease duration with a minimum of 12 hours when you use public worker agents to run your pipeline. If you use private worker agents, make sure that you set a minimum lease duration to the forced cancellation duration for a pipeline. It is recommended that you confirm these settings with your account administrator. By setting the reuse option and an appropriate lease duration, you can make sure that the dynamically managed IAM credentials service ID API key persists during your pipeline runs.\n\nZoom\n\n![IAM credentials lease duration and reuse API key](https://cloud.ibm.com/docs-content/v1/content/562806c0b18119f4d21cb66f5ae6d051634b4a16/ContinuousDelivery/images/secret-leaseduration.png)\n\nFigure 3. IAM credentials lease duration and reuse API key\n\nBy running the Rotate action on IAM credentials from the Secrets Manager dashboard, you can maintain the compliance posture requirements for API Key rotations that are used by your Continuous Delivery pipelines. Secrets Manager works with IAM to generate a new API Key for an IAM credentials secret and manages the versioning of the secret.\n\nThe IAM credentials secret type also helps to provide continuity of service during and after secret rotation:\n\n\n\n* New Continuous Delivery pipeline workloads use the newly rotated API Key until its lease duration expires.\n* Existing Continuous Delivery pipeline workloads that are running with the API Key that was issued before rotation can continue to run with the previous version until the lease duration of the previous version expires.\n\n\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"}, {"document_id": "ibmcld_12960-7096-9156", "score": 13.548148667795129, "text": "\nThe IAM credentials secret type is fully integrated with IAM. Secrets Manager auto-manages dynamic service IDs and API keys that are associated with an IAM credentials secret. Continuous Delivery and Secrets Manager service APIs engage to resolve authorized IAM Credentials secret references in Continuous Delivery toolchains and pipeline workloads.\n\nWhen you create an IAM credentials secret in Secrets Manager, make sure that you select the Reuse IAM credentials until lease expires checkbox. Also, specify a lease duration with a minimum of 12 hours when you use public worker agents to run your pipeline. If you use private worker agents, make sure that you set a minimum lease duration to the forced cancellation duration for a pipeline. It is recommended that you confirm these settings with your account administrator. By setting the reuse option and an appropriate lease duration, you can make sure that the dynamically managed IAM credentials service ID API key persists during your pipeline runs.\n\nZoom\n\n![IAM credentials lease duration and reuse API key](https://cloud.ibm.com/docs-content/v1/content/562806c0b18119f4d21cb66f5ae6d051634b4a16/ContinuousDelivery/images/secret-leaseduration.png)\n\nFigure 3. IAM credentials lease duration and reuse API key\n\nBy running the Rotate action on IAM credentials from the Secrets Manager dashboard, you can maintain the compliance posture requirements for API Key rotations that are used by your Continuous Delivery pipelines. Secrets Manager works with IAM to generate a new API Key for an IAM credentials secret and manages the versioning of the secret.\n\nThe IAM credentials secret type also helps to provide continuity of service during and after secret rotation:\n\n\n\n* New Continuous Delivery pipeline workloads use the newly rotated API Key until its lease duration expires.\n* Existing Continuous Delivery pipeline workloads that are running with the API Key that was issued before rotation can continue to run with the previous version until the lease duration of the previous version expires.\n\n\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/services/ContinuousDelivery?topic=ContinuousDelivery-secretsmanager"}, {"document_id": "ibmcld_06843-4238-6198", "score": 13.346156480074475, "text": "\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https://cloud.ibm.com/docs/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https://github.com/IBM/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-devsecops-cc-pipeline"}, {"document_id": "ibmcld_12467-1716-3849", "score": 13.324199949359755, "text": "\n* When you try to modify or delete a secret while it is locked, Secrets Manager denies the request with an HTTP 412 Precondition Failed response. You see an error message similar to the following example:\n\nThe requested action can't be completed because the secret version is locked.\n\nIf you're working with\n\ndynamic secrets, such as IAM credentials, locking your secrets also means that by default, those secrets can't be read or accessed. For more information, see [Why can't I read a locked IAM credentials secret?](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-locked-iam-credentials)\n* If a locked secret reaches its expiration date, it stays in the Active state and its data remains accessible to your applications. Secrets Manager moves the secret to the Destroyed state and permanently deletes the expired secret data only after all locks on the secret are removed.\n\nSSL/TLS certificates still reach their defined expiration dates and move into a Destroyed state even if they are locked. For more information, see [Why did my locked certificate move to the Destroyed state?](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-locked-certificates)\n* If you try to rotate a secret while its current version is locked and the previous version is unlocked (or if an automatic rotation is scheduled), the request to rotate the secret is allowed. The current secret version becomes the new previous version, retaining its existing locks. A new current version is created without any locks.\n* If you try to rotate a secret while its previous version is locked (or if an automatic rotation is scheduled), your request to rotate the secret is denied. Rotation is allowed only after all locks on the previous secret version are removed.\n\n\n\n\n\n Creating locks in the UI \n\nYou can create up to 1000 locks on a secret by using the Secrets Manager UI. Each lock can be used to represent a single application or service that uses your secret.\n\nA secret is considered locked after you attach one or more locks to it. A lock can be applied only on a secret version that contains active payload, or secret data.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-secret-locks"}, {"document_id": "ibmcld_07578-1215486-1217535", "score": 13.309528842268302, "text": "\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1218119-1220168", "score": 13.309528842268302, "text": "\nThere are several different strategies that you might use to approach secret groups. For more information and recommendations, see [Best practices for organizing secrets and assigning access](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-best-practices-organize-secrets).\n* What is an IAM credential?\n\nAn IAM credential is a type of dynamic secret that you can use to access an IBM Cloud resource that requires IAM authentication. When you create an IAM credential through Secrets Manager, the service creates a service ID and an API key on your behalf. For more information about creating and storing IAM credentials, see [Creating IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials).\n* What happens when I rotate my secret?\n\nWhen a secret is rotated, a new version of its value becomes available for use. You can choose to manually add a value or automatically generate one at regular intervals by enabling automatic rotation.\n\nFor more information about secret rotation, see [Rotating secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation).\n* What happens when my secret expires?\n\nIn some secret types such as arbitrary or username_password, you can set the date and time when your secret expires. When the secret reaches its expiration date, it transitions to a Destroyed state. When the transition happens, the value that is associated with the secret is no longer recoverable. The transition to the Destroyed state can take up to a couple of minutes after the secret expires, or a lock that prevented expiration is removed.\n\nFor more information about how your information is protected, see [Securing your data](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-mng-data).\n* What are differences between the Reader and SecretsReader roles?\n\nBoth the Reader and SecretsReader roles help you to assign read-only access to Secrets Manager resources.\n\n\n\n* As a reader, you can browse a high-level view of secrets in your instance.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_12447-1578-3681", "score": 13.295732407114647, "text": "\nIf the IAM credentials secret was created by using an existing service ID in the account, only the API key is regenerated as part of a manual rotation. In contrast, if the secret was created by selecting an access group, both the service ID and API key values are regenerated when they're manually rotated.<br><br>The Reuse IAM credentials until lease expires (reuse_api_key) option for an IAM credentials secret impacts whether it can be rotated manually. If this field is false or set to Off in the UI, manual rotation isn't supported. The API key that is dynamically generated for the secret on each read is already a single-use, ephemeral value. \n [Imported certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatesimport-certificates) Certificates that were initially imported to a service instance are immediately replaced with the data that you reimport on rotation. \n [Key-value secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-key-value) Key-value secrets are immediately replaced with the data that you provide on rotation. \n [Private certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatescreate-certificates) Private certificates are immediately replaced with a certificate that is signed by its parent or issuing certificate authority. \n [Public certificates](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-certificatesorder-certificates) Public certificates move to the Active, Rotation pending status to indicate that a request to rotate a certificate is being processed. Secrets Manager sends the request to the configured certificate authority (CA), for example Let's Encrypt, to validate the ownership of your domains. If the validation completes successfully, a new certificate is issued. \n [User credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-user-credentials) Passwords that are associated with user credentials secrets are immediately replaced with the data that you provide on rotation. \n\n\n\n\n\n\n\n\n\n Creating new secret versions in the UI", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-manual-rotation&interface=ui"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16295-7-1721", "score": 46.16896541739263, "text": "\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat"}, {"document_id": "ibmcld_16368-7-2072", "score": 45.40563595533174, "text": "\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_03080-7-1901", "score": 44.89885795770722, "text": "\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-config"}, {"document_id": "ibmcld_16365-12876-14604", "score": 43.97275472680484, "text": "\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https://web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https://integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https://cloud.ibm.com/docs/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_03166-4-2012", "score": 43.77813714517982, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Adding the web chat to your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks, and can transfer customers to human agents.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\nTo learn more about how web chat can help your business, read [this Medium blog post](https://medium.com/ibm-watson/building-an-engaging-virtual-assistant-cf39cd0c3730).\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, either click Integrate web chat, or click Add integration, and then choose the Web chat tile.\n\nThe web chat integration is added to your first assistant automatically. If you're using the My first assistant, click the Web chat tile to open the integration that was added for you.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n\nA preview pane is displayed that shows you what the web chat looks like when it is embedded in a web page. If a message is displayed that starts with, There is an error, it means you haven't added a conversational skill to your assistant yet. After you add a skill, you can test the conversation from the preview pane.\n4. Click Create to create a web chat instance.\n\nYou can skip this step if the web chat integration was created for you automatically.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chat"}, {"document_id": "ibmcld_16326-1697-3495", "score": 43.6748837045935, "text": "\nFor more information, see [Changing background website](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-preview-share"}, {"document_id": "ibmcld_03421-4-1877", "score": 43.49484674555285, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_16295-1365-2938", "score": 42.755797535239125, "text": "\nThe script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5. Edit the HTML source for the web page where you want the web chat widget to appear. Paste the code snippet into the page. Paste the code as close as possible to the closing </body> tag to ensure that your page renders faster.\n\nDo not modify the integrationID or region property values in the generated embed script.\n\nIf you aren't ready to add the web chat to a live website, you can quickly test it using a local HTML file. Use this HTML code as the source for a test page:\n\n<html>\n<head></head>\n<body>\n<title>My Test Page</title>\n<p>The body of my page.</p>\n\n</body>\n</html>\n\nJust copy this code into a file with the .html extension, and replace the script element with the embed script you copied in the previous step.\n\nThe identifiers in the embed script (such as integrationIDserviceInstanceID) are not considered secret, and are visible to anyone who has access to your website. For more information, see [Security](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architectureweb-chat-architecture-security).\n6. If the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the URLs that host the web chat are accessible.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat"}, {"document_id": "ibmcld_02855-7-2041", "score": 42.68621209369722, "text": "\nIntegrating the web chat with your website \n\nAdd your assistant to your company website as a web chat widget that can help your customers with common questions and tasks.\n\nWhen you create a web chat integration, code is generated that calls a script that is written in JavaScript. The script instantiates a unique instance of your assistant. You can then copy and paste the HTML script element into any page or pages on your website where you want users to be able to ask your assistant for help.\n\n\n\n Create a web chat instance to add to your website \n\nTo add the assistant to a web page on your company website, complete the following steps:\n\n\n\n1. From the Assistants page, click to open the assistant tile that you want to deploy to your site.\n2. From the Integrations section, click the Web chat tile.\n3. Optional: Change the web chat integration name from Web chat to something more descriptive.\n4. Click Create to create a web chat instance.\n5. Optional: Customize the style of the chat window. You can make the following changes:\n\n\n\n* Public assistant name. Name by which the assistant is known to users. This name is displayed in the header of the chat window. The name can be up to 18 characters in length.\n* Primary color. Sets the color of the web chat header.\n\nClick the white dot to open a color switcher where you can choose a color. The color is saved as an HTML color code, such as FF33FC for pink and 329A1D for green. Alternatively, you can add an HTML color code directly to the field to set the color.\n* Secondary color: Sets the color of the user input message bubble.\n* Accent color. Sets the color of interactive elements, including:\n\n\n\n* Chat launcher button that is embedded in your web page\n* Send button associated with the input text field\n* Input text field border when in focus\n* Marker that shows the start of the assistant\u2019s response\n* Border of a button after it is clicked\n* Border of the drop-down list field as the user chooses an option\n* Typing indicator that is shown to repesent a pause response", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_16365-11574-13329", "score": 42.4617773316789, "text": "\nAnyone who has these IDs could use them to send messages to your assistant and receive its replies. However, these IDs cannot be used to log in to your account, make any changes to your assistant, or retrieve logs or analytics information about your assistant.\n\nIf you are concerned about unauthorized access to your assistant, you can enable the web chat security feature for additional security, such as verifying message origin and authenticating users. Enabling the security feature requires additional development work on your website. For more information, see [Web chat security](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n Updating site security policies \n\nIf your website uses a Content Security Policy (CSP), you must update it to grant permission to the web chat.\n\nThe following table lists the values to add to your CSP.\n\n\n\nCSP properties\n\n Property Additional values \n\n default-src 'self' *.watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline' \n connect-src *.watson.appdomain.cloud \n\n\n\nThe following example shows a complete CSP metadata tag:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'unsafe-inline';connect-src .watson.appdomain.cloud\" />\n\n\n\n Allowing elements \n\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03285-5746-7932", "score": 36.511040536204675, "text": "\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https://cloud.ibm.com/apidocs/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions"}, {"document_id": "ibmcld_16321-5729-7915", "score": 36.511040536204675, "text": "\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https://cloud.ibm.com/apidocs/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_16321-14177-15957", "score": 28.739806110643382, "text": "\nThe WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use. For more information about voice model options, see [Supported languages and voices](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voiceslanguageVoices).\n\nThe model you specify must be one that is supported by the Text to Speech service instance that is configured for use with the integration.\n\n\n\n\n\n\n\n Transferring a call to a live agent \n\nWhen you configure the phone integration, you can optionally set up backup call center support, which makes it possible for the assistant to transfer a call to a human.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_03285-12413-14528", "score": 28.079305356423596, "text": "\n\"parameter name\": \"parameter value\",\n\"parameter name\": \"parameter value\"\n}\n}\n}\n]\n}\n}\nShow more\n\n\n\nEach command type along with its related parameters are described in the following sections.\n\n\n\n command_info.type : configure \n\nDynamically reconfigures the Text to Speech service by applying a set of configuration parameters, which can be based on the dialog or action flow. For example, you might want to choose a particular voice at a specific point in the conversation.\n\n\n\n parameter description required default \n\n synthesize The Text to Speech service configuration to use when synthesizing audio. The parameters defined by this object are used when connecting to the Text to Speech service for speech synthesis requests. For more information about these parameters, see the [Text to Speech API documentation](https://cloud.ibm.com/apidocs/text-to-speechsynthesize-audio-websockets-). yes Current Text to Speech configuration \n update_strategy Specifies the update strategy to use when setting the speech configuration. Possible values include:<br><br><br><br> * replace: Replaces the configuration for the rest of the session. Any root-level fields in the new configuration completely overwrite the previous configuration.<br> * replace_once: Replaces the configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions"}, {"document_id": "ibmcld_16321-12507-14690", "score": 27.7939442041382, "text": "\nDynamically reconfigures the Text to Speech service by applying a set of configuration parameters, which can be based on the conversation flow. For example, you might want to choose a particular voice at a specific point in the conversation.\n\n\n\n parameter description required default \n\n synthesize The Text to Speech service configuration to use when synthesizing audio. The parameters defined by this object are used when connecting to the Text to Speech service for speech synthesis requests. For more information about these parameters, see the [Text to Speech API documentation](https://cloud.ibm.com/apidocs/text-to-speechsynthesize-audio-websockets-). yes Current Text to Speech configuration \n update_strategy Specifies the update strategy to use when setting the speech configuration. Possible values include:<br><br><br><br> * replace: Replaces the configuration for the rest of the session. Any root-level fields in the new configuration completely overwrite the previous configuration.<br> * replace_once: Replaces the configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_03285-13886-15581", "score": 27.40641686029589, "text": "\nOnly changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for synthesize reflect the parameters that are made available by the Text to Speech WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For a full list of parameters, see the [Text to Speech API documentation](https://cloud.ibm.com/apidocs/text-to-speech).\n\n\n\n\n\n command_info.type : disable_barge_in \n\nDisables speech barge-in so that playback isn't interrupted when the caller speaks while audio is being played back.\n\nNo parameters.\n\n\n\n\n\n command_info.type : enable_barge_in \n\nEnables speech barge-in so that callers can interrupt playback by speaking.\n\nNo parameters.\n\n\n\n\n\n Changing the assistant's voice \n\nYou can change the voice of your assistant when it covers certain topics in the conversation that warrant it. For example, you might want to use a voice with a British accent for a branch of the conversation that applies only to customers in the UK.\n\nThis example shows how to specify a voice during the conversation:\n\n{\n\"output\": {\n\"generic\": [\n{\n\"response_type\": \"text_to_speech\",\n\"command_info\": {\n\"type\": \"configure\",\n\"parameters\": {\n\"synthesize\": {\n\"voice\": \"en-GB_KateV3Voice\"\n}\n}\n}\n}\n]\n}\n}\n\nShow more\n\nIn the voice parameter, specify the voice model that you want to use.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions"}, {"document_id": "ibmcld_16291-1353-3298", "score": 27.04701436103302, "text": "\nClick Users, and then locate and click the user account you want to use for the integration.\n4. Click the Access Keys tab.\n5. Click Generate New Access Key.\n6. Click Show Secret Key, and copy the secret key to a secure location.\n\nYou cannot retrieve the secret key again after you complete the next step and Save. You must generate a new key if the current one is lost or forgotten.\n7. Click Save.\n\n\n\n\n\n\n\n Set up the integration \n\nTo complete setup, you must have an assistant ready to deploy, your NICE CXone access keys, and phone numbers allocated for this integration.\n\nTo integrate your assistant with NICE CXone:\n\n\n\n1. In the Integrations section on the main page for your assistant under Essential Channels, you will see a tile for Phone.\n2. On the Phone tile, click Add.\n3. On the pop-up window, click Add again.\n4. Select NICE CXone on the Select contact center page.\n\nClick Next.\n5. On the Connect to contact center page, specify the following values: - the Authentication URL from NICE CXone - the API URL, which is the Admin API endpoint from NICE CXone - the Access key ID - the Access key secret\n\nClick Test connection to verify the credentials.\n\nClick Next.\n6. On the Phone number page, enter a phone number you allocated for the NICE CXone integration. You can add more phone numbers later.\n\nClick Next.\n7. On the Speech to Text page, select the instance of the Speech to Text service you want to use.\n\n\n\n* If you have existing Speech to Text instances, select the instance you want to use from the list.\n* If you do not have any existing Speech to Text instances, click Create new instance to create a new Plus or Enterprise instance.\n\n\n\n8. In the Choose your Speech to Text language model field, select the language you want to use.\n\nThe list of language models is automatically filtered to use the same language as your assistant. To see all language models, toggle the Filter models based on assistant language switch to Off.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone"}, {"document_id": "ibmcld_16288-1733-3996", "score": 26.922929887945887, "text": "\nIt's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call. This 503 response can then be used by the SIP trunking provider to reroute the call to another region. If you want to take advantage of this capability, open a service ticket against the Watson Assistant service instance that requires disaster recovery.\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by going to the Advanced options tab in the phone integration settings, and selecting one or both of the following options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Applying advanced SIP trunk configuration settings \n\nTo configure how your assistant interacts with a SIP trunk from an external provider, go to the SIP trunk tab in the phone integration settings, and update the following options in the SIP trunking integration section:\n\n\n\n* SIP INVITE headers to extract: List the headers that you want your assistant to use.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_16297-7-1893", "score": 26.150454269437596, "text": "\nIntegrating with WhatsApp \n\nIBM Cloud\n\nIntegrate with WhatsApp messaging so your assistant can exchange messages with your customers where they are.\n\nMany customers use WhatsApp because it provides fast, simple, secure messaging for free, and is available on phones all over the world. WhatsApp uses the phone Internet connection to send messages so customers can avoid SMS fees.\n\nThis integration creates a connection between your assistant and WhatsApp by using Twilio as a provider.\n\n\n\n Before you begin \n\nIf you don't have one, set up a Twilio messaging account and get a phone number.\n\n\n\n1. Go to the [Twilio website](https://www.twilio.com/).\n2. Create an account.\n3. From the Develop tab, click Phone numbers.\n4. Follow the instructions to get a phone number.\n\nWhen you get a Twilio phone number, it supports voice, SMS, and MMS automatically. Your new phone number is listed as an active number.\n\n\n\nKeep the Twilio web page open in a web browser tab so you can refer to it again later.\n\n\n\n\n\n Ask WhatsApp for permission to enable your Twilio number for WhatsApp \n\nWhatsApp has a rigorous process that they use to review all businesses that want to interact with customers over their network. WhatsApp, which is owned by Facebook, requires that you register your business with the Facebook business directory.\n\n\n\n1. To register, go to the [Facebook Business Manager](https://business.facebook.com/overview) website, and click Create account. Follow the instructions to create an account.\n2. Get your Facebook Business Manager ID. In [Settings](https://business.facebook.com/settings), click the Business info tab. The Facebook Business Manager ID is at the top of the page.\n3. Submit the Request to enable your Twilio numbers for WhatsApp form from the [Twilio API for WhatsApp](https://www.twilio.com/whatsapp/request-access) web page.\n\nTips for specifying the following values:", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-whatsapp"}, {"document_id": "ibmcld_16287-2974-4988", "score": 25.493406386178325, "text": "\nChoose whether to generate a free phone number for your assistant, integrate with your contact center, or connect to an existing SIP trunk:\n\n\n\n* To generate a free phone number for your assistant, click Generate a free phone number.\n\nGenerating a free phone number is supported only for Watson Assistant instances in the Dallas and Washington DC data centers.\n* To integrate with a [contact center](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-nicecxone), click Integrate with your contact center.\n* To use an existing phone number you have already configured with a [SIP trunk provider](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-sip-providers), click Use an existing phone number with an external provider.\n\n\n\nClick Next.\n5. If you are integrating with a contact center, follow the instructions to configure the contact center. Skip this step if you are generating a free phone number.\n\n\n\n1. On the Select contact center page, select the tile of the connect center you would like to use.\n2. On the Connect to contact center page, enter the required information. There is a Test Connection button on the page to validate the connection. Click Next.\n\n\n\n6. If you are using an existing phone number, follow the instructions to configure the SIP trunk. Skip this step if you are generating a free phone number.\n\n\n\n1. On the Bring your own SIP trunk page, copy the SIP URI and assign it to your SIP trunk. Click Next.\n\n\n\n7. On the Phone number page (only for Integrate with your contact center and Use an existing phone number with an external provider), specify the phone number of the SIP trunk. Specify the number by using the international phone number format: +1 958 555 0123. Do not surround the area code with parentheses.\n\nCurrently, only one primary phone number can be added during initial setup of the phone integration. You can add more phone numbers in the phone integration settings later.\n\nClick Next.\n8.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04518-1426-3052", "score": 57.88954654750401, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10817-1342-3184", "score": 51.06683916464871, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-7-1743", "score": 50.21766320200422, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10817-7-1802", "score": 42.48004965118998, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_10852-43319-44485", "score": 41.55878286389378, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_12332-1034-2510", "score": 39.84195490794319, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}, {"document_id": "ibmcld_07551-14062-16080", "score": 36.40284124684146, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_02772-4213-5899", "score": 27.108532011552, "text": "\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}, {"document_id": "ibmcld_07551-15747-17355", "score": 25.755091857244516, "text": "\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager \n\nAdd the following to your Package.swift file to identify ENPushDestination as a dependency. The package manager clones ENPushDestination when you build your project with swift build.\n\ndependencies: [\n.package(url: \"https://github.com/IBM/event-notifications-destination-ios-sdk\", from: \"0.0.1\")\n]\n\n\n\n\n\n\n\n Installation - Initialize SDK \n\nComplete the following steps to enable iOS applications to receive notifications.\n\n\n\n1. Add the import statements in your .swift file.\n\nimport ENPushDestination\n2. Initialize the ENPushDestination SDK\n\nlet instanceGUID = \"<instance_guid>>\";\nlet destinationID = \"<instance_destination_id>\";\nlet apiKey = \"<instance_apikey>\";\n\nlet enPush = ENPush.sharedInstance\nenPush.setCloudRegion(region: .usSouth)\nenPush.initialize(instanceGUID, destinationID, apiKey)\n\n\n\n* region: Region of the Event Notifications instance. For example, Region.usSouth.\n\n\n\n\n\n\n\n\n\n Register for notifications \n\nUse the ENPush.registerDevice() API to register the device with iOS destination in Event Notifications service.\n\nThe following options are supported:\n\n\n\n* Register without userId:\n\n/Register iOS devices/\nenPush.registerWithDeviceToken(deviceToken: \"<apns-device-token>\") { response, statusCode, error in\nprint(response?.id ?? \"\")\n}\n* Register with UserId.", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_10852-44214-45420", "score": 22.631841900679582, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03112-5424-6783", "score": 56.505649903738856, "text": "\n},\n'skills': {\n'main skill': {\n'user_defined': {\n'account_number': '123456'\n}\n}\n}\n}\n).get_result()\n\nprint(json.dumps(response, indent=2))\n\nservice\n.message({\nassistant_id: '{assistant_id}',\nsession_id: '{session_id}',\ninput: {\nmessage_type: 'text',\ntext: 'Hello',\noptions: {\n'return_context': true\n}\n},\ncontext: {\n'global': {\n'system': {\n'user_id': 'my_user_id'\n}\n},\n'skills': {\n'main skill': {\n'user_defined': {\n'account_number': '123456'\n}\n}\n}\n}\n})\n.then(res => {\nconsole.log(JSON.stringify(res, null, 2));\n})\n.catch(err => {\nconsole.log(err);\n});\n\nIn this example request, the application specifies a value for user_id as part of the global context. In addition, it sets one user-defined context variable (account_number) as part of the skill-specific context. This context variable can be accessed by dialog nodes as $account_number. (For more information about using the context in your dialog, see [How the dialog is processed](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-runtime).)\n\nYou can specify any variable name you want to use for a user-defined context variable. If the specified variable already exists, it is overwritten with the new value; if not, a new variable is added to the context.\n\nThe output from this request includes not only the usual output, but also the context, showing that the specified values have been added.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-client-get-context"}, {"document_id": "ibmcld_16364-111960-113964", "score": 53.542878700632244, "text": "\nThe @sys-location and @sys-person system entities were removed\n: The @sys-location and @sys-person system entities are no longer listed on the System entities page. If your dialog uses one of these entities, a red Entity not created notification is displayed to inform you that the entity is not recognized.\n\nSkill menu actions moved\n: The menu that was displayed in the header of the skill while you were working with a skill was removed. The actions that were available from the menu, such as import and export, are still available. Go to the Skills page, and click the menu on the skill tile.\n\nThe import skill process was updated to support overwriting an existing skill on import. For more information, see [Overwriting a skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-tasksskill-tasks-overwrite).\n\nDialog issues were addressed\n: These dialog issues were addressed:\n\n\n\n* Fixed an issue with adding a jump-to from a conditional response in one node to a conditional response in another node.\n* The page now responds better when you scroll horizontally to see multiple levels of child nodes.\n\n\n\n\n\n\n\n 15 July 2020 \n\nSupport ended for @sys-location and @sys-person\n: The person and location system entities, which were available as a beta feature in English dialog skills only, are no longer supported. You cannot enable them. If your dialog uses them, they are ignored by the service.\n\nUse contextual entities to teach your skill to recognize the context in which such names are used. For more information about contextual entities, see [Annotation-based method](https://cloud.ibm.com/docs/assistant?topic=assistant-entitiesentities-annotations-overview).\n\nFor more information about how to use contextual entites to identify names of people, see the [Detecting Names And Locations With Watson Assistant](https://medium.com/ibm-watson/detecting-names-and-locations-with-watson-assistant-e3e1fa2a8427) blog post on Medium.\n\nHow legacy numeric system entities are processed has changed", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03118-1768-3298", "score": 53.459491740659026, "text": "\n(Search skills are a beta feature available only to Plus or Premium plan users.)\n\n\n\nFor details about the v2 API, see the Watson Assistant [v2 API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v2).\n\nNote: The Watson Assistant v1 API still supports the legacy /message method that sends user input directly to the workspace used by a dialog skill. The v1 runtime API is supported primarily for backward compatibility purposes. If you use the v1 /message method, you must implement your own state management, and you cannot take advantage of versioning or any of the other features of an assistant.\n\n\n\n\n\n Authoring applications \n\nThe v1 API provides methods that enable an application to create or modify dialog skills, as an alternative to building a skill graphically using the Watson Assistant user interface. An authoring application uses the API to create and modify skills, intents, entities, dialog nodes, and other artifacts that make up a dialog skill. For more information, see the [v1 API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v1).\n\nNote: The v1 authoring methods create and modify workspaces rather than skills. A workspace is a container for the dialog and training data (such as intents and entities) within a dialog skill. If you create a new workspace using the API, it will appear as a new dialog skill in the Watson Assistant user interface.\n\nFor a list of the available API methods, see [API methods summary](https://cloud.ibm.com/docs/assistant?topic=assistant-api-methods).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-overview"}, {"document_id": "ibmcld_03383-17365-19519", "score": 53.25113682121895, "text": "\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add"}, {"document_id": "ibmcld_13042-17392-19546", "score": 53.25113682121895, "text": "\nIf you see this happening, consider choosing a different collection field from which to extract search results.\n\nThe Discovery document highlight field stores values in an array.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nOpen the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. From the Assistants page, click to open the tile for the assistant to which you want to add the skill.\n2. Click Add search skill.\n3. Click Add existing skill, then click the skill that you want to add from the available skills that are displayed.\n\n\n\n\n\n\n\n\n\n Search triggers \n\nThe search skill is triggered in the following ways:\n\n\n\n* From a specific dialog node or action step: This approach is useful if you want to narrow down a user query before you trigger a search.\n\nFor example, the conversational flow might collect information about the type of device a customer wants to buy. When you know the device model, you can then send a model keyword in the query that is submitted to the search skill to get better results.\n\nTrigger the search only at a specific point in a conversation in one of the following ways:\n\n\n\n* Dialog skill: Add a search skill response type to a dialog node. When the node is processed, your assistant retrieves a passage from an external data source and returns it as the response to a particular question. This type of search occurs only when the individual dialog node is processed. For more information, see [Adding a search skill response type](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-overviewdialog-overview-add-search-skill).\n* Actions skill: In the And then field of the step where you want the search to be triggered, choose Search for the answer.", "title": "", "source": "https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add"}, {"document_id": "ibmcld_03381-2858-4802", "score": 53.17437620279546, "text": "\n* To define your own intents, see [Defining intents](https://cloud.ibm.com/docs/assistant?topic=assistant-intents).\n\n\n\nThe dialog skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add).\n\n\n\n Troubleshooting skill upload issues \n\nHere are some solutions to typical upload issues:\n\n\n\n* If you get the message, Error. Should NOT be shorter than 1 character, then check whether your skill has a name. If not, add one.\n* The @sys-person and @sys-location system entities are no longer supported. If the skill you are uploading references them in its dialog, an error is displayed. Remove these system entities from your dialog.\n* If you receive a message that says the skill contains artifacts that exceed the limits imposed by your service plan, complete the following steps to upload the skill successfully:\n\n\n\n1. Purchase a plan with higher artifact limits.\n2. Create a service instance in the new plan.\n3. Upload the skill to the new service instance.\n4. If you don't want to keep the higher-level plan, make edits to the skill such that it meets the artifact limit requirements for the plan you want to use going forward.\n\n\n\nFor information about how to decrease the number of dialog nodes, see [How many nodes are in my dialog?](/docs/assistant?topic=assistant-dialog-tasksdialog-tasks-count-nodes).\n\n\n\n1. Download the edited skill to export it.\n2. Try again to upload the edited skill into the original service instance on the plan you want.\n\n\n\n\n\n\n\n\n\n Adding the skill to an assistant \n\nYou can add one dialog skill to an assistant. You must open the assistant tile and add the skill to the assistant from the assistant configuration page; you cannot choose the assistant that will use the skill from within the skill configuration page. One dialog skill can be used by more than one assistant.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add"}, {"document_id": "ibmcld_02882-27313-29495", "score": 53.09429881008812, "text": "\nThis response type only returns a valid response if the assistant to which you added this dialog skill also has a search skill associated with it.\n\n\n\n2. Click Add response to add another response type to the current response.\n\nYou might want to add multiple response types to a single response to provide a richer answer to a user query. For example, if a user asks for store locations, you could show a map and display a button for each store location that the user can click to get address details. To build that type of response, you can use a combination of image, options, and text response types. Another example is using a text response type before a pause response type so you can warn users before pausing the dialog.\n\nYou cannot add more than 5 response types to a single response. Meaning, if you define three conditional responses for a dialog node, each conditional response can have no more than 5 response types added to it.\n\nA single dialog node cannot have more than one Connect to human agent or more than one Search skill response.\n3. If you added more than one response type, you can click the Move up or down arrows to arrange the response types in the order you want your assistant to process them.\n\n\n\n\n\n\n\n\n\n Conditional responses \n\nA single dialog node can provide different responses, each one triggered by a different condition. Use this approach to address multiple scenarios in a single node.\n\nThe node still has a main condition, which is the condition for using the node and processing the conditions and responses that it contains.\n\nIn this example, your assistant uses information that it collected earlier about the user's location to tailor its response, and provide information about the store nearest the user. See [Context variables](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables) for more information about how to store information collected from the user.\n\n![Shows a node that shows a user ask, Where are you located, and the dialog has three different responses depending on conditions that use info from the $state context variable to specify locations in those states.]", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overview"}, {"document_id": "ibmcld_07578-78252-80149", "score": 52.51777196691177, "text": "\nWith the V2 API and an Enterprise plan, you can use the Segment extension to see what browser was used to send the message. For more information, see [Sending events to Segment](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-segment-add).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nWatson Assistant for IBM Cloud Pak for Data (Installed)\n\n\n\n* What's a...\n\n\n\n Term Definition \n\n Assistant Container for your skills. You add skills to an assistant, and then deploy the assistant when you are ready to start helping your customers. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistants). \n Condition Logic that is defined in the If assistant recognizes section of a dialog node that determines whether the node is processed. The dialog node conditions is equivalent to an If statement in If-Then-Else programming logic. \n Content catalog A set of prebuilt intents that are categorized by subject, such as customer care. You can add these intents to your skill and start using them immediately. Or you can edit them to complement other intents that you create. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-catalog). \n Context variable A variable that you can use to collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on. A context variable is used by the dialog skill. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables). \n Dialog The component where you build the conversation that your assistant has with your customers. For each defined intent, you can author the response your assistant should return.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-78227-80124", "score": 52.51777196691177, "text": "\nWith the V2 API and an Enterprise plan, you can use the Segment extension to see what browser was used to send the message. For more information, see [Sending events to Segment](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-segment-add).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nWatson Assistant for IBM Cloud Pak for Data (Installed)\n\n\n\n* What's a...\n\n\n\n Term Definition \n\n Assistant Container for your skills. You add skills to an assistant, and then deploy the assistant when you are ready to start helping your customers. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistants). \n Condition Logic that is defined in the If assistant recognizes section of a dialog node that determines whether the node is processed. The dialog node conditions is equivalent to an If statement in If-Then-Else programming logic. \n Content catalog A set of prebuilt intents that are categorized by subject, such as customer care. You can add these intents to your skill and start using them immediately. Or you can edit them to complement other intents that you create. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-catalog). \n Context variable A variable that you can use to collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on. A context variable is used by the dialog skill. [Learn more](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-variables). \n Dialog The component where you build the conversation that your assistant has with your customers. For each defined intent, you can author the response your assistant should return.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_02914-2824-4863", "score": 52.27608896966527, "text": "\nRetaining information across dialog turns \n\nThe dialog in a dialog skill is stateless, meaning that it does not retain information from one interaction with the user to the next. When you add a dialog skill to an assistant and deploy it, the assistant saves the context from one message call and then re-submits it on the next request throughout the current session. The current session lasts for as long a user interacts with the assistant plus the designated session inactivity time frame. The maximum session inactivity time allowed ranges from 5 minutes to 7 days, depending on your plan type. If you do not add the dialog skill to an assistant, it is your responsibility as the custom application developer to maintain any continuing information that the application needs.\n\nThe application can pass information to the dialog, and the dialog can update this information and pass it back to the application, or to a subsequent node. The dialog does so by using context variables.\n\n\n\n\n\n\n\n Context variables \n\nA context variable is a variable that you define in a node. You can specify a default value for it. Other nodes, application logic, or user input can subsequently set or change the value of the context variable.\n\nYou can condition against context variable values by referencing a context variable from a dialog node condition to determine whether to execute a node. You can also reference a context variable from dialog node response conditions to show different reponses depending on a value provided by an external service or by the user.\n\nLearn more:\n\n\n\n* [Passing context from the application](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-from-app)\n* [Passing context from node to node](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-node-to-node)\n* [Defining a context variable](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-contextdialog-runtime-context-var-define)", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-context"}]}
{"task_id": "34ac6bedd4b35167cc59e289893e206a<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16729-104404-106143", "score": 23.82975499553171, "text": "\nIf you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster\n\nOpenShift Data Foundation is a highly available storage solution that you can use to manage persistent storage for your containerized workloads in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-05-09\n\n\n\n[Creating Red Hat OpenShift on IBM Cloud clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial)Creating Red Hat OpenShift on IBM Cloud clusters\n\nCreate a cluster with worker nodes that come installed with Red Hat OpenShift container orchestration platform.\n\nRed Hat OpenShift on IBM Cloud\n\n\n\n* 45 minutes\n* 2023-07-13\n\n\n\n[Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorial)Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)\n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 45 minutes\n* 2023-07-07\n\n\n\n[Setting capacity quotas for apps that use IBM Cloud Object Storage](https://cloud.ibm.com/docs/openshift?topic=openshift-storage-cos-tutorial-quota)Setting capacity quotas for apps that use IBM Cloud Object Storage", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_10702-7-1940", "score": 23.65462605196653, "text": "\nCreating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC) \n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nWith Red Hat OpenShift on IBM Cloud clusters on VPC, you can create your cluster in the next generation of the IBM Cloud platform, in your [Virtual Private Cloud](https://cloud.ibm.com/docs/vpc?topic=vpc-about-vpc).\n\n\n\n* Red Hat OpenShift on IBM Cloud gives you all the [advantages of a managed offering](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov) for your cluster infrastructure environment, while using the [Red Hat OpenShift tooling and catalog](https://docs.openshift.com/container-platform/4.11/welcome/index.html) that runs on Red Hat Enterprise Linux for your app deployments.\n* VPC gives you the security of a private cloud environment with the dynamic scalability of a public cloud. VPC uses the next version of Red Hat OpenShift on IBM Cloud [infrastructure providers](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providersinfrastructure_providers), with a select group of v2 API, CLI, and console functionality.\n\n\n\nRed Hat OpenShift worker nodes are available for paid accounts and standard clusters only. You can create Red Hat OpenShift clusters that run version 4 only. The operating system is Red Hat Enterprise Linux 7.\n\n\n\n Objectives \n\nIn the tutorial lessons, you create a Red Hat OpenShift on IBM Cloud cluster in a Virtual Private Cloud (VPC). Then, you access built-in Red Hat OpenShift components, deploy an app in a Red Hat OpenShift project, and expose the app on with a VPC load balancer so that external users can access the service.\n\n\n\n\n\n Audience \n\nThis tutorial is for administrators who are creating a cluster in Red Hat OpenShift on IBM Cloud in VPC compute for the first time.\n\n\n\n\n\n Prerequisites \n\nComplete the following prerequisite steps to set up permissions and the command-line environment.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorial"}, {"document_id": "ibmcld_10154-17039-18368", "score": 23.3276591473118, "text": "\nContainer-native virtualization You can set up [container-native virtualization add-on](https://docs.openshift.com/container-platform/4.11/virt/about-virt.html) on bare metal machines, but not on virtual machines. Container-native virtualization is not supported by IBM. If you experience issues, you are responsible for resolving the issues and any impact to your workloads. \n Serverless workloads You can set up [Red Hat OpenShift Serverless](https://www.redhat.com/en/topics/microservices/why-choose-openshift-serverless). You can also set up Red Hat OpenShift Serverless. \n Service mesh You can set up the [Red Hat OpenShift Service Mesh](https://docs.openshift.com/container-platform/4.11/service_mesh/v1x/installing-ossm.html). You can also set up the Red Hat OpenShift Service Mesh, but you must [apply a network policy](https://gist.githubusercontent.com/kitch/39c504a2ed9e381c2aadea436d5b52e4/raw/d8efa69f41d41425b16bb363a881a98d40d3708c/mesh-policy.yaml) for the service mesh ingress to work. \n API and CLI tools OpenShift Container Platform clusters are set up with access to Kubernetes and Red Hat OpenShift API resources. You can also install command line tools such as oc and odo. Red Hat OpenShift on IBM Cloud clusters come with the same capabilities to use the Kubernetes and Red Hat OpenShift API and CLI tools.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}, {"document_id": "ibmcld_16729-218252-220002", "score": 23.084282372900937, "text": "\nA VPC allows you to create your own space in IBM Cloud so that you can run an isolated environment in the public cloud with custom network policies.\n\nVirtual Private Cloud (VPC) Terraform on IBM Cloud\n\n\n\n* 2 hours\n* 2023-04-21\n\n\n\n[Updating VPC worker nodes that use OpenShift Data Foundation](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-vpc)Updating VPC worker nodes that use OpenShift Data Foundation\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 60 minutes\n* 2023-07-11\n\n\n\n[Installing OpenShift Data Foundation on a private cluster](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-odf-private)Installing OpenShift Data Foundation on a private cluster\n\nOpenShift Data Foundation is a highly available storage solution that you can use to manage persistent storage for your containerized workloads in Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae clusters.\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 2 hours\n* 2023-05-09\n\n\n\n[Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc_rh_tutorial)Creating a Red Hat OpenShift cluster in your Virtual Private Cloud (VPC)\n\nCreate an Red Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae cluster in your Virtual Private Cloud (VPC).\n\nRed Hat OpenShift on IBM Cloud Virtual Private Cloud (VPC)\n\n\n\n* 45 minutes\n* 2023-07-07", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_14497-7-1724", "score": 23.011123008119945, "text": "\nVMware Solutions and Red Hat OpenShift overview \n\nIBM Cloud\u00ae for VMware Solutions includes fully automated, rapid deployments of VMware vCenter Server\u00ae in the IBM Cloud. These offerings complement the on-premises infrastructure and allow existing and future workloads to run in the IBM Cloud without conversion by using the same tools, skills, and processes they use on-premises. For more information, see [Virtualization for extending virtualized private cloud](https://www.ibm.com/cloud/architecture/architectures/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae for VMware Solutions is a reference architecture and a manual build process to deploy a Red Hat OpenShift cluster 4.7 on to an existing vCenter Server instance. The components of Red Hat OpenShift cluster are deployed as virtual machines (VMs) and appliances by using NSX software-defined networking.\n\n\n\n* Reference architecture - [vCenter Server and Red Hat OpenShift architecture overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro)\n* Build process - The current document. The process and steps that are needed to install Red Hat OpenShift 4.7 on to an existing vCenter Server instance.\n\n\n\nZoom\n\n![VMware Solutions and Red Hat OpenShift](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"}, {"document_id": "ibmcld_14497-11060-12784", "score": 22.858737470506444, "text": "\nThe NSX DLR virtual machines are configured as an active - passive pair, and vSphere Distributed Resource Scheduler (DRS) anti-affinity rules are created to ensure that the DLR VMs do not run on the same host. This step is described in [Red Hat OpenShift NSX DLR configuration](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-nsxdlr-intro).\n* Update DNS - The infrastructure DNS, provisioned with the vCenter Server instance is updated with the names and IP addresses for the Red Hat OpenShift components by using a PowerShell script. This step is described in [VMware Solutions DNS configuration](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-dns-intro).\n\n\n\n* Phase 2 - Red Hat OpenShift installation. These steps are described in [Red Hat OpenShift 4.7 user provider infrastructure installation](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-install-intro).\n\n\n\n* A Red Hat virtual machine, the bastion node, is provisioned to run the Red Hat OpenShift installer and to host an HTTP Server. It is registered with Red Hat by using your subscription, and the Red Hat OpenShift installer is downloaded.\n* On the bastion node, the install-config.yaml file is populated with the required Red Hat OpenShift parameters and Red Hat OpenShift ignition is used to generate a number of files used for the installation of the bootstrap, control plane, and worker machines.\n* Terraform, on the bastion node, uses the files that are created by Ignition to create the Red Hat OpenShift VMs.\n\n\n\n* Phase 3 - Post deployment activities. Configure a persistent volume for use by the Red Hat OpenShift cluster.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"}, {"document_id": "ibmcld_08259-0-511", "score": 22.80017438687556, "text": "\n\n\n\n\n\n\n  Release notes for Red Hat OpenShift for HPC \n\nUse these release notes to learn about the latest updates to Red Hat\u00ae OpenShift\u00ae for HPC that are grouped by date.\n\n\n\n  March 2022 \n\n\n\n  24 March 2022 \n\nIntroducing Red Hat OpenShift for HPC solutions\n:   You can now take advantage of automated deployment of a Red Hat OpenShift cluster along with a deployer virtual server instance, which allows you to easily assemble, compile, and deploy your HPC applications to the Red Hat OpenShift cluster.\n\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/hpc-openshift?topic=hpc-openshift-release-notes"}, {"document_id": "ibmcld_08006-7-1967", "score": 22.475460112625086, "text": "\nSingle-region IBM Cloud for Financial Services reference architecture for VPC with Red Hat OpenShift on IBM Cloud \n\nIf you want to use containers, you can add [Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-roks-overview) to your VPC. Except for the addition of Red Hat OpenShift on IBM Cloud, you use the same architectural patterns and components that were described for the [Single-region IBM Cloud for Financial Services reference architecture for VPC with Virtual Servers for VPC](https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-vsi).\n\nThe following diagram shows a more detailed view of both the management and workload VPCs when Red Hat OpenShift on IBM Cloud is introduced.\n\n\n\n Architecture diagram \n\nZoom\n\n![Single region IBM Cloud for Financial Services reference architecture for VPC with Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs-content/v1/content/9ac5c38b41e0aa1cb4ccc6cc7f547751ec805221/framework-financial-services/vpc/images/roks-single-region/roks-single-region-consumer-intranet.svg)\n\nFigure 1. Single region IBM Cloud for Financial Services reference architecture for VPC with Red Hat OpenShift on IBM Cloud\n\nYou can choose to use Red Hat OpenShift on IBM Cloud alongside (or instead of) virtual servers in either or both VPCs. Even though it is shown in the diagram as an option, it is not required to put Red Hat OpenShift on IBM Cloud in your management VPC.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud concepts \n\nRed Hat OpenShift on IBM Cloud is a managed offering to create your own Red Hat OpenShift on IBM Cloud cluster of compute hosts to deploy and manage containerized apps on IBM Cloud. Red Hat OpenShift on IBM Cloud provides intelligent scheduling, self-healing, horizontal scaling, service discovery and load balancing, automated rollouts and rollbacks, and secret and configuration management for your apps.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-vpc-architecture-detailed-openshift"}, {"document_id": "ibmcld_10407-7-1954", "score": 22.45612427919176, "text": "\nService limitations \n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud\u00ae and the Red Hat OpenShift open source project come with default service settings and limitations to ensure security, convenience, and basic functionality. Some limitations you might be able to change where noted.\n\nIf you anticipate reaching any of the following Red Hat OpenShift on IBM Cloud limitations, [contact IBM Support](https://cloud.ibm.com/docs/get-support?topic=get-support-using-avatar) and provide the cluster ID, the new quota limit, and the region in your support ticket.\n\n\n\n Service and quota limitations \n\nRed Hat OpenShift on IBM Cloud comes with the following service limitations and quotas that apply to all clusters, independent of what infrastructure provider you plan to use. Keep in mind that the [classic](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_limitationsclassic_limits) and [VPC](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_limitationsks_vpc_gen2_limits) cluster limitations also apply.\n\nTo view quota limits on cluster-related resources in your IBM Cloud account, use the ibmcloud oc quota ls command.\n\n\n\nRed Hat OpenShift on IBM Cloud limitations\n\n Category Description \n\n API rate limits 200 requests per 10 seconds to the Red Hat OpenShift on IBM Cloud API from each unique source IP address. \n App deployment The apps that you deploy to and services that you integrate with your cluster must be able to run on the operating system of the worker nodes. \n Container-native virtualization The Red Hat OpenShift [container-native virtualization add-on](https://docs.openshift.com/container-platform/4.11/virt/about-virt.html) to run VM workloads alongside container workloads is not supported by IBM. If you choose to install the add-on yourself, you must use bare metal machines, not virtual machines. You are responsible for resolving any issues and impact to your workloads from using container-native virtualization.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_limitations"}, {"document_id": "ibmcld_14682-7-2113", "score": 22.348921311392527, "text": "\nVMware vCenter Server and Red Hat OpenShift architecture overview \n\nThe IBM Cloud\u00ae for VMware Solutions offering includes fully automated, rapid deployments of VMware\u00ae vCenter Server\u00ae. This offering complements the on-premises infrastructure and allows existing and future workloads to run on IBM Cloud without conversion by using the same tools, skills, and processes that are used on-premises. For more information, see [Virtualization for extending virtualized private cloud](https://www.ibm.com/cloud/architecture/architectures/virtualizationArchitecture).\n\nRed Hat\u00ae OpenShift\u00ae on IBM Cloud for VMware Solutions provides the capability to deploy a Red Hat OpenShift Cluster by using an automated deployment of the VMware Software Defined Data Center (SDDC) architecture. The Red Hat OpenShift Cluster on IBM Cloud components are deployed as virtual machines (VM) or appliances by using VMware NSX\u00ae software-defined networking.\n\nThis reference architecture is for Red Hat OpenShift clusters deployed on a vCenter Server instance. It provides the foundation for customers who are starting their application modernization journey to the IBM Cloud.\n\n\n\n* vCenter Server is an offering from IBM Cloud for VMware Solutions and is a VMware-based platform that is automatically provisioned on IBM Cloud.\n* Red Hat OpenShift is an application platform for developing and managing containerized applications, which are deployed onto virtualized infrastructure platforms, such as VMware.\n\n\n\nZoom\n\n![IBM Cloud for VMware Solutions and Red Hat OpenShift](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/openshift-sddc.svg)\n\nFigure 1. IBM Cloud for VMware Solutions and OpenShift\n\n\n\n Application modernization on IBM Cloud \n\nApplication modernization is a term that describes the process of transitioning existing applications to use new approaches on the cloud. Customers today are seeking innovative, efficient approaches that help them make this transition based on business and application complexity.\n\nBusiness pressures demand faster time to market.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vcs-openshift-intro"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01533-4546-6910", "score": 30.757857698269717, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4585-6962", "score": 30.720689122500588, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_07578-365833-367834", "score": 28.587751378748234, "text": "\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-365807-367808", "score": 28.587751378748234, "text": "\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07971-2155-4528", "score": 27.972247588933755, "text": "\n* Document and evidence the execution of the system/service and security testing/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https://github.com/IBM/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overview)", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-development-processes"}, {"document_id": "ibmcld_01415-6473-8616", "score": 27.626760464746962, "text": "\nFor more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_faq&interface=ui"}, {"document_id": "ibmcld_01533-6329-8623", "score": 27.27948950868676, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-6381-8675", "score": 27.27948950868676, "text": "\nThis action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results. The possible vulnerabilities are updated daily by using the published security notices for the Docker image types that are listed in the following table. Typically, for a vulnerable package to pass the scan, a later version of the package is required that includes a fix for the vulnerability. The same package can list multiple vulnerabilities, and in this case, a single package update can address multiple vulnerabilities.\n\nVulnerability Advisor returns vulnerabilities only when a package fix is published by the distributor. Declared vulnerabilities that aren't fixed yet, or are not going to be fixed, are not reported by Vulnerability Advisor. Therefore, if Vulnerability Advisor does not report any vulnerabilities, there might still be a risk in the image.\n\nFor version 3, the scanning of an image is triggered in one of the following ways:\n\n\n\n* When a new image is pushed to the registry.\n* When a new security notice is released for a package that is installed in the image, the image is queued for scanning, which might take some time to complete.\n* While an image is tagged in the registry, it is scanned every week.\n\n\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023. For more information about how to update to version 4, see [Update Vulnerability Advisor to version 4 by 19 June 2023](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_notices_va_v4&interface=ui).\n\nFor version 4, the image is indexed the first time that it is pushed. Thereafter, the vulnerability assessment is calculated every time Vulnerability Advisor is queried about that image.\n\nThe following tables show the supported Docker base images that Vulnerability Advisor checks for vulnerable packages.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_06004-36463-38401", "score": 26.984933602938842, "text": "\nAs you plan and develop your app, consider the following options to maintain a secure image, ensure that sensitive information is encrypted, encrypt traffic between app microservices, and control traffic between your app pods and other pods and services in the cluster.\n\nImage security\n: To protect your app, you must protect the image and establish checks to ensure the image's integrity. Review the [image and registry security topic](https://cloud.ibm.com/docs/containers?topic=containers-securityimages_registry) for steps that you can take to ensure secure container images. For example, you might use Vulnerability Advisor to check the security status of container images. When you add an image to your organization's IBM Cloud Container Registry namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index).\n\nKubernetes secrets\n: When you deploy your app, don't store confidential information, such as credentials or keys, in the YAML configuration file, configmaps, or scripts. Instead, use [Kubernetes secrets](https://cloud.ibm.com/docs/containers?topic=containers-securitypi), such as an image pull secret for registry credentials. You can then reference these secrets in your deployment YAML file.\n\nSecret encryption\n: You can encrypt the Kubernetes secrets that you create in your cluster by using a key management service (KMS) provider. To get started, see [Encrypt secrets by using a KMS provider](https://cloud.ibm.com/docs/containers?topic=containers-encryptionkeyprotect) and [Verify that secrets are encrypted](https://cloud.ibm.com/docs/containers?topic=containers-encryptionverify_kms).\n\nMicroservice traffic encryption", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-plan_deploy"}, {"document_id": "ibmcld_01415-4937-6994", "score": 26.73784273379266, "text": "\nIf you have active containers that are running [untagged](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_untagged) images, you must retain the untagged images. If you delete untagged images that are in use, you can cause problems with scaling or automated restarts. Deleting untagged images might cause a problem in the following circumstances:\n\n\n\n* The image was deployed by referencing the image by using the digest.\n* The image reference was mutated by a webhook service, such as [Portieris](https://cloud.ibm.com/docs/Registry?topic=Registry-security_enforce_portieris).\n\n\n\n\n\n\n\n What are eligible images? \n\nIf you are cleaning up images by using retention policies, only eligible images are cleaned up. Images that are always retained are distroless images that do not set a created time, such as Google distroless images and manifest lists. Images that are always retained are not eligible images.\n\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n\n\n\n\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n\n\n\n\n\n\n\n Frequently asked questions about Vulnerability Advisor \n\n\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_faq&interface=ui"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07115-5269-7471", "score": 38.58464700187434, "text": "\nYour documents might not have a text field if you uploaded a CSV file that doesn't have a column named text, or uploaded a JSON file that doesn't have an object named text, or if you used the Smart Document Understanding tool to define fields with other names in which the bulk of the content of your documents now are stored.\n\nWhen you train a project from the API, results are taken from all of the root-level fields and they are all considered to have equal significance. Unlike Discovery Query Language queries, with natural language queries you cannot specify which fields from the document you care about or how much significance to give to each one. When you teach Discovery with examples, the service figures out for you how much weight to give to each field.\n\nDiscovery builds a model that assigns different weights to term, bigram, and skip-gram matches for each of the root-level fields and balances them against matches from all of the other document fields. With enough examples, Discovery can return better answers because it knows where the best answers are typically stored.\n\nRelevancy training cannot be used to give more weight to nested fields. Nested fields are grouped and assigned one overall score. No matter how much you train, Discovery never gives a nested field more weight than it gives to a root-level field. For more information about nested fields, see the [FAQ](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-faqsfaq-nested-fields).\n\n\n\n\n\n Training a project \n\nThe training data that is used to train the relevancy model includes these parts:\n\n\n\n* A natural language query that is representative of a query that your users might submit\n* Results of the query which are returned by the service\n* The rating that you apply to the result that indicates whether the result is relevant or not relevant\n\n\n\nTo apply relevancy training to a project, complete the following steps:\n\n\n\n1. Go to the Improve and customize page. On the Improvement tools panel, select Improve relevance, then Relevancy training.\n2. Enter a natural language query in the Enter a question to train field.\n\nDo not include a question mark in your query. Use the same wording as your users.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-train"}, {"document_id": "ibmcld_07214-57536-59639", "score": 32.516336062812634, "text": "\nImproved query and add functions at top level : id, score, and highlight at the top level (You can continue to add documents to your collection using document IDs with the add a document function. See the [API Reference](https://cloud.ibm.com/apidocs/discoveryadd-a-document) for details. : _ prefixed field names at the top level (as a result, when querying for a document by ID, you can query for id instead of _id.) : and , in the field name : + and - prefixed field names : \"\" empty values for a field name : If your JSON documents include these characters in the field names, or id, score, and highlight at the top level, you need to remove them before adding the documents to your collection, or those fields are empty. You can create a custom configuration and normalize your JSON before adding documents to your collection to avoid this issue. See the [API reference](https://cloud.ibm.com/apidocs/discoveryadd-configuration) for details. In addition, documents that include the punctuation characters ?, :, or in the file name cause errors during ingestion. Before ingesting them, rename any documents that include these characters.\n\nImproved 'natural_language_query' retrieval methods : The retrieval methods for natural_language_query are updated to improve the relevance of results by matching words with related semantics. This update only affects collections that did not undergo relevance training. If you are using natural_language_query and did not conduct relevance training, you might see improvement in the order of results returned.\n\nImproved query builder navigation : Changes to the query builder to make it easier to toggle between the Discovery Query Language and Natural Language query options, as well as among query, filter, and aggregation.\n\n\n\n\n\n 25 August 2017 \n\nImproved 'passages' array : The passages array now includes field, start_offset, and end _offset. field is the name of the field the passage was extracted from. start_offset is the starting character of the passage text within the field. end_offset is the ending character of the passage text within the field.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-release-notes"}, {"document_id": "ibmcld_07163-1627-3707", "score": 32.007851352361946, "text": "\nSee [Confidence scores](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence) for details.\n\nAdding a custom stopwords list can improve the relevance of results for natural language queries. See [Defining stopwords](https://cloud.ibm.com/docs/discovery?topic=discovery-query-conceptsstopwords) for more information.\n\nSee [Training data requirements](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-apireqs) for the minimum requirements for training, as well as the training limits.\n\nSee [Usage monitoring](https://cloud.ibm.com/docs/discovery?topic=discovery-usage) for details on tracking usage and using this data to help you understand and improve your applications.\n\nThe components needed to train a Discovery instance include the following:\n\n\n\n* Training data. This is the set of queries and examples the service uses to refine query results.\n* Query. A natural-language query that applies to the training-data set. Each query has one or more associated examples, as described in the following bullet point. Each query must be unique within the training-data set.\n* Example. This is a document indexed in a Discovery collection that acts as an exemplar, good or bad, for the associated query. When you add an example to a training-data query, you include a relevance label that indicates the relevance (or \"goodness\" versus \"badness\") of the document as it applies to the specified query.\n\nExamples are identified by the indexed document ID. As noted, every example must include a label that indicates the \"goodness\" or \"badness\" of the document as it pertains to the query.\n\nExamples can optionally specify a cross-reference query. The cross-reference query needs to return only the example document and must be independent of the unique Watson Discovery document ID. Cross-reference queries are not currently used automatically but can be used to repair training data in the event that new IDs are assigned to documents during an ingestion event.\n\n\n\n\n\n Training data requirements", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-api"}, {"document_id": "ibmcld_07115-7009-9068", "score": 31.778509629459045, "text": "\n* The rating that you apply to the result that indicates whether the result is relevant or not relevant\n\n\n\nTo apply relevancy training to a project, complete the following steps:\n\n\n\n1. Go to the Improve and customize page. On the Improvement tools panel, select Improve relevance, then Relevancy training.\n2. Enter a natural language query in the Enter a question to train field.\n\nDo not include a question mark in your query. Use the same wording as your users. For example, IBM Watson in healthcare. Write queries that include some of the terms that are mentioned in the target answer. Term overlap improves the initial results when the natural language query is evaluated.\n3. Click Add+.\n4. Click Rate results.\n5. After the results are displayed, assess each result, and then select Relevant or Not relevant, whichever option applies given the quality of the result.\n\nWhen you select Relevant, you apply a score of 10 to the result. Not relevant applies a score of 0. You can use a different scoring scale if you use the API to rate results, but you can't mix scoring scales within the same project.\n\nIf the result shows the message, \u201cNo content preview available for this document\u201d, it means that the document that was returned does not contain a text field or that its text field is empty. If none of the documents in your collection have a text field, use the API to train the project instead of training it from the product user interface.\n6. When you are finished, click Back to queries.\n7. Continue adding queries and rating them.\n\nAs you rate results, your progress is shown. Check your progress to see when enough rating information is available to meet the training threshold needs. Your progress is broken into the following tasks:\n\n\n\n* Add more queries\n* Rate more results\n* Add more variety to your ratings\n\n\n\nYou must evaluate at least 50 unique queries, maybe more, depending on the complexity of your data. You cannot add more than 10,000 training queries.\n8. You can continue adding queries and rating results after you reach the threshold.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-train"}, {"document_id": "ibmcld_00460-32793-34849", "score": 31.357819056949694, "text": "\nPrefer: return=minimal header\n: Added the header Prefer: return=minimal to return only essential headers. This header reduces the size of the request, which gives a performance improvement to nonbrowser clients.\n\nDisabled JavaScript constructors\n: If a user calls the disabled JavaScript constructors, eval() or Function(), an error message similar to this one is returned, Call to eval() was blocked by CSP. You can fix the problem by replacing eval() calls with the calls from the [expr-eval library](https://github.com/silentmatt/expr-eval).\n\n\n\n\n\n 4 December 2017 \n\nRemoved support for virtual hosts\n: IBM Cloudant disabled the virtual host functionality on 4 December 2017. Support for insecure HTTP connections was replaced by HTTPS only. After you turn off HTTP support, the virtual hosts feature is no longer available since use of virtual hosts precludes secure HTTPS connections. Previous users of the virtual host feature need to make alternative arrangements to present a chosen hostname to your clients from your application and use HTTPS connections only.\n\n\n\n\n\n\n\n November 2017 \n\n\n\n 7 November 2017 \n\nIncompatibility between CouchDB version 1.6 and IBM Cloudant version 2.0.0\n: An incompatibility exists between the most recent version of IBM Cloudant and CouchDB 1.6-based codebase. In the older version of IBM Cloudant, if you add a query parameter (\"reduce=false\") to the request body, the parameter in the request body is ignored. However, the parameter in the request URL is respected. In recent versions of IBM Cloudant, the query parameter (\"reduce=false\") in the request body isn't ignored.\n\n\n\n\n\n\n\n October 2017 \n\n\n\n 17 October 2017 \n\nQuery (_find endpoint) improved\n: IBM Cloudant Query now uses a new method to select an index. Learn more about [IBM Cloudant Query index selection](https://www.ibm.com/support/pages/improving-cloudant-query-index-selection).\n\nIndex validation\n: The logic for determining whether a specific index is valid for a query that changed, addressing a bug that might lead to incorrect results.\n\nText indexes", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-classic-release-notes"}, {"document_id": "ibmcld_07214-65893-68177", "score": 31.01328806791523, "text": "\n: The new version string enables enrichments in German (de) or Spanish (es) if the language of a collection is set to one of those languages. Previously, all enrichments were performed in English regardless of a collection's language setting. : If you do not use enrichments in non-English languages, you can continue to use the 2016-12-01 version string. However, to avoid potential future conflicts, it is recommended that you update the version string as soon as possible.\n\nNew anomaly detection availability : Anomaly detection is now available as part of timeslice aggregations as a GA capability.\n\nNew beta improvement to relevancy tooling : Added the beta ability to improve the relevancy of query results using the Discovery tooling (relevancy tooling). See [Improving the relevance of your query results with the Discovery tooling](https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-tooling).\n\n\n\n\n\n 19 June 2017 \n\nNew select language of documents : Added option to specify the language of the documents in a new collection as English, Spanish, or German. To use it, choose Select the language of your documents on the Name your new collection dialog.\n\nAdded a Summary tab to the Build queries screen : The Summary tab displays an overview of the full query results provided in the existing JSON tab. The Summary display varies, based on your query and enrichments. Information that might be displayed includes: document name or ID, aggregation statistics, document passages in order of relevance, and results by enrichment.\n\nAdded a Natural Language Query option to the Build queries screen : To use it, click Ask a question in plain language in the Search for documents section, and a field displays where you can enter your question. You can now access the original query field, formerly titled Enter a query or keyword, by clicking the Use the Discovery Query Language button.\n\nThe Build queries screen was redesigned, but all fields and options remain. : Following are the old and new names for the fields.\n\n Old field name New field or section name \n\n Write and run a query Search for documents \n Narrow your query results (Filter) Limit which documents you query \n Group query results (Aggregation) Include analysis of your results", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-release-notes"}, {"document_id": "ibmcld_07086-6808-9095", "score": 30.82884970678215, "text": "\nFor relevancy training to be used, you must successfully train the project either programmatically ([Create training query method](https://cloud.ibm.com/apidocs/discovery-datacreatetrainingquery)) or by using the product user interface.\n\nQPP\n: A Query Performance Prediction algorithm that, given a query and a list of top results, produces a score that determines how relevant a document is. Used only if no Relevancy training ranker is available.\n\nfilter\n: The filter parameter can be passed along with query and natural_language_query requests to remove documents that don't meet certain criteria from the result set. The filter is shown as the last step within the document retrieval phase. However, it is used at different times in the flow. Its placement in the diagram is chosen to emphasize the fact that any documents that don't match the filter definition are excluded from the result set. The exclusion applies even to documents that might be specified in a curation.\n\nPassage retrieval\n: Returns passages from documents when the passages.enabled=true parameter is included with a natural language query request.\n\nAnswer finding\n: When the passages.find_answers=true parameter is included with a natural language query request, returns succinct answers from passages along with the passages that are extracted from documents. If answer finding is enabled, then the final confidence score for each search result is a combination of the confidence scores from answer finding, passage retrieval, and QPP or Reranked search, whichever method is used.\n\nTable retrieval\n: Returns information from tables in documents when the table_results.enabled=true parameter is included with a natural language query request.\n\n\n\n\n\n Query limits \n\nA query is any operation that submits a POST request to the /query endpoint of the API. Such operations include queries that are submitted by using the API. It does not include queries that are submitted from the search bar on the Improve and customize page of the product user interface.\n\nA query is counted only if the request is successful, meaning it returns a response (with message code 200).\n\nThe number of search queries that you can submit per month per service instance depends on your Discovery plan type.\n\n\n\nNumber of queries per month", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-query-concepts"}, {"document_id": "ibmcld_00460-10355-12276", "score": 30.438019220492652, "text": "\n: Introduce the Mango query operator, $keyMapMatch that offers the ability to make queries on the keys of a map.\n\nImprovements\n: Internal bug fixes.\n\nDatabase reporting\n: Report the database that was used for authentication for a GET /_session request, provided it is configured.\n\n\n\n\n\n\n\n September 2020 \n\n\n\n 1 September 2020 \n\nThe following changes were made in build 8162:\n\nImprovements\n: Internal bug fixes.\n\nDrilldown parameters\n: Drilldown parameters for text index searches can now be specified as a list of lists, which gives you the ability to avoid having to define it redundantly in a single query. Some languages don't have this facility.\n\ncouch_index server\n: The couch_index server doesn't crash and log errors in the following cases: If a design document is deleted while that index is building, or when a design document is added immediately after database creation.\n\nInvalid parameters\n: IBM Cloudant now checks for and reports invalid parameters on database creation.\n\n\n\n\n\n\n\n July 2020 \n\n\n\n 1 July 2020 \n\nThe following changes were made in build 8158:\n\nImprovements\n: Internal bug fixes.\n\n\n\n\n\n\n\n May 2020 \n\n\n\n 15 May 2020 \n\nThe following changes were made in build 8153:\n\nImprovements\n: Internal bug fixes.\n\n\n\n\n\n\n\n April 2020 \n\n\n\n 1 April 2020 \n\nThe following changes were made in build 8152:\n\nImprovements\n: Internal bug fixes.\n\n\n\n\n\n\n\n March 2020 \n\n\n\n 15 March 2020 \n\nThe following changes were made in build 8142:\n\nNew! Endpoints\n: New endpoints were added, so you can post multiple queries: POST /{db}/_all_docs/queries and POST /{db}/_design_docs/queries.\n\nMultiple queries\n: The ability to submit multiple queries against a view by using the POST to /{db}/_design/{ddoc}/_view/{view} with the ?queries option was replaced by the new queries endpoint. The same is true of the _all_docs and _design_docs endpoints. Specify a keys object when you POST to these endpoints.\n\ndisk_size and data_size fields", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-classic-release-notes"}, {"document_id": "ibmcld_13480-7-2163", "score": 30.202897949485823, "text": "\nGetting started with the catalog \n\nEach instance of IBM Cloud\u00ae Data Engine includes a database catalog that you can use to register and manage table definitions for your data on IBM Cloud\u00ae Object Storage. Catalog syntax is compatible with Hive metastore syntax. See how to [work with the catalog](https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalogusage) and refer to the [Catalog management](https://cloud.ibm.com/docs/sql-query?topic=sql-query-sql-referencechapterHiveCatalog) section of the SQL reference.\n\n\n\n Benefits \n\nYou can explore, change, or discover structured data on [Cloud Object Storage](https://cloud.ibm.com/docs/services/cloud-object-storage/getting-started.htmlgetting-started-console) with Data Engine by using SQL syntax. To query data on Object Storage without a table in the catalog, you need to specify the data location (the corresponding Object Storage URI) and the data format in your SELECT statement. During query execution, data and schema are dynamically discovered as part of the SQL compilation process. This process, called inference, derives column names, data types, the list of partitions, and individual objects on Object Storage that together make up the table data.\n\nInferring all this information and doing it repetitively with every query imposes latency to your queries. The inference process can take up a significant amount of time, especially for text formats (for example, CSV and JSON), or when thousands of objects exist in different table partitions. In some cases, the inference process even accounts for the largest part of the overall query execution time. So, if you are either familiar with the schema, or want to repetitively use the data for queries, create a table in the catalog. Such a table improves performance for repeated query executions.\n\nAnother advantage of creating a table in the catalog is that the table name serves as an alias and is decoupled from the data location. Hence, you can separate the tasks of data engineers and SQL authors. Data engineers deal with the data location and publish registered tables in the catalog by using descriptive table names.", "title": "", "source": "https://cloud.ibm.com/docs/sql-query?topic=sql-query-getting_started_catalog"}, {"document_id": "ibmcld_07395-1443-2217", "score": 29.99589679195609, "text": "\nThe specific IDs of affected VPCs.\n2. The IDs of the DNS Services private resource records (if any).\n3. The IDs of zones that have affected private resource records (if any).\n4. The DNS queries made. If possible, give the details on DNS queries related to the issue, including DNS message ID and timestamp for each.\n5. Information about the source of the DNS query (for example, the ID of the VPC from which the query originated).\n6. If it affects a custom resolver, then include the custom resolver ID.\n7. If it affects a GLB health check, then include the GLB health check ID and the IDs of affected GLBs.\n8. If it is an issue with a forwarding rule, then include the forwarding rule ID.\n9. If it is an issue with a secondary zone, then include the secondary zone rule ID.", "title": "", "source": "https://cloud.ibm.com/docs/dns-svcs?topic=dns-svcs-gettinghelp"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02114-9608-11655", "score": 22.889092732549027, "text": "\n: Provide a comma-separated list of pricing plans that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--provider PROVIDER (optional)\n: Provide a comma-separated list of providers that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--release RELEASE (optional)\n: Provide a comma-separated list of categories that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--type TYPE (optional)\n: Provide a comma-separated list of software types that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n\n\n\n\n\n\n ibmcloud catalog filter delete \n\nRun the following command to delete an applied filter. This filter defaults to the account level unless a catalog is specified. As a result, the filter is reset to include all products in the public catalog.\n\nibmcloud catalog filter delete --catalog CATALOG\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n\n\n\n\n\n\n ibmcloud catalog filter offering \n\nUpdate the filter to include or exclude a particular product and any applicable pricing plans. This filter defaults to the account level unless a catalog or account group is specified.\n\nibmcloud catalog filter offering --offering PRODUCT-NAME\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n--plans-list PLANS LIST\n: A comma-separated list of plan IDs or names to include or exclude.\n\n--offering OFFERING\n: The product name or ID.\n\n--include\n: The default value is true if a flag is not provided. Valid values are true and false. If set to true, the product and plans provided are visible to users in the account. If set to false, the product and plans aren't visible to users in the account.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-manage-catalogs-plugin"}, {"document_id": "ibmcld_04491-9608-11655", "score": 22.889092732549027, "text": "\n: Provide a comma-separated list of pricing plans that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--provider PROVIDER (optional)\n: Provide a comma-separated list of providers that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--release RELEASE (optional)\n: Provide a comma-separated list of categories that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--type TYPE (optional)\n: Provide a comma-separated list of software types that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n\n\n\n\n\n\n ibmcloud catalog filter delete \n\nRun the following command to delete an applied filter. This filter defaults to the account level unless a catalog is specified. As a result, the filter is reset to include all products in the public catalog.\n\nibmcloud catalog filter delete --catalog CATALOG\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n\n\n\n\n\n\n ibmcloud catalog filter offering \n\nUpdate the filter to include or exclude a particular product and any applicable pricing plans. This filter defaults to the account level unless a catalog or account group is specified.\n\nibmcloud catalog filter offering --offering PRODUCT-NAME\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n--plans-list PLANS LIST\n: A comma-separated list of plan IDs or names to include or exclude.\n\n--offering OFFERING\n: The product name or ID.\n\n--include\n: The default value is true if a flag is not provided. Valid values are true and false. If set to true, the product and plans provided are visible to users in the account. If set to false, the product and plans aren't visible to users in the account.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-manage-catalogs-plugin"}, {"document_id": "ibmcld_12577-9608-11655", "score": 22.889092732549027, "text": "\n: Provide a comma-separated list of pricing plans that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--provider PROVIDER (optional)\n: Provide a comma-separated list of providers that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--release RELEASE (optional)\n: Provide a comma-separated list of categories that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n--type TYPE (optional)\n: Provide a comma-separated list of software types that you want to include or exclude. Run the ibmcloud catalog filter options command to view all options.\n\n\n\n\n\n\n\n ibmcloud catalog filter delete \n\nRun the following command to delete an applied filter. This filter defaults to the account level unless a catalog is specified. As a result, the filter is reset to include all products in the public catalog.\n\nibmcloud catalog filter delete --catalog CATALOG\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n\n\n\n\n\n\n ibmcloud catalog filter offering \n\nUpdate the filter to include or exclude a particular product and any applicable pricing plans. This filter defaults to the account level unless a catalog or account group is specified.\n\nibmcloud catalog filter offering --offering PRODUCT-NAME\n\n\n\n Command options \n\n--catalog CATALOG\n: The catalog name or ID.\n\n--account-group ACCOUNT GROUP\n: The account group name or ID. This option applies only to enterprise accounts.\n\n--plans-list PLANS LIST\n: A comma-separated list of plan IDs or names to include or exclude.\n\n--offering OFFERING\n: The product name or ID.\n\n--include\n: The default value is true if a flag is not provided. Valid values are true and false. If set to true, the product and plans provided are visible to users in the account. If set to false, the product and plans aren't visible to users in the account.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-manage-catalogs-plugin"}, {"document_id": "ibmcld_12857-1800-3864", "score": 20.808898952992337, "text": "\nClick I plan to offer free pricing plans.\n4. Click the IBM Digital Provider Agreement link to review the agreement.\n5. Select I understand and agree to the IBM Digital Provider Agreement, and click Save.\n\n\n\n\n\n\n\n Step 2: Provide your service name and type \n\nWhen you add a product, you can add a new product or import an existing product from a private catalog. For the purposes of this tutorial, add a new product.\n\n\n\n1. Click My Products > Create.\n2. Enter the name of your product, for example, Example Corp SaaS Product. Make sure that the name you enter meets the following requirements:\n\n\n\n* Use 60 characters or less.\n* Don't include \"IBM Cloud\".\n* Don't include the name of your company, former product names, or pricing details.\n\n\n\n3. Select Software as a Service as the type of product that you're onboarding, and click Add.\n\nThe product type that you select is used for tax assessment purposes.\n\n\n\n\n\n\n\n Step 3: Confirm your display name and programmatic name for approval \n\nYour programmatic name is different than the name that you provided in the previous step. It's automatically generated for you and includes your company name. If your company offers multiple products in IBM Cloud, the value of each service name includes both the company name and product name.\n\nYour programmatic name must be approved to create your pricing plans or registering your service broker. You can review and make updates to your programmatic name before you submit it for approval.\n\nYour programmatic name can't be updated after you submit it for review.\n\n\n\n1. From the Dashboard tab, click Edit, enter your updates, and click Save.\n2. Click Confirm.\n\n\n\n\n\n\n\n Step 4: Create your service ID \n\nAfter your programmatic name is review, you can create your service ID. A service ID is used to identify your service when you communicate with other IBM Cloud services, for example, when you submit metering usage data for your service. For more information, see [Creating and working with service IDs](https://cloud.ibm.com/docs/account?topic=account-serviceids&interface=ui).", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-svc-define"}, {"document_id": "ibmcld_01805-25778-27379", "score": 20.33884300986724, "text": "\nUse the following steps to import a product to your private catalog by using Terraform.\n\n\n\n1. Add your argument to your main.tf file. The following example adds your product by using the ibm_cm_offering resource, where label is a display name to identify the product.\n\nresource \"ibm_cm_offering\" \"cm_offering\" {\ncatalog_id = \"catalog_id\"\nlabel = \"label\"\ntags = [ \"tags\" ]\n}\n\nFor more information, see the argument reference details on the [Terraform Catalog Management](https://registry.terraform.io/providers/IBM-Cloud/ibm/latest/docs/resources/cm_offering) page.\n2. After you finish building your configuration file, initialize the Terraform CLI. For more information, see [Initializing Working Directories](https://www.terraform.io/cli/init).\n\nterraform init\n3. Provision the resources from the main.tf file. For more information, see [Provisioning Infrastructure with Terraform](https://www.terraform.io/cli/run).\n\n\n\n1. Run terraform plan to generate a Terraform execution plan to preview the proposed actions.\n\nterraform plan\n2. Run terraform apply to create the resources that are defined in the plan.\n\nterraform apply\n\n\n\n\n\n\n\n\n\n Importing a version of your software by using Terraform \n\nAfter you add your product, use the following steps to add a version of your software by using Terraform.\n\n\n\n1. Add your argument to your main.tf file. The following example accesses the software version by using the cm_version resource, where offering_id identifies the software.\n\nresource \"cm_version\" \"cm_version\" {\ncatalog_identifier = \"catalog_identifier\"\noffering_id = \"offering_id\"\nzipurl = \"zipurl\"\n}", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-create-private-catalog&interface=ui"}, {"document_id": "ibmcld_12838-7607-9492", "score": 19.85715993699526, "text": "\nAll plans for a product use either global or per location. By selecting per location, you can specify different regions or data centers for each plan that you add.\n8. Link a broker to the plan.\n\nIf you haven't finished adding a broker to your account, you will not see this option, and you can continue and save your pricing plan. However, you can't complete your pricing plan until the broker is added and linked to your plan.\n9. Click Save.\n\n\n\n\n\n\n\n Adding a paid pricing plan \n\nBy adding a usage-based pricing plan, you are indicating that you offer your product as a paid integrated product, and customers need to pay to use it. All information that is entered on the Add plan panel is displayed to customers in the IBM Cloud catalog to help them purchase your service.\n\nWhen you add a usage-based pricing plan, you provide your suggested retail pricing information. However, IBM reserves the right to set the final pricing for any product that is offered to customers in the IBM Cloud catalog.\n\nTo add a paid pricing plan for your service, complete the following steps:\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https://cloud.ibm.com/docs-content/v1/content/ff5860bfede49db3197c4bbba7f7123769bdc068/icons/icon_hamburger.svg) > Partner Center > Sell > My products.\n2. Select the product that you're onboarding, and click Pricing.\n3. Click Add plan.\n4. Select Usage-based.\n5. Enter a name for your plan.\n6. Describe the details of your plan.\n7. Choose the locations where your plan is available. All plans for a product use either global or per location. By selecting per location, you can specify different regions or data centers for each plan that you add.\n8. Select a broker to link to the plan.\n\nIf you haven't finished adding the broker to your account, you will not see this option, and you can continue and save your pricing plan.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-service-pricing-info"}, {"document_id": "ibmcld_12838-7-2044", "score": 19.354408711977207, "text": "\nDefining your pricing plan \n\nWhen you onboard your service to IBM Cloud\u00ae, you must define a pricing plan. If you have detailed knowledge about how you want to charge users for your service, you can provide that information in your plan. However, you can start by enabling a free plan, and then set up a paid plan later if your needs change. Currently, IBM Cloud supports free and paid usage-based pricing plans.\n\n\n\n Before you begin \n\nBefore you submit a pricing plan for approval, you must sign the required agreements, documentation, and provide the Export Control Classification Number (ECCN) and United Nations Standard Products and Services Code (UNSPSC) that applies to your product. The prerequisites might differ depending on whether you have a free or usage-based pricing plan.\n\nFor free plans:\n\n\n\n* Provide the ECCN that applies to your product.\n* Provide the UNSPSC that applies to your product.\n* Confirm the digital platform agreement.\n\n\n\nFor paid, usage-based plans:\n\n\n\n* Provide the ECCN that applies to your product.\n* Provide the UNSPSC that applies to your product.\n* Submit your tax and Electronic Funds Transfer (EFT) information for paid plans to set up and receive payment disbursements for usage.\n* Confirm the digital platform reseller agreement.\n\n\n\nDepending on the type of plan you're adding, complete each prerequisite by using the following instructions.\n\n\n\n Submitting tax and EFT forms \n\nFor services that you offer on IBM Cloud with a paid, usage-based pricing plan, you receive disbursements based on the usage in accordance with your pricing structure. To receive disbursements, you must complete and submit the EFT form and tax documentation.\n\nTo provide tax and EFT information, complete the following steps:\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https://cloud.ibm.com/docs-content/v1/content/ff5860bfede49db3197c4bbba7f7123769bdc068/icons/icon_hamburger.svg) > Partner Center > Sell > Payments to me.\n2. Download the relevant EFT form, and complete it.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-service-pricing-info"}, {"document_id": "ibmcld_02114-11278-13293", "score": 19.237960573750716, "text": "\n: A comma-separated list of plan IDs or names to include or exclude.\n\n--offering OFFERING\n: The product name or ID.\n\n--include\n: The default value is true if a flag is not provided. Valid values are true and false. If set to true, the product and plans provided are visible to users in the account. If set to false, the product and plans aren't visible to users in the account.\n\n\n\n\n\n\n\n ibmcloud catalog filter hide-ibm-public-catalog \n\nBy default, the IBM Cloud catalog is visible to all users in the account. You can make products available only to the users you choose by turning off visibility to the IBM Cloud catalog and adding the products to your private catalogs.\n\nibmcloud catalog filter hide-ibm-public-catalog\n\n\n\n\n\n ibmcloud catalog filter show-ibm-public-catalog \n\nBy default, the IBM Cloud catalog is visible to all users in the account. You can make products available only to the users you choose by turning off visibility to the IBM Cloud catalog and adding the products to your private catalogs.\n\nibmcloud catalog filter show-ibm-public-catalog\n\n\n\n\n\n ibmcloud catalog filter options \n\nRun the following command to retrieve the filter options for each filter category.\n\nibmcloud catalog filter options\n\n\n\n Command options \n\n-- all\n: Includes industry, solution type, and pricing plan in the list of filters.\n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nDeployment target ID\nIBM Cloud Kubernetes Service target_iks\nIBM Cloud Schematics target_terraform\nRed Hat OpenShift target_roks\nVMware vCenter Server target_vcenter\nVirtual private cloud target_vpc-x86\nPower Systems Virtual Server target_power-iaas\n\nProvider ID\nThird party ibm_third_party\nCommunity ibm_community\nIBM ibm_created\n\nWorks with ID\nSAP Certified sap_certified\nQuantum Technologies quantum_tech\nSatellite Enabled satellite_enabled\nHPC hpc\n\nDelivery method ID", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-manage-catalogs-plugin"}, {"document_id": "ibmcld_04491-11278-13293", "score": 19.237960573750716, "text": "\n: A comma-separated list of plan IDs or names to include or exclude.\n\n--offering OFFERING\n: The product name or ID.\n\n--include\n: The default value is true if a flag is not provided. Valid values are true and false. If set to true, the product and plans provided are visible to users in the account. If set to false, the product and plans aren't visible to users in the account.\n\n\n\n\n\n\n\n ibmcloud catalog filter hide-ibm-public-catalog \n\nBy default, the IBM Cloud catalog is visible to all users in the account. You can make products available only to the users you choose by turning off visibility to the IBM Cloud catalog and adding the products to your private catalogs.\n\nibmcloud catalog filter hide-ibm-public-catalog\n\n\n\n\n\n ibmcloud catalog filter show-ibm-public-catalog \n\nBy default, the IBM Cloud catalog is visible to all users in the account. You can make products available only to the users you choose by turning off visibility to the IBM Cloud catalog and adding the products to your private catalogs.\n\nibmcloud catalog filter show-ibm-public-catalog\n\n\n\n\n\n ibmcloud catalog filter options \n\nRun the following command to retrieve the filter options for each filter category.\n\nibmcloud catalog filter options\n\n\n\n Command options \n\n-- all\n: Includes industry, solution type, and pricing plan in the list of filters.\n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nDeployment target ID\nIBM Cloud Kubernetes Service target_iks\nIBM Cloud Schematics target_terraform\nRed Hat OpenShift target_roks\nVMware vCenter Server target_vcenter\nVirtual private cloud target_vpc-x86\nPower Systems Virtual Server target_power-iaas\n\nProvider ID\nThird party ibm_third_party\nCommunity ibm_community\nIBM ibm_created\n\nWorks with ID\nSAP Certified sap_certified\nQuantum Technologies quantum_tech\nSatellite Enabled satellite_enabled\nHPC hpc\n\nDelivery method ID", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-manage-catalogs-plugin"}, {"document_id": "ibmcld_12577-11278-13293", "score": 19.237960573750716, "text": "\n: A comma-separated list of plan IDs or names to include or exclude.\n\n--offering OFFERING\n: The product name or ID.\n\n--include\n: The default value is true if a flag is not provided. Valid values are true and false. If set to true, the product and plans provided are visible to users in the account. If set to false, the product and plans aren't visible to users in the account.\n\n\n\n\n\n\n\n ibmcloud catalog filter hide-ibm-public-catalog \n\nBy default, the IBM Cloud catalog is visible to all users in the account. You can make products available only to the users you choose by turning off visibility to the IBM Cloud catalog and adding the products to your private catalogs.\n\nibmcloud catalog filter hide-ibm-public-catalog\n\n\n\n\n\n ibmcloud catalog filter show-ibm-public-catalog \n\nBy default, the IBM Cloud catalog is visible to all users in the account. You can make products available only to the users you choose by turning off visibility to the IBM Cloud catalog and adding the products to your private catalogs.\n\nibmcloud catalog filter show-ibm-public-catalog\n\n\n\n\n\n ibmcloud catalog filter options \n\nRun the following command to retrieve the filter options for each filter category.\n\nibmcloud catalog filter options\n\n\n\n Command options \n\n-- all\n: Includes industry, solution type, and pricing plan in the list of filters.\n\n--output FORMAT (optional)\n: Specifies output format. The default is terminal compatible and the only supported alternative is JSON, for example, --output json.\n\n\n\n\n\n Output \n\nThe command returns the following output:\n\nDeployment target ID\nIBM Cloud Kubernetes Service target_iks\nIBM Cloud Schematics target_terraform\nRed Hat OpenShift target_roks\nVMware vCenter Server target_vcenter\nVirtual private cloud target_vpc-x86\nPower Systems Virtual Server target_power-iaas\n\nProvider ID\nThird party ibm_third_party\nCommunity ibm_community\nIBM ibm_created\n\nWorks with ID\nSAP Certified sap_certified\nQuantum Technologies quantum_tech\nSatellite Enabled satellite_enabled\nHPC hpc\n\nDelivery method ID", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-manage-catalogs-plugin"}]}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13770-6649-7831", "score": 16.960902286120763, "text": "\nThe request specifies the speaker ID for the speaker named speaker_one and the customization ID for the custom model that was created in the first step. The Content-Type header of the request must be multipart/form-data.\n\nIBM Cloud\n\ncurl -X POST -u apikey:{apikey} --header \"Content-Type:multipart/form-data\" --form metadata=\"{\"prompt_text\": \"Thank you and good-bye!\", \"speaker_id\": \"56367f89-546d-4b37-891e-4eb0c13cc833\"}\" --form file=@goodbye-prompt.wav \"{url}/v1/customizations/82f4809a-bf63-89a6-52ca-22731fe467ba/prompts/goodbye\"\n\nIBM Cloud Pak for Data\n\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type:multipart/form-data\" --form metadata=\"{\"prompt_text\": \"Thank you and good-bye!\", \"speaker_id\": \"56367f89-546d-4b37-891e-4eb0c13cc833\"}\" --form file=@goodbye-prompt.wav \"{url}/v1/customizations/82f4809a-bf63-89a6-52ca-22731fe467ba/prompts/goodbye\"\n\nThe service returns the following response with information about the prompt, including its initial status:\n\n{\n\"prompt\": \"Thank you and good-bye!\",\n\"prompt_id\": \"goodbye\",\n\"status\": \"processing\",\n\"speaker_id\": \"823068b2-ed4e-11ea-b6e0-7b6456aa95cc\"\n}\n\nAdding a prompt is an asynchronous operation.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-tbe-create"}, {"document_id": "ibmcld_03137-4194-5167", "score": 16.16033788658716, "text": "\nIf it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.\n\nFor example, if a user enters a sentence like I wnt to buy a boook, fuzzy matching recognizes that the term boook means the same thing as your entity value book, and adds it to the protected words list. Your assistant corrects the input to be, I want to buy a boook. Notice that it corrects wnt but does not correct the spelling of boook. If you see this type of result when you are testing your dialog, you might think your assistant is misbehaving. However, your assistant is not. Thanks to fuzzy matching, it correctly identifies boook as a @reading_material entity mention. And thanks to autocorrection revising the term to want, your assistant is able to map the input to your buy_something intent. Each feature does its part to help your assistant understand the meaning of the user input.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-autocorrection"}, {"document_id": "ibmcld_13877-35297-36247", "score": 15.313220244956952, "text": "\nRelated content \n\n\n\n* [Security to safeguard and monitor your cloud apps](https://www.ibm.com/cloud/garage/architectures/securityArchitecture)\n* [IBM Cloud Platform security](https://cloud.ibm.com/docs/overview?topic=overview-securitysecurity)\n* [Security in the IBM Cloud](https://www.ibm.com/cloud/security)\n* Tutorial: [Best practices for organizing users, teams, applications](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applicationsusers-teams-applications)\n* Blog: [Secure Apps on IBM Cloud with Wildcard Certificates](https://www.ibm.com/cloud/blog/secure-apps-on-ibm-cloud-with-wildcard-certificates)\n* Blog: [Cloud Offboarding: How to Remove a User and Maintain Security](https://www.ibm.com/cloud/blog/cloud-offboarding-how-to-remove-a-user-and-maintain-security)\n* Blog: [Going Passwordless on IBM Cloud Thanks to FIDO2](https://www.ibm.com/cloud/blog/going-passwordless-on-ibm-cloud-thanks-to-fido2)", "title": "", "source": "https://cloud.ibm.com/docs/tutorials?topic=solution-tutorials-cloud-e2e-security"}, {"document_id": "ibmcld_05374-5986-7899", "score": 13.720640023872537, "text": "\nI took the exact same code I did from Heroku. I created a new project and then I created an application and I just pushed it and it just worked so imagine what you can do with that for yourself. This shows the power that is Code Engine and on a free tier it is truly free - just like Heroku was or will be or was will won't be in the future. Code Engine is free forever, which is great and hopefully, it'll make your life a little easier.\n\nThanks so much for watching and if you have any questions, my Twitter handle is @jjasghar or you're more than welcome to email me at [awesome@ibm.com](mailto:awesome@ibm.com). My job is to be a personable nerd so never hesitate to reach out.\n\nThanks so much.\n\nBye y'all.\n\n\n\n\n\n\n\n Prerequisites \n\nBefore you can get started with Code Engine, you need to set up your account and install the CLI.\n\n\n\n* All Code Engine users are required to have a Pay-as-you-Go account.\n* While you can use Code Engine through the console, the examples in this documentation focus on the command line. Therefore, you must install the Code Engine CLI.\n\nibmcloud plugin install code-engine\n\nFor more information, see [setting up the Code Engine CLI](https://cloud.ibm.com/docs/codeengine?topic=codeengine-install-cli). For more information about the CLI, see [Code Engine CLI reference](https://cloud.ibm.com/docs/codeengine?topic=codeengine-cli).\n\n\n\n\n\n\n\n Comparing Heroku and Code Engine terminology \n\nBefore you get started with deploying apps in Code Engine, learn the basics about Code Engine. The following table describes some high-level terminology differences between Cloud Foundry and Code Engine.\n\n\n\nTable 1. Terminology\n\n Heroku Code Engine Description \n\n N/A Resource group and projects A grouping of workloads. The specific choice of which workload goes into each grouping is defined by the user. \"Resource groups\" are an IBM Cloud concept, while \"projects\" are Code Engine specific.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-heroku-migrate"}, {"document_id": "ibmcld_16267-2886-4844", "score": 13.720640023872537, "text": "\n* Words containing special characters, such as hyphens (-), asterisks (*), ampersands (&), or at signs (@), including those used in email addresses or URLs.\n* Words that belong, meaning words that have implied significance because they occur in your action steps or dialog entity values, entity synonyms, or intent user examples.\n\n\n\n\n\n How is spelling autocorrection related to fuzzy matching? \n\nIn dialog, fuzzy matching helps your assistant recognize dictionary-based entity mentions in user input. It uses a dictionary lookup approach to match a word from the user input to an existing entity value or synonym in the skill's training data. For example, if the user enters boook, and your training data contains a @reading_material entity with a book value, then fuzzy matching recognizes that the two terms (boook and book) mean the same thing.\n\nIn dialog, when you enable both autocorrection and fuzzy matching, the fuzzy matching function runs before autocorrection is triggered. If it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.\n\nFor example, if a user enters a sentence like I wnt to buy a boook, fuzzy matching recognizes that the term boook means the same thing as your entity value book, and adds it to the protected words list. Your assistant corrects the input to be, I want to buy a boook. Notice that it corrects wnt but does not correct the spelling of boook. If you see this type of result when you are testing your dialog, you might think your assistant is misbehaving. However, your assistant is not. Thanks to fuzzy matching, it correctly identifies boook as a @reading_material entity mention. And thanks to autocorrection revising the term to want, your assistant is able to map the input to your buy_something intent. Each feature does its part to help your assistant understand the meaning of the user input.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-autocorrection"}, {"document_id": "ibmcld_02932-4408-6545", "score": 13.472057995037641, "text": "\nFor example, if the user enters boook, and your training data contains a @reading_material entity with a book value, then fuzzy matching recognizes that the two terms (boook and book) mean the same thing.\n\nWhen you enable both autocorrection and fuzzy matching, the fuzzy matching function runs before autocorrection is triggered. If it finds a term that it can match to an existing dictionary entity value or synonym, it adds the term to the list of words that belong to the skill, and does not correct it.\n\nFor example, if a user enters a sentence like I wnt to buy a boook, fuzzy matching recognizes that the term boook means the same thing as your entity value book, and adds it to the protected words list. Your assistant corrects the input to be, I want to buy a boook. Notice that it corrects wnt but does not correct the spelling of boook. If you see this type of result when you are testing your dialog, you might think your assistant is misbehaving. However, your assistant is not. Thanks to fuzzy matching, it correctly identifies boook as a @reading_material entity mention. And thanks to autocorrection revising the term to want, your assistant is able to map the input to your buy_something intent. Each feature does its part to help your assistant understand the meaning of the user input.\n\n\n\n\n\n How autocorrection works \n\nNormally, user input is saved as-is in the text field of the input object of the message. If, and only if the user input is corrected in some way, a new field is created in the input object, called original_text. This field stores the user's original input that includes any misspelled words in it. And the corrected text is added to the input.text field.\n\nIf you want to ask users to confirm the assistant's understanding of their meaning, you can do so in a way that takes into account that their input might have been corrected. Set the condition for the dialog node or conditional response that is asking for confirmation to original_text. This means that if the user's input was automatically corrected, show the corresponding response. And the response can contain the expression: You said: <?", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-spell-check"}, {"document_id": "ibmcld_13878-17352-18831", "score": 13.405818462101003, "text": "\n* Tutorial: [Apply end to end security to a cloud application](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-cloud-e2e-security)\n* Tutorial: [Best practices for organizing users, teams, applications](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applications)\n* Blog: [Cloud App Security: What Makes a Secure App?](https://www.ibm.com/cloud/blog/cloud-app-security)\n* Blog: [Onboarding Cloud Projects: Security and Resource Considerations](https://www.ibm.com/cloud/blog/onboarding-cloud-projects-security-and-resource-considerations)\n* Blog: [Use Your FIDO2 Key for 2FA on IBM Cloud Apps](https://www.ibm.com/cloud/blog/use-your-fido2-key-for-2fa-on-ibm-cloud-apps)\n* Blog: [Going Passwordless on IBM Cloud Thanks to FIDO2](https://www.ibm.com/cloud/blog/going-passwordless-on-ibm-cloud-thanks-to-fido2)\n* Blog: [IBM Cloud Security Hands-On: Share Your Chatbot Project](https://www.ibm.com/cloud/blog/share-your-chatbot-project)\n* Blog: [Increase Information Security for Db2 on IBM Cloud](https://www.ibm.com/cloud/blog/increase-information-security-for-db2-on-ibm-cloud)\n* IBM Architecture Center: [Security to safeguard and monitor your cloud apps](https://www.ibm.com/cloud/architecture/architectures/securityArchitecture)\n* [IBM Cloud platform service CLIs and APIs](https://cloud.ibm.com/docs/overview?topic=overview-platform-svc-cli-api)\n* [IBM Cloud Compliance Programs](https://www.ibm.com/cloud/compliance)", "title": "", "source": "https://cloud.ibm.com/docs/tutorials?topic=solution-tutorials-extended-app-security"}, {"document_id": "ibmcld_02718-4890-5645", "score": 13.32562295454032, "text": "\nSo we've got maybe [Writing] app one here, [Writing] app two, and say a [Writing] web page.\n\nWith a feature flagging service we can actually group these in collections so that we're a little bit more organized with which feature flags are tied to, which apps are web pages.\n\nSo now today we've learned about returning feature flags on and off without deployment testing directly in production, and then segmenting those features based on the user attributes.\n\nThank you for watching. If you have questions, please drop us a line below. If you want to see more videos like this in the future, please like and subscribe. And don't forget, you can grow your skills and earn badges with IBM CloudLabs, which are free browser-based interactive kubernetes labs.", "title": "", "source": "https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-videos"}, {"document_id": "ibmcld_08058-5456-6715", "score": 11.996625182799853, "text": "\ncasemanagementv1.GetCaseOptionsFieldsStatusConst,\ncasemanagementv1.GetCaseOptionsFieldsSeverityConst,\ncasemanagementv1.GetCaseOptionsFieldsCreatedByConst,\n})\n\ncaseVar, response, err := caseManagementService.GetCase(getCaseOptions)\nif err != nil {\npanic(err)\n}\nb, _ := json.MarshalIndent(caseVar, \"\", \" \")\nfmt.Println(string(b))\n\nconst fieldsToReturn = [\nCaseManagementV1.GetCaseConstants.Fields.DESCRIPTION,\nCaseManagementV1.GetCaseConstants.Fields.STATUS,\nCaseManagementV1.GetCaseConstants.Fields.SEVERITY,\nCaseManagementV1.GetCaseConstants.Fields.CREATED_BY,\n];\n\nconst params = {\ncaseNumber: caseNumber,\nfields: fieldsToReturn,\n};\n\ncaseManagementService.getCase(params)\n.then(res => {\nconsole.log(JSON.stringify(res.result, null, 2));\n})\n.catch(err => {\nconsole.warn(err)\n});\n\n\n\n\n\n Updating support cases by using the API \n\nThe following sample request shows how to programmatically update a support case. For more information, see the [Case Management API](https://cloud.ibm.com/apidocs/case-managementcasemanagement-createcase).\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -X PUT '/case-management/v1/cases/{case_number}/status' -H 'Authorization: TOKEN' -d '{\n\"action\": \"resolve\",\n\"comment\": \"The issue is resolved. Thank you!\",\n\"resolution_code\": 1\n}'", "title": "", "source": "https://cloud.ibm.com/docs/get-support?topic=get-support-managing-support-cases"}, {"document_id": "ibmcld_13770-12514-13724", "score": 11.857498356167808, "text": "\n* The service might fail to detect a mismatch between the prompt\u2019s text and audio. This problem is more likely to occur with longer prompts. Multiple shorter prompts are preferable to a single long prompt.\n* The text of a prompt might include a word that the service does not recognize. In this case, you can add a custom word/translation pair to the prompt's custom model to tell the service how to pronounce the word. For more information, see [Adding a single word to a custom model](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-customWordscuWordAdd).\n* The quality of the input audio might be insufficient or the service\u2019s processing of the audio might fail to detect or reflect the intended prosody. Submitting new audio for the prompt can correct these issues.\n\n\n\nIf a prompt that is created without a speaker ID does not adequately reflect the intended prosody, enrolling the speaker and providing a speaker ID for the prompt is one recommended means of potentially improving the quality of the prompt. This is especially important for shorter prompts such as \"good-bye\" or \"thank you,\" where less audio data makes it more difficult for the service to match the prosody of the speaker.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-tbe-create"}]}
{"task_id": "1be66272113492407e814eaf21a761d4<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_14504-1731-3967", "score": 30.233728681729332, "text": "\n* Smarts SAM Notification \u2013 sends alert notifications to EMC Smarts Server Assurance Manager.\n* Network Share \u2013 sends reports to a shared location, supports SMB version 2.0.\n\n\n\nNotifications are alert notifications that meet the filter criteria in the notification rules before they are sent northbound to external systems. Notification rules are configured for the required outbound alerts so that they can be filtered before they are sent to the selected external system. The notifications list is used to manage these rules.\n\n\n\n Integration use case \n\nThis example use case is based on an existing generic service management layer that is used by an enterprise. The client provisioned a vCenter Server instance with the Operations Management option, and they want to integrate this platform into their service management platform. They use an event aggregation system to integrate the alerts generated from the domain-specific monitoring tools:\n\n\n\n* A tool set to monitor the OS, middleware and applications across their UNIX\u00ae, Linux\u00ae, and Windows\u00ae workloads, but this tool does not monitor the infrastructure components like VMware\u00ae, networking devices, or storage.\n* An SNMP manager to receive SNMP traps from their network infrastructure. This tool also collects SNMP metrics to enable performance and capacity alerts.\n* A backup management tool to manage their backups.\n* Storage management tools to manage their storage arrays.\n* An availability tool that uses ping to test the devices reachability.\n\n\n\nTheir service management layer also consists of:\n\n\n\n* A server capacity and performance tool to collect metrics to provide reports.\n* A patching and compliance server to update OS, middleware, and applications and measure compliance on these platforms.\n* A ticketing tool used to manage tickets for, incidents, problems, and changes. This tool is also the enterprise\u2019s Configuration Management Database (CMDB). The tool is able to send emails to the operations teams and SMS messages.\n* An enterprise logging system that captures logs from all systems and managed by the security team.\n\n\n\nNow that they have VMware Aria Operations they can integrate this tool by using northbound notification that uses the SNMP Trap plug in.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-opsmgmt-integration"}, {"document_id": "ibmcld_14504-7-2283", "score": 29.19991293996878, "text": "\nIntegration \n\nReview the following topic to understand the Operational Management layer of the design. However, some enterprises might want to integrate this layer with the Service Management layer. In this design, VMware Aria\u00ae Operations\u2122 Manager is the central point where all alerts are surfaced.\n\nReview the following categories of integration.\n\n\n\n* Northbound \u2013 Integration from VMware Aria Operations to other tools.\n\n\n\n* Notification of alerts to SMTP server or tools like Slack or PagerDuty.\n* Ticket integration into a service desk tool like ServiceNow.\n* Initiating VMware Aria Orchestrator workflows to remediate an issue discovered by VMware Aria\u00ae Automation\u2122.\n\n\n\n* Southbound \u2013 Integration from service management or cloud management tools.\n\n\n\n* VMware Aria Automation configures monitoring when new workload is added.\n* Update VMware Aria Operations objects with event enrichment from external sources.\n\n\n\n\n\nVMware Aria Operations provides the following outbound alert plug-ins:\n\n\n\n* Automated Action \u2013 enabled by default.\n* Standard email \u2013 uses Simple Mail Transfer Protocol (SMTP) to email VMware Aria Operations Manager alert notifications to your interested individuals.\n* SNMP Trap\u2013 logs alerts on your SNMP Trap server.\n* REST Notification \u2013 sends VMware Aria Operations alerts to another REST-enabled application where you built a REST web service to accept these messages.\n* Log file \u2013 enables VMware Aria Operations to log alerts to a file on each of your VMware Aria Operations Manager nodes. If you installed VMware Aria Operations Manager as a multiple node cluster, each node processes and logs the alerts for the objects that it monitors. Each node logs the alerts for the objects it processes.\n* Smarts SAM Notification \u2013 sends alert notifications to EMC Smarts Server Assurance Manager.\n* Network Share \u2013 sends reports to a shared location, supports SMB version 2.0.\n\n\n\nNotifications are alert notifications that meet the filter criteria in the notification rules before they are sent northbound to external systems. Notification rules are configured for the required outbound alerts so that they can be filtered before they are sent to the selected external system. The notifications list is used to manage these rules.\n\n\n\n Integration use case", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-opsmgmt-integration"}, {"document_id": "ibmcld_11754-3222-5094", "score": 28.34385054265924, "text": "\nBy default, three types of logs are automatically generated for your Satellite location: [R00XX-level error messages](https://cloud.ibm.com/docs/satellite?topic=satellite-healthlogs-error), [the status of whether resource deployment to the location is enabled](https://cloud.ibm.com/docs/satellite?topic=satellite-healthlogs-deploy), and [the status of Satellite Link](https://cloud.ibm.com/docs/satellite?topic=satellite-healthlogs-link). Review the following sections for an example of each log type and descriptions of each log field.\n\n\n\n\n\n How can I set up alerts for location error logs? \n\nYou can use the built-in Log Analysis dashboard tools to save log searches and set up alerts for certain types of logs, such as errors.\n\n\n\n1. To filter for a specific Satellite location, click Apps in the Filters toolbar, select the CRN for your Satellite location, and click Apply. To identify the CRN for your location, look for the location's ID at the end of the CRN.\n2. Search for a specific query that you want an alert for. For example, to be alerted for any logs that contain R00XX-level location error messages, search for R00. To be alerted for Satellite Link health check failures, search for Failed to reach endpoint.\n3. Click Unsaved view > Save as new view. Add a name and an optional category.\n4. In the Alert drop-down list, select View-specific alert and follow the steps for the notification channel that you selected to configure a custom alert for this log query.\n5. Click Save view.\n\n\n\n\n\n\n\n Is IBM alerted for any of these logs? \n\nThe IBM Cloud Monitoring component generates certain alerts for issues with your location setup and host infrastructure. To review the alerts that IBM monitors, see [IBM monitoring to resolve and report location alerts](https://cloud.ibm.com/docs/satellite?topic=satellite-monitormonitoring-default).\n\n\n\n\n\n\n\n R00XX error logs", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-health"}, {"document_id": "ibmcld_09744-7-2214", "score": 26.92902582776713, "text": "\nSending SMS alerts by using IBM Cloud Event Notifications \n\nIn the IBM Cloud Monitoring service, you can configure single alerts and multi-condition alerts to notify support staff by an SMS (Short Message Service) message about problems that might require attention. Alerts can generate notifications to the IBM Cloud Event Notifications service to be handled as configured in that service.\n\n[IBM Cloud Event Notifications is available in a limited number of regions](https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-regions-endpoints). Your IBM Cloud Monitoring and IBM Cloud Event Notifications instances must be in the same region to communicate with one another. Because of this, support for integration with IBM Cloud Event Notifications is limited to the regions where IBM Cloud Event Notifications is supported and where IBM Cloud Monitoring is also installed.\n\nSMS messages can only be sent to phone numbers in the United States and Canada.\n\nIBM Cloud Event Notifications supports message concatenation so SMS messages longer than 160 characters can be sent. However, messages will be sent in blocks of at most 160 characters. Multiple messages might result in additional charges to the recipient.\n\nFor a step-by-step tutorial, see [Sending SMS notifications to IBM Cloud Event Notifications](https://cloud.ibm.com/docs/monitoring?topic=monitoring-tutorial-en-sms).\n\nTo configure 1 instance of the IBM Cloud Monitoring service to send notifications to IBM Cloud Event Notifications to be sent as an SMS message, do the following:\n\n\n\n Step 1. Provision an IBM Cloud Event Notifications instance \n\nProvision an [IBM Cloud Event Notifications instance.](https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-create-en-instance)\n\nThe IBM Cloud Event Notifications instance must be provisioned in the same region as the Monitoring instance.\n\nThe number of events and filters that are available with IBM Cloud Event Notifications depends on the pricing plan selected. Review the limitations statement when creating your IBM Cloud Event Notifications instance for [plan limitations](https://cloud.ibm.com/catalog/services/event-notifications).\n\n\n\n\n\n Step 2.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-eventnotif_sms"}, {"document_id": "ibmcld_09782-1362-3189", "score": 25.811706983889124, "text": "\n: Information about the alert.\n\n--type <TYPE>\n: Type of alert. Valid values are MANUAL, BASELINE, and HOST_COMPARISON.\n\n--timespan <TIMESPAN>\n: Minimum time interval, in microseconds, for which the alert condition must be met before the alert is triggered. The default value is 60,000,000 microseconds.\n\n--condition <CONDITION>\n: Threshold of the alert. This parameter is required for manual alerts, and does not apply to other alert types.\n\n--severity <SEVERITY> | -s <SEVERITY>\n: Level of severity. Valid values range from 0 to 7. 0 means emergency and 7 means debug. By default, severity is set to 4.\n\n--severity-label <LOW | MEDIUM | HIGH>\n: Criticality of an alert. Valid values are HIGH, MEDIUM, LOW. A lower severity value indicates a higher severity.\n\n--disable\n: State of the alert. By default, an alert is enabled when it is created. You must set this parameter to disable the alert when it is created.\n\n--segment <SEGMENT>\n: Additional segmentation criteria. For example, you can segment an alert by ['host.mac', 'proc.name'].\n\n--segment-condition <SEGMENT_CONDITION>\n: Defines when the alert is triggered for each monitored entity that is specified in the --segment parameter. This parameter is required for manual alerts, and does not apply to other alert types. Valid values are ANY and ALL. ANY indicates that the alert is triggered when at least one of the monitored entities satisfies the condition. ALL indicates that the alert is triggered when all of the monitored entities satisfy the condition.\n\n--user-filter <USER_FILTER>\n: Boolean expression that you can set to reduce the scope of the alert. Use this parameter to configure segments, such as filters like kubernetes.namespace.name='production' or container.image='nginx'.\n\n--notify <NOTIFY>\n: Type of notification that you want this alert to generate.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-monitor-cli"}, {"document_id": "ibmcld_09475-2653-4603", "score": 25.789438911064988, "text": "\nHowever, to get a complete picture of what is happening in your VMware deployment, you should centralized all your logs to an external service such as IBM Log Analysis where you can troubleshoot problems across all components and be alerted of potential issues that need looking into. Log Analysis offers administrators, DevOps teams, and developers advanced features to filter, search, and tail log data, define alerts, and design custom views to monitor application and system logs. For more information, see [Log Analysis getting started](https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-getting-started).\n\n\n\n\n\n Types of logs \n\nA VMware deployment generates multiple types of logs.\n\n\n\n* Events\n* vCenter logs\n* ESXi logs\n* NSX logs\n* Guest Introspection (GI) logs\n\n\n\n\n\n Events \n\nEvents are audit records that report user actions or system actions on objects in the vCenter Server or on a host.\n\n\n\n* You can send events that are generated by the vCenter Server Appliance. For example, an event can report when a virtual machine is powered off.\n* The maximum length of syslog messages is 1024 characters. Events with a size greater than 1024 characters are split into multiple syslog messages.\n\n\n\nAn event log record includes information about who made the request, when the event occurred, and what type of event is.\n\nThe format of an event is the following.\n\n<syslog-prefix> : Event [eventId] [partInfo] [createdTime] [eventType] [severity] [user] [target] [chainId] [desc]\n\nWhere\n\n\n\n* syslog-prefix: Displays the syslog prefix that is defined by the remote syslog server.\n* eventId: Displays the unique ID of the event.\n* partInfo: Displays whether the message is split into parts. The format is [1-X]. For example, [1-1] indicates 1 message only.\n* createdTime: Displays the time when the event is generated.\n* eventType: Displays the event type.\n* severity: Displays whether the event is informational, a warning message, or an error.", "title": "", "source": "https://cloud.ibm.com/docs/log-analysis?topic=log-analysis-vmware-vcenter"}, {"document_id": "ibmcld_09702-1215-2982", "score": 25.759039247608143, "text": "\nnotification_channel_ids = res\n\n Create and define the alert details\nres = sdclient.create_alert(\nname=<ALERT_NAME>,\ndescription=<ALERT_DESCRIPTION>,\nseverity=<SEVERITY>,\nfor_atleast_s=<FOR_ATLEAST_S>,\ncondition=<CONDITION>,\nsegmentby=<SEGMENTBY>,\nsegment_condition=<SEGMENT_CONDITION>,\nuser_filter=<USER_FILTER>,\nnotify=<NOTIFICATION_CHANNEL_IDS>,\nenabled=<ENABLED>,\nannotations=<ANNOTATIONS>,\nalert_obj=<ALERT_OBJ>\n)\n\nif not res[0]:\nprint(\"Alert creation failed\")\nShow more\n\nConsider the following information when you create a Python script:\n\n\n\n* You must include the following information: <MONITORING-ENDPOINT>, <IAM_APIKEY>, and <GUID> These data is required to authenticate the request with the monitoring instance. To get the monitoring instance information, see [Authenticate your user or service ID by using IAM](https://cloud.ibm.com/docs/monitoring?topic=monitoring-python-clientpython-client-iam-auth).\n* You must define the notification channels through which you want to be notified when the alert is triggered.\n\nValid notification channel types are SLACK, PAGER_DUTY, VICTOROPS, WEBHOOK, and EMAIL.\n\nWhen you define the notification channels, the channels must be configured in the monitoring instance.\n\nWhen you add an email notification channel, you can add multiple recipients. You separate values by using a comma.\n\nWhen you define a Slack channel, replace <SLACK_CHANNEL_NAME> with the name of your channel. You must include the symbol with the name of the channel, for example, my_monitoring_alert_channel.\n\n\n\nWhen you configure the alert, complete the following sections:\n\n\n\n* [name and description]: You must define a unique name for the alert name by replacing <ALERT_NAME>, and optionally, add a description by replacing <ALERT_DESCRIPTION>.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert_python"}, {"document_id": "ibmcld_08592-8007-9409", "score": 25.599226828287073, "text": "\nYou can scope down your metrics by using the following scope filters.\n\n\n\nTable 4. Describes the scope filters for Hyper Protect Crypto Services metrics.\n\n Attribute Name Description \n\n ibmResourceGroupName The name of the resource group associated with the Hyper Protect Crypto Services service instance. \n ibmScope The account, organization, or space GUID associated with the metric. \n ibmServiceInstanceName The service instance associated with the metric. \n ibmHpcsApi The Hyper Protect Crypto Services API calls associated with the metric. \n\n\n\nBecause of Monitoring limitations, you are able to see the values in the filters for up to 6 hours at a time. You can manually type in value into scope variables to use scope filters for given time periods.\n\n\n\n\n\n\n\n Setting Alerts \n\nYou can set alerts on your Monitoring dashboard to notify you of certain metrics. To set up alerts, complete the following steps:\n\n\n\n1. Click Alerts on the side menu.\n2. Click Add Alert and select Metric as the alert type.\n3. Select the aggregation and the metric that you would like to be performed on.\n4. Select the scope if applicable.\n5. Set the metric and time requirements for the alert to trigger.\n6. Configure and set up the notification channel and notification interval.\n7. Click CREATE.\n\n\n\nFor more information about configuring metric alerts, see [Metric Alerts](https://docs.sysdig.com/en/metric-alerts.html).", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-operational-metrics"}, {"document_id": "ibmcld_09782-7-1715", "score": 25.41298290600174, "text": "\nMonitoring (ibmcloud monitoring) CLI \n\nThe IBM Cloud\u00ae command-line interface (CLI) provides extra capabilities for service offerings. This information describes how you can use the CLI to access information in IBM Cloud Monitoring.\n\n\n\n Prerequisites \n\n\n\n* Install the [IBM Cloud CLI](https://cloud.ibm.com/docs/cli?topic=cli-getting-started).\n* Install the IBM Cloud Monitoring CLI by running the following command:\n\nibmcloud plugin install monitoring\n\n\n\nYou are notified on the command line when updates to the IBM Cloud CLI and plug-ins are available. Be sure to keep your CLI up to date so that you can use the latest commands. You can view the current version of all installed plug-ins by running ibmcloud plugin list.\n\n\n\n\n\n ibmcloud monitoring alert add \n\nUse this command to add an alert.\n\nibmcloud monitoring alert add --name NAME [--alert-name ALERT_NAME] [--description DESCRIPTION] [--type TYPE] [--timespan TIMESPAN] [--condition CONDITION] [--severity SEVERITY] [--severity-label LOW, MEDIUM OR HIGH] [--disable] [--segment SEGMENT] [--segment-condition SEGMENT_CONDITION] [--user-filter USER_FILTER] [--notify NOTIFY] [--file JSON_FILE] [--region REGION] [--output FORMAT] [--team TEAM_NAME]\n\n\n\n Command options \n\n--name <NAME> | --n <NAME>\n: Name of the instance.\n\n--alert-name <ALERT_NAME>\n: Name of the alert.\n\n--description <DESCRIPTION>\n: Information about the alert.\n\n--type <TYPE>\n: Type of alert. Valid values are MANUAL, BASELINE, and HOST_COMPARISON.\n\n--timespan <TIMESPAN>\n: Minimum time interval, in microseconds, for which the alert condition must be met before the alert is triggered. The default value is 60,000,000 microseconds.\n\n--condition <CONDITION>\n: Threshold of the alert.", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-monitor-cli"}, {"document_id": "ibmcld_09701-2229-3786", "score": 25.375529094471403, "text": "\n* <REST_API_ENDPOINT> indicates the endpoint targetted by the REST API call. For more information, see [Monitoring REST API endpoints](https://cloud.ibm.com/docs/monitoring?topic=monitoring-endpointsendpoints_rest_api). For example, the public endpoint for an instance that is available in us-south is the following: https://us-south.monitoring.cloud.ibm.com/api\n* You can pass multiple headers by using -H.\n\nAuthorization and IBMInstanceID are headers that are required for authentication.\n\nTeamID is optional. When you specify this header, you limit the request to the data and resources available for the team specified.\n\nTo get an AUTH_TOKEN and the GUID see, [Headers for IAM Tokens](https://cloud.ibm.com/docs/monitoring?topic=monitoring-mon-curlmon-curl-headers-iam).\n* You can pass data to create the alert in the alert.json file by using -d.\n\nWhen you create an alert, include the following parameters: type, name, severity, timespan, condition, segmentby, segmentConditionn, filter, notificationChannelIds, enabled\n\nFor more information, see [Alert schema](https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert_apialert-api-schema-req).\n\n\n\nThe following sample shows the request body parameters that you can set to create an alert:\n\n{\n\"alert\": {\n\"version\": null,\n\"name\": \"My Alert!\",\n\"description\": null,\n\"teamId\": null,\n\"enabled\": false,\n\"filter\": null,\n\"type\": \"MANUAL\",\n\"condition\": \"avg(timeAvg(uptime)) <= 0\",\n\"timespan\": 600000000,\n\"notificationChannelIds\": [],\n\"reNotify\": false,\n\"reNotifyMinutes\": 30,\n\"segmentBy\": [\n\"host.hostName\"", "title": "", "source": "https://cloud.ibm.com/docs/monitoring?topic=monitoring-alert_api"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16417-3559-5683", "score": 35.85065030742743, "text": "\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16481-3559-5682", "score": 35.85065030742743, "text": "\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16464-12399-14287", "score": 28.32160205820184, "text": "\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.]", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16464-13891-15856", "score": 27.612347247115174, "text": "\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https://cloud.ibm.com/docs-content/v1/content/148d3bd95f946aa1bb53ea1540475f522e6b61c9/watson-knowledge-studio-data/images/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16417-5155-7505", "score": 27.277977873463307, "text": "\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16481-5154-7504", "score": 27.277977873463307, "text": "\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16563-10714-12816", "score": 26.004896185747214, "text": "\nFrom the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\nIn a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}, {"document_id": "ibmcld_16417-1764-4158", "score": 25.814158549794712, "text": "\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16481-1764-4158", "score": 25.814158549794712, "text": "\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16563-12333-14196", "score": 25.71233596962041, "text": "\nThe IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https://cloud.ibm.com/docs-content/v1/content/50eddb8fd81f33092880335ff107a78ff5cd0f65/watson-knowledge-studio/images/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}]}
{"task_id": "674aa142d92a6b4262de254df0c3f7b2<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13074-16820-18514", "score": 61.377456154240974, "text": "\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https://cloud.ibm.com/docs/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https://cloud.ibm.com/docs/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https://cloud.ibm.com/catalog/services/discovery).\n\n\n\n\n\n Enrichment language support", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-configservice"}, {"document_id": "ibmcld_13074-15255-17243", "score": 56.24473362144739, "text": "\nSee [Entity extraction](https://cloud.ibm.com/docs/discovery?topic=discovery-configserviceentity-extraction) and [Keyword extraction](https://cloud.ibm.com/docs/discovery?topic=discovery-configservicekeyword-extraction) about those enrichments.\n\nThe subject, action, and object are extracted for every sentence that contains a relation.\n\n\n\n\n\n Sentiment analysis \n\nIdentifies attitude, opinions, or feelings in the content that is being analyzed. Discovery can calculate overall sentiment within a document, sentiment for user-specified targets, entity-level sentiment, quotation-level sentiment, directional-sentiment, and keyword-level sentiment. The combination of these capabilities supports a variety of use cases ranging from social media monitoring to trend analysis.\n\nExample portion of a document enriched with Sentiment Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"sentiment\": {\n\"document\": {\n\"score\": 0.459813,\n\"label\": \"positive\"\n}\n}\n\nIn the preceding example, you could query the sentiment label by accessing enriched_text.sentiment.document.label\n\nThe label is the overall sentiment of the document (positive, negative, or neutral). The sentiment label is based on the score; a score of 0.0 would indicate that the document is neutral, a positive number would indicate the document is positive, a negative number would indicate the document is negative.\n\n\n\n\n\n Emotion analysis \n\nDetects anger, disgust, fear, joy, and sadness implied in English text. Emotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-configservice"}, {"document_id": "ibmcld_13761-7-2364", "score": 39.90615714396026, "text": "\nModifying speech synthesis with expressive neural voices \n\nThe expressive neural voices that are available with the IBM Watson\u00ae Text to Speech service offer some additional features that are not available with other types of voices: using speaking styles, emphasizing interjections, and emphasizing words. These features are available for both the HTTP and WebSocket interfaces.\n\nThe features involve the use of elements of the Speech Synthesis Markup Language (SSML). The descriptions of the features provide information about how they interact with related SSML elements and attributes.\n\n\n\n Using speaking styles \n\nThe expressive neural voices determine the sentiment of the text from the context of its words and phrases. The speech that they produce, in addition to having a very conversational style, reflects the mood of the text. The expressive voices naturally express gratitude, thankfulness, happiness, empathy, confusion, and other sentiments by default, with no explicit additional tagging.\n\nHowever, you can embellish the voices' natural tendencies by using the <express-as> element with the required style attribute to indicate that all or some of the text is to emphasize specific characteristics. These characteristics are referred to as speaking styles:\n\n\n\n* cheerful - Expresses happiness and good news. The style is upbeat, welcoming, and conveys a positive message.\n* empathetic - Expresses empathy and compassion. The style has sympathetic undertones, but it is not excessively sorrowful.\n* neutral - Expresses objectivity and evenness. The style strives for less emotion, and instead conveys a more even and instructional tone.\n* uncertain - Expresses uncertainty and confusion. The style conveys the feeling of being unsure or in doubt.\n\n\n\nIn many cases, the effect of the styles is very subtle. In such cases, the differences might not be readily discernible from the default expressive tone. But there are instances where the style can audibly enhance the voices' inherent ability to detect and express emotion. The differences are often detectable only on certain words and phrases.\n\nTable 1 provides examples of each available style for the <express-as> element. To demonstrate the effect of the styles, the table provides two samples for each example. The first sample speaks the text with the default en-US_EmmaExpressive voice.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-synthesis-expressive"}, {"document_id": "ibmcld_09906-2727-4077", "score": 37.89325297769803, "text": "\nThe targets option for sentiment in the following example tells the service to search for the targets \"apples\", \"oranges\", and \"broccoli\". Since \"apples\" and \"oranges\" are located in the text, sentiment scores are returned for those targets.\n\nYou can also get sentiment and emotion results for entities and keywords that are detected in your text. In the example, the emotion option for keywords tells the service to analyze each detected keyword for emotion results.\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application/json\" --data '{\n\"text\": \"I love apples! I do not like oranges.\",\n\"features\": {\n\"sentiment\": {\n\"targets\": [\n\"apples\",\n\"oranges\",\n\"broccoli\"\n]\n},\n\"keywords\": {\n\"emotion\": true\n}\n}\n}' \"{url}/v1/analyze?version=2019-07-12\"\nShow more\n\nRunnable command for Windows users:\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application/json\" --data \"{\"text\":\"I love apples! I do not like oranges.\",\"features\":{\"sentiment\":{\"targets\":[\"apples\",\"oranges\",\"broccoli\"]},\"keywords\":{\"emotion\":true}}}\" \"{url}/v1/analyze?version=2019-07-12\"\n\n\n\n\n\n Next steps \n\n\n\n* View the [API reference](https://cloud.ibm.com/apidocs/natural-language-understanding).\n* Learn how to identify [custom entities and relations](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-customizing).", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-getting-started"}, {"document_id": "ibmcld_09906-1621-3194", "score": 36.076923504715104, "text": "\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application/json\" --data '{\n\"url\": \"http://newsroom.ibm.com/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\n\"features\": {\n\"sentiment\": {},\n\"categories\": {},\n\"concepts\": {},\n\"entities\": {},\n\"keywords\": {}\n}\n}' \"{url}/v1/analyze?version=2019-07-12\"\n\nWindows users: This command might not run on Windows. Run the following command instead:\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application/json\" --data \"{\"url\":\"http://newsroom.ibm.com/Guerbet-and-IBM-Watson-Health-Announce-Strategic-Partnership-for-Artificial-Intelligence-in-Medical-Imaging-Liver\",\"features\":{\"sentiment\":{},\"categories\":{},\"concepts\":{},\"entities\":{},\"keywords\":{}}}\" \"{url}/v1/analyze?version=2019-07-12\"\n\nThe next step demonstrates how to specify options that customize the analysis for each feature.\n\n\n\n\n\n Step 2: Analyze target phrases and keywords \n\nNatural Language Understanding can analyze target phrases in context of the surrounding text for focused sentiment and emotion results. The targets option for sentiment in the following example tells the service to search for the targets \"apples\", \"oranges\", and \"broccoli\". Since \"apples\" and \"oranges\" are located in the text, sentiment scores are returned for those targets.\n\nYou can also get sentiment and emotion results for entities and keywords that are detected in your text. In the example, the emotion option for keywords tells the service to analyze each detected keyword for emotion results.", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-getting-started"}, {"document_id": "ibmcld_16356-7-2036", "score": 34.35251854109729, "text": "\nDetecting trigger words \n\nUse the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent. The second group shows customers a customizable warning message.\n\nBy default, this action has two steps\u2014the Connect to agent step and the Show warning step. To see how this action works, click Set by assistant in the list of actions, and then click Trigger word detected.\n\nThis is a beta feature that is available for evaluation and testing purposes.\n\n\n\n Connect to agent \n\nThe first step of the Trigger word detected action is the Connect to agent step. The Connect to agent step goes to the Fallback action if any trigger words are detected in the customer's input. Use this step to capture any key phrases where it\u2019s important to connect a customer with a live agent rather than activate any further actions.\n\nFor example, you might add hurt and harm as trigger words for the Connect to agent step:\n\nZoom\n\n![Adding trigger words to the Connect to agent step](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/connect-to-agent-phrases.png)\n\nAdding trigger words to the Connect to agent step\n\nIn this example, a customer enters a word or phrase including hurt or harm, which triggers the Fallback action. Step 4 has:\n\n\n\n* Danger word detected as the fallback reason.\n* The default message: It seems this conversation would be best managed by a human agent. Let me connect you to one of our agents. You can customize this message.\n* And then set to Connect to agent (action ends).\n\n\n\nFor more information about the Fallback action, see [Editing the fallback action](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n\n\n Show warning \n\nThe second and final step of the Trigger word detected action is the Show warning step. The Show warning step shows a customizable warning message to your customer if any trigger words are detected in the customer's input.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-trigger-phrases"}, {"document_id": "ibmcld_13761-1826-3662", "score": 34.1882424904274, "text": "\nIn such cases, the differences might not be readily discernible from the default expressive tone. But there are instances where the style can audibly enhance the voices' inherent ability to detect and express emotion. The differences are often detectable only on certain words and phrases.\n\nTable 1 provides examples of each available style for the <express-as> element. To demonstrate the effect of the styles, the table provides two samples for each example. The first sample speaks the text with the default en-US_EmmaExpressive voice. The second sample speaks the same text with the same voice but with the indicated style. A request that uses the <express-as> element fails if the style is not one of the supported values or is omitted from the element.\n\n\n\nTable 1. Speaking styles\n\n Style Example input text Audio sample \n\n cheerful \"Oh, that's good news. I am very happy for you!\" Your browser does not support the audio tag. \n \"<express-as style='cheerful'>Oh, that's good news. I am very happy for you!</express-as>\" Your browser does not support the audio tag. \n empathetic \"Oh, I'm sorry to hear that. I know how difficult that can be.\" Your browser does not support the audio tag. \n \"<express-as style='empathetic'>Oh, I'm sorry to hear that. I know how difficult that can be.</express-as>\" Your browser does not support the audio tag. \n neutral \"A five-alarm fire early this morning claimed the lives of more than a dozen residents.\" Your browser does not support the audio tag. \n \"<express-as style='neutral'>A five-alarm fire early this morning claimed the lives of more than a dozen residents.</express-as>\" Your browser does not support the audio tag. \n uncertain \"That's strange. Hmm, I don't know if I've seen this before.\" Your browser does not support the audio tag. \n \"<express-as style='uncertain'>That's strange.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-synthesis-expressive"}, {"document_id": "ibmcld_03040-20244-22167", "score": 33.895023528858644, "text": "\nFor more information about defining entities, see [Defining information to look for in customer input](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-entities).\n\nPattern entities do not prevent spelling autocorrection\n: Pattern entities that match all characters and words that are usually used to count input words do not prevent spelling autocorrection. For example, if a customer defines the ^..{0,19}$ pattern entity that matches the first 20 characters of an input, then the entity match does not affect spelling autocorrection. In this example, an input of cancl transaction is autocorrected to cancel transaction.\n\nThis change applies to the following languages: English and French. For more information, see [Correcting user input](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime-spell-checkdialog-runtime-spell-check-rules).\n\nFuzzy matching updates\n: Previously, an update was made so that interactions between the stemming and misspelling fuzzy matching features were not allowed. This change applied to the following languages: English, French, German, and Czech. This was updated so that this change applies only to the English language. For more information, see [How fuzzy matching works](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-entitiesentities-fuzzy-matching).\n\nImproved irrelevance detection for Dutch\n: Irrelevance detection for Dutch disregards any punctuation in an input sentence. For example, you can now expect the same confidence score for the following two inputs: ik ben een kleine krijger? and ik ben een kleine krijger. In this example, the question mark (?) doesn't affect the confidence score.\n\nImproved enhanced intent detection\n: The exact match in enhanced intent detection now better handles small differences between training examples and runtime utterances when the differences do not change the meaning of a sentence.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-release-notes"}, {"document_id": "ibmcld_09921-7-1813", "score": 33.8804958628707, "text": "\nTone analytics (Classifications) \n\nTone analytics is currently available for English and French languages only, as indicated in the [language support](https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-language-support) topic.\n\nTone analysis is done by using a pre-built classifications model, which provides an easy way to detect language tones in written text. It detects seven tones: sad, frustrated, satisfied, excited, polite, impolite, and sympathetic.\n\n\n\n Analyzing tone \n\nTo detect tone, use the language-specific classifications model ID in your API request.\n\nThe language-specific tone model ID is formatted as tone-classifications-xx-v1, where xx is a two-character language code. Languages available include:\n\n\n\n Language Code \n\n English en \n French fr \n\n\n\n\n\n* Example parameters.json file:\n\n{\n\"language\": \"en\",\n\"text\": \"This is example text in English.\",\n\"features\": {\n\"classifications\": {\n\"model\": \"tone-classifications-en-v1\"\n}\n}\n}\n* Example cURL request:\n\ncurl --request POST --header \"Content-Type: application/json\" --user \"apikey\":\"{apikey}\" \"{url}/v1/analyze?version=2021-08-01\" --data @parameters.json\n\n\n\n\n\n Understanding tone analytics \n\nThe model returns scores for the following tones:\n\n\n\n Tone Description \n\n excited Showing personal enthusiasm and interest \n frustrated Feeling annoyed and irritable \n impolite Being disrespectful and rude \n polite Displaying rational, goal-oriented behavior \n sad An unpleasant passive emotion \n satisfied An affective response to perceived service quality \n sympathetic An affective mode of understanding that involves emotional resonance \n\n\n\n\n\n* Example response:\n\n{\n\"usage\": {\n\"text_units\": 1,\n\"text_characters\": 60,\n\"features\": 1\n},\n\"language\": \"en\",\n\"classifications\": [\n{\n\"confidence\": 0.564849,", "title": "", "source": "https://cloud.ibm.com/docs/natural-language-understanding?topic=natural-language-understanding-tone_analytics"}, {"document_id": "ibmcld_16313-10077-11045", "score": 33.74444658722798, "text": "\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable. Each step sends a message to the customer, based on the error condition, and then uses the Connect to agent feature to transfer the conversation to a live agent. (For more information about this feature, see [Connecting to a live agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-human-agent).) You can modify these steps if you want to handle an error condition in a different way.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errors"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08435-3634-5079", "score": 35.9711864903748, "text": "\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon ![Trash can icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/icon_trash.svg) is displayed in the State column. Hover over the icon to view the deletion expiration date.\n\n\n\n2. To delete the key, follow the instructions in [Deleting keys with the console](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-gui).\n\n\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_08435-6973-8664", "score": 33.5595064243192, "text": "\nYour IBM Cloud access token. Include the full contents of the IAM token, including the Bearer value, in the cURL request. For more information, see [Retrieving an access token](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Hyper Protect Crypto Services instance. For more information, see [Retrieving an instance ID](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keys) by using the IBM Cloud console or key management service API.\n\nIf you need to prevent the deletion of a key that is already authorized for deletion, you can remove the existing authorization by calling POST /api/v2/keys/<key_ID>/actions/unsetKeyForDeletion.\n\n\n\n\n\n\n\n Step 2. Delete the key \n\nAfter you set a key for deletion, a second user with a Manager access policy can safely delete the key.\n\nHyper Protect Crypto Services sets a 7-day waiting period that starts after you provide the first authorization to delete the key. During this 7-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_08435-8253-9823", "score": 31.654472327021043, "text": "\nDuring this 7-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. If no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\nTo delete a key and the contents, make a DELETE call to the service endpoint by following instructions in [Deleting keys with the API](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-keys-api).\n\n\n\n\n\n Removing an existing authorization \n\nIf you need to cancel an authorization for a key before the 7-day waiting period expires, you can remove the existing authorization by making a POST call to the following endpoint.\n\nhttps://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>/actions/unsetKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo remove an authorization to delete a key, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to unset or deauthorize for deletion.\n3. Remove an existing authorization to delete the key.\n\ncurl -X POST", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_08435-4752-6201", "score": 29.662345091290906, "text": "\nIf no action is taken by the second user and the 7-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api) to delete the key.\n\n\n\n\n\n\n\n Authorize deletion for a key with the API \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you enable dual authorization [for an instance](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by making a POST call to the following endpoint.\n\nhttps://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>/actions/setKeyForDeletion\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-up-kms-api).\n\nTo set a key for deletion, you must be assigned a Manager or Writer access policy for the instance or key. To learn how IAM roles map to Hyper Protect Crypto Services actions, check out [Service access roles](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-accessservice-access-roles).\n2. Copy the ID of the key that you want to set or authorize for deletion.\n3. Provide the first authorization to delete the key.\n\ncurl -X POST \n'https://api.<region>.hs-crypto.cloud.ibm.com:<port>/api/v2/keys/<key_ID>/actions/setKeyForDeletion'", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_09061-6176-7874", "score": 28.66132375298921, "text": "\n<br> <br>For more information, see [Retrieving an access token](https://cloud.ibm.com/docs/key-protect?topic=key-protect-retrieve-access-token). \n instance_ID Required. The unique identifier that is assigned to your Key Protect service instance. <br>For more information, see [Retrieving an instance ID](https://cloud.ibm.com/docs/key-protect?topic=key-protect-retrieve-instance-ID). \n\n\n\nA successful request returns an HTTP 204 No Content response, which indicates that your key was authorized for deletion. Another user with a Manager access policy can now [delete the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keys) by using the Key Protect GUI or API.\n\nIf you need to prevent the deletion of a key that's already authorized for deletion, you can remove the existing authorization by calling POST /api/v2/keys/<keyID_or_alias>/actions/unsetKeyForDeletion.\n\n\n\n Delete the key \n\nAfter you set a key for deletion, another user with a Manager access policy can safely delete the key by using the Key Protect GUI or API.\n\nKey Protect sets a seven-day authorization period that starts after you provide the first authorization to delete the key. During this seven-day period, the key remains in the [Active state](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-states) and all key operations are allowed on the key. If no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_08435-1255-3053", "score": 26.27863793673898, "text": "\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_08435-4-1684", "score": 25.13893566209476, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_09061-7530-9143", "score": 21.571849211682398, "text": "\nIf no action is taken by another user and the seven-day period expires, you must [restart the dual authorization process](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keysdelete-dual-auth-keys-set-key-deletion-api) to delete the key.\n\nDelete a key and its contents by making a DELETE call to the following endpoint.\n\nhttps://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>\n\n\n\n1. [Retrieve your authentication credentials to work with keys in the service](https://cloud.ibm.com/docs/key-protect?topic=key-protect-set-up-api).\n2. Retrieve the ID of the key that you would like to delete.\n\nYou can retrieve the ID for a specified key by making a GET /v2/keys request, or by viewing your keys in the Key Protect dashboard.\n3. Run the following curl command to delete the key and its contents.\n\n$ curl -X DELETE \"https://<region>.kms.cloud.ibm.com/api/v2/keys/<keyID_or_alias>\" -H \"authorization: Bearer <IAM_token>\" -H \"bluemix-instance: <instance_ID>\" -H \"prefer: <return_preference>\"\n\nReplace the variables in the example request according to the following table.\n\n\n\n\n\nTable 2. Describes the variables that are needed to delete a key.\n\n Variable Description \n\n region Required. The region abbreviation, such as us-south or eu-gb, that represents the geographic area where your Key Protect instance resides. <br> <br>For more information, see [Regional service endpoints](https://cloud.ibm.com/docs/key-protect?topic=key-protect-regionsservice-endpoints). \n key_ID_or_alias Required. The unique identifier or alias for the key that you would like to delete. \n IAM_token Required.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_08776-2908-4519", "score": 21.18444027520032, "text": "\nDual authorization enabled The status of a dual authorization policy on the key.<br><br><br><br> * True: Dual authorization is required to delete the key.<br> * False: No prior authorization is required to delete the key.<br><br><br> \n Set for deletion Indicates whether a delete authorization is issued for a key.<br><br><br><br> * True: An authorization to delete this key is issued by the first user. A second user with a Manager access policy can safely delete the key.<br> * False: The key is not set for deletion. No further action is needed.<br><br><br> \n Deletion expiration The date that an authorization for deletion expires for the key. If this date passes, the authorization is no longer valid. If False is the value for the Dual authorization enabled or Set for deletion column of the key, the Deletion expiration column is left empty. \n\n\n\nNot all key characteristics are displayed by default. To customize how the Keys table is to be presented, click the Settings icon![Settings icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/settings.svg) and check the columns to be displayed.\n\nNot seeing the full list of keys that are stored in your service instance? Verify with your administrator that you are assigned the correct role for the applicable service instance or individual key. For more information about roles, see [Roles and permissions](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-accessroles).\n\nYou can also search for a specific key by using the search bar, or filter keys based on your needs by clicking the Filter icon !", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-keys"}, {"document_id": "ibmcld_08435-2509-4057", "score": 20.84401385985807, "text": "\nAfter you [enable dual authorization for an instance](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4. On the KMS keys page, use the Keys table to browse the keys in your service.\n5. Click the Actions icon ![Actions icon](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/icons/action-menu-icon.svg) to open a list of options for the key that you want to delete.\n6. From the options menu, click Schedule key deletion and review the key's associated resources.\n7. Enter the name of the key that is to be deleted, and click Schedule key deletion.\n8. Contact the second approver to complete the deletion of the key.\n\n\n\n\n\n\n\n Step 2. Delete the key \n\nTo delete the key, the second approver must have Manager access policy for the instance or key in order to authorize the key for deletion.\n\n\n\n1. In the Keys table of the KMS keys page, you can find keys that are authorized for deletion with the following indicators:\n\n\n\n* The Set for deletion column has a value of True. The authorization expiration time is displayed in the Deletion expiration column.\n* A Trash can icon !", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_14311-3835-5367", "score": 24.402588968175724, "text": "\n[Layer 2 bridge setup with a new bridge edge cluster](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.\n* If you have a larger deployment, deploying a dedicated edge cluster or several edge clusters offers better performance and generally scales better.\n* If you use new edge nodes for bridging, they do not have to be in the same network or POD as the workload edge. Edge nodes are transport nodes and they communicate with the other NSX-T transport nodes (edges or hosts) through Geneve tunnels over layer 3 routed connections by using the IBM Cloud classic network as a transport network.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [VMware vSphere overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview)\n* [Getting started with IBM Cloud Gateway Appliance](https://cloud.ibm.com/docs/gateway-appliance?topic=gateway-appliance-getting-started)\n* [Installing NSX-T edge transport nodes](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/3.2/installation/GUID-5EF2998C-4867-4DA6-B1C6-8A6F8EBCC411.html)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"}, {"document_id": "ibmcld_14311-2669-4435", "score": 23.12095453210237, "text": "\nIf you use the existing workload edge cluster, you must create the edge bridge profile by using that cluster and change the existing-distributed port group to allow Promiscuous mode and Forged transmits. This setup shares the capacity of the private uplinks from the edge nodes for both private routed and bridged traffic. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-edge-private.\n\nZoom\n\n![Layer 2 bridge setup with workload edge cluster](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/arch-pattern-l2-workload-edge.svg)\n\nFigure 2. Layer 2 bridge setup with workload edge cluster\n\nAlternatively, you can deploy a new edge cluster for bridging. In this case, you must create new edge nodes and create a new edge cluster by using these nodes. When you configure the edge bridge profile, you can then use this edge cluster for bridging only. This alternative scales better, and provides a better dedicated bridging performance. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-bridge.\n\nZoom\n\n![Layer 2 bridge setup with a new bridge edge cluster](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"}, {"document_id": "ibmcld_14311-7-1811", "score": 21.321013654620735, "text": "\nArchitecture pattern for using layer 2 (L2) bridging with NSX-T \n\nWith layer 2 bridging, you can have a L2 connection to a VLAN-backed port group or a device that is outside of your NSX-T data center deployment. An L2 bridge is also useful in a migration scenario, in which you need to split a subnet across physical and virtual workloads. Or when you run a database cluster on IBM Cloud bare metal servers.\n\nYou can use layer 2 bridging in IBM Cloud by following the principles that are presented in this pattern. You can adapt the pattern based on your needs by following VMware\u00ae best practices and IBM Cloud Classic network capabilities.\n\n\n\n Layer 2 bridging with NSX-T \n\nThe following diagram presents an overview for an architecture pattern for using layer 2 bridging with NSX-T edges in IBM Cloud classic infrastructure.\n\nZoom\n\n![Layer 2 bridging with NSX-T](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/arch-pattern-l2-bridge.svg)\n\nFigure 1. Layer 2 bridging with NSX-T\n\nThe following list is a summary of the architecture pattern deployment:\n\n\n\n1. An L2 bridge requires an Edge cluster and an Edge Bridge profile to be deployed. An Edge Bridge profile specifies which Edge cluster to use for bridging and which Edge transport node acts as the primary and backup bridge.\n2. You need to have a new VLAN for the bridged devices. After the VLAN is provisioned, you can request to trunk the hosts. VLAN must be trunked to all hosts in your cluster through IBM Cloud Classic portal (Classic Infrastructure > Network > Gateway appliances). Then, add the ESX hosts to a wanted NSX-T VLAN transport zone, for example tz-bridge.\n3. On the edge cluster uplink distributed port group, enable Promiscuous mode and Forged transmits for bridging.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"}, {"document_id": "ibmcld_15141-6204-8279", "score": 20.931110021869475, "text": "\nThe VPN server receives the username and passcode from the VPN client and makes an IAM call to verify the passcode and permission with IAM policy.\n\n\n\n* The passcode is an one-time password. The user MUST re-generate the passcode for re-connection, even if the re-connection is initiated by the VPN server.\n* The SoftLayer MFA is not supported because SoftLayer MFA enforcement is not done via the browser.\n\n\n\nIf you use user ID/passcode authentication, maintenance activities force users to re-authenticate by fetching and re-entering the code. The connection is restored only after the new code is entered. This is applicable using stand-alone or HA mode.\n\n\n\n\n\n Client certificate revocation lists \n\nOptionally, you can import a certificate revocation list (CRL), which is a time-stamped list of certificates that have been revoked by a certificate authority (CA). A certificate in a certificate revocation list (CRL) might not be expired, but is no longer trusted by the certificate authority that issued the certificate. The VPN client uses this list to validate digital certificates.\n\nAfter you import a CRL, the VPN client uses this list to validate digital certificates. The CRL is saved as a string (not a file) in the system. If you need to download the CRL in the future, it is renamed as <vpn_server_name>.pem.\n\nFor more information, see [Setting up client-to-server authentication](https://cloud.ibm.com/docs/vpc?topic=vpc-client-to-site-authentication).\n\n\n\n\n\n Transport protocol \n\nThe transport layer oversees the delivery of data from a process on one device to a process on another device. Transport layer protocols act as liaisons between the application layer protocols and the services that are provided by the network. Client VPN for VPC supports the following protocols:\n\nUDP is recommended for optimal performance; TCP for reliability.\n\n\n\n* User Datagram Protocol (UDP)\n\nThe User Datagram Protocol (UDP) is a simple, lightweight protocol with minimum overhead. If a process wants to send a small message and doesn't care about reliability, it can use UDP.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-client-to-site-vpn-planning"}, {"document_id": "ibmcld_16000-0-2579", "score": 19.86470156298035, "text": "\n\n\n\n\n\n\n  Understanding Internet Communication Protocols \n\nGenerally speaking, a communication protocol is a system of rules that allow two or more entities of a communications system to transmit information. The internet has a large suite of protocols to cover many situations. In creating web-based applications and programming interfaces, software developers commonly use three of these communication protocols to describe the state of the network and the ways that data packets are moved across the network:\n\n\n\n*  ICMP, Internet Control Message Protocol, part of the internet protocol suite defined in RFC 792.\n*  TCP, Transmission Control Protocol\n*  UDP, User Datagram Protocol\n\n\n\nThe protocols that are used for a particular implementation of, say, an API call, can influence the overall behavior of your network. So it is worthwhile to understand the basic differences between them. If you need more information, many good articles are available on the internet with detailed descriptions of the protocols.\n\n\n\n  ICMP \n\nICMP is a control protocol, meaning that it is designed to carry information about the status of the network itself. It is essentially a network layer (OSI layer 3) error-reporting and error-control protocol for the network. The best-known examples of ICMP in practice are the ping and traceroute utilities. The ping utility uses ICMP to probe remote hosts for responsiveness and overall round-trip time of the probe messages. The traceroute utility uses ICMP to discover and trace network routes that the ICMP packets take when they travel to their destination.\n\nWhat developers need to know is that ICMP packets have no TCP or UDP port numbers that are associated with them because port numbers are a layer 4 (transport layer) construct.\n\n\n\n\n\n  TCP and UDP \n\nBoth Transmission Control Protocol (TCP) and User Datagram Protocol (UDP) are OSI layer 4 transport protocols. These protocols are used to pass the actual data. The main difference between TCP and UDP, from a developer's perspective, is how they handle packet order.\n\nTCP is a connection-oriented protocol, it guarantees that all sent packets reach the destination in the correct order.\n\nAlternatively, UDP is a connection-less protocol. Communication is datagram-oriented, so the integrity is guaranteed only on the single datagram. Datagrams reach a destination and can arrive out of order, or possibly they don't arrive at all.\n\nTypically, UDP is used for real-time communication, where a little percentage of the packet loss rate is preferable to the overhead of a TCP connection.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-understanding-icp"}, {"document_id": "ibmcld_15141-7808-9997", "score": 19.247074747832187, "text": "\nTransport layer protocols act as liaisons between the application layer protocols and the services that are provided by the network. Client VPN for VPC supports the following protocols:\n\nUDP is recommended for optimal performance; TCP for reliability.\n\n\n\n* User Datagram Protocol (UDP)\n\nThe User Datagram Protocol (UDP) is a simple, lightweight protocol with minimum overhead. If a process wants to send a small message and doesn't care about reliability, it can use UDP. Sending a message by using UDP takes much less time than using TCP. It performs little error checking and does not add any advantages to IP services except to provide process-to-process communication instead of host-to-host communication.\n* Transmission Control Protocol (TCP)\n\nTransmission Control Protocol (TCP) is a reliable but complex transport-layer protocol. TCP adds connection-oriented features and reliability to IP services.\n\nTCP is a stream delivery service that guarantees delivery of data streams sent from one host to another without duplication or lost data. Since packet transfer is not reliable, a technique known as positive acknowledgment with retransmission is used to guarantee reliability of packet transfers. This fundamental technique requires the receiver to respond with an acknowledgment message as it receives the data.\n\nThe sender keeps a record of each packet it sends, and waits for acknowledgment before sending the next packet. The sender also keeps a timer from when the packet was sent, and retransmits a packet if the timer expires. This timer is needed in case a packet becomes lost or corrupted.\n\n\n\n\n\n\n\n Full versus split-tunnel mode \n\nWhen a VPN connection is set up, an encrypted tunnel is created over the internet to the VPN server. The VPN connection appears as a virtual network interface to the computer in addition to the existing LAN interface. You can now use both interfaces simultaneously by sending the private traffic destined to the VPC inside the VPN tunnel and the public traffic (internet traffic) over the other interface (outside the VPN tunnel). When the traffic is split between the VPN interface and other interfaces, split tunneling is said to be in use.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-client-to-site-vpn-planning"}, {"document_id": "ibmcld_04107-6095-8145", "score": 18.687853780859914, "text": "\nThis tactic is commonly used by abuse bots, crawlers, or APIs.\n* Challenge passage - Controls how long a visitor that passed a challenge (or JavaScript challenge) gains access to your site before they are challenged again. This challenge is based on the visitor's IP, and therefore does not apply to challenges presented by WAF rules because they are based on an action that the user performs on your site.\n* Security level - Sets the security level of your website to determine which visitors receive a challenge page.\n* Always use HTTPS - Redirects all visitors to the HTTPS version.\n* Email obfuscation - Prevents spam from harvesters and bots that try to access email addresses on your pages.\n* Automatic HTTPS rewrites - Helps fix mixed content by changing http to https for all resources (or links) on your website that can be served with HTTPS.\n* Opportunistic encryption - Allows browsers to benefit from the improved performance of HTTP/2 by informing them that your site is available over an encrypted connection.\n* Universal SSL - Activates universal SSL certificates from your zone to the edge.\n* True client IP header - Sends the user's IP address in the True-Client-IP header.\n\n\n\n\n\n\n\n Security standards and platform \n\n\n\n* TLS (SHA2 and SHA1)\n* IPv4 and IPv6\n* HTTP/2\n\n\n\n\n\n\n\n Network attacks and mitigation \n\nGenerally, attacks fall into two categories:\n\n\n\nTable 1. Types of network attacks\n\n Layer-3 or Layer-4 attacks Layer-7 attacks \n\n These attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-ibm-cloud-internet-services-cis"}, {"document_id": "ibmcld_04107-7548-9466", "score": 18.622977446051387, "text": "\nThese attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address. This allows CIS to ingest, single-pass inspect, and re-encrypt data before sending it to the origin server destination. CIS can also act in DNS-only mode, returning the actual DNS record without obfuscating the IP, which disables DDoS and the other functions of CIS. To enable CIS protections, switch the \"proxy\" slider next to each DNS record to on; to disable protections, switch to off.\n\n\n\n\n\n Unlimited DDoS mitigation \n\nDDoS mitigation is typically an expensive service that can grow in cost when under attack. Unlimited DDoS mitigation is included with CIS at no additional cost.\n\n\n\n\n\n Mitigate Layer 7 attacks (configuration) \n\nThough DDoS is enabled by default in CIS, you can further configure Layer 7 security by:\n\n\n\n* Configuring WAF ruleset sensitivity and response behavior\n* Adding rate limiting\n* Adding firewall rules\n\n\n\nUse these features to customize Layer 7 mitigation of both volumetric and non-volumetric attacks.\n\n\n\n\n\n Mitigate non volumetric attacks \n\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https://cloud.ibm.com/docs/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-ibm-cloud-internet-services-cis"}, {"document_id": "ibmcld_11891-7-2391", "score": 18.57740346485015, "text": "\nSetting up Satellite as a Secure Gateway for on-prem solutions \n\nDeploy IBM Cloud Satellite as a secure solution for connecting resources in a protected on-premises environment to cloud resources.\n\n\n\n Satellite as a Layer 4 connection solution \n\nWhile you can set up many possible solutions to enable secure connections between your on-premises network and IBM Cloud, you can use Satellite to control client communications among your hybrid cloud deployments.\n\nFor example, you might use a minimal Satellite location deployment as an alternative to the [Secure Gateway solution](https://cloud.ibm.com/docs/SecureGateway?topic=SecureGateway-getting-started-with-sg). Satellite provides the same application-level transport through common ports as Secure Gateway, with greater client visibility and audit control. The Satellite Link functionality improves upon the Secure Gateway client experience with a highly available and secure-by-default communication between the cloud and on-premises networks, third-party clouds, or network edge.\n\nOn-premises setup with a Satellite location\n: A minimum deployment of Satellite includes using three RHEL 7 or 8 hosts to set up a Satellite location control plane. These hosts might be in your on-premises network or in other clouds. Then, you can attach more hosts to your location and deploy IBM Cloud managed services to run on these hosts. For example, you can deploy a Red Hat OpenShift cluster to your on-premises hosts that are attached to your Satellite location. Then, you can deploy any apps that need secure access to IBM Cloud to your Red Hat OpenShift cluster.\n\nSecure transport to IBM Cloud\n: Next, your on-premises client that runs on the location hosts can use [Satellite Link](https://cloud.ibm.com/docs/satellite?topic=satellite-link-cloud-createlink-location) as Layer 4 application transport between the location and other services that run in IBM Cloud or your own applications that run within IBM Cloud. You can use Satellite Link to create location endpoints, which allow resources in IBM Cloud to securely access a resource in your on-premises Satellite location, and cloud endpoints, which allow resources in your on-premises Satellite location to access a resource that runs anywhere outside of the Satellite location. To allow access to a resource, authorization must granted in the Link endpoint's access control list.", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-sg-usecase"}, {"document_id": "ibmcld_14311-5070-5527", "score": 18.46397580022002, "text": "\n* [Getting started with IBM Cloud Gateway Appliance](https://cloud.ibm.com/docs/gateway-appliance?topic=gateway-appliance-getting-started)\n* [Installing NSX-T edge transport nodes](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/3.2/installation/GUID-5EF2998C-4867-4DA6-B1C6-8A6F8EBCC411.html)\n* [Administering NSX-T Layer 2 bridging](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/3.2/administration/GUID-B4ABDE64-52BC-40F0-A560-670D3B7EAF7A.html)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03273-14436-16185", "score": 18.65140464045374, "text": "\nhttps://{location}.assistant.watson.cloud.ibm.com/{location}/{instance-id}/skills/{skill-id}/build/dialognode={node-id}\n4. Edit the URL by replacing the current {node-id} value with the ID of the node you want to find, and then submit the new URL.\n5. If necessary, highlight the edited URL again, and resubmit it.\n\n\n\nThe page refreshes, and shifts focus to the dialog node with the node ID that you specified. If the node ID is for a slot, a Found or Not found slot condition, a slot handler, or a conditional response, then the node in which the slot or conditional response is defined gets focus and the corresponding modal is displayed.\n\nIf you still cannot find the node, you can export the dialog skill and use a JSON editor to search the skill JSON file.\n\n\n\n How many nodes are in my dialog? \n\nTo see the number of dialog nodes in a dialog skill, do one of the following things:\n\n\n\n* If it is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n* Send a GET request to the /dialog_nodes API endpoint, and include the include_count=true parameter. For example:\n\ncurl -u \"apikey:{apikey}\" \"{url}/v1/workspaces/{workspace_id}/dialog_nodes?version=2018-09-20&include_count=true\"\n\nwhere {url} is the appropriate URL for your instance. For more details, see [Service endpoint](https://cloud.ibm.com/apidocs/assistant/assistant-v1service-endpoint).\n\nIn the response, the total attribute in the pagination object contains the number of dialog nodes.\n\n\n\nIf the total seems larger than you expected, it might be because the dialog that you build from the application is translated into a JSON object.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-tasks"}, {"document_id": "ibmcld_02953-12940-14393", "score": 18.143971074382144, "text": "\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\nYou can see the number of dialog nodes in a dialog skill from the assistant tile. If the skill is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n\nIf the total seems larger than you expected, it might be because the dialog that you build from the application is translated into a JSON object. Some fields that appear to be part of a single node are actually structured as separate dialog nodes in the underlying JSON object.\n\n\n\n* Each node and folder is represented as its own node.\n* Each conditional response that is associated with a single dialog node is represented as an individual node.\n* For a node with slots, each slot, slot found response, slot not found response, slot handler, and if set, the prompt for everything response is an individual node. In effect, one node with three slots might be equivalent to eleven dialog nodes.\n\n\n\nPrevious topic:[Controlling the dialog flow](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-runtime)\n\nNext topic:[Dialog building tips](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tips)", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tasks"}, {"document_id": "ibmcld_03036-2789-4951", "score": 17.369413577452924, "text": "\nIf you have [selected a data source](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logslogs-deploy-id) other than the skill, you might not see an intent or entity from your data source logs as an option in the filters, unless those intents and entities are also in the skill.\n* Refresh data: Select Refresh data to refresh the data that is used in the page metrics.\n\nThe statistics show traffic from customers who interact with your assistant; they do not include interactions from the Try it out pane.\n\n\n\n\n\n\n\n Scorecards \n\nThe scorecards give you a quick view of your metrics. Scroll to see full interactive graphs later in the page.\n\n![Shows the scorecards that are displayed at the start of the Analytics page](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/scorecard.png)\n\n\n\n* Total conversations: The total number of conversations between active users and your assistant that occur during the selected time period.\n\nA single conversation consists of messages that an active user sends to your assistant, and the messages your assistant sends to the user to initiate the conversation or respond.\n\nIf your assistant starts by saying Hi, how can I help you?, and then the user closes the browser without responding, that message is included in the total conversation count.\n\nThe total conversations metric is not used for billing purposes. An exchange with a user is not considered a billable conversation until the user submits a message.\n* Avg. msg. per conversation: The total messages received during the selected time period divided by the total conversations during the selected time period, as shown in the corresponding graph.\n* Max. conversations: The maximum number of conversations for a single data point within the selected time period.\n* Weak understanding: The number of individual messages with weak understanding. These messages are not classified by an intent, and do not contain any known entities. Reviewing unrecognized messages can help you to identify potential dialog problems.\n\n\n\n\n\n\n\n Graphs and statistics \n\nDetailed graphs provide additional information.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}, {"document_id": "ibmcld_16364-158662-160553", "score": 16.76531881736725, "text": "\nDialog node limit changes\n: The dialog node limit was temporarily changed from 100,000 to 500 for new Standard plan instances. This limit change was later reversed. If you created a Standard plan instance during the time frame in which the limit was in effect, your dialogs might be impacted. The limit was in effect for skills created between 10 December and 12 December 2018. The lower limits will be removed from all impacted instances in January. If you need to have the lower limit lifted before then, open a support ticket.\n\n\n\n\n\n 1 December 2018 \n\nDetermine the number of dialog nodes\n: To determine the number of dialog nodes in a dialog skill, do one of the following things:\n\n\n\n* From the tool, if it is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n* Send a GET request to the /dialog_nodes API endpoint, and include the include_count=true parameter. For example:\n\ncurl -u \"apikey:{apikey}\" \"https://{service-hostname}/assistant/api/v1/workspaces/{workspace_id}/dialog_nodes?version=2018-09-20&include_count=true\"\n\nwhere {service-hostname} is the appropriate URL for your instance. For more details, see [Service endpoint](https://cloud.ibm.com/apidocs/assistant/assistant-v1service-endpoint).\n\nIn the response, the total attribute in the pagination object contains the number of dialog nodes.\n\nSee [Troubleshooting skill import issues](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-addskill-dialog-add-import-errors) for information about how to edit skills that you want to continue using.\n\n\n\n\n\n\n\n 27 November 2018 \n\nA new service plan, the Plus plan, is available\n: The new plan offers premium-level features at a lower price point. Unlike previous plans, the Plus plan is a user-based billing plan.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_02845-1378-3615", "score": 16.518144043090317, "text": "\nMeaning it can include even skills and assistants to which you do not have access.\n* The access permissions information of the original service instances is not stored in the backup. Meaning original access rights, which determine who can see a service instance and who cannot, are not preserved.\n* You cannot use this procedure to back up the data that is returned by the search skill. Data that is retrieved by the search skill comes from a data collection in a Discovery instance. See the [Discovery documentation](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-backup-restore) to find out how to back up its data.\n* If you back up and restore or otherwise change the Discovery service that your search skill connects to, then you cannot restore the search skill, but must recreate it. When you set up a search skill, you map sections of the assistant's response to fields in a data collection that is hosted by an instance of Discovery on the same cluster. If the Discovery instance changes, your mapping to it is broken. If your Discovery service does not change, then the search skill can continue to connect to the data collection.\n* The tool that restores the data clears the current database before it restores the backup. Therefore, if you might need to revert to the current database, create a backup of it first.\n* The target IBM Cloud Pak for Data cluster where you restore the data must have the same number of provisioned Watson Assistant service instances as the environment from which you back up the database. To verify in the IBM Cloud Pak for Data web client, select Services from the main navigation menu, select Instances, and then open the Provisioned instances tab. If more than one user created instances, then ask the other users who created instances to log in and check the number they created. You can then add up the total sum of instances for your deployment. Note that not even an administrative user can see instances that were created by others from the web client user interface.\n\n\n\n\n\n\n\n Backing up data by using the CronJob \n\nA CronJob named $INSTANCE-store-cronjob is created and enabled for you automatically when you deploy the service. A CronJob is a type of Kubernetes controller.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-backup"}, {"document_id": "ibmcld_02953-11701-13401", "score": 16.42433789405043, "text": "\n[More icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kabob.png) icon on the folder, and then select Add node to folder.\n\nThe dialog node is added to the end of the dialog tree within the folder.\n\n\n\n\n\n\n\n\n\n Deleting a folder \n\nYou can delete either a folder alone or the folder and all of the dialog nodes in it.\n\nTo delete a folder, complete the following steps:\n\n\n\n1. From the tree view of the Dialog tab, find the folder that you want to delete.\n2. Click the More![More icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/kabob.png) icon on the folder, and then select Delete.\n3. Do one of the following things:\n\n\n\n* To delete the folder only, and keep the dialog nodes that are in the folder, deselect the Delete the nodes inside the folder checkbox, and then click Yes, delete it.\n* To delete the folder and all of the dialog nodes in it, click Yes, delete it.\n\n\n\n\n\nIf you deleted the folder only, then the nodes that were in the folder are displayed in the dialog tree in the spot where the folder used to be.\n\n\n\n\n\n\n\n Dialog node limits \n\nThe number of dialog nodes you can create per skill is 100,000.\n\nThe welcome and anything_else dialog nodes that are prepopulated in the tree do count toward the total.\n\nTree depth limit: The dialog supports 2,000 dialog node descendants; the dialog performs best with 20 or fewer.\n\nYou can see the number of dialog nodes in a dialog skill from the assistant tile. If the skill is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-tasks"}, {"document_id": "ibmcld_03364-8502-10365", "score": 16.211073069315788, "text": "\n* Skill ID: The unique identifier of a skill.\n* User: A user is anyone who interacts with your assistant; often these are your customers.\n* User ID: A unique label that is used to track the level of service usage of a specific user.\n* Workspace ID: The unique identifier of a workspace. Although any workspaces that you created before November 9 are shown as skills in the product user interface, a skill and a workspace are not the same thing. A skill is effectively a wrapper for a V1 workspace.\n\n\n\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each /message API call.\n\n\n\n\n\n Associating message data with a user for deletion \n\nThere might come a time when you want to completely remove a set of your user's data from a Watson Assistant instance. When the delete feature is used, then the Overview metrics will no longer reflect those deleted messages; for example, they will have fewer Total Conversations.\n\n\n\n Before you begin \n\nTo delete messages for one or more individuals, you first need to associate a message with a unique Customer ID for each individual. To specify the Customer ID for any message sent using the /message API, include the X-Watson-Metadata: customer_id property in your header. You can pass multiple Customer ID entries with semicolon separated field=value pairs, using customer_id, as in the following example:\n\ncurl -X POST -u \"apikey:3Df...", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-logs-resources"}, {"document_id": "ibmcld_03369-121126-122848", "score": 15.89999985317627, "text": "\n: You can now create Watson Assistant service instances that are hosted in the London data center without syndication. See [Data centers](https://cloud.ibm.com/docs/assistant?topic=assistant-services-informationservices-information-regions) for more details.\n\nDialog node limit changes\n: The dialog node limit was temporarily changed from 100,000 to 500 for new Standard plan instances. This limit change was later reversed. If you created a Standard plan instance during the time frame in which the limit was in effect, your dialogs might be impacted. The limit was in effect for skills created between 10 December and 12 December 2018. The lower limits will be removed from all impacted instances in January. If you need to have the lower limit lifted before then, open a support ticket.\n\n\n\n\n\n 1 December 2018 \n\nDetermine the number of dialog nodes\n: To determine the number of dialog nodes in a dialog skill, do one of the following things:\n\n\n\n* From the tool, if it is not associated with an assistant already, add the dialog skill to an assistant, and then view the skill tile from the main page of the assistant. The trained data section lists the number of dialog nodes.\n* Send a GET request to the /dialog_nodes API endpoint, and include the include_count=true parameter. For example:\n\ncurl -u \"apikey:{apikey}\" \"https://{service-hostname}/assistant/api/v1/workspaces/{workspace_id}/dialog_nodes?version=2018-09-20&include_count=true\"\n\nwhere {service-hostname} is the appropriate URL for your instance. For more details, see [Service endpoint](https://cloud.ibm.com/apidocs/assistant/assistant-v1service-endpoint).\n\nIn the response, the total attribute in the pagination object contains the number of dialog nodes.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_02970-31082-33090", "score": 15.175746275480556, "text": "\nEnabling a system entity makes it possible to quickly populate your skill with training data that is common to many use cases.\n\nSystem entities can be used to recognize a broad range of values for the object types they represent. For example, the @sys-number system entity matches any numerical value, including whole numbers, decimal fractions, or even numbers written out as words.\n\nSystem entities are centrally maintained, so any updates are available automatically. You cannot modify system entities.\n\n\n\n1. From the skill menu, click to expand Entities, and then click System entities.\n\n![Screen capture of \"System entities\" tab](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/system-entities1.png)\n\nv1.3: On the Entities page, click System entities.\n2. Browse through the list of system entities to choose the ones that are useful for your application.\n\n\n\n* To see more information about a system entity, including examples of matching input, click the entity in the list.\n* For details about the available system entities, see [System entities](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-system-entities).\n\n\n\n3. Click the toggle switch next to a system entity to enable or disable it.\n\n\n\nAfter you enable system entities, Watson Assistant begins to retrain. After training is complete, you can use the entities.\n\n\n\n\n\n Entity limits \n\n\n\nLimit details\n\n Entities per skill Entity values per skill Entity synonyms per skill Contextual entities and annotations \n\n 1,000 100,000 100,000 150 contextual entities with 3000 annotations \n\n\n\nSystem entities that you enable for use count toward your totals.\n\n\n\n\n\n Editing entities \n\nYou can click any entity in the list to open it for editing. You can rename or delete entities, and you can add, edit, or delete values, synonyms, or patterns.\n\nIf you change the entity type from synonym to pattern, or vice versa, the existing values are converted, but might not be useful as-is.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-entities"}, {"document_id": "ibmcld_03036-7103-8947", "score": 15.133707460149918, "text": "\n* Average messages per conversation - The total messages received during the selected time period divided by the total conversations during the selected time period.\n* Total messages - The total number of messages received from active users over the selected time period.\n* Active users - The number of unique users who have engaged with your assistant within the selected time period.\n* Average conversations per user - The total conversations divided by the total number of unique users during the selected time period.\n\nStatistics for Active users and Average conversations per user require a unique user_id parameter. See [Enabling user metrics](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-resourceslogs-resources-user-id) for more information.\n\n\n\n\n\n\n\n Top Intents and Top Entities \n\nYou can also view the intents and entities that were recognized most often during the specified time period.\n\n\n\n* Top intents - Intents are shown in a simple list. In addition to seeing the number of times an intent was recognized, you can select an intent to open the User conversations page with the date range filtered to match the data you are viewing, and the intent filtered to match the selected intent.\n* Top entities are also shown in a list. For each entity you can select from the Values column to see a list of the most common values that were identified for this entity during the time period. You can also select an entity to open the User conversations page with the date range filtered to match the data you are viewing, and the entity filtered to match the selected entity.\n\n\n\nSee [Improve your skill](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs) for tips on how to edit intents and entities based on discoveries you make by reviewing the intents and entities that your assistant recognizes.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16423-3286-5408", "score": 19.851825851900735, "text": "\nUpload one CSV file at a time. The first column in the CSV file specifies the file name of the document. The second column in the file contains the document text. For an example of the required format, see the [documents-new.csv](https://watson-developer-cloud.github.io/doc-tutorial-downloads/knowledge-studio/documents-new.csv) file in the tutorial sample files.\n\n\n\n\n\n PDF files \n\nText cannot be extracted from a PDF in some cases, depending on how the PDF was created. Typically, text can't be extracted from embedded fonts that don't map to unicode characters. If you are unsure whether text from a PDF can be extracted, you can try copying the text from the PDF and then pasting it into a text editor. If you do not see the same characters that are visible in the PDF itself, then the text extraction would likely fail.\n\n\n\n\n\n Formatted documents \n\nWhen formatted documents are converted to plain text, it's possible that losing the formatting could result in poor tokenization of words. For example, if a table row in a DOCX file contains cell values that do not end with a period, the values might be converted as one sentence. As another example, if a PDF document contains a very long word that is hyphenated at the end of a line, that word might be converted as two words. In cases like these, the documents might not be suitable for machine learning unless you pre-process the files to fix formatting limitations.\n\n\n\n\n\n Documents from another Watson Knowledge Studio workspace \n\nIf you previously downloaded documents from a Knowledge Studio workspace, you can upload the ZIP file that you downloaded. An option lets you specify whether you want the ground truth annotations to be included in the imported files.\n\nAfter documents are annotated, the annotated documents are stored in JSON format. The markup language in these files, which shows how the original document text was parsed and tokenized, includes elements for all of the annotations that a human annotator added. To improve model accuracy over time, you can upload these files into another workspace, thus preserving all of the existing annotations.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-documents-for-annotation"}, {"document_id": "ibmcld_06968-15099-17180", "score": 18.804183649137094, "text": "\n[checkmark icon](https://cloud.ibm.com/docs-content/v1/content/f16b1f78a92498247223b337bd9303c2758b9ba8/icons/checkmark-icon.svg) \n\n\n\n\n\n* PDF files that are secured with a password or certificate are not supported. Vector objects, including SVG images and vectorized text, are not supported. Only images of the supported image file types that occur in the PDF are rendered.\n* Only single-page image files are supported.\n* Files within compressed archive files (ZIP, GZIP, TAR) are extracted. Discovery ingests the supported file types within the archive; it ignores all other file types. The file names must be encoded in UTF-8. Files with names that include Japanese characters, for example, must be renamed before they are added to the ZIP file.\n* Discovery supports MacOS ZIP files only if they are generated by using a command such as: zip -r my-folder.zip my-folder -x \".DS_Store\". ZIP files that are created by right-clicking a folder and clicking Compress are not supported.\n* PDF files that you upload as part of an archive file are not displayed in the advanced view for a query result that you open from the Improve and customize page. If you want the file to be viewable from the advanced view, reimport the PDF file separately from the archive file.\n\n\n\nWhen you add files to a Document Retrieval for Contracts project type, any file types that support SDU and OCR are processed with a pretrained Smart Document Understanding model and Optical Character Recognition automatically.\n\n\n\n\n\n Document limits \n\nThe number of documents that are allowed per service instance depends on your Discovery plan type.\n\nThe document limit applies to the number of documents in the index. Upload fewer documents at the start if the enrichments that you plan to apply might increase the number of documents later. For example, the following configurations generate more documents:\n\n\n\n* Splitting documents segments one document into multiple documents\n* CSV files that you upload generate one document per line\n* Database data sources that you crawl produce one document per database row", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-collections"}, {"document_id": "ibmcld_07232-1707-3805", "score": 18.78516988782025, "text": "\nIf you crawl Box or Salesforce, a list of available resources is presented when you configure a source, using the Discovery tooling.\n* If you are using the Discovery tooling, you can configure a collection with a single data source.\n* Crawling a data source uses resources, namely API calls, of the data source. The number of API calls depends on the number of documents that need to be crawled. You must obtain an appropriate level of service license, for example Enterprise, for the data source. For information about the appropriate service level license that you need, contact the source system administrator.\n* Discovery source crawls do not delete documents that are stored in a collection, but you can manually delete them using the API. When a source is re-crawled, new documents are added, updated documents are modified to the current version, and deleted documents remain as the version last stored.\n* Discovery can only ingest the following file types, and it ignores all other document types:\n\n\n\n\n\n Lite plans Advanced plans \n\n PDF, Word, PowerPoint, Excel, JSON*, HTML* PDF, Word, PowerPoint, Excel, PNG**, TIFF**, JPG**, JSON*, HTML* \n\n\n\n* IBM Watson\u2122 Discovery supports crawling JSON and HTML documents, but you cannot edit these documents using the SDU editor. To change the configuration of HTML and JSON documents, you must use the API. For more information, see the [API reference](https://cloud.ibm.com/apidocs/discovery/).\n\n** Individual image files, such as PNG, TIFF, and JPG, are scanned, and any text is extracted. PNG, TIFF, and JPEG images embedded in PDF, Word, PowerPoint, and Excel files are also scanned, and any text is extracted.\n\nView the following table to see the objects that a data source can crawl and which data sources support crawling new and modified documents during a refresh:\n\n\n\nTable 1. Data sources that support crawling new and modified documents during refresh and objects that can be crawled\n\n Data source Crawls new and modified documents during refresh? Compatible objects that can be crawled \n\n Box (Application level access) No Files, folders", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-sources"}, {"document_id": "ibmcld_07117-1664-3943", "score": 18.337000866060272, "text": "\nIf you encounter this issue, open the file in a more recent version of Microsoft Office and convert the file to the DOCX, PPTX, or XLSX format respectively, and then upload the DOCX, PPTX, or XLSX file.\n\nLine breaks are inserted randomly\n: When some files in Microsoft Office format are added to a collection, line breaks are inserted seemingly at random to the text that is stored in the html field in the collection's index. The unexpected line breaks can impact the efficiency of enrichments, such as custom rule recognition.\n\nCause: As part of their ingestion into Discovery, such files are converted from Office format to PDF format. When the conversion happens, textual content is sometimes lost due to the nature of a PDF file. While the new lines appear to be added at random, they typically get inserted in areas where text wraps in the original document, such as in narrow text boxes or to accommodate other inline elements, such as images or diagrams.\n\nSolution: To avoid new line insertions, increase the width of text boxes in the original document. If the original document has a section where text wraps to accommodate an inline element, such as an image, move the image so that it is situated in its own section and the nearby text doesn't need to wrap around it. To test whether your fixes address the issue, you can convert the original file to a PDF file to check for unexpected carriage returns in the text.\n\nAfter applying a pretrained Smart Document Understanding model to a PPT file, table boundaries are not recognized properly\n: During the conversion process, text that is extracted from the table is confused with text that is outside the table in some PPT pages. This issue is more likely to occur in tables with a lot of text and that have footnotes displayed just outside the table border. If you encounter this issue, export the PPT file as a PDF file, and then upload the PDF file instead. Apply a user-trained Smart Document Understanding (SDU) model to the document, and then use the SDU tool to identify the tables in the document. The resulting model handles table boundaries properly and can extract text from the tables cleanly.\n\n\n\n\n\n PDF file troubleshooting tips \n\nFailed to parse document due to invalid encoding\n: Enable OCR for the file.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-troubleshoot-ingestion"}, {"document_id": "ibmcld_07140-1291-3176", "score": 17.398835761689384, "text": "\n* \"description\": \"Descriptive text about the configuration\" - A description of your configuration\n\n\n\nThe following objects and arrays must be defined to convert, enrich and normalize documents that are uploaded to your collection.\n\n\n\n* \"conversions\": {} - How documents are transformed into JSON that can be enriched.\n* \"enrichments\": [] - Which enrichments are applied to which parts of the JSON.\n* \"normalizations\": [] - Any post enrichment adjustments that are required before the document is stored.\n\n\n\nAdditionally, the following items are added to the base object by Discovery when the configuration is created/updated:\n\n{\n\"configuration_id\": \"4f5b7c7b-ebf4-4963-882e-27eff08f08e3\",\n\"created\": \"2017-09-13T14:45:03.575Z\",\n\"updated\": \"2017-09-13T14:45:03.575Z\"\n}\n\n\n\n\n\n Conversion \n\nConverting documents takes the original source format and using one or more steps transforms it into JSON that can be used for the rest of the ingestion process. Depending on the type of file uploaded, the process is as follows:\n\n\n\n* PDF files are converted to HTML using the pdf options, the resulting HTML is then converted to JSON using the html options, and finally the resulting JSON is converted using the json options.\n* Microsoft Word files are converted to HTML using the word options, the resulting HTML is then converted to JSON using the html options, and finally the resulting JSON is converted using the json options.\n* HTML files are converted to JSON using the html options, and the resulting JSON is converted using the json options.\n* JSON files are converted using the json options.\n\n\n\nIf you configure your collection using [Smart Document Understanding](https://cloud.ibm.com/docs/discovery?topic=discovery-sdu), the PDF and Word conversion settings listed are not used, so changing these conversion settings are ignored.\n\nThese options are described in the following sections.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-configref"}, {"document_id": "ibmcld_03054-7324-9318", "score": 16.961563386504025, "text": "\nSelect the language of the files that you are adding to this collection.\n\nFor information about the languages supported by Discovery, see [Language support](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-language-support).\n\nIf you are uploading a PDF document and want to extract party, nature, and category information from it, then expand the Advanced section and click Use the Default Contract Configuration with this collection.\n\n\n\n2. Click Next.\n3. Click Select documents to upload documents.\n\nSupported file types include PDF, HTML, JSON, Word, Excel, PowerPoint, PNG, TIFF, JPG, GIF, TXT, CSV, ZIP, GZIP, and TAR\n\nNo ongoing synchronization of uploaded documents is available. If you want to pick up changes that are made to a document, upload a later version of the document.\n\n\n\n\n\n2. Wait for the collection to be fully ingested.\n\nYour collection is added to a project that is created for you automatically. The project is a conversational search project with a name like Untitled Project 3; its sole purpose is to store your data collection.\n3. Find the project name in the page breadcrumb after your collection is created. Make a note of the project name in case you want to return to the collection from the Discovery application later.\n4. 1.5.0 only: If you want to add another collection to the project, click Manage collections, and then click New collection to add another collection.\n5. When the project contains all of the data collections that you want to use, click Back to Watson Assistant to finish creating the search skill.\n6. Select the project you just created from the list of projects, and then click Configure.\n\n\n\n\n\n Data collection creation example \n\nFor example, you might have a JSON file like this one:\n\n{\n\"Title\": \"About\",\n\"Shortdesc\": \"IBM Watson Assistant is a cognitive bot that you can customize for your business needs, and deploy across multiple channels to bring help to your customers where and when they need it.\",\n\"Topics\": \"overview\",", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add"}, {"document_id": "ibmcld_07224-7-1998", "score": 16.876062313985315, "text": "\nSmart Document Understanding \n\nSmart Document Understanding (SDU) trains IBM Watson\u2122 Discovery to extract custom fields in your documents. Customizing how your documents are indexed into Discovery improves the answers that your application returns.\n\nWith SDU, you annotate fields within your documents to train custom conversion models. As you annotate, Watson is learning and starts to predict annotations. SDU models can be exported and used on other collections.\n\nThis documentation applies to Discovery service instances that you create with a Lite or an Advanced plan, or that you created with a Premium plan before 16 July 2020. For more information about features in Premium plan instances created on or after 16 July 2020, and in Plus (including Plus Trial) plan instances, see [these docs](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-configuring-fields).\n\n\n\n Supported document types and browsers \n\nSupported document types for Smart Document Understanding:\n\n\n\n* Lite plans: PDF, Word, PowerPoint, Excel, JSON*, HTML*\n* Advanced plans: PDF, Word, PowerPoint, Excel, PNG**, TIFF**, JPG**, JSON*, HTML*\n\n\n\n* JSON and HTML documents are supported by IBM Watson\u2122 Discovery, but can not be edited using the SDU editor. To change the configuration of HTML and JSON docs, you need to use the API. For more information, see the [API reference](https://cloud.ibm.com/apidocs/discovery/).\n\n** Individual image files (PNG, TIFF, JPG) are scanned and the text (if any) is extracted. PNG, TIFF, and JPEG images embedded in PDF, Word, PowerPoint, and Excel files are also scanned and the text, if any, is extracted.\n\n\n\n\n\n Using the Smart Document Understanding editor \n\nThe SDU editor is only available for collections that contain supported document types and do not have the Element Classification enrichment applied. If you do not want to use the SDU editor, you can set up your configuration using the API, see the [API reference](https://cloud.ibm.com/apidocs/discovery/).", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-sdu"}, {"document_id": "ibmcld_07117-3483-5402", "score": 16.80308655285773, "text": "\nIf you encounter this issue, export the PPT file as a PDF file, and then upload the PDF file instead. Apply a user-trained Smart Document Understanding (SDU) model to the document, and then use the SDU tool to identify the tables in the document. The resulting model handles table boundaries properly and can extract text from the tables cleanly.\n\n\n\n\n\n PDF file troubleshooting tips \n\nFailed to parse document due to invalid encoding\n: Enable OCR for the file.\n\n\n\n\n\n Enrichment troubleshooting tips \n\nTable Understanding: n input tables excluded by enrichment\n: If tables in a document have inconsistent column and row spans or are too large for the system to process completely, the table understanding enrichment is not applied to them. Information from such tables cannot be returned in search results. If you want the table understanding enrichment to be applied to a table that was skipped, consider editing the table. Change a table with inconsistent column and row spans to have a simpler table format. Split a large table into many smaller tables.\n\nTo find the table where the enrichment was not applied, check the warning message. It lists the character offsets where the table begins and ends in the HTML representation of the document. To see the full warning message and get the document ID, click View all, and then make a note of the document ID. From the Improve and customize page, submit an empty search query to return all of the indexed documents. Look for the document ID. (You can change the search result settings to show the document ID as the result title.) Click the View passage in document link for your document, and then click Open advanced view. Choose to view the document as JSON and then look for the html field. Copy and paste the HTML representation of the document into a text editor. Look for the character offsets that were listed in the original warning message to find the table.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-troubleshoot-ingestion"}, {"document_id": "ibmcld_09218-11893-13832", "score": 16.684292596675643, "text": "\nThe service extracts and translates speaker names separately to guarantee consistent translation.\n* Paragraphs - The text to be translated is grouped into paragraphs. Each paragraph can span multiple cues, but it always consists of a full set of cue lines. In other words, each paragraph consists of one or more cues in their entirety, with each cue contained fully in a single paragraph.\n\nA single cue can contain one or more lines of text (for example, two short sentences). The service creates paragraph breaks only at cue line boundaries to preserve the count of lines in the cue. For languages with punctuation, a paragraph generally maps to a complete sentence. For languages without punctuation, a paragraph can contain multiple sentences, which can adversely affect the distribution of lines into cues in the translated document.\n* Comments, notes, and titles - For formats that permit these elements, the service preserves the original text and adds translation that is prefixed by language code. Because this information is intended for use by the author, the service maintains the text in both its original and translated forms.\n\n\n\n\n\n\n\n Other file formats \n\nTable 4 lists all other file formats that the service supports for translation.\n\n\n\nTable 4. Other file formats\n\n File format File extension Content type \n\n Adobe\u00ae Portable Document Format [1] pdf application/pdf \n Extensible Markup Language .xml text/xml \n HyperText Markup Language .htm text/html \n .html text/html \n .xhtml text/html \n JavaScript Object Notation [2] .json text/json \n Plain text .txt text/plain \n Rich Text Format .rtf application/rtf \n\n\n\nNotes:\n\n\n\n1. For PDF files, translation is experimental functionality. The quality of PDF translation is still largely an alpha release. The translation works best for single-column PDF documents that do not include many tables or images.\n2. For JSON files, values with type string or string array are translated.", "title": "", "source": "https://cloud.ibm.com/docs/language-translator?topic=language-translator-document-translator-tutorial"}, {"document_id": "ibmcld_07132-3199-5135", "score": 16.6245410954375, "text": "\n* The following file types can be ingested by Discovery, all other document types are ignored:\n\n\n\n\n\n Lite plans Advanced plans \n\n PDF, Word, PowerPoint, Excel, JSON*, HTML* PDF, Word, PowerPoint, Excel, PNG**, TIFF**, JPG**, JSON*, HTML* \n\n\n\n* JSON and HTML documents are supported by IBM Watson\u2122 Discovery, but can not be edited using the SDU editor. To change the configuration of HTML and JSON docs, you need to use the API. For more information, see the [API reference](https://cloud.ibm.com/apidocs/discovery/).\n\n** Individual image files (PNG, TIFF, JPG) are scanned and the text (if any) is extracted. PNG, TIFF, and JPEG images embedded in PDF, Word, PowerPoint, and Excel files are also scanned and the text (if any) extracted.\n\n\n\n* You cannot specify the data type (For example: text or date) of fields. During document ingestion, if a field is detected that does not yet exist in the index, Discovery automatically detects the data type of that field based on the value of the field for the first document indexed.\n* A document can fail to be ingested because of a type mismatch between data in the current document and similar data in a previously ingested document. For example, a field might be typed as a date in one document and a string in a subsequent document, preventing the subsequent document from being indexed correctly.\n* If you plan to use custom tokenization (currently only available for Japanese collections when using the Discovery API), the tokenization dictionary for your collection must be added before uploading documents.\n\n\n\n\n\n\n\n Uploading documents with the Discovery tooling \n\n\n\n1. Create a collection. See [Preparing the service for your documents](https://cloud.ibm.com/docs/discovery?topic=discovery-configservicepreparing-the-service-for-your-documents).\n2. Click on the collection to open it.\n3. Click the Upload documents button and start uploading your documents via drag and drop or browse.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-addcontent"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08867-7-2058", "score": 32.3012456456677, "text": "\nUsing Terraform on IBM Cloud to manage your own Red Hat OpenShift Container Platform on IBM Cloud classic infrastructure \n\nUse this tutorial to create your own highly available Red Hat\u00ae OpenShift Container Platform 3.11 environment on IBM\u00ae Cloud classic infrastructure by using Terraform on IBM Cloud.\n\nInstead of manually installing Red Hat\u00ae OpenShift Container Platform on IBM Cloud classic infrastructure, check out [Red Hat OpenShift on IBM Cloud](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_tutorial). This offering lets you create an IBM Cloud Kubernetes Service cluster with worker nodes that come installed with the OpenShift Container Platform software. You get all the advantages of managed IBM Cloud Kubernetes Service for your cluster infrastructure environment, while the OpenShift tooling and catalog that runs on Red Hat Enterprise Linux for your app deployments.\n\n[Red Hat\u00ae OpenShift Container Platform ![External link icon](https://cloud.ibm.com/docs-content/v1/content/4cd6263f39a034d265ddb4b0a5e6d50c55d13ee8/icons/launch-glyph.svg)](https://www.redhat.com/en/technologies/cloud-computing/openshift/container-platform) is built around a core of containers, with orchestration and management provided by Kubernetes, on a foundation of Atomic Host and Red Hat\u00ae Enterprise Linux. OpenShift Origin is the community distribution of Kubernetes that is optimized for continuous app development and multi-tenant deployment. The community project provides developer and operations-centric tools that are based on Kubernetes to enable rapid app development, deployment, scaling, and long-term app lifecycle maintenance.\n\nThis tutorial shows how you can set up OpenShift Container Platform 3.11 on IBM Cloud classic infrastructure with Terraform on IBM Cloud to try out the high availability capabilities of native Kubernetes and IBM Cloud. Review the following image to find an architectural overview of the classic infrastructure components that are needed for the Red Hat OpenShift Container Platform to work properly.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/ibm-cloud-provider-for-terraform?topic=ibm-cloud-provider-for-terraform-redhat"}, {"document_id": "ibmcld_05707-7-2073", "score": 32.15651149167165, "text": "\nBenefits and service offerings \n\n[IBM Cloud\u00ae Kubernetes Service](https://www.ibm.com/cloud/kubernetes-service) delivers powerful tools by combining Docker containers, the Kubernetes technology, an intuitive user experience, and built-in security and isolation to automate the deployment, operation, scaling, and monitoring of containerized apps in a cluster of compute hosts. For more information about certification, see [Compliance on the IBM Cloud](https://www.ibm.com/cloud/compliance).\n\n\n\n Benefits of using the service \n\nClusters are deployed on compute hosts that provide native Kubernetes and IBM-specific capabilities.\n\nChoice of container platform provider\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud. For more information, see Comparison between [Red Hat OpenShift](https://cloud.ibm.com/docs/containers?topic=containers-cs_ovopenshift_kubernetes) and community Kubernetes clusters.\n\nSingle-tenant Kubernetes clusters with compute, network, and storage infrastructure isolation\n: Create your own customized infrastructure that meets the requirements of your organization.\n: Choose between [IBM Cloud Classic or VPC infrastructure providers](https://cloud.ibm.com/docs/containers?topic=containers-infrastructure_providers).\n: Provision a dedicated and secured Kubernetes master, worker nodes, virtual networks, and storage by using the resources provided by IBM Cloud infrastructure.\n: Fully managed Kubernetes master that is continuously monitored and updated by IBM to keep your cluster available.\n: Option to provision worker nodes as bare metal servers for compute-intensive workloads such as data, GPU, and AI.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_ov"}, {"document_id": "ibmcld_14497-1215-3210", "score": 31.980152646511172, "text": "\n[VMware Solutions and Red Hat OpenShift](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/openshift-sddc.svg)\n\nFigure 1. VMware Solutions and OpenShift\n\n\n\n Red Hat OpenShift overview \n\nThe Red Hat OpenShift platform is a platform that is designed to orchestrate containerized workloads across a cluster of nodes. The platform uses Kubernetes as the core container orchestration engine, which manages the Docker container images and their lifecycle.\n\nThe operating system of the nodes is Red Hat\u00ae Enterprise Linux\u00ae CoreOS, which is the container host version of Red Hat Enterprise Linux (RHEL) and features an RHEL kernel with SELinux enabled by default. RHEL CoreOS includes kubelet, which is the Kubernetes node agent, and the CRI-O container runtime, which is optimized for Kubernetes. In Red Hat OpenShift 4.7, you must use RHEL CoreOS for all control plane machines, but you can use Red Hat Enterprise Linux (RHEL) as the operating system for compute, or worker machines. If you choose to use RHEL workers, you must perform more system maintenance than if you use RHEL CoreOS for all of the cluster machines.\n\nThe reference architecture and this build process use RHEL CoreOS. The nodes must have direct Internet access to complete the following tasks.\n\n\n\n* Access the Red Hat OpenShift Infrastructure Providers page to download the installation program.\n* Access quay.io to obtain the packages that are required to install the cluster.\n* Obtain the packages that are required to perform cluster updates.\n* Access Red Hat\u2019s software as a service page to perform subscription management.\n\n\n\nIn the reference architecture, the following components are installed and configured in the build process:\n\n\n\n* Bastion node - This RHEL VM acts as a \"jump-server\" on the overlay network to enable the build process. It is accessed by using SSH through the private network. It also hosts a webserver to help the build process of the cluster.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-openshift-runbook-runbook-intro"}, {"document_id": "ibmcld_07578-395666-397546", "score": 31.72842095074539, "text": "\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform. If you want to use multiple container platforms, create a separate cluster for each.\n\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https://kubernetes.io/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system. With the [IBM Cloud Kubernetes Service version](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionscs_versions), you get access to community Kubernetes API features that are considered beta or higher by the community. Kubernetes alpha features, which are subject to change, are generally not enabled by default. With Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-395640-397520", "score": 31.72842095074539, "text": "\nWith IBM Cloud, you can create clusters for your containerized workloads from two different container management platforms: the IBM version of community Kubernetes and Red Hat OpenShift on IBM Cloud. The container platform that you select is installed on your cluster master and worker nodes. Later, you can [update the version](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate) but can't roll back to a previous version or switch to a different container platform. If you want to use multiple container platforms, create a separate cluster for each.\n\nFor more information, see [Comparison between Red Hat OpenShift and community Kubernetes clusters](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes).\n\nKubernetes\n: [Kubernetes](https://kubernetes.io/) is a production-grade, open source container orchestration platform that you can use to automate, scale, and manage your containerized apps that run on an Ubuntu operating system. With the [IBM Cloud Kubernetes Service version](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionscs_versions), you get access to community Kubernetes API features that are considered beta or higher by the community. Kubernetes alpha features, which are subject to change, are generally not enabled by default. With Kubernetes, you can combine various resources such as secrets, deployments, and services to securely create and manage highly available, containerized apps.\n\nRed Hat OpenShift\n: Red Hat OpenShift on IBM Cloud is a Kubernetes-based platform that is designed especially to accelerate your containerized app delivery processes that run on a Red Hat Enterprise Linux 7 operating system. You can orchestrate and scale your existing Red Hat OpenShift workloads across on-prem and off-prem clouds for a portable, hybrid solution that works the same in multicloud scenarios.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03994-7147-8799", "score": 31.58164245886986, "text": "\nThis option duplicates your Kubernetes deployment across zones and regions, enabling high availability (HA) of your components and disaster recovery (DR).\n* Connect to other Fabric networks: Join IBM Blockchain Platform peers to any network running Hyperledger Fabric components. Similarly, you can invite Fabric peers to join channels hosted on an ordering service deployed on the IBM Blockchain Platform. Note that you will need to use Hyperledger Fabric APIs or the CLI.\n\n\n\nThis offering is intended for experienced Fabric users who want to build and manage their own networks.\n\nHave questions and want to speak to an IBM Blockchain Platform expert? [Schedule a consult](https://www.ibm.com/cloud/blockchain-platform/developer?schedulerform) now to learn more about how blockchain can transform your business.\n\n\n\n\n\n Supported IBM Cloud configuration \n\nReminder: If your IBM Blockchain Platform instance is linked to an IBM Cloud Kubernetes Service cluster that is no longer supported, you must immediately upgrade it to a supported version listed in the table below. See [Kubernetes version information](https://cloud.ibm.com/docs/containers?topic=containers-cs_versions) for Kubernetes version details. For the actual steps that are required, see [Updating clusters, worker nodes, and cluster components](https://cloud.ibm.com/docs/containers?topic=containers-updateupdate).\n\n\n\nTable 1. Supported IBM Cloud configuration\n\n\n\n Kubernetes <br><br> * v1.24 - v1.26<br><br><br> \n Orchestration Service <br><br> * Kubernetes<br> * OpenShift Container Platform on IBM Cloud 4.9, 4.10, 4.11, 4.12<br><br><br> \n Infrastructure <br><br> * Classic<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-overview"}, {"document_id": "ibmcld_04085-7-1799", "score": 30.51896498913366, "text": "\nKubernetes \n\nThe IBM Blockchain Platform allows you to provision blockchain components into your Kubernetes cluster. Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n\nKubernetes provides a container-centric management environment. It orchestrates computing, networking, and storage infrastructure on behalf of user workloads. This provides much of the simplicity of Platform as a Service (PaaS) with the flexibility of Infrastructure as a Service (IaaS), and enables portability across infrastructure providers.\n\nThe following diagram explains the architecture of Kubernetes. For more explanation about nodes, containers, and pod, see the [Key Kubernetes objects](https://cloud.ibm.com/docs/blockchain?topic=blockchain-k8s-overviewk8s-overview-key-obj) section below.\n\nZoom\n\n![Kubernetes architecture diagram](https://cloud.ibm.com/docs-content/v1/content/c5288bed34c3820e3a5251d820ee91adcd2591a3/blockchain/images/k8s-archi-diagram.svg)\n\nFigure 1. Kubernetes architecture diagram\n\n\n\n Key Kubernetes objects \n\n\n\n* Cluster\n\nA set of machines, called nodes, that run containerized applications managed by Kubernetes. A cluster has several worker nodes and at least one master node.\n* Node\n\nA node is a worker machine in Kubernetes. A node may be a VM or physical machine, depending on the cluster. Each node contains the services necessary to run pods and is managed by the master components. The services on a node include the container runtime, kubelet and kube-proxy. For more information, see the [Kubernetes Node section](https://kubernetes.io/docs/concepts/architecture/nodes/) in the Kubernetes documentation.\n* Container\n\nA lightweight and portable executable image that contains software and all of its dependencies.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-k8s-overview"}, {"document_id": "ibmcld_05707-8988-11065", "score": 30.511929459481113, "text": "\n[Portable public IP addresses](https://cloud.ibm.com/docs/containers?topic=containers-subnetsreview_ip) Yes \n [Logging and monitoring](https://cloud.ibm.com/docs/containers?topic=containers-healthlogging) Yes \n [Option to provision your worker nodes on physical (bare metal) servers](https://cloud.ibm.com/docs/containers?topic=containers-planning_worker_nodesplanning_worker_nodes) Yes \n\n\n\n\n\n\n\n Comparison between Red Hat OpenShift and community Kubernetes clusters \n\nBoth Red Hat OpenShift on IBM Cloud and IBM Cloud Kubernetes Service clusters are production-ready container platforms that are tailored for enterprise workloads. The following table compares and contrasts some common characteristics that can help you choose which container platform is best for your use case.\n\n\n\nCharacteristics of community Kubernetes and Red Hat OpenShift clusters\n\n Characteristics Community Kubernetes clusters Red Hat OpenShift clusters \n\n Complete cluster management experience through the IBM Cloud Kubernetes Service automation tools (API, CLI, console) Yes Yes \n Worldwide availability in single and multizones Yes Yes \n Consistent container orchestration across hybrid cloud providers Yes Yes \n Access to IBM Cloud services such as AI Yes Yes \n Software-defined storage Portworx solution available for multizone data use cases Yes Yes \n Create a cluster in an IBM Virtual Private Cloud (VPC) Yes Yes \n Latest community Kubernetes distribution Yes \n Scope IBM Cloud IAM access policies to access groups for service access roles that sync to cluster RBAC Yes \n Classic infrastructure cluster on only the private network Yes \n GPU bare metal worker nodes Yes Yes \n Integrated IBM Cloud Paks and middleware Yes \n Built-in container image streams, builds, and tooling ([read more](https://blog.cloudowski.com/articles/why-managing-container-images-on-openshift-is-better-than-on-kubernetes/)) Yes \n Integrated CI/CD with Jenkins Yes \n Stricter app security context set up by default Yes \n Simplified Kubernetes developer experience, with an app console that is suited for beginners Yes", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_ov"}, {"document_id": "ibmcld_03824-7-1809", "score": 30.47836782454575, "text": "\nKubernetes \n\nThe IBM Blockchain Platform allows you to provision blockchain components into your Kubernetes cluster. Kubernetes is an open-source system for automating deployment, scaling, and management of containerized applications.\n\nKubernetes provides a container-centric management environment. It orchestrates computing, networking, and storage infrastructure on behalf of user workloads. This provides much of the simplicity of Platform as a Service (PaaS) with the flexibility of Infrastructure as a Service (IaaS), and enables portability across infrastructure providers.\n\nThe following diagram explains the architecture of Kubernetes. For more explanation about nodes, containers, and pod, see the [Key Kubernetes objects](https://cloud.ibm.com/docs/blockchain/reference?topic=blockchain-k8s-overviewk8s-overview-key-obj) section below.\n\nZoom\n\n![Kubernetes architecture diagram](https://cloud.ibm.com/docs-content/v1/content/c5288bed34c3820e3a5251d820ee91adcd2591a3/blockchain/images/k8s-archi-diagram.svg)\n\nFigure 1. Kubernetes architecture diagram\n\n\n\n Key Kubernetes objects \n\n\n\n* Cluster\n\nA set of machines, called nodes, that run containerized applications managed by Kubernetes. A cluster has several worker nodes and at least one master node.\n* Node\n\nA node is a worker machine in Kubernetes. A node may be a VM or physical machine, depending on the cluster. Each node contains the services necessary to run pods and is managed by the master components. The services on a node include the container runtime, kubelet and kube-proxy. For more information, see the [Kubernetes Node section](https://kubernetes.io/docs/concepts/architecture/nodes/) in the Kubernetes documentation.\n* Container\n\nA lightweight and portable executable image that contains software and all of its dependencies.", "title": "", "source": "https://cloud.ibm.com/docs/blockchain/reference?topic=blockchain-k8s-overview"}, {"document_id": "ibmcld_10154-1411-3594", "score": 30.16448370385921, "text": "\n: Deploy clusters with Red Hat OpenShift or community Kubernetes installed as the container platform orchestrator.\n: Choose the developer experience that fits your company, or run workloads across both Red Hat OpenShift or community Kubernetes clusters.\n: Built-in integrations from the IBM Cloud console to the Kubernetes dashboard or Red Hat OpenShift web console.\n: Single view and management experience of all your Red Hat OpenShift or community Kubernetes clusters from IBM Cloud. For more information, see Comparison between [Red Hat OpenShift](https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ovopenshift_kubernetes) and community Kubernetes clusters.\n\nSingle-tenant Kubernetes clusters with compute, network, and storage infrastructure isolation\n: Create your own customized infrastructure that meets the requirements of your organization.\n: Choose between [IBM Cloud Classic or VPC infrastructure providers](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providers).\n: Provision a dedicated and secured Red Hat OpenShift master, worker nodes, virtual networks, and storage by using the resources provided by IBM Cloud infrastructure.\n: Fully managed Kubernetes master that is continuously monitored and updated by IBM to keep your cluster available.\n: Option to provision worker nodes as bare metal servers for compute-intensive workloads such as data, GPU, and AI.\n: Store persistent data, share data between Kubernetes pods, and restore data when needed with the integrated and secure volume service.\n: Benefit from full support for all native Kubernetes APIs.\n\nMultizone clusters to increase high availability\n: Easily manage worker nodes of the same flavor (CPU, memory, virtual or physical) with worker pools.\n: Guard against zone failure by spreading nodes evenly across select multizones and by using anti-affinity pod deployments for your apps.\n: Decrease your costs by using multizone clusters instead of duplicating the resources in a separate cluster.\n: Benefit from automatic load balancing across apps with the multizone load balancer (MZLB) that is set up automatically for you in each zone of the cluster.\n\nHighly available masters", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_ov"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04175-0-1274", "score": 41.88766833660394, "text": "\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models"}, {"document_id": "ibmcld_04105-5067-6335", "score": 38.90336221437711, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04168-6066-7283", "score": 35.37723137152747, "text": "\n* [Querying Edge Functions metrics with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https://cloud.ibm.com/docs/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https://cloud.ibm.com/docs/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https://cloud.ibm.com/docs/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https://cloud.ibm.com/docs/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https://cloud.ibm.com/docs/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https://cloud.ibm.com/docs/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https://cloud.ibm.com/docs/cis?topic=cis-at_events)", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-http-concepts"}, {"document_id": "ibmcld_10916-45658-47923", "score": 32.88443142002485, "text": "\nA JavaScript object that represents a back-end service such as a database, REST API (to be consumed), or SOAP web service. Data sources are backed by connectors that then communicate directly with the database or other back-end services.\n\n\n\n\n\n LoopBack model \n\nA model that provides a remote (REST) API that clients use to perform operations and interact with backend systems. The model consists of application data, validation rules, data access capabilities, and business logic. Every LoopBack application by default has a set of built-in models: user, application, email, and several models for access control.\n\n\n\n\n\n LUN \n\nSee [logical unit number](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx2163327).\n\n\n\n\n\n\n\n M \n\n\n\n machine learning (ML) \n\nA method of data analysis that iteratively learns from past data and independently adapts when exposed to new data. The mathematical model at the core of machine learning is built from ground truth inputs. Through training and refinement of example input data, the model can deliver accurate, repeatable results when it analyzes new data.\n\n\n\n\n\n machine learning annotator \n\nSee [machine learning model](https://cloud.ibm.com/docs/overview?topic=overview-glossaryx7579194).\n\n\n\n\n\n machine learning model \n\nA component that identifies entities and entity relationships according to a statistical model that is based on ground truth. The model applies past experience, such as training data, to determine or predict the correct outcome of future experiences based on characteristics of the data. These past experiences are captured in the form of a model by calculating feature scores for each candidate answer or evidence and combining that with known outcomes.\n\n\n\n\n\n Managed Service Provider (MSP) \n\nAn IBM Business Partner that provides IT services on a contractual basis to maintain clients' computers, networks or software. They manage services on-site at the clients' data center, remotely in the clients\u2019 data center, or in a third-party data center.\n\n\n\n\n\n master key \n\nAn encryption key that is used to protect a crypto unit. The master key provides full control of the hardware security module and ownership of the root of trust that encrypts the chain keys, including the root key and standard key.", "title": "", "source": "https://cloud.ibm.com/docs/overview?topic=overview-glossary"}, {"document_id": "ibmcld_02841-7-1807", "score": 30.122757453117007, "text": "\nAssistants \n\nAn assistant is a cognitive bot that you can customize for the unique needs of your business. You teach it about the types of things your customers want to know and do, and then design a script for the assistant to follow as it converses with your customers to help them accomplish their business goals.\n\n![Skills](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/skill-icon.png) An assistant routes your customer queries to a skill, which then provides the appropriate response. Dialog skills return responses that are authored by you to answer common questions, while search skills search for and return passages from existing self-service content to answer more complex inquiries.\n\n\n\n Dialog skill \n\nA dialog skill can understand and address questions or requests that your customers typically need help with. You provide information about the subjects or tasks your users ask about, and how they ask about them, and the product dynamically builds a machine learning model that is tailored to understand the same and similar user requests.\n\n\n\n Dialog tree Graphical user interface \n\n You can use graphical tools to create a dialog for your assistant to read from when interacting with your users, a dialog that simulates a real conversation. The dialog keys off the common customer goals that you teach it to recognize, and provides useful responses. ![A sample dialog tree with example content](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/dialog-depiction.png) \n\n\n\nThe dialog skill itself is defined in text, but you can integrate it with Watson Speech to Text and Watson Text to Speech services that enable users to interact with your assistant verbally.\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistants"}, {"document_id": "ibmcld_04105-3403-5572", "score": 29.788770180456293, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04170-7-2189", "score": 29.780086602908327, "text": "\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https://research.google/pubs/pub45581/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with /cdn-cgi/challenge-platform/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_16493-10519-12570", "score": 29.766007109644775, "text": "\nA subject matter expert who reviews, modifies, and augments the results of pre-annotation by identifying mentions, entity type relationships, and mention coreferences. By examining text in context, a human annotator helps determine ground truth and improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n I \n\n\n\n* inter-annotator agreement\n\nA measure of how similarly a document in two or more document sets is annotated.\n\n\n\n\n\n\n\n K \n\n\n\n* knowledge graph\n\nA model that consolidates typed entities, their relationships, their properties, and hierarchical taxonomies to represent an organization of concepts for a given domain. After the knowledge graph store is loaded with inputs from structured and unstructured data sources, users and applications can access the knowledge graph to explore key elements of knowledge for a specific domain, explore interactions, and discover additional relationships.\n\n\n\n\n\n\n\n L \n\n\n\n* lemma\n\nThe normalized or canonical form of a word. Typically, the lemma is the underived and uninflected form of a noun or a verb. For example, the lemma of the terms 'organizing' and 'organized' is 'organize'. See also [dictionary](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_D) and [surface form](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_S).\n\n\n\n\n\n\n\n M \n\n\n\n* machine learning\n\nA method of data analysis that iteratively learns from past data and independently adapts when exposed to new data. The mathematical model at the core of machine learning is built from ground truth inputs. Through training and refinement of example input data, the model can deliver accurate, repeatable results when it analyzes new data.\n* machine learning annotator\n\nSee [machine learning model](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-glossarygloss_M).\n* machine learning model\n\nA component that identifies entities and entity relationships according to a statistical model that is based on ground truth.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-glossary"}, {"document_id": "ibmcld_16436-10819-12900", "score": 29.5872079228981, "text": "\nA subject matter expert who reviews, modifies, and augments the results of pre-annotation by identifying mentions, entity type relationships, and mention coreferences. By examining text in context, a human annotator helps determine ground truth and improve the accuracy of the machine learning model.\n\n\n\n\n\n\n\n I \n\n\n\n* inter-annotator agreement\n\nA measure of how similarly a document in two or more document sets is annotated.\n\n\n\n\n\n\n\n K \n\n\n\n* knowledge graph\n\nA model that consolidates typed entities, their relationships, their properties, and hierarchical taxonomies to represent an organization of concepts for a given domain. After the knowledge graph store is loaded with inputs from structured and unstructured data sources, users and applications can access the knowledge graph to explore key elements of knowledge for a specific domain, explore interactions, and discover additional relationships.\n\n\n\n\n\n\n\n L \n\n\n\n* lemma\n\nThe normalized or canonical form of a word. Typically, the lemma is the underived and uninflected form of a noun or a verb. For example, the lemma of the terms 'organizing' and 'organized' is 'organize'. See also [dictionary](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossarygloss_D) and [surface form](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossarygloss_S).\n\n\n\n\n\n\n\n M \n\n\n\n* machine learning\n\nA method of data analysis that iteratively learns from past data and independently adapts when exposed to new data. The mathematical model at the core of machine learning is built from ground truth inputs. Through training and refinement of example input data, the model can deliver accurate, repeatable results when it analyzes new data.\n* machine learning annotator\n\nSee [machine learning model](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossarygloss_M).\n* machine learning model\n\nA component that identifies entities and entity relationships according to a statistical model that is based on ground truth.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-glossary"}, {"document_id": "ibmcld_16729-325238-327171", "score": 28.4680044814651, "text": "\n[Build, deploy, test and monitor a predictive machine learning model](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model)Build, deploy, test and monitor a predictive machine learning model\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\nObject Storage\n\n\n\n* 2 hours\n* 2023-06-14\n\n\n\n[Plan, create and update deployment environments](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-plan-create-update-deployments)Plan, create and update deployment environments\n\nMultiple deployment environments are common when building a solution. They reflect the lifecycle of a project from development to production. This tutorial introduces tools like the IBM Cloud CLI and Terraform to automate the creation and maintenance of these deployment environments.\n\nKubernetes service Virtual Servers for Classic\n\n+5\n\nObject Storage,Cloudant,,Activity Tracker hosted event search,Monitoring\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Resource sharing across accounts](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-resource-sharing)Resource sharing across accounts\n\nThis tutorial walks you through different options on how to share cloud-based resources across accounts.\n\nVirtual Private Cloud (VPC) Log Analysis\n\n+6\n\nActivity Tracker hosted event search,Secrets Manager,App ID,Key Protect,Hyper Protect Crypto Services,Object Storage\n\n\n\n* 1 hour\n* 2023-05-05\n\n\n\n[Serverless web application and API with Code Engine](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-serverless-webapp)Serverless web application and API with Code Engine", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_11886-7-2186", "score": 20.21079481837079, "text": "\nGranting Satellite Config access to your clusters \n\nBy default, clusters that you create in a Satellite location have Satellite Config components automatically installed. However, you must grant the service accounts that Satellite Config uses the appropriate access to view and manage Kubernetes resources in each cluster.\n\nSatellite Config requires admin access to your clusters to manage them. You can configure access in one of the following ways.\n\n\n\n* Automatically during cluster creation. Choose this option if you want to use Satellite storage templates.\n* Manually after cluster creation. Choose this option if you want more controlled access and do not plan on using Satellite storage templates.\n\n\n\nIf you do not grant Satellite Config access, you cannot later use the Satellite Config functionality to view or deploy Kubernetes resources for your clusters.\n\n\n\n Automatically granting Satellite Config access to your clusters \n\nYou can give Satellite Config access to your cluster by specifying the relevant option when you create the cluster.\n\nTo give Satellite Config access to manage Kubernetes resources from the console, select Enable cluster admin access for Satellite Config when you create the cluster. To set up access with the CLI, specify the --enable-config-admin option when you create the cluster.\n\nIf you didn't give Satellite Config access at cluster creation time, follow the steps in [Manually granting Satellite Config access to your clusters](https://cloud.ibm.com/docs/satellite?topic=satellite-setup-clusters-satconfigmanual-setup-clusters-satconfig).\n\n\n\n\n\n Manually granting Satellite Config access to your clusters \n\nIf you did not grant Satellite Config access to your cluster during cluster creation time, you can still set up the access manually.\n\nChoose from the following options.\n\n\n\n* Admin access when you create a Satellite cluster: You can enable admin permissions when you create the cluster in the console or in the CLI by using the --enable-config-admin option in the ibmcloud oc cluster create satellite command. After creating the cluster, you must perform a one-time login by running ibmcloud ks cluster config in the command line.", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-setup-clusters-satconfig"}, {"document_id": "ibmcld_10026-37631-39076", "score": 19.839629745179796, "text": "\n--service-instance <cluster_ID> To restrict the policy to a particular cluster, enter the cluster's ID. To get your cluster ID, run ibmcloud oc clusters. If you don't include the service instance, the access policy grants the service ID access to all your clusters, Kubernetes and Red Hat OpenShift. You can also scope the access policy to a region (--region) or resource group (--resource-group-name). \n\n\n\n3. Create an API key for the service ID. Name the API key similar to your service ID, and include the service ID that you previously created, <cluster_name>-id. Be sure to give the API key a description that helps you retrieve the key later. Save your API key in a secure location. You can't retrieve the API key again. If you want to export the output to a file on your local machine, include the --file <path>/<file_name> option.\n\nibmcloud iam service-api-key-create <cluster_name>-key <service_ID> --description \"API key for service ID <service_ID> in Red Hat OpenShift cluster <cluster_name>\"\n\nExample output\n\nPlease preserve the API key! It can't be retrieved after it's created.\n\nName <cluster_name>-key\nDescription API key for service ID <service_ID> in Red Hat OpenShift cluster <cluster_name>\nBound To crn:v1:bluemix:public:iam-identity::a/1bb222bb2b33333ddd3d3333ee4ee444::serviceid:ServiceId-ff55555f-5fff-6666-g6g6-777777h7h7hh\nCreated At 2019-02-01T19:06+0000\nAPI Key i-8i88ii8jjjj9jjj99kkkkkkkkk_k9-llllll11mmm1\nLocked false", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-access_cluster"}, {"document_id": "ibmcld_05739-9250-10978", "score": 18.127528683957184, "text": "\nEndpoint Security Mitigation Kubernetes cluster role system:aggregate-to-edit has removed endpoints permissions as a security mitigation for [CVE-2021-25740](https://nvd.nist.gov/vuln/detail/CVE-2021-25740). If your cluster does not require any customizations to the system:aggregate-to-edit cluster role, besides removing the endpoints permission, allow Kubernetes to reconcile the permissions by running the kubectl annotate --overwrite clusterrole/system:aggregate-to-edit rbac.authorization.kubernetes.io/autoupdate=true command. Subsequent cluster master operations (for example, ibmcloud ks cluster master refresh) will then ensure the permissions are reconciled by Kubernetes. \n Unsupported: kubectl autoscale removes --generator option The kubectl austoscale no longer uses the deprecated --generator option. If your scripts rely on this option, update them. \n Unsupported: kubectl create deployment removes --generator option The kubectl create deployment command no longer uses the deprecated --generator option. If your scripts rely on this option, update them. \n system:aggregate-to-edit write access for Endpoints API The system:aggregate-to-edit role no longer includes write access to the Endpoints API. Existing clusters that are upgraded to Kubernetes 1.22 are not impacted. However, in new Kubernetes 1.22 clusters, the Editor and Administrator roles don't have write access to the Endpoints API. For more information on retaining this access in newly created 1.22 clusters, see [Write access for Endpoints](https://kubernetes.io/docs/reference/access-authn-authz/rbac/write-access-for-endpoints). This update is a mitigation for [CVE-2021-25740](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-25740).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_versions_122"}, {"document_id": "ibmcld_07578-380995-382843", "score": 17.644170558581642, "text": "\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https://cloud.ibm.com/docs/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https://cloud.ibm.com/docs/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https://cloud.ibm.com/docs/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-380969-382817", "score": 17.644170558581642, "text": "\n* What options do I have to secure my cluster?\n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-securitysecurity).\n* What access policies do I give my cluster users?\n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles. For more information about types of access policies, see [Pick the correct access policy and role for your users](https://cloud.ibm.com/docs/containers?topic=containers-access-overviewaccess_roles).\n\nThe access policies that you assign users vary depending on what you want your users to be able to do. You can find more information about what roles authorize which types of actions on the [User access reference page](https://cloud.ibm.com/docs/containers?topic=containers-access_reference) or in the following table's links. For steps to assign policies, see [Granting users access to your cluster through IBM Cloud IAM](https://cloud.ibm.com/docs/containers?topic=containers-userschecking-perms).\n\n\n\nTypes of roles you might assign to meet different use cases.\n\n Use case Example roles and scope", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_05777-8738-10765", "score": 17.484761626482275, "text": "\nThis setup is called a [multizone cluster](https://cloud.ibm.com/docs/containers?topic=containers-ha_clustersmz-clusters) and ensures that your app is accessible, even if a worker node or an entire zone is not available.\n\nTo protect against an entire region failure, create [multiple clusters and spread them across IBM Cloud regions](https://cloud.ibm.com/docs/containers?topic=containers-ha_clustersmultiple-clusters-glb). By setting up a network load balancer (NLB) for your clusters, you can achieve cross-region load balancing and cross-region networking for your clusters.\n\nIf you have data that must be available, even if an outage occurs, make sure to store your data on [persistent storage](https://cloud.ibm.com/docs/containers?topic=containers-storage-plan).\n\nFor more information about how to achieve high availability for your cluster, see [High availability for IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-haha).\n\n\n\n\n\n What options do I have to secure my cluster? \n\nYou can use built-in security features in IBM Cloud Kubernetes Service to protect the components in your cluster, your data, and app deployments to ensure security compliance and data integrity. Use these features to secure your Kubernetes API server, etcd data store, worker node, network, storage, images, and deployments against malicious attacks. You can also leverage built-in logging and monitoring tools to detect malicious attacks and suspicious usage patterns.\n\nFor more information about the components of your cluster and how you can meet security standards for each component, see [Security for IBM Cloud Kubernetes Service](https://cloud.ibm.com/docs/containers?topic=containers-securitysecurity).\n\n\n\n\n\n What access policies do I give my cluster users? \n\nIBM Cloud Kubernetes Service uses Cloud Identity and Access Management (IAM) to grant access to cluster resources through IAM platform access roles and Kubernetes role-based access control (RBAC) policies through IAM service access roles.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-faqs"}, {"document_id": "ibmcld_05525-70102-71582", "score": 17.108382023071, "text": "\nKubernetes v1.13.5 v1.14.1 See the [Kubernetes release notes](https://github.com/kubernetes/kubernetes/releases/tag/v1.14.1) and [Kubernetes 1.14 blog](https://kubernetes.io/blog/2019/03/25/kubernetes-1-14-release-announcement/). <br>The Kubernetes default role-based access control (RBAC) policies no longer grant access to [discovery and permission-checking APIs to unauthenticated users](https://kubernetes.io/docs/reference/access-authn-authz/rbac/discovery-roles). This change applies only to new version 1.14 clusters. If you update a cluster from a prior version, unauthenticated users still have access to the discovery and permission-checking APIs. \n Kubernetes admission controllers configuration N/A N/A <br><br> * Added NodeRestriction to the --enable-admission-plugins option for the cluster's Kubernetes API server and configured the related cluster resources to support this security enhancement.<br> * Removed Initializers from the --enable-admission-plugins option and admissionregistration.k8s.io/v1alpha1=true from the --runtime-config option for the cluster's Kubernetes API server because these APIs are no longer supported. Instead, you can use [Kubernetes admission webhooks](https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/).<br><br><br> \n Kubernetes DNS autoscaler 1.3.0 1.4.0 See the [Kubernetes DNS autoscaler release notes](https://github.com/kubernetes-sigs/cluster-proportional-autoscaler/releases/tag/1.4.0).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-114_changelog"}, {"document_id": "ibmcld_06231-17034-19040", "score": 16.766162346120314, "text": "\nOtherwise, [give the users the platform Viewer role](https://cloud.ibm.com/docs/containers?topic=containers-usersadd_users_cli_platform).\n5. Optional: After a couple minutes, verify that the user is added to the corresponding [RBAC role binding or cluster role binding](https://cloud.ibm.com/docs/containers?topic=containers-userschecking-rbac).\n\n\n\nUsers must run the ibmcloud ks cluster config command for their role changes to take effect.\n\n\n\n\n\n\n\n Understanding RBAC permissions \n\nRBAC roles and cluster roles define a set of permissions for how users can interact with Kubernetes resources in your cluster.\n\nWith IBM Cloud IAM, you can automatically manage RBAC from IBM Cloud, by assigning users [service access roles](https://cloud.ibm.com/docs/containers?topic=containers-usersadd_users). You might want a deeper understanding of RBAC to customize access for resources within your cluster, like service accounts.\n\n\n\n What are the types of RBAC roles? \n\n\n\n* A Kubernetes role is scoped to resources within a specific namespace, such as a deployment or service.\n* A Kubernetes cluster role is scoped to cluster-wide resources, such as worker nodes, or to namespace-scoped resources that can be found in each namespace, like pods.\n\n\n\n\n\n\n\n What are RBAC role bindings and cluster role bindings? \n\nRole bindings apply RBAC roles or cluster roles to a specific namespace. When you use a role binding to apply a role, you give a user access to a specific resource in a specific namespace. When you use a role binding to apply a cluster role, you give a user access to namespace-scoped resources that can be found in each namespace, like pods, but only within a specific namespace.\n\nCluster role bindings apply RBAC cluster roles to all namespaces in the cluster. When you use a cluster role binding to apply a cluster role, you give a user access to cluster-wide resources, like worker nodes, or to namespace-scoped resources in every namespace, like pods.\n\n\n\n\n\n What do these roles look like in my cluster?", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-users"}, {"document_id": "ibmcld_12666-2025-3606", "score": 16.75964995275656, "text": "\nAdditionally, the workstation must have a directory with write permissions and sufficient storage to store the backup. 125GB of storage space is sufficient for all deployments.\n\nTo take a backup, follow these steps:\n\n\n\n1. Access the cluster where Data Security Broker Manager is deployed by logging into a Kubernetes or Red Hat OpenShift workstation.\n2. To back up the MongoDB collections and Data Security Broker Manager configuration files, create the script provided below and execute it. The location that is specified after the -b option is where the backup file is kept by the script. Check whether the script is being used to back up a Data Security Broker Manager deployment on a Red Hat OpenShift cluster or a Kubernetes cluster, and uncomment the relevant command alias for the specified type of cluster where Data Security Broker Manager is installed.\n\n\n\n!/bin/bash\nif [ $ -eq 0 ]\nthen\necho \"No arguments supplied\"\necho \"Usage: $0 -b <backup location> -n <k8s namespace>\"\nfi\n\nwhile getopts b:n: flag\ndo\ncase \"${flag}\" in\nb) backup=${OPTARG};;\nn) namespace=${OPTARG};;\nesac\ndone\n\nif [ -z \"${backup}\" ];\nthen\necho \"Please provide backup location with -b option\"\nexit\nfi\n\nif [! -d \"$backup\" ];\nthen\necho \"Please provide a valid backup location with -b option\"\nexit\nfi\n\nif [ -z \"${namespace}\" ];\nthen\necho \"Please provide a valid namespace with -n option\"\nexit\nfi\n\n NOTE: SET THE kb ALIAS TO THE CORRECT ONE FOR THE CLUSTER TYPE\n\n For Kubernetes\nkb='kubectl --namespace $namespace'\n For OpenShift\nkb='kubectl --namespace '$namespace\n\n Retrieving container details\n\n\necho $kb", "title": "", "source": "https://cloud.ibm.com/docs/security-broker?topic=security-broker-sb_dr"}, {"document_id": "ibmcld_13177-14661-16794", "score": 16.57485810904837, "text": "\n* no matter the environment, all clusters will tend to look the same,\n* it is easier to control who has access to a specific cluster,\n* it gives flexibility in the update cycles for deployments and underlying resources: When there is a new Kubernetes version, it gives you the option to update the Development cluster first, validate your application then update the other environment,\n* it avoids mixing different workloads that may impact each other such as isolating the production deployment from the others.\n\n\n\nHowever, often not all of that properties are needed and the use of fewer resources is desired. Then, another approach is to use [Kubernetes namespaces](https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/) in conjunction with [Kubernetes resource quotas](https://kubernetes.io/docs/concepts/policy/resource-quotas/) to isolate environments and control resource consumption. The following diagram shows a non-production and a production resource group with a Kubernetes cluster in a VPC each. The non-production cluster has a development and testing namespace, the production cluster a production namespace.\n\nZoom\n\n![Diagram showing separate Kubernetes namespaces to isolate environments](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution20-users-teams-applications/multiple-environments-with-namespaces.svg)\n\nUse separate Kubernetes namespaces to isolate environments\n\n\n\n\n\n Setup delivery pipeline \n\nWhen it comes to deploying to the different environments, your continuous integration / continuous delivery pipeline can be setup to drive the full process:\n\n\n\n* continuously update the Development environment with the latest and greatest code from the development branch, running unit tests and integration tests on the dedicated cluster;\n* promote development builds to the Testing environment, either automatically if all tests from the previous stages are OK or through a manual promotion process. Some teams will use different branches too here, merging the working development state to a stable branch as example;", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-users-teams-applications"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03373-2953-4766", "score": 18.694271961844102, "text": "\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\n![Diagram of a simple exchange between a customer and an actions skill step.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/action-skill-explained.png)\n\n\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https://cloud.ibm.com/docs/assistant?topic=assistant-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. The name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.\n* [Dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-build): A dialog is a branching conversation flow that defines how your application responds when it recognizes the defined intents and entities. You use the dialog editor to create conversations with users, providing responses based on the intents and entities that you recognize in their input.\n\n![Diagram of a basic implementation that uses intent and dialog only.]", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add"}, {"document_id": "ibmcld_03334-20892-22106", "score": 18.69037531797779, "text": "\nRepeat the previous steps to resolve other intents with conflicts.\n\n\n\n\n\n\n\n Deleting intents \n\nYou can select a number of intents for deletion.\n\nIMPORTANT: By deleting intents that you are also deleting all associated examples, and these items cannot be retrieved later. All dialog nodes that reference these intents must be updated manually to no longer reference the deleted content.\n\n\n\n1. Go to the Intents page\n\n\n\n* To delete all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Delete all intents icon. ![Delete option](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/delete-c10.png)\n* To delete the intents that are listed on the current page only, select the checkbox in the header. This action selects all of the intents that are listed on the current page. Click Delete.\n* To delete one or more specific intents, select the intents that you want to delete, and then click Delete.\n\n![Shows that an intent was selected and the delete icon is in focus](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/intent-delete.png)", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}, {"document_id": "ibmcld_03010-18014-19579", "score": 18.15679587279717, "text": "\n[Shows the Move menu with a list of one intent options](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/intent-move-conflict.png)\n\nWhen deciding where to put an example, look for the intent that has synonymous, or nearly synonymous, examples.\n\nIf the exact same example is used by the other intent already, the move action only removes the example from the current intent. It does not add the same example to the other intent twice.\n5. After moving or deleting the example, click Submit to resolve the conflict.\n\n![Shows a resolved conflict](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/intent-submit-conflict.png)\n\nThe Reset reverts your changes. Click the x to close the page without submitting your changes.\n6. Repeat the previous steps to resolve other intents with conflicts.\n\n\n\n\n\n\n\n Deleting intents \n\nYou can select a number of intents for deletion.\n\nIMPORTANT: By deleting intents that you are also deleting all associated examples, and these items cannot be retrieved later. All dialog nodes that reference these intents must be updated manually to no longer reference the deleted content.\n\n\n\n1. Go to the Intents page\n\n\n\n* To delete all intents, meaning the intents listed on this and any additional pages, do not select any individual intents. Instead, click the Delete all intents icon. ![Delete option](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/delete-c10.png)", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents"}, {"document_id": "ibmcld_03334-19597-21305", "score": 18.05527849935121, "text": "\nIt provides you with context that can help you make a more informed decision.\n\nKeep each intent as distinct and focused on one goal as possible. If you have two intents with multiple user examples that overlap, maybe you don't need two separate intents. You can move or delete user examples that don't directly overlap into one intent, and then delete the other.\n4. To move a user example, click Move, and then click the intent where you want to move the example.\n\n![Shows the Move menu with a list of one intent options](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/intent-move-conflict.png)\n\nWhen deciding where to put an example, look for the intent that has synonymous, or nearly synonymous, examples.\n\nIf the exact same example is used by the other intent already, the move action only removes the example from the current intent. It does not add the same example to the other intent twice.\n5. After moving or deleting the example, click Submit to resolve the conflict.\n\n![Shows a resolved conflict](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/intent-submit-conflict.png)\n\nThe Reset reverts your changes. Click the x to close the page without submitting your changes.\n6. Repeat the previous steps to resolve other intents with conflicts.\n\n\n\n\n\n\n\n Deleting intents \n\nYou can select a number of intents for deletion.\n\nIMPORTANT: By deleting intents that you are also deleting all associated examples, and these items cannot be retrieved later. All dialog nodes that reference these intents must be updated manually to no longer reference the deleted content.\n\n\n\n1. Go to the Intents page", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}, {"document_id": "ibmcld_16364-67629-69709", "score": 17.949724455446848, "text": "\n: We have added step-by-step documentation for connecting to [Genesys](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone-genesys) and [Twilio Flex](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone-flex) over the phone. Easily hand off to your live agents when your customers require telephony support from your service team. Watson Assistant deploys on the phone via SIP, so most phone based service desks can easily be integrated via SIP trunking standards.\n\n\n\n\n\n 23 August 2021 \n\nIntent detection updates\n: Intent detection for the English language has been updated with the addition of new word-piece algorithms. These algorithms improve tolerance for out-of-vocabulary words and misspelling. This change affects only English-language assistants, and only if the enhanced intent recognition model is enabled. (For more information about the enhanced intent recognition model, and how to determine whether it is enabled, see [Improved intent recognition](https://cloud.ibm.com/docs/assistant?topic=assistant-intent-detection).)\n\nAutomatic retraining of old skills and workspaces\n: As of August 23, 2021, Watson Assistant enabled automatic retraining of existing skills in order to take advantage of updated algorithms. The Watson Assistant service will continually monitor all ML models, and will automatically retrain those models that have not been retrained within the previous 6 months. For more information, see [Automatic retraining of old skills and workspaces](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-auto-retrain).\n\n\n\n\n\n 19 August 2021 \n\nActions preview now includes debug mode and variable values\n: When previewing your actions, you can use debug mode and variable values to ensure your assistant is working the way you expect.\n\nDebug mode allows you to go to the corresponding step by clicking on a step locator next to each message. It shows you the confidence score of top three possible action when the input triggers an action. You can also follow the step in the action editor along with the conversation flow.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}, {"document_id": "ibmcld_03310-10261-12004", "score": 16.991150155124494, "text": "\nThe response also includes the top 10 other intents that are defined in the skill regardless of their confidence score. (In this example, its confidence in the other intents is set to 0 because the first intent is an exact match.) The top 10 intents are returned because the \"Try it out\" pane sends the alternate_intents:true parameter with its request. If you are using the API directly and want to see the top 10 results, be sure to specify this parameter in your call. If alternate_intents is false, which is the default value, only intents with a confidence above 0.2 are returned in the array.\n\n[!{\"intent\":\"greeting\",\"confidence\":1},\n{\"intent\":\"yes\",\"confidence\":0},\n{\"intent\":\"pizza-order\",\"confidence\":0}]\n\nIf you want to include text in the response, use the toJson() method in the expression to cast the returned intents list into a JSON object. For example:\n\nRecognized intents are: <? intents.toJson() ?>\n\nThe following examples show how to check for an intent value:\n\n\n\n* intents[0] == 'Help'\n* intent == 'Help'\n\n\n\nintent == 'help' differs from intents[0] == 'help' because intent == 'help' does not throw an exception if no intent is detected. It is evaluated as true only if the intent confidence exceeds a threshold. If you want to, you can specify a custom confidence level for a condition, for example, intents.size() > 0 && intents[0] == 'help' && intents[0].confidence > 0.1\n\n\n\n\n\n Accessing input \n\nThe input JSON object contains one property only: the text property. The text property represents the text of the user input.\n\n\n\n Input property usage examples \n\nThe following example shows how to access input:\n\n\n\n* To execute a node if the user input is \"Yes\", add this expression to the node condition: input.text == 'Yes'", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-expression-language"}, {"document_id": "ibmcld_02988-8862-10727", "score": 16.985766179375496, "text": "\nThe confidence property is a decimal percentage that represents your assistant's confidence in the recognized intent.\n\nWhile testing your dialog, you can see details of the intents that are recognized in user input by specifying this expression in a dialog node response:\n\n<? intents ?>\n\nFor the user input, Hello now, your assistant finds an exact match with the #greeting intent. Therefore, it lists the #greeting intent object details first. The response also includes the 10 other intents that are defined in the skill regardless of their confidence score. (In this example, its confidence in the other intents is set to 0 because the first intent is an exact match.) The top 10 intents are returned because the Try it out pane sends the alternate_intents:true parameter with its request. If you are using the API directly and want to see the top 10 results, be sure to specify this parameter in your call. If alternate_intents is false, which is the default value, only intents with a confidence above 0.2 are returned in the array.\n\n[!{\"intent\":\"greeting\",\"confidence\":1},\n{\"intent\":\"yes\",\"confidence\":0},\n{\"intent\":\"pizza-order\",\"confidence\":0}]\n\nThe following examples show how to check for an intent value:\n\n\n\n* intents[0] == 'Help'\n* intent == 'Help'\n\n\n\nintent == 'help' differs from intents[0] == 'help' because intent == 'help' does not throw an exception if no intent is detected. It is evaluated as true only if the intent confidence exceeds a threshold. If you want to, you can specify a custom confidence level for a condition, for example, intents.size() > 0 && intents[0] == 'help' && intents[0].confidence > 0.1\n\n\n\n\n\n Accessing input \n\nThe input JSON object contains one property only: the text property. The text property represents the text of the user input.\n\n\n\n Input property usage examples \n\nThe following example shows how to access input:", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-expression-language"}, {"document_id": "ibmcld_03182-4-2053", "score": 16.970637008494194, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Dialog creation workflow \n\nUse Watson Assistant to leverage AI as you build, deploy, and incrementally improve a conversational assistant.\n\n![Shows the flow of development steps starting with developing training data and ending with deploying to production](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/dev-process.png)\n\n\n\n Development process \n\nThe typical workflow for an assistant project includes the following steps:\n\n\n\n1. Define a narrow set of key customer needs that you want the assistant to address on your behalf, including any business processes that it can initiate or complete for your customers. Start small.\n2. Create intents that represent the customer needs you identified in the previous step. For example, intents such as about_company or place_order.\n3. Build a dialog that detects the defined intents and addresses them, either with simple responses or with a dialog flow that collects more information first.\n4. Define any entities that are needed to more clearly understand the user's meaning. For example, you might add an @product entity that you can use with the place_order intent to understand what product the customer wants to buy.\n\nMine existing intent user examples for common entity value mentions. Using annotations to define entities captures not only the text of the entity value, but the context in which the entity value is typically used in a sentence.\n\nFor dictionary-based entities, you can use synonym recommendations to expand your entity definitions.\n5. Test each function that you add to the assistant in the \"Try it\" pane, incrementally, as you go.\n6. When you have a working assistant that can successfully handle key tasks, add an integration that deploys the assistant to a development environment. Test the deployed assistant and make refinements.\n7.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dev-process"}, {"document_id": "ibmcld_03069-7-2188", "score": 16.73469616465273, "text": "\nTutorial: Building a complex dialog \n\nIn this tutorial, you will use the Watson Assistant service to create a dialog for an assistant that helps users with inquiries about a fictitious restaurant called Truck Stop Gourmand.\n\n\n\n Learning objectives \n\nBy the time you finish the tutorial, you will understand how to:\n\n\n\n* Plan a dialog\n* Define custom intents\n* Add dialog nodes that can handle your intents\n* Add entities to make your responses more specific\n* Add a pattern entity, and use it in the dialog to find patterns in user input\n* Set and reference context variables\n\n\n\n\n\n Duration \n\nThis tutorial will take approximately 2 to 3 hours to complete.\n\n\n\n\n\n Prerequisite \n\nBefore you begin, complete the [Getting Started tutorial](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-getting-started).\n\nYou will use the dialog skill that you created, and add nodes to the simple dialog that you built as part of the getting started exercise.\n\n\n\n\n\n\n\n Step 1: Plan the dialog \n\nYou are building an assistant for a restaurant named Truck Stop Gourmand that has one location and a thriving cake-baking business. You want the simple assistant to answer user questions about the restaurant, its menu, and to cancel customer cake orders. Therefore, you need to create intents that handle inquiries related to the following subjects:\n\n\n\n* Restaurant information\n* Menu details\n* Order cancellations\n\n\n\nYou'll start by creating intents that represent these subjects, and then build a dialog that responds to user questions about them.\n\n\n\n\n\n Step 2: Answer questions about the restaurant \n\nAdd an intent that recognizes when customers ask for details about the restaurant itself. An intent is the purpose or goal expressed in user input. The General_About_You intent that is provided with the General content catalog serves a similar function, but its user examples are designed to focus on queries about the assistant as opposed to the business that is using the assistant to help its customers. So, you will add your own intent.\n\n\n\n Add the about_restaurant intent \n\n\n\n1. From the Intents tab, click Create intent.\n\n![Shows the the Create intent button on the Intents page.]", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-tutorial"}, {"document_id": "ibmcld_03334-1458-3293", "score": 16.719760323449915, "text": "\nThe user examples should be tailored to your specific business. For example, if you are an insurance company, a user example might look more like this, I want to buy a new XYZ insurance plan.\n\nThe examples that you provide are used by your assistant to build a machine learning model that can recognize the same and similar types of utterances and map them to the appropriate intent.\n\n\n\nStart with a few intents, and test them as you iteratively expand the scope of the application.\n\n![Plus or higher plans only](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/plus.png) If you already have chat transcripts from a call center or customer inquiries that you collected from an online application, put that data to work for you. Share the real customer utterances with Watson and let Watson recommend the best intents and intent user examples for your needs. See [Get help defining intents](https://cloud.ibm.com/docs/assistant?topic=assistant-intent-recommendations) for more details.\n\n\n\n\n\n Creating intents \n\n\n\n1. Open your dialog skill. The skill opens to the Intents page.\n2. Select Create intent.\n3. In the Intent name field, type a name for the intent.\n\n\n\n* The intent name can contain letters (in Unicode), numbers, underscores, hyphens, and periods.\n* The name cannot consist of .. or any other string of only periods.\n* Intent names cannot contain spaces and must not exceed 128 characters. The following are examples of intent names:\n\n\n\n* weather_conditions\n* pay_bill\n* escalate_to_agent\n\n\n\n\n\nA number sign is prepended to the intent name automatically to help identify the term as an intent. You do not need to add it.\n\nKeep the name as short as possible. It's easier to read in the \"Try it out\" pane and conversation logs if you keep the intent name short and concise.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-intents"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-1183252-1185036", "score": 40.56991527113185, "text": "\nThe user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n* How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?\n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https://cloud.ibm.com/catalog/services/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1185885-1187669", "score": 40.56991527113185, "text": "\nThe user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n* How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator?\n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https://cloud.ibm.com/catalog/services/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03729-7-2197", "score": 39.48217108518057, "text": "\nHow you're charged \n\nIBM Cloud\u00ae charges vary depending on the resources that are used by a particular service, runtime, container, or support option. The resources can be the number of API calls, the number of instances, memory, or storage. In addition, tiered pricing is offered in simple, graduated, or block.\n\nIBM Cloud provides detailed [cost estimators](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost) to help you plan for charges.\n\nAfter you build your resources, you can check the actual cost. In the IBM Cloud\u00ae console, go to Manage > Billing and usage, and select Usage. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization used. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage of the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations. You can see more information about a specific charge from each resource details page.\n\nDifferent types of charges apply depending on the features of IBM Cloud that you're using. The following table provides a high-level overview:\n\n\n\nTable 1. Charges based on features\n\n Type of Charge Description Resource Type Example \n\n Fixed Fixed-rate pricing is based on an agreed upon monthly charge. If you buy an additional bare metal server, virtual server, or storage resource after the start of the monthly billing period, the cost of the resource for the first month is prorated based on the number of days remaining in the billing period. The prorated cost is billed in a separate invoice. Services For Bare Metal Servers, there are fixed plans to choose from, and those plans are charged at a fixed monthly rate. \n Metered Usage is a unit-based pricing model in which you pay for what you consume. In this case, the number of GB hours that are consumed for runtimes and the number of IP addresses and storage that is consumed for containers. Services, Compute, and Containers For Push Notifications, any usage that is consumed over the free monthly allowance of 100,000 digital messages per month, will be charged.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-charges"}, {"document_id": "ibmcld_16727-1064600-1066235", "score": 38.14656761461609, "text": "\n* How do I add a new commitment?\n\nContact your [IBM Cloud Sales](https://www.ibm.com/cloud?contactmodule) representative to add a new commitment to your account.\n* Why am I getting invoiced for a commitment I didn\u2019t use?\n\nSince you committed to a certain amount for a certain period of time and you didn't reach it, IBM Cloud\u00ae have the rights to charge you with the remaining amount.\n* Can I convert my US-based USD Pay-As-You-Go to a Subscription account? If so, what kind of impact does the commitment model have?\n\nYes, you can convert your account from US-based USD Pay-As-You-Go to an Enterprise Savings Plan, but it will be only effective after the term end of your former plan.\n* Where can I access my invoice?\n\nIf you have a billable account, you can access your invoice by clicking Manage > Billing and usage, and selecting Invoices. If you have a Lite account, you don't have an invoice because you're never charged for Lite plan usage.\n\nYou might be redirected to [IBM Invoices website](https://www.ibm.com/invoices). See [How do I view invoices for Pay-As-You-Go or Subscription accounts?](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-ts_cant-view-invoice) and [Viewing your invoices](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-managing-invoices) for more information.\n* Why does my usage not match my invoice?\n\nYour usage might not match your invoice because the months that are used to compare usage aren't the same, or the total amount of the orgs wasn't selected. For more information, see [Viewing your usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-viewingusage).", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03776-3313-5682", "score": 37.98654217406077, "text": "\nWhen you have a Subscription account, you buy a subscription for an amount of credit to spend on resource usage within a certain time period. In exchange for this spending commitment, you get a discount on your usage costs. For example, you might buy a subscription for $12,000 USD a year that comes with a 10% discount. No matter when you incur usage costs within that year, you get fixed billing for the subscription amount, such as $1,000 a month. This account type is a good fit for enterprise organizations with large cloud workloads that want the predictability of fixed billing for their financial planning.\n\nIn addition to the two billable account types, customers that have a Subscription account can sign up for the Enterprise Savings Plan billing model. This billing model is similar to a Subscription account with a few added benefits. The following table details the two billable account types and billing model.\n\n\n\nTable 1. Comparative analysis of account types\n\n Pay-As-You-Go Subscription Enterprise Savings Plan \n\n Monthly billing Timely billing Timely billing \n Invoiced on monthly consumption Invoices independent of usage Invoiced on monthly consumption \n Best suited for developers and companies Best suited for enterprise organizations Best suited for both developers and enterprise organizations \n\n\n\n\n\n Estimating your costs \n\nAfter you select the type of account that fits your organization's needs, it's time to understand how you will be charged for it. With an IBM Cloud billable account, you're charged for the compute, containers, and services that your organization consumes. You might be invited by other IBM Cloud users to participate in organizations under a different account. The usage for the apps or services that you use in the organizations that you're invited to are charged to the account that contains those organizations.\n\nThe following are the various charging types:\n\n\n\n* Fixed: Fixed-rate pricing is based on an agreed upon monthly charge that isn't adjusted.\n* Metered: Metered-usage pricing is based on the number of GB hours that are consumed for runtimes and the number of IP addresses and storage for containers.\n* Tiered: Some pricing plans are based on a tiered pricing model, so you can get a volume-based discount according to your actual usage. Services might offer simple, graduated, or block tier pricing plans.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-overview"}, {"document_id": "ibmcld_03798-0-2240", "score": 37.957478742524216, "text": "\n\n\n\n\n\n\n  Understanding my invoice \n\nBillable accounts receive a monthly invoice for the usage charges and other fees that are incurred. At any time, you can view your invoice or expected invoiced charges by going to the [Invoices](https://cloud.ibm.com/billing/invoices) page from the billing and usage dashboard in the IBM Cloud\u00ae console.\n\nIf your account is billed through a separate billing platform, you can see the following message on the Invoices page:\n\nThe account is invoiced on a separate billing platform. This page reflects only classic infrastructure charges. To view your official invoice and for any pricing inquiries, visit IBM Invoices. To sign up and view your invoices, you must provide your IBM customer number. If you don't know your customer number, contact IBM Cloud Support by calling 1-866-325-0045 and selecting the third option.\n\nIn this situation, go to [Invoices@IBM](http://ibm.com/invoices) to review your upcoming invoice, past invoices, or details about service charges.\n\n\n\n  Invoicing for different account types \n\nDepending on your account type, your usage is incurred and reflected differently on your invoice. Review the following differences for billing based on your account type:\n\n\n\n*  Subscription: The billed interval is contractual and depends on a negotiated payment for usage credits.\n*  Pay-As-You-Go: An estimation of your charges is found on the [Usage](https://cloud.ibm.com/billing/usage) page. Charges from platform and classic infrastructure services are included if your account uses both types. Infrastructure as a Service (IaaS) charges aren't included.\n\n\n\nThird-party services, such as SendGrid, don't bill for their service through IBM Cloud if you signed up for their service outside of IBM Cloud.\n\nAn IBM Cloud service might provide a free allocation before the start of your billing period. To determine whether your service instance provides a free allocation, go to the [Resources list](https://cloud.ibm.com/resources) in the IBM Cloud console. Click the service name, and then click Plan. Review the feature description for each plan to see whether the service offers free allocations. Free allocations are applied to the account level and not the organization level.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-understand-invoices"}, {"document_id": "ibmcld_08474-1435-3113", "score": 37.886777759310874, "text": "\nOperational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4 \n\n\n\n\n\n\n\n How am I charged for my use of Hyper Protect Crypto Services with Unified Key Orchestrator? \n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. After you connect to an external keystore of any type, the Unified Key Orchestrator base price of $5.00 USD/hour is charged.\n\nThe first 5 internal keystores and the very first external keystore are free of charge. Each additional internal or external keystore is charged with a tiered pricing starting at $225 USD or $70 USD per month, respectively. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https://cloud.ibm.com/catalog/services/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units in the service instance, and creates 22 internal keystores and 15 external keystores. The first 5 internal keystores and the first external keystore are free of charge.\n\n\n\nTable 2. A Unified Key Orchestrator billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n 22 internal keystores $3795 (5x0+15x225+2x210) \n 15 external keystores $980 (1x0+14x70) \n Unified Key Orchestrator connection $3600 (30x24x5.00) \n Total charge $11442.2", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-faq-pricing"}, {"document_id": "ibmcld_08474-7-1664", "score": 37.79552760739525, "text": "\nFAQs: Pricing \n\nRead to get answers for questions about IBM Cloud\u00ae Hyper Protect Crypto Services pricing.\n\n\n\n How am I charged for my use of Hyper Protect Crypto Services standard plan? \n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. If you also enable [failover crypto units](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-understand-conceptscrypto-unit-concept), each failover crypto unit is also charged the same as the operational crypto unit.\n\nThe first 5 keystores, including KMS key rings and EP11 keystores, are free of charge. Each additional key ring or EP11 keystore is charged with a tiered pricing starting at $225 USD per month. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https://cloud.ibm.com/catalog/services/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours) \n\n Operational crypto unit 1 $1533.6 (30x24x2.13) \n Operational crypto unit 2 $1533.6 (30x24x2.13) \n Failover crypto unit 1 $1533.6 (30x24x2.13) \n Failover crypto unit 2 $1533.6 (30x24x2.13) \n 10 KMS key rings and 12 GREP11 keystores $3795 (5x0+15x225+2x210) \n Total charge $9929.4", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-faq-pricing"}, {"document_id": "ibmcld_12746-0-1760", "score": 37.73702970856421, "text": "\n\n\n\n\n\n\n  How does Security and Compliance Center calculate pricing? \n\nPricing for IBM Cloud\u00ae Security and Compliance Center is based on the number of evaluations performed. An evaluation is the check of one assessment against one resource.\n\nFor the most up-to-date pricing information, you can create a cost estimate by clicking Add to estimate from either the [provisioning](https://cloud.ibm.com/security-compliance/catalog) or [plan page](https://cloud.ibm.com/security-compliance/plan).\n\n\n\n  Plan types \n\nThe service offers two pricing plans.\n\nTrial\n:   To try out the service, you can enroll in a Trial period where you have access the full capabilities of the Posture Management component for 30 days at no charge. You can create profiles, set up credentials, and configure your account to evaluate your resources, among other things. Each account can have 1 instance of the trial service for the lifetime of the account.\n\nStandard\n:   With a Standard plan, you are able to access the full capabilities of the service without limitations. However, you are charged per evaluation.\n\n\n\n\n\n  When am I charged? \n\nYou are charged if an evaluation produces a result of pass or fail. You are not charged for the evaluation if the check cannot be performed or is not applicable. Each scan that is run provides you with the number of billable evaluations in the results UI.\n\n\n\n\n\n  How do I stop getting charged for Security and Compliance Center? \n\nYou are charged when an evaluation takes place. If you no longer want to be charged for a specific evaluation, stop the scan or scans that you do not want to be charged for from running by deleting your attachment. This does not remove your historical results, but it does stop future scans from being run.\n\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-scc-pricing"}, {"document_id": "ibmcld_07578-1181831-1183629", "score": 36.590902244418366, "text": "\n* Can I add or remove crypto units after I provision a service instance?\n\nYes, you can request to add or remove crypto units by raising support tickets in the IBM Cloud\u00ae Support Center. For detailed instructions, see [Adding or removing crypto units](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-add-remove-crypto-units).\n* Is there a Service Level Agreement (SLA) specifically for Hyper Protect Crypto Services?\n\nYes, you can find the [SLA](https://www-03.ibm.com/software/sla/sladb.nsf/sla/bm-8506-01) for detailed terms.\n* How am I charged for my use of Hyper Protect Crypto Services standard plan?\n\nEach provisioned operational crypto unit is charged $2.13 USD per hour. If you also enable [failover crypto units](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-understand-conceptscrypto-unit-concept), each failover crypto unit is also charged the same as the operational crypto unit.\n\nThe first 5 keystores, including KMS key rings and EP11 keystores, are free of charge. Each additional key ring or EP11 keystore is charged with a tiered pricing starting at $225 USD per month. For keystores that are created or connected less than a month, the cost is prorated based on actual days within the month.\n\nThe detailed [pricing plan](https://cloud.ibm.com/catalog/services/hyper-protect-crypto-services) is available for your reference.\n\nThe following example shows a total charge of 30 days (720 hours). The user enables two operational crypto units and two failover crypto units for cross-region high availability. The user also creates 10 KMS keystores and 12 GREP11 keystores. The first five keystores, including both KMS key rings and GREP11 keystores, are free of charge.\n\n\n\nTable 1. A standard plan billing example of 30 days\n\n Pricing components Cost for 30 days (720 hours)", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "4175fcce99c56af0e02be5b8990fc16a<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-891912-893651", "score": 18.564073283868513, "text": "\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https://www.ibm.com/cloud/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-891789-893528", "score": 18.564073283868513, "text": "\nThe first snapshot is a full backup of the volume. Subsequent snapshots of the same volume capture only the changes since the last snapshot. For more information, see [About Block Storage for VPC Snapshots for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-about).\n* What is a backup snapshot?\n\n What is a backup snapshot? \n\nBackup snapshots, simply called \"backups\", are snapshots that are automatically created by the Backup for VPC service. For more information, see [About Backup for VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about).\n* What can I do about data backups for disaster recovery?\n\n What can I do about data backups for disaster recovery? \n\nBlock Storage for VPC secures your data across redundant fault zones in your region. By using the [backup service](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about), you can regularly back up your volume data based on a schedule that you set up. You can create backup snapshots as frequently as 1 hour. However, the backup service does not provide continual backup with automatic failover, and restoring a volume from a backup or snapshot is a manual operation that takes time. If you require a higher level of service for automatic disaster recovery, see IBM's [Cloud disaster recovery solutions](https://www.ibm.com/cloud/disaster-recovery).\n* What is restoring a volume from a snapshot?\n\n What is restoring a volume from a snapshot? \n\nRestoring from a snapshot creates a new, fully provisioned boot or data volume. You can restore storage volumes during instance creation, instance modification, or when you provision a new stand-alone volume. For data volumes, you can also use the volumes API to create a data volume from a snapshot.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_14984-13428-15314", "score": 18.524462336190325, "text": "\nThe instance must be in a Running state.\n3. On the Instance details page, scroll to the list of Storage volumes and click Attach volumes. A side panel opens for you to define the volume attachment.\n4. From the Attach data volume panel, expand the list of Block volumes, and select Create a data volume.\n5. Select Import from snapshot. Expand the Snapshot list and select a backup snapshot.\n6. Optionally, increase the size of the volume within the specified range.\n7. Click Save. The side panel closes and messages indicate that the restored volume is being attached to the instance.\n\n\n\nThe new volume appears in the list of Storage volumes. Hover over the camera icon to see the name of the backup snapshot from which it was created.\n\n\n\n\n\n\n\n Restoring a volume from a snapshot from the CLI \n\nUse the CLI to create a boot or data volume from a backup snapshot. The commands are the same as the ones that are used to restore a volume from a manually created snapshot. For more information, see [Restore a volume from a snapshot with the CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-restore&interface=clisnapshots-vpc-restore-CLI).\n\nFor more information about all backup service commands, see the [VPC CLI reference](https://cloud.ibm.com/docs/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference).\n\n\n\n\n\n Restoring a volume from a backup snapshot with the API \n\nYou can restore boot and data volumes from a backup snapshot with the VPC API. To begin, make a GET /snapshots request to see a list of snapshots. You can filter by resource group and source volume ID in the request.\n\n\n\n* To restore a boot volume from a bootable backup snapshot, specify the boot volume attachment and snapshot ID in the POST /instances request.\n* To restore a data volume from a backup snapshot and attach it, specify the data volume attachment and snapshot ID in the POST /instances request.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore"}, {"document_id": "ibmcld_14996-13519-15405", "score": 18.524462336190325, "text": "\nThe instance must be in a Running state.\n3. On the Instance details page, scroll to the list of Storage volumes and click Attach volumes. A side panel opens for you to define the volume attachment.\n4. From the Attach data volume panel, expand the list of Block volumes, and select Create a data volume.\n5. Select Import from snapshot. Expand the Snapshot list and select a backup snapshot.\n6. Optionally, increase the size of the volume within the specified range.\n7. Click Save. The side panel closes and messages indicate that the restored volume is being attached to the instance.\n\n\n\nThe new volume appears in the list of Storage volumes. Hover over the camera icon to see the name of the backup snapshot from which it was created.\n\n\n\n\n\n\n\n Restoring a volume from a snapshot from the CLI \n\nUse the CLI to create a boot or data volume from a backup snapshot. The commands are the same as the ones that are used to restore a volume from a manually created snapshot. For more information, see [Restore a volume from a snapshot with the CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-restore&interface=clisnapshots-vpc-restore-CLI).\n\nFor more information about all backup service commands, see the [VPC CLI reference](https://cloud.ibm.com/docs/vpc?topic=vpc-infrastructure-cli-plugin-vpc-reference).\n\n\n\n\n\n Restoring a volume from a backup snapshot with the API \n\nYou can restore boot and data volumes from a backup snapshot with the VPC API. To begin, make a GET /snapshots request to see a list of snapshots. You can filter by resource group and source volume ID in the request.\n\n\n\n* To restore a boot volume from a bootable backup snapshot, specify the boot volume attachment and snapshot ID in the POST /instances request.\n* To restore a data volume from a backup snapshot and attach it, specify the data volume attachment and snapshot ID in the POST /instances request.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore&interface=ui"}, {"document_id": "ibmcld_14996-2951-4749", "score": 18.469397191852728, "text": "\nYou can restore a volume from a backup snapshot of a boot volume in multiple ways.\n\n\n\n* You can restore a boot volume when you provision an instance to start the new instance.\n* You can restore a boot volume as a stand-alone volume, and use it later to start a new instance. The restoration process starts when the boot volume is attached to the instance.\n\n\n\n\n\n\n\n Restoring from a nonbootable backup \n\nYou can restore a volume from a backup snapshot of a data volume in multiple ways.\n\n\n\n* You can restore a data volume when you provision an instance. During provisioning, you can select a nonbootable backup snapshot to create a data volume hat is then attached to the instance as auxiliary storage.\n* You can restore a data volume when you want to add more storage to an existing instance.\n* You can restore a data volume to create a stand-alone volume, which you can attach to an instance later.\n\n\n\n\n\n\n\n\n\n Restoring a volume from a backup snapshot in the UI \n\nRestoring a volume from a backup snapshot in the UI creates a fully provisioned boot or data volume. You can restore a volume from the list of Block storage snapshots and from the snapshot details page.\n\nYou can restore a volume from a backup snapshot in the following ways.\n\n\n\n* When you [provision an instance](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-vpc-restore-vol-ui), specify a snapshot of a boot or data volume. Data volumes are automatically attached to the instance as auxiliary storage. Use the restored boot volume to start the new instance.\n* From a snapshot of a [previously created volume](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-vpc-create-from-vol-ui). The created volume from snapshot is automatically attached to the instance as auxiliary storage.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore&interface=ui"}, {"document_id": "ibmcld_14984-3011-4697", "score": 18.261098194013712, "text": "\n* You can restore a boot volume when you provision an instance to start the new instance.\n* You can restore a boot volume as a stand-alone volume, and use it later to start a new instance. The restoration process starts when the boot volume is attached to the instance.\n\n\n\n\n\n\n\n Restoring from a nonbootable backup \n\nYou can restore a volume from a backup snapshot of a data volume in multiple ways.\n\n\n\n* You can restore a data volume when you provision an instance. During provisioning, you can select a nonbootable backup snapshot to create a data volume hat is then attached to the instance as auxiliary storage.\n* You can restore a data volume when you want to add more storage to an existing instance.\n* You can restore a data volume to create a stand-alone volume, which you can attach to an instance later.\n\n\n\n\n\n\n\n\n\n Restoring a volume from a backup snapshot in the UI \n\nRestoring a volume from a backup snapshot in the UI creates a fully provisioned boot or data volume. You can restore a volume from the list of Block storage snapshots and from the snapshot details page.\n\nYou can restore a volume from a backup snapshot in the following ways.\n\n\n\n* When you [provision an instance](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restorebaas-vpc-restore-vol-ui), specify a snapshot of a boot or data volume. Data volumes are automatically attached to the instance as auxiliary storage. Use the restored boot volume to start the new instance.\n* From a snapshot of a [previously created volume](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restorebaas-vpc-create-from-vol-ui). The created volume from snapshot is automatically attached to the instance as auxiliary storage.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore"}, {"document_id": "ibmcld_15034-3931-5816", "score": 18.254223909504887, "text": "\nWhen you restore a volume from a snapshot, and the tags that are applied to the new volume match the tags in a backup policy, the new volume is backed up. But you can't directly back up a snapshot that has tags in a backup policy.\n\n\n\n\n\n How long are backups retained? \n\nYou can specify that backups be kept 1 - 30 days (default). The retention period can't be shorter than the backup frequency or it returns an error.\n\nYou can also specify the number of backups to retain, up to 750 per volume, after which the oldest backups are deleted.\n\n\n\n\n\n Are there limitations on how many backups I can take? \n\nYes. You can create 10 backup policies per account and up to 750 backups of a volume. For other limitations of this release, see [Limitations in this release](https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about&interface=uibackup-service-limitations).\n\n\n\n\n\n How do I create a new volume from a backup? \n\nRestoring from a backup snapshot creates a volume with data from the snapshot. You can restore data from a backup by using the UI, the CLI, or the API. You can restore boot and data volumes during instance creation, when you modify an existing instance, or when you provision a stand-alone volume. When you restore data from a backup snapshot, the data is pulled from an Object Storage bucket. For best performance, you can enable backup snapshots for fast restore. By using the fast restore feature, you can restore a volume that is fully provisioned when the volume is created. When you use fast restore, the data is pulled from a cached backup snapshot in another zone of your VPC. For more information, see [About restoring from a backup snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Am I charged for usage? \n\nYes. Cost for backups is calculated based on GB capacity that is stored per month, unless the duration is less than one month.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-vpc-faq"}, {"document_id": "ibmcld_15007-13930-15825", "score": 18.191442171313405, "text": "\nRestoring from a bootable snapshot is slower than using a regular boot volume.\n\nWhile the creation of the backup requires the volumes to be attached to a running virtual server instance, you can also restore a data volume from a snapshot of an unattached volume. Backups, like snapshots, have a lifecycle that is independent from the source Block Storage for VPC volume.\n\nThe restored volume has the same capacity and IOPS tier profile as the original volume. For more information, see [Restoring a volume from a backup snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Restoring a volume by using fast restore \n\nWhen you restore a volume by using fast restore, a fully hydrated volume is created.\n\nYou can create a [backup policy plan](https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=uibackup-plan-ui) with fast restore zones, and add or remove zones later as needed. The fast restore feature caches one or more copies of a backup snapshot to the zones that you selected. Later, you can use these backup clones to create volumes in any zone within the same region.\n\nFor more information, see [Restoring a volume from a backup snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Cross-regional backup copies \n\nNew\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. You can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about"}, {"document_id": "ibmcld_15020-13969-15864", "score": 18.191442171313405, "text": "\nRestoring from a bootable snapshot is slower than using a regular boot volume.\n\nWhile the creation of the backup requires the volumes to be attached to a running virtual server instance, you can also restore a data volume from a snapshot of an unattached volume. Backups, like snapshots, have a lifecycle that is independent from the source Block Storage for VPC volume.\n\nThe restored volume has the same capacity and IOPS tier profile as the original volume. For more information, see [Restoring a volume from a backup snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Restoring a volume by using fast restore \n\nWhen you restore a volume by using fast restore, a fully hydrated volume is created.\n\nYou can create a [backup policy plan](https://cloud.ibm.com/docs/vpc?topic=vpc-create-backup-policy-and-plan&interface=uibackup-plan-ui) with fast restore zones, and add or remove zones later as needed. The fast restore feature caches one or more copies of a backup snapshot to the zones that you selected. Later, you can use these backup clones to create volumes in any zone within the same region.\n\nFor more information, see [Restoring a volume from a backup snapshot](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore).\n\n\n\n\n\n Cross-regional backup copies \n\nNew\n\nYou can copy a backup snapshot from one region to another region, and later use that snapshot to restore a volume in the new region. You can use and manage the cross-regional snapshot in the target region independently from the parent volume or the original snapshot.\n\nIf the source snapshot is not encrypted with a customer key, the encryption of the copy remains provider-managed. If the source snapshot is protected by a customer-managed key, you must specify the customer-managed key that you want to use to encrypt the new copy.\n\nOnly one copy of the backup snapshot can exist in each region.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-backup-service-about&interface=ui"}, {"document_id": "ibmcld_14996-1525-3435", "score": 18.185525799158047, "text": "\nAfter the volume is hydrated (fully provisioned), you can use the new boot or data volume. For more information about how performance is affected during restoration, see [Performance impact when backup snapshots are used](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-performance-considerations).\n\nFor best performance, use backups with fast restore. You can enable fast restore backup snapshots in multiple zones and use them to restore a volume that is fully provisioned when the volume is created. The fast restore feature can achieve a\n\nrecovery time objective(RTO) quicker than restoring from a regular backup snapshot. For more information, see [fast restore](https://cloud.ibm.com/docs/vpc?topic=vpc-snapshots-vpc-aboutsnapshots_vpc_fast_restore).\n\nTo restore a volume, the backup snapshot must be in a stable state.\n\nYou can't simultaneously restore a boot and a data volume.\n\n\n\n Restoring from a bootable backup \n\nWhen you restore from a bootable backup snapshot, you create a boot volume that you use to provision another instance. The boot volume uses a general-purpose profile and is limited to 250 GB. Because the bootable backup snapshot is not fully provisioned, in the beginning the performance is slower than when you use a regular boot volume. For more information, see [Performance impact](https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore&interface=uibaas-boot-perf).\n\nYou can restore a volume from a backup snapshot of a boot volume in multiple ways.\n\n\n\n* You can restore a boot volume when you provision an instance to start the new instance.\n* You can restore a boot volume as a stand-alone volume, and use it later to start a new instance. The restoration process starts when the boot volume is attached to the instance.\n\n\n\n\n\n\n\n Restoring from a nonbootable backup \n\nYou can restore a volume from a backup snapshot of a data volume in multiple ways.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-baas-vpc-restore&interface=ui"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00640-1128-2229", "score": 16.899022767218494, "text": "\nCloudant service = Cloudant.newInstance();\n\nAllDocsQuery query1 = new AllDocsQuery.Builder()\n.keys(Arrays.asList(\"small-appliances:1000042\",\n\"small-appliances:1000043\"))\n.build();\n\nAllDocsQuery query2 = new AllDocsQuery.Builder()\n.limit(3)\n.skip(2)\n.build();\n\nPostAllDocsQueriesOptions queriesOptions =\nnew PostAllDocsQueriesOptions.Builder()\n.queries(Arrays.asList(query1, query2))\n.db(\"products\")\n.build();\n\nAllDocsQueriesResult response =\nservice.postAllDocsQueries(queriesOptions).execute()\n.getResult();\n\nSystem.out.println(response);\n\nfrom ibmcloudant.cloudant_v1 import AllDocsQuery, CloudantV1\n\nservice = CloudantV1.new_instance()\n\nall_docs_query1 = AllDocsQuery(\nkeys=['small-appliances:1000042', 'small-appliances:1000043']\n)\n\nall_docs_query2 = AllDocsQuery(\nlimit=3,\nskip=2\n)\n\nresponse = service.post_all_docs_queries(\ndb='products',\nqueries=[all_docs_query1, all_docs_query2]\n).get_result()\n\nprint(response)\n\nallDocsQueries := []cloudantv1.AllDocsQuery{\n{\nKeys: []string{\n\"small-appliances:1000042\",\n\"small-appliances:1000043\",\n},\n},\n{\nLimit: core.Int64Ptr(3),\nSkip: core.Int64Ptr(2),\n},\n}", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-send-multiple-queries-to-a-database"}, {"document_id": "ibmcld_04339-2716-4263", "score": 16.823574417646, "text": "\n\"query\" : 50,\n\"read\" : 1000,\n\"write\" : 500\n}\n}\n}\n\n\n\n\n\n Default JMESPath \n\nA JMESPath query is applied to the output of this command by default. The default JMESPath is:\n\ncurrent.throughput\n\nIf a custom JMESPath query is provided, it will replace the default JMESPath.\n\n\n\n\n\n\n\n ibmcloud cloudant capacity-update \n\nSets the target provisioned throughput capacity for an IBM Cloudant instance. When target capacity is changed, the current capacity asynchronously changes to meet the target capacity.\n\nibmcloud cloudant capacity-update --blocks BLOCKS\n\n\n\n Command options \n\n--blocks (int64)\n: A number of blocks of throughput units. A block consists of 100 reads/sec, 50 writes/sec, and 5 global queries/sec of provisioned throughput capacity. Required.\n\nThe minimum value is 0.\n\n\n\n\n\n Example \n\nExample request\n\nibmcloud cloudant capacity-update --blocks 10\n\n\n\n\n\n Example default output \n\nExample CapacityThroughputInformation response.\n\nblocks\t10\nquery\t50\nread\t1000\nwrite\t500\n\n\n\n\n\n Example full output \n\nExample CapacityThroughputInformation response.\n\n{\n\"current\" : {\n\"throughput\" : {\n\"blocks\" : 5,\n\"query\" : 25,\n\"read\" : 500,\n\"write\" : 250\n}\n},\n\"target\" : {\n\"throughput\" : {\n\"blocks\" : 10,\n\"query\" : 50,\n\"read\" : 1000,\n\"write\" : 500\n}\n}\n}\n\n\n\n\n\n Default JMESPath \n\nA JMESPath query is applied to the output of this command by default. The default JMESPath is:\n\ntarget.throughput\n\nIf a custom JMESPath query is provided, it will replace the default JMESPath.\n\n\n\n\n\n\n\n\n\n Monitoring \n\nCommands for Monitoring resource.\n\n\n\n ibmcloud cloudant events-config", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cloudant-cli"}, {"document_id": "ibmcld_04339-5327-6381", "score": 16.738755830489367, "text": "\nRequired.\n\nAllowable list items are: management, data. The minimum length is 1 item.\n\n\n\n\n\n Example \n\nExample request\n\nibmcloud cloudant events-config-update --types management,data\n\n\n\n\n\n Example output \n\nExample Ok response.\n\n{\n\"ok\" : true\n}\n\n\n\n\n\n\n\n ibmcloud cloudant throughput \n\nView the current consumption of provisioned throughput capacity for an IBM Cloudant instance. The current consumption shows the quantities of reads, writes, and global queries conducted against the instance for a given second.\n\nibmcloud cloudant throughput\n\n\n\n Example \n\nExample request\n\nibmcloud cloudant throughput\n\n\n\n\n\n Example default output \n\nExample CurrentThroughputInformation response.\n\nquery\t13\nread\t133\nwrite\t42\n\n\n\n\n\n Example full output \n\nExample CurrentThroughputInformation response.\n\n{\n\"throughput\" : {\n\"query\" : 13,\n\"read\" : 133,\n\"write\" : 42\n}\n}\n\n\n\n\n\n Default JMESPath \n\nA JMESPath query is applied to the output of this command by default. The default JMESPath is:\n\nthroughput\n\nIf a custom JMESPath query is provided, it will replace the default JMESPath.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-cloudant-cli"}, {"document_id": "ibmcld_00522-3956-5681", "score": 16.70130924907783, "text": "\nCopy and paste the following index definition:\n\n{\n\"index\": {\n\"fields\": [\n\"publisher\", \"year\"\n]\n},\n\"name\": \"publisher-year-index\",indexingdashboard5\n\"type\": \"json\"\n}\n\nSee an example in the following screen capture:\n\nZoom\n\n![Click Create index to create an index.](https://cloud.ibm.com/docs-content/v1/content/522c6f62358b063f921283400a601c3f9bc66f08/Cloudant/images/indexingdashboard2.png)\n\nFigure 2. Window for creating indexes\n\n\n\nThe fields array contains a list of fields that we want IBM Cloudant to index.\n\nIf we repeat our query, it is faster and remains quick even as the database size reaches millions of documents.\n\nIndexing instructs IBM Cloudant to create a secondary data structure that allows it to find the slice of data you need much faster than looking over every document in turn. IBM Cloudant Query is best for fixed queries based on the same fields in the same order.\n\nFor more information, see the following details in IBM Cloudant documentation:\n\n\n\n* [Optimizing IBM Cloudant Queries](https://blog.cloudant.com/2020/04/24/Optimising-Cloudant-Queries.html)\n* [IBM Cloudant Query documentation](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-query)\n\n\n\nThis index is useful for queries that involve both the publisher and the year, but if we introduce another field or make the query more complex (for example, by using the $or operator), then the index doesn't get used. We are back to a full database scan.\n\nFor a general-purpose search facility, we need IBM Cloudant Search, which is described in the next section.\n\n\n\n\n\n\n\n Step 3. Creating a search engine - IBM Cloudant Search \n\nIBM Cloudant Search is based on Apache Lucene and has its own query language that allows rich queries to be constructed.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-dig-deeper-dashboard"}, {"document_id": "ibmcld_00640-7-1376", "score": 16.632643380144323, "text": "\nSending multiple queries to a database \n\nNow, the following instructions describe how to send multiple queries to a database by using _all_docs and _view endpoints.\n\n\n\n Sending multiple queries to a database by using _all_docs \n\nTo send multiple queries to a specific database, send a POST request to https://$ACCOUNT.cloudant.com/$DATABASE/_all_docs/queries.\n\nSee the following example that uses HTTP to send multiple queries to a database:\n\nPOST /$DATABASE/_all_docs/queries HTTP/1.1\n\nSee the following example to multi-query the list of all documents in a database:\n\n\n\n* Curl\n* Java\n* Python\n* Go\n* Node\n\n\n\ncurl -H \"Authorization: Bearer $API_BEARER_TOKEN\" -X POST \"$SERVICE_URL/products/_all_docs/queries\" -H \"Content-Type: application/json\" --data '{\n\"queries\": [\n{\n\"keys\":\n\"small-appliances:1000042\",\n\"small-appliances:1000043\"\n]\n},\n{\n\"limit\": 3,\n\"skip\": 2\n}\n]\n}'\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsQuery;\nimport com.ibm.cloud.cloudant.v1.model.AllDocsQueriesResult;\nimport com.ibm.cloud.cloudant.v1.model.PostAllDocsQueriesOptions;\n\nimport java.util.Arrays;\n\nCloudant service = Cloudant.newInstance();\n\nAllDocsQuery query1 = new AllDocsQuery.Builder()\n.keys(Arrays.asList(\"small-appliances:1000042\",\n\"small-appliances:1000043\"))\n.build();\n\nAllDocsQuery query2 = new AllDocsQuery.Builder()\n.limit(3)\n.skip(2)", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-send-multiple-queries-to-a-database"}, {"document_id": "ibmcld_00579-2977-4822", "score": 16.53410390371076, "text": "\n* IBM Cloudant guide to using [views](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-using-viewsusing-views)\n* Performance implications of using [include_docs](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-using-viewsmulti-document-fetching)\n\n\n\n\n\n\n\n Never rely on the default behavior of IBM Cloudant Query\u2019s no-indexing \n\nIt\u2019s tempting to rely on IBM Cloudant Query's ability to query without creating explicit indexes. This practice is costly in terms of performance, as every lookup is a full scan of the database rather than an indexed lookup. If your data is small, this full-scan lookup doesn\u2019t matter, but as the data set grows, performance becomes a problem for you, and for the cluster as a whole. It is likely that we will limit this facility soon. The IBM Cloudant Dashboard provides a method for creating indexes in an easy way.\n\nCreating indexes and crafting IBM Cloudant Queries that take advantage of them requires some flair. To identify which index is being used by a particular query, send a POST to the _explain endpoint for the database, with the query as data.\n\nFor more information, see [IBM Cloudant Query docs](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-query).\n\n\n\n\n\n In IBM Cloudant Search (or IBM Cloudant Query indexes of type text), limit the number of fields \n\nIBM Cloudant Search and IBM Cloudant Query indexes of type text (both of which are Apache Lucene under the hood) provide you with a way to index any number of fields into the index. Some examples exist where this type of indexing is abused either deliberately, or mostly by mistake. Plan your indexing to comprise only the fields required by your actual queries. Indexes take up space and can be costly to rebuild if the number of indexed fields are large.\n\nWe also have the issue of which fields that you store in an IBM Cloudant Search.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-indexing-and-querying"}, {"document_id": "ibmcld_00472-13535-15011", "score": 16.50981517873251, "text": "\nSee the following example that uses the command line to test the standard analyzer:\n\ncurl \"https://$ACCOUNT.cloudant.com/_search_analyze\" -H \"Content-Type: application/json\"\n-d '{\"analyzer\":\"standard\", \"text\":\"ablanks@renovations.com\"}'\n\nSee the following result of testing the standard analyzer:\n\n{\n\"tokens\": [\n\"ablanks\",\n\"renovations.com\"\n]\n}\n\n\n\n\n\n\n\n Queries \n\nAfter you create a search index, you can query it.\n\n\n\n* Run a partition query by using the following request:\n\nGET /$DATABASE/_partition/$PARTITION_KEY/_design/$DDOC/_search/$INDEX_NAME\n* Run a global query by using the following request:\n\nGET /$DATABASE/_design/$DDOC/_search/$INDEX_NAME\n\n\n\nSpecify your search by using the query parameter.\n\nSee the following example that uses HTTP to query a partitioned index:\n\nGET /$DATABASE/_partition/$PARTITION_KEY/_design/$DDOC/_search/$INDEX_NAME?include_docs=true&query=\":\"&limit=1 HTTP/1.1\nContent-Type: application/json\nHost: $ACCOUNT.cloudant.com\n\nSee the following example that uses the command line to query a partitioned index:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl \"https://$ACCOUNT.cloudant.com/$DATABASE/_partition/$PARTITION_KEY/_design/$DDOC/_search/$INDEX_NAME?include_docs=true&query=\":\"&limit=1\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.PostPartitionSearchOptions;\nimport com.ibm.cloud.cloudant.v1.model.SearchResult;\n\nCloudant service = Cloudant.newInstance();\n\nPostPartitionSearchOptions searchOptions =", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-cloudant-search"}, {"document_id": "ibmcld_00539-7-1755", "score": 16.327925539447893, "text": "\nUsing IBM Cloudant Query FAQ \n\n[IBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae Query](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-query) is an API for querying slices of data based on the values of a database's document attributes. It is a flexible API that must be used carefully to ensure that database performance can be maintained as the data size grows over time.\n\n\n\n How do I use IBM Cloudant Query? \n\nIBM Cloudant Query is accessed through the [POST /{db}/_find](https://cloud.ibm.com/apidocs/cloudantpostfind) API endpoint where the JSON specification of the query is passed in the HTTP POST body. For example, this query finds up to 10 documents where the firstname is \"Charles\" and the surname is \"Dickens\":\n\n{\n\"selector\": {\n\"firstname\": \"Charles\",\n\"surname\": \"Dickens\"\n},\n\"limit\": 10\n}\n\nFor more information, see [Selector Syntax](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-queryselector-syntax).\n\n\n\n\n\n How do I create an index to support an IBM Cloudant Query? \n\nWithout a suitable secondary index, IBM Cloudant Query scans each document in the database in turn until it has enough matches to satisfy the query. The larger the data set and the more documents it has to scan to find matching documents, the slower the response time. For faster performance, an IBM Cloudant Query _find must be backed by a suitable secondary index. A secondary index is a pre-calculated data structure that allows IBM Cloudant to quickly jump to the slice of data it needs without scanning irrelevant documents. For the surname fields, we call the [POST /{db}/_index](https://cloud.ibm.com/apidocs/cloudantpostindex) endpoint to pass the JSON index definition as the HTTP POST body:\n\n{\n\"index\": {\n\"fields\": [\"firstname\", \"surname\"]\n},\n\"ddoc\": \"jsonindexes\",", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-faq-using-cloudant-query"}, {"document_id": "ibmcld_00472-16393-17597", "score": 16.244620126444076, "text": "\n\"github.com/IBM/cloudant-go-sdk/cloudantv1\"\n)\n\nSee the following example that uses HTTP to query a global index:\n\nGET /$DATABASE/_design/$DDOC/_search/$INDEX_NAME?include_docs=true&query=\":\"&limit=1 HTTP/1.1\nContent-Type: application/json\nHost: $ACCOUNT.cloudant.com\n\nSee the following example that uses the command line to query a global index:\n\n\n\n* Curl\n* Java\n* Node\n* Python\n* Go\n\n\n\ncurl \"https://$ACCOUNT.cloudant.com/$DATABASE/_design/$DDOC/_search/$INDEX_NAME?include_docs=true&query=\":\"&limit=1\"\n\nimport com.ibm.cloud.cloudant.v1.Cloudant;\nimport com.ibm.cloud.cloudant.v1.model.PostSearchOptions;\nimport com.ibm.cloud.cloudant.v1.model.SearchResult;\n\nCloudant service = Cloudant.newInstance();\n\nPostSearchOptions searchOptions = new PostSearchOptions.Builder()\n.db(\"<db-name>\")\n.ddoc(\"<ddoc>\")\n.index(\"<index-name>\")\n.query(\":\")\n.includeDocs(true)\n.limit(1)\n.build();\n\nSearchResult response =\nservice.postSearch(searchOptions).execute()\n.getResult();\n\nSystem.out.println(response);\n\nimport { CloudantV1 } from '@ibm-cloud/cloudant';\n\nconst service = CloudantV1.newInstance({});\n\nservice.postSearch({\ndb: '<db-name>',\nddoc: '<ddoc>',\nindex: '<index-name>',\nquery: ':',\nincludeDocs: true,\nlimit: 1", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-cloudant-search"}, {"document_id": "ibmcld_00491-1283-3050", "score": 16.23293906390619, "text": "\n(Optional) [Create an acurl alias](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-working-with-curlencode-user-name-and-password).\n\n\n\nIf you decide not to set up acurl, use the following URL with curl instead of the one provided in the exercises, curl \"https://$USERNAME:$PASSWORD@$ACCOUNT.cloudant.com/databasedemo\".\n\nThe acurl alias is more secure. It prevents someone from reading your password over your shoulder as you type. It also makes sure that your password isn\u2019t sent in plain text over the network by enforcing HTTPS.\n\nNow, we're ready to learn how to run queries against the database you created in step two of [Before you begin](https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-querybefore-you-begin-qt).\n\n\n\n\n\n Step 1: Creating an index \n\nIBM Cloudant Query uses Mongo-style query syntax to search for documents by using logical operators. IBM Cloudant Query is a combination of a view and a search index.\n\nWhen you use IBM Cloudant Query, the query planner looks at the selector (your query) to determine the correct index to choose from. In memory, you filter out the documents by the selector, which is why, even without an index, you can still query with various fields.\n\nIf no available defined index matches the specified query, then IBM Cloudant uses the _all_docs index, which looks up documents by ID. In the worst case scenario, it returns all the documents by ID (full table scan). Full table scans are expensive to process. It is recommended that you create an index.\n\nTo create an index, follow these steps:\n\n\n\n1. Copy the following sample JSON data into a file named query-demo-index.json:\n\n{\n\"index\": {\n\"fields\": [\n\"descriptionField\",\n\"temperatureField\"\n],\n\"partial_filter_selector\": {\n\"descriptionField\": {", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-creating-an-ibm-cloudant-query"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02361-24500-26305", "score": 11.897413026112856, "text": "\n[Information about Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-adoption"}, {"document_id": "ibmcld_05138-7979-9034", "score": 11.854294711932964, "text": "\nAfter your bucket is created with Activity Tracker and Monitoring, it may take a few minutes for the rules to take effect.\n\nYou are now ready to store data in a secure content store with encryption, monitoring, and audit observability!\n\n\n\n\n\n Get started by uploading data \n\n\n\n* See [uploading data](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-upload) for more information.\n\n\n\n\n\n\n\n Add capabilities \n\nAdd capabilities to protect objects from ransomware and accidental deletion such as [versioning](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-versioning) and [immutable retention polices](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-ol-overview) for supporting immutable storage, and immutable backup and archive data.\n\n\n\n\n\n Library of Object Storage tutorials \n\nCheck out the IBM Cloud Tutorials library for more tutorials when deploying solutions with [Cloud Object Storage](https://cloud.ibm.com/docs?tab=tutorials&page=1&pageSize=20&tags=cloud-object-storage).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-secure-content-store"}, {"document_id": "ibmcld_04866-4961-6763", "score": 11.748010478015663, "text": "\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https://www.ecfr.gov/cgi-bin/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https://www.finra.org/rules-guidance/rulebooks/finra-rules/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-4961-6763", "score": 11.748010478015663, "text": "\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https://www.ecfr.gov/cgi-bin/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https://www.finra.org/rules-guidance/rulebooks/finra-rules/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_14704-7-1976", "score": 11.73251960540956, "text": "\nImmutable backup solution architecture \n\nThe immutable backup solution architecture is suitable for clients who want to extend their VMware vCenter Server\u00ae instance with the Veeam\u00ae service to use immutable storage and minimize costs. The immutable backup solution architecture does not preclude any of the vCenter Server options such as Caveonix, Entrust, and VMware Aria\u00ae Operations\u2122.\n\nThe solution architecture is enabled by the following key technologies:\n\n\n\n* The immutable storage is provided by a Veeam Linux\u00ae hardened repository that is hosted on an IBM Cloud\u00ae bare metal server. For more information, see [Veeam Linux hardened repository](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-lhr).\n* Optionally, if a sandbox is required, the following technologies are used:\n\n\n\n* Veeam vPower NFS service enables a virtual machine (VM) to be started and run directly from the backup file that is hosted in the backup repository.\n* Veeam Instant Restore enables a VM to be started directly from the backup files. Veeam vPower NFS service is used to access the backup files.\n* The Veeam VM Recovery with the restore to new location option, enables a copy of the VM to be started and connected to an isolated network. The backup file is converted to VMDK files and placed in the designated data store.\n* Veeam Secure Restore is only available for Microsoft\u00ae Windows\u00ae VMs. It is an extra option in the VM Recovery workflow that enables the VM to be scanned by antivirus software before you restore the VM. The VMs disks are connected to a mount server and then the antivirus software on the mount server that is used to scan files from the mounted disks.\n* VMware NSX-T\u2122 overlay segments allow the creation of isolated segments onto which copies of the VMs can be attached and isolated from the production VMs.\n* NSX-T distributed firewall provides the required isolation so that only required cybertoolsets can access the copies of the VMs.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-ib"}, {"document_id": "ibmcld_14704-5996-7720", "score": 11.72660258956625, "text": "\nThe immutable backup solution architecture consists of:\n\n\n\n* Linux hardened repository - The hardened repository is one or more IBM Cloud bare metal servers that run a supported Linux OS. The hardened repository is configured as an immutable storage repository. The IBM Cloud bare metal servers are ordered with internal disks and a RAID card to present this directly attached storage to the OS to be used as a backup repository.\n* Optionally, the immutable backup solution architecture can include one or more sandboxes. For more information, see [Veeam technologies used in the sandbox](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sandboxveeam).\n\n\n\nThe solution architecture does not show the components to adhere to the 3-2-1 backup rule. The 3-2-1 rule describes a backup architecture that:\n\n\n\n* 3 - At least three copies of data: production, primary backup, and backup copy\n* 2 - Use of two different types of media\n* 1 - Keep one backup copy offsite\n\n\n\nTo adhere to this rule, consider:\n\n\n\n* Use a Scale-Out-Repository capacity tier to copy data to Cloud Object Storage. Currently, IBM Cloud Object Storage cannot be used by Veeam as an immutable capacity tier.\n* Set up a Veeam backup copy job to transfer the backup to another backup repository hosted in another IBM Cloud data center.\n\n\n\n\n\n Related links \n\n\n\n* [Overview of VMware Solutions](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-solution_overview)\n* [Veeam on bare metal server introduction](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-bms-archi-intro)\n* [Veeam Backup and Replication 12 overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeamvm_overview)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-veeam-cr-sa-ib"}, {"document_id": "ibmcld_09579-7-1886", "score": 11.705439319604762, "text": "\nSetting up On-Premises Location with NetApp ONTAP-SAN storage \n\nTo deploy the ICD enabled by IBM Cloud Satellite service, prepare your Satellite location. Follow these steps to set up IBM Cloud\u2122 Databases (ICD) enabled by IBM Cloud Satellite in an on-premises location.\n\nOn-premises satellite location currently supports only NetApp ONTAP-SAN storage.\n\n\n\n Step 1: Prepare an on-premises Satellite location for IBM Cloud Databases \n\n\n\n Attach extra hosts to the Satellite location \n\nThese additional-attached worker nodes are used to create a service cluster into which the database instances are deployed later. Attach to your Satellite location:\n\n\n\n* Three type 8x32 hosts\n* Three type 32x128 hosts\n\n\n\nYou should also attach an additional three 32x128 hosts to be kept in reserve. While optional, this step is recommended and you will see a notification in the UI until the reserve workers are attached.\n\nTo be assigned to a service cluster, your worker nodes must match these specifications exactly.\n\n\n\n\n\n Create an on-premises Satellite block storage configuration for NetAPP ONTAP-SAN block storage \n\n\n\n Set up NetApp ONTAP-SAN storage \n\nTo set up your NetApp ONTAP-SAN storage (20.07), refer to [Setting up NetApp storage templates](https://cloud.ibm.com/docs/satellite?topic=satellite-config-storage-netapp).\n\n\n\n\n\n Deploy your NetApp ONTAP-SAN Block driver \n\nTo get a list of NetApp-supported templates, use the following command:\n\nibmcloud sat storage templates | grep \"NetApp Ontap\"\n\n\n\n\n\n Create a storage configuration based on your NetApp backend \n\n\n\n* Operator configuration:\n\nibmcloud sat storage config create\n--location ${LOCATION_ID}\n--name ${OPERATORCONFIGNAME}\n--template-name 'netapp-trident'\n--template-version '20.07'\n* SAN configuration:\n\nibmcloud sat storage config create\n--location ${LOCATION_ID}\n--name ${SANCONFIGNAME}\n--template-name 'netapp-ontap-san'", "title": "", "source": "https://cloud.ibm.com/docs/messages-for-rabbitmq?topic=messages-for-rabbitmq-satellite-on-prem"}, {"document_id": "ibmcld_06468-7-1886", "score": 11.705439319604762, "text": "\nSetting up On-Premises Location with NetApp ONTAP-SAN storage \n\nTo deploy the ICD enabled by IBM Cloud Satellite service, prepare your Satellite location. Follow these steps to set up IBM Cloud\u2122 Databases (ICD) enabled by IBM Cloud Satellite in an on-premises location.\n\nOn-premises satellite location currently supports only NetApp ONTAP-SAN storage.\n\n\n\n Step 1: Prepare an on-premises Satellite location for IBM Cloud Databases \n\n\n\n Attach extra hosts to the Satellite location \n\nThese additional-attached worker nodes are used to create a service cluster into which the database instances are deployed later. Attach to your Satellite location:\n\n\n\n* Three type 8x32 hosts\n* Three type 32x128 hosts\n\n\n\nYou should also attach an additional three 32x128 hosts to be kept in reserve. While optional, this step is recommended and you will see a notification in the UI until the reserve workers are attached.\n\nTo be assigned to a service cluster, your worker nodes must match these specifications exactly.\n\n\n\n\n\n Create an on-premises Satellite block storage configuration for NetAPP ONTAP-SAN block storage \n\n\n\n Set up NetApp ONTAP-SAN storage \n\nTo set up your NetApp ONTAP-SAN storage (20.07), refer to [Setting up NetApp storage templates](https://cloud.ibm.com/docs/satellite?topic=satellite-config-storage-netapp).\n\n\n\n\n\n Deploy your NetApp ONTAP-SAN Block driver \n\nTo get a list of NetApp-supported templates, use the following command:\n\nibmcloud sat storage templates | grep \"NetApp Ontap\"\n\n\n\n\n\n Create a storage configuration based on your NetApp backend \n\n\n\n* Operator configuration:\n\nibmcloud sat storage config create\n--location ${LOCATION_ID}\n--name ${OPERATORCONFIGNAME}\n--template-name 'netapp-trident'\n--template-version '20.07'\n* SAN configuration:\n\nibmcloud sat storage config create\n--location ${LOCATION_ID}\n--name ${SANCONFIGNAME}\n--template-name 'netapp-ontap-san'", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-etcd?topic=databases-for-etcd-satellite-on-prem"}, {"document_id": "ibmcld_06660-7-1886", "score": 11.705439319604762, "text": "\nSetting up On-Premises Location with NetApp ONTAP-SAN storage \n\nTo deploy the ICD enabled by IBM Cloud Satellite service, prepare your Satellite location. Follow these steps to set up IBM Cloud\u2122 Databases (ICD) enabled by IBM Cloud Satellite in an on-premises location.\n\nOn-premises satellite location currently supports only NetApp ONTAP-SAN storage.\n\n\n\n Step 1: Prepare an on-premises Satellite location for IBM Cloud Databases \n\n\n\n Attach extra hosts to the Satellite location \n\nThese additional-attached worker nodes are used to create a service cluster into which the database instances are deployed later. Attach to your Satellite location:\n\n\n\n* Three type 8x32 hosts\n* Three type 32x128 hosts\n\n\n\nYou should also attach an additional three 32x128 hosts to be kept in reserve. While optional, this step is recommended and you will see a notification in the UI until the reserve workers are attached.\n\nTo be assigned to a service cluster, your worker nodes must match these specifications exactly.\n\n\n\n\n\n Create an on-premises Satellite block storage configuration for NetAPP ONTAP-SAN block storage \n\n\n\n Set up NetApp ONTAP-SAN storage \n\nTo set up your NetApp ONTAP-SAN storage (20.07), refer to [Setting up NetApp storage templates](https://cloud.ibm.com/docs/satellite?topic=satellite-config-storage-netapp).\n\n\n\n\n\n Deploy your NetApp ONTAP-SAN Block driver \n\nTo get a list of NetApp-supported templates, use the following command:\n\nibmcloud sat storage templates | grep \"NetApp Ontap\"\n\n\n\n\n\n Create a storage configuration based on your NetApp backend \n\n\n\n* Operator configuration:\n\nibmcloud sat storage config create\n--location ${LOCATION_ID}\n--name ${OPERATORCONFIGNAME}\n--template-name 'netapp-trident'\n--template-version '20.07'\n* SAN configuration:\n\nibmcloud sat storage config create\n--location ${LOCATION_ID}\n--name ${SANCONFIGNAME}\n--template-name 'netapp-ontap-san'", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-satellite-on-prem"}, {"document_id": "ibmcld_06722-7-1886", "score": 11.705439319604762, "text": "\nSetting up On-Premises Location with NetApp ONTAP-SAN storage \n\nTo deploy the ICD enabled by IBM Cloud Satellite service, prepare your Satellite location. Follow these steps to set up IBM Cloud\u2122 Databases (ICD) enabled by IBM Cloud Satellite in an on-premises location.\n\nOn-premises satellite location currently supports only NetApp ONTAP-SAN storage.\n\n\n\n Step 1: Prepare an on-premises Satellite location for IBM Cloud Databases \n\n\n\n Attach extra hosts to the Satellite location \n\nThese additional-attached worker nodes are used to create a service cluster into which the database instances are deployed later. Attach to your Satellite location:\n\n\n\n* Three type 8x32 hosts\n* Three type 32x128 hosts\n\n\n\nYou should also attach an additional three 32x128 hosts to be kept in reserve. While optional, this step is recommended and you will see a notification in the UI until the reserve workers are attached.\n\nTo be assigned to a service cluster, your worker nodes must match these specifications exactly.\n\n\n\n\n\n Create an on-premises Satellite block storage configuration for NetAPP ONTAP-SAN block storage \n\n\n\n Set up NetApp ONTAP-SAN storage \n\nTo set up your NetApp ONTAP-SAN storage (20.07), refer to [Setting up NetApp storage templates](https://cloud.ibm.com/docs/satellite?topic=satellite-config-storage-netapp).\n\n\n\n\n\n Deploy your NetApp ONTAP-SAN Block driver \n\nTo get a list of NetApp-supported templates, use the following command:\n\nibmcloud sat storage templates | grep \"NetApp Ontap\"\n\n\n\n\n\n Create a storage configuration based on your NetApp backend \n\n\n\n* Operator configuration:\n\nibmcloud sat storage config create\n--location ${LOCATION_ID}\n--name ${OPERATORCONFIGNAME}\n--template-name 'netapp-trident'\n--template-version '20.07'\n* SAN configuration:\n\nibmcloud sat storage config create\n--location ${LOCATION_ID}\n--name ${SANCONFIGNAME}\n--template-name 'netapp-ontap-san'", "title": "", "source": "https://cloud.ibm.com/docs/databases-for-redis?topic=databases-for-redis-satellite-on-prem"}]}
{"task_id": "2f013337236ea4635ad106813275dab7<::>7", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05138-7979-9034", "score": 21.661425450428784, "text": "\nAfter your bucket is created with Activity Tracker and Monitoring, it may take a few minutes for the rules to take effect.\n\nYou are now ready to store data in a secure content store with encryption, monitoring, and audit observability!\n\n\n\n\n\n Get started by uploading data \n\n\n\n* See [uploading data](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-upload) for more information.\n\n\n\n\n\n\n\n Add capabilities \n\nAdd capabilities to protect objects from ransomware and accidental deletion such as [versioning](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-versioning) and [immutable retention polices](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-ol-overview) for supporting immutable storage, and immutable backup and archive data.\n\n\n\n\n\n Library of Object Storage tutorials \n\nCheck out the IBM Cloud Tutorials library for more tutorials when deploying solutions with [Cloud Object Storage](https://cloud.ibm.com/docs?tab=tutorials&page=1&pageSize=20&tags=cloud-object-storage).", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-secure-content-store"}, {"document_id": "ibmcld_02361-24500-26305", "score": 21.656647048080334, "text": "\n[Information about Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable) \n Expiration policy [3] Do you need automatic deletion of files? [Information about expiration rules](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-expiry) \n Long-term retention policy [4] Do you need to keep data for a long period of time? [Information about archiving COS files for long term storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-archive) \n Encryption of data at-rest with my own key [5] Can I use my own key to encrypt data at-rest? [Information about encryption of data at-rest](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-encryption) \n Data resiliency [6] Do you need to store the data in a specific geographical location? [Information about resiliency](https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-endpoints) \n\n\n\n[1]: Data might sit untouched for long periods of time. For less active workloads, you can create buckets with different storage classes. For example, use the standard storage class for active workloads, where you need to access data at any time.\n\n[2]: You can choose Immutable Object Storage to preserve electronic records and maintain data integrity. When you define a retention policy for a bucket, you are specifying that the data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds. Notice that Immutable Object Storage is available in certain regions only.\n\n[3]: You can use an expiration rule to delete objects automatically after a defined period from the object creation date.", "title": "", "source": "https://cloud.ibm.com/docs/activity-tracker?topic=activity-tracker-adoption"}, {"document_id": "ibmcld_06808-1384-2991", "score": 20.6560379530227, "text": "\n[Learn more](https://cloud.ibm.com/docs/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidencecd-devsecops-cos-bucket-resiliency).\n\n\n\n\n\n Naming your bucket \n\nCloud Object Storage object names consist of the following components:\n\n{NAMESPACE} / {PIPELINE_RUN_ID} / {TYPE} / {FILE_NAME} _ {HASH}\n\n\n\n Examples: \n\nci/48decaa9-9042-498f-b58d-3577e0ac0158/evidences/build-vulnerability-advisor.json_362c06afa88b3f304878f0d0979e834f\n\nci/48decaa9-9042-498f-b58d-3577e0ac0158/artifacts/app-image-va-report.json_b3f30487f0d0979e834f362c06afaaa8\n\nThe name component {NAMESPACE} / {PIPELINE_RUN_ID} / {TYPE} is useful as a prefix when you're looking for collected data from a certain pipeline run.\n\n\n\n\n\n Retention policy \n\nYou can set Cloud Object Storage buckets to enforce a retention policy or period for uploaded objects, otherwise known as [Immutable Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable). Immutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a Write-One-Read-Many (WORM), non-erasable, and non-rewritable manner. You cannot change or delete objects in protected buckets within the retention period, or delete protected buckets with objects themselves until the retention period is over. The policy is enforced until the end of a retention period and the removal of any legal holds.\n\nIt is recommended that teams set a retention policy for the buckets that are used as their evidence locker that stores every object for a minimum of 365 days.\n\n\n\n\n\n\n\n Audit event log", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-cd-devsecops-cos-bucket-evidence"}, {"document_id": "ibmcld_05168-15740-17188", "score": 20.58705425330298, "text": "\nfmt.Println(r)\nfmt.Println(e)\n\n}\n\nShow more\n\nThe typical response is exemplified here.\n\n{\nRules: [{\nFilter: {\n\n},\nID: \"id3\",\nStatus: \"Enabled\",\nTransitions: {\nDays: 5,\nStorageClass: \"GLACIER\"\n}]\n}]\n}\n\n\n\n\n\n Immutable Object Storage \n\nUsers can configure buckets with an Immutable Object Storage policy to prevent objects from being modified or deleted for a defined period of time. The retention period can be specified on a per-object basis, or objects can inherit a default retention period set on the bucket. It is also possible to set open-ended and permanent retention periods. Immutable Object Storage meets the rules set forth by the SEC governing record retention, and IBM Cloud administrators are unable to bypass these restrictions.\n\nNote: Immutable Object Storage does not support Aspera transfers via the SDK to upload objects or directories at this stage.\n\nfunc main() {\n\n// Create Client\nsess := session.Must(session.NewSession())\nclient := s3.New(sess, conf)\n\n// Create a bucket\ninput := &s3.CreateBucketInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\n}\nd, e := client.CreateBucket(input)\nfmt.Println(d) // should print an empty bracket\nfmt.Println(e) // should print <nil>\n\n// PUT BUCKET PROTECTION CONFIGURATION\npInput := &s3.PutBucketProtectionConfigurationInput{\nBucket: aws.String(\"<BUCKET_NAME>\"),\nProtectionConfiguration: &s3.ProtectionConfiguration{\nDefaultRetention: &s3.BucketProtectionDefaultRetention{\nDays: aws.Int64(100),\n},", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-using-go"}, {"document_id": "ibmcld_04866-4961-6763", "score": 20.292728750300938, "text": "\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https://www.ecfr.gov/cgi-bin/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https://www.finra.org/rules-guidance/rulebooks/finra-rules/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05032-4961-6763", "score": 20.292728750300938, "text": "\nPermanent retention can only be enabled at a IBM Cloud Object Storage bucket level with retention policy enabled and users are able to select the permanent retention period option during object uploads. Once enabled, this process can't be reversed and objects uploaded that use a permanent retention period cannot be deleted. It's the responsibility of the users to validate at their end if there's a legitimate need to permanently store objects by using Object Storage buckets with a retention policy.\n\nWhen using Immutable Object Storage, you are responsible for ensuring that your IBM Cloud Account is kept in good standing per IBM Cloud policies and guidelines for as long as the data is subject to a retention policy. Refer to IBM Cloud Service terms for more information.\n\n\n\n\n\n\n\n Immutable Object Storage and considerations for various regulations \n\nWhen using immutable Object Storage, it is the client's responsibility to check for and ensure whether any of the feature capabilities that are discussed can be used to satisfy and comply with the key rules around electronic records storage and retention that is generally governed by:\n\n\n\n* [Securities and Exchange Commission (SEC) Rule 17a-4(f)](https://www.ecfr.gov/cgi-bin/text-idx?SID=b6b7a79d18d000a733725e88d333ddb5&mc=true&node=pt17.4.240&rgn=div5se17.4.240_117a_64),\n* [Financial Industry Regulatory Authority (FINRA) Rule 4511(c)](https://www.finra.org/rules-guidance/rulebooks/finra-rules/4511), and\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04866-6428-8391", "score": 20.243634438229915, "text": "\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https://cloud.ibm.com/docs/cloud-object-storage/images/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_05075-8514-10699", "score": 20.08273657515303, "text": "\nDeleting a versioned object creates a delete marker. The object may appear to be deleted, but if the object is protected it is not possible to delete the protected version. Delete markers themselves are not protected.\n\n\n\n\n\n Replication \n\nObject Lock cannot be used on the source bucket for replication, only on the destination. Objects will be assigned the default retention period.\n\n\n\n\n\n Key Management Systems \n\nProtected objects will be encrypted using the root key of the bucket. When Object Lock is enabled on a bucket, the root key hosted by Key Protect or Hyper Protect Crypto Services is protected from deletion as long as an associated bucket has Object Lock enabled. This prevents crypto shredding of protected objects.\n\n\n\n\n\n Lifecycle configurations \n\nIt is possible to enable lifecycle policies that [archive locked objects](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-archive), but naturally not those that [expire objects](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-expiry) under retention or legal hold (unprotected objects in the bucket can still be expired).\n\n\n\n\n\n Immutable Object Storage \n\nObject Lock is an alternative to the retention policies available when using Immutable Object Storage. As Object Lock requires versioning to be enabled, and Immutable Object Storage is not compatible with versioning, it is not possible to have both WORM solutions enabled on the same bucket. It is possible to have a mix of buckets in a Service Instance, each using either Immutable Object Storage or Object Lock.\n\n\n\n\n\n Object Tagging \n\nThere are no restrictions on adding or modifying tags on a protected object.\n\n\n\n\n\n Other interactions \n\nThere should be no adverse interactions when using Object Lock with other Object Storage features, such as setting CORS policies, setting IP firewalls or condition based restrictions, bucket quotas, or Code Engine.\n\n\n\n\n\n\n\n IAM actions \n\nThere are new IAM actions associated with Object Lock.\n\n\n\n IAM Action Role \n\n cloud-object-storage.bucket.get_object_lock_configuration Manager, Writer, Reader \n cloud-object-storage.bucket.put_object_lock_configuration Manager, Writer", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-ol-overview"}, {"document_id": "ibmcld_05032-6428-8442", "score": 20.050440344056046, "text": "\n* [Commodity Futures Trading Commission (CFTC) Rule 1.31(c)-(d)](https://www.ecfr.gov/cgi-bin/text-idx?SID=2404f765a6f79e0b7fcf05b6844046cb&mc=true&node=se17.1.1_131&rgn=div8)\n\n\n\nTo assist clients in making informed decisions, IBM engaged Cohasset Associates Inc. to conduct an independent assessment of IBM\u2019s Immutable Object Storage. Review [Cohasset Associates Inc.\u2019s report](https://cloud.ibm.com/docs/images/immutable-cos.pdf) that provides details on the assessment of the Immutable Object Storage feature of IBM Cloud Object Storage.\n\n\n\n Audit of access and transactions \n\nAccess log data for Immutable Object Storage to review changes to retention parameters, object retention period, and application of legal holds is available on a case-by-case basis by opening a customer service ticket.\n\n\n\n\n\n\n\n Using the console \n\nRetention policies can be added to new or existing empty buckets, and cannot be removed. For a new bucket, ensure that you are creating the bucket in a [supported region](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability), and then choose the Add retention policy option. For an existing bucket, ensure that it has no objects and then navigate to configuration settings and click the Create policy button below the bucket retention policy section. In either case, set a minimum, maximum, and default retention periods.\n\n\n\n\n\n Using the REST API, Libraries, and SDKs \n\nSeveral new APIs have been introduced to the IBM Cloud Object Storage SDKs to provide support for applications working with retention policies. Select a language (HTTP, Java, JavaScript, or Python) at the beginning of this page to view examples that use the appropriate Object Storage SDK.\n\nAll code examples assume the existence of a client object that is called cos that can call the different methods. For details on creating clients, see the specific SDK guides.\n\nAll date values used to set retention periods are Greenwich mean time.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-immutable"}, {"document_id": "ibmcld_04866-7-2136", "score": 19.89652158970029, "text": "\nUsing Immutable Object Storage to protect buckets \n\nImmutable Object Storage preserves electronic records and maintains data integrity. Retention policies ensure that data is stored in a WORM (Write-Once-Read-Many), non-erasable and non-rewritable manner. This policy is enforced until the end of a retention period and the removal of any legal holds.\n\nThis feature is not currently supported in Object Storage for Satellite. [Learn more.](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-about-cos-satellite)\n\nPolicies are enforced until the end of a retention period, and can not be altered until the retention period has expired. While IBM Cloud Object Storage makes use of the S3 API for most operations, the APIs used for configuring retention policies is not the same as the S3 API, although some terminology may be shared. Read this documentation carefully to prevent any users in your organization from creating objects that can not be deleted, even by IBM Cloud administrators.\n\nThis feature can be used by any user that needs long-term data retention in their environment, including but not limited to organizations in the following industries:\n\n\n\n* Financial\n* Healthcare\n* Media content archives\n* Anyone looking to prevent privileged modification or deletion of objects or documents\n\n\n\nRetention policies can also be used by organizations that deal with financial records management, such as broker-dealer transactions, and might need to store data in a non-rewritable and non-erasable format.\n\nImmutable Object Storage is available in certain regions only, see [Integrated Services](https://cloud.ibm.com/docs/services/cloud-object-storage/basics?topic=cloud-object-storage-service-availabilityservice-availability) for details. It also requires a Standard pricing plan. See [pricing](https://www.ibm.com/cloud/object-storage) for details.\n\nIt isn't possible to use Aspera high-speed transfer with buckets with a retention policy.\n\n\n\n Terminology and usage \n\n\n\n Retention period \n\nThe duration of time an object must be stored in the IBM Cloud Object Storage bucket.\n\n\n\n\n\n Retention policy", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage/basics?topic=cloud-object-storage-immutable"}]}
{"task_id": "adf9b1f61c73d715809bc7b37ac02724<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-806120-808288", "score": 34.92608581643857, "text": "\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https://cloud.ibm.com/interconnectivity/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-805993-808161", "score": 34.92608581643857, "text": "\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https://cloud.ibm.com/interconnectivity/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n\n\n\n\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n\n\n\n\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n\n\n\n\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order. However, due to the nature of IBM Cloud Direct Link, the Direct Link service billing begins when a BGP session is established with IBM Cloud, or 30 days after the order is submitted.\n\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_01623-6277-8255", "score": 34.879703689191714, "text": "\nAfter you verify your identity, you set up and provide details for your authentication factor.\n\n\n\n\n\n Step 3: Estimate your costs \n\nComplete the following steps to get an estimate of how much your usage might cost:\n\n\n\n1. Go to the [catalog](https://cloud.ibm.com/catalog), and select Services.\n2. Select a service that you're interested in.\n3. Select a pricing plan, enter other configuration details if needed, and click Add to estimate.\n\nBy default, the estimator shows the pricing and billing currency for your location. Pricing can vary by region. If you're estimating costs for a different location, select the correct region to view accurate pricing.\n4. Add the calculated cost to your estimate by clicking Save.\n5. When you're done adding products to your estimate, click Review estimate to a detailed view of your estimate.\n\nYou can download a CSV, XSLX, or PDF of the estimate by clicking Download.\n\n\n\n\n\n\n\n Step 4: Manage your invoices and payment methods \n\nBefore you start working with resources in your account, familiarize yourself with where you can manage your payment method and access your invoices.\n\n\n\n Managing your payment method \n\n\n\n* To manage your payment method for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Payments.\n* To manage your payment method for an account that's billed in non-USD currency, go to [IBM Billing](https://myibm.ibm.com/billing/).\n\n\n\n\n\n\n\n Accessing your invoices \n\n\n\n* To access an invoice for an account that's billed in USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices.\n* To access an invoice for an account that's billed in non-USD currency, go to Manage > Billing and usage in the IBM Cloud console, and select Invoices. Then, click IBM Invoices.\n\n\n\n\n\n\n\n\n\n Step 5: Set preferences for receiving notifications \n\nComplete the following steps to set your preferences for receiving various types of notifications:\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-account-getting-started"}, {"document_id": "ibmcld_07578-807740-809746", "score": 34.54359121800962, "text": "\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https://cloud.ibm.com/interconnectivity/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n* In terms of cost, what do I pay for?\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n* Can I change billing options after my direct link is provisioned?\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-807613-809619", "score": 34.54359121800962, "text": "\nBilling stops after (1) you request a circuit to be deleted, and (2) the provider has de-provisioned the circuit.\n\n\n\n\n\n What extra charges will I incur from other parties with Direct Link? \n\nYou might have extra charges from your provider. See to your carrier or service provider for their fee information.\n\n\n\n* Where do I find cost estimates for Direct Link offerings?\n\n Where do I find cost estimates for Direct Link offerings? \n\nYou can estimate the cost of a service using the cost estimator on the provisioning pages for Direct Link offerings. For example, log in to the [IBM Cloud Direct Link console](https://cloud.ibm.com/interconnectivity/direct-link) and click Order Direct Link. Then, choose to order Direct Link Connect or Direct Link Dedicated. As you complete the ordering form, cost estimates appear in the Summary side panel.\n* In terms of cost, what do I pay for?\n\n In terms of cost, what do I pay for? \n\nThere are two pricing plans: metered and unmetered. Metered has a port fee and bill per GB egressed across the Direct Link. Unmetered billing has a higher port fee and no usage charges, which are ideal for customers who consistently egress traffic across their direct link.\n* Can I change billing options after my direct link is provisioned?\n\n Can I change billing options after my direct link is provisioned? \n\nYes, you can change billing options after a direct link is provisioned, regardless of whether you chose global or local routing. For example, to change from metered to unmetered billing, navigate to the Details page of the direct link and click Edit. In the side panel, select Unmetered in the Billing section, review the updated information, then agree to the prerequisites and click Submit.\n* When does billing begin with Direct Link?\n\n When does billing begin with Direct Link? \n\nThe fees for Direct Link cover the cost of service termination on the IBM Cloud infrastructure.\n\nInfrastructure services are billed in advance and begin upon acceptance of a client\u2019s order.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_03735-7-1918", "score": 33.69489114005603, "text": "\nEstimating your costs \n\nYou can use the cost estimator to estimate the cost of IBM Cloud\u00ae products by customizing plans that fit your business needs. Your account type doesn't affect your estimates. Explore the catalog to find available products to add to an estimate.\n\nEstimates can now be saved to an account. Make sure you're in the account that you want to save the estimate to. If you have existing estimates, they must be converted to a saved estimate that is attached to an account.\n\n\n\n Creating a new estimate \n\n\n\n1. In the IBM Cloud console, go to Cost estimator icon![Cost estimator icon](https://cloud.ibm.com/docs-content/v1/content/9713d864488177dc6b273b53b7f2383a81f10bc1/icons/calculator.svg). From here, you are directed to Estimating your costs page.\n2. Click Create new estimate.\n3. Enter a name and description for the estimate.\n4. Click Create\n5. From here, you are directed to the estimate details page. Click Go to catalog to add products to the estimate.\n6. Select the product that you are interested in.\n\nDepending on the product, an interim informational page might be displayed. For example, if you select Bare Metal Servers, an informational page that describes various features is displayed. Click Continue.\n7. Select your pricing plan and enter other configuration details if needed. Then, click Add to estimate.\n\nSome products might require that you log in to add them to an estimate.\n8. Enter your estimated usage, and click Calculate Cost. You can adjust the estimated usage and recalculate the cost to see how different usage levels affect the overall cost.\n\n\n\nBy default, the estimator shows the pricing and billing currency set for your account. Pricing can vary by region. If you're estimating costs for a different location or currency, you might have to select the appropriate currency on the order summary page for the product or change the currency on your account.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost"}, {"document_id": "ibmcld_05666-10204-11956", "score": 32.47413579756815, "text": "\nIn the [Kubernetes cluster creation console](https://cloud.ibm.com/kubernetes/catalog/create), this uplift is reflected in the pricing calculator as you configure your cluster details. The following table describes the pricing uplift by region.\n: For a table that describes the pricing uplift by region, see [Regional pricing for VPC](https://cloud.ibm.com/vpc-ext/provision/vs).\n\nSustained usage discounts\n: For virtual server instances that are billed at an hourly rate, discounted prices depend on how long the instance runs during the billing month. For more information, expand the Sustained usage discounts on IBM Cloud Virtual Servers for VPC section on the [Pricing for VPC](https://cloud.ibm.com/vpc-ext/provision/vs) page.\n\n\n\n\n\n\n\n Estimating costs \n\nSee [Estimating your costs](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-costcost).\n\nKeep in mind that some charges are not reflected in the estimate, such as tiered pricing for increased hourly usage. For more information, see [Understanding costs for your clusters](https://cloud.ibm.com/docs/containers?topic=containers-costscosts-for-clusters).\n\n\n\n\n\n Managing costs \n\nThe following steps present a general process to manage costs for your IBM Cloud Kubernetes Service clusters.\n\n\n\n1. Decide on a cloud platform strategy to manage your resources.\n\n\n\n* See [Best practices for billing and usage](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-best-practices).\n* Organize your billing with [resource groups](https://cloud.ibm.com/docs/account?topic=account-rgs).\n* [Add tags to your clusters](https://cloud.ibm.com/docs/containers?topic=containers-add_workerscluster_tags) according to your organizational strategy.\n\n\n\n2. Plan the type of cluster that you need.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-costs"}, {"document_id": "ibmcld_07578-506456-508701", "score": 32.13077325068232, "text": "\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https://cloud.ibm.com/billing/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https://cloud.ibm.com/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-506398-508643", "score": 32.13077325068232, "text": "\nFor client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n* How to view usage metrics for App Configuration?\n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https://cloud.ibm.com/billing/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https://cloud.ibm.com/observe) section of the IBM Cloud console.\n* How to predict App Configuration cost?\n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price. If you exceed the included allotment, your instance continues to operate normally but you accumulate an overage charge based on the published rate for entity IDs and API calls.\n\nThe Active Entity ID cost is based on the number of unique entities that interact with your App Configuration instance during the month. Entities self-identify when an API call is made, and each instance of your application provides a unique entity ID.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_02665-3418-5653", "score": 32.04273186833256, "text": "\nFor server-side entities like microservices, when the state of a feature flag or property changes in the App Configuration, a websocket connection notifies the SDK in the microservice that a state change occurred. The microservice then calls back into the App Configuration to retrieve the update. This action is an API call.\n\nAn API call also occurs on startup to the retrieve the initial configuration state. For client-side entities like mobile apps, websockets are not used. Instead, an API call fetches the current configuration state when a user opens the app, or brings it to the foreground. You can also programmatically call the App Configuration to retrieve the most recent configuration state.\n\n\n\n\n\n How to view usage metrics for App Configuration? \n\nView basic historical App Configuration usage metrics on the IBM platform [Billing and Usage dashboard](https://cloud.ibm.com/billing/usage). If you need more sophisticated monitoring, create an IBM Cloud Monitoring instance from the [Observability](https://cloud.ibm.com/observe) section of the IBM Cloud console.\n\n\n\n\n\n How to predict App Configuration cost? \n\nThe simplest way to estimate cost for any IBM Cloud managed service is to use the [IBM Cloud Cost Estimator tool](https://cloud.ibm.com/docs/billing-usage?topic=billing-usage-cost).\n\nGuidelines to help you predict cost in more detail:\n\nThe Application Instance cost is a fixed monthly cost. If you delete an App Configuration instance mid-month, the monthly Application Instance charge is pro-rated. To predict month instance cost, you must be aware of the number of App Configuration instances you have and what pricing plan is assigned to each.\n\nSee all your existing instances in the IBM Cloud Console Resource List in the Services Section. Determine your plan either by clicking the Resource List row that contains your App Configuration instance to reveal an information slide-out, or go to the instance dashboard and look in the Plan section.\n\nSome App Configuration pricing plans have a monthly Application Instance price and others do not. If the plan you select has an instance price, the price for the instance includes a set number of entity IDs and API calls that are included in the instance price.", "title": "", "source": "https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-faqs-usage"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03330-4-2191", "score": 35.906755687420834, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n About Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant leverages industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search skill to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how the product delivers an exceptional, omnichannel customer experience:\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-index"}, {"document_id": "ibmcld_16729-1071-2858", "score": 34.5409438358243, "text": "\nRed Hat OpenShift on IBM Cloud Kubernetes service\n\n+3\n\n,Kubernetes service,Cloudant\n\n\n\n* 3 hours\n\n\n\n[Build a database-driven Slackbot](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-slack-chatbot-database-watson)![Architectural diagram of a Slackbot built with DB2, Cloud Functions, and Watson Assistant.](https://cloud.ibm.com/media/docs/images/homepage/featuredtutorial3.svg)Build a database-driven Slackbot\n\nIn this tutorial, you are going to build a Slackbot to create and search Db2 database entries for events and conferences. The Slackbot is backed by the IBM Watson Assistant service.\n\nCloud Foundry Public Classic Watson Assistant\n\n+2\n\nFunctions,Db2 on Cloud\n\n\n\n* 2 hours\n\n\n\nAI / Machine Learning[Getting started with an actions skill](https://cloud.ibm.com/docs/assistant?topic=assistant-gs-actions)Getting started with an actions skill\n\nIn this short tutorial, we help you use an actions skill to build your first conversation.\n\nClassic Watson Assistant\n\n\n\n* 10 minutes\n* 2022-04-01\n\n\n\n[Getting started with a dialog skill](https://cloud.ibm.com/docs/assistant?topic=assistant-gs-dialog)Getting started with a dialog skill\n\nIn this short tutorial, we help you use a dialog skill to build your first conversation.\n\nClassic Watson Assistant\n\n\n\n* 10 minutes\n* 2022-12-14\n\n\n\n[Improving a dialog node with slots](https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial-slots-complex)Improving a dialog node with slots\n\nIn this tutorial, you will enhance a simple node with slots that collects the information necessary to make a restaurant reservation.\n\nClassic Watson Assistant\n\n\n\n* 2 hours\n* 2021-01-15\n\n\n\n[Adding a node with slots to a dialog](https://cloud.ibm.com/docs/assistant?topic=assistant-tutorial-slots)Adding a node with slots to a dialog", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_03085-4-2046", "score": 34.29538222057871, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Managing access \n\nYou can give other people access to your Watson Assistant resources, and control the level of access they get.\n\nMaybe you want one development team to have access to a test assistant and another development team to have access to a production assistant. And you want data scientists to be able to view analytics for user conversation logs from both assistants. And maybe you want a writer to be able to author the dialogue that is used by your assistant to converse with your customers. To manage who can do what with your skills and assistants, you can assign different access roles to different people.\n\n\n\n Before you grant access to others \n\nFor each person to whom you grant access to your Watson Assistant service instance, decide whether you want to give the person a role with instance-level or resource-level access. Instance-level access applies to all of the assistants and skills in a single service instance. Resource-level access applies to individual skills and assistants within a service instance only.\n\n\n\n\n\n Granting users access to your resources \n\n\n\n1. If you plan to give a user access to a single skill or assistant in your service instance, get the ID for the skill or assistant. You need to provide the ID in a later step.\n\n\n\n* To get the assistant ID, go to the Assistants page. Click the overflow menu for the assistant, and then click Settings > API Details. Copy the assistant ID and paste it somewhere that you can access it from later.\n* To get the skill ID, go to the Skills page. Click the overflow menu for the skill, and then click View API Details. Copy the skill ID and paste it somewhere that you can access it from later.\n\n\n\n2. Click the User ![User](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/user-icon2.png) icon in the page header.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-access-control"}, {"document_id": "ibmcld_03330-3253-5192", "score": 31.538356889816587, "text": "\n* A conversational skill interprets the customer's message further, then directs the flow of the conversation. The skill gathers any information it needs to respond or perform a transaction on the customer's behalf.\n* A search skill leverages existing FAQ or other curated content that you own to find relevant answers to customer questions.\n* If a customer wants more personalized help or wants to discuss a sensitive subject, the assistant can connect the customer with someone from your support team through the web chat integration.\n\n\n\n\n\nFor more information about the architecture, read the [How to Make Chatbot Orchestration Easier](https://medium.com/ibm-watson/how-to-make-chatbot-orchestration-easier-c8ed61620b8d) blog on Medium.com.\n\nTo see how Watson Assistant is helping enterprises cut costs and improve customer satisfaction today, read the [Independent study finds IBM Watson Assistant customers can accrue $23.9 million in benefits](https://www.ibm.com/blogs/watson/2020/03/independent-study-finds-ibm-watson-assistant-customers-accrued-23-9-million-in-benefits/) blog on ibm.com.\n\nThis documentation describes managed instances of Watson Assistant that are offered in IBM Cloud or in Cloud Pak for Data as a Service. If you are interested in on-premises or installed deployments, see [this documentation](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-index).\n\nRead more about these implementation steps by following these links:\n\n\n\n* [Creating an assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-add)\n* [Adding skills to your assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add)\n* [Deploying your assistant](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-integration-add)\n\n\n\n\n\n\n\n Browser support \n\nThe Watson Assistant application (where you create assistants and skills) requires the same level of browser software as is required by IBM Cloud.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-index"}, {"document_id": "ibmcld_03369-87803-90065", "score": 31.193084628463986, "text": "\nFor more information about the parameter, see [Configuration](https://integrations.us-south.assistant.watson.cloud.ibm.com/web/developer-documentation/api-configuration).\n\n\n\n\n\n 26 March 2020 \n\nThe Covid-19 content catalog is available in Brazilian Portuguese, French, and Spanish\n: The content catalog defines a group of intents that recognize the common types of questions people ask about the novel coronavirus. You can use the catalog to jump-start development of chatbots that can answer questions about the virus and help to minimize the anxiety and misinformation associated with it. For more information about how to add a content catalog to your skill, see [Using content catalogs](https://cloud.ibm.com/docs/assistant?topic=assistant-catalog).\n\n\n\n\n\n 19 March 2020 \n\nA Covid-19 content catalog is available\n: The English-only content catalog defines a group of intents that recognize the common types of questions people ask about the novel coronavirus. The World Health Organization characterized COVID-19 as a pandemic on 11 March 2020. You can use the catalog to jump-start development of chatbots that can answer questions about the virus and help to minimize the anxiety and misinformation associated with it. For more information about how to add a content catalog to your skill, see [Using content catalogs](https://cloud.ibm.com/docs/assistant?topic=assistant-catalog).\n\nFixed a problem with missing User Conversation data\n: A recent change resulted in no logs being shown in the User Conversations page unless you had a skill as the chosen data source. And the chosen skill had to be the same skill (with same skill ID) that was connected to the assistant when the user messages were submitted.\n\n\n\n\n\n 18 March 2020 \n\nTechnology preview is discontinued\n: The technology preview user interface was replaced with the Watson Assistant standard user interface. If you used an Actions page to create actions and steps for your skill previously, you cannot access the Actions page anymore. Instead, use the Intents and Dialog pages to work with your skill.\n\n\n\n\n\n 16 March 2020 \n\nInstructions updated for Slack integrations\n: The steps required to set up a Slack integration have changed to reflect permission assignment changes that were made by Slack.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_07578-1-1686", "score": 30.055992571909357, "text": "\nFAQ library\n\nFilter:\n\nCategories\n\n\n\n1.\nAI / Machine Learning\n2.\nAnalytics\n3. Blockchain\n4.\nCompute\n5.\nContainers\n6.\nDatabases\n7.\nDeveloper tools\n8.\nIntegration\n9.\nLogging and monitoring\n10.\nMigration\n11.\nNetworking\n12.\nPlatform\n13.\nSecurity\n14.\nSolutions\n15.\nStorage\n\n\n\nAI / Machine Learning Classic Watson Assistant\n\n\n\n* What's a...\n\n\n\n Term Definition \n\n Action An action that you add to an actions skill represents a discrete task or question that your assistant is designed to help customers with. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-actions-overviewactions-overview-actions). \n Assistant Container for your skills. You add skills to an assistant, and then deploy the assistant when you are ready to start helping your customers. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-assistants). \n Condition Logic that is defined in the If assistant recognizes section of a dialog node that determines whether the node is processed. The dialog node conditions is equivalent to an If statement in If-Then-Else programming logic. \n Content catalog A set of prebuilt intents that are categorized by subject, such as customer care. You can add these intents to your skill and start using them immediately. Or you can edit them to complement other intents that you create. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-catalog). \n Context variable A variable that you can use to collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on. A context variable is used by the dialog skill.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1-1686", "score": 30.055992571909357, "text": "\nFAQ library\n\nFilter:\n\nCategories\n\n\n\n1.\nAI / Machine Learning\n2.\nAnalytics\n3. Blockchain\n4.\nCompute\n5.\nContainers\n6.\nDatabases\n7.\nDeveloper tools\n8.\nIntegration\n9.\nLogging and monitoring\n10.\nMigration\n11.\nNetworking\n12.\nPlatform\n13.\nSecurity\n14.\nSolutions\n15.\nStorage\n\n\n\nAI / Machine Learning Classic Watson Assistant\n\n\n\n* What's a...\n\n\n\n Term Definition \n\n Action An action that you add to an actions skill represents a discrete task or question that your assistant is designed to help customers with. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-actions-overviewactions-overview-actions). \n Assistant Container for your skills. You add skills to an assistant, and then deploy the assistant when you are ready to start helping your customers. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-assistants). \n Condition Logic that is defined in the If assistant recognizes section of a dialog node that determines whether the node is processed. The dialog node conditions is equivalent to an If statement in If-Then-Else programming logic. \n Content catalog A set of prebuilt intents that are categorized by subject, such as customer care. You can add these intents to your skill and start using them immediately. Or you can edit them to complement other intents that you create. [Learn more](https://cloud.ibm.com/docs/assistant?topic=assistant-catalog). \n Context variable A variable that you can use to collect information during a conversation, and reference it later in the same conversation. For example, you might want to ask for the customer's name and then address the person by name later on. A context variable is used by the dialog skill.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_16233-7-2298", "score": 29.69464317829863, "text": "\nAbout Watson Assistant \n\nUse IBM Watson\u00ae Assistant to build your own branded live chatbot into any device, application, or channel. Your chatbot, which is also known as an assistant, connects to the customer engagement resources you already use to deliver an engaging, unified problem-solving experience to your customers.\n\n\n\n\n\n Create AI-driven conversational flows Your assistant uses industry-leading AI capabilities to understand questions that your customers ask in natural language. It uses machine learning models that are custom-built from your data to deliver accurate answers in real time. \n Embed existing help content You already know the answers to customer questions? Put your subject matter expertise to work. Add a search integration with IBM Watson\u00ae Discovery to give your assistant access to corporate data collections that it can mine for answers. \n Connect to your customer service teams If customers need more help or want to discuss a topic that requires a personal touch, connect them to human agents from your existing service desk provider. \n Bring the assistant to your customers, where they are Configure one or more built-in integrations to quickly publish your assistant on popular social media platforms such as Slack, Facebook Messenger, Intercom, or WhatsApp. Turn the assistant into a member of your customer support call center team, where it can answer the phone and address simple requests so its human teammates can focus on more nuanced customer needs. Make your assistant the go-to help resource for customers by adding it as a chat widget to your company website. If none of the built-in integrations fit your needs, use the APIs to build your own custom app. \n Track customer engagement and satisfaction Use built-in metrics to analyze logs from conversations between customers and your assistant to gauge how well it's doing and identify areas for improvement. \n\n\n\n\n\n How it works \n\nThis diagram illustrates how IBM Watson\u00ae Assistant delivers an exceptional, omnichannel customer experience:\n\nZoom\n\n![Flow diagram of the service](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/arch-detail.png)\n\nHow it works\n\nCustomers interact with the assistant through one or more of these channels:", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-about"}, {"document_id": "ibmcld_16278-7-2318", "score": 29.073426422144216, "text": "\nComparing actions and dialog \n\nChoose the right type of conversation for your use case.\n\n\n\n Actions benefits \n\nUsing actions is the best choice when you want to approach the assistant with a focus on content. Actions offers the following benefits:\n\n\n\n* The process of creating a conversational flow is easier. People who have expertise with customer care can write the words that your assistant says. With a simplified process anyone can build a conversation. You don't need knowledge about machine learning or programming.\n* Actions provide better visibility into the customer's interaction and satisfaction with the assistant. Because each task is discrete and has a clear beginning and ending, you can track user progress through a task and identify snags.\n* The conversation designer doesn't need to manage data collected during the conversation. By default, your assistant collects and stores information for the duration of the current action. You don't need to take extra steps to delete saved data or reset the conversation. But if you want, you can store certain types of information, such as the customer's name, for the duration of a conversation.\n* Many people can work at the same time in separate, self-contained actions. The order of actions within a conversation doesn't matter. Only the order of steps within an action matters. And the action author can use drag and drop to reorganize steps in the action for optimal flow.\n\n\n\n\n\n\n\n Dialog benefits \n\nA dialog-based conversation is the best choice when you want greater control over the logic of the flow. The dialog editor exposes more of the underlying artifacts (such as intents and entities) used to build the AI models. The dialog flow uses an if-then-else style structure that might be familiar to developers, but not to content designers or customer-care experts.\n\n\n\n\n\n How actions are different from dialog \n\nIf you are already familiar with dialog-based conversations, learn more about how actions compares.\n\n\n\nConversational flow skill feature support\nThis table has row and column headers. The row headers identify features. The column headers identify the different skill types. To understand which features are supported by a skill, go to the row that describes the feature, and find the columns for the skill you are interested in.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-comparing-actions-dialog"}, {"document_id": "ibmcld_16364-125672-127828", "score": 28.298108639967317, "text": "\n19 March 2020 \n\nA Covid-19 content catalog is available\n: The English-only content catalog defines a group of intents that recognize the common types of questions people ask about the novel coronavirus. The World Health Organization characterized COVID-19 as a pandemic on 11 March 2020. You can use the catalog to jump-start development of chatbots that can answer questions about the virus and help to minimize the anxiety and misinformation associated with it. For more information about how to add a content catalog to your skill, see [Using content catalogs](https://cloud.ibm.com/docs/assistant?topic=assistant-catalog).\n\nFixed a problem with missing User Conversation data\n: A recent change resulted in no logs being shown in the User Conversations page unless you had a skill as the chosen data source. And the chosen skill had to be the same skill (with same skill ID) that was connected to the assistant when the user messages were submitted.\n\n\n\n\n\n 18 March 2020 \n\nTechnology preview is discontinued\n: The technology preview user interface was replaced with the Watson Assistant standard user interface. If you used an Actions page to create actions and steps for your skill previously, you cannot access the Actions page anymore. Instead, use the Intents and Dialog pages to work with your skill.\n\n\n\n\n\n 16 March 2020 \n\nInstructions updated for Slack integrations\n: The steps required to set up a Slack integration have changed to reflect permission assignment changes that were made by Slack. For more information, see [Integrating with Slack](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-slack).\n\nOrder of response types is preserved\n: Previously, if you included a response type of Search skill in a list of response types for a dialog node, the search results were displayed last despite its placement in the list. This behavior was changed to show the search results in the appropriate order, namely in the sequence in which the search skill response type is listed for the dialog node.\n\n\n\n\n\n 10 March 2020 \n\nContextual entity support is generally available\n: You can add contextual entities to English-language dialog skills.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}]}
{"task_id": "1dcbbeb35d4d25ba1ffb787a9f2080e2<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_02844-1555-3643", "score": 17.65506989048894, "text": "\nconversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent. \n conversation.example.delete deletes a user example from an intent. \n conversation.example.update edits a user example that is associated with an intent. \n conversation.intent.create creates an intent. \n conversation.intent.delete deletes an intent. \n conversation.intent.update edits an intent. \n conversation.log.create corrects an intent that was inaccurately categorized by the skill from the Analytics>User conversations page. \n conversation.node.create creates a dialog node. \n conversation.node.delete deletes a dialog node. \n conversation.node.update edits a dialog node. \n conversation.skill.create creates a skill, either dialog or search. \n conversation.skill.delete deletes a skill. \n conversation.skill.update updates a skill. \n conversation.skill_reference.create adds a specific skill to an assistant. \n conversation.skill_reference.delete removes a specific skill from an assistant. \n conversation.skill_reference.update updates a specific skill that is associated with an assistant. \n conversation.snapshot.create creates a version of a dialog skill. \n conversation.snapshot.delete deletes a version of a dialog skill. \n conversation.synonym.create creates a synonym for an entity value. \n conversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-audit-events"}, {"document_id": "ibmcld_02844-3227-3811", "score": 17.385955936287104, "text": "\nconversation.synonym.delete deletes a synonym that is associated with an entity value. \n conversation.synonym.update edits a synonym that is associated with an entity value. \n conversation.userdata.delete deletes data that was created by a specified customer. \n conversation.value.create creates an entity value. \n conversation.value.delete deletes an entity value. \n conversation.value.update edits an entity value. \n conversation.workspace.create creates a workspace. \n conversation.workspace.delete deletes a workspace. \n conversation.workspace.update makes changes to a workspace.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-audit-events"}, {"document_id": "ibmcld_16262-6573-7996", "score": 16.640632428292623, "text": "\n{\n\"output\": {\n\"generic\": [!\n{\n\"response_type\": \"text\",\n\"text\": \"Welcome to the Watson Assistant example\"\n}\n],\n\"intents\": [\n{\n\"intent\": \"hello\",\n\"confidence\": 1\n}\n],\n\"entities\": []\n},\n\"user_id\": \"my_user_id\",\n\"context\": {\n\"global\": {\n\"system\": {\n\"turn_count\": 1,\n\"user_id\": \"my_user_id\"\n}\n},\n\"skills\": {\n\"main skill\": {\n\"user_defined\": {\n\"account_number\": \"123456\"\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n Restoring conversation state \n\nIn some situations, you might want the ability to restore a conversation to a previous state.\n\nYou can use the export option on stateful message requests to specify that you want the context object in the response to include complete session state data. If you specify true for this option, the returned skill context includes an encoded state property that represents the current conversation state.\n\nIf you are using the stateful message API, the service stores conversation state data only for the life of the session. However, if you save this context data (including state) and send it back to the service with a subsequent message request, you can restore the conversation to the same state, even if the original session expired or was deleted.\n\nIf you are using the stateless message API, the state property is always included in responses (along with the rest of context). Although stateless sessions do not expire, you can still use this state data to reset a conversation to a previous state.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-client-get-context"}, {"document_id": "ibmcld_03117-5698-7668", "score": 16.14369172197695, "text": "\nAfter a conversation ends, use the v2 [Delete session](https://cloud.ibm.com/apidocs/assistant/assistant-v2deletesession) method to delete the session.\n\n\n\nservice .deleteSession({ assistant_id: assistantId, session_id: sessionId, })\n\n {: codeblock python}\nservice.delete_session(\nassistant_id = assistant_id,\nsession_id = session_id\n)\n\n {: codeblock java}\n\nDeleteSessionOptions deleteSessionOptions = new DeleteSessionOptions.Builder(assistantId, sessionId .build(); service.deleteSession(deleteSessionOptions).execute();\n\nIf you do not explicitly delete the session, it will be automatically deleted after the configured timeout interval. (The timeout duration depends on your plan; for more information, see [Session limits](/docs/assistant?topic=assistant-assistant-settingsassistant-settings-session-limits).)\n\nTo see examples of the v2 APIs in the context of a simple client application, see [Building a client application](/docs/assistant?topic=assistant-api-client).\n\n Handle the v2 response format\n\nYour application might need to be updated to handle the v2 runtime response format, depending on which parts of the response your application needs to access:\n\n- Output for all response types (such as text and option) are still returned in the output.generic object. Application code for handling these responses should work without modification.\n\n- Detected intents and entities are now returned as part of the output object, rather than at the root of the response JSON.\n\n- The conversation context is now organized into two objects:\n\n- The global context contains system-level context data shared by all skills used by the assistant.\n\n- The skill context contains any user-defined context variables used by your dialog skill.\n\nHowever, keep in mind that state data, including conversation context, is now maintained by the assistant, so your application might not need to access the context at all (see [Let the assistant maintain state](api-migration-state)).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-migration"}, {"document_id": "ibmcld_02844-4-2018", "score": 15.872698023482759, "text": "\n{{site.data.content.newlink}}\n\n\n\n Audit events \n\nAs a security officer, auditor, or manager, you can use the [IBM Cloud Pak for Data audit service](https://www.ibm.com/docs/en/cloud-paks/cp-data/latest?topic=considerations-auditing-cloud-pak-data) to track how users and applications interact with Watson Assistant.\n\nIBM Cloud Pak for Data audit service records user-initiated activities that change the state of a service in Watson Assistant. You can use this service to investigate abnormal activity and critical actions and to comply with regulatory audit requirements. For more information about exporting audit records to your security information and event management (SIEM) solutions, see [Auditing Cloud Pak for Data](https://www.ibm.com/docs/en/cloud-paks/cp-data/latest?topic=considerations-auditing-cloud-pak-data).\n\n\n\n List of events \n\nThe following table lists the Watson Assistant activities that generate events.\n\n\n\nTable 1. Activities that generate events\n\n Action Triggered when someone... \n\n conversation.assistant.create creates an assistant. \n conversation.assistant.delete deletes an assistant. \n conversation.assistant.update updates an assistant. For example, renames the skill, changes the session timeout, or changes its associated skills. \n conversation.counterexample.create marks test user input in the Try it out pane as being irrelevant or corrects the categorization of a user input that was incorrectly assigned to an intent by marking it as irrelevant. \n conversation.counterexample.delete deletes a counterexample. \n conversation.counterexample.update edits a counterexample. \n conversation.data.update does a bulk action, such as importing a CSV file of intents or entities to the skill, or deleting multiple training data items, such as multiple entities or intents. \n conversation.entity.create creates an entity. \n conversation.entity.delete deletes an entity. \n conversation.entity.update edits an entity. \n conversation.example.create adds a user input example to an intent.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-audit-events"}, {"document_id": "ibmcld_11580-5094-6991", "score": 15.721523456130692, "text": "\nSystem Relocation that uses SAP LaMa to orchestrate move Physically or virtually relocate running or shutdown instances. Uses SAP LaMa. Cannot relocate SAP HANA DB MDC Tenants. Moving individual SAP instances to new infrastructure landscape that is already set up. Yes minimal, running systems have downtimes as they are stopped, unprepared, then prepared and started Using SAP LaMa, relocation can be automated Package network transfer that uses LaMa or LaMa adapter for VMware \n DMO for SUM with System Move execution (Combines Migration, Unicode conversion, Upgrades, and more tasks) Supported for App Server (NetWeaver) upgrade or database conversion to SAP HANA. Moves the NW PAS + database server and upgrade - all at the same time. Migrations to Business Suite on SAP HANA or part of SAP S/4HANA conversion migration (Brownfield) Yes. Both PAS Target and database host in the target landscape (for example, IBM Cloud) needs to be ready before DMO for SUM with System Move execution. Significant preparation is required. System Export is performed in source landscape. Import is performed in target landscape. The export/import can also be done in parallel. \n Selective Data Transition, with Shell Conversion Create shell of SAP System with Customizing and Development only; then upgrade / conversion to either SAP ECC or SAP S/4HANA. Migrate selective data from ECC to the upgraded shell system Used in Business split scenarios (e.g. Divestitures), and Transformation/Conversion projects with SAP S/4HANA Yes minimal, the target can be built and tested in advance (repeatedly testing the conversion steps and remediation). Data can be replicated to target in advance, so downtime is only for the delta data synchronization and replacing the old system with target. Significant preparation is required. SAP Landscape Transformation Replication Server, handled through a direct SAP engagement", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-faq-moving-sap-workloads"}, {"document_id": "ibmcld_11580-6435-7767", "score": 15.67131829327902, "text": "\nMigrate selective data from ECC to the upgraded shell system Used in Business split scenarios (e.g. Divestitures), and Transformation/Conversion projects with SAP S/4HANA Yes minimal, the target can be built and tested in advance (repeatedly testing the conversion steps and remediation). Data can be replicated to target in advance, so downtime is only for the delta data synchronization and replacing the old system with target. Significant preparation is required. SAP Landscape Transformation Replication Server, handled through a direct SAP engagement \n Selective Data Transition, with Mix & Match Merge of two or more system configurations to create a new SAP System with required configuration; then upgrade / conversion to SAP S/4HANA Used in Business merge scenarios (e.g. Acquisitions) or multiple SAP system consolidation (e.g. ERPs for each Geographic Region or Business Units), and Transformation/Conversion projects with SAP S/4HANA Yes minimal, the target can be built and tested in advance (repeatedly testing the conversion steps and remediation). Data can be replicated to target in advance, so downtime is only for the delta data synchronization and replacing the old system with target. Significant preparation is required. SAP Landscape Transformation Replication Server, handled through a direct SAP engagement", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-faq-moving-sap-workloads"}, {"document_id": "ibmcld_16367-0-1894", "score": 14.89885851113531, "text": "\n\n\n\n\n\n\n  Configuring the home screen \n\nOn the Home screen tab, you can configure the contents of the home screen, which welcomes customers and helps them start the conversation with the assistant. The home screen replaces any greeting that would otherwise be sent by the Greet customer system action.\n\n![An example of the home screen](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/home-screen.png)\n\nIf you prefer to use a Greet customer system action instead of the home screen, you can disable it by clicking the toggle switch on the Home screen tab.\n\nIf you use the home screen, you must configure it to show content that is relevant to your customers:\n\n\n\n*  In the Greeting message field, type a greeting that is engaging and invites the user to interact with your assistant. This greeting is the first message your customers will see when they open the web chat window.\n*  In the Conversation starters section, specify the conversation starter messages you want to be displayed on the home screen.\n\nThese messages are displayed on the home screen as options that customers can click to start the conversation (for example, I need to reset my password or What is my account balance?). Specify conversation starters that are likely to be useful to your customers, and that your assistant knows how to handle.\n\nBe sure to test each conversation starter. Use only messages that your assistant understands and knows how to answer well. Conversation starters cannot be longer than 35 characters.\n\nYou can specify up to 5 conversation starters.\n\n\n\nThe messages you specify are immediately reflected by the web chat preview that is shown on the page, and you can click the conversation starters to see how your assistant responds. However, no configuration changes are applied to the environment until you click Save and exit.\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-configure-home-screen"}, {"document_id": "ibmcld_03037-2895-4808", "score": 14.678962943033646, "text": "\nImportant: The User ID property is not equivalent to the Customer ID property, though both can be passed with the message. The User ID field is used to track levels of usage for billing purposes, whereas the Customer ID field is used to support the labeling and subsequent deletion of messages that are associated with end users. Customer ID is used consistently across all Watson services and is specified in the X-Watson-Metadata header. User ID is used exclusively by the Watson Assistant service and is passed in the context object of each /message API call.\n\n\n\n\n\n Enabling user metrics \n\nUser metrics allow you to see, for example, the number of unique users who have engaged with your assistant, or the average number of conversations per user over a given time interval on the [Overview page](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-overview). User metrics are enabled by using a unique User ID parameter.\n\nTo specify the User ID for a message sent using the /message API, include the user_id property in your global [context](https://cloud.ibm.com/apidocs/assistant-data-v2message), as in this example:\n\n\"context\": {\n\"global\": {\n\"system\": {\n\"user_id\": \"{UserID}\"\n}\n}\n}\n\nIf your application is still using the older [v1 runtime API](https://cloud.ibm.com/apidocs/assistant-data-v1?curl=message), the context format is different:\n\n\"context\" : {\n\"metadata\" : {\n\"user_id\": \"{UserID}\"\n}\n}\n\n\n\n\n\n Associating message data with a user for deletion \n\nThere might come a time when you want to completely remove a set of your user's data from a Watson Assistant instance. When the delete feature is used, then the Overview metrics will no longer reflect those deleted messages; for example, they will have fewer Total Conversations.\n\n\n\n Before you begin \n\nTo delete messages for one or more individuals, you first need to associate a message with a unique Customer ID for each individual.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-logs-resources"}, {"document_id": "ibmcld_03112-7441-8509", "score": 14.192158005579582, "text": "\n}\n}\n}\n}\n}\nShow more\n\n\n\n\n\n Restoring conversation state \n\nIn some situations, you might want the ability to restore a conversation to a previous state.\n\nYou can use the export option on stateful message requests to specify that you want the context object in the response to include complete session state data. If you specify true for this option, the returned skill context includes an encoded state property that represents the current conversation state.\n\nIf you are using the stateful message API, the service stores conversation state data only for the life of the session. However, if you save this context data (including state) and send it back to the service with a subsequent message request, you can restore the conversation to the same state, even if the original session has expired or has been deleted.\n\nIf you are using the stateless message API, the state property is always included in responses (along with the rest of context). Although stateless sessions do not expire, you can still use this state data to reset a conversation to a previous state.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-client-get-context"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>8", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16321-19290-20983", "score": 28.25758751093342, "text": "\n\"uri\": \"sip:12345556789\\@myhost.com\"\n\n\n\n Transferring after hangup \n\nBy default, the phone integration transfers calls by using a SIP REFER request. Depending on the IVR service provider, you might need to configure call transfer to use a SIP BYE request instead. Use the transfer_method attribute to specify how to transfer the call, using either refer or hangup. When transfer_method is set to hangup instead of refer, the behavior of the transfer action changes. Instead of sending a SIP REFER request, the phone integration plays back any associated text and then hangs up the call by sending a SIP BYE request.\n\nAfter the hangup, the phone integration passes the transfer destination that is specified in the url attribute to the call anchor in the BYE message. The header field that contains the transfer target is determined by the transfer_target_header attribute. If the transfer_target_header attribute isn't specified, the phone integration uses Transfer-Target.\n\n{\n\"generic\": [\n{\n\"response_type\": \"connect_to_agent\",\n\"transfer_info\": {\n\"target\": {\n\"service_desk\": {\n\"sip\": {\n\"uri\": \"sip:user\\@domain.com\",\n\"transfer_method\": \"hangup\",\n\"transfer_target_header\": \"Transfer-Target\"\n}\n}\n}\n},\n\"agent_available\": {\n\"message\": \"Please hold on while I connect you with a live agent.\"\n},\n\"agent_unavailable\": {\n\"message\": \"Sorry, I could not find an agent.\"\n},\n\"message_to_human_agent\": \"The caller needs help resetting their password\"\n}\n]\n}\nShow more\n\n\n\n\n\n Transferring upon failure \n\nTo configure transfer on failures, go to the Advanced tab in the phone integration settings. The following selections can be configured:\n\n\n\n* Transfer failure message\n* Disconnect call on transfer failure", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_03158-17978-19852", "score": 28.2457437768138, "text": "\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Buy a Number.\n* If you already have a number, you can click the plus sign (+) to provision a new phone number in your region.\n\n\n\n8. Assign the number to the SIP trunk you created by going back to the SIP trunk and clicking the number sign (#) icon.\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target.\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https://www.five9.com/products/capabilities/contact-center-software)\n* [Genesys](https://www.genesys.com/en-sg/definitions/what-is-a-trunk)\n* [Vonage](https://www.vonage.com/communications-apis/sip-trunking/)\n* [Voximplant](https://voximplant.com/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1. Create a [IBM Cloud case](https://cloud.ibm.com/unifiedsupport/cases/form).\n2. Click Customer success as the case type.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone"}, {"document_id": "ibmcld_16288-10521-12298", "score": 27.50154486598604, "text": "\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Add a number and then Buy a Number.\n* If you already have a number, you can click Add a number and then Add an Existing Number.\n\n\n\n\n\nIf you use a Lite or Trial Twilio account for testing purposes, then be sure to verify the transfer target. For more information, see the [Twilio documentation](https://support.twilio.com/hc/en-us/articles/223136107-How-does-Twilio-s-Free-Trial-work-).\n\nYou cannot enable SIP authentication if you choose Twilio as your SIP trunk provider. Twilio doesn't support SIPS for originating calls.\n\n\n\n\n\n Using other third-party providers \n\nYou can ask for help setting up an account with another SIP trunk provider by opening a support request.\n\nIBM has established relationships with the following SIP trunk providers:\n\n\n\n* [Five9](https://www.five9.com/products/capabilities/contact-center-software)\n* [Genesys](https://www.genesys.com/en-sg/definitions/what-is-a-trunk)\n* [Vonage](https://www.vonage.com/communications-apis/sip-trunking/)\n* [Voximplant](https://voximplant.com/)\n\n\n\nThe SIP trunk provider sets up a SIP trunk for your voice traffic, and manages access from allowed IP addresses. Most of the major SIP trunk providers have existing relationships with IBM. Therefore, the network configuration that is required to support the SIP trunk connection typically can be handled for you with minimal effort.\n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_16288-7-2218", "score": 27.36907570702413, "text": "\nPhone integration configuration \n\nIBM Cloud\n\nAfter you have set up the phone integration for your assistant, you can modify the phone integration settings to customize the call behavior.\n\n\n\n Handling call and transfer failures \n\nYou can configure the phone integration to transfer the caller to a human agent if the phone connection fails for any reason. To transfer the caller to a human agent automatically, go to the Advanced tab in the phone integration settings, and make the following configuration selections:\n\n\n\n* SIP target when a call fails: Add the SIP endpoint for your support agent service. Specify a SIP or telephone URI for a general call queue that can redirect requests to other queues. For more information, see [Configuring backup call center support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-transfer-service).\n* Call failure message: Add the message you want the assistant to say to a caller before it transfers the call to a human agent.\n\n\n\nIf, after you transfer the call to a human, the connection to a live agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message you want the assistant to say to a caller if transfer to a live agent fails. The message can be up to 150 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after the failure message. This option is enabled by default. If this option is disabled, when a call transfer fails, your assistant can disconnect or process a different action.\n\nIf you choose to leave a call connected despite a transfer failure, Watson Assistant will initiate a new turn to determine the next step. It's important that the Assistant be configured with an Action or webhook that can handle this scenario.\n\n\n\nThe phone integration supports disaster recovery by providing the ability to do a fast failover to another region instead of routing the call to a live agent when a service outage occurs. This is accomplished by sending a SIP 503 response to the upstream SIP trunking provider, instead of auto referring the call to a live agent when failures happen during the setup of a call.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_03165-4477-6547", "score": 26.97425468721349, "text": "\nFrom the All Products and Services menu, click Phone Numbers.\n9. From the Active Numbers page, click one of your phone numbers. Scroll to the Messaging section, and then find the Webhook field that defines what to do when a message comes in.\n\nPaste the value that you copied from the Webhook URI field into it.\n10. If you want to support multiple phone numbers, repeat the previous step for each phone number that you want to use.\n11. Click Save and exit.\n\n\n\nTo watch a video that walks through the setup process, see [Phone and SMS Integration](https://community.ibm.com/community/user/watsonapps/viewdocument/phone-and-sms-integration?CommunityKey=7a3dc5ba-3018-452d-9a43-a49dc6819633&tab=librarydocuments) in the IBM Watson Apps Community.\n\nIf you want your assistant to be able to switch between voice and text during a customer interaction, enable both the phone and text messaging integrations. The integrations do not need to use the same third-party service provider. For more information, see [Integrating with phone](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone).\n\n\n\n\n\n Advanced configuration options \n\nClick the Advanced options tab to make any of the following customizations to the messaging behavior:\n\n\n\n* Initiate conversation from inbound messages: Disable this option if you want to limit messaging support to allow messages that are sent in the context of an ongoing phone integration conversation only, and not allow customers to start a message exchange with the assistant outside of a phone call.\n* Default failure message: Add a message to send to the customer if the SMS connection fails.\n* Base URL: This URL is the REST API endpoint for the SMS service you are using.\n\n\n\n\n\n\n\n Optimize your dialog for messaging \n\nFor the best customer experience, design your dialog with the capabilities of the Twilio integration in mind:\n\n\n\n* Do not include HTML elements in your text responses.\n* You can send media files or even documents in your response. These files can be intercepted and processed by a configured premessage webhook.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-sms"}, {"document_id": "ibmcld_16288-9295-10984", "score": 26.901926400290133, "text": "\n* [Use other third-party providers](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-request-setup)\n* [Bring your own SIP trunk](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-byost)\n* [Migrate from Voice Agent with Watson](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-configdeploy-phone-config-migrate-from-va)\n\n\n\n\n\n Creating a Twilio SIP trunk \n\nTo set up a Twilio SIP trunk, complete the following steps:\n\n\n\n1. Create a Twilio account on the [Twilio website](https://www.twilio.com/sip-trunking).\n2. From the Twilio website, go to the Elastic SIP Trunking dashboard. If you do not see it on the sidebar, go to the Search Bar at the top and search for 'Elastic SIP Trunking', then select Elastic SIP Trunks.\n3. On the Elastic SIP Trunks page, click the Create new SIP Trunk button to create a SIP trunk. Enter a name for your SIP trunk and click Create. If you already have a SIP trunk, go to the next step.\n4. From the Elastic SIP Trunks page, select your SIP trunk.\n5. Select Origination from the navigation bar for your SIP trunk and configure the origination SIP URI.\n\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Add a number and then Buy a Number.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-phone-config"}, {"document_id": "ibmcld_03158-8929-11062", "score": 26.772378592544815, "text": "\nFor more information, see [Configuring backup support](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-transfer-service).\n* Call failure message: Add the message to say to a caller before you transfer them to a human agent.\n\n\n\nIf, after you transfer the caller to a human agent, the connection to the human agent fails for any reason, you can configure what to do.\n\n\n\n* Transfer failure message: Add the message to stream to callers if the transfer to a human agent fails. The message can be up to 1,024 characters in length.\n* Disconnect call on transfer failure: Choose whether to disconnect the call after sharing the failure message. This option is enabled by default. If disabled, when a call transfer fails, your assistant can disconnect or process a different dialog node.\n\n\n\n\n\n\n\n Secure the phone connection \n\nYou can add security to the phone connection by selecting one or both of the following configuration options:\n\n\n\n* Force secure trunking: Select this option to use Secure Real-Time Transfer Protocol (SRTP) to secure the audio that is transmitted over the phone. For more information about RTP, see [Call routing details](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-route).\n* Enable SIP authentication: Select this option if you want to require SIP digest authentication.\n\nWhen SIP authentication is required, all inbound traffic (meaning requests from the SIP provider to your assistant) is authenticated using SIP digest authentication, and must be sent using Transport Layer Security (TLS). If this option is selected, the SIP digest user name and password must be configured, and the SIP trunk being used to connect to Assistant must be configured to use only TLS.\n\nIf you use Twilio as your SIP trunk provider, you cannot enable SIP authentication for outbound SIP trunks to Watson Assistant.\n\n\n\n\n\n\n\n Apply advanced SIP trunk configuration settings \n\n\n\n* SIP INVITE headers to extract: List headers that you want to use in your dialog.\n\nThe SIP request often sends INVITE headers with information about the request that is used by the SIP network.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone"}, {"document_id": "ibmcld_16250-5445-7809", "score": 26.439376703407184, "text": "\nTo support disaster recovery, the service provider may need to configure two separate SIP trunks, one for each region, and only when all the zones in a single region fail should the call be switched to the backup region. It's important to set the SIP INVITE failure timeouts at the SIP trunking provider low enough to avoid long call setup latencies when a failover is occurring.\n\n\n\n\n\n Partial service outage \n\nThe second type of failure is a partial service outage within the region. This is much harder to detect and manage because of the large number of variations in service failures that can occur within a region. In some cases, these may be small issues that affect the performance characteristics of the call but not cause the call to fail.\n\nFor issues like this that ultimately cause a call to fail, there are two ways Watson Assistant can handle the call. The first is to accept the call and then transfer it to a configured default SIP URI. This can be configured in the Watson Assistant phone integration settings and is also used if there is a mid-call failure. The default transfer target SIP URI is defined in the SIP target when a call fails field located on the Advanced tab of the phone integration configuration panel.\n\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call. Using only the default transfer target to handle call failures is acceptable for low call volume scenarios but can result in large numbers of calls being directed to a customer contact center when bigger call volumes are handled by Watson Assistant. To enable this 500 error response capability for a specific Watson Assistant instance, you need to make a request to IBM.\n\nYou should plan for both full and partial service outages. A good first step is to plan for a manual failover between regions before enabling automation. This requires a complete replica of Watson Assistant in both regions, including all custom speech model training.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-failover"}, {"document_id": "ibmcld_03158-16828-18419", "score": 26.375229043153123, "text": "\nYou can set up a SIP trunk in the following ways:\n\n\n\n* [Create a Twilio SIP trunk](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-twilio-setup)\n* [Use other third-party providers](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-request-setup)\n* [Bring your own SIP trunk](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-byost)\n* [Migrate from Voice Agent with Watson](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phonedeploy-phone-migrate-from-va)\n\n\n\n\n\n Creating a Twilio SIP trunk \n\nTo set up a Twilio SIP trunk, complete the following steps:\n\n\n\n1. Create a Twilio account on the [Twilio website](https://www.twilio.com/sip-trunking).\n2. From the Twilio website, go to the Elastic SIP Trunking dashboard.\n3. Select Trunks from the navigation bar and create a SIP trunk. If you already have a SIP trunk, click the plus sign (+). Enter a name for your SIP trunk and click Create.\n4. From the Elastic SIP Trunks page, select your SIP trunk.\n5. Select Origination from the navigation bar for your SIP trunk and configure the origination SIP URI.\n\nYou can get the SIP URI for your phone integration from the phone integration configuration page.\n6. If you plan to support call transfers, enable Call Transfer (SIP REFER) in your SIP trunk. If you expect to transfer calls to the public switched telephone network (PSTN), also enable PSTN Transfer on your trunk.\n7. Select Numbers from the navigation bar for your SIP trunk, and then do one of the following things:\n\n\n\n* Click Buy a Number.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-phone"}, {"document_id": "ibmcld_03312-5487-7760", "score": 26.31480407026423, "text": "\nIf a failover is automated and a regional backup is enabled, it is always best to try a different zone first and only redirect traffic to the passive backup region if a preconfigured number of failures occur within a short period of time. This prevents an unnecessary failover between regions if only a short outage occurs.\n\nNote that Watson Assistant provides a round-robin fully qualified domain name (FQDN) that includes the IPs for each zone in the region. Many SIP trunking providers automatically retry each IP in the FQDN when failures occur. To support disaster recovery, the service provider may need to configure two separate SIP trunks, one for each region, and only when all the zones in a single region fail should the call be switched to the backup region. It's important to set the SIP INVITE failure timeouts at the SIP trunking provider low enough to avoid long call setup latencies when a failover is occurring.\n\n\n\n\n\n Partial service outage \n\nThe second type of failure is a partial service outage within the region. This is much harder to detect and manage because of the large number of variations in service failures that can occur within a region. In some cases, these may be small issues that affect the performance characteristics of the call but not cause the call to fail.\n\nFor issues like this that ultimately cause a call to fail, there are two ways Watson Assistant can handle the call. The first is to accept the call and then transfer it to a configured default SIP URI. This can be configured in the Watson Assistant phone integration settings and is also used if there is a mid-call failure. The default transfer target SIP URI is defined in the SIP target when a call fails field located on the Advanced tab of the phone integration configuration panel.\n\nThe phone integration can also be configured to respond to a SIP INVITE with a SIP 500 (service unavailable) message if an outage is detected during call setup instead of transferring a call to a live agent. A SIP 500 can then be used to redirect the call to another zone, or if many SIP 500s are received, to another region. Using a SIP 500 INVITE error is a better way to signal a failure to an upstream SIP trunking provider because it gives the provider a way to reroute the call.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-failover"}]}
{"task_id": "4c86c8740c3d49e06b7aca9d308119fa<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_05342-35727-36837", "score": 10.076839345612527, "text": "\n_) / /( (_ )( / / ) _)\n(____)_)__) ___/(__)_)__)(____)\n\nSome Env Vars:\n--------------\nHOME=/root\nHOSTNAME=myjobrunresubmit2-2-0\nJOB_INDEX=2\nKUBERNETES_PORT=tcp://172.21.0.1:443\nKUBERNETES_PORT_443_TCP=tcp://172.21.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=172.21.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=172.21.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nPWD=/\nSHLVL=1\nTARGET=My new big literal secret\n\n\n\nTo summarize, you completed basic scenarios to demonstrate how to use secrets with a job by referencing an existing full secret and updating keys within a secret.\n\n\n\n\n\n Referencing secrets that are not yet defined with the CLI \n\nIf a secret does not exist before it is referenced, an app will not deploy successfully, and a job will not run successfully until the referenced secret is created.\n\nIf you are working with an app or a job and the referenced secret is not yet defined, use the --force option to avoid verification of the existence of the referenced secret.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-configmap-secret"}, {"document_id": "ibmcld_05436-35667-36777", "score": 10.076839345612527, "text": "\n_) / /( (_ )( / / ) _)\n(____)_)__) ___/(__)_)__)(____)\n\nSome Env Vars:\n--------------\nHOME=/root\nHOSTNAME=myjobrunresubmit2-2-0\nJOB_INDEX=2\nKUBERNETES_PORT=tcp://172.21.0.1:443\nKUBERNETES_PORT_443_TCP=tcp://172.21.0.1:443\nKUBERNETES_PORT_443_TCP_ADDR=172.21.0.1\nKUBERNETES_PORT_443_TCP_PORT=443\nKUBERNETES_PORT_443_TCP_PROTO=tcp\nKUBERNETES_SERVICE_HOST=172.21.0.1\nKUBERNETES_SERVICE_PORT=443\nKUBERNETES_SERVICE_PORT_HTTPS=443\nPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nPWD=/\nSHLVL=1\nTARGET=My new big literal secret\n\n\n\nTo summarize, you completed basic scenarios to demonstrate how to use secrets with a job by referencing an existing full secret and updating keys within a secret.\n\n\n\n\n\n Referencing secrets that are not yet defined with the CLI \n\nIf a secret does not exist before it is referenced, an app will not deploy successfully, and a job will not run successfully until the referenced secret is created.\n\nIf you are working with an app or a job and the referenced secret is not yet defined, use the --force option to avoid verification of the existence of the referenced secret.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-secret"}, {"document_id": "ibmcld_05557-5511-7293", "score": 9.464892719844118, "text": "\nIn Kubernetes cluster versions 1.21 and later, Konnectivity replaced the OpenVPN solution. If you have cluster version 1.21 and later, and your webhook uses the ClusterIP, you must update your webhook to use a Kubernetes service instead.\n\nYou can configure a webhook by referencing the webhook app as a Kubernetes service, or by referencing the webhook app as an IP address or publicly registered DNS name.\n\nExample configuration for referencing the webhook app as a Kubernetes service\n\n {: codeblock}\nclientConfig:\ncaBundle: CA_BUNDLE_BASE64\nservice:\nname: admission-webhook\nnamespace: default\npath: /validate\nport: 443\n\nExample configuration for referencing the webhook app as an IP address or publicly registered DNS name\n\n {: codeblock}\nclientConfig:\ncaBundle: CA_BUNDLE_BASE64\nurl: https://WEBHOOK_URL:443/validate\n\nShow more\n\nNote the following limitations for referencing the webhook app as an IP address or DNS name:\n\n\n\n* If the URL is a DNS, then this DNS must be a publicly registered DNS name. Private DNS configurations are not supported.\n* If the URL is an external IP address, which means the webhook service is outside of the cluster, the control plane network is used to connect to the service. The control plane must be able to reach the IP address. If, for example, the IP address is from an on-premises network and the control plane can't reach the IP address, the webhook service does not work.\n* If the URL is a cluster IP address, which means the webhook service is inside of the cluster, the Kubernetes API needs to connect to cluster network. If you have cluster version 1.21 and later, and your webhook uses the cluster IP address, you must update your webhook to use a Kubernetes service instead.\n\n\n\n\n\n\n\n\n\n I need help with a broken webhook. What can I do?", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-access_webhooks"}, {"document_id": "ibmcld_11886-2994-4812", "score": 9.451643185265464, "text": "\nFor more information, see the [Kubernetes documentation](https://kubernetes.io/docs/reference/access-authn-authz/authorization/).\n\nIf you choose a custom access option, some Satellite Config components might not work. For example, if you grant access to view only certain resources, you cannot use subscriptions to create Kubernetes resources in your cluster group. To view an inventory of your Kubernetes resources in a cluster, Satellite Config must have an appropriate role that is bound to the razee-viewer service account. To deploy Kubernetes resources to a cluster by using subscriptions, Satellite Config must have an appropriate role that is bound to the razee-editor service account.\n\n\n\n\n\n Cluster admin access \n\nGrant the Satellite Config service accounts access to the cluster admin role.\n\nkubectl create clusterrolebinding razee-cluster-admin --clusterrole=razee-cluster-admin --serviceaccount=razeedeploy:razee-viewer --serviceaccount=razeedeploy:razee-editor --serviceaccount=razeedeploy:razee-satcon\n\n\n\n\n\n Custom access, cluster-wide \n\nCreate custom RBAC policies to grant Satellite Config access to the actions and Kubernetes resources that you want for the cluster.\n\n\n\n1. Create a cluster role with the actions and resources that you want to grant. For example, the following command creates a viewer role so that Satellite Config can list all the Kubernetes resources in a cluster, but cannot modify them.\n\nkubectl create clusterrole razee-viewer --verb=get,list,watch --resource=\".\"\n\n\n\nUnderstanding this command's components\n\n Component Description \n\n razee-viewer The name of the cluster role, such as razee-viewer. \n --verb=get,list,watch A comma-separated list of actions that the role authorizes. In this example, the action verbs are for roles typical for a viewer or auditor, get,list,watch.", "title": "", "source": "https://cloud.ibm.com/docs/satellite?topic=satellite-setup-clusters-satconfig"}, {"document_id": "ibmcld_02683-2805-4831", "score": 9.295348710075782, "text": "\nFor your application and SDK to continue operations during the unlikely scenario of an App Configuration service downtime, across your application restarts, you can configure the SDK to work by using a persistent cache. The SDK uses the persistent cache to store the App Configuration data that is available across your application restarts.\n\n// 1. default (without persistent cache)\nappConfigClient.setContext(collectionId, environmentId);\n\n// 2. optional (with persistent cache)\nConfigurationOptions configOptions = new ConfigurationOptions();\nconfigOptions.setPersistentCacheDirectory(\"/var/lib/docker/volumes/\");\nappConfigClient.setContext(collectionId, environmentId, configOptions);\n\nWhere:\n\n\n\n* persistentCacheDirectory: Absolute path to a directory that has read and write permission for the user. The SDK creates a file - appconfiguration.json in the specified directory, and it is used as the persistent cache to store the App Configuration service information.\n\n\n\nWhen persistent cache is enabled, the SDK keeps the last known good configuration at the persistent cache. If the App Configuration server being unreachable, the latest configurations at the persistent cache are loaded to the application to continue working.\n\nEnsure that the cache file is not lost or deleted in any case. For example, consider the case when a kubernetes pod is restarted and the cache file (appconfiguration.json) was stored in ephemeral volume of the pod. As pod gets restarted, kubernetes destroys the ephermal volume in the pod, as a result the cache file gets deleted. So, make sure that the cache file created by the SDK is always stored in persistent volume by providing the correct absolute path of the persistent directory.\n\n\n\n\n\n Offline options \n\nThe SDK is also designed to serve configurations, and perform feature flag and property evaluations without being connected to App Configuration service.\n\nConfigurationOptions configOptions = new ConfigurationOptions();\nconfigOptions.setBootstrapFile(\"saflights/flights.json\");", "title": "", "source": "https://cloud.ibm.com/docs/app-configuration?topic=app-configuration-ac-java"}, {"document_id": "ibmcld_06123-1617-3175", "score": 8.807838459223795, "text": "\nRPO (Recovery Point Objective) and RTO (Recovery Time Objective) for this configuration is less than 60 seconds.\n* [Asynchronous DR](https://docs.portworx.com/portworx-install-with-kubernetes/disaster-recovery/2-asynchronous-dr-nodes-are-across-different-regions-datacenters): Your Kubernetes clusters are deployed in different regions, such as us-south and us-east. Each cluster has its own Portworx installation and uses a separate Portworx key-value store that is not shared. To replicate data between clusters, you must set up scheduled replication between these clusters. Because of the higher latency and scheduled replication times, the RPO for this scenario might be up to 15 minutes.\n\n\n\nTo include your cluster in a Portworx disaster recovery configuration:\n\n\n\n1. [Choose the disaster recovery configuration that works for your cluster setup](https://docs.portworx.com/portworx-install-with-kubernetes/disaster-recovery/).\n2. Review the prerequisites for the [Metro DR](https://docs.portworx.com/portworx-install-with-kubernetes/disaster-recovery/px-metro/1-install-px/prerequisites) and [Asynchronous DR](https://docs.portworx.com/portworx-install-with-kubernetes/disaster-recovery/async-dr/pre-requisites) configuration.\n3. Configure disaster recovery for your cluster. Metro DR:\n\n\n\n1. Choose at least two Kubernetes clusters that are located in the same metro location. If you have one cluster only, you can still configure this cluster for metro disaster recovery, but Portworx can't do a proper failover until a second cluster is configured.\n2.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-storage_portworx_recovery"}, {"document_id": "ibmcld_06004-14210-16020", "score": 8.497917045193368, "text": "\nPods that are managed by a daemon set are automatically scheduled when a worker node is added to a cluster. Typical use cases include log collectors, such as logstash or prometheus, that collect logs from every worker node to provide insight into the health of a cluster or an app. \n [Job](https://kubernetes.io/docs/concepts/workloads/controllers/job/) A job ensures that one or more pods run successfully to completion. You might use a job for queues or batch jobs to support parallel processing of separate but related work items, such as specific frames to render, emails to send, and files to convert. To schedule a job to run at certain times, use a [CronJob](https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/). \n\n\n\n\n\n\n\n What if I want my app configuration to use variables? How do I add these variables to the YAML? \n\nTo add variable information to your deployments instead of hardcoding the data into the YAML file, you can use a Kubernetes [ConfigMap](https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/) or [Secret](https://kubernetes.io/docs/concepts/configuration/secret/) object.\n\nTo consume a ConfigMap or secret, you need to mount it to the pod. The ConfigMap or secret is combined with the pod just before the pod is run. You can reuse a deployment spec and image across many apps, but then swap out the customized configmaps and secrets. Secrets in particular can take up a lot of storage on the local node, so plan accordingly.\n\nBoth resources define key-value pairs, but you use them for different situations.\n\nConfigmap\n: Provide non-sensitive configuration information for workloads that are specified in a deployment. You can use configmaps in three main ways.\n\n\n\n* File system: You can mount an entire file or a set of variables to a pod.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-plan_deploy"}, {"document_id": "ibmcld_10439-18453-20263", "score": 8.497917045193368, "text": "\nPods that are managed by a daemon set are automatically scheduled when a worker node is added to a cluster. Typical use cases include log collectors, such as logstash or prometheus, that collect logs from every worker node to provide insight into the health of a cluster or an app. \n [Job](https://kubernetes.io/docs/concepts/workloads/controllers/job/) A job ensures that one or more pods run successfully to completion. You might use a job for queues or batch jobs to support parallel processing of separate but related work items, such as specific frames to render, emails to send, and files to convert. To schedule a job to run at certain times, use a [CronJob](https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/). \n\n\n\n\n\n\n\n What if I want my app configuration to use variables? How do I add these variables to the YAML? \n\nTo add variable information to your deployments instead of hardcoding the data into the YAML file, you can use a Kubernetes [ConfigMap](https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/) or [Secret](https://kubernetes.io/docs/concepts/configuration/secret/) object.\n\nTo consume a ConfigMap or secret, you need to mount it to the pod. The ConfigMap or secret is combined with the pod just before the pod is run. You can reuse a deployment spec and image across many apps, but then swap out the customized configmaps and secrets. Secrets in particular can take up a lot of storage on the local node, so plan accordingly.\n\nBoth resources define key-value pairs, but you use them for different situations.\n\nConfigmap\n: Provide non-sensitive configuration information for workloads that are specified in a deployment. You can use configmaps in three main ways.\n\n\n\n* File system: You can mount an entire file or a set of variables to a pod.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-plan_deploy"}, {"document_id": "ibmcld_07578-534510-536520", "score": 8.48050214573938, "text": "\nThe multiple worker agents are now listed in the private worker integration UI and jobs are scheduled on those agents based on the cluster load at pipeline run request time.\n* How do I view the status of private workers on multiple clusters by using the CLI?\n\nYou can use the following command within a script that traverses all of the clusters that private workers are installed on.\n\nkubectl get workeragent -ojson | jq '.items[] | .status.versionStatus.state'\n\nConsider upgrading any private workers that return results that are not OK.\n* Which attributes can I use for private worker agents?\n\nThe following attributes are available for private worker agents:\n\n\n\n* NAME: The name that was specified when the agent was registered. This name appears on the Private Worker integration page.\n* SERVICEID: The work queue ID from which this agent processes work requests.\n* AGENT: A value of OK indicates that the agent can process work requests.\n* REGISTERED: A value of Succeeded indicates that the agent successfully registered with the regional private worker service.\n* VERSION: A value of OK indicates whether the version of the agent is current.\n* AUTH: A value of OK indicates whether the agent apikey is valid.\n* CONSTRAINED: A value of false indicates that enough cluster resources are available for the agent to run tasks. A value of True specifies that the cluster is resource-constrained.\n* PAUSED: A value of false indicates that the agent is operational and can run tasks. A value of true specifies that the agent is paused and cannot run any tasks. One reason that an agent might be paused is for cluster maintenance.\n\n\n\n* How do I set my ClusterImagePolicy so that I can access Tekton images?\n\nBecause Delivery Pipeline private workers depend on the Tekton and tekton-pipelines infrastructure, they must pull tekton-releases images from icr.io (icr.io/continuous-delivery/pipeline/). You might need to define a specific Kubernetes ClusterImagePolicy to pull images from these container registries.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-534464-536474", "score": 8.48050214573938, "text": "\nThe multiple worker agents are now listed in the private worker integration UI and jobs are scheduled on those agents based on the cluster load at pipeline run request time.\n* How do I view the status of private workers on multiple clusters by using the CLI?\n\nYou can use the following command within a script that traverses all of the clusters that private workers are installed on.\n\nkubectl get workeragent -ojson | jq '.items[] | .status.versionStatus.state'\n\nConsider upgrading any private workers that return results that are not OK.\n* Which attributes can I use for private worker agents?\n\nThe following attributes are available for private worker agents:\n\n\n\n* NAME: The name that was specified when the agent was registered. This name appears on the Private Worker integration page.\n* SERVICEID: The work queue ID from which this agent processes work requests.\n* AGENT: A value of OK indicates that the agent can process work requests.\n* REGISTERED: A value of Succeeded indicates that the agent successfully registered with the regional private worker service.\n* VERSION: A value of OK indicates whether the version of the agent is current.\n* AUTH: A value of OK indicates whether the agent apikey is valid.\n* CONSTRAINED: A value of false indicates that enough cluster resources are available for the agent to run tasks. A value of True specifies that the cluster is resource-constrained.\n* PAUSED: A value of false indicates that the agent is operational and can run tasks. A value of true specifies that the agent is paused and cannot run any tasks. One reason that an agent might be paused is for cluster maintenance.\n\n\n\n* How do I set my ClusterImagePolicy so that I can access Tekton images?\n\nBecause Delivery Pipeline private workers depend on the Tekton and tekton-pipelines infrastructure, they must pull tekton-releases images from icr.io (icr.io/continuous-delivery/pipeline/). You might need to define a specific Kubernetes ClusterImagePolicy to pull images from these container registries.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "d5b1e735a040853ed361a3dfde1b8ef0<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_00546-2347-3956", "score": 34.081358090006525, "text": "\ndisk_size Size in bytes of the data as stored on the disk. Views indexes aren't included in the calculation. \n doc_count A count of the documents in the specified database. \n doc_del_count Number of deleted documents. \n instance_start_time Always 0. \n other JSON object that contains a data_size field. \n purge_seq The number of purge operations on the database. \n sizes A JSON object, containing file, external, and active sizes. active is the size in bytes of data that is stored internally (excluding old revisions). external is the size in bytes of decompressed user data. This value is the billable data size. The other/data_size field is an alias for the external field. file is the size in bytes of data that is stored on the disk. Indexes aren't included in the calculation. The disk_size field is an alias for the file field. This size includes data that is waiting for compaction. \n update_seq An opaque string that describes the state of the database. Don't rely on this string for counting the number of updates. \n partitioned_indexes A JSON object that appears only if the database is partitioned. count is the number of partitioned indexes. indexes list the type of partitioned indexes, and limit shows the maximum number of allowed partitioned indexes. \n\n\n\nSee the following example (abbreviated) response that contains database details:\n\n{\n\"update_seq\": \"982...uUQ\",\n\"db_name\": \"db\",\n\"sizes\": {\n\"file\": 46114703224,\n\"external\": 193164408719,\n\"active\": 34961621142\n},\n\"purge_seq\": 0,\n\"other\": {\n\"data_size\": 193164408719\n},\n\"doc_del_count\": 5564,\n\"doc_count\": 9818541,\n\"disk_size\": 46114703224,", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-database-details"}, {"document_id": "ibmcld_00580-6386-8382", "score": 31.956491096507396, "text": "\nIt has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.\n\nDevelopers like this flexibility because they can design their data in their code, turn it into JSON, and write it to the database.\n\nIt's still important to think about the shape of your data, especially in terms of how you are going to query and index it, as we see later.\n\nData design is still required, but strictly speaking that database doesn't need to know about your schema.\n\nLet's say we want to create a database of US presidents. We can simply devise our \"model\" of the data in our app, turn it into JSON, and write it to the database. In this case, we are using a common CouchDB convention: the \"type\" field indicates the data type of the document.\n\nIf at a future date we decide we want to add more data to our \"schema\", we can simply write a new object to the database with no complaints from IBM Cloudant. We could decide to add the \"address\" object only to the following documents:\n\n\n\n* Documents that are created from now on.\n* Only documents that we have addresses for.\n\n\n\nIn other words, documents of the same type can have fields present or missing.\n\nYour database's schema can evolve over time to match your application's needs. You don't (necessarily) need to tell the database about the schema change - write new documents in the new format.\n\nWe can even store multiple document \"types\" in the same database. In this case, people, books, and places reside in the same database. We know which is which because of the \"type\" field (this field is a convention and not something that means anything to IBM Cloudant).", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_00546-1171-2777", "score": 30.98727846897091, "text": "\n\"products\",\n)\n\ndatabaseInformation, response, err := service.GetDatabaseInformation(getDatabaseInformationOptions)\nif err != nil {\npanic(err)\n}\n\nb, _ := json.MarshalIndent(databaseInformation, \"\", \" \")\nfmt.Println(string(b))\n\nconst { CloudantV1 } = require('@ibm-cloud/cloudant');\n\nconst service = CloudantV1.newInstance({});\n\nservice.getDatabaseInformation({db: 'products'}).then(response => {\nconsole.log(response.result);\n});\n\nThe previous Go example requires the following import block:\n\nimport (\n\"encoding/json\"\n\"fmt\"\n\"github.com/IBM/cloudant-go-sdk/cloudantv1\"\n)\n\nAll Go examples require the service object to be initialized. For more information, see the API documentation's [Authentication section](https://cloud.ibm.com/apidocs/cloudant?code=goauthentication-with-external-configuration) for examples.\n\nThe elements of the returned structure are shown in the following table:\n\n\n\nTable 1. Database details\n\n Field Description \n\n compact_running Set to true if the database compaction routine is operating on this database. \n db_name The name of the database. \n disk_format_version The version of the physical format that is used for the data that is stored on disk. \n disk_size Size in bytes of the data as stored on the disk. Views indexes aren't included in the calculation. \n doc_count A count of the documents in the specified database. \n doc_del_count Number of deleted documents. \n instance_start_time Always 0. \n other JSON object that contains a data_size field. \n purge_seq The number of purge operations on the database. \n sizes A JSON object, containing file, external, and active sizes.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-getting-database-details"}, {"document_id": "ibmcld_07163-5129-7116", "score": 30.18878440586579, "text": "\nWe recommend that you apply both available ratings to your results: Relevant and Not relevant. Only rating the Relevant documents does not provide the data needed. If you plan to score your documents, using both the Discovery tooling and the API, or if you plan to begin with the API and move to the tooling, use the 0 and 10 relevancy scores.\n* A random sample of documents that are not explicitly given a relevance rating is assigned a relevance score of 0. It is not mandatory to apply a relevance score of 0 when you train your documents, but if you apply a relevance score of 0 to certain documents, relevancy training marks those documents as non-relevant examples, instead of treating them as a random sample of results from the query.\n* The training queries must include some term overlap between the query and the desired answer so it can be retrieved by the Discovery service's initial search, which is broad in scope.\n\n\n\nWatson uses training data to learn patterns and to generalize, not to memorize individual training queries. The service, therefore, might not always reproduce identical relevance results for any given training query.\n\nTraining cannot exceed the following maximum requirements:\n\n\n\n* You cannot exceed 40 trained collections per environment.\n* Within a single collection, you are limited to 10,000 training queries, with a maximum of 100 examples per query.\n\n\n\n\n\n\n\n Adding a query to the training-data set \n\nUse the POST /v1/environments/{environment_id}/collections/{collection_id}/training_data method to add a query to a collection's set of training data. The query is specified as a JSON object in the following format:\n\n{\n\"query_id\": \"string\",\n\"natural_language_query\": \"string\",\n\"filter\": \"string\",\n\"examples\": [\n{\n\"document_id\": \"string\",\n\"cross_reference\": \"string\",\n\"relevance\": 0\n}\n]\n}\n\nThe values in this object are as follows:\n\n\n\n* query_id: A unique ID for the query. If you do not specify this field, the service automatically generates an ID.", "title": "", "source": "https://cloud.ibm.com/docs/discovery?topic=discovery-improving-result-relevance-with-the-api"}, {"document_id": "ibmcld_07046-11817-13746", "score": 29.800961909733036, "text": "\nHowever, a different document ID was assigned to it and stored in the parent_document_id field. The assigned document ID is what was returned when you called the List documents method and is what had to be used as the document_id in the endpoint URL for a Delete document method request. When you used the Update document method to assign a new document_id, the original ID continued to be returned in query results. However, the assigned ID had to be used to delete the document. If you have an application that relies on the previous behavior, you can specify a version number earlier than 2023-03-31, such as 2020-08-30, in your API calls.\n\n\n\nNotes about enhancing data:\n\n\n\n* You cannot apply prebuilt or user-trained Smart Document Understanding models to JSON files.\n* When you apply an enrichment to a field from the JSON file, the field data type is converted to an array. The field is converted to an array even if it contains a single value. For example, \"field1\": \"Discovery\" becomes \"field1\": [\"Discovery\"].\n* Only the first 50,000 characters of a custom field from a JSON file are enriched.\n* In project types where the Part of Speech (POS) enrichment is applied automatically, the enrichment is applied to the field that contains the bulk of the file content in the first JSON file that is added to the collection. This field is determined by the following rules:\n\n\n\n* If a field is named text, the POS enrichment is applied to it.\n* The field with the longest string value and highest number of distinct values is chosen.\n* If more than one field meets the previous condition, one of the fields is chosen at random.\n\n\n\n* If you want to apply an enrichment to a nested field, you must create a Content Mining project, and then apply the enrichment to the field. If you want to use a project type other than Content Mining, you can reuse the collection that you created with the Content Mining project type elsewhere.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-index-overview"}, {"document_id": "ibmcld_00580-4796-6846", "score": 29.516614323454455, "text": "\nAn IBM Cloudant document must be a JSON object, starting and ending with curly braces and containing a number of key-value attributes.\n\nJSON objects must be less that 1 megabyte in size and contain any number of strings, numbers, booleans, arrays, and objects. The nesting of objects within objects can continue to any depth.\n\nThe keys that are used can be as brief or verbose as you like.\n\nThe following list includes some simple example documents that show how each data type is used.\n\n\n\n* The first example shows a person object, storing strings, booleans, and an array of tags.\n* The second example shows brief attribute names to save on storage and represents a web event such as click a website.\n* The last example shows how the document may itself contain subjects.\n\n\n\nA note on dates. JSON has no native Date type, so dates are usually stored in 30-October-2018 or similar formats. We return to dates later.\n\nNow, for your first practical exercise, visit www.ibm.com/cloud. Register an account with the IBM Cloud, if you don't have one already.\n\nOnce registered, you can click services, search for the Cloudant database, and provision a new service.\n\nThe IBM Cloudant Lite service provides a free plan to allow users to try IBM Cloudant in a limited capacity while in development. Its bigger brother, the Standard Plan, is a paid-for service where you specify the number of reads, writes, and queries per second for your application and that capacity is reserved for you. You pay for the capacity you provision and your data storage usage.\n\nThe Lite plan operates in a similar way. It has only a small provisioned capacity and a fixed storage size, but it's fine for testing the IBM Cloudant service.\n\nIBM Cloudant is often referred to as a \"schemaless\" database - but we have to be careful how we define that term.\n\nIt's true to say that you don't need to define your schema (field names, types, constraints, and relationships) ahead of time in an IBM Cloudant database. You can simply write a JSON document of your own design to a database.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_00580-37889-39953", "score": 29.339538624548, "text": "\nIf you need to access objects within documents, you can use standard dot notation for example, address.zipcode to access a postal code string inside an address object.\n\nWe can also add the following parameters:\n\nFields\n: Specifies the document attributes that we want returned (the default is the entire document).\n\nSort\n: Defines how the data is to be sorted. Sort is an array, allowing the sort to be calculated on multiple attributes.\n\nLimit\n: The number of documents to return.\n\nIf you are from a relational database background, this query is the equivalent SQL query to that last IBM Cloudant query example.\n\nThe WHERE clause is the equivalent of SELECTOR in IBM Cloudant Query. ORDER and LIMIT are exactly equivalent, and the IBM Cloudant Query FIELDS list is equivalent to the comma-separated list of attributes after the SELECT keyword.\n\nThe JSON syntax might take a bit of getting used to, but MongoDB users might find it familiar.\n\nIBM Cloudant queries can be executed in the IBM Cloudant Dashboard. Select the database that you are working with, for example, books then choose the Query tab.\n\nEnter your IBM Cloudant Query JSON in the box that is provided, and click Run Query when you're ready. The result set appears on the page.\n\nThe Explain button is used to provide an explanation on how the database interprets the supplied query. This explanation becomes more important when we get to Indexing in the next part.\n\nQueries can be triggered from curl too. The Query JSON, in this case, is stored in a file and we POST to the _find endpoint by using the -d@ command-line syntax.\n\nThe Node.js code is similar. The Query is a standard JavaScript object, which is passed to the db.find function which it POSTs to the _find endpoint on your behalf.\n\nNow, time for a practical exercise. Devise your own IBM Cloudant Query that finds the titles of books that are written in the 20th Century. The IBM Cloudant Query documentation is at the on-screen URL if you need it.\n\nPause the presentation here if you don't want to know the answer...\n\nSee one solution:", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_07046-13262-15106", "score": 29.26490385313131, "text": "\n* The field with the longest string value and highest number of distinct values is chosen.\n* If more than one field meets the previous condition, one of the fields is chosen at random.\n\n\n\n* If you want to apply an enrichment to a nested field, you must create a Content Mining project, and then apply the enrichment to the field. If you want to use a project type other than Content Mining, you can reuse the collection that you created with the Content Mining project type elsewhere. For more information, see [Applying enrichments](https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-connector-database-cp4dconnector-database-cp4d-enrich-db).\n\n\n\nYou can specify the normalizations and conversions objects in the [Update a collection](https://cloud.ibm.com/apidocs/discovery-dataupdatecollection) method of the API to move or merge JSON fields.\n\n\n\n\n\n\n\n How passages are derived \n\nDiscovery uses sophisticated algorithms to determine the best passages of text from all of the documents that are returned by a query. Passages are returned per document by default. They are displayed as a section within each document query result and are ordered by passage relevance.\n\nDiscovery uses sentence boundary detection to pick a passage that includes a full sentence. It searches for passages that have an approximate length of 200 characters, then looks at chunks of content that are twice that length to find passages that contain full sentences. Sentence boundary detection works for all supported languages and uses language-specific logic.\n\nFor all project types except Conversational Search, you can change how the passages are displayed in the search results from the Customize display > Search results page. For example, you can configure the number of passages that are shown per document and the maximum character size per passage.", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-index-overview"}, {"document_id": "ibmcld_00580-7918-10060", "score": 29.119599889089006, "text": "\nYour database's schema can evolve over time to match your application's needs. You don't (necessarily) need to tell the database about the schema change - write new documents in the new format.\n\nWe can even store multiple document \"types\" in the same database. In this case, people, books, and places reside in the same database. We know which is which because of the \"type\" field (this field is a convention and not something that means anything to IBM Cloudant).\n\nAn alternative to this configuration is to have three databases people, books, and places and keep each data type in its own database. Both approaches are fine. You can choose to have multiple types together in the same database if you need to perform queries across types or if you need to replicate all data types together. Otherwise, the separate databases approach might be better.\n\nTo summarize, although IBM Cloudant is \"schemaless\", this fact doesn't absolve you of the need to do detailed data design to get the best performance.\n\nThese tips are especially relevant if you have some relational database experience.\n\n\n\n* Avoid thinking in joins - an IBM Cloudant document must contain everything that you need about that object so that it can be retrieved in one API call.\n* Normalization goes out of the window in JSON store, some repeated values can be tolerated if it makes data retrieval more efficient.\n* Although we have a 1 MB limit on document size, your documents must be much smaller - a few KB is typical.\n* If your application can embrace a \"write only\"* design pattern, where data is only ever added to a database, then it can make your life easier. You must definitely avoid patterns that rely on updating the same document over and over in a small time window.\n\n\n\nThat's the end of this part. The next part is called The Document ID.\n\n\n\n\n\n\n\n The _id video \n\nLearn how _ids work in IBM Cloudant, how they are different from relational databases, and how you can define your own _id.\n\n\n\n* The _id video script\n\nWelcome to the Introduction to IBM Cloudant course, an 17-part video series that gives you an overview of the IBM Cloudant database-as-a-service.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-learning-center"}, {"document_id": "ibmcld_03893-39361-41102", "score": 29.039859914867996, "text": "\n\"format\": \"%{color}%{time:2006-01-02 15:04:05.000 MST} [%{module}] %{shortfunc} -> %{level:.4s} %{id:03x}%{color:reset} %{message}\"\n}\n},\n\"metrics\": {\n\"provider\": \"disabled\",\n\"statsd\": {\n\"network\": \"udp\",\n\"address\": \"127.0.0.1:8125\",\n\"writeInterval\": \"10s\",\n\"prefix\": null\n}\n}\n}\nShow more\n\n\n\n\n\n Providing your own customizations when you create a peer \n\nAfter you click Create a peer on the nodes tab and step through the peer configuration panels, you can click Edit configuration on the Summary panel to view and edit the JSON. Note that if you do not select any advanced options in the console, then the generated JSON is empty, but you can still insert your own customizations.\n\nAlternatively, if you do check any of the advanced options when you configure the peer, those settings are included in the JSON on the Summary panel and can be additionally customized with other fields as needed. Any edits that you make will override what was specified in the console. For example, if you selected to use a LevelDB as the state database, but then overrode the setting to use CouchDB as the state database in the JSON, then the CouchDB database settings would be used when the peer is deployed. The override settings that are visible in the JSON on the Summary page are what is used when the peer is deployed.\n\nYou don't need to include the entire set of available parameters in the JSON, only the advanced deployment options that you selected in the console along with the parameters that you want to override. For example, if you want to deploy a peer and override the chaincode startup timeout and specify a different port for the statsd address, you would paste in the following JSON:\n\n{\n\"peer\": {\n\"chaincode\": {\n\"startuptimeout\": \"600s\"\n}", "title": "", "source": "https://cloud.ibm.com/docs/blockchain?topic=blockchain-ibp-console-adv-deployment"}]}
{"task_id": "be461bfeda2d4826cdb663dcaa7d1ced<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06209-6757-8643", "score": 46.989810549416454, "text": "\n* [Updating classic worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node).\n* [Updating VPC worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updatevpc_worker_node).\n\n\n\n\n\n\n\n\n\n Updating classic worker nodes \n\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https://cloud.ibm.com/docs/containers?topic=containers-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_10394-7-1848", "score": 46.89745963275591, "text": "\nUpdating Classic worker nodes that use OpenShift Data Foundation \n\nClassic infrastructure\n\nFor Classic clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor worker node updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-classic"}, {"document_id": "ibmcld_10642-6354-8294", "score": 46.70524515879658, "text": "\nYou notice that an update is available for your worker nodes in a [classic infrastructure](https://cloud.ibm.com/docs/openshift?topic=openshift-infrastructure_providers) cluster. What does that mean? As security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only classic clusters. Have a VPC cluster? See [Updating VPC worker nodes](https://cloud.ibm.com/docs/openshift?topic=openshift-updatevpc_worker_node) instead.\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud oc worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can only be one version behind the master version (n-1). You can update the classic worker node to the same patch by using the ibmcloud oc worker update command.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-update"}, {"document_id": "ibmcld_06209-8154-10055", "score": 44.602636264443376, "text": "\n* Patch: A worker node patch update includes security fixes. You can update the classic worker node to the latest patch by using the ibmcloud ks worker reload or update commands. Keep in mind that the update command also updates the worker node to the same major.minor version as the master and latest patch version, if a major.minor version update is also available.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the classic worker node to the same patch by using the ibmcloud ks worker update command.\n\n\n\nFor more information, see [Update types](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types).\n\nWhat happens to my apps during an update?\n: If you run apps as part of a deployment on worker nodes that you update, the apps are rescheduled onto other worker nodes in the cluster. These worker nodes might be in a different worker pool, or if you have stand-alone worker nodes, apps might be scheduled onto stand-alone worker nodes. To avoid downtime for your app, you must ensure that you have enough capacity in the cluster to carry the workload.\n\nHow can I control how many worker nodes go down at a time during an update or reload?\n: If you need all your worker nodes to be up and running, consider [resizing your worker pool](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_pool_resize) or [adding stand-alone worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-kubernetes-service-clics_worker_add) to add more worker nodes. You can remove the additional worker nodes after the update is completed.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_10290-113594-115347", "score": 42.431872153225754, "text": "\nibmcloud oc worker reload --cluster my_cluster -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w1 -w kube-dal10-cr18a61a63a6a94b658596aa93d087aaa9-w2\n\n\n\n\n\n\n\n ibmcloud oc worker replace \n\nVirtual Private Cloud\n\nClassic infrastructure\n\nDelete a worker node and replace it with a new worker node in the same worker pool.\n\nThe replacement worker node is created in the same zone and has the same flavor as the old worker node, but might be assigned new public or private IP addresses. You might replace a worker node if you can't reload or update the worker node, such as if it enters a troubled state.\n\nYou can also use this command to update the Kubernetes version of the worker node to match the major and minor version of the Kubernetes master by including the --update option. If you don't include the --update option, patch version updates are applied to your worker node, but not major or minor updates. To see the changes from one major, minor, or patch version to the next, review the [Version change log](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_versions) documentation. Remember that your worker nodes can be only up to two versions behind the master version (n-2).\n\nWhen you replace a worker node, keep in mind the following considerations.\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Multiple worker nodes are replaced concurrently: If you replace multiple worker nodes at the same time, they are deleted and replaced concurrently, not one by one. Make sure that you have enough capacity in your cluster to reschedule your workloads before you replace worker nodes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-kubernetes-service-cli"}, {"document_id": "ibmcld_06209-19911-21816", "score": 42.28854655824154, "text": "\nAs security updates and patches are put in place for the API server and other master components, you must be sure that the worker nodes remain in sync. You can make two types of updates: updating only the patch version, or updating the major.minor version with the patch version.\n\nApplies to only VPC clusters. Have a classic cluster? See [Updating classic worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node) instead.\n\nIf you have Portworx deployed in your cluster, follow the steps to [update VPC worker nodes with Portworx volumes](https://cloud.ibm.com/docs/containers?topic=containers-storage_portworx_updateportworx_vpc_up).\n\nFor the latest security patches and fixes, make sure to update your worker nodes to the latest patch as soon as possible after it is available. For more information about the latest updates, review the [change log](https://cloud.ibm.com/docs/containers?topic=containers-changelog).\n\nTo update Satellite worker nodes, see [Updating hosts that are assigned as worker nodes to Satellite-enabled services](https://cloud.ibm.com/docs/satellite?topic=satellite-host-update-workers).\n\n\n\n* Patch: A worker node patch update includes security fixes. You can update the VPC worker node to the latest patch by using the ibmcloud ks worker replace command.\n* Major.minor: A major.minor update moves up the Kubernetes version of the worker node to the same version as the master. This type of update often includes changes to the Kubernetes API or other behaviors that you must prepare your cluster for. Remember that your worker nodes can be only up to two versions behind the master version (n-2). You can update the VPC worker node to the same patch by using the ibmcloud ks worker replace command with the --update option.\n\n\n\nFor more information, see [Update types](https://cloud.ibm.com/docs/containers?topic=containers-cs_versionsupdate_types).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-update"}, {"document_id": "ibmcld_10395-7-1827", "score": 41.69047625861205, "text": "\nUpdating VPC worker nodes that use OpenShift Data Foundation \n\nVirtual Private Cloud\n\nFor VPC clusters with a storage solution such as OpenShift Data Foundation you must cordon, drain, and replace each worker node sequentially. If you deployed OpenShift Data Foundation to a subset of worker nodes in your cluster, then after you replace the worker node, you must then edit the ocscluster resource to include the new worker node.\n\nThe following tutorial covers both major and minor updates. Each step is flagged with\n\nMajor\n\nor\n\nMinor\n\n.\n\n\n\nMajor\n\nApplies to major updates, for example if you are updating your worker nodes to a new major version, such as from 4.11 to 4.12 as well as OpenShift Data Foundation from 4.11 to 4.12\nMinor\n\nApplies to minor patch updates, for example if you are updating from 4.12.15_1542_openshift to 4.12.16_1544_openshift while keeping OpenShift Data Foundation at version 4.12.\n\n\n\nSkipping versions during an upgrade, such as from 4.8 to 4.12 is not supported.\n\n[Log in to your account. If applicable, target the appropriate resource group. Set the context for your cluster.](https://cloud.ibm.com/docs/containers?topic=containers-access_cluster)\n\nBefore updating your worker nodes, make sure to back up your app data. Also, plan to complete the following steps for one worker node at a time. Repeat the steps for each worker node that you want to update.\n\n\n\n Step 1: Update the cluster master \n\nMajor\n\n\n\n1. If you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-vpc"}, {"document_id": "ibmcld_05728-3926-5863", "score": 39.91715409338707, "text": "\nUpdate type Examples of version labels Updated by Impact \n\n Major 1.x.x You Operation changes for clusters, including scripts or deployments. \n Minor x.22.x You Operation changes for clusters, including scripts or deployments. \n Patch x.x.4_1510 IBM and you Kubernetes patches, as well as other IBM Cloud Provider component updates such as security and operating system patches. IBM updates masters automatically, but you apply patches to worker nodes. See more about patches in the following section. \n\n\n\nMajor and minor updates (1.x)\n: First, [update your master node](https://cloud.ibm.com/docs/containers?topic=containers-updatemaster) and then [update the worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node).\n\n\n\n* You can't update a Kubernetes master two or more minor versions ahead (n+2). For example, if your current master is version 1.22 and you want to update to 1.24, you must update to 1.23 first.\n* Worker nodes can't run a Kubernetes major or minor version that is greater than the masters. Additionally, your worker nodes can be only up to two versions behind the master version (n-2).\n* If you use a kubectl CLI version that does not match at least the major.minor version of your clusters, you might experience unexpected results. Make sure to keep your Kubernetes cluster and [CLI versions](https://cloud.ibm.com/docs/containers?topic=containers-cli-install) up-to-date.\n\n\n\nPatch updates (x.x.4_1510)\n: Changes across patches are documented in the change log of each version. Master patches are applied automatically, but you initiate worker node patches and updates. Worker nodes can also run patch versions that are greater than the masters. As updates become available, you are notified when you view information about the master and worker nodes in the IBM Cloud console or CLI, such as with the following commands: ibmcloud ks cluster ls, cluster get, worker ls, or worker get.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_versions"}, {"document_id": "ibmcld_05597-3924-5861", "score": 39.91715409338707, "text": "\nUpdate type Examples of version labels Updated by Impact \n\n Major 1.x.x You Operation changes for clusters, including scripts or deployments. \n Minor x.22.x You Operation changes for clusters, including scripts or deployments. \n Patch x.x.4_1510 IBM and you Kubernetes patches, as well as other IBM Cloud Provider component updates such as security and operating system patches. IBM updates masters automatically, but you apply patches to worker nodes. See more about patches in the following section. \n\n\n\nMajor and minor updates (1.x)\n: First, [update your master node](https://cloud.ibm.com/docs/containers?topic=containers-updatemaster) and then [update the worker nodes](https://cloud.ibm.com/docs/containers?topic=containers-updateworker_node).\n\n\n\n* You can't update a Kubernetes master two or more minor versions ahead (n+2). For example, if your current master is version 1.22 and you want to update to 1.24, you must update to 1.23 first.\n* Worker nodes can't run a Kubernetes major or minor version that is greater than the masters. Additionally, your worker nodes can be only up to two versions behind the master version (n-2).\n* If you use a kubectl CLI version that does not match at least the major.minor version of your clusters, you might experience unexpected results. Make sure to keep your Kubernetes cluster and [CLI versions](https://cloud.ibm.com/docs/containers?topic=containers-cli-install) up-to-date.\n\n\n\nPatch updates (x.x.4_1510)\n: Changes across patches are documented in the change log of each version. Master patches are applied automatically, but you initiate worker node patches and updates. Worker nodes can also run patch versions that are greater than the masters. As updates become available, you are notified when you view information about the master and worker nodes in the IBM Cloud console or CLI, such as with the following commands: ibmcloud ks cluster ls, cluster get, worker ls, or worker get.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-changelog"}, {"document_id": "ibmcld_10394-1469-2994", "score": 39.4540522894369, "text": "\nIf you are updating your worker nodes to a new major version, such as from 4.11 to 4.12, update the cluster master first.\n\nibmcloud oc cluster master update --cluster CLUSTER [--version MAJOR.MINOR.PATCH] [--force-update] [-f] [-q]\n\nExample command:\n\nibmcloud oc cluster master update --cluster mycluster --version 4.11.42 --force-update\n2. Wait until the master update finishes.\n\n\n\n\n\n\n\n Step 2: Determine which worker nodes you want to update \n\nMajor\n\nMinor\n\n\n\n1. List your worker nodes by using the oc get nodes command and determining which worker nodes you want to update.\n\noc get nodes\n\nExample output\n\nNAME STATUS ROLES AGE VERSION\n10.241.0.4 Ready master,worker 106s v1.21.6+4b61f94\n10.241.128.4 Ready master,worker 22d v1.21.6+bb8d50a\n10.241.64.4 Ready master,worker 22d v1.21.6+bb8d50a\n\n\n\n\n\n\n\n Step 3: Scale down OpenShift Data Foundation \n\nMajor\n\nMinor\n\n\n\n1. For each worker node that you found in the previous step, find the rook-ceph-mon and rook-ceph-osd deployments.\n\noc get pods -n openshift-storage -o wide | grep -i <node_name>\n2. Scale down the deployments that you found in the previous step.\n\noc scale deployment rook-ceph-mon-c --replicas=0 -n openshift-storage\noc scale deployment rook-ceph-osd-2 --replicas=0 -n openshift-storage\noc scale deployment --selector=app=rook-ceph-crashcollector,node_name=NODE-NAME --replicas=0 -n openshift-storage\n\n\n\n\n\n\n\n Step 4: Cordon and drain the worker node \n\nMajor\n\nMinor\n\n\n\n1. Cordon the node. Cordoning the node prevents any pods from being scheduled on this node.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-storage-update-classic"}]}
{"task_id": "e1b602e47ded79a35d8df4eefe194e39<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03353-4-2000", "score": 26.421435264359218, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Supported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a Beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Actions skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-actions-add) [Dialog skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add) [Search skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add) \n\n English (en) GA GA GA \n Arabic (ar) GA GA GA", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-language-support"}, {"document_id": "ibmcld_03040-42016-43592", "score": 25.906172408548528, "text": "\nIBM Watson\u00ae Assistant for IBM Cloud Pak\u00ae for Data version 1.4 is available\n: Watson Assistant for IBM Cloud Pak\u00ae for Data version 1.4 is compatible with IBM Cloud Pak\u00ae for Data version 2.5.\n\nCzech language not automatically enabled\n: The Czech language is not enabled automatically anymore.\n\nAssistants and Skills navigation menu update\n: The main menu options of Assistants and Skills have moved from being displayed at the top of the page to being shown as icons in a new navigation pane.\n\n\n\n* ![Assistants menu icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/nav-ass-icon.png) Assistants\n* ![Skills menu icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/nav-skills-icon.png) Skills\n\n\n\nSkills secondary navigation menu update\n: The tabbed pages for the tools that you use to develop a dialog skill were moved to a secondary navigation bar that is displayed when you open the skill.\n\n![Skills secondary navigation menu](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/secondary-nav.png)\n\nRich response types support\n: Rich response types are now supported in a dialog node with slots. You can display a list of options for a user to choose from as the prompt for a slot, for example. For more information, see [Gathering information with slots](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-slots).\n\nImproved Entities, Dialog, and Intents page responsiveness", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-release-notes"}, {"document_id": "ibmcld_03043-7-2031", "score": 25.87558119403284, "text": "\nAdding a skill to your assistant \n\nCustomize your assistant by adding to it the skills it needs to satisfy your customers' goals.\n\nYou can create the following types of skills:\n\n\n\n* Dialog skill: Uses Watson natural language processing and machine learning technologies to understand user questions and requests, and respond to them with answers that are authored by you.\n* Search skill: For a given user query, uses the IBM Watson\u00ae Discovery service to search a data source of your self-service content and return an answer.\n\n\n\nTypically, you create a skill of each type first. Then, as you build a dialog for the dialog skill, you decide when to initiate the search skill. For some questions or requests, a hardcoded or programmatically-derived response (that is defined in the dialog skill) is sufficient. For others, you might want to provide a more robust response by returning a full passage of related information (that is extracted from an external data source by using the search skill).\n\n\n\n Dialog skill \n\nA dialog skill contains the training data and logic that enables an assistant to help your customers. It contains the following types of artifacts:\n\n\n\n* [Intents](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-intents): An intent represents the purpose of a user's input, such as a question about business locations or a bill payment. You define an intent for each type of user request you want your application to support. In the tool, the name of an intent is always prefixed with the character. To train the dialog skill to recognize your intents, you supply lots of examples of user input and indicate which intents they map to.\n\nA content catalog is provided that contains prebuilt common intents you can add to your application rather than building your own. For example, most applications require a greeting intent that starts a dialog with the user. You can add the General content catalog to add an intent that greets the user and does other useful things, like end the conversation.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-add"}, {"document_id": "ibmcld_03145-4-1748", "score": 25.754968548096276, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Using built-in intents \n\nContent Catalogs provide an easy way to add common intents to your Watson Assistant dialog skill.\n\nIntents you add from the catalog are meant to provide a starting point. Add to or edit the catalog intents to tailor them for your use case.\n\nThe latest content catalog, named Covid-19, is available in Brazilian Portuguese, English, French, and Spanish only. For more information about language support for the catalogs, see [Supported languages](https://cloud.ibm.com/docs/assistant?topic=assistant-language-support).\n\n\n\n Adding a content catalog to your dialog skill \n\n\n\n1. Open your dialog skill, open the Content Catalog page.\n\n![Screen capture showing available catalogs](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/catalog-overview.png)\n2. Select a content catalog, such as Banking, to see the intents that are provided with it.\n\n![Screen capture showing Banking category intents](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/catalog-open.png)\n\nIntents that are added from a content catalog are distinguishable from other intents by their names. Each intent name is prepended with the content catalog name.\n3. Add a content catalog to your dialog skill by clicking the Add to skill button.\n4. Go to the Intents page to see the intents that you added from the catalog listed.\n\n\n\nYour skill trains itself on the new data.\n\nAfter you add a catalog to your skill, the intents become part of your training data.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-catalog"}, {"document_id": "ibmcld_03381-4-1869", "score": 25.31099012964352, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Adding a dialog skill \n\nThe natural-language processing for the Watson Assistant service is defined in a dialog skill, which is a container for all of the artifacts that define a conversation flow.\n\nYou can add one dialog skill to an assistant. See [Skill limits](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-addskill-add-limits) for information about limits per plan.\n\n\n\n Create the dialog skill \n\nYou can create a skill from scratch, use a sample skill that is provided by IBM, or upload a skill from a JSON file.\n\nTo add a skill, complete the following steps:\n\n\n\n1. From the assistant where you want to add the skill, click Add an actions or dialog skill.\n2. Do one of the following:\n\n\n\n* To create a new dialog skill, remain on the Create skill tab.\n* To add the dialog sample skill that is provided with the product as a starting point for your own skill or as an example to explore before you create one yourself, open the Use sample skill tab, and then click the sample labeled TYPE: Dialog. You can skip the remaining steps.\n* To add a skill that was downloaded previously, you can upload it as a JSON file. Open the Upload skill tab. Drag a file or click Drag and drop file here or click to select a file and select the JSON file you want to upload.\n\nThe uploaded JSON file must use UTF-8 encoding, without byte order mark (BOM) encoding. The JSON cannot contain tabs, newlines, or carriage returns.\n\nThe maximum size for a skill JSON file is 10 MB. If you need to upload a larger skill, consider using the REST API. For more information, see the [API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v1?curl=createworkspace).\n\nClick Upload.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add"}, {"document_id": "ibmcld_03027-7-1946", "score": 25.154397551691304, "text": "\nSupported languages \n\nWatson Assistant supports individual features to varying degrees per language.\n\nWatson Assistant has classifier models that are designed specifically to support conversational skills in the following languages:\n\n\n\nTable 1. Supported languages\n\n Language Language code \n\n Arabic ar \n Chinese (Simplified) zh-cn \n Chinese (Traditional) zh-tw \n Czech cs \n Dutch nl \n English en-us \n French fr \n German de \n Italian it \n Japanese ja \n Korean ko \n Portuguese (Brazilian) pt-br \n Spanish es \n Universal* xx \n\n\n\n* If you want to support conversations in a language for which Watson Assistant doesn't have a dedicated model, such as Russian, use the Universal language model. For more information, see [Adding support for global audiences](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-language).\n\n\n\n Feature support details \n\nThe following tables illustrate the level of language support available for product features.\n\nIn the following tables, the level of language and feature support is indicated by these codes:\n\n\n\n* GA: The feature is generally available and supported for this language. Note that features might continue to be updated even after they are generally available.\n* Beta: The feature is supported only as a beta release, and is still undergoing testing before it is made generally available in this language.\n* NA: Indicates that a feature is not available in this language.\n\n\n\n\n\n Skill support details \n\n\n\nTable 2. Skill support details\n\n Language [Dialog skill](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-dialog-add) [Search skill](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add) \n\n English (en) GA GA \n Arabic (ar) GA GA \n Chinese (Simplified) (zh-cn) GA GA \n Chinese (Traditional) (zh-tw) GA GA \n Czech (cs) GA GA \n Dutch (nl) GA GA \n French (fr) GA GA \n German (de) GA GA \n Italian (it) GA GA \n Japanese (ja) GA GA", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-language-support"}, {"document_id": "ibmcld_03369-36856-39124", "score": 25.007833626640693, "text": "\nAfter you identify the list of steps, you can then focus on writing engaging content to turn each interaction into a positive experience for your customer.\n\nDate and time response types\n: New to action skills, these response types allow you to collect date and time information from customers as they answer questions or make requests.\n\nNew built-in variables\n: Two kinds of built-in variables are now available for action skills.\n\n\n\n* Set by assistant variables include the common and essential variables Now, Current time, and Current date.\n* Set by integration variables are Timezone and Locale and are available to use when connected to a webhook or integration.\n\n\n\nUniversal language model now generally available\n: You now can build an assistant in any language you want to support. If a dedicated language model is not available for your target language, create a skill that uses the universal language model. The universal model applies a set of shared linguistic characteristics and rules from multiple languages as a starting point. It then learns from training data written in the target language that you add to it. For more information, see [Understanding the universal language model](https://cloud.ibm.com/docs/assistant?topic=assistant-assistant-languageassistant-language-universal).\n\n\n\n\n\n 3 June 2021 \n\nLog webhook support for actions and search skills\n: The log webhook now supports messages exchanged with actions skills and search skills, in addition to dialog skills. For more information, see [Logging activity with a webhook](https://cloud.ibm.com/docs/assistant?topic=assistant-webhook-log).\n\n\n\n\n\n 27 May 2021 \n\nChange to conversation skill choices\n: When adding skills to new or existing assistant, the conversation skill choices have been combined, so that you pick from either an actions skill or a dialog skill.\n\nWith this change:\n\n\n\n* New assistants can use up to two skills, either actions and search or dialog and search. Previously, new assistants could use up to three skills: actions, dialog, and search.\n* Existing assistants that already use an actions skill and a dialog skill together can continue to use both.\n* The ability to use actions and dialog skills together in a new assistant is planned for 2H 2021.\n\n\n\n\n\n\n\n 20 May 2021", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_03369-75826-77957", "score": 24.733147674239536, "text": "\n* Fixed an issue with adding a jump-to from a conditional response in one node to a conditional response in another node.\n* The page now responds better when you scroll horizontally to see multiple levels of child nodes.\n\n\n\n\n\n\n\n 15 July 2020 \n\nSupport ended for @sys-location and @sys-person\n: The person and location system entities, which were available as a beta feature in English dialog skills only, are no longer supported. You cannot enable them. If your dialog uses them, they are ignored by the service.\n\nUse contextual entities to teach your skill to recognize the context in which such names are used. For more information about contextual entities, see [Annotation-based method](https://cloud.ibm.com/docs/assistant?topic=assistant-entitiesentities-annotations-overview).\n\nFor more information about how to use contextual entites to identify names of people, see the [Detecting Names And Locations With Watson Assistant](https://medium.com/ibm-watson/detecting-names-and-locations-with-watson-assistant-e3e1fa2a8427) blog post on Medium.\n\nHow legacy numeric system entities are processed has changed\n: All new dialog skills use the new system entities automatically.\n\nFor existing skills that use legacy numeric system entities, how the entities are processed now differs based on the skill language.\n\n\n\n* Arabic, Chinese, Korean, and Japanese dialog skills that use legacy numeric system entities function the same as before.\n* If you choose to continue to use the legacy system entities in European-language dialog skills, a new legacy API format is used. The new legacy API format simulates the legacy system entities behavior. In particular, it returns a metadata object and does not stop the service from idenfifying multiple system entities for the same input string. In addition, it returns an interpretation object, which was introduced with the new version of system entities. Review the interpretation object to see the useful information that is returned by the new version.\n\n\n\nUpdate your skills to use the new system entities from the Options>System Entities page.\n\nWeb chat security is generally available", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_03369-89572-91689", "score": 24.683083478461597, "text": "\n: The technology preview user interface was replaced with the Watson Assistant standard user interface. If you used an Actions page to create actions and steps for your skill previously, you cannot access the Actions page anymore. Instead, use the Intents and Dialog pages to work with your skill.\n\n\n\n\n\n 16 March 2020 \n\nInstructions updated for Slack integrations\n: The steps required to set up a Slack integration have changed to reflect permission assignment changes that were made by Slack. For more information, see [Integrating with Slack](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-slack).\n\nOrder of response types is preserved\n: Previously, if you included a response type of Search skill in a list of response types for a dialog node, the search results were displayed last despite its placement in the list. This behavior was changed to show the search results in the appropriate order, namely in the sequence in which the search skill response type is listed for the dialog node.\n\n\n\n\n\n 10 March 2020 \n\nContextual entity support is generally available\n: You can add contextual entities to English-language dialog skills. For more information about contextual entities, see [Creating entities](https://cloud.ibm.com/docs/assistant?topic=assistant-entitiesentities-annotations-overview).\n\nFrench language support added for autocorrection\n: Autocorrection helps your assistant understand what your customers want. It corrects misspellings in the input that customers submit before the input is evaluated. With more precise input, your assistant can more easily recognize entity mentions and understand the customer's intent. See [Correcting user input](https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-runtime-spell-check) for more details.\n\nThe new system entities are used by new skills\n: For new English, Brazilian Portuguese, Czech, Dutch, French, German, Italian, and Spanish dialog skills, the new system entities are enabled automatically. If you decide to turn on a system entity and add it to your dialog, it's the new and improved version of the system entity that is used.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-release-notes"}, {"document_id": "ibmcld_07578-18457-20516", "score": 24.62057258932135, "text": "\n5. Under Time Frame, select the month you need.\n6. Select your Plus plans or Plus Trial plans to see monthly active users and the API calls.\n\n\n\n* Error: New Off Topic not supported\n\nYou see the error New Off Topic not supported after editing the JSON file for a dialog skill and changing the skill language from English to another language.\n\nTo resolve this issue, modify the JSON file by setting off_topic to false. For more information about this feature, see [Defining what's irrelevant](https://cloud.ibm.com/docs/assistant?topic=assistant-irrelevance-detection).\n* Is it possible to increase the number of intents per skill\n\nNo, it is not possible to increase the number of intents per skill.\n\n\n\nDiscovery v1\n\n\n\n* Where can I get technical support for Discovery?\n\nIf you cannot find a solution to the issue you are having, search this documentation. You can also try the resources available from the Developer community section of the table of contents.\n\nIf your service plan covers it, you can get help by creating a case from [IBM Cloud Support](https://cloud.ibm.com/unifiedsupport/supportcenter).\n* How do you interpret the confidence score that appears in query results?\n\nDiscovery returns a confidence score for both natural language queries and those written in the Discovery Query Language. For more information, see [Confidence scores](https://cloud.ibm.com/docs/services/discovery?topic=discovery-improving-result-relevance-with-the-toolingconfidence).\n* How do you integrate Watson Discovery with Watson Assistant?\n\nIf you create a chatbot in IBM Watson\u2122 Assistant, you can route complex customer inquiries to Discovery using a search skill. When a customer asks a question that the dialog is not designed to answer, your assistant can search for relevant information from Discovery, extract the information, and return it as the response. See [Creating a search skill](https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add) for details. (This feature is available only to Watson Assistant Plus or Premium plan users.)", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}]}
{"task_id": "81afaf82a0d9a5fad6eaa196f8d9641c<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08435-4-1684", "score": 23.967285251540723, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys by using dual authorization \n\nYou can use IBM Cloud\u00ae Hyper Protect Crypto Services to safely delete root keys or standard keys by using a dual authorization process.\n\nBefore you delete keys, make sure you understand [the concept of deleting and purging keys](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-purge-keys) and review the [considerations](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for deleting a key using dual authorization \n\nDeleting a key that has a [dual authorization policy](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) requires an authorization from two users. With the Hyper Protect Crypto Services key management service API, you can provide the first authorization by [setting the key for deletion](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keysset-key-deletion-api). Then, a different user provides a second authorization by using the IBM Cloud console or key management service API to delete the key.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Hyper Protect Crypto Services resources. To use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_08695-7-1852", "score": 23.919220607387377, "text": "\nWhy can't I delete keys? \n\nWhen you use the Hyper Protect Crypto Services user interface, you're unable to delete a key.\n\n What\u2019s happening \n\nFrom the IBM Cloud dashboard, you select your instance of the Hyper Protect Crypto Services service.\n\nYou're assigned a Manager access policy for the service instance. You try to delete a key, but the action fails with either of the following error messages:\n\n\n\n* Error message 1:\n\n> The service was not able to delete key \"<key_name>\". The key cannot be deleted because it is protecting one or more cloud resources that have a retention policy.\n* Error message 2:\n\n> The service was not able to delete key \"<key_name>\". Because the key is enabled with the dual authorization policy and you set the key for deletion, a second approver needs to continue with the key deletion operation.\n\n\n\n Why it\u2019s happening \n\nThe following reasons might cause the errors:\n\n\n\n* If error message 1 is displayed, this key is actively protecting one or more cloud resources, such as a Cloud Object Storage bucket.\n* If error message 2 is displayed, this key is enabled with the dual authorization policy that requires a deletion authorization from two users. You set the key for deletion and you need to contact the second approver to complete the deletion.\n\n\n\n How to fix it \n\nThe following instructions can help you solve the problems:\n\n\n\n* To resolve the error that is reported in error message 1, [review the resources](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-view-protected-resources) that are associated with the key before you delete a key.\n\nYou can [force deletion on a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-keysdelete-key-force) that's protecting a cloud resource. However, the action won't succeed if the key's associated resource is nonerasable due to a retention policy.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-troubleshoot-unable-to-delete-keys"}, {"document_id": "ibmcld_07578-1212442-1214450", "score": 23.849997453171802, "text": "\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https://cloud.ibm.com/docs/key-protect?topic=key-protect-set-dual-auth-key-policy).\n* Can I disable a dual authorization settings for my Key Protect instance?\n\nYes. If you need to add a key that doesn't require dual authorization to your Key Protect instance, you can always [disable dual authorization for the Key Protect instance](/docs/key-protect?topic=key-protect-manage-dual-auth#disable dual-auth-instance-policy-ui) so that any new or future keys won't require it.\n* What happens when I need to delete or deprovision my Key Protect instance?\n\nIf you decide to move on from Key Protect, you must delete any remaining keys from your Key Protect instance before you can delete or deprovision the service. After you delete your Key Protect instance, Key Protect uses[envelope encryption](https://cloud.ibm.com/docs/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1215075-1217083", "score": 23.849997453171802, "text": "\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https://cloud.ibm.com/docs/key-protect?topic=key-protect-set-dual-auth-key-policy).\n* Can I disable a dual authorization settings for my Key Protect instance?\n\nYes. If you need to add a key that doesn't require dual authorization to your Key Protect instance, you can always [disable dual authorization for the Key Protect instance](/docs/key-protect?topic=key-protect-manage-dual-auth#disable dual-auth-instance-policy-ui) so that any new or future keys won't require it.\n* What happens when I need to delete or deprovision my Key Protect instance?\n\nIf you decide to move on from Key Protect, you must delete any remaining keys from your Key Protect instance before you can delete or deprovision the service. After you delete your Key Protect instance, Key Protect uses[envelope encryption](https://cloud.ibm.com/docs/key-protect?topic=key-protect-envelope-encryption) to crypto-shred any data that is associated with the Key Protect instance.\n* Why does the user interface show unauthorized access?\n\nSetting and retrieving the network access policy is only supported through the application programming interface (API). Network access policy support will be added to the user interface (UI), command line interface (CLI), and software development kit (SDK) in the future.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_15994-2940-5003", "score": 23.766489062521895, "text": "\nYou can't delete a block storage volume by name or ID.\n\n Why it\u2019s happening \n\nThe volume name and ID are not accepted.\n\n How to fix it \n\nVerify that the volume name or identifier is correct and that the volume is not attached to a virtual server instance. Also, verify that the volume is not in a pending state.\n\n\n\n\n\n Expandable volume remains in an updating state when an attempt is made to delete an instance \n\n What\u2019s happening \n\nWhen you attempt to delete a virtual server instance with an attached volume that is being resized, the volume remains in an updating state and can't be deleted.\n\n Why it\u2019s happening \n\nA volume is being resized and you tried to delete the instance that the volume is attached to, either manually or by auto-delete. The status of the volume remains updating and the volume isn't deleted with the instance.\n\n How to fix it \n\nA volume must be in an available state for operations such as attach, detach, delete. When you are expanding a volume, wait for the volume resize to complete before you perform any operations. If you try to delete a volume that's resizing, the volume remains in an updating state and is not deleted with the instance. To delete the volume, reattach the volume to a different instance, and make sure that the resizing is complete (volume status becomes available), and then delete the volume.\n\n\n\n\n\n Removing IAM authorization from the storage service to the KMS causes root key deregistration failure \n\n What\u2019s happening \n\nThe root keys in the Key management service (KMS) instance remain registered to the deleted block storage volume or image resources.\n\n Why it\u2019s happening \n\nIf you remove IAM authorization from Cloud Block Storage to the KMS before you delete all BYOK volumes or images, the root key fails to unregister from the resource.\n\n How to fix it \n\nAs best practice, delete all storage or image resources before you remove IAM authorization. If you already removed authorization, you must restore the IAM authorization between Cloud Block Storage (source service) and your KMS (target service).", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-troubleshooting-block-storage"}, {"document_id": "ibmcld_08435-1255-3053", "score": 23.06167395361042, "text": "\nTo use dual authorization, be sure to identify a user who can set the key for deletion, and another user who can delete the key. Users with a Writer or Manager access policy can set keys for deletion. Users with a Manager access policy can delete keys.\n* Plan to delete the key within a 7-day waiting period. When the first user authorizes a key for deletion, Hyper Protect Crypto Services sets a 7-day waiting period on the key. During this period, the key remains in the [Active state](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-key-states) and all key operations are allowed on the key. To complete the deletion, the second user with a Manager access policy can use the IBM Cloud console or API to delete the key.\n* The key and its associated data become inaccessible 90 days after the key is deleted. When you delete a key, the key can be restored within 30 days after the deletion. You are able to retrieve associated data such as key metadata, registrations, and policies for up to 90 days. After 90 days, the key becomes eligible to be automatically purged and its associated data will be permanently removed from your instance.\n\n\n\n\n\n\n\n Authorize deletion for a key with the IBM Cloud console \n\n\n\n Step 1. Authorize deletion for a key \n\nAfter you [enable dual authorization for an instance](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-manage-dual-auth) or [for a key](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-set-dual-auth-key-policy), you can provide the first authorization to delete a key by using the IBM Cloud console.\n\n\n\n1. [Log in to the IBM Cloud console](https://cloud.ibm.com/).\n2. Go to Menu > Resource list to view a list of your resources.\n3. From your IBM Cloud resource list, select your provisioned instance of Hyper Protect Crypto Services.\n4.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-delete-dual-auth-keys"}, {"document_id": "ibmcld_09061-4-1966", "score": 22.87730737807005, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Deleting keys that have a dual-authorization deletion policy \n\nYou can use IBM\u00ae Key Protect for IBM Cloud\u00ae to safely delete encryption keys by using a dual authorization process.\n\nBefore deleting keys, make sure to review the [Considerations before deleting and purging a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-purge-keysdelete-purge-keys-considerations).\n\n\n\n Considerations for a key that has a dual-authorization deletion policy \n\n[Dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) are set to ensure that keys are not deleted in error by requiring the authorization of two specified users. Whatever the reason for a dual authorization policy, the method for deletion is the same. One of the users authorized to delete the key schedules it for deletion, which must be confirmed by another user.\n\nBefore you delete a key by using dual authorization:\n\n\n\n* Determine who can authorize deletion of your Key Protect resources. To use dual authorization, be sure to identify a user who can set the key for deletion and another who can delete the key. Users with a Writer or Manager role can set keys for deletion, but only users with a Manager role can delete keys.\n* Plan to delete the key within a seven day authorization period. When the first user authorizes a key for deletion, it remains in the [Active state](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-states) for seven days, during which all key operations are allowed on the key. To complete the deletion, another user with a Manager role can use the Key Protect GUI or API to delete the key at any point during those seven days, at which time the key will be moved to the Destroyed state. Note that because it is impossible to purge an active key, another user must delete the key before it can purged.\n* The key and its associated data will be inaccessible 90 days after being deleted.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-dual-auth-keys"}, {"document_id": "ibmcld_09088-10880-12721", "score": 22.325043939255394, "text": "\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n\n\n\n\n\n What happens when I disable a key? \n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n\n\n\n\n\n What is a dual authorization policy? \n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n\n\n\n\n\n What happens after I enable a dual authorization policy? \n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted. If you want to enable those keys for dual authorization, you can use the Key Protect APIs t [set dual authorization policies for those individual keys](https://cloud.ibm.com/docs/key-protect?topic=key-protect-set-dual-auth-key-policy).\n\n\n\n\n\n Can I disable a dual authorization settings for my Key Protect instance? \n\nYes.", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-faqs"}, {"document_id": "ibmcld_07578-1211120-1213024", "score": 22.261577173919388, "text": "\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-1213753-1215657", "score": 22.261577173919388, "text": "\nIf needed, you can [force deletion on a key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-delete-keysdelete-keys-force-delete) by using the Key Protect APIs. [Review which resources are encrypted by the key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-view-protected-resources) and verify with the owner of the resources to ensure you no longer require access to that data.\n\nIf you can't delete a key because a retention policy exists on the associated resource, contact the account owner to remove the retention policy on that resource.\n* What happens when I disable a key?\n\nWhen you disable a key, the key transitions to the Suspended state. Keys in this state are no longer available for encrypt or decrypt operations, and any data that's associated with the key becomes inaccessible.\n\nDisabling a key is a reversible action. You can always [enable a disabled key](https://cloud.ibm.com/docs/key-protect?topic=key-protect-disable-keysenable-api) and restore access to the data that was previously encrypted with the key.\n* What is a dual authorization policy?\n\nDual authorization is a two-step process that requires an action from two approvers to delete a key. By forcing two entities to authorize the deletion of a key, you minimize the chances of inadvertent deletion or malicious actions.\n\nWith Key Protect, you can [enforce dual authorization policies](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-dual-auth) at the instance level or for individual keys.\n* What happens after I enable a dual authorization policy?\n\nAfter you enable a dual authorization policy for a Key Protect instance, any keys that you add to the instance inherit the policy at the key level. Dual authorization policies for keys cannot be reverted.\n\nIf you have existing keys in a Key Protect instance, those keys will continue to require only a single authorization to be deleted.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}]}
{"task_id": "f3a917e029970190be5ee508ba770d7f<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_08766-9493-11228", "score": 28.941042379354034, "text": "\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.\n\nIn the context of web servers, the TLS/SSL protocol allows a website to establish the identity. Users of the website can be sure that no one else is masquerading as the website. It is done through a public-private key pair.\n\nHyper Protect Crypto Services provides a way to offload the cryptographic operations that are done during the TLS handshake to establish a secure connection to the web server, while it keeps the TLS/SSL private key securely stored in the dedicated HSM. In this way, you have control over your TLS/SSL keys and processing. As a result, security is improved and reputational risk is decreased.\n\nTLS/SSL offloading to the Hyper Protect Crypto Services HSM enables data in transit protection for web, API, and mobile transactions by using the standard PKCS #11 API. With Hyper Protect Crypto Services, you can integrate TLS/SSL offloading with other cloud proxies.\n\nFor a tutorial on how to offload the SSL workload to a load balancer such as NGINX while managing keys by using Hyper Protect Crypto Services, see [Using IBM Cloud Hyper Protect Crypto Services to offload NGINX TLS](https://developer.ibm.com/components/ibmz/tutorials/use-hyper-protect-crypto-services-to-offload-nginx-tls/).\n\nZoom\n\n!", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-use-cases"}, {"document_id": "ibmcld_08739-11193-12939", "score": 28.890313175802554, "text": "\n* For a tutorial on how to use TDE with Hyper Protect Crypto Services, see\n\n[Tutorial: Using Oracle Transparent Database Encryption with Hyper Protect Crypto Services PKCS #11](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-tutorial-tde-pkcs11).\n* For a tutorial on how to use Db2 default encryption with Hyper Protect Crypto Services, see\n\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.\n\nIn the context of web servers, the TLS/SSL protocol allows a website to establish the identity. Users of the website can be sure that no one else is masquerading as the website. It is done through a public-private key pair.\n\nHyper Protect Crypto Services provides a way to offload the cryptographic operations that are done during the TLS handshake to establish a secure connection to the web server, while it keeps the TLS/SSL private key securely stored in the dedicated HSM. In this way, you have control over your TLS/SSL keys and processing. As a result, security is improved and reputational risk is decreased.\n\nTLS/SSL offloading to the Hyper Protect Crypto Services HSM enables data in transit protection for web, API, and mobile transactions by using the standard PKCS #11 API. With Hyper Protect Crypto Services, you can integrate TLS/SSL offloading with other cloud proxies.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-uko-use-cases"}, {"document_id": "ibmcld_08766-8126-10005", "score": 27.71682206190279, "text": "\n[IBM Db2 default encryption by using the standard PKCS #11 API](https://cloud.ibm.com/docs-content/v1/content/217f108cc44e2ce15fb692d4b57b4c628464e908/hs-crypto//images/pkcs-db2.svg)\n\nFigure 5. IBM Db2 default encryption by using the standard PKCS #11 API\n\n\n\nWith the PKCS #11 library integration, Hyper Protect Crypto Services supports the industry-standard PKCS #11 API. The Hyper Protect Crypto Services PKCS #11 library connects your database to Hyper Protect Crypto Services to perform cryptographic operations. The database system can invoke operations to manage the TDE master encryption keys or the master keys in the Hyper Protect Crypto Services PKCS #11 library. The Hyper Protect Crypto Services PKCS #11 library then interacts with your Hyper Protect Crypto Services instance to provide the highest level of security for storing and managing your TDE master encryption keys or your master keys in the cloud. It, in turn, provides the highest level of security to your data encryption keys and your data.\n\n\n\n* For a tutorial on how to use TDE with Hyper Protect Crypto Services, see\n\n[Tutorial: Using Oracle Transparent Database Encryption with Hyper Protect Crypto Services PKCS #11](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-tutorial-tde-pkcs11).\n* For a tutorial on how to use Db2 default encryption with Hyper Protect Crypto Services, see\n\n[Using IBM Db2 default encryption with Hyper Protect Crypto Services PKCS #11](https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-tutorial-db2-pkcs11).\n\n\n\n\n\n\n\n Protecting data in transit with TLS/SSL offloading \n\nTransport Layer Security (TLS) and Secure Sockets Layer (SSL) are cryptographic protocols that are designed to provide communication security over a computer network. The TLS/SSL protocol aims primarily to provide privacy and data integrity between two or more communicating computer applications.", "title": "", "source": "https://cloud.ibm.com/docs/hs-crypto?topic=hs-crypto-use-cases"}, {"document_id": "ibmcld_14311-3835-5367", "score": 24.402588968175724, "text": "\n[Layer 2 bridge setup with a new bridge edge cluster](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.\n* If you have a larger deployment, deploying a dedicated edge cluster or several edge clusters offers better performance and generally scales better.\n* If you use new edge nodes for bridging, they do not have to be in the same network or POD as the workload edge. Edge nodes are transport nodes and they communicate with the other NSX-T transport nodes (edges or hosts) through Geneve tunnels over layer 3 routed connections by using the IBM Cloud classic network as a transport network.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [VMware vSphere overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview)\n* [Getting started with IBM Cloud Gateway Appliance](https://cloud.ibm.com/docs/gateway-appliance?topic=gateway-appliance-getting-started)\n* [Installing NSX-T edge transport nodes](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/3.2/installation/GUID-5EF2998C-4867-4DA6-B1C6-8A6F8EBCC411.html)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"}, {"document_id": "ibmcld_04107-7548-9466", "score": 23.656422609630454, "text": "\nThese attacks consist of a flood of traffic at ISO Layer 3 (the network layer), such as ICMP floods, or at Layer 4 (the transport layer), such as TCP SYN floods or reflected UDP floods. These attacks send malicious ISO Layer-7 requests (the application layer), such as GET floods. \n Automatically blocked at CIS edge CIS handles these attacks with Defense mode, WAF, and security-level settings. \n\n\n\n\n\n\n\n On-demand anti-DDoS \n\nIBM Cloud Internet Services ingests traffic by returning a CIS IP address on the DNS lookup for a domain, instead of the actual record for the origin server\u2019s IP address. This allows CIS to ingest, single-pass inspect, and re-encrypt data before sending it to the origin server destination. CIS can also act in DNS-only mode, returning the actual DNS record without obfuscating the IP, which disables DDoS and the other functions of CIS. To enable CIS protections, switch the \"proxy\" slider next to each DNS record to on; to disable protections, switch to off.\n\n\n\n\n\n Unlimited DDoS mitigation \n\nDDoS mitigation is typically an expensive service that can grow in cost when under attack. Unlimited DDoS mitigation is included with CIS at no additional cost.\n\n\n\n\n\n Mitigate Layer 7 attacks (configuration) \n\nThough DDoS is enabled by default in CIS, you can further configure Layer 7 security by:\n\n\n\n* Configuring WAF ruleset sensitivity and response behavior\n* Adding rate limiting\n* Adding firewall rules\n\n\n\nUse these features to customize Layer 7 mitigation of both volumetric and non-volumetric attacks.\n\n\n\n\n\n Mitigate non volumetric attacks \n\nCIS WAF contains rulesets to mitigate non-volumetric attacks, including cross-site forgery, cross-site-scripting (XSS), file inclusion, and SQL injection. For additional information about WAF, see [Web Application Firewall concepts](https://cloud.ibm.com/docs/cis?topic=cis-waf-q-and-awhat-types-of-attacks-can-waf-prevent).\n\n\n\n\n\n Cost protection", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-ibm-cloud-internet-services-cis"}, {"document_id": "ibmcld_09121-34367-36050", "score": 23.644906426377982, "text": "\nAs an account owner or admin, review the existing access policies for all Key Protect users in your account to ensure that they are assigned the appropriate levels of access. To learn more about Key Protect roles and permissions, see [Managing user access](https://cloud.ibm.com/docs/key-protect?topic=key-protect-manage-access).\n\n\n\n\n\n\n\n September 2019 \n\n\n\n 27 September 2019 \n\nKey Protect supports fine-grain access\n: As an account admin, you can now assign fine-grained access to individual keys within a Key Protect instance. To learn more about granting access, see [Granting access to keys](https://cloud.ibm.com/docs/key-protect?topic=key-protect-grant-access-keys).\n\n\n\n\n\n 16 September 2019 \n\nTransport keys deprecated, replaced with import tokens\n: On 20 March 2019, [Key Protect announced transport keys](https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-protect-key-protect-relnotesadded-transport-keys-beta) as a beta feature for importing encryption keys to the cloud with an extra layer of security. We're happy to announce that the feature has now reached its end of beta period. The following API methods have changed:\n\n\n\n* POST api/v2/lockers is now POST api/v2/import_token\n* GET api/v2/lockers is now GET api/v2/import_token\n* GET api/v2/lockers/{id} is no longer supported\n\n\n\nYou can now create [import tokens](https://cloud.ibm.com/docs/key-protect?topic=key-protect-importing-keysusing-import-tokens) to enable added security for keys that you upload to Key Protect.\n\nTo find out more about your options for importing keys, check out [Bringing your encryption keys to the cloud](https://cloud.ibm.com/docs/key-protect?topic=key-protect-importing-keys).", "title": "", "source": "https://cloud.ibm.com/docs/key-protect?topic=key-protect-key-protect-key-protect-relnotes"}, {"document_id": "ibmcld_05440-3062-4677", "score": 23.512492572785174, "text": "\nUse secrets to store sensitive information You can store information, such as passwords and SSH keys in a secret. For more information, see [Working with secrets](https://cloud.ibm.com/docs/codeengine?topic=codeengine-secret). \n\n\n\n\n\n Supported TLS versions and cipher suites \n\nThe Code Engine API and application endpoints support transport layer security (TLS) 1.2 (or higher) and the following cipher suites.\n\n\n\n TLS cipher suites \n\n\n\n* ECDHE-ECDSA-AES128-GCM-SHA256\n* ECDHE-ECDSA-AES256-GCM-SHA384\n* ECDHE-RSA-AES128-GCM-SHA256\n* ECDHE-RSA-AES256-GCM-SHA384\n* ECDHE-ECDSA-CHACHA20-POLY1305\n* ECDHE-RSA-CHACHA20-POLY1305\n\n\n\n\n\n\n\n\n\n DDoS protection \n\nCode Engine provides out-of-the-box DDoS protection for your application. Code Engine's DDoS protection is provided by Cloud Internet Services (CIS) at no additional cost to you.\n\nDDoS protection covers System Interconnection (OSI) Layer 3 and Layer 4 (TCP/IP) protocol attacks, but not Layer 7 (HTTP) attacks.\n\nTo address Layer 7 attacks, you can take the following steps so that your traffic runs through a secure route using your custom domain and is no longer available to the public internet through the Code Engine provided domain.\n\n\n\n1. Obtain your custom domain.\n2. In Code Engine, [create a custom domain mapping](https://cloud.ibm.com/docs/codeengine?topic=codeengine-domain-mappings) for your app.\n3. Set up an instance of [Cloud Internet Services (CIS)](https://cloud.ibm.com/catalog/services/internet-services) to manage your custom domain.\n4. [Add the custom domain to the CIS instance](https://cloud.ibm.com/docs/cis?topic=cis-multi-domain-support).", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-secure"}, {"document_id": "ibmcld_05275-6041-7982", "score": 23.44901349171402, "text": "\nApplications follow the scale-to-zero model, where no instances are created in the absence of traffic, leading to cost optimization. When there is an incoming request, an app automatically scales up from zero to accommodate the workload.\n\nWith Code Engine, you can control autoscaling by setting the minimum and maximum number of instances. You can also specify the concurrency of the application by specifying the number of requests to run in parallel for a specific application instance, to help determine when a new instance is provisioned.\n\nFor more information about scaling your app, see [Configuring application scaling](https://cloud.ibm.com/docs/codeengine?topic=codeengine-app-scale).\n\n\n\n\n\n Security \n\nCode Engine provides out-of-the-box DDOS protection for your application. Code Engine's DDOS protection is provided by Cloud Internet Services (CIS) at no additional cost to you. DDoS protection covers System Interconnection (OSI) Layer 3 and Layer 4 (TCP/IP) protocol attacks, but not Layer 7 (HTTP) attacks. See [DDoS protection](https://cloud.ibm.com/docs/codeengine?topic=codeengine-securesecure-ddos).\n\nCode Engine also provides a service mesh to use its networking layer, which enables mutual Transport Layer Security (TLS) traffic on applications, thus securing service-to-service and user-to-service communication.\n\nFor more information about security, see [Code Engine and security](https://cloud.ibm.com/docs/codeengine?topic=codeengine-secure).\n\n\n\n\n\n Triggering applications with events \n\nYou can subscribe Code Engine applications to receive cron events, IBM Cloud Object Storage events or Kafka topics. When you subscribe to an event producer, you must specify the name of your destination application to receive the events.\n\nFor more information about working with event producers, see [Getting started with subscriptions](https://cloud.ibm.com/docs/codeengine?topic=codeengine-subscribing-events).\n\n\n\n\n\n Visibility", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-ceapplications"}, {"document_id": "ibmcld_05277-6235-8105", "score": 23.385956802764753, "text": "\nFor more information about creating and invoking Functions, see [Working with Functions in Code Engine](https://cloud.ibm.com/docs/codeengine?topic=codeengine-fun-work).\n\n\n\n\n\n Security \n\nCode Engine provides out-of-the-box DDOS protection for your Function. Code Engine's DDOS protection is provided by Cloud Internet Services (CIS) at no additional cost to you. DDoS protection covers System Interconnection (OSI) Layer 3 and Layer 4 (TCP/IP) protocol attacks, but not Layer 7 (HTTP) attacks. See [DDoS protection](https://cloud.ibm.com/docs/codeengine?topic=codeengine-securesecure-ddos).\n\nCode Engine also provides a service mesh to use its networking layer, which enables mutual Transport Layer Security (TLS) traffic for Functions, thus securing service-to-service and user-to-service communication.\n\nFor more information about security, see [Code Engine and security](https://cloud.ibm.com/docs/codeengine?topic=codeengine-secure).\n\n\n\n\n\n Invocation concurrency and scaling of Function instances \n\nWhen multiple Functions are being invoked at the same time, Code Engine initializes new Function instances for each invocation, but at the same time, tries to maximize the reuse. Only one Function invocation is handled by a Function instance at a single point in time. For Node.js, the Function can be configured with concurrency > 0 to allow multiple invocations to be handled in a single Function instance.\n\n\n\n\n\n Packaging your source code for a Function \n\nFunctions can be packaged in three different ways.\n\n\n\n* as a single file\n* as multiple files (with a folder structure and dependent modules)\n* as a container image\n\n\n\n\n\n\n\n\n\n How can I get started with Functions? \n\nTo deploy a simple Code Engine application with a hello-world sample image, see [Running IBM Code Engine Functions](https://cloud.ibm.com/docs/codeengine?topic=codeengine-fun-tutorial) tutorial.", "title": "", "source": "https://cloud.ibm.com/docs/codeengine?topic=codeengine-cefunctions"}, {"document_id": "ibmcld_14311-2669-4435", "score": 23.12095453210237, "text": "\nIf you use the existing workload edge cluster, you must create the edge bridge profile by using that cluster and change the existing-distributed port group to allow Promiscuous mode and Forged transmits. This setup shares the capacity of the private uplinks from the edge nodes for both private routed and bridged traffic. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-edge-private.\n\nZoom\n\n![Layer 2 bridge setup with workload edge cluster](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/arch-pattern-l2-workload-edge.svg)\n\nFigure 2. Layer 2 bridge setup with workload edge cluster\n\nAlternatively, you can deploy a new edge cluster for bridging. In this case, you must create new edge nodes and create a new edge cluster by using these nodes. When you configure the edge bridge profile, you can then use this edge cluster for bridging only. This alternative scales better, and provides a better dedicated bridging performance. Transport zones are defined in the edge host switch (N-VDS), for example add the new tz-bridge to nvds-bridge.\n\nZoom\n\n![Layer 2 bridge setup with a new bridge edge cluster](https://cloud.ibm.com/docs-content/v1/content/5bdb37c0149145723c5437e8176651928565e722/vmwaresolutions/images/arch-pattern-l2-bridge-edge.svg)\n\nFigure 3. Layer 2 bridge setup with a new bridge edge cluster\n\nMake sure you have the bridged VLANs transport zone (for example tz-bridge) configured on all wanted transport nodes.\n\n\n\n\n\n Considerations \n\nWhen you design or deploy this architecture pattern, consider the following steps:\n\n\n\n* Using the existing workload edge cluster is good for testing the layer 2 capability and for small deployments.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-arch-pattern-bridging"}]}
{"task_id": "ddbbbe7ea13560c5768639207e1ca604<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16417-5155-7505", "score": 43.40150245734594, "text": "\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16481-5154-7504", "score": 43.40150245734594, "text": "\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.\n\nGenerally, a type system that includes many entity types and relation types is open to more interpretation, thus inter-annotator agreement might be lower during the early phases of model development. Looking at the scores, you can see which entity types, for example, have low scores. These low scores are an indication that the annotation guidelines need to be improved. By looking at the scores between pairs of human annotators, you can identify whether a particular annotator consistently shows lower scores than others. This annotator might be having problems understanding the guidelines or using the annotation tools, and thus is a candidate for additional training.\n\n\n\n\n\n Reviewing inter-annotator agreement scores \n\nWhen determining which documents are to be promoted to ground truth, you must review the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\n\n\n About this task \n\nWhen you examine inter-annotator agreement, you examine documents that were annotated by more than one human annotator. If a document is not shared across multiple annotation sets and human annotators, there is no inter-annotator agreement to calculate. When you add annotation sets to a task, ensure that the sets that you want to compare contain the same overlapping documents. You can see which documents are in an annotation set by opening the Assets> Documents page, clicking the Annotation Sets tab, and then clicking the names of the sets.\n\nYou might experience situations in which no overlapping documents are found. This might happen, for example, if you create annotation sets in two rounds and add them to the same task. Even though the annotation sets were created at about the same time, they don't have any documents in common.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16417-3559-5683", "score": 42.395361432623595, "text": "\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1: Inter-annotator Guidelines\n\n\n\n Score Agreement level \n\n <0 Poor \n .01 - .20 Slight \n .21 - .40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16481-3559-5682", "score": 42.395361432623595, "text": "\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task. The value, which can range up to 1 and even be negative, can help you identify weaknesses in the annotation guidelines or particular human annotators. The following guidelines (Landis and Koch, 1977) provide a starting point for assessing overall performance.\n\nTable 1. Inter-annotator guidelines\n\n\n\n Score Agreement level \n\n < 0 Poor \n .01 -.20 Slight \n .21 -.40 Fair \n .41 - .60 Moderate \n .61 - .80 Substantial \n .81 - 1.0 Perfect \n\n\n\nThe score in the other columns is an F1 measure. It represents the level of annotation consistency between a pair of human annotators. The value can range from 0 to 1, where perfect agreement is indicated by the score 1. What constitutes an acceptable level of agreement depends on your domain data and type system. But to provide an example, here are the F1 thresholds that project managers expect to be met or exceeded in projects that are based on the KLUE type system:\n\n\n\n* Mentions with entity types: 0.85\n* Relations: 0.8\n* Coreference chains: 0.9\n\n\n\nInterpreting the scores depends on the complexity of your type system, the amount and complexity of the content annotated, how experienced the human annotators are, and other factors. For example, if the annotation task is focused on labeling parts of speech, you might expect to see a high score because of how well-defined the parts of speech are. But a task that requires deeper analysis of the text, where human interpretation is required, might show lower scores until you take steps to clarify the causes of the ambiguity.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16563-10714-12816", "score": 42.21441783915202, "text": "\nFrom the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\nIn a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_tutml_intro"}, {"document_id": "ibmcld_16464-12399-14287", "score": 42.201835953453525, "text": "\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.\n\nIn this tutorial, the human annotators submitted all the document sets for approval. If the inter-annotator agreement scores are acceptable, you can approve the document sets. If you reject a document set, it is returned to the human annotator for improvement.\n\nFor more information about inter-annotator agreement, see [Building the ground truth](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth).\n\n\n\n\n\n Procedure \n\n\n\n1. Log in to Knowledge Studio as the administrator and select Machine Learning Model > Annotations. Click the Annotation Tasks tab, then click the Test task.\n\nIn the Status column, you can see that the document sets are submitted.\n2. Click Calculate Inter-Annotator Agreement.\n3. View IAA scores for mention, relations, and coreference chains by clicking the first menu. You can also view agreement by pairs of human annotators. You can also view agreement by specific documents. In general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.]", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16417-1764-4158", "score": 41.93743516818792, "text": "\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-build-groundtruth"}, {"document_id": "ibmcld_16481-1764-4158", "score": 41.93743516818792, "text": "\nAs the project manager resolves annotation conflicts, the approved annotations are promoted to ground truth.\n\n\n\nKeep in mind that human annotation always requires judgment calls. The annotation guidelines can do a lot to ensure that text is correctly and consistently annotated, but even the best guidelines are open to interpretation by humans. To obtain ground truth, you will want to spend time training and educating human annotators so that they can make the best judgments when analyzing domain content.\n\n\n\n Inter-annotator agreement \n\nAfter human annotators have annotated the documents, you must determine which documents to promote to ground truth. Start by reviewing the inter-annotator agreement scores. Documents with low scores are candidates to be rejected and returned to the human annotator for improvement.\n\nWhen calculating inter-annotator agreement scores, the system examines all overlapping documents in all annotation sets in the task, regardless of the status of the sets. Because you cannot accept or reject annotation sets until they are in the Submitted status, you might not want to evaluate inter-annotator agreement until all annotation sets are submitted, or you might want to limit your review to only the human annotators who submitted their completed annotation sets.\n\nThe inter-annotator agreement scores show how different human annotators annotated mentions, relations, and coreference chains. You can view the scores by comparing a pair of human annotators (for example, compare all of John's mention annotations to all of Mary's mention annotations). You can also view the scores by comparing specific documents (for example, compare the relation annotations that John made in one document to the relation annotations that Mary made in the same document).\n\nTo help you identify areas that require investigation, scores that fall below the value that you specified for the inter-annotator agreement threshold are highlighted in red. In early stages of your annotation project, you might find that relation scores are often worse than mention scores because a perfect relation annotation requires that the mentions that define the relationship be in agreement first.\n\nThe score in the All column is a Fleiss Kappa score. It represents how consistently the same annotation was applied by multiple human annotators across all overlapping documents in the task.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-build-groundtruth"}, {"document_id": "ibmcld_16464-10867-12930", "score": 40.92691629135279, "text": "\n[This screen capture shows two mentions connected by the relation type, \"founderOf\".](images/wks_tut_annotaterelation.png \"This screen capture shows two mentions connected by the relation type, \"founderOf\".\")\n\n\n\n8. From the status menu, select Completed, and then click the Save button.\n9. Click Open document list to return to the list of documents for this task and click Submit All Documents to submit the documents for approval.\n\n> Note: In a realistic situation, you would create many more annotations and complete all the documents in the set before submitting.\n10. Close this annotation set, and then open the other annotation set in the Test task.\n\nDepending on how you set up the annotation tasks and which users you assigned them to, you might need to log in to Knowledge Studio as the user who is assigned to the other annotation set in the annotation task.\n11. Repeat the same annotations in the Technology - gmanews.tv document, except this time, use the employedBy relation instead of the founderOf relation.\n\nLogging in as another user will help illustrate inter-annotator agreement in the next lesson. But if you have only one user, you can still complete the tutorial to get an understanding of how inter-annotator agreement works.\n12. After you complete the annotations for the second annotation set, click Submit All Documents.\n\n\n\n\n\n\n\n\n\n Lesson 5: Analyzing inter-annotator agreement \n\nIn this lesson, you will learn how to compare the work of multiple human annotators in Knowledge Studio.\n\n\n\n About this task \n\nTo determine whether different human annotators are annotating overlapping documents consistently, review the inter-annotator agreement (IAA) scores.\n\nKnowledge Studio calculates IAA scores by examining all overlapping documents in all document sets in the task, regardless of the status of the document sets. The IAA scores show how different human annotators annotated mentions, relations, and coreference chains. It is a good idea to check IAA scores periodically and verify that human annotators are consistent with each other.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}, {"document_id": "ibmcld_16464-13891-15856", "score": 37.48638278091869, "text": "\nIn general, aim for a score of .8 out of 1, where 1 means perfect agreement. Because you annotated only two entity types in this tutorial, most of the entity type scores are N/A (not applicable), which means no information is available to give a score.\n\nFigure 1. Reviewing inter-annotator scores with users named dave and phil\n\n![This screen capture shows the inter-annotator scores for a task.](https://cloud.ibm.com/docs-content/v1/content/148d3bd95f946aa1bb53ea1540475f522e6b61c9/watson-knowledge-studio-data/images/wks_tutiaa2.png)\n4. After you review the scores, you can decide whether you want to approve or reject document sets that are in the SUBMITTED status. Take one of these actions:\n\n\n\n* If the scores are acceptable for an annotation set, select the check box and click Accept. Documents that do not overlap with other document sets are promoted to ground truth. Documents that do overlap must first be reviewed through adjudication so that conflicts can be resolved. For this tutorial, accept both document sets.\n* If the scores are not acceptable for an annotation set, select the check box and click Reject. The document set needs to be revisited by the human annotator to improve the annotations.\n\n\n\n\n\n\n\n\n\n Results \n\nWhen you evaluated the inter-annotator agreement scores, you saw how different pairs of human annotators annotated the same document. If the inter-annotator agreement score was acceptable, you accepted the document set.\n\n\n\n\n\n\n\n Lesson 6: Adjudicating conflicts in annotated documents \n\nIn this lesson, you will learn how to adjudicate conflicts in documents that overlap between document sets in Knowledge Studio.\n\n\n\n About this task \n\nWhen you approve a document set, only the documents that do not overlap with other document sets are promoted to ground truth. If a document is part of the overlap between multiple document sets, you must adjudicate any annotation conflicts before the document can be promoted to ground truth.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-wks_tutml_intro"}]}
{"task_id": "674aa142d92a6b4262de254df0c3f7b2<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13074-16820-18514", "score": 56.05709415094677, "text": "\nEmotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,\n\"joy\": 0.626655,\n\"anger\": 0.02303,\n\"fear\": 0.018884,\n\"sadness\": 0.096802\n}\n}\n}\n\nIn the preceding example, you could query the joy Emotion by accessing enriched_text.emotion.document.emotion.joy\n\nEmotion Analysis analyzes your text and calculates a score for each emotion (anger, disgust, fear, joy, sadness) on a scale of 0.0 to 1.0. If the score of any emotion is 0.5 or higher, then that emotion is detected. The higher the score above 0.5, the higher the relevance. In the snippet shown, joy has a score above 0.5, so Watson detected joy.\n\nEmotion Analysis is supported in English only.\n\n\n\n\n\n Element classification \n\nThe Element Classification enrichment is deprecated and will no longer be available, effective 10 July 2020.\n\nParses elements (sentences, lists, tables) in governing documents to classify important types and categories For more information, see [Element classification](https://cloud.ibm.com/docs/discovery?topic=discovery-element-classification).\n\n[Smart Document Understanding](https://cloud.ibm.com/docs/discovery?topic=discovery-sdu) is unavailable if this enrichment is used.\n\n\n\n Enrichment pricing \n\nEnrichment pricing information is available on [IBM Cloud](https://cloud.ibm.com/catalog/services/discovery).\n\n\n\n\n\n Enrichment language support", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-configservice"}, {"document_id": "ibmcld_13074-15255-17243", "score": 50.157587228285806, "text": "\nSee [Entity extraction](https://cloud.ibm.com/docs/discovery?topic=discovery-configserviceentity-extraction) and [Keyword extraction](https://cloud.ibm.com/docs/discovery?topic=discovery-configservicekeyword-extraction) about those enrichments.\n\nThe subject, action, and object are extracted for every sentence that contains a relation.\n\n\n\n\n\n Sentiment analysis \n\nIdentifies attitude, opinions, or feelings in the content that is being analyzed. Discovery can calculate overall sentiment within a document, sentiment for user-specified targets, entity-level sentiment, quotation-level sentiment, directional-sentiment, and keyword-level sentiment. The combination of these capabilities supports a variety of use cases ranging from social media monitoring to trend analysis.\n\nExample portion of a document enriched with Sentiment Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"sentiment\": {\n\"document\": {\n\"score\": 0.459813,\n\"label\": \"positive\"\n}\n}\n\nIn the preceding example, you could query the sentiment label by accessing enriched_text.sentiment.document.label\n\nThe label is the overall sentiment of the document (positive, negative, or neutral). The sentiment label is based on the score; a score of 0.0 would indicate that the document is neutral, a positive number would indicate the document is positive, a negative number would indicate the document is negative.\n\n\n\n\n\n Emotion analysis \n\nDetects anger, disgust, fear, joy, and sadness implied in English text. Emotion Analysis can detect emotions that are associated with targeted phrases, entities, or keywords, or it can analyze the overall emotional tone of your content.\n\nExample portion of a document enriched with Emotion Analysis:\n\n{\n\"text\": \"The stockholders were pleased that Acme Corporation plans to build a new factory in Atlanta, Georgia.\",\n\"enriched_text\": {\n\"emotion\": {\n\"document\": {\n\"emotion\": {\n\"disgust\": 0.102578,", "title": "", "source": "https://cloud.ibm.com/docs/services/discovery?topic=discovery-configservice"}, {"document_id": "ibmcld_16313-8575-10638", "score": 40.526389201925916, "text": "\nFor more information on uploading or downloading example phrases, see [Adding more examples](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-understand-questionsunderstand-questions-adding-more-examples).\n\n\n\n\n\n\n\n Editing the fallback action \n\nThe built-in Fallback action is automatically provided with each assistant and cannot be deleted. However, you can edit the Fallback action to modify the conversation your users have with the assistant when errors occur. For example, you might want to add steps or modify step conditions to provide more control over how specific error conditions are handled.\n\nTo edit the Fallback action, click Set by assistant in the list of actions, and then click Fallback.\n\nZoom\n\n![Fallback built-in action](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/fallback-action.png)\n\nFallback built-in action\n\nWhenever the Fallback action is triggered, the assistant also sets a value for the Fallback reason session variable. This value indicates what kind of situation led to the Fallback action being triggered. By default, this variable can have one of five values:\n\n\n\n* Step validation failed: The customer repeatedly gave answers that were not valid for the expected customer response type.\n* Agent requested: The customer directly asked to be connected to a live agent.\n* No action matches: The customer repeatedly made requests or asked questions that the assistant did not understand.\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errors"}, {"document_id": "ibmcld_16313-10077-11045", "score": 38.63243825622506, "text": "\n* Danger word detected: The customer uses words or phrases that match the Connect to agent step in the Trigger word detected action.\n* Profanity detected: The customer repeatedly used words or phrases that match the Show warning step in the Trigger word detected action.\n\n\n\nFor more information about the Trigger word detected action, see [Detecting trigger words](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-trigger-words).\n\nThe Fallback action defines five conditional steps, one for each possible value of the Fallback reason variable. Each step sends a message to the customer, based on the error condition, and then uses the Connect to agent feature to transfer the conversation to a live agent. (For more information about this feature, see [Connecting to a live agent](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-human-agent).) You can modify these steps if you want to handle an error condition in a different way.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errors"}, {"document_id": "ibmcld_16251-6430-8753", "score": 37.44748092270035, "text": "\nPortuguese (Brazilian) (pt-br) GA GA GA \n Spanish (es) GA GA GA \n Universal (xx) GA GA GA \n\n\n\nThe Watson Assistant service supports multiple languages as noted, but the user interface itself (such as descriptions and labels) is in English. All supported languages can be input and trained through the English interface.\n\nGB18030 compliance: GB18030 is a Chinese standard that specifies an extended code page for use in the Chinese market. This code page standard is important for the software industry because the China National Information Technology Standardization Technical Committee mandates that any software application that is released for the Chinese market after September 1, 2001, be enabled for GB18030. The Watson Assistant service supports this encoding, and is certified GB18030-compliant\n\n\n\n\n\n\n\n Changing an assistant language \n\nAfter an assistant is created, its language cannot be modified.\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents with the Watson Assistant service. As such, both accented and nonaccented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever, for some languages like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the nonaccented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system provides the highest confidence scores in entities with exact matches. For example, barrio isn't detected if barri\u00f3 is in the training set; and barri\u00f3 isn't detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words that use the Spanish letter \u00f1 versus the letter n, such as \"u\u00f1a\" versus \"una\". In this case, the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-admin-language-support"}, {"document_id": "ibmcld_16356-7-2036", "score": 37.34783158341903, "text": "\nDetecting trigger words \n\nUse the Trigger word detected action to add words or phrases to two separate groups. The first group connects customers with an agent. The second group shows customers a customizable warning message.\n\nBy default, this action has two steps\u2014the Connect to agent step and the Show warning step. To see how this action works, click Set by assistant in the list of actions, and then click Trigger word detected.\n\nThis is a beta feature that is available for evaluation and testing purposes.\n\n\n\n Connect to agent \n\nThe first step of the Trigger word detected action is the Connect to agent step. The Connect to agent step goes to the Fallback action if any trigger words are detected in the customer's input. Use this step to capture any key phrases where it\u2019s important to connect a customer with a live agent rather than activate any further actions.\n\nFor example, you might add hurt and harm as trigger words for the Connect to agent step:\n\nZoom\n\n![Adding trigger words to the Connect to agent step](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/connect-to-agent-phrases.png)\n\nAdding trigger words to the Connect to agent step\n\nIn this example, a customer enters a word or phrase including hurt or harm, which triggers the Fallback action. Step 4 has:\n\n\n\n* Danger word detected as the fallback reason.\n* The default message: It seems this conversation would be best managed by a human agent. Let me connect you to one of our agents. You can customize this message.\n* And then set to Connect to agent (action ends).\n\n\n\nFor more information about the Fallback action, see [Editing the fallback action](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n\n\n Show warning \n\nThe second and final step of the Trigger word detected action is the Show warning step. The Show warning step shows a customizable warning message to your customer if any trigger words are detected in the customer's input.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-trigger-phrases"}, {"document_id": "ibmcld_16356-1613-3336", "score": 36.6329929423151, "text": "\nFor more information about the Fallback action, see [Editing the fallback action](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).\n\n\n\n\n\n Show warning \n\nThe second and final step of the Trigger word detected action is the Show warning step. The Show warning step shows a customizable warning message to your customer if any trigger words are detected in the customer's input. Use this step to discourage customers from interacting with your assistant in unacceptable ways, such as using profanity.\n\nFor example, you might add darn, dang, and heck as trigger words for the Show warning step:\n\nZoom\n\n![Adding trigger words to the Show warning step](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/show-warning-phrases.png)\n\nAdding trigger words to the Show warning step\n\nIn this example, a customer enters darn, dang, or heck, the assistant responds with Please use appropriate language when interacting with the assistant. You can customize this message.\n\nIf the customer triggers the Show warning step again, the Fallback action is triggered. The default setting is if attempts exceed 2 total tries. You can customize this setting.\n\nIn the Fallback action, step 5 has:\n\n\n\n* Profanity detected as the fallback reason.\n* The default message: It seems this conversation would be best managed by a human agent. Let me connect you to one of our agents. You can customize this message.\n* And then set to Connect to agent (action ends).\n\n\n\nFor more information about the Fallback action, see [Editing the fallback action](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-handle-errorsfallback-action).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-trigger-phrases"}, {"document_id": "ibmcld_13761-7-2364", "score": 35.80281339311161, "text": "\nModifying speech synthesis with expressive neural voices \n\nThe expressive neural voices that are available with the IBM Watson\u00ae Text to Speech service offer some additional features that are not available with other types of voices: using speaking styles, emphasizing interjections, and emphasizing words. These features are available for both the HTTP and WebSocket interfaces.\n\nThe features involve the use of elements of the Speech Synthesis Markup Language (SSML). The descriptions of the features provide information about how they interact with related SSML elements and attributes.\n\n\n\n Using speaking styles \n\nThe expressive neural voices determine the sentiment of the text from the context of its words and phrases. The speech that they produce, in addition to having a very conversational style, reflects the mood of the text. The expressive voices naturally express gratitude, thankfulness, happiness, empathy, confusion, and other sentiments by default, with no explicit additional tagging.\n\nHowever, you can embellish the voices' natural tendencies by using the <express-as> element with the required style attribute to indicate that all or some of the text is to emphasize specific characteristics. These characteristics are referred to as speaking styles:\n\n\n\n* cheerful - Expresses happiness and good news. The style is upbeat, welcoming, and conveys a positive message.\n* empathetic - Expresses empathy and compassion. The style has sympathetic undertones, but it is not excessively sorrowful.\n* neutral - Expresses objectivity and evenness. The style strives for less emotion, and instead conveys a more even and instructional tone.\n* uncertain - Expresses uncertainty and confusion. The style conveys the feeling of being unsure or in doubt.\n\n\n\nIn many cases, the effect of the styles is very subtle. In such cases, the differences might not be readily discernible from the default expressive tone. But there are instances where the style can audibly enhance the voices' inherent ability to detect and express emotion. The differences are often detectable only on certain words and phrases.\n\nTable 1 provides examples of each available style for the <express-as> element. To demonstrate the effect of the styles, the table provides two samples for each example. The first sample speaks the text with the default en-US_EmmaExpressive voice.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-synthesis-expressive"}, {"document_id": "ibmcld_03353-8238-10149", "score": 35.61746283939684, "text": "\n[Bidi options](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/bidi-options.png)\n3. Click the X to close the page. Your changes are saved automatically.\n\n\n\n\n\n\n\n Working with accented characters \n\nIn a conversational setting, users might or might not use accents while interacting with the Watson Assistant service. As such, both accented and non-accented versions of words might be treated the same for intent detection and entity recognition.\n\nHowever for some languages, like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity might implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word \"barri\u00f3\", which has an accent and corresponds to the past tense of the verb \"barrer\" (to sweep), your assistant can also match the word \"barrio\" (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as \"u\u00f1a\" vs. \"una\". In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-language-support"}, {"document_id": "ibmcld_16364-192793-195089", "score": 35.5616784913593, "text": "\nThe name you specify is saved as a title attribute of the node in the workspace JSON file and the system uses a unique ID that is stored in the name attribute to reference the node.\n\n\n\n\n\n 23 August 2017 \n\nUpdates to Korean, Japanese, and Italian\n: Language support has been enhanced for Korean, Japanese, and Italian. Note that the Watson Assistant service learning models may have been updated as part of this enhancement, and when you retrain your model any changes will be applied.\n\n\n\n\n\n 10 August 2017 \n\nAccent normalization\n: In a conversational setting, users may or may not use accents while interacting with the Watson Assistant service. As such, an update has been made to the algorithm so that accented and non-accented versions of words are treated the same for intent detection and entity recognition.\n\nHowever, for some languages like Spanish, some accents can alter the meaning of the entity. Thus, for entity detection, although the original entity may implicitly have an accent, your assistant can also match the non-accented version of the same entity, but with a slightly lower confidence score.\n\nFor example, for the word barri\u00f3, which has an accent and corresponds to the past tense of the verb barrer (to sweep), your assistant can also match the word barrio (neighborhood), but with a slightly lower confidence.\n\nThe system will provide the highest confidence scores in entities with exact matches. For example, barrio will not be detected if barri\u00f3 is in the training set; and barri\u00f3 will not be detected if barrio is in the training set.\n\nYou are expected to train the system with the proper characters and accents. For example, if you are expecting barri\u00f3 as a response, then you should put barri\u00f3 into the training set.\n\nAlthough not an accent mark, the same applies to words using, for example, the Spanish letter \u00f1 vs. the letter n, such as u\u00f1a vs. una. In this case the letter \u00f1 is not simply an n with an accent; it is a unique, Spanish-specific letter.\n\nYou can enable fuzzy matching if you think your customers will not use the appropriate accents, or misspell words (including, for example, putting a n instead of a \u00f1), or you can explicitly include them in the training examples.\n\nNote: Accent normalization is enabled for Portuguese, Spanish, French, and Czech.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-watson-assistant-release-notes"}]}
{"task_id": "927077bd895f0c292618f4a34789bef3<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16601-1150-2518", "score": 69.62168740787425, "text": "\n* [Salesforce SDK](https://github.com/watson-developer-cloud/salesforce-sdk)\n* [Swift SDK](https://github.com/watson-developer-cloud/swift-sdk)\n* [Unity SDK](https://github.com/watson-developer-cloud/unity-sdk)\n\n\n\n\n\n\n\n SDK updates and deprecation \n\nThe supported Watson SDKs are updated according to the following guidelines.\n\n\n\n Semantic versioning \n\nSupported Watson SDKs adhere to semantic versioning with releases labeled as {major}.{minor}.{patch}.\n\n\n\n\n\n Release frequency \n\nSDKs are released independently and might not update on the same schedule.\n\n\n\n* The current releases of the Watson SDKs are updated on a 2- to 6-week schedule. These releases are either minor updates or patches that do not include breaking changes. You can update to any version of the SDK with the same major version number.\n* Major updates that might include breaking changes are released approximately every 6 months.\n\n\n\n\n\n\n\n Deprecated release \n\nWhen a major version is released, support continues on the previous major release for 12 months in a deprecation period. The deprecated release might be updated with bug fixes, but no new features will be added and documentation might not be available.\n\n\n\n\n\n Obsolete release \n\nAfter the 12-month deprecation period, a release is obsolete. The release might be functional but is unsupported and not updated. Update to the current release.", "title": "", "source": "https://cloud.ibm.com/docs/watson?topic=watson-using-sdks"}, {"document_id": "ibmcld_15507-5434-7003", "score": 68.39213464291142, "text": "\nTo remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manageschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates, the obsolete-at date must be after the deprecate-at date.\n\nibmcloud is image-update IMAGE [--deprecate-at YYYY-MM-DDThh:mm:ss+hh:mm] [--obsolete-at YYYY-MM-DDThh:mm:ss+hh:mm]\n\nIf you want to change the deprecate-at and obsolete-at date and time entries, you can run these commands again.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manage"}, {"document_id": "ibmcld_15647-27849-29558", "score": 67.08995948031088, "text": "\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=uischedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=ui"}, {"document_id": "ibmcld_15646-27823-29559", "score": 66.70994808873293, "text": "\nIf you use both the --reset-deprecate-at and --reset-obsolete-at options, the image status returns to available.\n\n\n\n\n\n Change the custom image lifecycle status by using the API \n\nYou can change the lifecycle status of an IBM Cloud VPC custom image by using the application programming interface (API). You can make an immediate status change or schedule a status change to happen later.\n\nTo make an immediate status change, use one of the following examples. For the$image_id variable, specify the ID of the custom image for the status change.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-imagesschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images"}, {"document_id": "ibmcld_15646-25256-26940", "score": 66.59534352408438, "text": "\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-imagesschedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images"}, {"document_id": "ibmcld_15647-25269-26966", "score": 66.45695223210419, "text": "\nYou can make an immediate status change by using the ibmcloud is image-deprecate or ibmcloud is image-obsolete commands. You can also schedule these status changes for a future date and time by using the ibmcloud is image-update command. Specify the name or ID of the custom image with the IMAGE variable.\n\nTo make an immediate status change, use one of the following examples.\n\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the CLI](https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=uischedule-reset-ilm-status-change-cli). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change the image lifecycle status to deprecate.\n\nibmcloud is image-deprecate IMAGE\n* Change the image lifecycle status to obsolete.\n\nibmcloud is image-obsolete IMAGE\n\n\n\nTo schedule a status change, use the following example.\n\nFor the deprecate-at or obsolete-at option, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=ui"}, {"document_id": "ibmcld_15507-8094-9618", "score": 65.13570230078912, "text": "\nYou can make an immediate status change only if a future status change is not scheduled. To remove a scheduled status change, see [Remove a scheduled custom image lifecycle status change by using the API](https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manageschedule-ilm-reset-status-change-API). After you remove the scheduled status change, you can make an immediate status change.\n\n\n\n* Change image lifecycle status to deprecated.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/deprecate?version=2023-02-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n* Change the image lifecycle status to obsolete.\n\ncurl -X POST \"$vpc_api_endpoint/v1/images/$image_id/obsolete?version=2023-12-21&generation=2\" -H \u201cAuthorization: Bearer $iam_token\u201d\n\n\n\nTo schedule a status change, use one of the following examples.\n\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-image-from-volume-vpc-manage"}, {"document_id": "ibmcld_15175-10224-11754", "score": 60.773447676056364, "text": "\necc68c2f-96a1-4862-bc86-14f47e5d9ed8 aa-1-bx-boot-1617035447000\nCreated 2021-05-20T09:43:16+08:00\nVisibility private\nFile size(GB) -\nEncryption none\nResource group f22cf48f-8836-4527-9131-1d7c73ba85e9\n\n\n\n\n\n\n\n Schedule custom image lifecycle status changes by using the CLI \n\nWhen you import a custom image by using the command-line interface (CLI), you can also schedule the lifecycle status changes of the IBM Cloud VPC custom image at the same time by using options of the ibmcloud is image-create command.\n\nSpecify the name of the custom image to be created by using the IMAGE_NAME variable and the source by using the --source-volume option to indicate that the source is an existing boot volume.\n\nTo schedule the deprecate-at or obsolete-at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecate-at and obsolete-at dates and times, the deprecate-at date must be after the obsolete-at date and time.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-create-ifv"}, {"document_id": "ibmcld_15646-29196-30599", "score": 60.02148543657976, "text": "\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images"}, {"document_id": "ibmcld_15647-29235-30638", "score": 60.02148543657976, "text": "\nFor the deprecation_at or obsolescence_at properties, specify a date in the ISO 8601 (YYYY-MM-DDThh:mm:ss+hh:mm) date and time format.\n\n\n\n* YYYY is the four digit year\n* MM is the two digit month\n* DD is the two digit day\n* T separates the date and time information\n* hh is the two digit hours\n* mm is the two digit minutes\n* +hh:mm or -hh:mm is the UTC time zone\n\n\n\nThus, the date of 30 September 2023 at 8:00 p.m. in the North American Central Standard Time Zone (CST) would be 2023-09-30T20:00:00-06:00\n\nWhen scheduling the date and time, you can't use your current date and time. For example, if it is 8 a.m. on June 12, then the scheduled date and time must be after 8 a.m. on June 12. If you define both the deprecation_at and obsolescence_at dates and times, the obsolescence_at date must be after the deprecation_at date and time.\n\n\n\n* Schedule a status change to deprecated.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\"deprecation_at\": \"2023-03-01T06:11:28+05:30\" }'\n* Schedule a status change to obsolete.\n\ncurl -X PATCH \"$vpc_api_endpoint/v1/images/$image_id?version=2022-11-21&generation=2\" -H \"Authorization: Bearer $iam_token\" -d '{\n\u201cobsolescence_at\": \"2023-12-31T06:11:28+05:30\" }'\n\nIf you want to change the deprecation_at and obsolescence_at date and time entries, you can run these commands again.", "title": "", "source": "https://cloud.ibm.com/docs/vpc?topic=vpc-managing-custom-images&interface=ui"}]}
{"task_id": "1c041ce47a81941c26899fdf08bde961<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16551-0-1579", "score": 16.759225026661053, "text": "\n\n\n\n\n\n\n  How can I address storage space limits? \n\nDepending on your subscription plan, you might reach the storage limit that is specified for your plan and be prevented from completing tasks.\n\n  What\u2019s happening \n\nYou might see a message about exceeding the allowed storage space when you attempt to perform one of these tasks:\n\n\n\n*  Upload documents or dictionaries\n*  Deploy a model or version a model\n*  Run a pre-annotator on documents\n\n\n\n  Why it\u2019s happening \n\nThe storage limit is met or exceeded if the action proceeds.\n\n  How to fix it \n\nThe largest consumers of storage space are machine learning and rule-based models. To free up space, you can take the following actions:\n\n\n\n*  Delete snapshot versions of any models that you do not expect to need to revert to.\n*  Delete any models that you do not need.\n*  If your models are too important to delete, consider upgrading your plan to one that provides a larger allotment of storage space.\n\n\n\nAfter you remove models or model versions, wait an hour before you retry the action that resulted in the error message. It can take up to an hour for the storage space that you freed up to be available for use.\n\nTo manage your monthly bill, if the Admin role is assigned to you and you have a Premium or Standard account, you can set a storage limit on the Service Details page in Knowledge Studio. To see the Service Details page and set the storage limit, from the top navigation bar in Knowledge Studio, click the Settings icon, click the View/modify service details link, and then click the Set storage limit link.\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-wks_ts_storage"}, {"document_id": "ibmcld_01241-13660-15370", "score": 13.590428558951643, "text": "\n-h, --help Show this message and exit.\n\nIf you're using the replication feature, be sure that the schedule that you're deleting isn't the schedule that is used by replication. For more information about deleting a replication schedule, see [here](https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-replication).\n\n\n\n\n\n Deleting a snapshot in the UI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. Deletion is done through Storage > File Storage for Classic.\n\n\n\n1. Click your storage volume and click Snapshot to see the list of existing snapshots.\n2. Click Actions![Actions icon](https://cloud.ibm.com/docs-content/v1/content/04e9937a86546143babfc65ea21fdd4ea2d12d13/icons/action-menu-icon.svg) next to a particular snapshot and click Delete to delete the snapshot. This deletion doesn't affect any future or past snapshots on the same schedule as snapshots don't depend on each other.\n\n\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Deleting a snapshot from the SLCLI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. You can delete a snapshot from the SLCLI by using the following command.\n\n slcli file snapshot-delete --help\nUsage: slcli file snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-managingSnapshots"}, {"document_id": "ibmcld_04693-5720-7686", "score": 13.519052076887029, "text": "\nFor example, you might scale from 256 - 1256 MB by changing the memory quota on the app details page. However, because the disk quota remained the same, you didn't get more disk space.\n\n Why it\u2019s happening \n\nThe default disk quota that is allocated for an app is 1 GB. If you need more disk space, you must manually specify the disk quota.\n\n How to fix it \n\nUse one of the following methods to specify your disk quota. The maximum disk quota that you can specify is 2 GB. If 2 GB is still not enough, try an external service such as [Cloud Object Storage](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage).\n\n\n\n* In the manifest.yml file, add the following item:\n\ndisk_quota: <disk_quota>\n* Use the -k option with the ibmcloud cf push command when you push your app to IBM Cloud:\n\nibmcloud cf push appname -p app_path -k <disk_quota>\n\n\n\n\n\n\n\n Org's services limit is exceeded \n\nIf you are a Lite account user, you might be unable to create an app in IBM Cloud if you exceeded your organization's services limit.\n\n What\u2019s happening \n\nWhen you try to create an app in IBM Cloud, the following error message is displayed:\n\nBXNUI2032E: The <service_instances> resource wasn't created. While Cloud Foundry was being contacted to create the resource, an error occurred. Cloud Foundry message: \"You have exceeded your organization's services limit.\"\n\n Why it\u2019s happening \n\nThis error occurs when you exceed the limit on the number of service instances that you can have for your account.\n\n How to fix it \n\nDelete any services instances that aren't needed, or remove the limit on the number of service instances that you can have.\n\n\n\n* To delete a services instance, you can use the IBM Cloud console or the command line interface.\n\nTo use the IBM Cloud console to delete a service instance, complete the following steps: 1. In the resource list, click the Actions menu for the service that you want to delete. 2.", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-ts-cf-apps"}, {"document_id": "ibmcld_00241-13788-15540", "score": 13.509891533460145, "text": "\n-h, --help Show this message and exit.\n\nIf you're using the replication feature, be sure that the schedule you're deleting isn't the schedule that is used by replication. For more information about deleting a replication schedule, see [Replicating Data](https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-replication).\n\n\n\n\n\n Deleting a snapshot in the UI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. Deletion is done through Storage > Block Storage for Classic.\n\n\n\n1. Click your storage volume and click Snapshot to see the list of existing snapshots.\n2. Click Actions![Actions icon](https://cloud.ibm.com/docs-content/v1/content/14cf2f2f32b430cf4ed67ad14b3cecc010f91c45/icons/action-menu-icon.svg) next to a particular snapshot and click Delete. Click the confirmation box that warns about possible data loss, then click Delete. This deletion doesn't affect any future or past snapshots on the same schedule as snapshots don't depend on each other.\n\n\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations (oldest first).\n\n\n\n\n\n Deleting a snapshot from the SLCLI \n\nSnapshots that are no longer needed can be manually removed to free up space for future snapshots. You can delete a snapshot from the SLCLI by using the following command.\n\n slcli block snapshot-delete\nUsage: slcli block snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI", "title": "", "source": "https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-managingSnapshots"}, {"document_id": "ibmcld_16452-7020-8905", "score": 12.195677756797451, "text": "\nFor help using the ground truth editor, see [Annotating documents](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-user-guide).\n\n\n\n\n\n\n\n Experimental services and features: What does experimental mean? \n\nIBM releases experimental services and features for you to try out. These services might be unstable, change frequently in ways that are not compatible with earlier versions, and might be discontinued with short notice. These services and features are not recommended for use in production environments.\n\nFor more information about experimental services, see the [IBM Cloud documentation ![External link icon](https://cloud.ibm.com/docs-content/v1/content/icons/launch-glyph.svg)](https://cloud.ibm.com/docs/get-support/servicessupport.htmls-services-exporcont). For the full details of experimental services, see the latest version of the [IBM Cloud Service Description ![External link icon](https://cloud.ibm.com/docs-content/v1/content/icons/launch-glyph.svg)](https://www.ibm.com/software/sla/sladb.nsf/sla/bm?OpenDocument).\n\n\n\n\n\n Storage space issues \n\n\n\n Symptoms \n\nYou might see a message about having exceeded the allowed storage space when you attempt to perform one of these tasks:\n\n\n\n* Upload documents or dictionaries\n* Deploy a model or version a model\n* Run a pre-annotator on documents\n\n\n\n\n\n\n\n Causes \n\nThe storage limit has been met or would be exceeded if the action were to proceed.\n\n\n\n\n\n Resolving the problem \n\nThe largest consumers of storage space are machine learning and rule-based models. To free up space, you can take the following actions:\n\n\n\n* Delete snapshot versions of any models that you do not expect to need to revert to.\n* Delete any models that you do not need.\n* If your models are too important to delete, consider increasing the amount of storage in your deployment.\n\n\n\n\n\n\n\n\n\n Contacting IBM Support", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-troubleshooting"}, {"document_id": "ibmcld_05149-4519-6367", "score": 12.099470074483271, "text": "\nIf not, follow the [getting started tutorial](https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-getting-started-cloud-object-storage) to obtain the prerequisites and become familiar with the console.\n\n\n\n Set a list of authorized IP addresses using a legacy firewall \n\n\n\n1. Start by selecting Storage to view your resource list.\n2. Next, select the service instance with your bucket from within the Storage menu. This takes you to the Object Storage Console.\n3. Choose the bucket that you want to limit access to authorized IP addresses.\n4. Select Access policies from the navigation menu.\n5. Select the Authorized IPs tab.\n6. Click Add IP addresses, then choose Add.\n7. Specify a list of IP addresses in [CIDR notation](https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing), for example 192.168.0.0/16, fe80:021b::0/64. Addresses can follow either IPv4 or IPv6 standards.\n8. Click Add.\n9. The firewall will not be enforced until the address is saved in the console. Click Save all to enforce the firewall.\n10. Note that all objects in this bucket are only accessible from those IP addresses.\n\n\n\n\n\n\n\n Remove any IP address restrictions using a legacy firewall \n\n\n\n1. From the Authorized IPs tab, check the boxes next to any IP addresses or ranges to remove from the authorized list.\n2. Select Delete, and then confirm the dialog box by clicking Delete again.\n3. The updated list won't be enforced until the changes are saved in the console. Click Save all to enforce the new rules.\n4. Now all objects in this bucket are only accessible from these IP addresses!\n\n\n\nIf there are no authorized IP addresses listed this means that normal IAM policies will apply to the bucket, with no restrictions on the user's IP address, unless there are context-based restrictions in place.\n\n\n\n\n\n Set a legacy firewall through an API", "title": "", "source": "https://cloud.ibm.com/docs/cloud-object-storage?topic=cloud-object-storage-setting-a-firewall"}, {"document_id": "ibmcld_10407-21814-23415", "score": 12.054864932969696, "text": "\nTo connect your cluster to resources in an on-premises network or another VPC, see [Using VPN with your VPC](https://cloud.ibm.com/docs/vpc?topic=vpc-vpn-onprem-example). \n Subnets <br><br> * See [VPC networking limitations](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-subnetsvpc_basics_limitations).<br> * Do not delete the subnets that you attach to your cluster during cluster creation or when you add worker nodes in a zone. If you delete a VPC subnet that your cluster used, any load balancers that use IP addresses from the subnet might experience issues, and you might be unable to create new load balancers.<br><br><br> \n VPC load balancer See [VPC load balancer limitations](https://cloud.ibm.com/docs/openshift?topic=openshift-vpc-lbaaslbaas_limitations). \n\n\n\n\n\n\n\n Storage \n\nKeep in mind that the [service](https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_limitationstech_limits) limitations also apply.\n\n\n\nVPC cluster storage limitations\n\n Category Description \n\n Storage class for profile sizes For more information, see [available volume profiles](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-profiles). \n Supported types You can set up IBM Cloud Object Storage and Cloud Databases only. \n Volume attachments See [Volume attachment limits](https://cloud.ibm.com/docs/vpc?topic=vpc-attaching-block-storagevol-attach-limits). \n Portworx Review the [Portworx limitations](https://cloud.ibm.com/docs/openshift?topic=openshift-storage_portworx_planportworx_limitations). \n Block Storage for VPC The default storage class in VPC clusters can not be changed.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-openshift_limitations"}, {"document_id": "ibmcld_00241-15158-16579", "score": 11.696150837994674, "text": "\nslcli block snapshot-delete\nUsage: slcli block snapshot-delete [OPTIONS] SNAPSHOT_ID\n\nOptions:\n-h, --help Show this message and exit.\n\nManual snapshots that aren't deleted in the portal manually, are automatically deleted when you reach space limitations. The oldest snapshot is deleted first.\n\n\n\n\n\n Restoring storage volume to a specific point in time by using a snapshot in the UI \n\nYou might need to take your storage volume back to a specific point in time because of user-error or data corruption.\n\n\n\n1. Unmount and detach your storage volume from the host to ensure the host is not connecting to the volume during the restore for any reason.\n\n\n\n* [Unmounting Block Storage for Classic volumes on Linux\u00ae server](https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-mountingLinuxunmountingLin)\n* [Unmounting Block Storage for Classic volumes on Microsoft\u00ae server](https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-mountingWindowsunmountingWin)\n\n\n\n2. Go to the [IBM Cloud\u00ae console](https://cloud.ibm.com/login). From the menu, select Classic Infrastructure![Classic icon](https://cloud.ibm.com/docs-content/v1/content/14cf2f2f32b430cf4ed67ad14b3cecc010f91c45/icons/classic.svg).\n3. Click Storage, Block Storage for Classic.\n4. Scroll on the list, and click your volume to be restored. The Snapshots page displays the list of all saved snapshots along with their size and creation date.\n5. Click Actions!", "title": "", "source": "https://cloud.ibm.com/docs/BlockStorage?topic=BlockStorage-managingSnapshots"}, {"document_id": "ibmcld_01225-7204-8862", "score": 11.58867129310006, "text": "\nUnmount, then mount the modified volume, so the OS can recognize the extra storage space.\n\n\n\n\n\n Resizing storage with Terraform \n\nYou can increase your storage capacity by using the ibm_storage_file resource, and specifying a different number in the capacity argument. The following example increases the capacity of an Endurance volume to 40 GB.\n\nresource \"ibm_storage_file\" \"fs_endurance\" {\ntype = \"Endurance\"\ndatacenter = \"dal09\"\ncapacity = 40\niops = 0.25\n}\n\nThe following example increases the capacity of a Performance volume to 40 GB.\n\nresource \"ibm_storage_file\" \"fs_performance\" {\ntype = \"Performance\"\ndatacenter = \"dal09\"\ncapacity = 40\niops = 100\n}\n\nFor more information about the arguments and attributes, see [ibm_storage_file](https://registry.terraform.io/providers/IBM-Cloud/ibm/latest/docs/resources/storage_file).\n\nUnmount, then mount the modified volume, so the OS can recognize the extra storage space.\n\n\n\n\n\n Expanding Storage over 12 TB \n\nIf you need to increase your Storage volume capacity beyond 12 TB, you can request to be added to the allowlist by submitting a [support case](https://cloud.ibm.com/unifiedsupport/cases/add). When the request is approved by the Offering Manager, you're going to be notified through the case process. You're also going to see the option to increase your storage up to 24 TB in the console.\n\nThe number of operations that can be performed on the storage is limited. This limit is 180k IOPS. So if you want to provision a volume with 10 IOPS, your maximum volume size is 18 TB. If you want to provision the maximum size of 24 TB, then the maximum rate of reads and writes to the volume is 4 IOPS per GB.", "title": "", "source": "https://cloud.ibm.com/docs/FileStorage?topic=FileStorage-expandCapacity"}, {"document_id": "ibmcld_05964-14660-16155", "score": 11.502767697773974, "text": "\nIf you delete a VPC subnet that your cluster used, any load balancers that use IP addresses from the subnet might experience issues, and you might be unable to create new load balancers.<br><br><br> \n VPC load balancer See [VPC load balancer limitations](https://cloud.ibm.com/docs/containers?topic=containers-vpc-lbaaslbaas_limitations). \n\n\n\n\n\n\n\n Storage \n\nKeep in mind that the [service](https://cloud.ibm.com/docs/containers?topic=containers-limitationstech_limits) limitations also apply.\n\n\n\nVPC cluster storage limitations\n\n Category Description \n\n Storage class for profile sizes For more information, see [available volume profiles](https://cloud.ibm.com/docs/vpc?topic=vpc-block-storage-profiles). \n Supported types You can set up Block Storage for VPC, IBM Cloud Object Storage and Cloud Databases only.<br><br><br><br> * [Block Storage for VPC](https://cloud.ibm.com/docs/containers?topic=containers-vpc-block) is available as a cluster add-on. Make sure to [attach a public gateway to all the VPC subnets](https://cloud.ibm.com/docs/vpc?topic=vpc-creating-vpc-resources-with-cli-and-api&interface=cliattach-public-gateway-cli) that the cluster uses so that you can provision Block Storage for VPC.<br> * [IBM Cloud Object Storage](https://cloud.ibm.com/docs/containers?topic=containers-storage_cos_install) is available as a Helm chart.<br><br><br> \n Volume attachments See [Volume attachment limits](https://cloud.ibm.com/docs/vpc?topic=vpc-attaching-block-storagevol-attach-limits).", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-limitations"}]}
{"task_id": "47b2471404382af6e973013ab1cf96b9<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_12865-4-1690", "score": 20.843784308595545, "text": "\n* UI\n* API\n\n\n\n\n\n\n\n Defining your pricing model for software \n\nWhen onboarding your product, you need to define the pricing model for your software. Currently, the IBM Cloud\u00ae catalog supports free plans and bring your own license (BYOL).\n\n\n\n Adding a free plan by using the console \n\nBy adding a free plan, you are indicating that your product does not require any payment or license to use.\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https://cloud.ibm.com/docs-content/v1/content/ff5860bfede49db3197c4bbba7f7123769bdc068/icons/icon_hamburger.svg) > Partner Center > Sell > My products.\n2. Select the product that you're onboarding, and click Pricing.\n3. Select Free.\n\n\n\n\n\n\n\n Adding a BYOL plan by using the console \n\nBy adding a bring your own license plan, you are indicating that customers need to purchase a license to use your product. You are required to provide the name of the license and a URL where customers can purchase the license.\n\nIf you have not imported a version of your software, you can still create a BYOL plan. However, you need to import a version before your product is published. For more information, see [Onboarding your software](https://cloud.ibm.com/docs/sell?topic=sell-sw-validate).\n\n\n\n1. In the IBM Cloud console, click the Navigation Menu icon ![Navigation Menu icon](https://cloud.ibm.com/docs-content/v1/content/ff5860bfede49db3197c4bbba7f7123769bdc068/icons/icon_hamburger.svg) > Partner Center > Sell > My products.\n2. Select the product that you're onboarding, and click Pricing.\n3. Select Pricing plans.\n4. Click Add plan.\n5. Select BYOL.\n6. In the Add pricing plan panel, enter the Name of the license.", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-sw-pricing"}, {"document_id": "ibmcld_12865-1326-2924", "score": 20.774473925318997, "text": "\n[Navigation Menu icon](https://cloud.ibm.com/docs-content/v1/content/ff5860bfede49db3197c4bbba7f7123769bdc068/icons/icon_hamburger.svg) > Partner Center > Sell > My products.\n2. Select the product that you're onboarding, and click Pricing.\n3. Select Pricing plans.\n4. Click Add plan.\n5. Select BYOL.\n6. In the Add pricing plan panel, enter the Name of the license. Customers use the license name to find and purchase the license.\n7. Enter the URL that customers can use to learn about and purchase the license.\n8. Enter the Description of your license. Explain why customers need to purchase the license and what access they will receive.\n9. Click Add.\n\n\n\nAll information that is entered in the Add pricing plan panel is displayed to customers in the IBM Cloud catalog to help them purchase the required license.\n\n\n\n\n\n Creating a free plan by using the API \n\nYou can programmatically create a free plan by calling the [Partner Center Sell API](https://cloud.ibm.com/apidocs/partner-center-sellupdate-catalog) as shown in the following sample request.\n\ncurl --request PATCH --url https://product-\nlifecycle.api.cloud.ibm.com/openapi/v1/products/9fab83da-98cb-4f18-\na7ba-b6f0435c9673/catalog --header 'Authorization: Bearer TOKEN' --header 'Content-Type: application/json' --data '{\n\"pricingModel\": \"free\",\n}'\n\n\n\n\n\n Creating a BYOL plan by using the API \n\nYou can programmatically create a BYOL plan by calling the [Partner Center Sell API](https://cloud.ibm.com/apidocs/partner-center-sellcreate-plan) as shown in the following sample request. The example creates a BYOL plan that is named Standard:", "title": "", "source": "https://cloud.ibm.com/docs/sell?topic=sell-sw-pricing"}, {"document_id": "ibmcld_10169-9995-12331", "score": 20.37510214099532, "text": "\nContext \n\nTraditional grocer increases customer traffic and sales with digital insights.\n\n\n\n* Competitive pressures from online retailers and large retail stores disrupted traditional grocery retail models. Sales are declining, evidenced by low foot traffic in physical stores.\n* Their loyalty program needs a boost in the arm with a modern take on the printed coupons at check out. So Developers must constantly evolve the related apps, but traditional tools slow their ability to deploy updates and features frequently.\n* Certain high-value inventory isn\u2019t moving as well as expected, but yet the \u201cfoodie\u201d movement seems to be growing in major metropolitan markets.\n\n\n\n\n\n Solution \n\nThe grocer needs an app to increase conversion and store traffic to generate new sales and build customer loyalty in a reusable cloud analytics platform. The in-store targeted experience can be an event along with a services or product vendor that attracts both loyalty and new customers based on affinity to the specific event. The store and business partner then offer incentives to come to the event as well as buying products from the store or business partner.\n\nAfter the event, customers are guided to purchasing the necessary products, so they can repeat the demonstrated activity on their own in the future. The targeted customer experience is measured with incentive redemption and new loyalty customer sign-ups. The combination of a hyper-personalized marketing event and a tool to track in-store purchases can carry the targeted experience all the way through to product purchase. All these actions result in higher traffic and conversions.\n\nAs an example event, a local chef is brought into the store to show how to make a gourmet meal. The store provides an incentive to drive attendance. For example they provide a free appetizer at the chef's restaurant and an extra incentive to buy the ingredients for the demonstrated meal (for example, $20 off $150 cart).\n\nThe solution is made up of the following primary components.\n\n\n\n1. INVENTORY ANALYSIS: the in-store events (recipes, ingredient lists, and product locations) are tailored to market the slow-moving inventory.\n2. LOYALTY MOBILE APP provides targeted marketing with digital coupons, shopping lists, product inventory (prices, availability) on a store map, and social sharing.\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-cs_uc_retail"}, {"document_id": "ibmcld_05726-10249-12623", "score": 20.352740173142767, "text": "\n* Their loyalty program needs a boost in the arm with a modern take on the printed coupons at check out. So Developers must constantly evolve the related apps, but traditional tools slow their ability to deploy updates and features frequently.\n* Certain high-value inventory isn\u2019t moving as well as expected, but yet the \u201cfoodie\u201d movement seems to be growing in major metropolitan markets.\n\n\n\n\n\n Solution \n\nThe grocer needs an app to increase conversion and store traffic to generate new sales and build customer loyalty in a reusable cloud analytics platform. The in-store targeted experience can be an event along with a services or product vendor that attracts both loyalty and new customers based on affinity to the specific event. The store and business partner then offer incentives to come to the event as well as buying products from the store or business partner.\n\nAfter the event, customers are guided to purchasing the necessary products, so they can repeat the demonstrated activity on their own in the future. The targeted customer experience is measured with incentive redemption and new loyalty customer sign-ups. The combination of a hyper-personalized marketing event and a tool to track in-store purchases can carry the targeted experience all the way through to product purchase. All these actions result in higher traffic and conversions.\n\nAs an example event, a local chef is brought into the store to show how to make a gourmet meal. The store provides an incentive to drive attendance. For example they provide a free appetizer at the chef's restaurant and an extra incentive to buy the ingredients for the demonstrated meal (for example, $20 off $150 cart).\n\nThe solution is made up of the following primary components.\n\n\n\n1. INVENTORY ANALYSIS: the in-store events (recipes, ingredient lists, and product locations) are tailored to market the slow-moving inventory.\n2. LOYALTY MOBILE APP provides targeted marketing with digital coupons, shopping lists, product inventory (prices, availability) on a store map, and social sharing.\n3. SOCIAL MEDIA ANALYTICS provides personalization by detecting customers\u2019 preferences in terms of trends: cuisines, chefs, and ingredients. The analytics connect regional trends with an individual\u2019s Twitter, Pinterest, and Instagram activity.\n4. DEVELOPER-FRIENDLY TOOLS accelerate roll-out of features and bug fixes.", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-cs_uc_retail"}, {"document_id": "ibmcld_09501-7-2462", "score": 20.21596069601089, "text": "\nMaintenance \n\n\n\n Deployment Options \n\nThe MAS Cloud Service supports two architectural deployment options, Dedicated Cluster and Shared Cluster, each of which require Capacity Units, Virtual Processor Cores and Gigabyte entitlements. The difference between the two options is how the Cloud Service is deployed and used. For both deployment options, the client will have their own MAS Applications and their own database schemas, but the underlying architecture will be different. The Cloud Service will be configured based on the deployment option purchased.\n\nClients who purchased MAS-MS (Managed Service) or were quoted prior to December 2022 are Shared Cluster deployment. Clients who were quoted and purchased off that quote after January 2023 are MAS-Dedicated Cluster deployment. If you are not sure which deployment option you have please contact your IBM sales person, CSM or open a support ticket.\n\nDedicated Cluster Deployment (default)\n\nWith the Dedicated Cluster deployment (otherwise known as MAS-Dedicated), Red Hat OpenShift is not shared by multiple Production Instances(s), Non-Production Instance(s) or Clients. Each MAS Client Production Instance and Non-Production Instance will have its own Services and it will not be shared across clients. Clients choosing the Dedicated Cluster deployment will determine when they wish to implement MAS-Dedicated software upgrades. The upgrade may be postponed or deferred by the client. Client will need to communicate to IBM Support if they wish to defer an upgrade. The following exceptions apply:\n\n\n\n* Client must always be on a supported version. Client will need to upgrade their current version before it reaches the end of support date.\n* Client will always be required to accept critical security patches. IBM alone will determine whether a patch is deemed a critical security patch and the date it will be applied.\n\n\n\nShared Cluster Deployment (optional)\n\nIn the Shared Cluster deployment (otherwise known as MAS-MAS), Red Hat OpenShift will be shared across multiple Production Instance(s), Non-Production Instance(s) and Clients. Clients choosing the Shared Cluster deployment will be subject to the software upgrade policy that is set by IBM SRE. IBM will determine and communicate when upgrades will occur, and no deferrals or exceptions will be allowed.\n\n\n\n\n\n Maintenance Windows \n\nStandard maintenance windows for Production environments are planned on weekends (Saturday / Sunday).", "title": "", "source": "https://cloud.ibm.com/docs/mas-ms?topic=mas-ms-maintenance"}, {"document_id": "ibmcld_11563-7-2133", "score": 19.630676469133597, "text": "\nBring your own SAP product license \n\nThe IBM Cloud\u00ae SAP-Certified infrastructure is \"bring your own license\" (BYOL) capable for your SAP products. You need to apply the corresponding license for your SAP products after installation. If you are new to SAP, start exploring under [SAP All Products](https://www.sap.com/products.html). You can also contact SAP Sales or SAP Support for details on how to obtain the required licenses.\n\n\n\n Database licenses for SAP general information \n\nIt is recommended to check the license type of your Database Server for your SAP installation scenario onto IBM Cloud to avoid unsupported scenarios. Typically the license types are:\n\n\n\n* Full-use database license. Supports both SAP and non-SAP software, unrestricted usage of all functions\n* Runtime database license. Solely to support software licensed from SAP, restricted usage of functions required by the SAP Business Application. This usage can include databases from other vendors if those databases were purchases as OEM products through SAP.\n\n\n\n\n\n\n\n SAP AnyDB - Bring your own IBM Db2 license \n\nIf you purchased your SAP and IBM Db2 (for Linux, UNIX, Windows also known as LUW) licenses as part of an original equipment manufacturer (OEM) application-specific licensing (ASL) agreement, you can download and apply license files from the [SAP Support Portal)](https://support.sap.com/en/index.html); click Download Software. For more information, see [SAP Note 816773 - DB6: Installing the Application-Specific Db2 License from SAP](https://launchpad.support.sap.com//notes/816773).\n\nHowever, if you purchased IBM Db2 from IBM or an IBM Business Partner, you must use the license files that are provided by your vendor instead.\n\n\n\n\n\n SAP HANA licenses \n\nSAP HANA licenses are handled by the SAP HANA Cockpit.\n\n\n\n\n\n SAP NetWeaver and SAP Business Application licenses \n\nBoth the SAP NetWeaver application server license and the SAP Business Application license are handled by SAPGUI (or variation thereof).\n\n\n\n Creating an SAP license key \n\nThe SAP license key, saplikey or SLICENSE, displays a \"hardware key\" based on the hardware ID.", "title": "", "source": "https://cloud.ibm.com/docs/sap?topic=sap-bring-your-own-sap-product-license"}, {"document_id": "ibmcld_00550-1830-3181", "score": 19.003316984957706, "text": "\n\"order_id\": \"320afa89017426b994162ab004ce3383\",\n\"basket\": [\n{\n\"product_id\": \"A56\",\n\"title\": \"Adele - 25\",\n\"category\": \"Audio CD\",\n\"price\": 8.33,\n\"tax\": 0.2,\n\"quantity\": 2\n},\n{\n\"product_id\": \"B32\",\n\"title\": \"The Lady In The Van - Alan Bennett\",\n\"category\": \"Paperback book\",\n\"price\": 3.49,\n\"tax\": 0,\n\"quantity\": 2\n}\n],\n\"account_id\": \"985522332\",\n\"delivery\": {\n\"option\": \"Next Day\",\n\"price\": 2.99,\n\"address\": {\n\"street\": \"17 Front Street\",\n\"town\": \"Middlemarch\",\n\"postcode\": \"W1A 1AA\"\n}\n},\n\"pretax\" : 20.15,\n\"tax\" : 3.32,\n\"total\": 26.46\n}\nShow more\n\nThis document provides enough data for a purchase record to render a summary of an order on a web page, or an email, without fetching more records. Notice key details about the order. In particular, see the following details:\n\n\n\n* The basket contains reference IDs (product_id) to a database of products stored elsewhere.\n* The basket duplicates some of the product data in this record, enough to record the state of the items purchased at the point of sale.\n* The document doesn't contain fields that mark the status of the order. More documents would be added later to record payments and delivery.\n* The database automatically generates a document _id when it inserts the document into the database.\n* A unique identifier (order_id) is supplied with each purchase record to reference the order later.", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudant"}, {"document_id": "ibmcld_00550-7-2005", "score": 18.930814438018295, "text": "\nGrouping related documents together in IBM Cloudant \n\nTraditionally, e-commerce systems are built with relational databases. These databases typically use a number of tables joined to record sales, customer details, purchased products, and delivery tracking information.\n\nRelational databases offer high consistency, which means that application developers can build their applications to a database's strengths. This practice includes joins between collections, enumerations to record the state of an object, and database transactions to guarantee atomic operations.\n\nIBM\u00ae Cloudant\u00ae for IBM Cloud\u00ae favors availability over consistency. It's a high-availability, fault-tolerant, distributed database that is eventually consistent. A distributed database means the customer's shopping service is always available and scalable enough to cope with many users who make purchases at the same time. With that in mind, your application can leverage IBM Cloudant's strengths and not treat it like a relational database.\n\nThis discussion outlines some of the factors that are involved in building an e-commerce system that takes advantage of IBM Cloudant's strengths. IBM Cloudant uses concepts that are applicable to many other domains, such as:\n\n\n\n* Using multiple documents to represent the state of a purchase, rather than frequently updating a single document.\n* Storing copies of related objects in order instead of joining to another collection.\n* Creating views to collate documents by order_id to reflect the current state of a purchase.\n\n\n\nFor example, you might create a purchase document that includes details such as the items ordered, customer information, cost, and delivery information.\n\nSee the following example document that describes a purchase:\n\n{\n\"_id\": \"023f7a21dbe8a4177a2816e4ad1ea27e\",\n\"type\": \"purchase\",\n\"order_id\": \"320afa89017426b994162ab004ce3383\",\n\"basket\": [\n{\n\"product_id\": \"A56\",\n\"title\": \"Adele - 25\",\n\"category\": \"Audio CD\",\n\"price\": 8.33,\n\"tax\": 0.2,\n\"quantity\": 2\n},\n{", "title": "", "source": "https://cloud.ibm.com/docs/Cloudant?topic=Cloudant-grouping-related-documents-together-in-ibm-cloudant"}, {"document_id": "ibmcld_11435-7-1817", "score": 18.499089149873633, "text": "\nUsing Entitled Software Support (ESS) to download ISO images \n\nEntitled software means that the software is covered by a valid Software Maintenance Agreement (SWMA). If you obtain software maintenance by using a custom SWMA contract (as opposed to a standard SWMA), you might need to register on the [Entitled Software Support (ESS)](https://www.ibm.com/servers/eserver/ess/ProtectedServlet.wss) website to access the custom SWMA contract. Without access to the customer SWMA contract, you might not be able to download ISO images. You cannot download all levels of entitled software. For example, you cannot download installation media for AIX technology levels that are outdated.\n\nThe ESS customer number registration process can take several days.\n\n\n\n Before you begin \n\nBefore you can download an ISO image of an AIX installation DVD, you must have an [IBM ID](https://www.ibm.com/account/reg/us-en/signup?formid=urx-19776) and your IBM Cloud customer number. If you bought entitlement through [Passport Advantage](https://www.ibm.com/software/passportadvantage/), Entitled Systems Support (ESS) will not recognize your customer number. In this case, you need to get the customer number that the entitlement is being purchased under and go to Passport Advantage to download the files under the 5737-D09 product ID. Meanwhile, you can also purchase and download other optional software products for AIX through Passport Advantage, such as IBM Open XL C/C++ and Fortran compilers, under the 5725-C72 and 5725-C74 product ID. For informtaion on using Passport advantage, see [Passport Advantage](https://www.ibm.com/docs/en/b2b-integrator/6.0.1?topic=items-passport-advantage).\n\n\n\n\n\n Using the ESS website to download an ISO image \n\nTo download an ISO image from the ESS website, complete the following steps.", "title": "", "source": "https://cloud.ibm.com/docs/power-iaas?topic=power-iaas-using-ess-iso"}, {"document_id": "ibmcld_14816-1663-3421", "score": 17.424589769968303, "text": "\n* VMware Site Recovery Manager\n* VMware Aria Automation Enterprise\n* VMware Aria Operation Enterprise\n* VMware Aria Operations for Logs\n\n\n\nSmall differences exist between NSX-T Data Center and Data Center SP editions. For more information, see [Product offerings for VMware NSX-T Data Center 3.2.x](https://kb.vmware.com/s/article/86095).\n\n\n\n\n\n Licensing options \n\nUsing individual license keys together with the combined license keys does not meet the payment requirements for the licenses you need.\n\nYou have the following options for licensing the selected VMware components:\n\n\n\n* Include license with purchase: In this case, a new license for the VMware component is purchased on your behalf. A combined VMware license is generated to match the cluster size of the order.\n\nWhen you purchase any license, except for vSphere Enterprise Plus and vCenter Server, and you order multiple VMware ESXi\u2122 servers, an IBM Cloud ticket is opened automatically to combine license keys. You are responsible to follow up with the ticket to ensure that you use only the license keys that the VMware Solutions Support team generates.\n* I will provide the license: Bring your own license (BYOL) is no longer allowed for VMware components except if you are migrating or upgrading an existing BYOL cluster. If you are upgrading your cluster, do not enter your BYOL licenses when you create your order for the first time, but do it later when the vSphere instance is created.\n\n\n\n\n\n\n\n Related links \n\n\n\n* [Bare metal server](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vs_orderinginstances-bare-metal-settings)\n* [Procedure to order VMware vSphere instances](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vs_orderinginstances-procedure)", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vs_orderinginstances-licensing-settings"}]}
{"task_id": "c6c3b02ca32795af64c903dd76700517<::>6", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_01533-4546-6910", "score": 28.590463910908653, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-4585-6962", "score": 28.546417254572503, "text": "\nTo find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection \n\nTo scan images and containers in your account for security issues, Vulnerability Advisor collects, stores, and processes the following information:\n\n\n\n* Free-form fields, including IDs, descriptions, and image names (registry, namespace, repository name, and image tag)\n* Metadata about the file modes and creation timestamps of the configuration files\n* The content of system and application configuration files in images and containers\n* Installed packages and libraries (including their versions)\n\n\n\nDo not put personal information into any field or location that Vulnerability Advisor processes, as identified in the preceding list.\n\nScan results, aggregated at a data center level, are processed to produce anonymized metrics to operate and improve the service. In version 3, a vulnerability report (scan result) is generated when the image is pushed to the registry (and is regenerated regularly thereafter). When Vulnerability Advisor is queried, a scan result is retrieved that might be up to 5 days old. Scan results are deleted 30 days after they are generated.\n\nIn version 4, the image is indexed when it is first pushed to Container Registry registry, and that index report is stored in the database. When Vulnerability Advisor is queried, the image index report is retrieved, and a vulnerability assessment is produced. This action happens dynamically every time Vulnerability Advisor is queried. Therefore, no pregenerated scan result exists that requires deleting. However, the image index report is deleted within 30 days of the deletion of the image from the registry.\n\n\n\n\n\n\n\n Types of vulnerabilities \n\n\n\n Vulnerable packages \n\nVulnerability Advisor checks for vulnerable packages in images that are using supported operating systems and provides a link to any relevant security notices about the vulnerability.\n\nPackages that contain known vulnerability issues are displayed in the scan results.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_06004-36463-38401", "score": 26.159292453057283, "text": "\nAs you plan and develop your app, consider the following options to maintain a secure image, ensure that sensitive information is encrypted, encrypt traffic between app microservices, and control traffic between your app pods and other pods and services in the cluster.\n\nImage security\n: To protect your app, you must protect the image and establish checks to ensure the image's integrity. Review the [image and registry security topic](https://cloud.ibm.com/docs/containers?topic=containers-securityimages_registry) for steps that you can take to ensure secure container images. For example, you might use Vulnerability Advisor to check the security status of container images. When you add an image to your organization's IBM Cloud Container Registry namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index).\n\nKubernetes secrets\n: When you deploy your app, don't store confidential information, such as credentials or keys, in the YAML configuration file, configmaps, or scripts. Instead, use [Kubernetes secrets](https://cloud.ibm.com/docs/containers?topic=containers-securitypi), such as an image pull secret for registry credentials. You can then reference these secrets in your deployment YAML file.\n\nSecret encryption\n: You can encrypt the Kubernetes secrets that you create in your cluster by using a key management service (KMS) provider. To get started, see [Encrypt secrets by using a KMS provider](https://cloud.ibm.com/docs/containers?topic=containers-encryptionkeyprotect) and [Verify that secrets are encrypted](https://cloud.ibm.com/docs/containers?topic=containers-encryptionverify_kms).\n\nMicroservice traffic encryption", "title": "", "source": "https://cloud.ibm.com/docs/containers?topic=containers-plan_deploy"}, {"document_id": "ibmcld_07971-2155-4528", "score": 25.22070494624545, "text": "\n* Document and evidence the execution of the system/service and security testing/scanning along with the results.\n* Track security flaws and flaw resolution within the system and report findings to designated personnel.\n\n\n\n\n\n Red Hat OpenShift on IBM Cloud \n\nWhen using Red Hat OpenShift on IBM Cloud to host workloads, you must use Container Registry and the Vulnerability Advisor component it contains. Red Hat OpenShift on IBM Cloud provides a multi-tenant, highly available, scalable, and encrypted private image registry that is hosted and managed by IBM\u00ae. You can use Container Registry by setting up your own image namespace and pushing container images to your namespace. By using Container Registry, only users with access to your IBM Cloud account can access your images.\n\nWhen you push images to Container Registry, you benefit from the built-in Vulnerability Advisor features that scan for potential security issues and vulnerabilities. Vulnerability Advisor checks for vulnerable packages in specific Docker base images, and known vulnerabilities in app configuration settings. When vulnerabilities are found, information about the vulnerability is provided. You can use this information to resolve security issues so that containers are not deployed from vulnerable images.\n\nAny issues that are found by Vulnerability Advisor result in a verdict that indicates that it is not advisable to deploy this image. If you choose to deploy the image, any containers that are deployed from the image include known issues that might be used to attack or otherwise compromise the container. The verdict is adjusted based on any exemptions that you specified. This verdict can be used by Portieris to prevent the deployment of nonsecure images in Container Registry. [Portieris](https://github.com/IBM/portieris) is a Kubernetes admission controller for the enforcement of image security policies. You can create image security policies for each Kubernetes namespace, or at the cluster level, and enforce different rules for different images.\n\nFixing the security and configuration issues that are reported by Vulnerability Advisor can help you to secure your IBM Cloud infrastructure.\n\nSee the following for more information on Container Registry and how to set it up:\n\n\n\n* [About Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overview)", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services?topic=framework-financial-services-shared-development-processes"}, {"document_id": "ibmcld_10439-40150-42016", "score": 24.884289394169603, "text": "\nAs you plan how many Service objects you need in your cluster, keep in mind that Kubernetes uses iptables to handle networking and port forwarding rules. If you run many services in your cluster, such as 5000, performance might be impacted.\n\n\n\n\n\n\n\n Securing apps \n\nAs you plan and develop your app, consider the following options to maintain a secure image, ensure that sensitive information is encrypted, and control traffic between your app pods and other pods and services in the cluster.\n\nImage security\n: To protect your app, you must protect the image and establish checks to ensure the image's integrity. Review the [image and registry security topic](https://cloud.ibm.com/docs/openshift?topic=openshift-securityimages_registry) for steps that you can take to ensure secure container images. For example, you might use Vulnerability Advisor to check the security status of container images. When you add an image to your organization's IBM Cloud Container Registry namespace, the image is automatically scanned by Vulnerability Advisor to detect security issues and potential vulnerabilities. If security issues are found, instructions are provided to help fix the reported vulnerability. To get started, see [Managing image security with Vulnerability Advisor](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index).\n\nKubernetes secrets\n: When you deploy your app, don't store confidential information, such as credentials or keys, in the YAML configuration file, configmaps, or scripts. Instead, use [Kubernetes secrets](https://cloud.ibm.com/docs/openshift?topic=openshift-securitypi), such as an image pull secret for registry credentials. You can then reference these secrets in your deployment YAML file.\n\nSecret encryption\n: You can encrypt the Kubernetes secrets that you create in your cluster by using a key management service (KMS) provider.", "title": "", "source": "https://cloud.ibm.com/docs/openshift?topic=openshift-plan_deploy"}, {"document_id": "ibmcld_07578-365833-367834", "score": 24.175424488768616, "text": "\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-365807-367808", "score": 24.175424488768616, "text": "\nThe images that are not eligible are still displayed, but they do not count toward the total number of images that is set in the retention policy and are not removed.\n* What regions are available?\n\n What regions are available? \n\nTo find out about the regions that are available for IBM Cloud Container Registry, see [Regions](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_regions).\n* How much does Vulnerability Advisor cost?\n\n How much does Vulnerability Advisor cost? \n\nThe cost of Vulnerability Advisor is built into the pricing for IBM Cloud Container Registry. For more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n* Can images from other registries be scanned?\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n* How is a Vulnerability Advisor scan triggered?\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n* Why doesn't a new image scan?\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the registry A storage and distribution service that contains public or private images that are used to create containers., you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry.", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_01533-3131-4993", "score": 23.635759582209708, "text": "\n* Applies exemption policies to reports at an account, [namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides instructions about how to fix a reported [vulnerable package](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexpackages) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe Security status column in the Images tab of the Container Registry dashboard displays the number of issues that are associated with each image. To find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_indexva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index"}, {"document_id": "ibmcld_01535-3157-5045", "score": 23.497582010060473, "text": "\n* Applies exemption policies to reports at an account, [namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe following functions are available in version 4:\n\n\n\n* Scans images for issues.\n* Provides an evaluation report that is based on security practices that are specific to IBM Cloud Kubernetes Service.\n* Provides instructions about how to fix a reported [vulnerable package](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages) in its reports.\n* Applies exemption policies to reports at an account, [namespace](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_namespace), [repository](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_repository), or [tag](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewoverview_elements_tag) level to mark when issues that are flagged do not apply to your use case.\n\n\n\nThe Security status column in the Images tab of the Container Registry dashboard displays the number of issues that are associated with each image. To find out more about the issues, click the link in the Security status column.\n\nThe Vulnerability Advisor dashboard provides an overview and assessment of the security for an image. If you want to find out more about the Vulnerability Advisor dashboard, see [Reviewing a vulnerability report](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uiva_reviewing).\n\nEncrypted images aren't scanned by Vulnerability Advisor.\n\n\n\n Data protection", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=ui"}, {"document_id": "ibmcld_01415-6473-8616", "score": 23.41048928490816, "text": "\nFor more information, see [Billing for storage and pull traffic](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_overviewregistry_billing_traffic).\n\n\n\n\n\n Can images from other registries be scanned? \n\nVulnerability Advisor scans images from IBM Cloud Container Registry only.\n\n\n\n\n\n How is a Vulnerability Advisor scan triggered? \n\nFor more information about how the scanning of an image is triggered, see [Vulnerable packages](https://cloud.ibm.com/docs/Registry?topic=Registry-va_index&interface=uipackages).\n\n\n\n\n\n Why doesn't a new image scan? \n\nIf you get the vulnerability report immediately after you add the image to the\n\nregistry, you might receive the following error:\n\nBXNVA0009E: <imagename> has not been scanned. Try again later.\nIf this issue persists, contact support for help;\nsee https://cloud.ibm.com/docs/get-support?topic=get-support-getting-customer-supportgetting-customer-support\n\nYou receive this message because the images are scanned asynchronously to the requests for results, and the scanning process takes a while to complete. During normal operation, the scan completes within the first few minutes after you add the image to the registry. The time that it takes to complete depends on variables like the image size and the amount of traffic that the registry is receiving.\n\nIf you get this message as part of a build pipeline and you see this error regularly, try adding some retry logic that contains a short pause.\n\nIf you still see unacceptable performance, contact support, see [Getting help and support for Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-help-and-support).\n\n\n\n\n\n How often are the security notices updated? \n\nSecurity notices for Vulnerability Advisor are loaded from the vendors' operating system sites approximately every 12 hours.\n\n\n\n\n\n Why can I see a vulnerability in Vulnerability Advisor v4 but not in v3? \n\nSome vulnerabilities are picked up earlier by Vulnerability Advisor version 4 than by version 3 because version 4 uses a different architecture and a different scanning engine.\n\nVulnerability Advisor version 3 is deprecated from 19 June 2023.", "title": "", "source": "https://cloud.ibm.com/docs/Registry?topic=Registry-registry_faq&interface=ui"}]}
{"task_id": "1065ea5ad1ae2b90e6fce67d851a7a66<::>1", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10817-7-1802", "score": 23.44391944978554, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_13724-72779-74671", "score": 23.237011119467343, "text": "\nThe customization interface includes a collection of new HTTP methods that have the names POST /v1/customizations, POST /v1/customizations/{customization_id}, POST /v1/customizations/{customization_id}/words, and PUT /v1/customizations/{customization_id}/words/{word}. The service also provides a new GET /v1/pronunciation method that returns the pronunciation for any word and a new GET /v1/voices/{voice} method that returns detailed information about a specific voice. In addition, existing methods of the service's interface now accept custom model parameters as needed.\n\nFor more information about customization and its interface, see [Understanding customization](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-customIntro) and the [API & SDK reference](https://cloud.ibm.com/apidocs/text-to-speech).\n\nThe customization interface is a beta release that currently supports US English only. All customization methods and the GET /v1/pronunciation method can currently be used to create and manipulate custom models and word translations only in US English.\n\nNew Brazilian Portuguese voice: pt-BR_IsabelaVoice\n: The service supports a new voice, pt-BR_IsabelaVoice, to synthesize audio in Brazilian Portuguese with a female voice. For more information, see [Languages and voices](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-voices).\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile Software Development Kits (SDKs) are available for the speech services. The SDKs enable mobile applications to interact with both the Text to Speech and Speech to Text services. You can use the SDKs to send text to the Text to Speech service and receive an audio response.\n\n\n\n* The Watson Swift SDK is available from the [swift-sdk repository](https://github.com/watson-developer-cloud/swift-sdk) in the watson-developer-cloud namespace on GitHub.", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-release-notes"}, {"document_id": "ibmcld_01660-16615-18504", "score": 23.184401924865437, "text": "\nThe account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https://cloud.ibm.com/docs-content/v1/content/4d8c6eec891cff72b666dc24bd3211810c77fb42/account/images/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n\n\n\n\n\n Can I move data between IBM Cloud accounts? \n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https://cloud.ibm.com/unifiedsupport/supportcenter) for assistance with data migration questions.\n\n\n\n\n\n Can I bookmark a console page for a specific account? \n\nYou can target URLs for any IBM Cloud console page to a specific account. If you have multiple accounts, you can bookmark the account-specific URLs to easily access resources in different accounts without having to manually switch between them.\n\n\n\n1. Switch to the account that you want to target, and go to the [Account settings](https://cloud.ibm.com/account/settings) page in the console. In the Account section, find the account ID, such as a1b2c3d4e5f61234567890fedcba4321.\n2. Go to the console page that you want to bookmark, and add ?bss_account=<account-id> to the URL, replacing <account-id> with the ID from your account. For example,:", "title": "", "source": "https://cloud.ibm.com/docs/account?topic=account-accountfaqs"}, {"document_id": "ibmcld_13429-166159-168045", "score": 22.835219290864835, "text": "\nNew UK English and Arabic models\n: The service supports more languages with its transcription models: en-UK_BroadbandModel and en-UK_NarrowbandModel for UK English, and ar-AR_BroadbandModel for Modern Standard Arabic. For more information, see [Previous-generation languages and models](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-models).\n\nNew session_closed field for session-based methods\n: In the JSON responses that it returns for errors with session-based methods, the service now also includes a new session_closed field. The field is set to true if the session is closed as a result of the error. For more information about possible return codes for any method, see the [API & SDK reference](https://cloud.ibm.com/apidocs/speech-to-text).\n\nHTTP platform timeout no longer applies\n: HTTP recognition requests are no longer subject to a 10-minute platform timeout. The service now keeps the connection alive by sending a space character in the response JSON object every 20 seconds as long as recognition is ongoing. For more information, see [Timeouts](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-inputtimeouts).\n\nRate limiting with curl command no longer needed\n: When you use the curl command to transcribe audio with the service, you no longer need to use the --limit-rate option to transfer data at a rate no faster than 40,000 bytes per second.\n\nChanges to HTTP error codes\n: The service no longer returns HTTP status code 490 for the session-based HTTP methods GET /v1/sessions/{session_id}/observe_result and POST /v1/sessions/{session_id}/recognize. The service now responds with HTTP status code 400 instead.\n\n\n\n\n\n 21 September 2015 \n\nNew mobile SDKs available\n: Two new beta mobile SDKs are available for the speech services. The SDKs enable mobile applications to interact with both the Speech to Text and Text to Speech services.", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-release-notes"}, {"document_id": "ibmcld_07642-0-563", "score": 22.379116063409107, "text": "\n\n\n\n\n\n\n  AC-19 (5) - Full Device / Container-based Encryption \n\n\n\n  Control requirements \n\nAC-19 (5) - 0\n:   The organization employs [IBM Assignment: file level, full disk/device, or both] to protect the confidentiality and integrity of information on [Assignment: organization-defined mobile devices].\n\n\n\n\n\n  NIST supplemental guidance \n\nContainer-based encryption provides a more fine-grained approach to the encryption of data/information on mobile devices, including for example, encrypting selected data structures such as files, records, or fields.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ac-19.5"}, {"document_id": "ibmcld_16727-1086316-1088349", "score": 22.289197899136983, "text": "\nThe account selector displays the account name and account number.\n* How can I join accounts?\n\nThe account owner, organization manager, or a user with the correct permissions can invite you to join their account.\n\n\n\n* If you're new to IBM Cloud\u00ae, you receive an email that contains all the information you need.\n* As an existing member of IBM Cloud\u00ae, you can accept the invitation in your notifications, by email, or by using the CLI to onboard to the new account. To accept invitations in the CLI, use the [ibmcloud login](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_cliaccept-invitation-to-join-a-new-account-) command.\n\n\n\n* Can I switch between multiple accounts?\n\nIf you have access to more than one account, you can click your account name in the console menu bar to switch to another account.\n\n![A screen capture of the account selector in the console menu bar. The account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https://cloud.ibm.com/images/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n* Can I move data between IBM Cloud accounts?\n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https://cloud.ibm.com/unifiedsupport/supportcenter) for assistance with data migration questions.\n* Can I bookmark a console page for a specific account?", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_07578-1083825-1085863", "score": 22.246306273551486, "text": "\nThe account selector displays the account name and account number.\n* How can I join accounts?\n\nThe account owner, organization manager, or a user with the correct permissions can invite you to join their account.\n\n\n\n* If you're new to IBM Cloud\u00ae, you receive an email that contains all the information you need.\n* As an existing member of IBM Cloud\u00ae, you can accept the invitation in your notifications, by email, or by using the CLI to onboard to the new account. To accept invitations in the CLI, use the [ibmcloud login](https://cloud.ibm.com/docs/cli?topic=cli-ibmcloud_cliaccept-invitation-to-join-a-new-account-) command.\n\n\n\n* Can I switch between multiple accounts?\n\nIf you have access to more than one account, you can click your account name in the console menu bar to switch to another account.\n\n![A screen capture of the account selector in the console menu bar. The account selector displays the account name and account number, and you select the current account to display a list of other accounts that you can access.](https://cloud.ibm.com/docs/images/account-faq.svg)\n\nFigure 2. Account selector displays all accounts to which you have access\n* Can I move data between IBM Cloud accounts?\n\nData can't be directly migrated from one IBM Cloud account to another. But, you might be able to re-create configurations and add them to another account. Consider the following approaches:\n\n\n\n* Save your applications and replicate them in different accounts by using GitHub or another code repository.\n* Review the applicable documentation to determine whether your infrastructure services can be backed up and re-created in different accounts.\n* Use manifests and other documented methods to rebuild your applications and services by using documented methods to back up and restore your data.\n\n\n\nUsers with a Basic, Advanced, or Premium support plan can open a [Support case](https://cloud.ibm.com/unifiedsupport/supportcenter) for assistance with data migration questions.\n* Can I bookmark a console page for a specific account?", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_14390-16273-17983", "score": 21.559594430147076, "text": "\n* At the end of the documented process, your vCenter Server instance is running vSphere 7.0 Update 1c with N-VDS distributed switches. This configuration is different than the currently supported [Software BOM for vCenter Server instances](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vc_bomvc_bom-software), which is vSphere 7.0 Update 3c with Distributed vSwitch 7.0.0.\n* For more information about the migration of N-VDS to VDS switches for vSphere 7.0 or later and NSX-T Data Center 3.0 and later, see [Migrate host switch to vSphere Distributed Switch](https://docs.vmware.com/en/VMware-NSX-T-Data-Center/3.1/administration/GUID-1039A36F-F55E-4A0A-B6C6-2C383F4A716D.html). Currently, this procedure is not verified on a VMware Solutions vCenter Server instance.\n* IBM Cloud is undertaking an assessment of the N-VDS to VDS conversion and the required changes to the automation database to allow this in-place upgrade.\n* Currently, Day 2 automation workflows such as add host or add cluster, are not tested against VMware Solutions vCenter Server instances that are upgraded from vSphere 6.7 to 7 and still using N-VDS distributed switches. Customers must assume that this automation might fail and that if this automation is required then the lift and shift migration approach used. If this automation is not needed, you can use the upgrade process that is documented.\n* A workaround for the add nodes and add cluster features is to use the VMware vSphere offering. For more information, see [VMware vSphere overview](https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-vs_vsphereclusteroverview). You must complete a number of manual tasks after the automated deployment.", "title": "", "source": "https://cloud.ibm.com/docs/vmwaresolutions?topic=vmwaresolutions-faq-v2t-migration"}, {"document_id": "ibmcld_10852-44214-45420", "score": 21.129944587457004, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_00959-2830-5215", "score": 20.802380309873136, "text": "\n* Avoid application downtime.\n* Enable production testing of new functions without impacting customers.\n* Limit the impact of production issues to a subset of users.\n* Enable rapid rollback to the previous version if issues are found.\n\n\n\nMany possible deployment strategies are available. In general, they depend on running multiple instances of the application and managing how the various instances are updated. You can pre-configure the following common deployment strategies in Continuous Delivery:\n\nBasic\n: Deploys the new release by stopping and updating all of the running instances simultaneously, causing downtime. For rollback, you must deploy the previous version again, which causes extra downtime. Although this strategy is simple, fast, and has low runtime resource requirements, it is the riskiest and causes downtime. The Basic deployment strategy is not recommended for critical apps that must be highly available.\n\nRolling update\n: Similar to the Basic strategy, this deployment strategy is simple, fast, and has low runtime resource requirements. However, because each running instance is taken down and updated individually, avoiding downtime, rollback requires you to deploy the previous release again. This time consuming approach might cause issues if the current version of the app in production is broken.\n\nBlue-Green deployment\n: Creates two separate, permanent production environments (blue and green), and only one of those environments receives traffic at a time. The current release is always deployed to the idle environment and traffic is switched to it after deployment completes, with no downtime. Because you need to switch only the traffic to the unchanged environment, rollback does not cause downtime. Because this strategy requires two full production environments, the resource requirements are higher. However, this strategy enables powerful Developer flows, such as the ability to test new app versions in the production environment before it allows customer traffic. Blue-Green deployment also supports fast rollback.\n\nCanary release\n: Deploys a new release in parallel with the original production environment (similar to Blue-Green), with no downtime. The amount of traffic that is sent to both the updated and original instances is managed so that the new version is available to a controlled subset of users while the deployment proceeds.", "title": "", "source": "https://cloud.ibm.com/docs/ContinuousDelivery?topic=ContinuousDelivery-tutorial-cd-kubernetes"}]}
{"task_id": "c01c8cf11437e6bb3bc93efac26528c2<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_10817-7-1802", "score": 46.48584017946634, "text": "\nMobile SDK \n\nIBM Cloud\u00ae Functions provides a mobile SDK for iOS and watchOS devices that enables mobile apps to fire remote triggers and invoke remote actions. A version for Android is not available, so Android developers can use the OpenWhisk REST API directly. The mobile SDK is written in Swift 4 and supports iOS 11 and later releases. You can build the mobile SDK by using Xcode 9.\n\nThe mobile SDK is not supported for IAM-based namespaces. Use a Cloud Foundry-based namespace instead.\n\n\n\n Add the SDK to your app \n\nYou can install the mobile SDK by using CocoaPods, Carthage, or from the source directory.\n\n\n\n Install mobile SDK with CocoaPods \n\nThe IBM Cloud\u00ae Functions SDK for mobile is available for public distribution through CocoaPods. Assuming CocoaPods is installed, put the following lines into a file called Podfile inside the starter app project directory.\n\ninstall! 'cocoapods', :deterministic_uuids => false\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\ntarget 'MyApp WatchKit Extension' do\npod 'OpenWhisk', :git => 'https://github.com/apache/incubator-openwhisk-client-swift.git', :tag => '0.3.0'\nend\n\nFrom the command line, type pod install. This command installs the SDK for an iOS app with a watchOS extension. Use the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-7-1743", "score": 37.953266026108935, "text": "\nInitializing BMSClient \n\nBMSCore provides the HTTP infrastructure that the other IBM Cloud\u00ae Web and Mobile services client SDKs use to communicate with their corresponding IBM Cloud services.\n\n\n\n Initializing your Android app \n\nYou can either download and import the BMSCore package to your Android Studio project, or use Gradle.\n\n\n\n1. Import the Client SDK by adding the following import statement at the beginning of your project file:\n\nimport com.ibm.mobilefirstplatform.clientsdk.android.core.api.;\n2. Initialize the BMSClient SDK in your Android application by adding the initialization code in the onCreate method of the main activity in your Android app, or in a location that works best for your project.\n\nBMSClient.getInstance().initialize(getApplicationContext(), BMSClient.REGION_US_SOUTH); // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you are using, for example, BMSClient.REGION_US_SOUTH, BMSClient.REGION_UK, or BMSClient.REGION_SYDNEY.\n\n\n\n\n\n\n\n Initializing your iOS app \n\nYou can use [CocoaPods](https://cocoapods.org) or [Carthage](https://github.com/Carthage/Carthage) to get the BMSCore package.\n\n\n\n1. To install BMSCore by using CocoaPods, add the following lines to your Podfile. If your project doesn't have a Podfile yet, use the pod init command.\n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_10852-43319-44485", "score": 37.77692100586148, "text": "\n* [Creating a trigger for an Event Streams package outside IBM Cloud](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_trigger_outside)\n* [Listening for messages](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_listen_messages)\n* [Messages are batched](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamseventstreams_batched)\n\n\n\n* [References for Event Streams](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_event_streamsmessage_references)\n\n\n\n[Mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkpkg_mobile_sdk)\n\n\n\n* [Add the SDK to your app](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkadd-mobile-sdk-app)\n\n\n\n* [Install mobile SDK with CocoaPods](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-cocoapods)\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_02772-4213-5899", "score": 36.53553279440336, "text": "\nIn the defaultConfig section, configure the redirect scheme.\n\ndefaultConfig {\n...\nmanifestPlaceholders = ['appIdRedirectScheme': android.defaultConfig.applicationId]\n}\n\n\n\n4. Synchronize your project with Gradle. Click Tools > Android > Sync Project with Gradle Files.\n\n\n\n\n\n\n\n Initializing the SDK \n\n\n\n1. Pass the context, tenant ID, and region parameters to the initialize method to configure the SDK.\n\nA common, though not mandatory, place to put the initialization code is in the onCreate method of the main activity in your Android application.\n\nAppID.getInstance().initialize(getApplicationContext(), <tenantID>, <region>);\n\n\n\n\n\n\n\n\n\n Authenticating with the iOS Swift SDK \n\nProtect your mobile applications by using the App ID client SDK.\n\n\n\n Before you begin \n\nYou must have the following prerequisites before you get started:\n\n\n\n* Xcode 9.0 or higher\n* CocoaPods 1.1.0 or higher\n* iOS 10.0 or higher\n\n\n\n\n\n\n\n Installing the SDK \n\nThe App ID client SDK is distributed with CocoaPods, a dependency manager for Swift and Objective-C Cocoa projects. CocoaPods downloads artifacts, and makes them available to your project.\n\n\n\n1. Create an Xcode project or open an existing one.\n2. Create a new or open your existing Podfile in the project's directory.\n3. Add the IBMCloudAppID pod and use_frameworks! command to your target's dependencies\n\ntarget '<yourTarget>' do\nuse_frameworks!\npod 'IBMCloudAppID'\nend\n4. Install your dependencies from the command line within your project directory.\n\npod install --repo-update\n5. After installation, open the {your app}.xcworkspace file that contains your Xcode project and your linked dependencies\n6. Enable keychain sharing in your Xcode project.", "title": "", "source": "https://cloud.ibm.com/docs/appid?topic=appid-mobile-apps"}, {"document_id": "ibmcld_10817-1342-3184", "score": 36.53210216864288, "text": "\nUse the workspace file CocoaPods creates for your app to open the project in Xcode.\n\nAfter installation, open your project workspace. You might get the following warning when building: Use Legacy Swift Language Version\u201d (SWIFT_VERSION) is required to be configured correctly for targets which use Swift. Use the [Edit > Convert > To Current Swift Syntax\u2026] menu to choose a Swift version or use the Build Settings editor to configure the build setting directly. This is caused if CocoaPods does not update the Swift version in the Pods project. To fix, select the Pods project and the IBM Cloud\u00ae Functions target. Go to Build Settings and change the setting Use Legacy Swift Language Version to no. Alternatively, you can add the following post installation instructions at the end of you Podfile:\n\npost_install do installer\ninstaller.pods_project.targets.each do target\ntarget.build_configurations.each do config\nconfig.build_settings['SWIFT_VERSION'] = '4.0'\nend\nend\nend\n\n\n\n\n\n Install mobile SDK with Carthage \n\nCreate a file in the project directory for your app and name it Cartfile. Put the following line in the file:\n\ngithub \"openwhisk/openwhisk-client-swift.git\" > 0.3.0 Or latest version\n\nFrom the command line, type carthage update --platform ios. Carthage downloads and builds the SDK, creates a directory that is called Carthage in the project directory for your app, and puts an OpenWhisk.framework file inside Carthage/build/iOS.\n\nYou must then add OpenWhisk.framework file to the embedded frameworks in your Xcode project\n\n\n\n\n\n Install mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}, {"document_id": "ibmcld_04518-1426-3052", "score": 30.15236306323045, "text": "\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'BMSCore'\nend\n\nThen run the pod install command, and open the generated .xcworkspace file. To update to a newer release of BMSCore, use pod update BMSCore.\n\nFor more information about using CocoaPods, see the [CocoaPods Guides](https://guides.cocoapods.org/using/index.html).\n2. To install BMSCore by using Carthage, follow these [instructions](https://github.com/Carthage/Carthagegetting-started).\n\n\n\n1. Add the following line to your Cartfile:\n\ngithub \"ibm-bluemix-mobile-services/bms-clientsdk-swift-core\"\n2. Run the carthage update command.\n3. After the build is finished, add BMSCore.framework to your project by following [Step 3](https://github.com/Carthage/Carthagegetting-started) in the Carthage instructions.\n\nFor apps that are built with Swift 2.3, use the carthage update --toolchain com.apple.dt.toolchain.Swift_2_3 command. Otherwise, use the carthage update command.\n\n\n\n3. Import the BMSCore module.\n\nimport BMSCore\n4. Initialize the BMSClient class by using the following code.\n\nPlace the initialization code in the application(_:didFinishLaunchingWithOptions:) method of your app delegate, or in a location that works best for your project.\n\nBMSClient.sharedInstance.initialize(bluemixRegion: BMSClient.Region.usSouth) // Make sure that you point to your region\n\nYou must initialize the BMSClient with the bluemixRegion parameter. In the initializer, the bluemixRegion value specifies which IBM Cloud deployment you're using, for example, BMSClient.Region.usSouth, BMSClient.Region.unitedKingdom, or BMSClient.Region.sydney.\n\n\n\n\n\n\n\n Initializing your Cordova app \n\n\n\n1.", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-sdk_BMSClient"}, {"document_id": "ibmcld_12332-1034-2510", "score": 24.485715698208992, "text": "\nYour Go SDK should be packaged as a [Go Module](https://blog.golang.org/using-go-modules), using the GitHub repository URL as a package name.\n\n\n\n\n\n Java \n\nYour Java SDK should publish its artifacts on [Maven Central](https://search.maven.org/). It is recommended that artifacts use a Maven groupId of com.ibm.cloud.\n\n\n\n\n\n Node \n\nYour Node SDK should be released as an [npm](https://www.npmjs.com/) package within the [ibm-cloud](https://www.npmjs.com/org/ibm-cloud) organization. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services). Using [NPM Scopes](https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-nodenode-publishing) is strongly encouraged.\n\n\n\n\n\n Python \n\nYour Python SDK should be released on [PyPI](https://pypi.python.org/) / [pip](https://pypi.python.org/pypi/pip) and should have a package name beginning with ibm-. It is recommended that your package name follows the pattern of ibm-<service-category> if possible (for example, ibm-platform-services or ibm-networking-services).\n\n\n\n\n\n Swift \n\nYour Swift SDK should be released on [Swift Package Manager](https://swift.org/package-manager/) / [CocoaPods](https://cocoapods.org/) / [Carthage](https://github.com/Carthage/Carthage) and should have a package name beginning with IBM.\n\nAdditional information is present in the [Common SDK Documentation](https://github.com/IBM/ibm-cloud-sdk-common).", "title": "", "source": "https://cloud.ibm.com/docs/sdk-handbook?topic=sdk-handbook-devtools"}, {"document_id": "ibmcld_07551-14062-16080", "score": 22.467847171173098, "text": "\nSelect Topics in the Event Notifications console and click Create. Enter the following topic details:\n\n\n\n* Name: enter a name for the topic.\n* Description: add an optional description for the topic.\n* Source: select a source from the dropdown list.\n* Event type: select event type from the dropdown list.\n* Event sub type select event sub type from the event sub type dropdown list.\n* Severity: select severity from the severity dropdown list.\n* Advanced conditions: write your own custom conditions, which must follow [jsonpath specifications](https://jsonpath.com/).\n\n\n\n\n\n\n\n Step 6: Create an Event Notifications subscription \n\nClick Subscriptions in the Event Notifications console. Enter the following subscription details:\n\n\n\n* Click Create to display subscription wizard.\n* Complete the following subscription details:\n\n\n\n* Subscription name: name of the subscription.\n* Subscription description: add an optional description.\n\n\n\n* Under the Subscribe to a topic section, select a topic from the drop-down list and select a destination from the destination drop-down list.\n* Destination type: select type under Destination and click Add.\n\n\n\n\n\n\n\n Step 7: Set up Event Notifications IOS SDK \n\nThe iOS SDK enables iOS apps to receive push notifications. Complete the following steps to install Event Notifications iOS SDK, initialize the SDK, and register for notifications for your iOS app.\n\n\n\n\n\n Installation \n\nThe current version of this SDK is: 0.0.1\n\nTo use the Event Notifications iOS destination SDK, define a dependency that contains the artifact coordinates (group ID, artifact ID, and version) for the service, like this:\n\n\n\n CocoaPods \n\nuse_frameworks!\n\ntarget 'MyApp' do\npod 'ENPushDestination', '> 0.0.1'\nend\n\n\n\n\n\n Carthage \n\nTo install ENPushDestination using Carthage, add the following to your Cartfile.\n\ngithub \"IBM/event-notifications-destination-ios-sdk\" > 0.0.1\n\nThen, run the following command to build the dependencies and frameworks:\n\ncarthage update --platform iOS\n\n\n\n\n\n Swift Package Manager", "title": "", "source": "https://cloud.ibm.com/docs/event-notifications?topic=event-notifications-en-push-apns"}, {"document_id": "ibmcld_10852-44214-45420", "score": 19.825097152979247, "text": "\n* [Install mobile SDK with Carthage](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-carthage)\n* [Install mobile SDK from source code](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-source-code)\n\n\n\n* [Install the starter app example for mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinstall-mobile-sdk-starter-app)\n* [Getting started with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkget-started-mobile-sdk)\n* [Invoke a mobile SDK action](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkinvoke-mobile-sdk-action)\n* [Fire a mobile SDK trigger](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkfire-mobile-sdk-trigger)\n* [Use mobile SDK actions that return a result](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkmobile-sdk-actions-results)\n* [Configuring the mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkconfigure-mobile-sdk)\n\n\n\n* [Support for qualified names with mobile SDK](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdkqualified-names-mobile-sdk)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_10817-2884-4620", "score": 18.328249213472205, "text": "\nInstall mobile SDK from source code \n\n\n\n1. Download the [source code](https://github.com/apache/openwhisk-client-swift).\n2. Open the project by using the OpenWhisk.xcodeproj with Xcode. The project contains two schemes: \"OpenWhisk\" (targeted for iOS) and \"OpenWhiskWatch\" (targeted for watchOS 2).\n3. Build the project for the targets that you need and add the resulting frameworks to your app (usually in /Library/Developer/Xcode/DerivedData/your-app-name).\n\n\n\n\n\n\n\n\n\n Install the starter app example for mobile SDK \n\nYou can use the Cloud Functions CLI to download example code that embeds the Cloud Functions SDK framework.\n\nTo install the starter app example, enter the following command:\n\nibmcloud fn sdk install iOS\n\nThis command downloads a compressed file that contains the starter app. The project directory contains a Podfile.\n\nTo install the SDK, enter the following command:\n\npod install\n\n\n\n\n\n Getting started with mobile SDK \n\nTo get up and running quickly, create a WhiskCredentials object with your Cloud Functions API credentials and create a Cloud Functions instance from the object.\n\nFor example, use the following example code to create a credentials object:\n\nlet credentialsConfiguration = WhiskCredentials(accessKey: \"myKey\", accessToken: \"myToken\")\nlet whisk = Whisk(credentials: credentialsConfiguration!)\n\nIn previous example, you pass in the myKey and myToken that you get from Cloud Functions. You can retrieve the key and token with the following CLI command:\n\nibmcloud fn property get --auth\n\nExample output\n\nwhisk auth kkkkkkkk-kkkk-kkkk-kkkk-kkkkkkkkkkkk:tttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttttt\n\nThe string before the colon is your key, and the string after the colon is your token.", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_mobile_sdk"}]}
{"task_id": "f5a8ca2f2bc12180940167fb920bb018<::>9", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_03117-4-2198", "score": 51.8742485922571, "text": "\nThis documentation for the classic Watson Assistant experience has moved. For the most up-to-date version, see [Migrating to the v2 API](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-api-migration). To see all documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Migrating to the v2 API \n\nThe Assistant v2 runtime API, which supports the use of assistants and skills, was introduced in November 2018. This API offers significant advantages over the v1 runtime API, including automatic state management, ease of deployment, skill versioning, and the availability of new features such as the search skill.\n\nThe v2 API is available for all users, regardless of service plan, at no additional cost.\n\nThe v2 API currently supports only runtime interaction with an existing assistant. Authoring applications that create or modify workspaces should continue to use the v1 API.\n\n\n\n Overview \n\nWith the v2 API, your client app communicates with an assistant, rather than directly with a workspace. An assistant is a new orchestration layer that offers several new capabilities, including automatic state management, skill versioning, easier deployment, and (for Plus and Premium plans) search skills. Your existing workspace (now referred to as a dialog skill) continues to function as before, but the new capabilities are provided by the new assistant layer.\n\nAll communication with an assistant takes place within the context of a session, which maintains conversation state throughout the duration of the conversation. State data, including any context variables that are defined by your dialog or client application, are automatically stored by Watson Assistant, without any action required on the part of your application.\n\nState data persists until you explicitly delete the session, or until the session times out because of inactivity.\n\nIf you prefer to manage state yourself, the v2 API also provides a stateless message method that functions more like the v1 API. If you use the stateless message method, you do not need to explicitly create or delete sessions, and your app is responsible for maintaining context.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-migration"}, {"document_id": "ibmcld_03118-4-2208", "score": 51.846110749549986, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Watson Assistant API overview \n\nYou can use the Watson Assistant REST APIs, and the corresponding SDKs, to develop applications that interact with the service.\n\n\n\n Client applications \n\nTo build a virtual assistant or other client application that communicates with an assistant at run time, use the new v2 API. By using this API, you can develop a user-facing client that can be deployed for production use, an application that brokers communication between an assistant and another service (such as a chat service or back-end system), or a testing application.\n\nBy using the v2 runtime API to communicate with your assistant, your application can take advantage of the following features:\n\n\n\n* Automatic state management. The v2 runtime API manages each session with an end user, storing and maintaining all of the context data your assistant needs for a complete conversation.\n* Ease of deployment using assistants. In addition to supporting custom clients, an assistant can be easily deployed to popular messaging channels such as Slack and Facebook Messenger.\n* Versioning. With dialog skill versioning, you can save a snapshot of your skill and link your assistant to that specific version. You can then continue to update your development version without affecting the production assistant.\n* Search capabilities. The v2 runtime API can be used to receive responses from both dialog skills and search skills. When a query is submitted that your dialog skill cannot answer, the assistant can use a search skill to find the best answer from the configured data sources. (Search skills are a beta feature available only to Plus or Premium plan users.)\n\n\n\nFor details about the v2 API, see the Watson Assistant [v2 API Reference](https://cloud.ibm.com/apidocs/assistant/assistant-v2).\n\nNote: The Watson Assistant v1 API still supports the legacy /message method that sends user input directly to the workspace used by a dialog skill. The v1 runtime API is supported primarily for backward compatibility purposes.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-api-overview"}, {"document_id": "ibmcld_03043-3079-5106", "score": 50.90109267165579, "text": "\nIn the tool, the name of an entity is always prefixed with the @ character.\n\nYou can train the skill to recognize your entities by providing entity term values and synonyms, entity patterns, or by identifying the context in which an entity is typically used in a sentence. To fine tune your dialog, go back and add nodes that check for entity mentions in user input in addition to intents.\n\n\n\n![Diagram of a more complex implementation that uses intent, entity, and dialog.](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/complex-impl.png)\n\nAs you add information, the skill uses this unique data to build a machine learning model that can recognize these and similar user inputs. Each time you add or change the training data, the training process is triggered to ensure that the underlying model stays up-to-date as your customer needs and the topics they want to discuss change.\n\nFor help creating a dialog skill, see [Creating a dialog skill](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-dialog-add).\n\n\n\n\n\n Search skill \n\nWhen Watson Assistant doesn't have an explicit solution to a problem, it routes the user question to a search skill to find an answer from across your disparate sources of self-service content. The search skill interacts with the IBM Watson\u00ae Discovery service to extract this information from a configured data collection.\n\nIf you already have Discovery for IBM Cloud Pak for Data installed and an instance provisioned, you can mine your existing data collections for source material that you can share with customers to address their questions.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question is sent to the Discovery service from a search skill.]", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-add"}, {"document_id": "ibmcld_07018-7974-8883", "score": 50.37207532783111, "text": "\nTo deploy a Conversational Search project, connect this project to an assistant that is built with Watson Assistant. The general steps to follow include:\n\n\n\n1. Create an assistant.\n\nYou can use a Watson Assistant Trial plan for testing purposes.\n2. Add a search skill to your assistant, and then connect it to this project.\n3. Deploy your assistant.\n\nFor more information about building a Watson Assistant search skill, see the appropriate documentation for your deployment:\n\n\n\nIBM Cloud\n\nFrom the new experience, see [Adding a search integration](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-search-add).\nIBM Cloud\n\nFrom the classic experience, see [Embedding existing help content](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add).\nIBM Cloud Pak for Data\n\n[Creating a search skill](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add).", "title": "", "source": "https://cloud.ibm.com/docs/discovery-data?topic=discovery-data-deploy"}, {"document_id": "ibmcld_03068-34858-36104", "score": 50.312234653920754, "text": "\nTo check whether the updated cacerts file is present in the configmap, run the oc get configmap watson-assistant-skill-cacerts --output yaml command.\n5. Override the cacerts file in the search skill pods. In this step, you configure the Watson Assistant operator to override the cacerts file in the search skill pods with the updated cacerts file. In the following example file, the Watson Assistant instance is called watson-assistant---wa. Replace this value with the name of your instance:\ncat <<EOF | oc apply -f -\nkind: TemporaryPatch\napiVersion: com.ibm.oppy/v1\nmetadata:\nname: watson-assistant---wa-skill-cert\nspec:\napiVersion: com.ibm.watson.watson-assistant/v1\nkind: WatsonAssistantSkillSearch\nname: \"watson-assistant---wa\" Replace this with the name of your Watson Assistance instance\npatchType: patchStrategicMerge\npatch:\n\"skill-search\":\ndeployment:\nspec:\ntemplate:\nspec:\nvolumes:\n- name: updated-cacerts\nconfigMap:\nname: watson-assistant-skill-cacerts\ndefaultMode: 420\ncontainers:\n- name: skill-search\nvolumeMounts:\n- name: updated-cacerts\nmountPath: /opt/ibm/java/jre/lib/security/cacerts\nsubPath: cacerts\nEOF\nShow more\n6. Wait until new search skill pods are created. It might take up to 10 minutes before the updates take affect.7.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-troubleshoot"}, {"document_id": "ibmcld_03054-18427-20301", "score": 49.98964103534396, "text": "\nFor details about how to add a search skill response type, see [Adding rich responses](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-dialog-overviewdialog-overview-multimedia-add).\n\nFor more tips about improving results, read the [Improve your natural language query results from Watson Discovery](https://developer.ibm.com/blogs/improving-your-natural-language-query-results-from-watson-discovery/) blog post.\n\n\n\n\n\n\n\n Next steps \n\nAfter you create the skill, it appears as a tile on the Skills page.\n\nThe search skill cannot interact with customers until it is added to an assistant and the assistant is deployed. See [Creating assistants](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-assistant-add).\n\n\n\n Adding the skill to an assistant \n\nYou can add one skill to an assistant. Open the assistant tile and add the skill to the assistant from there. You cannot choose the assistant that will use the skill from within the skill configuration page.\n\nOne search skill can be used by more than one assistant.\n\n\n\n1. Click the Assistants icon ![Skills menu icon](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/nav-ass-icon.png) to open the Assistants page.\n\nv1.3: Click the Assistants tab.\n2. Click to open the tile for the assistant to which you want to add the skill.\n3. Click Add Search Skill.\n4. Click Add existing skill.\n\nClick the skill that you want to add from the available skills that are displayed.\n\n\n\nAfter you add a search skill to an assistant, it is automatically enabled for the assistant as follows:\n\n\n\n* If the assistant has only a search skill, any user input that is submitted to one of the assistant's integration channels triggers the search skill.\n* If the assistant has both a dialog skill and a search skill, any user input triggers the dialog skill first.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-skill-search-add"}, {"document_id": "ibmcld_03383-4-1728", "score": 49.68175495947856, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Use a search skill to embed existing help content ![Plus or higher plan only](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/plus.png) \n\nPut your subject matter expertise to work by adding a search skill. The search skill gives your assistant access to corporate data collections that it can mine for answers.\n\nWhen a search skill is added, your assistant can route complex customer inquiries to the IBM Watson\u00ae Discovery service. Discovery treats the user input as a search query. It finds information that is relevant to the query from an external data source and returns it to the assistant.\n\nThis feature is available only to paid plan users.\n\nAdd a search skill to your assistant to prevent the assistant from having to say things like, I'm sorry. I can't help you with that. Instead, the assistant can query existing company documents or data to see whether any useful information can be found and shared with the customer.\n\n![Shows a search result in the Preview](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/search-preview-example.png)\n\nTo show the exact answer highlighted in bold font, enable the Emphasize the answer feature that is available with Discovery v2 instances.\n\nWatch a 4-minute video that provides an overview of the search skill:\n\nTo learn more about how search skill can benefit your business, [read this blog post](https://medium.com/ibm-watson/adding-search-to-watson-assistant-99e4e81839e5).", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add"}, {"document_id": "ibmcld_13042-4-1728", "score": 49.68175495947856, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Use a search skill to embed existing help content ![Plus or higher plan only](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/plus.png) \n\nPut your subject matter expertise to work by adding a search skill. The search skill gives your assistant access to corporate data collections that it can mine for answers.\n\nWhen a search skill is added, your assistant can route complex customer inquiries to the IBM Watson\u00ae Discovery service. Discovery treats the user input as a search query. It finds information that is relevant to the query from an external data source and returns it to the assistant.\n\nThis feature is available only to paid plan users.\n\nAdd a search skill to your assistant to prevent the assistant from having to say things like, I'm sorry. I can't help you with that. Instead, the assistant can query existing company documents or data to see whether any useful information can be found and shared with the customer.\n\n![Shows a search result in the Preview](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/search-preview-example.png)\n\nTo show the exact answer highlighted in bold font, enable the Emphasize the answer feature that is available with Discovery v2 instances.\n\nWatch a 4-minute video that provides an overview of the search skill:\n\nTo learn more about how search skill can benefit your business, [read this blog post](https://medium.com/ibm-watson/adding-search-to-watson-assistant-99e4e81839e5).", "title": "", "source": "https://cloud.ibm.com/docs/services/assistant?topic=assistant-skill-search-add"}, {"document_id": "ibmcld_03068-33594-35299", "score": 48.807521546810655, "text": "\nSEARCH_SKILL_POD=\"$(oc get pods -l component=skill-search --output custom-columns=NAME:.metadata.name --no-headers | head -n 1)\"\n\nc) Run the following command to see the selected pod:\n\necho \"Selected search skill pod: ${SEARCH_SKILL_POD}\"\n\nd) Retrieve the truststore file. The cacerts file is the default truststore that is used by Java. It contains the list of the certificate authorities that Java trusts by default. Run the following command to copy the binary cacerts file from the pod into your current directory:\n\noc cp ${SEARCH_SKILL_POD}:/opt/ibm/java/jre/lib/security/cacerts cacerts\n3. Run the following command to inject the ingress_ca.crt file into the cacerts file:\nkeytool -import -trustcacerts -keystore cacerts -storepass changeit -alias customer_ca -file ingress_ca.crt\n\nYou can run the keytool -list -keystore cacerts -storepass changeit | grep customer_ca -A 1 command to check that your CA certificate is included in the cacerts file.\n4. Run the following command to create the configmap that contains the updated cacerts file:\noc create configmap watson-assistant-skill-cacerts --from-file=cacerts\n\nBecause the cacerts file is binary, the output of the oc describe configmap watson-assistant-skill-cacerts command shows an empty data section. To check whether the updated cacerts file is present in the configmap, run the oc get configmap watson-assistant-skill-cacerts --output yaml command.\n5. Override the cacerts file in the search skill pods. In this step, you configure the Watson Assistant operator to override the cacerts file in the search skill pods with the updated cacerts file. In the following example file, the Watson Assistant instance is called watson-assistant---wa.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-troubleshoot"}, {"document_id": "ibmcld_03373-7076-8670", "score": 48.66908044764866, "text": "\nYou can then create a collection from a data source and configure your search skill to search this collection for answers to customer queries.\n\nThe following diagram illustrates how user input is processed when both a dialog skill and a search skill are added to an assistant. Any questions that the dialog is not designed to answer are sent to the search skill, which finds a relevant response from a Discovery data collection.\n\n![Diagram of how a question gets routed to the search skill.](https://cloud.ibm.com/docs-content/v1/content/417db917d18067d9dcc4cf2612564a9a87c3ddc8/assistant/images/search-skill-diagram.png)\n\n\n\n\n\n Creating a skill \n\nYou can add one conversation skill (actions or dialog) and one search skill to an assistant.\n\n\n\n Conversation \n\n\n\n* [Actions skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-actions-add)\n* [Dialog Skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-dialog-add)\n\n\n\n\n\n\n\n Search \n\n\n\n* [Search Skill](https://cloud.ibm.com/docs/assistant?topic=assistant-skill-search-add)\n\n\n\n\n\n\n\n\n\n Skill limits \n\nThe number of skills you can create depends on your Watson Assistant plan type. Any sample dialog skills that are available for you to use do not count toward your limit unless you use them. A skill version does not count as a skill.\n\n\n\nPlan details\n\n Plan Maximum number of skills of each type per service instance \n\n Enterprise 100 \n Premium (legacy) 100 \n Plus 50 \n Standard (legacy) 20 \n Lite, Trial 5 \n\n\n\n* After 30 days of inactivity, an unused skill in a Lite plan service instance might be deleted to free up space.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-skill-add"}]}
{"task_id": "20c2cbd18c16c12c9c2bbead6aef1a21<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_04175-0-1274", "score": 47.81216956157789, "text": "\n\n\n\n\n\n\n  Machine learning models \n\nEnterprise customers can enable auto-updates to their machine learning models for the newest bot detection models as they are released.\n\nTo enable auto-updates:\n\n\n\n1.  Log in to the CIS and select your account and domain.\n2.  Go to Security > Bots.\n3.  Select Configure Bot Management.\n4.  Enable auto-updates to the machine learning model.\n\n\n\nEnabling auto-updates for the machine learning model upgrades you to the latest version immediately. You can toggle the button off within 24 hours to revert to the previous version. To make changes after 24 hours, contact support.\n\n\n\n  What has changed? \n\nIf you are on an older machine learning model, you'll see a score change to requests scored by the machine learning source instantly. If you are already on the latest model, the changes show only after a new machine learning model becomes the global default.\n\nYou will be notified prior to a new machine learning model becoming the global default.\n\n\n\n\n\n  Why you should upgrade \n\nBy not updating to the latest version, you will be using a machine learning model that is no longer maintained or monitored by the engineering team. As internet traffic changes and new trends evolve, the scoring accuracy of older versions can degrade.\n\n\n\n\n\n\n\n\n", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models"}, {"document_id": "ibmcld_04105-5067-6335", "score": 47.78312714173737, "text": "\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:\n\n\n\n* Machine learning: A highly accurate bot identification machine learning model trained on trillions of requests with minimal impact to request processing speed\n* Heuristics engine: Detects bots by screening requests through a set of simple rules that capture bots based on certain attibutes of the requests made.\n* Behavioral analysis: Detects bots that have never been seen, calculating and analyzing normal visitor behavior over an extended period of time.\n* Verified bots: A way to avoid accidental blocks of useful bots using several validators and a bots directory of unique good bot identities.\n* JS fingerprinting: A challenge-response system with challenge injected into the webpage on Cloudflare\u2019s edge and rendered in the background for validation.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04168-6066-7283", "score": 45.54784456687498, "text": "\n* [Querying Edge Functions metrics with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-edge-func)\n* [Querying firewall events with GraphQL](https://cloud.ibm.com/docs/cis?topic=cis-graphql-firewall-events-example)\n\n\n\n* Working with alerts\n\n\n\n* [Configuring alert policies](https://cloud.ibm.com/docs/cis?topic=cis-configuring-policies)\n* [Configuring webhooks](https://cloud.ibm.com/docs/cis?topic=cis-configuring-webhooks)\n* [Creating alerts by type](https://cloud.ibm.com/docs/cis?topic=cis-create-alerts-by-type)\n\n\n\n* Working with Bot management\n\n\n\n* [About bot management](https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt)\n* [Machine learning models](https://cloud.ibm.com/docs/cis?topic=cis-machine-learning-models)\n* [JavaScript detections](https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections)\n\n\n\n* Enhancing security\n\n\n\n* [Managing access for CIS](https://cloud.ibm.com/docs/cis?topic=cis-iam-and-cis)\n* [Learning about CIS architecture and workload isolation](https://cloud.ibm.com/docs/cis?topic=cis-compute-isolation)\n* [Securing your data in CIS](https://cloud.ibm.com/docs/cis?topic=cis-mng-data)\n* [Auditing events for CIS](https://cloud.ibm.com/docs/cis?topic=cis-at_events)", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-http-concepts"}, {"document_id": "ibmcld_04105-3403-5572", "score": 35.45059838035523, "text": "\nHow bot management works \n\nTo identify bots, bot managers might use JavaScript challenges (which determine whether a traditional web browser is being used) or CAPTCHA challenges. They can also determine which users are humans and which are bots by behavioral analysis; by comparing a user's behavior to the standard behavior of users in the past.\n\nWhen a bot is identified as bad, it can be redirected to a different page or blocked from accessing a web resource altogether.\n\nGood bots can be added to an allowlist. A bot manager can also distinguish between good and bad bots by using further behavioral analysis.\n\nAnother bot management approach is to use the robots.txt file to set up a honeypot. A honeypot is a fake target for bad actors that, when accessed, exposes the bad actor as malicious. In the case of a bot, a honeypot could be a webpage on the site that's forbidden to bots by the robots.txt file. Good bots will read the robots.txt file and avoid that webpage; some bad bots will crawl the webpage. By tracking the IP address of the bots that access the honeypot, bad bots can be identified and blocked.\n\n\n\n\n\n Kinds of bot attacks bot management mitigates \n\nA bot management solution can help stop a variety of attacks, including the following:\n\n\n\n* DDoS attacks\n* DoS attacks\n* Credential stuffing\n* Credit card stuffing\n* Brute force password cracking\n* Spam content\n* Data scraping and web scraping\n* Email address harvesting\n* Ad fraud\n* Click fraud\n\n\n\nThese bot activities are not always considered \"malicious,\" but a bot manager should still be able to mitigate them:\n\n\n\n* Inventory hoarding\n* Automated posting on social forums or platforms\n* Shopping cart stuffing\n\n\n\n\n\n\n\n How does CIS manage bots? \n\nCIS collects data from requests flowing through its network every day. With this data, powered by Cloudflare's machine learning and behavior analysis, CIS can identify likely bot activity and can provide you with information on how to allow or disallow specific bot traffic using Firewall Rules.\n\nCloudflare Bot Management uses the following detection mechanisms, each producing their own scores, which are then combined to form a single score:", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-about-bot-mgmt"}, {"document_id": "ibmcld_04170-7-2189", "score": 31.57828240142628, "text": "\nJavaScript detections \n\nIBM Cloud\u00ae Internet Services (CIS) bot features include JavaScript detections. A small amount of JavaScript is injected into client devices using [Google\u2019s Picasso fingerprinting technique](https://research.google/pubs/pub45581/). Picasso results are factored into bot scores and help CIS classify traffic as automated or human. BotScoreSrc: Not Computed and a score of 0 are relevant to Picasso JavaScript Fingerprinting requests. These requests are exempt from being blocked by any firewall rules.\n\nThis detection technique gathers general data about the machines reaching CIS. For example, if a particular user is accessing CIS via Google Chrome on a MacBook Pro, because there are millions of people using Google Chrome on a MacBook Pro, CIS cannot identify specific individuals. CIS also takes steps to anonymize and phase out data for added privacy.\n\nJavaScript is only injected in response to requests for HTML pages or page views, excluding AJAX calls. API and mobile app traffic is unaffected. Additionally, code is not injected again until its 30-minute session life expires. The Picasso script is roughly 70 KB and execution time varies by device, anywhere from 90 ms to around 500 ms.\n\nThe snippets of JavaScript will contain a source pointing to the challenge platform with paths that start with /cdn-cgi/challenge-platform/....\n\n\n\n Enable JavaScript detections \n\nFor no-cost Trial plans (Bot Fight Mode), JavaScript detections are automatically enabled and cannot be disabled.\n\nFor all other plans (Super Bot Fight Mode and Bot Management for Enterprise), JavaScript detections are optional. To adjust your settings, go to Security > Bots.\n\n\n\n\n\n Enforcing execution of JavaScript detections \n\nTo ensure that visitors have previously run and passed JavaScript detections, you can create a firewall rule with the field cf.bot_management.js_detection.passed which performs a Managed Challenge action. Enter (cf.bot_management.js_detection.passed) into the Expression preview section as a singular rule.\n\n\n\n\n\n Considerations \n\n\n\n* If you have a Content Security Policy (CSP):\n\n\n\n* Ensure that anything under /cdn-cgi/challenge-platform/ is allowed.", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-javascript-detections"}, {"document_id": "ibmcld_04136-7-2226", "score": 27.764390790764068, "text": "\nDealing with Distributed Denial of Service attacks \n\nDistributed Denial of Service (DDoS) attacks are among the most common types of internet attacks that your website or host can encounter.\n\n\n\n What is a DDoS attack? \n\nA distributed denial of service (DDoS) attack is a malicious attempt to disrupt normal traffic of a server, service, or network by overwhelming the target or its surrounding infrastructure with a flood of internet traffic. DDoS attacks achieve effectiveness by utilizing many compromised computer systems as sources of attack traffic. Exploited machines can include computers and other networked resources such as IoT devices. From a high level, a DDoS attack is like a traffic jam clogging up a highway, preventing regular traffic from arriving at its destination.\n\n\n\n\n\n How DDoS attacks work \n\nAn attacker gains control of a network of online machines to carry out a DDoS attack. Computers and other machines (such as IoT devices) are infected with malware, turning each one into a bot (or zombie). The attacker controls the group of bots, which is called a botnet.\n\nAfter establishing a botnet, the attacker directs the machines by sending updated instructions to each bot using remote control. A targeted IP address can receive requests from a multitude of bots, causing the targeted server or network to overflow capacity. This creates a denial-of-service to normal traffic. Because each bot is a legitimate internet device, separating the attack traffic from normal traffic can be difficult.\n\n\n\n\n\n Common types of DDoS attacks \n\nDDoS attack vectors target varying components of a network connection. While nearly all DDoS attacks involve overwhelming a target device or network with traffic, attacks can be divided into three categories. An attacker can use one or multiple attack vectors, and might even cycle through these attack vectors based on countermeasures taken by the target.\n\nCommon types are:\n\n\n\n* Application layer attacks (Layer 7)\n* Protocol attacks (Layer 3 and Layer 4)\n* Volumetric attacks (amplification attacks)\n\n\n\n\n\n Application layer attacks \n\nAn application layer attack is sometimes referred to as a Layer-7 DDoS attack (in reference to the 7th layer of the OSI model).", "title": "", "source": "https://cloud.ibm.com/docs/cis?topic=cis-distributed-denial-of-service-ddos-attack-concepts"}, {"document_id": "ibmcld_16729-323776-325852", "score": 26.496506197253005, "text": "\nA script and tool will assist you to simulate the transmission of web server log messages from a static file to Event Streams.\n\nObject Storage Event Streams\n\n+3\n\nAnalytics Engine,Data Engine,Key Protect\n\n\n\n* 3 hours\n* 2023-05-05\n\n\n\n[Enhance cloud security by applying context-based restrictions](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-cbr-enhanced-security)Enhance cloud security by applying context-based restrictions\n\nThis tutorial walks you through the process of implementing context-based restrictions (CBRs) in your IBM Cloud account. CBRs help you to secure the cloud environment further and move towards a zero trust security model.\n\nKubernetes service Object Storage\n\n+7\n\nActivity Tracker hosted event search,Container Registry,Secrets Manager,App ID,Cloudant,Key Protect,Log Analysis\n\n\n\n* 2 hours\n* 2023-06-28\n\n\n\n[Apply end to end security to a cloud application](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-cloud-e2e-security)Apply end to end security to a cloud application\n\nThis tutorial walks you through key security services available in the IBM Cloud\u00ae catalog and how to use them together. An application that provides file sharing will put security concepts into practice.\n\nKubernetes service Object Storage\n\n+8\n\nActivity Tracker hosted event search,Container Registry,Secrets Manager,App ID,Cloudant,Key Protect,Log Analysis,Cloud Internet Services (CIS)\n\n\n\n* 2 hours\n* 2023-05-05\n\n\n\n[Build, deploy, test and monitor a predictive machine learning model](https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model)Build, deploy, test and monitor a predictive machine learning model\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\nObject Storage", "title": "", "source": "https://cloud.ibm.com/docs?tab=tutorials"}, {"document_id": "ibmcld_16524-7-2263", "score": 26.13437349379632, "text": "\nTraining the machine learning model \n\nIn IBM Watson\u00ae Knowledge Studio , the creation of the machine learning model involves training the machine learning model and evaluating how well the model performed when annotating test data and blind data.\n\n\n\n Creating a machine learning model \n\nWhen you create a machine learning model, you select the document sets that you want to use to train the model and specify the percentage of documents that are to be used as training data, test data, and blind data.\n\n\n\n About this task \n\nBy exploring the performance metrics, you can identify ways to improve the model's accuracy.\n\n> Restriction: Only three machine learning models can be trained at a time per Knowledge Studio instance. If your instance contains multiple workspaces and the number of machine learning models that are being trained in other workspaces totals 3 already, then your request to train the machine learning model in your workspace will be queued until the other training processes are done.\n\n\n\n\n\n Procedure \n\nTo create a machine learning model:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. Verify that all of the document sets have been approved and that all annotation conflicts have been resolved through adjudication. Only documents that have become ground truth through adjudication or approval can be used to train the model.\n4. Click Train and evaluate.\n5. Optional: To specify how you want to allocate documents from your document sets to be used by the system-level training, test, or blind sets, click Edit settings.\n\nSee [Document set management](https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-improve-mlwks_mamanagedata) for help determining which ratios to apply.\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\n> Important: Training a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio?topic=watson-knowledge-studio-train-ml"}, {"document_id": "ibmcld_16451-7-2278", "score": 26.115354506440383, "text": "\nTraining the machine learning model \n\nIn IBM Watson\u2122 Knowledge Studio for IBM Cloud Pak for Data, the creation of the machine learning model involves training the machine learning model and evaluating how well the model performed when annotating test data and blind data.\n\n\n\n Creating a machine learning model \n\nWhen you create a machine learning model, you select the document sets that you want to use to train the model and specify the percentage of documents that are to be used as training data, test data, and blind data.\n\n\n\n About this task \n\nBy exploring the performance metrics, you can identify ways to improve the model's accuracy.\n\nOnly three machine learning models can be trained at a time per Knowledge Studio instance. If your instance contains multiple workspaces and the number of machine learning models that are being trained in other workspaces totals 3 already, then your request to train the machine learning model in your workspace will be queued until the other training processes are done.\n\n\n\n\n\n Procedure \n\nTo create a machine learning model:\n\n\n\n1. Log in as a Knowledge Studio administrator and select your workspace.\n2. Select Machine Learning Model > Performance.\n3. Verify that all of the document sets have been approved and that all annotation conflicts have been resolved through adjudication. Only documents that have become ground truth through adjudication or approval can be used to train the model.\n4. Click Train and evaluate.\n5. Optional: To specify how you want to allocate documents from your document sets to be used by the system-level training, test, or blind sets, click Edit settings.\n\nFor more information about which ratios to apply, see [Document set management](https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-improve-mlwks_mamanagedata).\n6. Click Train to train the model, or click Train & Evaluate to train the model, evaluate annotations added by the machine learning model, and analyze the performance statistics.\n\nTraining a machine learning model can take several minutes or several hours, depending on the number of human annotations that exist and the total number of words across all documents.\n7. Select the document sets that you want to use for training the model.", "title": "", "source": "https://cloud.ibm.com/docs/watson-knowledge-studio-data?topic=watson-knowledge-studio-data-train-ml"}, {"document_id": "ibmcld_13129-7-1929", "score": 26.085391931692122, "text": "\nBuild, deploy, test and monitor a predictive machine learning model \n\nThis tutorial may incur costs. Use the [Cost Estimator](https://cloud.ibm.com/estimator/review) to generate a cost estimate based on your projected usage.\n\nThis tutorial walks you through the process of building a predictive machine learning model, deploying the generated model as an API to be used in your applications and testing the model all of this happening in an integrated and unified self-service experience on IBM Cloud. You will then monitor the deployed model with IBM Watson OpenScale.\n\nIn this tutorial, the Iris flower data set is used for creating a machine learning model to classify species of flowers.\n\nIn the terminology of machine learning, classification is considered an instance of supervised learning, i.e. learning where a training set of correctly identified observations is available.\n\nWatson Studio provides you with the environment and tools to solve your business problems by collaboratively working with data. You can choose the tools you need to analyze and visualize data, to cleanse and shape data, to ingest streaming data, or to create and train machine learning models.\n\n\n\n Objectives \n\n\n\n* Import data to a project.\n* Build a machine learning model.\n* Deploy the model and try out the API.\n* Test a machine learning model.\n* Monitor the deployed model\n* Retrain your model.\n\n\n\nZoom\n\n![Architecture Diagram](https://cloud.ibm.com/docs-content/v1/content/f84e2238288b7f0355715a4c355609ce7ac48fb0/solution-tutorials/images/solution22-build-machine-learning-model/architecture_diagram.png)\n\nFigure 1. Architecture diagram of the tutorial\n\n\n\n1. The admin uploads a CSV file from a local machine.\n2. The uploaded CSV file is stored in IBM Cloud Object Storage service as a dataset.\n3. The dataset is then used to build and deploy a machine learning model. The deployed model is exposed as an API (scoring-endpoint).\n4.", "title": "", "source": "https://cloud.ibm.com/docs/solution-tutorials?topic=solution-tutorials-create-deploy-retrain-machine-learning-model"}]}
{"task_id": "5815bb4a99e2a0d8a986348da4c49083<::>2", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_06843-4238-6198", "score": 35.34280624135156, "text": "\nThis command returns either cc, cd, ci, or pr, depending on which pipeline is running. This way, you can reuse the setup script between pipelines if necessary.\n\n\n\n\n\n Static code scan \n\nThe static code scan stage runs a static code analyzer tool on the specified app repo codebases.\n\nCC pipeline provides the repos that are found in the inventory for the scanner.\n\nYou can use any of the following methods to add static code to your pipeline:\n\n\n\n* Provide an already running SonarQube instance name, URL, and credentials by adding the SonarQube tool to your toolchain. The static-scan task runs a scan on the specified repos.\n* Add your code to the static-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\n\n\n\n\n Dynamic scan \n\nThe Dynamic scan stage runs a dynamic application security testing tool to find vulnerabilities in the deployed application.\n\n\n\n* Add your own dynamic scan code to the dynamic-scan custom stage in your .pipeline-config.yaml file for a custom implementation.\n\n\n\nTo learn more about configuring dynamic scan by using OWASP-ZAP, see [Configuring ZAP scan for CC pipeline](https://cloud.ibm.com/docs/devsecops?topic=devsecops-zap-scanszap-scan-for-cc).\n\n\n\n\n\n Scans and checks in compliance checks \n\n\n\nTable 3. Compliance scans and checks\n\n Scan or check Description \n\n Detect secrets The [IBM Detect Secrets](https://github.com/IBM/detect-secrets) tool identifies where secrets are visible in app code. \n Code Risk Analyzer vulnerability scan Finds vulnerabilities for all of the app package dependencies, container base images, and operating system packages. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer CIS check Runs configuration checks on Kubernetes deployment manifests. Uses the Code Risk Analyzer tool. \n Code Risk Analyzer Bill of Material (BOM) check The BOM for a specified repo that captures the pedigree of all of the dependencies. This BOM is collected at different granularities.", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-devsecops-cc-pipeline"}, {"document_id": "ibmcld_07899-3004-4915", "score": 33.746791151331664, "text": "\nSI-2 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain verifies source code branch protection rules to enforce security policies<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes unit tests to validate all code changes<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br> \n SI-2 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-si-2"}, {"document_id": "ibmcld_07844-4589-6711", "score": 33.479947070971626, "text": "\nRA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n RA-5 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nSecurity categorization of information systems guides the frequency and comprehensiveness of vulnerability scans. Organizations determine the required vulnerability scanning for all information system components, ensuring that potential sources of vulnerabilities such as networked printers, scanners, and copiers are not overlooked. Vulnerability analyses for custom software applications may require additional approaches such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"}, {"document_id": "ibmcld_07899-4108-6235", "score": 32.83030250134023, "text": "\nSI-2 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br> \n SI-2 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain verifies source code branch protection rules to enforce security policies<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain collects software bills of materials (SBOM) to provide transparency in build artifacts<br> * Check whether DevSecOps Toolchain passes unit tests to validate all code changes<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br> * Check whether DevSecOps Toolchain signs build artifacts to attest their provenance<br> * Check whether DevSecOps Toolchain deployment has approved change documentation including security impact analysis<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-si-2"}, {"document_id": "ibmcld_07844-2925-4586", "score": 32.39322039635653, "text": "\nRA-5 (a) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"}, {"document_id": "ibmcld_07844-3757-5369", "score": 32.34114647252487, "text": "\nRA-5 (b) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether Container Registry Vulnerability Advisor scans for critical or high vulnerabilities in the system at least every # day(s)<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br><br><br> \n RA-5 (c) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br>", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"}, {"document_id": "ibmcld_06845-2832-4521", "score": 32.10789863292895, "text": "\ncollect-evidence --tool-type \"sonarqube\" --evidence-type \"com.ibm.static_scan\" --asset-type \"repo\" --asset-key \"app-repo\" --status \"success\" --attachment ./sonarqube-result-1.json --attachment ./sonarqube-result-2.json --meta environment=staging\n\n\n\n\n\n\n\n Supported tool formats \n\nThe current implementation currently supports the following tools (provided as the --tool-type parameter):\n\n\n\n* cra IBM Code Risk Analyzer\n* va Vulnerability Advisor for IBM Cloud Container Registry\n* gosec GoLang Security Scanner\n* xray JFrog Xray - Vulnerability Scanning & Container Security\n* owasp-zap OWASP Zed Attack Proxy (ZAP)\n* owasp-zap-ui OWASP Zed Attack Proxy UI (ZAP UI)\n* sonarqube 'SonarQube scan\n\n\n\nIf the collect-evidence script is called with a tool type that is not supported, the script doesn't attempt to process the attachments. Additionally, the issue handling is skipped, and the evidence collection is not stopped.\n\nIf your script provides an attachment from a supported tool, but the attachment cannot be processed, the issue handling is skipped, and the evidence collection is not stopped.\n\n\n\n\n\n Evidence type \n\nYou can set the evidence type by using the --evidence-type parameter. You can set any type, but the IBM Cloud\u00ae Security and Compliance Center supports the following evidence types:\n\n\n\n* com.ibm.unit_tests\n* com.ibm.detect_secrets\n* com.ibm.branch_protection\n* com.ibm.static_scan\n* com.ibm.code_vulnerability_scan\n* com.ibm.code_bom_check\n* com.ibm.code_cis_check\n* com.ibm.cloud.image_vulnerability_scan\n* com.ibm.cloud.image_signing\n* com.ibm.dynamic_scan\n* com.ibm.acceptance_tests\n* com.ibm.prod_change_request\n* com.ibm.close_change_reques\n\n\n\n\n\n Asset requirements", "title": "", "source": "https://cloud.ibm.com/docs/devsecops?topic=devsecops-devsecops-collect-evidence"}, {"document_id": "ibmcld_12724-3197-5566", "score": 31.51560442572749, "text": "\n6.3 Ensure Toolchain has Code Risk Analyzer configured that collects a bill of materials for pipeline run Ensure DevSecOps Toolchain collects software bills of materials (SBOM) to provide transparency in build artifacts \n 6.4 Ensure Toolchain is configured with image signing Ensure DevSecOps Toolchain signs build artifacts to attest their provenance \n 6.5 Ensure Toolchain source code meets Center for Internet Security Docker benchmarks Ensure DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely \n 6.6 Ensure Toolchain has branch protection rules enabled Ensure DevSecOps Toolchain verifies source code branch protection rules to enforce security policies \n 6.7 Ensure Toolchain has secret detection scans enabled for source code Ensure DevSecOps Toolchain source code contains no secrets \n 6.8 Ensure Toolchain production change request exists and is approved Ensure DevSecOps Toolchain deployment has approved change documentation including security impact analysis \n 6.9 Ensure Toolchain Container Registry Vulnerability Advisor scans images for OS vulnerability detection Ensure DevSecOps Toolchain scans build artifacts to identify vulnerabilities \n 6.12 Ensure Toolchain acceptance tests exist and have passed Ensure DevSecOps Toolchain passes acceptance tests to validate every deployment \n 6.16 Ensure that only the tool integrations within the toolchain are included in the allow list parameter array Ensure Toolchain is configured only with the allowed integration tools \n 6.17 Ensure a Toolchain static scan exists and has passed Ensure DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code \n 6.18 Ensure a Toolchain dynamic scan exists and has passed Ensure DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts \n\n\n\n\n\n\n\n 13 March 2023 \n\nThe following new controls have been added to the IBM Cloud Security Best Practices library and profile as of 17 March 2023.\n\n\n\nTable. Summary of IBM Cloud Security Best Practices profile changes for Version 1.1.0\n\n Control ID Control Description \n\n 6.1 Ensure Toolchain scans during continuous integration the source code to identify vulnerabilities \n 6.2 Ensure Toolchain has unit tests that are continuously run to validate source code changes", "title": "", "source": "https://cloud.ibm.com/docs/security-compliance?topic=security-compliance-ibm-sec-best-practices-change-log"}, {"document_id": "ibmcld_12498-8087-10171", "score": 31.41496734390467, "text": "\nAnd, ultimately, it makes it a little more efficient for the management of your secrets while you're going through your DevOps operations.\n\nThank you. If you have questions, please drop us a line. If you want to see more videos like this in the future, please like and subscribe, and don't forget you can grow your skills and earn a badge with IBM Cloud Labs which, are free browser-based interactive Kubernetes labs.\n\n\n\n\n\n Working with secrets of different types \n\nSecrets that you create in Secrets Manager can be static or dynamic in nature. A static secret has its expiration date and time enforced at secret creation or rotation time. In contrast, a\n\ndynamic secrethas its expiration date and time enforced when its secret data is read or accessed.\n\nSecrets Manager further classifies static and dynamic secrets by their general purpose or function. For example, each secret type is identified by programmatic name, such as username_password. If you're looking to manage your secret by using the Secrets Manager API or CLI, you can use these programmatic names to run operations on secrets according to their type.\n\nReview the following table to understand the types of static and dynamic secrets that you can create and manage with the service.\n\n\n\nTable 1. Secret types in Secrets Manager\n\n Type Programmatic name Kind Description \n\n [Arbitrary secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-arbitrary-secrets) arbitrary Static Arbitrary pieces of sensitive data, including any type of structured or unstructured data, that you can use to access an application or resource. \n [IAM credentials](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-iam-credentials) iam_credentials* Dynamic A dynamically generated service ID and API key that can be used to access an IBM Cloud service that requires IAM authentication. \n [Key-value secrets](https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-key-value) kv Static Pieces of sensitive data that is structured in JSON format that you can use to access an application or resource.", "title": "", "source": "https://cloud.ibm.com/docs/secrets-manager?topic=secrets-manager-what-is-secret"}, {"document_id": "ibmcld_07844-5372-7725", "score": 31.004663881860754, "text": "\nRA-5 (d) <br><br> * Check whether DevSecOps Toolchain scans build artifacts to identify vulnerabilities<br> * Check whether DevSecOps Toolchain validates code against Center for Internet Security (CIS) Docker benchmarks to ensure container runtimes are configured securely<br> * Check whether DevSecOps Toolchain passes dynamic code scan to identify vulnerabilities in deployed artifacts<br> * Check whether DevSecOps Toolchain scans source code and their dependencies to identify vulnerabilities<br> * Check whether DevSecOps Toolchain source code contains no secrets<br> * Check whether DevSecOps Toolchain passes static code scan to identify vulnerabilities in source code<br> * Check whether DevSecOps Toolchain passes acceptance tests to validate every deployment<br><br><br> \n\n\n\n\n\n\n\n NIST supplemental guidance \n\nSecurity categorization of information systems guides the frequency and comprehensiveness of vulnerability scans. Organizations determine the required vulnerability scanning for all information system components, ensuring that potential sources of vulnerabilities such as networked printers, scanners, and copiers are not overlooked. Vulnerability analyses for custom software applications may require additional approaches such as static analysis, dynamic analysis, binary analysis, or a hybrid of the three approaches. Organizations can employ these analysis approaches in a variety of tools (e.g., web-based application scanners, static analysis tools, binary analyzers) and in source code reviews. Vulnerability scanning includes, for example: (i) scanning for patch levels; (ii) scanning for functions, ports, protocols, and services that should not be accessible to users or devices; and (iii) scanning for improperly configured or incorrectly operating information flow control mechanisms. Organizations consider using tools that express vulnerabilities in the Common Vulnerabilities and Exposures (CVE) naming convention and that use the Open Vulnerability Assessment Language (OVAL) to determine/test for the presence of vulnerabilities. Suggested sources for vulnerability information include the Common Weakness Enumeration (CWE) listing and the National Vulnerability Database (NVD). In addition, security control assessments such as red team exercises provide other sources of potential vulnerabilities for which to scan.", "title": "", "source": "https://cloud.ibm.com/docs/framework-financial-services-controls?topic=framework-financial-services-controls-ra-5"}]}
{"task_id": "b4614daadceeecb400f7baf0aa48dcb8<::>4", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_13429-127288-129174", "score": 22.562575060182727, "text": "\nIf your application uses the sessions interface, you must migrate to one of the following interfaces by September 7:\n\n\n\n* For stream-based speech recognition (including live-use cases), use the [WebSocket interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets), which provides access to interim results and the lowest latency.\n* For file-based speech recognition, use one of the following interfaces:\n\n\n\n* For shorter files of up to a few minutes of audio, use either the [synchronous HTTP interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-http)(POST /v1/recognize) or the [asynchronous HTTP interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-async) (POST /v1/recognitions).\n* For longer files of more than a few minutes of audio, use the asynchronous HTTP interface. The asynchronous HTTP interface accepts as much as 1 GB of audio data with a single request.\n\n\n\n\n\nThe WebSocket and HTTP interfaces provide the same results as the sessions interface (only the WebSocket interface provides interim results). You can also use one of the Watson SDKs, which simplify application development with any of the interfaces. For more information, see the [API & SDK reference](https://cloud.ibm.com/apidocs/speech-to-text).\n\n\n\n\n\n 13 July 2018 \n\nUpdates to Spanish narrowband model for improved speech recognition\n: The Spanish narrowband model, es-ES_NarrowbandModel, was updated for improved speech recognition. By default, the service automatically uses the updated model for all recognition requests. If you have custom language or custom acoustic models that are based on this model, you must upgrade your custom models to take advantage of the updates by using the following methods:\n\n\n\n* POST /v1/customizations/{customization_id}/upgrade_model\n* POST /v1/acoustic_customizations/{customization_id}/upgrade_model", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-release-notes"}, {"document_id": "ibmcld_03285-5746-7932", "score": 22.289899647465976, "text": "\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https://cloud.ibm.com/apidocs/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-dialog-voice-actions"}, {"document_id": "ibmcld_16321-5729-7915", "score": 22.289899647465976, "text": "\nSubsequently, the previous configuration is used.<br> * merge: Merges the new configuration with the existing configuration for the rest of the session. Only changed parameters are overwritten; any other configuration parameters are unchanged.<br> * merge_once: Merges the new configuration with the existing configuration only for the next turn of the conversation. Subsequently, the previous configuration is used.<br><br><br> no replace \n\n\n\nThe parameters that you can set for narrowband_recognize and broadband_recognize reflect the parameters that are made available by the Speech to Text WebSocket interface. The WebSocket API sends two types of parameters: query parameters, which are sent when the phone integration connects to the service, and message parameters, which are sent as part of the JSON data in the request body. For example, model is a query parameter, and smart_formatting is a WebSocket message parameter. For a full list of parameters, see the [Speech to Text API documentation](https://cloud.ibm.com/apidocs/speech-to-text).\n\nYou can define the following query parameters for the phone integration's connection to the Speech to Text service. Any other parameter that you define for narrowband or broadband is passed through as part of the WebSocket message request.\n\n\n\n* model\n* acoustic_customization_id\n* version\n* x-watson-learning-opt-out\n* base_model_version\n* language_customization_id\n\n\n\nThe following parameters from the Speech to Text service can't be modified because they have fixed values that are used by the phone integration.\n\n\n\n* action\n* content-type\n* interim_results\n* continuous\n* inactivity_timeout\n\n\n\nWhen configuring dynamically from Watson Assistant using the configure command, note that only the root level fields, such as narrowband or broadband, are updated. If these fields are omitted from the command, the original configuration settings persist. You can use the update_strategy values merge and merge_once to merge configuration parameters with the existing configuration.\n\n\n\n\n\n Using a custom language model \n\nWhen you set up the phone integration, you can configure the integration to use a custom language model all the time.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-phone-actions"}, {"document_id": "ibmcld_13361-1589-2935", "score": 21.90245352213005, "text": "\n* For the [WebSocket interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets), you first specify the customization ID with the language_customization_id parameter of the /v1/recognize method. You use this method to establish a WebSocket connection with the service.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}/v1/recognize'\n+ '?access_token=' + access_token\n+ '&language_customization_id={customization_id}';\nvar websocket = new WebSocket(wsURI);\n\nYou then specify the name of the grammar with the grammar_name parameter in the JSON start message for the active connection. Passing this value with the start message allows you to change the grammar dynamically for each request that you send over the connection.\n\nfunction onOpen(evt) {\nvar message = {\naction: 'start',\ncontent-type: 'audio/l16;rate=22050',\ngrammar_name: '{grammar_name}'\n};\nwebsocket.send(JSON.stringify(message));\nwebsocket.send(blob);\n}\n* For the [synchronous HTTP interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-http), pass both parameters with the POST /v1/recognize method.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio/flac\" --data-binary @audio-file.flac \"{url}/v1/recognize?language_customization_id={customization_id}&grammar_name={grammar_name}\"\n\nIBM Cloud Pak for Data", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-grammarUse"}, {"document_id": "ibmcld_13645-1132-2052", "score": 21.699212447409522, "text": "\n* The HTTP POST /v1/synthesize method:\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: application/json\" --header \"Accept: audio/flac\" --data \"{\"text\":\"IEEE\"}\" --output ieee.flac \"{url}/v1/synthesize?customization_id={customization_id}\"\n\nIBM Cloud Pak for Data\n\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type: application/json\" --header \"Accept: audio/flac\" --data \"{\"text\":\"IEEE\"}\" --output ieee.flac \"{url}/v1/synthesize?customization_id={customization_id}\"\n\n\n\nThe third example establishes a WebSocket connection with the /v1/synthesize method. The request uses the indicated custom model to synthesize text that is passed over the connection.\n\nvar access_token = '{access_token}';\nvar wsURI = '{ws_url}/v1/synthesize'\n+ '?access_token=' + access_token\n+ '&voice=en-US_AllisonV3Voice'\n+ '&customization_id=={customization_id}';\nvar websocket = new WebSocket(wsURI);", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-custom-using"}, {"document_id": "ibmcld_13779-3555-3945", "score": 21.240569806399535, "text": "\nvar access_token = '{access_token}';\nvar wsURI = '{ws_url}/v1/synthesize'\n+ '?access_token=' + access_token\n+ '&customization_id={customization_id}'\n+ '&voice=en-US_AllisonV3Voice';\nvar websocket = new WebSocket(wsURI);\n\nfunction onOpen(evt) {\nvar message = {\ntext: '<ibm:prompt id=\"goodbye\"/>',\naccept: 'audio/ogg;codecs=opus'\n};\nwebsocket.send(JSON.stringify(message));\n}\n\n. . .\nShow more", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-tbe-use"}, {"document_id": "ibmcld_10852-48513-49624", "score": 20.77398753524934, "text": "\n* [Reading an object with the CLI](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_read_cli)\n* [Reference for Object Storage and Cloud Functions](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_obstoragepkg_obstorage_actions)\n\n\n\n\n\n[Slack](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_slackpkg_slack)\n\n\n\n* [Posting a message to a Slack channel](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_slackpkg_slack_post)\n* [Using the Slack token-based API](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_slackpkg_slack_api)\n\n\n\n[Utilities](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_utilspkg_utils)\n\n[WebSocket](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_websocketpkg_websocket)\n\n\n\n* [Send a message to a WebSocket](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-pkg_websocketsend-websocket)\n\n\n\n[Creating custom event provider feeds](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-feeds_customfeeds_custom)\n\n\n\n* [Feed architecture](https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-feeds_customfeeds_arch)", "title": "", "source": "https://cloud.ibm.com/docs/openwhisk?topic=openwhisk-sitemap"}, {"document_id": "ibmcld_13779-2531-3774", "score": 20.765446484377, "text": "\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type: application/json\" --header \"Accept: audio/ogg;codecs=opus\" --data \"{\"text\":\"<ibm:prompt id='goodbye'/>\"}\" \"{url}/v1/synthesize?customization_id={customization_id}&voice=en-US_AllisonV3Voice\"\n* This example calls the GET /v1/synthesize method to synthesize the prompt, which must be URL-encoded:\n\nIBM Cloud\n\ncurl -X GET -u apikey:{apikey } --header \"Accept: audio/ogg;codecs=opus\" \"{url}/v1/synthesize?customization_id={customization_id}&voice=en-US_AllisonV3Voice&text=%3Cibm%3Aprompt%20id%3D%22goodbye%22%2F%3E\"\n\nIBM Cloud Pak for Data\n\ncurl -X GET --header \"Authorization: Bearer {token}\" --header \"Accept: audio/ogg;codecs=opus\" \"{url}/v1/synthesize?customization_id={customization_id}&voice=en-US_AllisonV3Voice&text=%3Cibm%3Aprompt%20id%3D%22goodbye%22%2F%3E\"\n\n\n\nThe following snippet of JavaScript code uses the [WebSocket interface](https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-usingWebSocket) to synthesize the prompt:\n\nvar access_token = '{access_token}';\nvar wsURI = '{ws_url}/v1/synthesize'\n+ '?access_token=' + access_token\n+ '&customization_id={customization_id}'\n+ '&voice=en-US_AllisonV3Voice';\nvar websocket = new WebSocket(wsURI);", "title": "", "source": "https://cloud.ibm.com/docs/text-to-speech?topic=text-to-speech-tbe-use"}, {"document_id": "ibmcld_13384-1568-2859", "score": 20.681098641490824, "text": "\n* For the [WebSocket interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-websockets), use the /v1/recognize method. The specified custom model is used for all requests that are sent over the connection.\n\nvar access_token = {access_token};\nvar wsURI = '{ws_url}/v1/recognize'\n+ '?access_token=' + access_token\n+ '&model=en-US_Telephony'\n+ '&language_customization_id={customization_id}';\nvar websocket = new WebSocket(wsURI);\n* For the [synchronous HTTP interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-http), use the POST /v1/recognize method. The specified custom model is used for that request.\n\nIBM Cloud\n\ncurl -X POST -u \"apikey:{apikey}\" --header \"Content-Type: audio/flac\" --data-binary @audio-file.flac \"{url}/v1/recognize?model=en-US_Telephony&language_customization_id={customization_id}\"\n\nIBM Cloud Pak for Data\n\ncurl -X POST --header \"Authorization: Bearer {token}\" --header \"Content-Type: audio/flac\" --data-binary @audio-file.flac \"{url}/v1/recognize?model=en-US_Telephony&language_customization_id={customization_id}\"\n* For the [asynchronous HTTP interface](https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-async), use the POST /v1/recognitions method. The specified custom model is used for that request.\n\nIBM Cloud", "title": "", "source": "https://cloud.ibm.com/docs/speech-to-text?topic=speech-to-text-languageUse"}, {"document_id": "ibmcld_04684-2405-4121", "score": 20.54423383946139, "text": "\nYou can specify a different set of Liberty features by setting the JBP_CONFIG_LIBERTY environment variable. For example, to enable only the jsp-2.3 and websocket-1.1 features, run the command and restage the app:\n\nibmcloud cf set-env myapp JBP_CONFIG_LIBERTY \"app_archive: {features: [jsp-2.3, websocket-1.1]}\"\n\nFor best results, set the Liberty features with the JBP_CONFIG_LIBERTY environment variable or deploy your app as a [server directory](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-options_for_pushingserver_directory) or [packaged server](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-options_for_pushingpackaged_server) with a custom server.xml file. Setting this environment variable ensures that your app uses only the feature that it needs and it is not affected by the buildpack's default Liberty feature set changes. If you need to provide extra Liberty configuration beyond the feature set, use the [server directory](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-options_for_pushingserver_directory) or the [packaged server](https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-options_for_pushingpackaged_server) option to deploy your app.\n\nIf you deployed a WAR file, the web app is accessible under the context root as set in the embedded ibm-web-ext.xml file. If the ibm-web-ext.xml file does not exist, or does not specify the context root, the app is accessible under the root context. For example,\n\nhttp://<yourappname>.mybluemix.net/\n\nIf you deployed an EAR file, the embedded web app is accessible under the context root as defined in the EAR deployment descriptor. For example,", "title": "", "source": "https://cloud.ibm.com/docs/cloud-foundry-public?topic=cloud-foundry-public-options_for_pushing"}]}
{"task_id": "fdee20f7fd677e420742b09989623d68<::>3", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_16368-7-2072", "score": 26.805665407749768, "text": "\nWeb chat development overview \n\nIf you are comfortable with JavaScript code, you can customize and extend the web chat by using the web chat API. You can also use a WebView to embed the web chat in your mobile app.\n\nFor detailed reference information about the web chat API, see the web chat [developer documentation](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=).\n\nTo add the web chat widget to your website or a WebView in your mobile app, all you need to do is embed a generated script element in your HTML source (for more information about the embed script, see [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat)). Within this embed script, you can use the web chat API to customize or extend the web chat.\n\nThe web chat API consists of several components:\n\n\n\n* Configuration object: The embed script defines a configuration object named watsonAssistantChatOptions, which specifies configuration objects for the web chat widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered. For more information about the available configuration options, see [Configuration options object](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationconfigurationobject) in the web API reference.\n* Instance methods: The web chat instance methods provide low-level control of the web chat widget. You can use the instance methods to implement custom behavior such as changing how the web chat widget opens, showing and hiding content, and setting identity information. For more information about the available instance methods, see [List of methods and properties](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodslistofmethods) in the web chat API reference.\n* Events: The web chat event system makes it possible for your website to respond to web chat events (such as opening or closing the web chat window, sending or receiving messages).", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-develop"}, {"document_id": "ibmcld_16384-7-2422", "score": 25.709203170059414, "text": "\nWeb chat overview \n\nYou can use the web chat integration to deploy your assistant on your website or embed it as a WebView in your mobile app. The web chat integration provides an easy-to-use chatbot interface that can integrate seamlessly with your site, without requiring the time and effort that would be required to build your own custom user interface.\n\nThe web chat can help your customers start the conversation with common questions or tasks; it can display multimedia and interactive elements such as forms, and it can transfer customers to human agents for more help. A developer can customize the web chat to add even more capabilities.\n\n\n\n Why use the web chat? \n\nBuilding a custom user interface requires spending time and effort solving typical UI problems. For example, you need to design the layout and styling, keep up with browser changes, manage scrolling behavior, validate input, and comply with accessibility requirements. The time you spend building and maintaining a custom UI is better spent building a high-quality assistant instead.\n\nThe web chat widget uses cutting-edge functionality from IBM Design and Research to engage your users when they need help, answer their questions quickly and efficiently, and provide fallback options so there is always a path to a solution. The web chat is easy for you to deploy and easy for customers to use, it is secure, and it supports a wide range of desktop and mobile browsers.\n\nThe web chat is also customizable, which means that you can take advantage of the web chat functionality while still maintaining consistency with your website style and branding, adding custom UI elements, and integrating with external systems (such as live agent tools or CRM systems).\n\n\n\n\n\n What you can do with the web chat \n\nYou can quickly deploy the web chat to your website (or even to a local test page) and see how it works. You can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_16384-1889-3334", "score": 24.963553558935175, "text": "\nYou can also use the web chat integration settings in the Watson Assistant user interface to configure the web chat for your website and your customers.\n\nIf you are a developer, you can further customize and extend the web chat by writing code and using the web chat API. You can also use a WebView with a JavaScript bridge to add the web chat to your mobile app.\n\nThe following documentation topics provide more information about the capabilities of the web chat integration, how to configure and deploy it, and how to customize it.\n\n\n\n* [How the web chat works](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture): Overview of web chat capabilities and architecture\n* [Embedding the web chat on your page](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat): How to embed the web chat widget on your website\n* [Web chat setup](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to configure the web chat using the integration settings\n* [Web chat development](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config): How to customize and extend the web chat by writing code\n* [Adding contact center support](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat-haa): How to integrate the web chat with a contact center platform so you can connect your customers to human agents", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-overview"}, {"document_id": "ibmcld_16365-12876-14604", "score": 24.046610430617818, "text": "\nIf your CSP uses a nonce to add elements such as <script> and <style> tags to an allowlist, do not use unsafe-inline to allow all such elements. Instead, provide a nonce value to the web chat widget as a configuration option. The web chat will then set the nonce on any of the <script> and <style> elements that it generates dynamically.\n\nA CSP that passes a nonce to the web chat widget might look like this:\n\n<meta\nhttp-equiv=\"Content-Security-Policy\"\ncontent=\"default-src 'self' .watson.appdomain.cloud fonts.gstatic.com 'nonce-<server generated value>';connect-src .watson.appdomain.cloud\"\n>\n\nYou can pass the nonce to the web chat by editing the embed script as follows:\n\nwindow.watsonAssistantChatOptions = {\nintegrationID: \"YOUR_INTEGRATION_ID\",\nregion: \"YOUR_REGION\",\nserviceInstanceID: \"YOUR_SERVICE_INSTANCE\",\n\ncspNonce: \"<server generated value>\",\n\nonLoad: function(instance) {\ninstance.render();\n}\n};\n\n\n\n\n\n\n\n Access to web chat hosts \n\nIf the system that hosts your website has limited Internet access (for example, if you use a proxy or firewall), make sure the following URLs are accessible:\n\n\n\n* https://web-chat.global.assistant.watson.appdomain.cloud: Hosts the code for the web chat widget, and is referenced by the script you embed on your website.\n* https://integrations.{location}.assistant.watson.appdomain.cloud: Hosts the web chat server, which handles communication with your assistant. Replace {location} with the location of the data center where your service instance is located, which is part of the service endpoint URL. For more information, see [Finding and updating the endpoint URL](https://cloud.ibm.com/docs/watson?topic=watson-endpoint-changeendpoint-find-update).\n\n\n\n\n\n\n\n Reviewing security", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-architecture"}, {"document_id": "ibmcld_03080-7-1901", "score": 23.396316297751323, "text": "\nApplying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens. For example, you might want to launch the web chat from some other button or process that exists on your website, or maybe open it in a different location, or at a different size.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-web-chat-config"}, {"document_id": "ibmcld_16326-1697-3495", "score": 22.72184690307856, "text": "\nFor more information, see [Changing background website](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-preview-sharepreview-change-background).\n* Customize web chat: Customize your draft web chat channel to match your brand or website. For more information, see [Web chat setup overview](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-config).\n\n\n\n![Image of the Preview page](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/preview-page.png)\n\n\n\n\n\n Copying a link to share \n\nYou can share an unauthenticated version of your assistant with your team by sending them a link. The link opens a sample web page with an interactive web chat widget where you can test out your assistant as if you were a customer. Your subject-matter experts can test your in-progress assistant without needing access to Watson Assistant itself. The experience is identical to using Preview this environment on the draft environment tab.\n\nTo share a link:\n\n\n\n1. On the Preview page, click Copy link to share.\n2. Send the link to your team.\n\n\n\nThe preview link is not accessible if web chat security is enabled. For more information about web chat security, see [Securing the web chat](https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-web-chat-security).\n\n\n\n\n\n Changing background website \n\nYou can visualize how your assistant would look as a web chat widget on your organization's website. You can enter a URL or upload an image.\n\n\n\n Entering a URL \n\nYou can enter a URL of your organization's website. Watson Assistant captures an image of your website to use as the Preview page background.\n\nYour website must be publicly available to all users. Private or intranet sites can\u2019t be accessed.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-preview-share"}, {"document_id": "ibmcld_03421-4-1877", "score": 22.652693803614124, "text": "\nThis documentation is for the classic Watson Assistant experience. To see the documentation for the new Watson Assistant, please go [here](https://cloud.ibm.com/docs/watson-assistant).\n\n\n\n Applying advanced customizations \n\nTailor the web chat to match your website and brand, and to behave in ways that meet your business needs.\n\n\n\n API overview \n\nThe following APIs are available:\n\n\n\n* Configuration object: When the embedded web chat widget starts, a configuration object named watsonAssistantChatOptions is used to define the widget. By editing the configuration object, you can customize the appearance and behavior of the web chat before it is rendered.\n* Runtime methods: Use the instance methods to perform tasks before a conversation between the assistant and your customer begins or after it ends.\n* Events: Your website can listen for these events, and then take custom actions.\n\n\n\nA developer can use these APIs to customize the web chat in the following ways:\n\n\n\n* [Change how the web chat opens and closes](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-open-close)\n* [Change the conversation](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-convo)\n* [Change the look of the web chat](https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-configweb-chat-config-look)\n\n\n\n\n\n\n\n Change how the web chat opens and closes \n\nYou can change the color of the launcher icon from the Style tab of the web chat configuration page. If you want to make more advanced customizations, you can make the following types of changes:\n\n\n\n* Change the launcher icon that is used to open the web chat widget. For a tutorial the shows you how, see [Using a custom launcher](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Change how the web chat widget opens.", "title": "", "source": "https://cloud.ibm.com/docs/assistant?topic=assistant-web-chat-config"}, {"document_id": "ibmcld_16295-7-1721", "score": 22.405522118431573, "text": "\nEmbedding the web chat on your page \n\nTo add the web chat widget to your website, all you need to do is embed a generated script element in your HTML source.\n\nThe web chat integration is automatically included for every assistant, and is configured separately for each environment.\n\nTo add the web chat to your website, follow these steps:\n\n\n\n1. On the ![Integrations icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/integrations-icon.png)Integrations page, find the Web chat tile and click click Open. The Open web chat window opens.\n2. In the Environment field, select the environment you want the web chat widget to connect to. Click Confirm.\n\nThe Web chat page opens, showing the settings for the web chat integration in the selected environment.\n\nThe preview pane shows what the web chat will look like when it is embedded in a web page. If you see a message that starts with, There is an error, you probably haven't added any actions to your assistant yet. After you add an action, you can test the conversation from the preview pane.\n3. Click the Embed tab.\n\nA code snippet is generated based on the web chat configuration. You (or a web developer) will add this code snippet to the web page where you want the web chat to appear.\n\nThis code snippet contains an HTML script element. The script calls JavaScript code that is hosted on an IBM site and creates an instance of a widget that communicates with the assistant.\n4. Click the ![Copy icon](https://cloud.ibm.com/docs-content/v1/content/ca9232b3702768f24bb897f48f10778fcda28718/watson-assistant/images/copy-icon.png)Copy to clipboard icon to copy the embed script to the clipboard.\n5.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-deploy-web-chat"}, {"document_id": "ibmcld_02855-5574-7284", "score": 21.723025017886222, "text": "\nFor more information, see the [Using a custom launcher tutorial](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-launcher).\n* Changing the size or position of the chat window that is displayed when users click the launcher button. For more information, see the [Render to a custom element tutorial](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=tutorials-example-element).\n\n\n\n14. Click the icon to open the chat window and talk to your assistant.\n\n![Web chat window](https://cloud.ibm.com/docs-content/v1/content/a2b18c153837bce00a5b4de496e4b4ca64bbf56e/assistant-data/images/web-chat-window.png)\n\nThe traffic to and from the web chat is sent between the instance that is hosted by your deployed cluster environment and the web page where you embed the web chat.\n15. Paste the code snippet into each web page where you want the assistant to be available to your customers.\n\nYou can paste the same script tag into as many pages on your website as you want. Add it anywhere that you want users to be able to reach your assistant for help. However, be sure to add it only one time per page.\n16. Submit test utterances from the chat widget that is displayed on your web page to see how the assistant responds.\n\nNo responses are returned until after you create a dialog skill and add it to the assistant.\n\nIf you don't extend the session timeout setting for the assistant, the dialog flow for the current session is restarted after 60 minutes of inactivity. This means that if a user stops interacting with the assistant, after 60 minutes, any context variable values that were set during the previous conversation are set to null or back to their initial values.", "title": "", "source": "https://cloud.ibm.com/docs/assistant-data?topic=assistant-data-deploy-web-chat"}, {"document_id": "ibmcld_16334-27263-29119", "score": 21.638463655134267, "text": "\nFor more information about the suggestions feature, see [Showing more suggestions](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-alternate). For more information about the home screen, see [Configuring the home screen](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-home-screen).\n* onError callback: The new onError callback option in the web chat configuration enables you to specify a callback function that is called if errors occur in the web chat. This makes it possible for you to handle any errors or outages that occur with the web chat. For more information, see [Listening for errors](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-configurationonerror-detail).\n* Session ID available in widget state: The state information returned by the getState() instance method now includes the session ID for the current conversation. For more information, see [instance.getState()](https://web-chat.global.assistant.watson.cloud.ibm.com/docs.html?to=api-instance-methodsgetState).\n* IBM watermark: The web chat can now display a Built with IBM Watson watermark to users. This watermark is always enabled for any new web chat integrations on Lite plans. For more information, see [Create a web chat instance to add to your website](https://cloud.ibm.com/docs/assistant?topic=assistant-deploy-web-chatdeploy-web-chat-task).\n* Fixes to rendering of list items: The rendering of HTML list items in the web chat widget has been updated.\n\n\n\n\n\n\n\n 4.1.0 \n\nRelease date: 8 April 2021\n\n\n\n* Home screen now generally available: Ease your customers into the conversation by adding a home screen to your web chat window. The home screen greets your customers and shows conversation starter messages that customers can click to easily start chatting with the assistant.", "title": "", "source": "https://cloud.ibm.com/docs/watson-assistant?topic=watson-assistant-release-notes-chat"}]}
{"task_id": "747a810abfd6da4a9c37cdb74feec95e<::>5", "Collection": "mt-rag-ibmcloud-elser-512-100-20240502", "contexts": [{"document_id": "ibmcld_07578-593375-595353", "score": 19.84818276125845, "text": "\n* When are the new Terraform and Ansible versions added to Schematics?\n\nAfter new Terraform and Ansible versions are released by the community, the IBM team begins hardening and testing the release for Schematics. Availability of new versions depends on the results of these tests, community updates, security patches, and technology changes between versions. Make sure that your Terraform templates and Ansible playbooks are compatible with one of the supported versions so that you can run them in Schematics. For more information, see [Upgrading the Terraform template version](https://cloud.ibm.com/docs/schematics?topic=schematics-migrating-terraform-version) and [Schematics runtime tools](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-utilitiessch-runtime-tf-job).\n* Can I run Ansible playbooks with Schematics?\n\nYes, you can run Ansible playbooks against your IBM Cloud by using the Schematics Actions or Ansible provisioner in your Terraform configuration file. For example, use the Ansible provisioner to deploy software on IBM Cloud resources or set actions against your resources, such as shutting down a virtual server instance. For more information, see [sample Ansible playbook templates for Schematics Actions](https://cloud.ibm.com/docs/schematics?topic=schematics-sample_actiontemplates).\n* What are the updates in the agent beta-1 release?\n\nThe following are the features in Agent beta-1 release.\n\n\n\n* Improvements to the agent deployment experience through CLI.\n* Support to run Ansible playbooks on the agent.\n* Dynamic assignment of workspace or action jobs to the agent.\n\n\n\n* What are the costs of installing and using Agents?\n\nThe following are the cost break-down for the Schematics Agent.\n\nPre-requisite: Agent infrastructure\n\n\n\n* Cost of VPC infrastructure elements such as, subnet, public gateways.\n* Cost of IBM Kubernetes Service (cluster) on VPC, with three-node worker pool.\n* Cost of IBM Cloud Object Storage\n\n\n\nAgent beta-1 service", "title": "", "source": "https://cloud.ibm.com/docs/faqs"}, {"document_id": "ibmcld_16727-593333-595311", "score": 19.84818276125845, "text": "\n* When are the new Terraform and Ansible versions added to Schematics?\n\nAfter new Terraform and Ansible versions are released by the community, the IBM team begins hardening and testing the release for Schematics. Availability of new versions depends on the results of these tests, community updates, security patches, and technology changes between versions. Make sure that your Terraform templates and Ansible playbooks are compatible with one of the supported versions so that you can run them in Schematics. For more information, see [Upgrading the Terraform template version](https://cloud.ibm.com/docs/schematics?topic=schematics-migrating-terraform-version) and [Schematics runtime tools](https://cloud.ibm.com/docs/schematics?topic=schematics-sch-utilitiessch-runtime-tf-job).\n* Can I run Ansible playbooks with Schematics?\n\nYes, you can run Ansible playbooks against your IBM Cloud by using the Schematics Actions or Ansible provisioner in your Terraform configuration file. For example, use the Ansible provisioner to deploy software on IBM Cloud resources or set actions against your resources, such as shutting down a virtual server instance. For more information, see [sample Ansible playbook templates for Schematics Actions](https://cloud.ibm.com/docs/schematics?topic=schematics-sample_actiontemplates).\n* What are the updates in the agent beta-1 release?\n\nThe following are the features in Agent beta-1 release.\n\n\n\n* Improvements to the agent deployment experience through CLI.\n* Support to run Ansible playbooks on the agent.\n* Dynamic assignment of workspace or action jobs to the agent.\n\n\n\n* What are the costs of installing and using Agents?\n\nThe following are the cost break-down for the Schematics Agent.\n\nPre-requisite: Agent infrastructure\n\n\n\n* Cost of VPC infrastructure elements such as, subnet, public gateways.\n* Cost of IBM Kubernetes Service (cluster) on VPC, with three-node worker pool.\n* Cost of IBM Cloud Object Storage\n\n\n\nAgent beta-1 service", "title": "", "source": "https://cloud.ibm.com/docs?tab=faqs"}, {"document_id": "ibmcld_11997-5537-6386", "score": 18.302287918822568, "text": "\n* Future: scheduled ops, drift detection, cost estimation, policy compliance\n\n\n\n\n\n\n\n\n\n Next steps \n\nSo far you have learned a little about Schematics Blueprints. The following are some next steps to explore.\n\n\n\n* [Working with blueprints and environments](https://cloud.ibm.com/docs/schematics?topic=schematics-work-with-blueprints) to understand how to use blueprints to manage the lifecycle of deploying and managing cloud environments.\n* See [understanding blueprint templates and configuration](https://cloud.ibm.com/docs/schematics?topic=schematics-blueprint-templates) to dig into how to define cloud environments using blueprint templates and inputs of latest version.\n* [Beta code for Schematics Blueprints](https://cloud.ibm.com/docs/schematics?topic=schematics-bp-beta-limitations) to provide your feedback and understand beta limitations.", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-blueprint-intro"}, {"document_id": "ibmcld_12581-17606-19704", "score": 17.052960205206773, "text": "\nIf you are validating a deployable architecture that references modules from the catalog, make sure that the modules were onboarded to the catalog.\n\n\n\n1. From the Validate version page, enter the name of your Schematics service, select a resource group, select a Schematics region, and click Next.\n\nIn the Tags field, you can enter a name of a specific tag to attach to your template. This tag is put on the IBM Cloud Schematics workspace. Tags provide a way to organize, track usage costs, and manage access to the resources in your account.\n2. From the input variables section, review your parameter values, and click Next.\n3. In the Validation version section, select I have read and agree to the following license agreements.\n4. Click Validate.\n\nTo monitor the progress of the validation process, click View logs.\n\n\n\n\n\n\n\n Validating a test deployment by using the CLI \n\nTo validate a version of your deployable architecture into an existing product, run the [ibmcloud catalog offering version validate](https://cloud.ibm.com/docs/cli?topic=cli-manage-catalogs-pluginvalidate-offering) command:\n\nibmcloud catalog offering version validate --vl <VERSION_LOCATOR>\n\n\n\n\n\n Reviewing cost by using the CLI \n\nReview the cost of your deployable architecture by using the console. To view the steps, see [Reviewing or defining cost by using the console](https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-onboard-custom&interface=uicustom-cost-ui).\n\n\n\n\n\n Reviewing or defining cost by using the console \n\nYou can review the estimated starting cost of your product. If you included the resource metadata in your source repository, the information is parsed during validation and pulled into a starting cost per hour (USD) summary table. The table is displayed in the catalog for customers to compare across variations of a deployable architecture or to get a general idea of what a base configuration of your deployable architecture might cost.\n\nThe summary table lists the resources that your product uses and their estimated costs. Starting cost is an estimate based on available data.", "title": "", "source": "https://cloud.ibm.com/docs/secure-enterprise?topic=secure-enterprise-onboard-custom"}, {"document_id": "ibmcld_08921-1291-2538", "score": 16.963394422578652, "text": "\n\"name\": \"Schematic Dev Workspace\",\n\u00a0 \"type\": [\n\u00a0\u00a0\u00a0 \"terraform_v0.13.7\"\n\u00a0 ],\n\u00a0 \"location\": \"us-south\",\n\u00a0 \"description\": \"Schematic Dev Workspace\",\n\u00a0 \"tags\": [],\n\u00a0 \"template_repo\": {\n\u00a0\u00a0\u00a0 \"url\": \"<GitHub repo URL>\",\n\u00a0\u00a0\u00a0 \"githubtoken\": \"<github-token>\"\n\u00a0 }\n\n\n\n Example Python request for schematics_variables_update.py file \n\nThe following Python example request is for the example file, schematics_variables_update.py.\n\nimport logging, os, json\n\nlogging.basicConfig()\nlogging.root.setLevel(logging.NOTSET)\nlogging.basicConfig(level=logging.NOTSET)\n\nfrom schematics_env_class import HPCCEnvironmentValues\n\nlogging.info(\"Schematic Variable Update Started\")\n\nif __name__ == '__main__':\n\n\u00a0\u00a0\u00a0 json_files = os.path.join(os.path.abspath(\".\"), \"config.json\")\n\n\u00a0\u00a0\u00a0 with open(json_files, \"r\") as file:\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 config_data = json.load(file)\n\n\u00a0\u00a0\u00a0 api_key = config_data[\"template_data\"][\"variablestore\"][\"value\"]\n\n\u00a0\u00a0\u00a0 schematic_obj = HPCCEnvironmentValues(api_key)\n\n\u00a0\u00a0\u00a0 workspace_response = schematic_obj.schematics_service.get_workspace(w_id=\"<workspace id>\").get_result()\n\u00a0\u00a0\u00a0 schematic_obj.update_variables(w_id=\"<workspace id>\",\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 t_id=workspace_response[\"template_data\"][\"id\"],\u00a0\n\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 variablestore=config_data[\"template_data\"][\"variablestore\"]\n\u00a0\u00a0\u00a0 )", "title": "", "source": "https://cloud.ibm.com/docs/ibm-spectrum-lsf?topic=ibm-spectrum-lsf-update-variables"}, {"document_id": "ibmcld_12008-4112-6332", "score": 16.711946464471154, "text": "\nCorrect the Terraform config error at source and push a new release to its Git source repository.\n\nIf explicit version of the blueprint modules is used on specific branches. The blueprint template requires updating in its Git repository to specify the new release tag or branch for the module statement.\n\n\n\n* Update the blueprint module statements to specify the new module version.\n* Push the new release of the blueprint template to its Git source repository. With an updated release tag for the template if needed.\n\n\n\nFor modules, when no Git release is specified on the blueprint module statements and relaxed module version are used. No update to the blueprint template is needed. The current change to the module repository is pulled automatically by Schematics.\n\nRun the ibmcloud schematics blueprint update command to refresh the blueprint configuration that is stored by Schematics with the update to the blueprint template. With latest release, Schematics identifies the updated module Git repository and run the Pull-Latest to update any modules with the modified Terraform configurations.\n\nibmcloud schematics blueprint update -id <blueprint_ID>\u00a0\n\nIf explicit version is used with release tags for each blueprint template release, the blueprint configuration must be updated in Schematics with the new release tag.\n\nibmcloud schematics blueprint update --id <blueprint_ID> --bp-git-release x.y.z\u00a0\u00a0\n\nFinally, run the ibmcloud schematics blueprint apply command to rerun the failed Terraform Apply operation and to complete all operations against all modules.\n\nibmcloud schematics blueprint apply -id <blueprint_ID>\u00a0\n\n\n\n\n\n Blueprint apply failure due to Terraform timeouts or transient failures \n\n What\u2019s happening \n\nWhen you run the blueprint apply command, it fails with message that the install of module fails.\n\n Why it\u2019s happening \n\nAnalysis of the logs indicates that the modules Terraform apply operation that is timed out or a transient failure occurs.\n\n How to fix it \n\nNo user action must be necessary to recover and the apply operation can be retried.\n\nRun the ibmcloud schematics blueprint apply command to rerun the failed Terraform Apply operation and complete all operations against all modules.", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-bp-apply-fails"}, {"document_id": "ibmcld_08295-130293-131214", "score": 16.584385880378704, "text": "\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- </section \"id=\"section-syntax_of_variablestore\" \"> --><-- </section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !", "title": "", "source": "https://cloud.ibm.com/docs/hpc-slurm?topic=hpc-slurm-schematics-cli-reference"}, {"document_id": "ibmcld_12258-139533-140454", "score": 16.584385880378704, "text": "\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- </section \"id=\"section-syntax_of_variablestore\" \"> --><-- </section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !", "title": "", "source": "https://cloud.ibm.com/docs/schematics?topic=schematics-schematics-cli-reference&interface=cli"}, {"document_id": "ibmcld_04516-139667-140633", "score": 16.494414574935746, "text": "\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- </section \"id=\"section-syntax_of_variablestore\" \"> --><-- </section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace. Initial support for files up to 4MB in size.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !", "title": "", "source": "https://cloud.ibm.com/docs/cli?topic=cli-schematics-cli-reference"}, {"document_id": "ibmcld_08331-131395-132711", "score": 16.405236025343765, "text": "\ntemplate_data[0].variablestore[v].use_default Optional Set the use_default parameter to true to override the default .tfvars parameter. By default, this parameter is set to false. \n github_source_repo_url Optional Enter the link to your GitHub repository. The link can point to the master branch, a different branch, or a subdirectory. \n\n\n\n\n\n\n\n Example for variable store \n\n\"variablestore\": [\n{\n\"value\": \"n {n internal = 800n external = 83009n protocol = \"tcp\"n }n ] ! ! ! \",\n\"description\": \"\",\n\"name\": \"docker_ports\",\n\"type\": \"list(object({n internal = numbern external = numbern protocol = stringn }))\",\n\"use_default\":true\n},\nExample ibmcloud schematics workspace update --id myworkspace-a1aa1a1a-a11a-11 --file myfile.json --json\n<-- </section \"id=\"section-syntax_of_variablestore\" \"> --><-- </section \"id=\"section-schematics-workspace-update\" \"> --><-- <section \"id=\"section-schematics-workspace-upload\" \"> --> ibmcloud schematics workspace upload Provide your Terraform template by uploading a tape archive file (.tar) to your Schematics Workspace.Before you begin, make sure that you created your workspace]ibmcloud workspace new] without a link to a GitHub or GitLab repository.Syntax ibmcloud schematics workspace upload --id WORKSPACE_ID --file FILE_NAME --template TEMPLATE_ID --output OUTPUT]--json] ! ! !", "title": "", "source": "https://cloud.ibm.com/docs/hpc-spectrum-scale?topic=hpc-spectrum-scale-schematics-cli-reference"}]}
